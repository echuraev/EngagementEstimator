{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cbdbb52-efcf-422d-9c12-ba1596b5e5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be3a71b-e9c9-4df9-8354-88a175b3908b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 09:22:03.732363: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-05 09:22:03.770302: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 09:22:03.770328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 09:22:03.770367: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 09:22:03.777585: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-05 09:22:04.454015: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.1.0+cu121\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential, load_model, model_from_json\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, classification_report\n",
    "\n",
    "print(f\"Torch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff1af93-899e-4029-ba0f-8a44f500743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense, Activation, Concatenate, Reshape\n",
    "from tensorflow.keras.layers import Flatten, RepeatVector, Permute, TimeDistributed\n",
    "from tensorflow.keras.layers import Multiply, Lambda, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b8b96fe-a854-476f-9b38-e28e75ddaed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/media/deelvin_disk/echuraev/Workspace/HSE/engagement/'\n",
    "BATCH_SIZE = 128\n",
    "TABLE_NAME = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000c5344-e9d5-42ce-b467-56ec2a66b41f",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "690cd1a6-aa5c-4cbb-af14-60c58d349397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_features(file_name, features):\n",
    "    if os.path.isfile(file_name):\n",
    "        print(\"Error! Cannot save features because file already exists\")\n",
    "        return\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(features, f) # , protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def load_features(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def save_weights(model, file_name):\n",
    "    if os.path.isfile(file_name):\n",
    "        print(\"Error! Cannot save features because file already exists\")\n",
    "        return\n",
    "    model.save_weights(file_name)\n",
    "\n",
    "def load_weights(model, file_name):\n",
    "    model.load_weights(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "203fda8c-0c21-4591-abbb-f52f494e58e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion_matrix(all_preds, all_labels):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import pandas as pd\n",
    "    import seaborn as sn\n",
    "\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for p in all_preds:\n",
    "        preds.append(float2int[p])\n",
    "    for l in all_labels:\n",
    "        labels.append(float2int[l])\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    preds = np.array(preds)\n",
    "    data=confusion_matrix(labels, preds)\n",
    "\n",
    "    df_cm = pd.DataFrame(data, columns=labels_list)\n",
    "    df_cm.index.name = 'Actual'\n",
    "    df_cm.columns.name = 'Predicted'\n",
    "    plt.figure(figsize = (13,10))\n",
    "    sn.set(font_scale=3)#for label size\n",
    "    sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16*2.5}, fmt='g')# font size\n",
    "    plt.yticks(np.arange(len(labels_list))+0.5, labels_list, rotation=0, va=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee3b5b51-fa74-4915-bce2-4f6f01f7e0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_sequences2norm_features(features):\n",
    "    ret = []\n",
    "    for i in range(len(features)):\n",
    "        ret.append(stat_func(features[i], axis=0))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a1cab33-de58-4395-bd65-0769de182bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred2label(pred):\n",
    "    if pred < 0.25:\n",
    "        return 0.0\n",
    "    if pred < 0.5:\n",
    "        return 0.33\n",
    "    if pred < 0.75:\n",
    "        return 0.66\n",
    "    return 1.0\n",
    "\n",
    "def get_prediction(model, file2feat, with_processing=False):\n",
    "    y_pred = []\n",
    "    exp_pred = []\n",
    "    for fn, x in file2feat.items():\n",
    "        #print(x.shape)\n",
    "        if len(x)==0:\n",
    "            continue\n",
    "        if CONCATENATE_STAT:\n",
    "            mean_x=np.repeat(stat_func(x,axis=0).reshape((1,-1)),len(x),axis=0)            \n",
    "            #preds=model.predict(np.expand_dims(np.concatenate((mean_x,x-mean_x),axis=1), axis=0))[0]\n",
    "            pred=model.predict(np.expand_dims(np.concatenate((mean_x,x),axis=1), axis=0), verbose=0)\n",
    "        else:\n",
    "            pred=model.predict(np.expand_dims(x, axis=0), verbose=0)\n",
    "        #y_pred.append(np.argmax(pred))\n",
    "        #if with_processing:\n",
    "        #    y_pred.append(pred2label(pred[0]))\n",
    "        #else:\n",
    "        #    y_pred.append(float(pred[0]))\n",
    "        y_pred.append(float(pred[0]))\n",
    "        exp_pred.append(video2label[fn])\n",
    "    return np.array(y_pred), np.array(exp_pred)\n",
    "\n",
    "def prediction2bin(preds, threshold):\n",
    "    y_pred = []\n",
    "    for y in preds:\n",
    "        if N_CLASSES == 2:\n",
    "            y = 0 if y < threshold else 1\n",
    "        y_pred.append(y)\n",
    "    return y_pred\n",
    "\n",
    "def dump_to_table(table_name, metric_name, acc, mse, uar, recall, precision, f1, num_comma=\",\"):\n",
    "    def _to_str(num, num_comma):\n",
    "        if num_comma == \",\":\n",
    "            return str(num).replace(\".\", \",\")\n",
    "        return str(num).replace(\",\", \".\")\n",
    "    \n",
    "    import pandas as pd\n",
    "    if os.path.isfile(table_name):\n",
    "        df = pd.read_excel(open(table_name,'rb'))\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['metric_name', 'accuracy', 'mse', 'uar', 'recall', 'precision', 'f1'])\n",
    "\n",
    "    idx = len(df)\n",
    "    # Remove previous recordings\n",
    "    df = df[df.metric_name != metric_name]\n",
    "    df.loc[idx] = [\n",
    "        metric_name,\n",
    "        _to_str(acc, num_comma),\n",
    "        _to_str(mse, num_comma),\n",
    "        _to_str(uar, num_comma),\n",
    "        _to_str(recall, num_comma),\n",
    "        _to_str(precision, num_comma), \n",
    "        _to_str(f1, num_comma)\n",
    "    ] \n",
    "    df.to_excel(table_name, index=False) \n",
    "    \n",
    "\n",
    "def print_results(pred, labels, table_name=None, metric_name=None, from_int=False):\n",
    "    if from_int is False:\n",
    "        float2int={0:0,0.33:1,0.66:2,1:3}\n",
    "        if N_CLASSES == 2:\n",
    "            float2int={0:1,0.33:1,0.66:0,1:0}\n",
    "        pred_int = np.array([float2int[pred2label(l)] for l in pred])\n",
    "        labels_int = np.array([float2int[l] for l in labels])\n",
    "        #labels_float = np.array([int2float[l] for l in labels])\n",
    "        #pred_float = np.array([int2float[l] for l in pred])\n",
    "        acc = (labels_int==pred_int).mean()\n",
    "        #if N_CLASSES == 2:\n",
    "        #    mse = ((labels-pred)**2).mean()\n",
    "        #else:\n",
    "        #    mse = ((labels_float-pred_float)**2).mean()\n",
    "        mse = ((labels-pred)**2).mean()\n",
    "        uar = recall_score(y_true=labels_int,y_pred=pred_int, average='macro')\n",
    "        if N_CLASSES == 2:\n",
    "            recall = recall_score(y_true=labels,y_pred=pred, average='binary',pos_label=1)\n",
    "            precision = precision_score(y_true=labels,y_pred=pred, average='binary',pos_label=1)\n",
    "            f1 = f1_score(y_true=labels,y_pred=pred, average='binary',pos_label=1)\n",
    "        else:\n",
    "            recall = 'N/A'\n",
    "            precision = 'N/A'\n",
    "            f1 = f1_score(y_true=labels_int,y_pred=pred_int, average='macro')\n",
    "    else:\n",
    "        int2float = {0:0.0, 1: 0.33, 2:0.66, 3: 1.0}\n",
    "        labels_float = np.array([int2float[l] for l in labels])\n",
    "        pred_float = np.array([int2float[l] for l in pred])\n",
    "        acc = (labels==pred).mean()\n",
    "        if N_CLASSES == 2:\n",
    "            mse = ((labels-pred)**2).mean()\n",
    "        else:\n",
    "            mse = ((labels_float-pred_float)**2).mean()\n",
    "        uar = recall_score(y_true=labels,y_pred=pred, average='macro')\n",
    "        if N_CLASSES == 2:\n",
    "            recall = recall_score(y_true=labels,y_pred=pred, average='binary',pos_label=1)\n",
    "            precision = precision_score(y_true=labels,y_pred=pred, average='binary',pos_label=1)\n",
    "            f1 = f1_score(y_true=labels,y_pred=pred, average='binary',pos_label=1)\n",
    "        else:\n",
    "            recall = 'N/A'\n",
    "            precision = 'N/A'\n",
    "            f1 = f1_score(y_true=labels,y_pred=pred, average='macro')\n",
    "    print('Metric_name: ', metric_name,\n",
    "          'Accuracy: ', acc,\n",
    "          'MSE: ', mse,\n",
    "          'UAR: ', uar,\n",
    "          'Recall: ', recall,\n",
    "          'Precision: ', precision,\n",
    "          'F1: ', f1)\n",
    "    if table_name is not None and metric_name is not None:\n",
    "        dump_to_table(table_name, metric_name, acc, mse, uar, recall, precision, f1)\n",
    "    return acc, mse, uar, recall, precision, f1\n",
    "\n",
    "def print_mse(preds, labels):\n",
    "    diff_correct,num_total=0.0,0\n",
    "    for i in range(len(preds)):\n",
    "        diff_correct+=(preds[i]-labels[i])**2\n",
    "        num_total+=1\n",
    "    print(num_total,diff_correct/num_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af2468be-d8a0-4500-97df-139a94874c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_dataset(engage_wild_dataset, bin_classification):\n",
    "    ENGAGE_WILD_DATASET = engage_wild_dataset\n",
    "    BIN_CLASSIFICATION = bin_classification\n",
    "    if BIN_CLASSIFICATION is True:\n",
    "        N_CLASSES = 2\n",
    "    else:\n",
    "        N_CLASSES = 4\n",
    "    if ENGAGE_WILD_DATASET is True:\n",
    "        ext = \"png\"\n",
    "        DATASET_NAME = 'EngageWild'\n",
    "        BASE_DATASET_DIR = '/home/HDD6TB/datasets/emotions/EmotiW/engagement/'\n",
    "        BASE_DATASET_DIR = '/media/deelvin_disk/echuraev/Workspace/HSE/datasets/EngageWild'\n",
    "    else:\n",
    "        ext = \"jpg\"\n",
    "        DATASET_NAME = 'DAiSEE'\n",
    "        BASE_DATASET_DIR = '/home/HDD6TB/datasets/emotions/DAiSEE/'\n",
    "        BASE_DATASET_DIR = '/media/deelvin_disk/echuraev/Workspace/HSE/datasets/DAiSEE'\n",
    "\n",
    "    return ENGAGE_WILD_DATASET, BIN_CLASSIFICATION, N_CLASSES, DATASET_NAME, BASE_DATASET_DIR, ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "373346b1-9103-44bc-b50d-60301a410255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video2label():\n",
    "    labels_list = ['very distracted', 'distracted', 'engaged', 'very engaged']\n",
    "    float2int={0:0,0.33:1,0.66:2,1:3}\n",
    "    if ENGAGE_WILD_DATASET is True:\n",
    "        import csv\n",
    "        video2label={}\n",
    "        with open(os.path.join(BASE_DATASET_DIR,'Engagement_Labels_Engagement.csv'), mode='r') as csvfile:\n",
    "            labels_reader = csv.reader(csvfile, delimiter='\\t')\n",
    "            for i,row in enumerate(labels_reader):\n",
    "                if i==0:\n",
    "                    continue\n",
    "                #videoname,label=row[0],float2int[float(row[1])]\n",
    "                videoname,label=row[0],float(row[1])\n",
    "                video2label[videoname]=label\n",
    "                #print(videoname,label)\n",
    "                #if (videoname not in filename2features_val) and (videoname not in filename2features_train):\n",
    "                #    print(videoname,label)\n",
    "        #check if fix is incorrect\n",
    "        video2label['subject_87_Vid_3']=video2label['subject_77_Vid_6']\n",
    "        #video2label = to_categorical(video2label)\n",
    "        #print(len(video2label))\n",
    "        #print(video2label)\n",
    "    else:\n",
    "        import pandas as pd\n",
    "        df=pd.read_csv(os.path.join(BASE_DATASET_DIR,'Labels/AllLabels.csv'))\n",
    "        df.columns = df.columns.str.replace(' ', '')\n",
    "        df.head()\n",
    "        labels2fileAndValues=df.set_index('ClipID').to_dict()\n",
    "        video2label={os.path.splitext(video)[0]:val for video,val in labels2fileAndValues['Engagement'].items()}\n",
    "        int2float = {0:0.0, 1: 0.33, 2:0.66, 3: 1.0}\n",
    "        for k, v in video2label.items():\n",
    "            video2label[k] = int2float[video2label[k]]\n",
    "        #print(video2label)\n",
    "    #print(video2label)\n",
    "    if N_CLASSES == 2:\n",
    "        labels_list = ['engaged', 'distracted']\n",
    "        bin_labels = {0:1, 1:1, 2:0, 3:0}\n",
    "        for k in video2label.keys():\n",
    "            video2label[k] = bin_labels[float2int[video2label[k]]]\n",
    "    return video2label, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e892933-aa4b-494f-9e10-08d3de782583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_path(metric_name):\n",
    "    return WEIGHTS_DIR + \"{}.h5\".format(metric_name)\n",
    "    \n",
    "def get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, aggregator, classificator):\n",
    "    return \"{}_{}_{}_{}_{}\".format(base_model_key, DATASET_NAME, N_CLASSES, aggregator, classificator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b40c7059-6a3d-4dc5-8d27-e89797e97e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classes(labels):\n",
    "    min_num = len(labels)\n",
    "    for i in np.unique(labels):\n",
    "        count = labels.count(i)\n",
    "        if count < min_num:\n",
    "            min_num = count\n",
    "        percent = count * 100 / len(labels)\n",
    "        print(\"{} {}/{}: {}%\".format(i, count, len(labels), percent))\n",
    "\n",
    "def get_labels(fn2feat):\n",
    "    labels = []\n",
    "    for fn in fn2feat.keys():\n",
    "        labels.append(video2label[fn])\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb41a413-6ea8-482c-9967-798a50a5b079",
   "metadata": {},
   "source": [
    "## Dataset balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b5d88ee-9f09-48dd-8889-500f8e2c1acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(filename2features):\n",
    "    x = []\n",
    "    y = []\n",
    "    ind=0\n",
    "    for fn in filename2features:\n",
    "        features=filename2features[fn]\n",
    "        total_features=None\n",
    "        if USE_ALL_FEATURES:\n",
    "            #prev=features[0].shape\n",
    "            cur_features=features[0][features[-1]==1]\n",
    "            #if filename2features_val==filename2features:\n",
    "            #    print(cur_features.shape)\n",
    "            #    cur_features=cur_features[2:]\n",
    "            #print(prev,features.shape)\n",
    "        else:\n",
    "            cur_features=features\n",
    "        \n",
    "        total_features=stat_func(cur_features)\n",
    "        if total_features is not None:\n",
    "            x.append(total_features)\n",
    "            y.append(video2label[fn])\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    print(x.shape,y.shape)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58a5385f-6003-4ad7-8cd3-b484baf9fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(7)\n",
    "\n",
    "def get_train_test_indices(x_all, y_all, SPLIT_RATIO):\n",
    "    inds_train, inds_test = [], []\n",
    "    inds = np.arange(len(y_all))\n",
    "    \n",
    "    for lbl in np.unique(y_all):\n",
    "        tmp_inds = inds[y_all == lbl]\n",
    "        random.shuffle(tmp_inds)\n",
    "        \n",
    "        ind=int(len(tmp_inds) * SPLIT_RATIO)\n",
    "        inds_train.append(tmp_inds[:ind])\n",
    "        inds_test.append(tmp_inds[ind:])\n",
    "    \n",
    "    inds_train = np.concatenate(inds_train, axis=0)\n",
    "    inds_test = np.concatenate(inds_test, axis=0)\n",
    "    return inds_train, inds_test\n",
    "\n",
    "def get_train_test():\n",
    "    inds_train, inds_test = get_train_test_indices()\n",
    "    X_train=x_all[inds_train]\n",
    "    y_train=y_all[inds_train]\n",
    "    X_test=x_all[inds_test]\n",
    "    y_test=y_all[inds_test]\n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f6b4d33-6613-4fc7-b389-6692e9a8b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_new_dataset(filename2features_train, filename2features_test, SPLIT_RATIO): # =0.767):\n",
    "    x_train, y_train = create_dataset(filename2features_train)\n",
    "    x_test, y_test = create_dataset(filename2features_test)\n",
    "\n",
    "    x_all=np.concatenate((x_train,x_test),axis=0)\n",
    "    y_all=np.concatenate((y_train,y_test),axis=0)\n",
    "    print(x_all.shape,y_all.shape)\n",
    "    \n",
    "    labels,counts=np.unique(y_all,return_counts=True)\n",
    "    print(labels,counts)\n",
    "\n",
    "    filenames_all=list(filename2features_train.keys())+list(filename2features_test.keys())\n",
    "    print(len(filenames_all))\n",
    "    \n",
    "    random.seed(7)\n",
    "    inds_train, inds_val = get_train_test_indices(x_all, y_all, SPLIT_RATIO)\n",
    "    \n",
    "    def get_filename2features_new(inds):\n",
    "        filename2features_new={}\n",
    "        for ind in inds:\n",
    "            filename=filenames_all[ind]\n",
    "            if filename in filename2features_train:\n",
    "                filename2features_new[filename]=filename2features_train[filename]\n",
    "            else:\n",
    "                filename2features_new[filename]=filename2features_test[filename]\n",
    "        print(len(filename2features_new))\n",
    "        return filename2features_new\n",
    "    filename2features_train_new=get_filename2features_new(inds_train)\n",
    "    filename2features_val_new=get_filename2features_new(inds_val)\n",
    "\n",
    "    return filename2features_train_new, filename2features_val_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e2f3045-37f6-4b28-90c9-c046f45d8142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_descriptor(cur_features, axis=0):\n",
    "    #cur_features=cur_features[1000:]\n",
    "    #cur_features=cur_features[30:-30]\n",
    "    #mean_features=features.mean(axis=0)\n",
    "    mean_features = np.mean(cur_features, axis=0)\n",
    "    std_features = np.std(cur_features, axis=0)\n",
    "    max_features = np.max(cur_features, axis=0)\n",
    "    min_features = np.min(cur_features, axis=0)\n",
    "\n",
    "    # join several features together\n",
    "    #feature = np.concatenate((mean_features, std_features, min_features, max_features), axis=None)                    \n",
    "    #feature = np.concatenate((mean_features, std_features, max_features), axis=None)\n",
    "    #feature = np.concatenate((mean_features, min_features, max_features), axis=None)\n",
    "    feature = np.concatenate((mean_features, std_features), axis=None)\n",
    "    #feature = np.concatenate((max_features, std_features), axis=None)\n",
    "\n",
    "    #feature=std_features\n",
    "    #feature=mean_features\n",
    "    #feature=np.percentile(cur_features, 100,axis=0)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a7c8f-7ae5-47c7-afb5-5440ff9610a5",
   "metadata": {},
   "source": [
    "## Attention specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48fea5d6-24c3-45f1-8648-3e5408d11c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SET_SIZE=128 #32 #20\n",
    "USE_GENERATORS = False\n",
    "USE_ALL_FEATURES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47e5377f-7c0a-413d-a054-39a6ee75e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(features_list, labels_list):\n",
    "    X_subsample,y_subsample=[],[]\n",
    "    for i in range(len(features_list)):\n",
    "        features=features_list[i]\n",
    "        label = labels_list[i]\n",
    "        total_features=None\n",
    "        if USE_ALL_FEATURES:\n",
    "            x=features[0][features[-1]==1]\n",
    "        else:\n",
    "            x=features\n",
    "        max_ind=len(x)-IMAGE_SET_SIZE\n",
    "        if max_ind<=0:\n",
    "            continue\n",
    "        stat_x=stat_func(x,axis=0)\n",
    "        num_samples=max(max_ind//(IMAGE_SET_SIZE),1)\n",
    "        for frame_ind in random.sample(range(max_ind),k=num_samples):\n",
    "            if CONCATENATE_STAT:\n",
    "                X_current=[np.concatenate((stat_x,x[frame_ind+i])) for i in range(IMAGE_SET_SIZE)]\n",
    "            else:\n",
    "                X_current=[x[frame_ind+i] for i in range(IMAGE_SET_SIZE)]\n",
    "            X_subsample.append(X_current)\n",
    "            y_subsample.append(label)\n",
    "    \n",
    " \n",
    "    X_subsample = np.array(X_subsample)\n",
    "    y_subsample=np.array(y_subsample)\n",
    "    print(X_subsample.shape,y_subsample.shape)\n",
    "    return X_subsample,y_subsample\n",
    "\n",
    "def get_samples(filename2features):\n",
    "    X_subsample,y_subsample=[],[]\n",
    "    for fn in filename2features:\n",
    "        features=filename2features[fn]\n",
    "        total_features=None\n",
    "        if USE_ALL_FEATURES:\n",
    "            x=features[0][features[-1]==1]\n",
    "        else:\n",
    "            x=features\n",
    "        max_ind=len(x)-IMAGE_SET_SIZE\n",
    "        if max_ind<=0:\n",
    "            continue\n",
    "        stat_x=stat_func(x,axis=0)\n",
    "        num_samples=max(max_ind//(IMAGE_SET_SIZE),1)\n",
    "        for frame_ind in random.sample(range(max_ind),k=num_samples):\n",
    "            if CONCATENATE_STAT:\n",
    "                X_current=[np.concatenate((stat_x,x[frame_ind+i])) for i in range(IMAGE_SET_SIZE)]\n",
    "            else:\n",
    "                X_current=[x[frame_ind+i] for i in range(IMAGE_SET_SIZE)]\n",
    "            X_subsample.append(X_current)\n",
    "            y_subsample.append(video2label[fn])\n",
    "    \n",
    " \n",
    "    X_subsample = np.array(X_subsample)\n",
    "    y_subsample=np.array(y_subsample)\n",
    "    print(X_subsample.shape,y_subsample.shape)\n",
    "    return X_subsample,y_subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1796b579-60bf-4967-b792-2c7cf1fae864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(features, labels):\n",
    "    X_subsample = []\n",
    "    Y_subsample = []\n",
    "    while True:\n",
    "        idx = random.randrange(len(labels))\n",
    "        x = features[idx]\n",
    "        img_count=len(x)\n",
    "        num_per_part = img_count // IMAGE_SET_SIZE\n",
    "\n",
    "        if img_count < IMAGE_SET_SIZE:\n",
    "            continue\n",
    "\n",
    "        mean_x=stat_func(x,axis=0)\n",
    "        for j in range(img_count):\n",
    "            if CONCATENATE_STAT:\n",
    "                #X_current=[np.concatenate((mean_x,x[frame_ind+i]-mean_x)) for i in range(IMAGE_SET_SIZE)]\n",
    "                X_current=[np.concatenate((mean_x,x[random.randint(num_per_part*j, min(num_per_part*(j+1),img_count-1))])) for j in range(IMAGE_SET_SIZE)]\n",
    "            else:\n",
    "                X_current=[x[random.randint(num_per_part*j, min(num_per_part*(j+1),img_count-1))] for j in range(IMAGE_SET_SIZE)]\n",
    "            X_subsample.append(X_current)\n",
    "            Y_subsample.append(labels[idx])\n",
    "            if len(Y_subsample) >= BATCH_SIZE:\n",
    "                X_subsample = np.array(X_subsample)\n",
    "                Y_subsample = np.array(Y_subsample)\n",
    "                yield X_subsample, Y_subsample\n",
    "                X_subsample = []\n",
    "                Y_subsample = []\n",
    "\n",
    "\n",
    "def get_num_samples(features):\n",
    "    num_samples = 0\n",
    "    for idx in range(len(features)):\n",
    "        x = features[idx]\n",
    "        img_count=len(x)\n",
    "        num_per_part = img_count // IMAGE_SET_SIZE\n",
    "\n",
    "        if img_count < IMAGE_SET_SIZE:\n",
    "            continue\n",
    "\n",
    "        num_samples += img_count\n",
    "\n",
    "    if num_samples % BATCH_SIZE > 0:\n",
    "        num_samples += BATCH_SIZE\n",
    "\n",
    "    if CONCATENATE_STAT:\n",
    "        mean_x=stat_func(x,axis=0)\n",
    "        #X_current=[np.concatenate((mean_x,x[frame_ind+i]-mean_x)) for i in range(IMAGE_SET_SIZE)]\n",
    "        vector_dim = len(np.concatenate((mean_x,x[random.randint(0, min(num_per_part,img_count-1))])))\n",
    "    else:\n",
    "        vector_dim = len(x[random.randint(0, min(num_per_part,img_count-1))])\n",
    "    return num_samples, vector_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "147937c0-db4d-439d-b58d-cd0bfaf66408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model,Model\n",
    "class SaveBestModel(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, save_best_metric='val_loss', this_max=False):\n",
    "        self.save_best_metric = save_best_metric\n",
    "        self.max = this_max\n",
    "        if this_max:\n",
    "            self.best = float('-inf')\n",
    "        else:\n",
    "            self.best = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metric_value = logs[self.save_best_metric]\n",
    "        if self.max:\n",
    "            if metric_value > self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_model_weights = self.model.get_weights()\n",
    "\n",
    "        else:\n",
    "            if metric_value < self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_model_weights = self.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "040d6c89-9f1e-45fb-bef2-5d21b0766ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d075de3-053a-43ba-955f-bb7e68a63135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES):\n",
    "    inputs = Input(shape=(None, FEATURE_VECTOR_DIM),name='image_set')  # (batch, samples, features)\n",
    "    e = Dense(1, activation='linear', name='e')(inputs)\n",
    "    e = Reshape([-1], name='alignment')(e)\n",
    "    alpha = Activation('softmax', name='alpha')(e)\n",
    "    \n",
    "    alpha_repeated = Permute([2, 1],name='alpha_repeated')(RepeatVector(FEATURE_VECTOR_DIM, name='repeat')(alpha))\n",
    "    \n",
    "    c = Multiply(name='c')([inputs, alpha_repeated])\n",
    "    x = Lambda(lambda xin: K.sum(xin, axis=1), output_shape=(FEATURE_VECTOR_DIM,), name='context')(c)\n",
    "    \n",
    "    #x = Dropout(0.3)(x)\n",
    "    x = Dense(units=512, activation='relu', name='hidden_FC')(x)  # (batch, units) #128 64\n",
    "    #x = tf.keras.activations.gelu(Dense(512, activation='linear')(x))\n",
    "\n",
    "    #pred=Dense(N_CLASSES,activation='softmax')(x)\n",
    "    pred=Dense(1,activation='sigmoid')(x)\n",
    "    modelAtn=Model(inputs=inputs,outputs=pred)\n",
    "    #modelAtn.compile(optimizer=Adam(lr=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    if N_CLASSES == 2:\n",
    "        #modelAtn.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['acc', f1_m,precision_m, recall_m])\n",
    "        metrics=['acc',tf.keras.metrics.AUC(multi_label=True,name='auc'), tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.Recall(),tf.keras.metrics.Precision()]\n",
    "        modelAtn.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=metrics)\n",
    "    else:\n",
    "        modelAtn.compile(optimizer=Adam(lr=1e-4), loss='mse', metrics=['mae'])\n",
    "    modelAtn.summary()\n",
    "\n",
    "    #save_best_model = SaveBestModel('val_accuracy',True)\n",
    "    save_best_model = SaveBestModel('val_loss',False)\n",
    "    return modelAtn, save_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0261c53f-a317-428c-b48b-81fc4cd67929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES):\n",
    "    embeddings_dim=512\n",
    "    embeddings_dim=FEATURE_VECTOR_DIM\n",
    "    inputs = Input(shape=(None, FEATURE_VECTOR_DIM),name='image_set')  # (batch, samples, features)\n",
    "    if False:\n",
    "        query_seq_encoding, value_seq_encoding=inputs,inputs\n",
    "    else:\n",
    "        query_seq_encoding=Dense(embeddings_dim, activation='linear',use_bias=False, name='query')(inputs)\n",
    "        value_seq_encoding=Dense(embeddings_dim, activation='linear',use_bias=False, name='value')(inputs)\n",
    "    query_value_attention_seq = tf.keras.layers.Attention()([query_seq_encoding, value_seq_encoding])\n",
    "    \n",
    "    e = Dense(1, activation='linear', name='e')(query_value_attention_seq)\n",
    "    e = Reshape([-1], name='alignment')(e)\n",
    "    alpha = Activation('softmax', name='alpha')(e)\n",
    "    \n",
    "    alpha_repeated = Permute([2, 1],name='alpha_repeated')(RepeatVector(embeddings_dim, name='repeat')(alpha))\n",
    "    \n",
    "    c = Multiply(name='c')([query_value_attention_seq, alpha_repeated])\n",
    "    x = Lambda(lambda xin: K.sum(xin, axis=1), output_shape=(embeddings_dim,), name='context')(c)\n",
    "\n",
    "    #pred=Dense(N_CLASSES,activation='softmax')(x)\n",
    "    pred=Dense(1,activation='sigmoid')(x)\n",
    "    modelAtn=Model(inputs=inputs,outputs=pred)\n",
    "    #modelAtn.compile(optimizer=Adam(lr=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    if N_CLASSES == 2:\n",
    "        #modelAtn.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['acc', f1_m,precision_m, recall_m])\n",
    "        metrics=['acc',tf.keras.metrics.AUC(multi_label=True,name='auc'), tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.Recall(),tf.keras.metrics.Precision()]\n",
    "        modelAtn.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=metrics)\n",
    "    else:\n",
    "        modelAtn.compile(optimizer=Adam(lr=1e-4), loss='mse', metrics=['mae'])\n",
    "    modelAtn.summary()\n",
    "\n",
    "    #save_best_model = SaveBestModel('val_accuracy',True)\n",
    "    save_best_model = SaveBestModel('val_loss',False)\n",
    "    return modelAtn, save_best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd92ed1-9dd6-4c7c-a9a1-938f2b2716ec",
   "metadata": {},
   "source": [
    "# EngageWild dataset (4 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f28e1c4-93f0-4ecc-b130-0983d744aa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_DIR = DATA_DIR + 'features_EngageWild/'\n",
    "WEIGHTS_DIR = DATA_DIR + 'weights_EngageWild/'\n",
    "TABLE_NAME = '02_EngageWild_4_classes.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5112ce-2f9c-4bd8-a107-145cfcabd316",
   "metadata": {},
   "source": [
    "## enet_b0_8_best_afew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72c65ed3-b57c-4084-b551-cdb41a82e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_key = 'enet_b0_8_best_afew.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44e5336d-317a-4c08-8450-ef57609e7104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['very distracted', 'distracted', 'engaged', 'very engaged']\n",
      "{'subject_1_Vid_1': 1.0, 'subject_1_Vid_2': 1.0, 'subject_1_Vid_3': 0.66, 'subject_1_Vid_4': 1.0, 'subject_1_Vid_5': 1.0, 'subject_31_Vid_6': 1.0, 'subject_2_Vid_6': 0.33, 'subject_3_Vid_6': 1.0, 'subject_3_Vid_1': 0.33, 'subject_3_Vid_2': 0.33, 'subject_3_Vid_3': 0.66, 'subject_3_Vid_4': 0.66, 'subject_3_Vid_5': 0.33, 'subject_3_Vid_7': 1.0, 'subject_4_Vid_6': 1.0, 'subject_5_Vid_6': 1.0, 'subject_6_Vid_6': 0.33, 'subject_7_Vid_1': 0.66, 'subject_7_Vid_2': 0.66, 'subject_7_Vid_3': 0.66, 'subject_7_Vid_4': 0.66, 'subject_7_Vid_5': 0.33, 'subject_8_Vid_6': 1.0, 'subject_9_Vid_6': 0.0, 'subject_10_Vid_6': 0.66, 'subject_11_Vid_6': 1.0, 'subject_12_Vid_6': 0.0, 'subject_13_Vid_6': 0.66, 'subject_14_Vid_6': 0.66, 'subject_15_Vid_6': 0.66, 'subject_16_Vid_6': 0.33, 'subject_17_Vid_6': 0.66, 'subject_18_Vid_6': 0.33, 'subject_19_Vid_6': 1.0, 'subject_20_Vid_6': 0.66, 'subject_20_Vid_1': 0.66, 'subject_20_Vid_2': 0.66, 'subject_20_Vid_3': 0.66, 'subject_20_Vid_4': 0.33, 'subject_20_Vid_5': 0.66, 'subject_20_Vid_5_1': 0.66, 'subject_20_Vid_5_2': 1.0, 'subject_20_Vid_7': 0.0, 'subject_21_Vid_5': 0.0, 'subject_22_Vid_5': 1.0, 'subject_23_Vid_5': 0.33, 'subject_24_Vid_5': 1.0, 'subject_25_Vid_5': 0.66, 'subject_26_Vid_1': 0.66, 'subject_26_Vid_2': 0.66, 'subject_26_Vid_3': 0.33, 'subject_26_Vid_4': 0.66, 'subject_26_Vid_5': 0.33, 'subject_26_Vid_5_1': 0.66, 'subject_26_Vid_5_2': 0.66, 'subject_26_Vid_7': 0.33, 'subject_27_Vid_1': 0.66, 'subject_29_Vid_6': 0.66, 'subject_29_Vid_7': 0.33, 'subject_30_Vid_1': 0.33, 'subject_30_Vid_2': 0.66, 'subject_30_Vid_3': 0.66, 'subject_30_Vid_4': 1.0, 'subject_30_Vid_5': 0.33, 'subject_32_Vid_6': 1.0, 'subject_32_Vid_1': 0.66, 'subject_32_Vid_2': 0.66, 'subject_32_Vid_3': 0.66, 'subject_32_Vid_4': 0.66, 'subject_32_Vid_5': 0.66, 'subject_32_Vid_7': 0.33, 'subject_33_Vid_1': 0.33, 'subject_33_Vid_2': 0.66, 'subject_33_Vid_3': 0.66, 'subject_33_Vid_4': 0.66, 'subject_33_Vid_7': 0.66, 'subject_34_Vid_7': 1.0, 'subject_34_Vid_1': 0.66, 'subject_34_Vid_5': 0.66, 'subject_35_Vid_6': 0.33, 'subject_35_Vid_7': 0.66, 'subject_36_Vid_7': 0.66, 'subject_37_Vid_7': 0.66, 'subject_38_Vid_7': 0.66, 'subject_39_Vid_6': 0.66, 'subject_39_Vid_7': 0.33, 'subject_40_Vid_6': 0.66, 'subject_40_Vid_7': 0.33, 'subject_41_Vid_6': 1.0, 'subject_41_Vid_2': 0.0, 'subject_41_Vid_3': 0.66, 'subject_41_Vid_4': 0.33, 'subject_41_Vid_5': 0.33, 'subject_41_Vid_5_1': 0.66, 'subject_41_Vid_5_2': 0.33, 'subject_41_Vid_7': 0.66, 'subject_42_Vid_7': 1.0, 'subject_43_Vid_7': 0.66, 'subject_44_Vid_7': 0.33, 'subject_45_Vid_7': 0.33, 'subject_46_Vid_6': 0.66, 'subject_47_Vid_6': 1.0, 'subject_48_Vid_6': 1.0, 'subject_48_Vid_7': 0.66, 'subject_49_Vid_7': 0.66, 'subject_50_Vid_6': 0.66, 'subject_50_Vid_1': 0.66, 'subject_50_Vid_2': 0.33, 'subject_50_Vid_3': 0.33, 'subject_50_Vid_4': 0.33, 'subject_50_Vid_5': 0.33, 'subject_51_Vid_7': 1.0, 'subject_52_Vid_7': 0.0, 'subject_53_Vid_2': 0.66, 'subject_53_Vid_3': 0.66, 'subject_53_Vid_4': 0.66, 'subject_53_Vid_5': 0.66, 'subject_54_Vid_6': 0.66, 'subject_55_Vid_6': 0.66, 'subject_56_Vid_6': 0.66, 'subject_56_Vid_1': 0.66, 'subject_56_Vid_2': 0.66, 'subject_56_Vid_3': 1.0, 'subject_56_Vid_4': 0.66, 'subject_56_Vid_5': 0.66, 'subject_57_Vid_7': 1.0, 'subject_58_Vid_6': 1.0, 'subject_58_Vid_7': 0.66, 'subject_59_Vid_7': 0.66, 'subject_60_Vid_6': 1.0, 'subject_60_Vid_7': 0.66, 'subject_62_Vid_6': 1.0, 'subject_62_Vid_1': 0.66, 'subject_62_Vid_2': 1.0, 'subject_62_Vid_3': 0.33, 'subject_62_Vid_4': 1.0, 'subject_62_Vid_5': 0.66, 'subject_62_Vid_7': 0.66, 'subject_63_Vid_7': 0.33, 'subject_64_Vid_6': 1.0, 'subject_64_Vid_7': 0.33, 'subject_65_Vid_6': 1.0, 'subject_66_Vid_6': 1.0, 'subject_66_Vid_7': 0.33, 'subject_67_Vid_6': 0.66, 'subject_67_Vid_1': 1.0, 'subject_67_Vid_2': 0.66, 'subject_67_Vid_4': 0.66, 'subject_67_Vid_5': 0.66, 'subject_68_Vid_6': 0.66, 'subject_68_Vid_7': 0.33, 'subject_69_Vid_6': 1.0, 'subject_69_Vid_7': 0.66, 'subject_70_Vid_6': 0.66, 'subject_70_Vid_1': 0.66, 'subject_70_Vid_2': 0.66, 'subject_70_Vid_3': 0.66, 'subject_70_Vid_4': 0.66, 'subject_70_Vid_5': 0.33, 'subject_72_Vid_6': 0.66, 'subject_73_Vid_6': 1.0, 'subject_73_Vid_7': 1.0, 'subject_74_Vid_7': 0.0, 'subject_75_Vid_7': 0.66, 'subject_76_Vid_6': 0.66, 'subject_76_Vid_7': 1.0, 'subject_77_Vid_6': 0.66, 'subject_77_Vid_1': 0.33, 'subject_77_Vid_2': 0.33, 'subject_77_Vid_3': 0.66, 'subject_77_Vid_4': 0.66, 'subject_77_Vid_5': 0.0, 'subject_78_Vid_6': 0.66, 'subject_79_Vid_7': 0.66, 'subject_80_Vid_6': 0.66, 'subject_80_Vid_1': 0.66, 'subject_80_Vid_2': 0.66, 'subject_80_Vid_3': 0.66, 'subject_80_Vid_4': 0.66, 'subject_80_Vid_5': 0.66, 'subject_81_Vid_7': 0.33, 'subject_82_Vid_7': 1.0, 'subject_83_Vid_7': 1.0, 'subject_84_Vid_6': 0.33, 'subject_84_Vid_1': 0.33, 'subject_84_Vid_2': 0.33, 'subject_84_Vid_3': 0.0, 'subject_84_Vid_4': 0.33, 'subject_84_Vid_5': 0.33, 'subject_85_Vid_7': 1.0, 'subject_86_Vid_7': 1.0, 'subject_77_Vid_7': 0.33, 'subject_34_Vid_2': 0.66, 'subject_34_Vid_3': 1.0, 'subject_34_Vid_4': 0.66, 'subject_87_Vid_3': 0.66}\n"
     ]
    }
   ],
   "source": [
    "ENGAGE_WILD_DATASET, BIN_CLASSIFICATION, N_CLASSES, DATASET_NAME, BASE_DATASET_DIR, ext = define_dataset(True, False)\n",
    "video2label, labels_list = get_video2label()\n",
    "print(labels_list)\n",
    "print(video2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e342e6-fc90-4f16-9951-1267a4a0446d",
   "metadata": {},
   "source": [
    "### Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1b68647-64fc-4079-a891-11769c701f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.std\n",
    "stat_name = \"std\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefcfc60-4d4f-4ee0-b55b-4b815813389b",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "235e9668-1144-4463-b0fa-abed6a7f5fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f26e7aa-2222-4e92-8a34-366eb18b26c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b6fd4f5-d6ea-44fc-8cbd-9d964b8673f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab68e9b3-2a00-4c5a-a866-122f7f17022c",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "264a77be-bd26-4b8c-8071-4d8786aa3cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_std_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2398d316-4885-43d7-8fa9-54fe333b60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5d3ef1c-a851-4fac-9bd2-a9cf0c685055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2560) (5449,)\n",
      "(2284, 128, 2560) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df3167f6-1373-4937-a762-5b64004f9e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 20:57:19.794348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b194d2a-d5be-4f29-8a05-8e49c7b1a0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 20:57:28.377540: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xcab7b090 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-21 20:57:28.377561: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-21 20:57:28.382472: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-21 20:57:28.415997: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-07-21 20:57:28.468254: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 6s 102ms/step - loss: 0.0463 - mae: 0.1715 - val_loss: 0.0895 - val_mae: 0.2561\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0175 - mae: 0.1041 - val_loss: 0.0881 - val_mae: 0.2481\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0114 - mae: 0.0791 - val_loss: 0.0936 - val_mae: 0.2515\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0078 - mae: 0.0619 - val_loss: 0.0885 - val_mae: 0.2469\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0057 - mae: 0.0523 - val_loss: 0.0915 - val_mae: 0.2512\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0042 - mae: 0.0460 - val_loss: 0.1035 - val_mae: 0.2689\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0032 - mae: 0.0399 - val_loss: 0.0986 - val_mae: 0.2649\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0025 - mae: 0.0346 - val_loss: 0.0990 - val_mae: 0.2656\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0020 - mae: 0.0319 - val_loss: 0.1020 - val_mae: 0.2721\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0016 - mae: 0.0285 - val_loss: 0.1052 - val_mae: 0.2760\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0015 - mae: 0.0287 - val_loss: 0.0996 - val_mae: 0.2689\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0011 - mae: 0.0231 - val_loss: 0.1033 - val_mae: 0.2749\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 9.1736e-04 - mae: 0.0214 - val_loss: 0.1006 - val_mae: 0.2722\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 8.5897e-04 - mae: 0.0214 - val_loss: 0.1052 - val_mae: 0.2798\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 7.6170e-04 - mae: 0.0200 - val_loss: 0.1031 - val_mae: 0.2785\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 7.0384e-04 - mae: 0.0195 - val_loss: 0.1029 - val_mae: 0.2773\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 5.7950e-04 - mae: 0.0176 - val_loss: 0.1005 - val_mae: 0.2741\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 5.7016e-04 - mae: 0.0177 - val_loss: 0.1029 - val_mae: 0.2780\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 5.4686e-04 - mae: 0.0175 - val_loss: 0.1034 - val_mae: 0.2780\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 4.5498e-04 - mae: 0.0157 - val_loss: 0.1011 - val_mae: 0.2753\n",
      "0.08812975138425827\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d31fecba-0da6-4bd8-b1ad-cc5d9b065276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d96ded0-714e-49a7-8623-72450de6c4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_std_single_attention_traditional Accuracy:  0.2916666666666667 MSE:  0.10009201708232872 UAR:  0.3478070175438596 Recall:  N/A Precision:  N/A F1:  0.3157444005270092\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ffa2a78-60b7-4300-8948-01d95e9fdebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4c20336-ccff-4f57-9ad8-c91aa1fc7ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f52b0d5-b088-4f12-b5fe-6fcba71775b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_std_single_attention_traditional_best Accuracy:  0.3541666666666667 MSE:  0.08007323866137694 UAR:  0.2850877192982456 Recall:  N/A Precision:  N/A F1:  0.2765014024088434\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01f63cc-be71-4dc7-baa9-7b6fe46f3d7c",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "148310a7-8c22-4d29-b00f-b60d61441af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_std_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b435bfe4-7e66-4eb6-b925-36c17956a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bde3167e-1e05-430c-93a0-bd516a745e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2560) (5449,)\n",
      "(2284, 128, 2560) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b39372c-cde7-4611-9405-c1b720d34ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15e29ad5-e101-44fa-ae17-ea12505e55b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 152ms/step - loss: 0.2071 - mae: 0.3759 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 102ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "0.25096195936203003\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b177b6ef-6f0f-4046-a756-136271cc2d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a99d16e-b695-49e5-9473-7f3eb7c28be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_std_self_attention_traditional Accuracy:  0.3125 MSE:  0.22261249999999996 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9bccfb4-f7f8-4b57-ab0d-16d3075f19df",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee31f909-495b-412f-a4c5-17af56501651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b9a99ae-2d1f-40de-b53a-cda1cbf609e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_std_self_attention_traditional_best Accuracy:  0.3125 MSE:  0.22261249999999996 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e359871-f824-4738-9018-93f48c9f1c8e",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0733af2b-a721-4e4a-8680-f448575c6776",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c42478b-82a4-47cc-8ddc-1a116e23ee87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef9b0fff-41f4-45ac-bf78-fad80190c02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c34bda4-ccfe-4532-ab39-2c33ec84ba4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147,) (147,)\n",
      "(48,) (48,)\n",
      "(195,) (195,)\n",
      "[0.   0.33 0.66 1.  ] [ 9 45 98 43]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.767)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4b693810-e437-498b-b414-8bd348c93a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 6/147: 4.081632653061225%\n",
      "0.33 34/147: 23.12925170068027%\n",
      "0.66 75/147: 51.02040816326531%\n",
      "1.0 32/147: 21.768707482993197%\n",
      "val:\n",
      "0.0 3/48: 6.25%\n",
      "0.33 11/48: 22.916666666666668%\n",
      "0.66 23/48: 47.916666666666664%\n",
      "1.0 11/48: 22.916666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87409032-8f8c-461d-8163-dee55ca48745",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3dc1617b-24c1-411a-9c4f-723e824289d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_std_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f546513a-72ab-4329-b143-5da4681ccf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cee27540-ca68-45e2-a6fc-1169d0b14c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 2560) (5641,)\n",
      "(2092, 128, 2560) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a3d28b65-66f6-40c6-a95a-c5ef120fd802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fed6f241-7138-4c81-b8f2-4c7c406d36c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 4s 72ms/step - loss: 0.0421 - mae: 0.1615 - val_loss: 0.0632 - val_mae: 0.2078\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 2s 37ms/step - loss: 0.0124 - mae: 0.0855 - val_loss: 0.0632 - val_mae: 0.2054\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.0072 - mae: 0.0624 - val_loss: 0.0682 - val_mae: 0.2172\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0053 - mae: 0.0538 - val_loss: 0.0716 - val_mae: 0.2219\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.0035 - mae: 0.0407 - val_loss: 0.0742 - val_mae: 0.2249\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 1s 32ms/step - loss: 0.0028 - mae: 0.0368 - val_loss: 0.0769 - val_mae: 0.2310\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 2s 36ms/step - loss: 0.0024 - mae: 0.0345 - val_loss: 0.0777 - val_mae: 0.2317\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.0017 - mae: 0.0283 - val_loss: 0.0813 - val_mae: 0.2362\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0019 - mae: 0.0316 - val_loss: 0.0826 - val_mae: 0.2412\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 2s 37ms/step - loss: 0.0014 - mae: 0.0261 - val_loss: 0.0816 - val_mae: 0.2394\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 0.0823 - val_mae: 0.2387\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 0.0819 - val_mae: 0.2396\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 2s 37ms/step - loss: 8.9481e-04 - mae: 0.0217 - val_loss: 0.0853 - val_mae: 0.2443\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 8.3718e-04 - mae: 0.0211 - val_loss: 0.0826 - val_mae: 0.2399\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0010 - mae: 0.0228 - val_loss: 0.0837 - val_mae: 0.2409\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 2s 37ms/step - loss: 6.6876e-04 - mae: 0.0194 - val_loss: 0.0844 - val_mae: 0.2425\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 5.1003e-04 - mae: 0.0166 - val_loss: 0.0859 - val_mae: 0.2435\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 5.0099e-04 - mae: 0.0167 - val_loss: 0.0843 - val_mae: 0.2412\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 6.1644e-04 - mae: 0.0186 - val_loss: 0.0847 - val_mae: 0.2416\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 2s 36ms/step - loss: 5.1745e-04 - mae: 0.0172 - val_loss: 0.0859 - val_mae: 0.2427\n",
      "0.06317615509033203\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ac297fac-c4cb-467c-8eda-9ec3f9143bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "68598819-edcd-455e-94df-b041e097a713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_std_single_attention_balanced Accuracy:  0.3541666666666667 MSE:  0.0828139840055649 UAR:  0.363965744400527 Recall:  N/A Precision:  N/A F1:  0.36019736842105265\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1f7ea92d-8bdf-4a4a-b248-4c600b8f7d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "89308f93-f569-4aa6-8e95-55755649f314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "415ac85b-dd94-49c9-9e60-8c86d5e0b7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_std_single_attention_balanced_best Accuracy:  0.4583333333333333 MSE:  0.056269898658401506 UAR:  0.4183135704874835 Recall:  N/A Precision:  N/A F1:  0.4298611111111111\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b672de75-2cb6-4666-8e5c-693c75cffffd",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e0aedb55-3a27-4aad-955c-47e7d60815c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0f6fdfd7-d096-4523-b86e-dde918d077fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "697d679c-75c0-4f52-a9fa-03447b48432d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 2560) (5641,)\n",
      "(2092, 128, 2560) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "900cbe9f-58ca-437f-a9be-33b52f7b9e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "79605949-8be5-4fe5-8865-763392c89d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 7s 138ms/step - loss: 0.2181 - mae: 0.3788 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 4s 99ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 4s 89ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 4s 87ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 4s 89ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 4s 89ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 4s 100ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 4s 89ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "0.22412924468517303\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "310bd33c-00d1-4fc4-944d-bc15e38ec5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c0cc9db6-8e4b-4ca1-884e-a6973f74f031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_std_self_attention_balanced Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eceab423-e924-4920-bf11-db65fdc560d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0bccc1c7-f561-4c38-8210-c29567130ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "41680688-1dfa-4e64-92da-263bec48ff7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_std_self_attention_balanced_best Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a64f30c-7fc5-4f45-8ff6-936379d55c44",
   "metadata": {},
   "source": [
    "### Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b195292-3588-4f98-baea-a8fb3f857246",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.max\n",
    "stat_name = \"max\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289fa512-d8d3-46c0-8a7d-65b7f3c74ac3",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "baa38a93-0b4f-4247-9cdd-b96b4aab49f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "518c1c99-3d72-4ec8-a62a-f00aa39718af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4d90fa0b-124d-4c46-b8d8-231bdce2cc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dff5bd-525f-4c01-b563-26d80a0822f3",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bade9065-2988-483c-bda0-cdc6686fa006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_max_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c72c8448-9cd0-4423-8745-d6e1ba73ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bf954463-4185-4a01-9bbe-c0e5a696ccaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2560) (5449,)\n",
      "(2284, 128, 2560) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "96d95aa8-f976-4bfa-9cee-eead931c6ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4c13a604-9b92-4279-9181-be5435898db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 89ms/step - loss: 0.2061 - mae: 0.3746 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "0.25096195936203003\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5b167531-1f5c-4232-95df-0e5efad6e33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "42a15824-1e28-4190-a760-5ed4a341aecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_max_single_attention_traditional Accuracy:  0.3125 MSE:  0.22261250000000113 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d419209f-1a85-48d2-bde0-8c1693f14949",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "14b93dc5-5db7-4270-9d72-ae77dde78a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5ab4dc3c-4bfd-4560-8e6d-bf6d081b1161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_max_single_attention_traditional_best Accuracy:  0.3125 MSE:  0.22261250000000113 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a49507a-7a0b-41c1-8dd0-a62375605168",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "184b407a-36f0-475d-9aec-75735dcefb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_max_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "63edb738-71cb-4261-a282-ad59f4d8211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1a1bdbd4-e484-424e-9b58-815f85ffce27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2560) (5449,)\n",
      "(2284, 128, 2560) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "57910f69-acb8-43ab-8e22-9cc58f876229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_2 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_2[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_2[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7c22ac8e-68de-4bb7-8af6-f46ecd2a727f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 135ms/step - loss: 0.2059 - mae: 0.3744 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 102ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "0.25096195936203003\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e560fc06-2eed-4bff-bf0d-70c8bfbbdf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "40ba1c65-45b4-420e-a78a-69eee9e551cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_max_self_attention_traditional Accuracy:  0.3125 MSE:  0.22261249999999996 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b219e0d2-61ad-44cf-9f6d-d662352bd212",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d89a59c4-5e8e-489d-bdea-42bbeecf6fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "df0ee10f-d0c8-4d2b-9677-dc7add7ceb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_max_self_attention_traditional_best Accuracy:  0.3125 MSE:  0.22261249999999996 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c4f180-1654-4e72-b69a-87c0ed2037e7",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b16e0523-5c1f-4039-8627-05f786a27090",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d95eaf87-91a1-4805-83a5-3832857b78a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c6e0aad-3173-41d3-a7d0-99ee13bdf54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30e6c463-4572-4b4b-a180-376e52b55a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147,) (147,)\n",
      "(48,) (48,)\n",
      "(195,) (195,)\n",
      "[0.   0.33 0.66 1.  ] [ 9 45 98 43]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.767)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec0867df-e582-4617-943b-7319f14e775f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 6/147: 4.081632653061225%\n",
      "0.33 34/147: 23.12925170068027%\n",
      "0.66 75/147: 51.02040816326531%\n",
      "1.0 32/147: 21.768707482993197%\n",
      "val:\n",
      "0.0 3/48: 6.25%\n",
      "0.33 11/48: 22.916666666666668%\n",
      "0.66 23/48: 47.916666666666664%\n",
      "1.0 11/48: 22.916666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d391549-ee93-4fef-b762-4f37292c35d1",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d5e9d3d-2b9c-4ee3-9d3e-32883263b899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_max_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17728ff2-1ee1-4ff4-9132-b45e3e5e9045",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f96053bc-4aed-4653-bc90-7f71cebe6377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 2560) (5641,)\n",
      "(2092, 128, 2560) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb590e04-90aa-4d0d-9097-9e9706c26fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 05:20:12.882923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f3ddea0-6cb0-4af2-8e69-3f52316cac35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 05:20:22.010341: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8a48007850 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-22 05:20:22.010361: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-22 05:20:22.015152: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-22 05:20:22.056624: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-07-22 05:20:22.109869: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 6s 94ms/step - loss: 0.2172 - mae: 0.3782 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 2s 37ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 2s 36ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 2s 37ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "0.22412924468517303\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00de1408-3c3a-45ca-90ca-1753d26a57c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3803109/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dcff4da7-30bc-441a-911f-6d662ecc2554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_max_single_attention_balanced Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c9b7b4f-92cb-4cda-a65a-c92b3539fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "601f8205-17b6-4321-a86d-ed60d1bbd235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3803109/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "67fa7c6c-cc8f-485b-ac6a-aa2e4009d7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_max_single_attention_balanced_best Accuracy:  0.22916666666666666 MSE:  0.2207645833333336 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f79cbe-5843-49de-8da0-603df23929a8",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e4bf602-9e4f-4b32-be76-78b4d3f81ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_max_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "954041ee-fb0f-463c-8ea0-cdae90d634c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0d79950-df9a-4652-8f4d-d72d54af02c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 2560) (5641,)\n",
      "(2092, 128, 2560) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e6044f64-92e4-4bfd-819a-128611a91885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5a1a2f5-ec51-4209-8cbd-eb92b1266fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 8s 152ms/step - loss: 0.2205 - mae: 0.3819 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 4s 87ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 4s 87ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 4s 87ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 4s 87ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 4s 87ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 4s 89ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 4s 89ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 4s 87ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "0.22412924468517303\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42ef849c-2be6-49ba-864b-fc1375334ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3803109/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a91960d4-27c3-42b8-be87-48b1d56dd753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_max_self_attention_balanced Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf2e0022-8351-4c93-926a-37dea0e16b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "287f120b-1937-42f8-a7fd-6e8c94c4194f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3803109/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fdc73b7c-fb4f-4373-82ad-a723eb8fd3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_max_self_attention_balanced_best Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244037aa-84e4-45ab-b459-6183941eab9d",
   "metadata": {},
   "source": [
    "### STAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15084b36-0ac8-4409-9b71-fd92a289245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = compute_descriptor\n",
    "stat_name = \"STAT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44566caa-87bc-4db9-9d7f-2dfd1644116e",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e2be21e-2e28-457d-bc16-863d799257ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed6d4efe-2a52-40de-a363-480f583a8cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a121bea-44b4-4592-9e64-3f4a60f774ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072c7336-c38d-438f-bbfa-464043748347",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2377d7ff-d97d-4de1-aaf7-131d6ff19b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_STAT_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb3ec4ba-01db-46cf-88af-b4785dbc602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fc97153-9986-442c-8efc-f9998206f2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 3840) (5449,)\n",
      "(2284, 128, 3840) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "814aac4a-620f-46c7-8fcf-c2d3e5ed149b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 06:05:31.848209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1966592   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1970946 (7.52 MB)\n",
      "Trainable params: 1970946 (7.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c7b5cf2-17fb-47b9-a7f7-fa58bea5131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a8eeb31-abe3-4ab2-a944-606d57e9404d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3828290/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57e1d00b-1228-4ed3-8645-e3c19a0d0741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_STAT_single_attention_traditional Accuracy:  0.25 MSE:  0.1146485906264167 UAR:  0.22631578947368422 Recall:  N/A Precision:  N/A F1:  0.2108556832694764\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "550935d5-9075-4b50-8b72-96791c7b798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    modelAtn.set_weights(best_model_weights)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "86bcd151-ff3b-4279-8279-67f94902194d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3828290/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f91bb04f-3a62-4209-a94c-0781109d70f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_STAT_single_attention_traditional_best Accuracy:  0.3958333333333333 MSE:  0.08042476034517941 UAR:  0.3078947368421053 Recall:  N/A Precision:  N/A F1:  0.2902121374865736\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4011366-38ce-4e07-9b36-0255eab682c5",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6389cde-e688-4da3-bc21-066f39a6fdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_STAT_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31c7184e-5500-4370-966c-05348887529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8e3a040-fd1d-4270-8cbb-dc5e969c3656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 3840) (5449,)\n",
      "(2284, 128, 3840) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b38a2497-6876-4c4d-8c41-10454ce01451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 3840)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    3841      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29498882 (112.53 MB)\n",
      "Trainable params: 29498882 (112.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb722b09-b49b-4ca9-94d9-96f47383a37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28db23d7-faf1-4977-9a1d-13a17ec8da43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3828290/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f970d777-e247-4aa4-b35b-afc07b0b9b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_STAT_self_attention_traditional Accuracy:  0.3541666666666667 MSE:  0.10893076012359715 UAR:  0.38728070175438595 Recall:  N/A Precision:  N/A F1:  0.36451612903225805\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b9092ecf-4678-469e-9aa6-2c9437f0bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    modelAtn.set_weights(best_model_weights)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b62f95e-2608-4c69-bdea-e29e076ee3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3828290/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f22c2c14-f3a1-4b15-b53d-0c405f052233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_STAT_self_attention_traditional_best Accuracy:  0.4166666666666667 MSE:  0.07915359221476707 UAR:  0.4232456140350877 Recall:  N/A Precision:  N/A F1:  0.45722610722610724\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31608616-2d31-46dc-bd8b-5f1010018b85",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a9d5fb2-df83-46a8-b19f-b85f357ac3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4cac28d-b556-49ec-976a-e26ff6e191e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ce918278-f91f-4e9e-a338-a5b786f3f2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "35839ec8-7813-4003-aabc-ea51c8ff7c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147, 2560) (147,)\n",
      "(48, 2560) (48,)\n",
      "(195, 2560) (195,)\n",
      "[0.   0.33 0.66 1.  ] [ 9 45 98 43]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.767)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8b764ae8-925b-4505-bc73-dbb10e28e31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 6/147: 4.081632653061225%\n",
      "0.33 34/147: 23.12925170068027%\n",
      "0.66 75/147: 51.02040816326531%\n",
      "1.0 32/147: 21.768707482993197%\n",
      "val:\n",
      "0.0 3/48: 6.25%\n",
      "0.33 11/48: 22.916666666666668%\n",
      "0.66 23/48: 47.916666666666664%\n",
      "1.0 11/48: 22.916666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de34c445-bcf1-44e2-96a3-3ebc8f417fff",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8374547-f6f3-4bf6-8a60-2c407660ae07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_STAT_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b67bed2b-fca6-47ca-ae88-462c37108f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a287d128-d2da-4767-8d94-226a3670c1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 3840) (5641,)\n",
      "(2092, 128, 3840) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f4f8ce50-8c05-4d4d-b350-6529f2fc6962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1966592   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1970946 (7.52 MB)\n",
      "Trainable params: 1970946 (7.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ea401fc0-804b-4ebe-acee-db2550c02f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 06:09:52.493356: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7eec008940 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-22 06:09:52.493378: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-22 06:09:52.498201: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-22 06:09:52.535635: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-07-22 06:09:52.588560: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 8s 146ms/step - loss: 0.0425 - mae: 0.1595 - val_loss: 0.0671 - val_mae: 0.2109\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 2s 43ms/step - loss: 0.0109 - mae: 0.0782 - val_loss: 0.0690 - val_mae: 0.2114\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 2s 47ms/step - loss: 0.0057 - mae: 0.0518 - val_loss: 0.0778 - val_mae: 0.2242\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 2s 43ms/step - loss: 0.0043 - mae: 0.0455 - val_loss: 0.0797 - val_mae: 0.2309\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 2s 44ms/step - loss: 0.0030 - mae: 0.0362 - val_loss: 0.0795 - val_mae: 0.2317\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 2s 44ms/step - loss: 0.0021 - mae: 0.0302 - val_loss: 0.0808 - val_mae: 0.2333\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 2s 45ms/step - loss: 0.0021 - mae: 0.0313 - val_loss: 0.0903 - val_mae: 0.2447\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 2s 44ms/step - loss: 0.0016 - mae: 0.0276 - val_loss: 0.0878 - val_mae: 0.2434\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 2s 44ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 0.0846 - val_mae: 0.2406\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 2s 44ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0877 - val_mae: 0.2451\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 2s 44ms/step - loss: 8.2759e-04 - mae: 0.0200 - val_loss: 0.0854 - val_mae: 0.2419\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 2s 43ms/step - loss: 6.4077e-04 - mae: 0.0170 - val_loss: 0.0861 - val_mae: 0.2433\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 2s 44ms/step - loss: 6.2194e-04 - mae: 0.0175 - val_loss: 0.0873 - val_mae: 0.2433\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 2s 46ms/step - loss: 6.9158e-04 - mae: 0.0192 - val_loss: 0.0882 - val_mae: 0.2439\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 2s 44ms/step - loss: 4.1023e-04 - mae: 0.0142 - val_loss: 0.0875 - val_mae: 0.2426\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 2s 44ms/step - loss: 7.9377e-04 - mae: 0.0215 - val_loss: 0.0867 - val_mae: 0.2427\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 2s 46ms/step - loss: 5.1462e-04 - mae: 0.0167 - val_loss: 0.0909 - val_mae: 0.2482\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 2s 44ms/step - loss: 4.4852e-04 - mae: 0.0158 - val_loss: 0.0895 - val_mae: 0.2450\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 2s 44ms/step - loss: 2.3415e-04 - mae: 0.0107 - val_loss: 0.0895 - val_mae: 0.2454\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 2s 42ms/step - loss: 2.5423e-04 - mae: 0.0115 - val_loss: 0.0889 - val_mae: 0.2446\n",
      "0.06714434176683426\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf841647-5bb6-4bed-84ec-9804cd532ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3828290/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "416d0c59-e656-4a6e-83b4-c8fdb934a989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_STAT_single_attention_balanced Accuracy:  0.3541666666666667 MSE:  0.08639217736825654 UAR:  0.363965744400527 Recall:  N/A Precision:  N/A F1:  0.34731934731934727\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8ca50cbd-902a-4dbd-8d6e-417bc8d031aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    modelAtn.set_weights(best_model_weights)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fc0a8704-9418-4564-b119-ce8413dbda25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3828290/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fbd3fa48-55f7-43b3-ba23-3eb0748c49fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_STAT_single_attention_balanced_best Accuracy:  0.4791666666666667 MSE:  0.0586605660204162 UAR:  0.42918313570487476 Recall:  N/A Precision:  N/A F1:  0.4437641723356009\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ed5e65-6532-424d-b488-04cfe3fcf0e2",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "88b6d625-ef94-4e41-91f4-141a16d514ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_STAT_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd2b2588-4801-4cb4-bb02-c24e314f2a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6e77439e-107d-4eaf-9ea8-8c5e027da9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 3840) (5641,)\n",
      "(2092, 128, 3840) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fb25e35d-5de3-46cb-88e3-f0c80883a59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 3840)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    3841      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29498882 (112.53 MB)\n",
      "Trainable params: 29498882 (112.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2937f4eb-0235-4ea5-a09e-79a2e547f5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 13s 270ms/step - loss: 0.2176 - mae: 0.3791 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 9s 197ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 8s 172ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 8s 171ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 8s 171ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 9/20\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.2202 - mae: 0.3810"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0859e-51b7-4190-82ed-a7562d95ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e91a51-24dd-4da2-9584-c2fb381106fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c4395-5936-441a-9f11-0e63e6e055fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    modelAtn.set_weights(best_model_weights)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a25056-68cc-4b0b-a52b-bf71d4f388a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bcf3a1-a509-4f50-b856-842264fe414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3ab641-f92d-4359-b8d8-5eb13a03502c",
   "metadata": {},
   "source": [
    "## MobileNet_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dffa3b34-1dac-4749-846b-7bfeef4c0d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_key = 'mobilenet_7.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a342b79f-70a8-42ce-ae9a-fe01450f49d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['very distracted', 'distracted', 'engaged', 'very engaged']\n",
      "{'subject_1_Vid_1': 1.0, 'subject_1_Vid_2': 1.0, 'subject_1_Vid_3': 0.66, 'subject_1_Vid_4': 1.0, 'subject_1_Vid_5': 1.0, 'subject_31_Vid_6': 1.0, 'subject_2_Vid_6': 0.33, 'subject_3_Vid_6': 1.0, 'subject_3_Vid_1': 0.33, 'subject_3_Vid_2': 0.33, 'subject_3_Vid_3': 0.66, 'subject_3_Vid_4': 0.66, 'subject_3_Vid_5': 0.33, 'subject_3_Vid_7': 1.0, 'subject_4_Vid_6': 1.0, 'subject_5_Vid_6': 1.0, 'subject_6_Vid_6': 0.33, 'subject_7_Vid_1': 0.66, 'subject_7_Vid_2': 0.66, 'subject_7_Vid_3': 0.66, 'subject_7_Vid_4': 0.66, 'subject_7_Vid_5': 0.33, 'subject_8_Vid_6': 1.0, 'subject_9_Vid_6': 0.0, 'subject_10_Vid_6': 0.66, 'subject_11_Vid_6': 1.0, 'subject_12_Vid_6': 0.0, 'subject_13_Vid_6': 0.66, 'subject_14_Vid_6': 0.66, 'subject_15_Vid_6': 0.66, 'subject_16_Vid_6': 0.33, 'subject_17_Vid_6': 0.66, 'subject_18_Vid_6': 0.33, 'subject_19_Vid_6': 1.0, 'subject_20_Vid_6': 0.66, 'subject_20_Vid_1': 0.66, 'subject_20_Vid_2': 0.66, 'subject_20_Vid_3': 0.66, 'subject_20_Vid_4': 0.33, 'subject_20_Vid_5': 0.66, 'subject_20_Vid_5_1': 0.66, 'subject_20_Vid_5_2': 1.0, 'subject_20_Vid_7': 0.0, 'subject_21_Vid_5': 0.0, 'subject_22_Vid_5': 1.0, 'subject_23_Vid_5': 0.33, 'subject_24_Vid_5': 1.0, 'subject_25_Vid_5': 0.66, 'subject_26_Vid_1': 0.66, 'subject_26_Vid_2': 0.66, 'subject_26_Vid_3': 0.33, 'subject_26_Vid_4': 0.66, 'subject_26_Vid_5': 0.33, 'subject_26_Vid_5_1': 0.66, 'subject_26_Vid_5_2': 0.66, 'subject_26_Vid_7': 0.33, 'subject_27_Vid_1': 0.66, 'subject_29_Vid_6': 0.66, 'subject_29_Vid_7': 0.33, 'subject_30_Vid_1': 0.33, 'subject_30_Vid_2': 0.66, 'subject_30_Vid_3': 0.66, 'subject_30_Vid_4': 1.0, 'subject_30_Vid_5': 0.33, 'subject_32_Vid_6': 1.0, 'subject_32_Vid_1': 0.66, 'subject_32_Vid_2': 0.66, 'subject_32_Vid_3': 0.66, 'subject_32_Vid_4': 0.66, 'subject_32_Vid_5': 0.66, 'subject_32_Vid_7': 0.33, 'subject_33_Vid_1': 0.33, 'subject_33_Vid_2': 0.66, 'subject_33_Vid_3': 0.66, 'subject_33_Vid_4': 0.66, 'subject_33_Vid_7': 0.66, 'subject_34_Vid_7': 1.0, 'subject_34_Vid_1': 0.66, 'subject_34_Vid_5': 0.66, 'subject_35_Vid_6': 0.33, 'subject_35_Vid_7': 0.66, 'subject_36_Vid_7': 0.66, 'subject_37_Vid_7': 0.66, 'subject_38_Vid_7': 0.66, 'subject_39_Vid_6': 0.66, 'subject_39_Vid_7': 0.33, 'subject_40_Vid_6': 0.66, 'subject_40_Vid_7': 0.33, 'subject_41_Vid_6': 1.0, 'subject_41_Vid_2': 0.0, 'subject_41_Vid_3': 0.66, 'subject_41_Vid_4': 0.33, 'subject_41_Vid_5': 0.33, 'subject_41_Vid_5_1': 0.66, 'subject_41_Vid_5_2': 0.33, 'subject_41_Vid_7': 0.66, 'subject_42_Vid_7': 1.0, 'subject_43_Vid_7': 0.66, 'subject_44_Vid_7': 0.33, 'subject_45_Vid_7': 0.33, 'subject_46_Vid_6': 0.66, 'subject_47_Vid_6': 1.0, 'subject_48_Vid_6': 1.0, 'subject_48_Vid_7': 0.66, 'subject_49_Vid_7': 0.66, 'subject_50_Vid_6': 0.66, 'subject_50_Vid_1': 0.66, 'subject_50_Vid_2': 0.33, 'subject_50_Vid_3': 0.33, 'subject_50_Vid_4': 0.33, 'subject_50_Vid_5': 0.33, 'subject_51_Vid_7': 1.0, 'subject_52_Vid_7': 0.0, 'subject_53_Vid_2': 0.66, 'subject_53_Vid_3': 0.66, 'subject_53_Vid_4': 0.66, 'subject_53_Vid_5': 0.66, 'subject_54_Vid_6': 0.66, 'subject_55_Vid_6': 0.66, 'subject_56_Vid_6': 0.66, 'subject_56_Vid_1': 0.66, 'subject_56_Vid_2': 0.66, 'subject_56_Vid_3': 1.0, 'subject_56_Vid_4': 0.66, 'subject_56_Vid_5': 0.66, 'subject_57_Vid_7': 1.0, 'subject_58_Vid_6': 1.0, 'subject_58_Vid_7': 0.66, 'subject_59_Vid_7': 0.66, 'subject_60_Vid_6': 1.0, 'subject_60_Vid_7': 0.66, 'subject_62_Vid_6': 1.0, 'subject_62_Vid_1': 0.66, 'subject_62_Vid_2': 1.0, 'subject_62_Vid_3': 0.33, 'subject_62_Vid_4': 1.0, 'subject_62_Vid_5': 0.66, 'subject_62_Vid_7': 0.66, 'subject_63_Vid_7': 0.33, 'subject_64_Vid_6': 1.0, 'subject_64_Vid_7': 0.33, 'subject_65_Vid_6': 1.0, 'subject_66_Vid_6': 1.0, 'subject_66_Vid_7': 0.33, 'subject_67_Vid_6': 0.66, 'subject_67_Vid_1': 1.0, 'subject_67_Vid_2': 0.66, 'subject_67_Vid_4': 0.66, 'subject_67_Vid_5': 0.66, 'subject_68_Vid_6': 0.66, 'subject_68_Vid_7': 0.33, 'subject_69_Vid_6': 1.0, 'subject_69_Vid_7': 0.66, 'subject_70_Vid_6': 0.66, 'subject_70_Vid_1': 0.66, 'subject_70_Vid_2': 0.66, 'subject_70_Vid_3': 0.66, 'subject_70_Vid_4': 0.66, 'subject_70_Vid_5': 0.33, 'subject_72_Vid_6': 0.66, 'subject_73_Vid_6': 1.0, 'subject_73_Vid_7': 1.0, 'subject_74_Vid_7': 0.0, 'subject_75_Vid_7': 0.66, 'subject_76_Vid_6': 0.66, 'subject_76_Vid_7': 1.0, 'subject_77_Vid_6': 0.66, 'subject_77_Vid_1': 0.33, 'subject_77_Vid_2': 0.33, 'subject_77_Vid_3': 0.66, 'subject_77_Vid_4': 0.66, 'subject_77_Vid_5': 0.0, 'subject_78_Vid_6': 0.66, 'subject_79_Vid_7': 0.66, 'subject_80_Vid_6': 0.66, 'subject_80_Vid_1': 0.66, 'subject_80_Vid_2': 0.66, 'subject_80_Vid_3': 0.66, 'subject_80_Vid_4': 0.66, 'subject_80_Vid_5': 0.66, 'subject_81_Vid_7': 0.33, 'subject_82_Vid_7': 1.0, 'subject_83_Vid_7': 1.0, 'subject_84_Vid_6': 0.33, 'subject_84_Vid_1': 0.33, 'subject_84_Vid_2': 0.33, 'subject_84_Vid_3': 0.0, 'subject_84_Vid_4': 0.33, 'subject_84_Vid_5': 0.33, 'subject_85_Vid_7': 1.0, 'subject_86_Vid_7': 1.0, 'subject_77_Vid_7': 0.33, 'subject_34_Vid_2': 0.66, 'subject_34_Vid_3': 1.0, 'subject_34_Vid_4': 0.66, 'subject_87_Vid_3': 0.66}\n"
     ]
    }
   ],
   "source": [
    "ENGAGE_WILD_DATASET, BIN_CLASSIFICATION, N_CLASSES, DATASET_NAME, BASE_DATASET_DIR, ext = define_dataset(True, False)\n",
    "video2label, labels_list = get_video2label()\n",
    "print(labels_list)\n",
    "print(video2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0814fe-ae1d-4655-8ad0-4c8f67c8611b",
   "metadata": {},
   "source": [
    "### Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "793e8d4a-5902-4266-b4a7-fa5fa5ed943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.std\n",
    "stat_name = \"std\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e991975-458a-4db2-a6a1-27138473f962",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0d598a6-14af-456e-8113-9a0d424f9ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "903ab869-7bbe-46e4-8a2f-1131ebccbb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "177e27ac-e0c2-4a6d-b0a2-9ee0fcaf360c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd728eb-895e-4d66-9699-40bffdfc5004",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "568affbd-ba0b-4bc1-80db-e88f0b819918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_std_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88d68cf7-f021-40c5-a048-d814c48e3596",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84fddbce-c1fc-445b-a04e-5cb297bf6f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2048) (5449,)\n",
      "(2284, 128, 2048) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4c31cc1-3752-460b-af40-1a6dfb95ec39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 15:58:54.594011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f142cab8-8855-44e4-9e38-42b7db03c7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 15:59:01.869079: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x13b0e8840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-23 15:59:01.869100: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-23 15:59:01.873846: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-23 15:59:01.905719: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-07-23 15:59:01.957648: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 5s 87ms/step - loss: 0.0493 - mae: 0.1724 - val_loss: 0.0992 - val_mae: 0.2626\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.0181 - mae: 0.1056 - val_loss: 0.0975 - val_mae: 0.2508\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.0098 - mae: 0.0745 - val_loss: 0.1053 - val_mae: 0.2578\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.0065 - mae: 0.0600 - val_loss: 0.1108 - val_mae: 0.2641\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.0044 - mae: 0.0480 - val_loss: 0.1173 - val_mae: 0.2652\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.0033 - mae: 0.0416 - val_loss: 0.1229 - val_mae: 0.2696\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.0024 - mae: 0.0352 - val_loss: 0.1229 - val_mae: 0.2677\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.0017 - mae: 0.0292 - val_loss: 0.1255 - val_mae: 0.2696\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 0.1253 - val_mae: 0.2709\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0012 - mae: 0.0238 - val_loss: 0.1314 - val_mae: 0.2749\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0011 - mae: 0.0232 - val_loss: 0.1291 - val_mae: 0.2751\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.0010 - mae: 0.0236 - val_loss: 0.1304 - val_mae: 0.2794\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 7.1315e-04 - mae: 0.0190 - val_loss: 0.1313 - val_mae: 0.2794\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 6.2009e-04 - mae: 0.0179 - val_loss: 0.1324 - val_mae: 0.2800\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 6.2929e-04 - mae: 0.0184 - val_loss: 0.1335 - val_mae: 0.2815\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 5.3124e-04 - mae: 0.0169 - val_loss: 0.1324 - val_mae: 0.2822\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 6.9970e-04 - mae: 0.0203 - val_loss: 0.1311 - val_mae: 0.2837\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 5.3418e-04 - mae: 0.0174 - val_loss: 0.1333 - val_mae: 0.2825\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 4.2130e-04 - mae: 0.0151 - val_loss: 0.1340 - val_mae: 0.2839\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 4.3590e-04 - mae: 0.0157 - val_loss: 0.1341 - val_mae: 0.2839\n",
      "0.09747046232223511\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66491423-128d-404f-8afc-77ee5b1bba6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a98c0707-dc80-4b03-b1e5-085e709c9b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_std_single_attention_traditional Accuracy:  0.4375 MSE:  0.11541946616558597 UAR:  0.356578947368421 Recall:  N/A Precision:  N/A F1:  0.3360759953501889\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f5a049b-f05c-4985-81a7-a2985f47e456",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e6a1fc7-e01f-48d5-b25c-a26eca5234f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89df3fc3-4d35-401b-9df1-f6bb880b8cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_std_single_attention_traditional_best Accuracy:  0.4166666666666667 MSE:  0.08423179411250159 UAR:  0.30087719298245613 Recall:  N/A Precision:  N/A F1:  0.2812820512820513\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20ddc05-09bd-47f5-8c1b-0ccc5b1dd818",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d44ef88-2e76-4abb-a87d-f9cff7c3c9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_std_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b27a3e80-0d83-45cb-862c-99c6b49bd797",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "baa585b2-512b-476c-8282-0479edc7c460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2048) (5449,)\n",
      "(2284, 128, 2048) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "403375d7-e066-4934-98c4-664785e9154c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2962b8ea-2de2-42da-a6d4-72c57379b974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 129ms/step - loss: 0.2048 - mae: 0.3731 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 3s 64ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "0.25096195936203003\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cabfec47-4487-4eef-9311-2b89dc1e378d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a3efe377-8f70-480b-94c1-9bc29de327d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_std_self_attention_traditional Accuracy:  0.3125 MSE:  0.22261249999999996 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5972dae2-5972-40fa-ba89-c9d96f4a7225",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "60425a81-f048-47f6-851e-1bc81d08f2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5264123-53e1-483a-b3bf-41d80e561bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_std_self_attention_traditional_best Accuracy:  0.3125 MSE:  0.22261249999999996 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e43bd5-010f-4def-9dac-0dd741cd6b47",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6aaea95a-618c-4fef-858f-2085095f0e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dfe3218a-8431-4c9e-9102-cb787c84af84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "503da23f-116f-4346-b0b7-c896c0825e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "405a075d-f875-401e-97d9-02f6ae499b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147,) (147,)\n",
      "(48,) (48,)\n",
      "(195,) (195,)\n",
      "[0.   0.33 0.66 1.  ] [ 9 45 98 43]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.767)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32f2a819-7f5e-4bfa-831f-507606beb945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 6/147: 4.081632653061225%\n",
      "0.33 34/147: 23.12925170068027%\n",
      "0.66 75/147: 51.02040816326531%\n",
      "1.0 32/147: 21.768707482993197%\n",
      "val:\n",
      "0.0 3/48: 6.25%\n",
      "0.33 11/48: 22.916666666666668%\n",
      "0.66 23/48: 47.916666666666664%\n",
      "1.0 11/48: 22.916666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d42ad2-fab9-4aff-b72f-c60ea8f158f0",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a41b3fd3-4cf6-4a78-ac31-2367da3c5d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_std_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f60a2150-e989-42f0-b67f-ac629044fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f89cb8d7-f346-456e-ae86-ebadbeb0e458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 2048) (5641,)\n",
      "(2092, 128, 2048) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c6f0c4f3-2b0d-42c3-8413-b21a6309c877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ebcfbfe0-58c0-437f-bb2b-7a6f2eb8874d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 3s 60ms/step - loss: 0.0497 - mae: 0.1738 - val_loss: 0.0687 - val_mae: 0.2079\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0171 - mae: 0.1051 - val_loss: 0.0673 - val_mae: 0.2081\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0086 - mae: 0.0705 - val_loss: 0.0686 - val_mae: 0.2080\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0052 - mae: 0.0536 - val_loss: 0.0678 - val_mae: 0.2071\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0037 - mae: 0.0443 - val_loss: 0.0726 - val_mae: 0.2110\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0030 - mae: 0.0398 - val_loss: 0.0736 - val_mae: 0.2154\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0026 - mae: 0.0379 - val_loss: 0.0758 - val_mae: 0.2195\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0020 - mae: 0.0317 - val_loss: 0.0764 - val_mae: 0.2181\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 0.0796 - val_mae: 0.2196\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0012 - mae: 0.0241 - val_loss: 0.0789 - val_mae: 0.2189\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0011 - mae: 0.0243 - val_loss: 0.0814 - val_mae: 0.2249\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0012 - mae: 0.0250 - val_loss: 0.0798 - val_mae: 0.2200\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 8.0569e-04 - mae: 0.0202 - val_loss: 0.0804 - val_mae: 0.2198\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 8.3052e-04 - mae: 0.0214 - val_loss: 0.0794 - val_mae: 0.2144\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 9.5357e-04 - mae: 0.0235 - val_loss: 0.0794 - val_mae: 0.2191\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 6.8454e-04 - mae: 0.0196 - val_loss: 0.0828 - val_mae: 0.2276\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 7.9620e-04 - mae: 0.0216 - val_loss: 0.0799 - val_mae: 0.2182\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 7.0113e-04 - mae: 0.0205 - val_loss: 0.0810 - val_mae: 0.2185\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 7.0571e-04 - mae: 0.0205 - val_loss: 0.0814 - val_mae: 0.2199\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 4.6846e-04 - mae: 0.0164 - val_loss: 0.0795 - val_mae: 0.2178\n",
      "0.06734990328550339\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f637f2b7-8e79-4c00-8442-b2a8d166cea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e3148656-8ffe-4e55-bf23-a4e1777d348f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_std_single_attention_balanced Accuracy:  0.4583333333333333 MSE:  0.06568898942859348 UAR:  0.3814229249011858 Recall:  N/A Precision:  N/A F1:  0.3470916568742656\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "14cf0d24-8bd5-4a51-ac7d-bf66b7d57fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1fa823f7-6c64-4d1c-a4d3-fa95e3766fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "899bfa38-6b18-4ef7-bcc2-bfb8b4546e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_std_single_attention_balanced_best Accuracy:  0.5208333333333334 MSE:  0.05547004883940995 UAR:  0.4627799736495389 Recall:  N/A Precision:  N/A F1:  0.4724120082815735\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7821a1f6-0253-4b24-99fa-3c0ef1aa0305",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "59594835-18ea-4822-b132-ab77d5e07c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "adeaa8fb-9004-4330-8f15-9b0491ae3aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "368dd962-f399-47bf-b61d-2825fc10edc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 2048) (5641,)\n",
      "(2092, 128, 2048) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b3504519-135e-4248-b5a0-ac9ea9a3aa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4ed9b857-c44d-4d91-93a1-dd091bd41c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 5s 94ms/step - loss: 0.2169 - mae: 0.3773 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 3s 64ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "0.22412924468517303\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f263d612-f50b-4114-90d6-1b0d2584a3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8ab2f30b-a69f-4922-a6de-0dba6726666f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_std_self_attention_balanced Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b0226d7d-c261-4d5f-9919-eae9d7f28bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f5cde8bf-6510-463f-ad5e-7f85e0136dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d69280fc-74a1-46e8-8866-35960de4a869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_std_self_attention_balanced_best Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4bfe57-f153-41a0-b28a-4f5f920a9ecf",
   "metadata": {},
   "source": [
    "### Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53903341-5237-4e04-9f1d-c38ffd56fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.max\n",
    "stat_name = \"max\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f8fec5-b27f-4b90-8e0d-7658bf7238a6",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bf36ee0a-6874-43d6-925c-cfa8dda9e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f7c002df-81e4-422f-b963-dfd4816fce3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a2e516c4-7d9f-45d0-b2bb-c5eb9fa4c60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c75f106-71c9-4dc7-b999-097591f7475f",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "82c22490-f81d-4e46-acf6-7f1c2ab894fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_max_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "faa49269-f2d4-4ea2-89eb-278963024bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3b5f46f7-9eb9-4966-9758-ebf1c7f043f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2048) (5449,)\n",
      "(2284, 128, 2048) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "16c73ea5-cec8-404b-a65a-694e401d28c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a0900e2e-9bf0-496d-83f6-5eb04d5247df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.2723 - mae: 0.4406 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "0.25096189975738525\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "be7e2354-81f0-4cf2-8dcc-f9a8c5ad706e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "21130651-91b7-44ee-962c-091985ca943f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_max_single_attention_traditional Accuracy:  0.3125 MSE:  0.2226124206764275 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "56fbc493-e04c-4f2e-885a-b4c23da99a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b2b107cf-f2e5-4214-b419-8df82052fba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4f11f25d-c6ef-4027-b3b1-715c6ec57018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_max_single_attention_traditional_best Accuracy:  0.3125 MSE:  0.2226123397141818 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7870ec08-5a8d-4200-bc65-eac8df1b9e03",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6040d5a2-d93f-4c92-91b9-fc27d3abf123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_max_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c688b11b-3bbf-4470-816a-7b6f04299bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f458f0d8-21a7-4c34-a322-d4c94157cb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2048) (5449,)\n",
      "(2284, 128, 2048) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ed7899f7-1964-4e82-9184-c3e6e7c16362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_2 (Attention)     (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention_2[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention_2[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a5bad1ef-5624-44a9-93cf-396f44b14166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 131ms/step - loss: 0.4446 - mae: 0.6123 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "0.5077046155929565\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "46541a48-dc5d-428f-93f6-711700cede03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1403b5f7-3165-43bc-8c92-9ab536714ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_max_self_attention_traditional Accuracy:  0.08333333333333333 MSE:  0.5076125 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.038461538461538464\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e3a68a51-5db7-427d-8a16-702447e7cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "05766c0d-88c4-4872-badc-7685accabb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d849d4bc-8052-4f79-92ff-090f051a2b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_max_self_attention_traditional_best Accuracy:  0.08333333333333333 MSE:  0.5076125 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.038461538461538464\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdde1c9-809a-4331-82c2-c2e651096ece",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6eed71f-7937-44dd-b740-d444c7385e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "696c2c22-572a-40b3-95cc-68bbc78f50f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42731249-1940-482b-bf85-552f30a0ceb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "287d37bf-ddd9-4dc2-bd15-ebf247cd2f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147,) (147,)\n",
      "(48,) (48,)\n",
      "(195,) (195,)\n",
      "[0.   0.33 0.66 1.  ] [ 9 45 98 43]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.767)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e22d53a-b458-4116-9af9-1881794bf714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 6/147: 4.081632653061225%\n",
      "0.33 34/147: 23.12925170068027%\n",
      "0.66 75/147: 51.02040816326531%\n",
      "1.0 32/147: 21.768707482993197%\n",
      "val:\n",
      "0.0 3/48: 6.25%\n",
      "0.33 11/48: 22.916666666666668%\n",
      "0.66 23/48: 47.916666666666664%\n",
      "1.0 11/48: 22.916666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a4f729-629b-4df1-8800-f61873462683",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e38f9faf-3363-4017-9812-80706868b674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_max_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74cefe18-c0b9-4f31-9e6c-be2958765c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b85b564-27b1-4807-83a8-d8c6f9163e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 2048) (5641,)\n",
      "(2092, 128, 2048) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90c68b0e-937a-408a-bef4-139569d93498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 16:10:15.235180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab08318e-4e7f-47ed-a24b-c4c91a715955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 16:10:22.778323: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb0a4d93cb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-23 16:10:22.778478: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-23 16:10:22.782701: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-23 16:10:22.813671: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-07-23 16:10:22.865698: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 5s 77ms/step - loss: 0.2181 - mae: 0.3792 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "0.22412924468517303\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d170749c-4162-472b-8b25-13d1ea01513c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3881236/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c32090fa-7af2-487a-a562-9fedf44520a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_max_single_attention_balanced Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d6aa022-c869-47c8-8804-817fc2b81a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "885c3097-9c4f-47d5-a561-5752fb4b86ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3881236/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c94e6e5-b279-4052-91d9-32203f9b05ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_max_single_attention_balanced_best Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf2f2bb-5e05-41a3-abfe-ba06087f6bc9",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c420b6d7-a8d5-4f9a-955e-5f23fb3da80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_max_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97a027d0-5bdd-4991-80a2-da4604093c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "427e1cf9-27e7-405a-a29d-7f1ac422556b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 2048) (5641,)\n",
      "(2092, 128, 2048) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7ca8b2d-02fc-43af-82fc-5c27ac6cfb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9bee3b98-49f1-4e58-aa66-990c3f7898ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 6s 118ms/step - loss: 0.2176 - mae: 0.3782 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 3s 64ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 3s 64ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "0.22412924468517303\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b00872a-3302-4d6f-a50e-1615b98fc012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3881236/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "42e03d2f-3b3f-42a2-ac1a-7414b478afaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_max_self_attention_balanced Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35ba92af-a219-413a-958f-d4da0a985c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12d5cfd0-bd51-4db6-ba41-6f5559b47512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3881236/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7cac8542-46a8-41dd-8ef3-dcfe592f85aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_max_self_attention_balanced_best Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad1ee20-2e16-40a5-a660-2ffc91ba13a1",
   "metadata": {},
   "source": [
    "### STAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c000f0c7-cf2d-4314-ae2f-a7209ecdcb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = compute_descriptor\n",
    "stat_name = \"STAT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5934ab-e5db-4d24-94c0-cec037fff2a9",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0098982b-15de-4272-805b-2a835d3481d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d41a70a3-95c2-494c-9a43-aeb65a806fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ceea9231-4ac9-4aa2-8c0d-39879e1e5d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4696aad1-d9e1-4b09-8744-e4a7626d8e59",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "953cb930-932b-4e18-a92a-dc84d8374a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_STAT_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8227f360-78d3-4bf6-a465-51e6de7d5bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3b2fd979-1222-45e5-bdc9-dc16924ab13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 3072) (5449,)\n",
      "(2284, 128, 3072) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d265e8d3-9475-448c-8d56-78fe8b7f7505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1573376   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1576962 (6.02 MB)\n",
      "Trainable params: 1576962 (6.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4d9181b8-8c1e-4ef4-aeac-76b7e54365fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 94ms/step - loss: 0.0865 - mae: 0.2254 - val_loss: 0.1025 - val_mae: 0.2601\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.0176 - mae: 0.1052 - val_loss: 0.1070 - val_mae: 0.2633\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0099 - mae: 0.0749 - val_loss: 0.1113 - val_mae: 0.2645\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0064 - mae: 0.0582 - val_loss: 0.1196 - val_mae: 0.2699\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0043 - mae: 0.0473 - val_loss: 0.1217 - val_mae: 0.2721\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.0030 - mae: 0.0385 - val_loss: 0.1276 - val_mae: 0.2794\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.0025 - mae: 0.0363 - val_loss: 0.1302 - val_mae: 0.2828\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 2s 41ms/step - loss: 0.0017 - mae: 0.0299 - val_loss: 0.1325 - val_mae: 0.2871\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.0015 - mae: 0.0276 - val_loss: 0.1371 - val_mae: 0.2895\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 9.5562e-04 - mae: 0.0210 - val_loss: 0.1398 - val_mae: 0.2907\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 8.8950e-04 - mae: 0.0213 - val_loss: 0.1391 - val_mae: 0.2936\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 7.7611e-04 - mae: 0.0200 - val_loss: 0.1427 - val_mae: 0.2949\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 6.4917e-04 - mae: 0.0184 - val_loss: 0.1434 - val_mae: 0.2971\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 5.2182e-04 - mae: 0.0160 - val_loss: 0.1459 - val_mae: 0.2998\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 4.5127e-04 - mae: 0.0149 - val_loss: 0.1460 - val_mae: 0.3002\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 3.7002e-04 - mae: 0.0133 - val_loss: 0.1490 - val_mae: 0.3007\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 3.5929e-04 - mae: 0.0134 - val_loss: 0.1502 - val_mae: 0.3041\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 5.5277e-04 - mae: 0.0176 - val_loss: 0.1498 - val_mae: 0.3030\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 6.0524e-04 - mae: 0.0189 - val_loss: 0.1510 - val_mae: 0.3063\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 5.2561e-04 - mae: 0.0173 - val_loss: 0.1497 - val_mae: 0.3031\n",
      "0.10252317041158676\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50be70eb-c0d0-4463-8281-298d2e4aeaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3881236/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e9452cb0-de96-49ba-89b6-b0de22674f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_STAT_single_attention_traditional Accuracy:  0.375 MSE:  0.1364128734837705 UAR:  0.3017543859649123 Recall:  N/A Precision:  N/A F1:  0.29008152173913043\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "30b199be-112b-4265-86a1-8ecec4ddc70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    modelAtn.set_weights(best_model_weights)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "03eae7c9-9821-47a0-8c3a-17f843972927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3881236/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6f01e069-434d-46a0-8213-8491ce75e839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_STAT_single_attention_traditional_best Accuracy:  0.4791666666666667 MSE:  0.08846163625492254 UAR:  0.34868421052631576 Recall:  N/A Precision:  N/A F1:  0.319724025974026\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583641a5-d2bc-46e9-a5de-e69375e87587",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "29060c19-b2e2-46a1-9aa6-949297694b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_STAT_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5221cf84-b162-43d7-bb74-3af0a668365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f601b8d0-6909-4f14-a44e-8942019714c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 3072) (5449,)\n",
      "(2284, 128, 3072) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bf8b083f-7f44-4986-b5f2-c1af73e1bdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 3072)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    3073      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18880514 (72.02 MB)\n",
      "Trainable params: 18880514 (72.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "57b228a2-82ba-42bf-8a7c-2aaa2f7f0d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 10s 208ms/step - loss: 0.2060 - mae: 0.3745 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 5s 124ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 5s 124ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 5s 128ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "0.25096195936203003\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b31cd053-343b-42b7-8f99-98c1ac5abb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3881236/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a2d88398-f03f-453f-84d7-2d2ca65bdbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_STAT_self_attention_traditional Accuracy:  0.3125 MSE:  0.22261249999999996 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "214e4dc2-f2c0-4224-bf4f-103d244ca333",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    modelAtn.set_weights(best_model_weights)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6a2d3cf6-d17e-40a0-95e5-100c7c208a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3881236/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cd848522-9320-434f-81fd-dcedbbe3f82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_STAT_self_attention_traditional_best Accuracy:  0.3125 MSE:  0.22261249999999996 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef580b8-5a94-4ea7-b0e3-a91a3aaa6f6d",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ab272e3-bd80-44a0-ba2d-5f46fc341d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3696a24e-6882-4733-86d2-aef5a874128c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0db22374-067d-4821-92d9-9633d5d57cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65fcfc76-ba44-48bc-bf90-afb01ac26795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147, 2048) (147,)\n",
      "(48, 2048) (48,)\n",
      "(195, 2048) (195,)\n",
      "[0.   0.33 0.66 1.  ] [ 9 45 98 43]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.767)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "338c38dc-930c-47f0-86c6-6448190c086f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 6/147: 4.081632653061225%\n",
      "0.33 34/147: 23.12925170068027%\n",
      "0.66 75/147: 51.02040816326531%\n",
      "1.0 32/147: 21.768707482993197%\n",
      "val:\n",
      "0.0 3/48: 6.25%\n",
      "0.33 11/48: 22.916666666666668%\n",
      "0.66 23/48: 47.916666666666664%\n",
      "1.0 11/48: 22.916666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542cd59e-9e94-448f-bbad-fc4a55257b05",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32d3fdc0-1dc8-434e-af28-377b224bbeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_STAT_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ea24dbf-21a4-42ed-aaa4-3cc917e5becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ee1b41a-203f-4c35-8575-5c67feb6e29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 3072) (5641,)\n",
      "(2092, 128, 3072) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "878d90cf-3629-42df-9d1d-51271bc42e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 16:25:00.604515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1573376   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1576962 (6.02 MB)\n",
      "Trainable params: 1576962 (6.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d397572-4014-446b-acb9-d3ef17b4bbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 16:25:11.002238: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0bdc043370 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-23 16:25:11.002261: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-23 16:25:11.007070: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-23 16:25:11.041331: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-07-23 16:25:11.093106: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 7s 116ms/step - loss: 0.0500 - mae: 0.1739 - val_loss: 0.0696 - val_mae: 0.2126\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 2s 36ms/step - loss: 0.0149 - mae: 0.0970 - val_loss: 0.0690 - val_mae: 0.2066\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 2s 36ms/step - loss: 0.0074 - mae: 0.0646 - val_loss: 0.0697 - val_mae: 0.2066\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 0.0047 - mae: 0.0493 - val_loss: 0.0718 - val_mae: 0.2080\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 2s 36ms/step - loss: 0.0037 - mae: 0.0436 - val_loss: 0.0804 - val_mae: 0.2211\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 0.0030 - mae: 0.0397 - val_loss: 0.0823 - val_mae: 0.2239\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 0.0025 - mae: 0.0366 - val_loss: 0.0831 - val_mae: 0.2199\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 0.0016 - mae: 0.0273 - val_loss: 0.0802 - val_mae: 0.2160\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 0.0014 - mae: 0.0259 - val_loss: 0.0827 - val_mae: 0.2199\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 2s 36ms/step - loss: 0.0010 - mae: 0.0222 - val_loss: 0.0872 - val_mae: 0.2296\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 0.0014 - mae: 0.0289 - val_loss: 0.0826 - val_mae: 0.2200\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 7.5491e-04 - mae: 0.0190 - val_loss: 0.0852 - val_mae: 0.2222\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 2s 37ms/step - loss: 5.8871e-04 - mae: 0.0167 - val_loss: 0.0870 - val_mae: 0.2238\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 5.0759e-04 - mae: 0.0157 - val_loss: 0.0873 - val_mae: 0.2252\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 2s 36ms/step - loss: 4.7194e-04 - mae: 0.0155 - val_loss: 0.0841 - val_mae: 0.2188\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 6.1348e-04 - mae: 0.0187 - val_loss: 0.0854 - val_mae: 0.2191\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 2s 36ms/step - loss: 5.5787e-04 - mae: 0.0179 - val_loss: 0.0868 - val_mae: 0.2257\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 5.4020e-04 - mae: 0.0175 - val_loss: 0.0874 - val_mae: 0.2233\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 3.2742e-04 - mae: 0.0133 - val_loss: 0.0878 - val_mae: 0.2250\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 3.3883e-04 - mae: 0.0135 - val_loss: 0.0903 - val_mae: 0.2278\n",
      "0.06898355484008789\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb213ada-65d6-42bf-810c-80712117457c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3894676/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa8a2e47-6920-4ef7-850a-6421b5f40f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_STAT_single_attention_balanced Accuracy:  0.4166666666666667 MSE:  0.07565788414361008 UAR:  0.3596837944664032 Recall:  N/A Precision:  N/A F1:  0.3188892948483741\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91b84415-b2f6-407a-9321-07a3a67c7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    modelAtn.set_weights(best_model_weights)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ac7e219-d6ed-4d69-a825-b56f3f56ed16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3894676/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b860994-6f14-46af-82c7-2d55eaed639e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_STAT_single_attention_balanced_best Accuracy:  0.5625 MSE:  0.056693993648760294 UAR:  0.4963768115942029 Recall:  N/A Precision:  N/A F1:  0.5041149068322982\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24c535a-3253-4c0c-9d26-364c844fa93b",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9fa7474a-80d9-41fb-88a0-cf90639837fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_STAT_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba56b4a0-fc44-4c49-a081-ff062f3a299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f978cc3d-e78d-4a53-9de3-e06742f47173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 3072) (5641,)\n",
      "(2092, 128, 3072) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47dd22be-31cf-4a06-90b1-751f3aeafe61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 3072)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    3073      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18880514 (72.02 MB)\n",
      "Trainable params: 18880514 (72.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f45ab39d-71d4-48fb-8317-2995234836bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 10s 204ms/step - loss: 0.2163 - mae: 0.3772 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 5s 119ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 6s 125ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 5s 119ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 5s 120ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "0.22412924468517303\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a0edb119-b242-40a4-a3eb-d69a8ee9feda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3894676/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "096428ac-367c-478c-ba80-e44004af86ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_STAT_self_attention_balanced Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03d39d38-4956-4e07-97b2-f1e459210c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    modelAtn.set_weights(best_model_weights)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7ed358a-67b3-467a-8b74-009e995ecfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3894676/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67080a14-ca52-4034-92c6-862b0e57d8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_STAT_self_attention_balanced_best Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7678d6-f719-40d4-bf2c-4d160fe3f1b7",
   "metadata": {},
   "source": [
    "# EngageWild dataset (2 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a1f2195-98b1-46c8-ae53-61a77c32ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_DIR = DATA_DIR + 'features_EngageWild/'\n",
    "WEIGHTS_DIR = DATA_DIR + 'weights_EngageWild/'\n",
    "TABLE_NAME = '02_EngageWild_2_classes.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3aae6a-4a9f-4bb8-b981-95fc936b9ffe",
   "metadata": {},
   "source": [
    "## enet_b0_8_best_afew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "358de87c-a64c-43e7-9364-71a8b1306d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_key = 'enet_b0_8_best_afew.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14a7dd6d-01f2-4c71-92d2-cebb84c3d1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['engaged', 'distracted']\n",
      "{'subject_1_Vid_1': 0, 'subject_1_Vid_2': 0, 'subject_1_Vid_3': 0, 'subject_1_Vid_4': 0, 'subject_1_Vid_5': 0, 'subject_31_Vid_6': 0, 'subject_2_Vid_6': 1, 'subject_3_Vid_6': 0, 'subject_3_Vid_1': 1, 'subject_3_Vid_2': 1, 'subject_3_Vid_3': 0, 'subject_3_Vid_4': 0, 'subject_3_Vid_5': 1, 'subject_3_Vid_7': 0, 'subject_4_Vid_6': 0, 'subject_5_Vid_6': 0, 'subject_6_Vid_6': 1, 'subject_7_Vid_1': 0, 'subject_7_Vid_2': 0, 'subject_7_Vid_3': 0, 'subject_7_Vid_4': 0, 'subject_7_Vid_5': 1, 'subject_8_Vid_6': 0, 'subject_9_Vid_6': 1, 'subject_10_Vid_6': 0, 'subject_11_Vid_6': 0, 'subject_12_Vid_6': 1, 'subject_13_Vid_6': 0, 'subject_14_Vid_6': 0, 'subject_15_Vid_6': 0, 'subject_16_Vid_6': 1, 'subject_17_Vid_6': 0, 'subject_18_Vid_6': 1, 'subject_19_Vid_6': 0, 'subject_20_Vid_6': 0, 'subject_20_Vid_1': 0, 'subject_20_Vid_2': 0, 'subject_20_Vid_3': 0, 'subject_20_Vid_4': 1, 'subject_20_Vid_5': 0, 'subject_20_Vid_5_1': 0, 'subject_20_Vid_5_2': 0, 'subject_20_Vid_7': 1, 'subject_21_Vid_5': 1, 'subject_22_Vid_5': 0, 'subject_23_Vid_5': 1, 'subject_24_Vid_5': 0, 'subject_25_Vid_5': 0, 'subject_26_Vid_1': 0, 'subject_26_Vid_2': 0, 'subject_26_Vid_3': 1, 'subject_26_Vid_4': 0, 'subject_26_Vid_5': 1, 'subject_26_Vid_5_1': 0, 'subject_26_Vid_5_2': 0, 'subject_26_Vid_7': 1, 'subject_27_Vid_1': 0, 'subject_29_Vid_6': 0, 'subject_29_Vid_7': 1, 'subject_30_Vid_1': 1, 'subject_30_Vid_2': 0, 'subject_30_Vid_3': 0, 'subject_30_Vid_4': 0, 'subject_30_Vid_5': 1, 'subject_32_Vid_6': 0, 'subject_32_Vid_1': 0, 'subject_32_Vid_2': 0, 'subject_32_Vid_3': 0, 'subject_32_Vid_4': 0, 'subject_32_Vid_5': 0, 'subject_32_Vid_7': 1, 'subject_33_Vid_1': 1, 'subject_33_Vid_2': 0, 'subject_33_Vid_3': 0, 'subject_33_Vid_4': 0, 'subject_33_Vid_7': 0, 'subject_34_Vid_7': 0, 'subject_34_Vid_1': 0, 'subject_34_Vid_5': 0, 'subject_35_Vid_6': 1, 'subject_35_Vid_7': 0, 'subject_36_Vid_7': 0, 'subject_37_Vid_7': 0, 'subject_38_Vid_7': 0, 'subject_39_Vid_6': 0, 'subject_39_Vid_7': 1, 'subject_40_Vid_6': 0, 'subject_40_Vid_7': 1, 'subject_41_Vid_6': 0, 'subject_41_Vid_2': 1, 'subject_41_Vid_3': 0, 'subject_41_Vid_4': 1, 'subject_41_Vid_5': 1, 'subject_41_Vid_5_1': 0, 'subject_41_Vid_5_2': 1, 'subject_41_Vid_7': 0, 'subject_42_Vid_7': 0, 'subject_43_Vid_7': 0, 'subject_44_Vid_7': 1, 'subject_45_Vid_7': 1, 'subject_46_Vid_6': 0, 'subject_47_Vid_6': 0, 'subject_48_Vid_6': 0, 'subject_48_Vid_7': 0, 'subject_49_Vid_7': 0, 'subject_50_Vid_6': 0, 'subject_50_Vid_1': 0, 'subject_50_Vid_2': 1, 'subject_50_Vid_3': 1, 'subject_50_Vid_4': 1, 'subject_50_Vid_5': 1, 'subject_51_Vid_7': 0, 'subject_52_Vid_7': 1, 'subject_53_Vid_2': 0, 'subject_53_Vid_3': 0, 'subject_53_Vid_4': 0, 'subject_53_Vid_5': 0, 'subject_54_Vid_6': 0, 'subject_55_Vid_6': 0, 'subject_56_Vid_6': 0, 'subject_56_Vid_1': 0, 'subject_56_Vid_2': 0, 'subject_56_Vid_3': 0, 'subject_56_Vid_4': 0, 'subject_56_Vid_5': 0, 'subject_57_Vid_7': 0, 'subject_58_Vid_6': 0, 'subject_58_Vid_7': 0, 'subject_59_Vid_7': 0, 'subject_60_Vid_6': 0, 'subject_60_Vid_7': 0, 'subject_62_Vid_6': 0, 'subject_62_Vid_1': 0, 'subject_62_Vid_2': 0, 'subject_62_Vid_3': 1, 'subject_62_Vid_4': 0, 'subject_62_Vid_5': 0, 'subject_62_Vid_7': 0, 'subject_63_Vid_7': 1, 'subject_64_Vid_6': 0, 'subject_64_Vid_7': 1, 'subject_65_Vid_6': 0, 'subject_66_Vid_6': 0, 'subject_66_Vid_7': 1, 'subject_67_Vid_6': 0, 'subject_67_Vid_1': 0, 'subject_67_Vid_2': 0, 'subject_67_Vid_4': 0, 'subject_67_Vid_5': 0, 'subject_68_Vid_6': 0, 'subject_68_Vid_7': 1, 'subject_69_Vid_6': 0, 'subject_69_Vid_7': 0, 'subject_70_Vid_6': 0, 'subject_70_Vid_1': 0, 'subject_70_Vid_2': 0, 'subject_70_Vid_3': 0, 'subject_70_Vid_4': 0, 'subject_70_Vid_5': 1, 'subject_72_Vid_6': 0, 'subject_73_Vid_6': 0, 'subject_73_Vid_7': 0, 'subject_74_Vid_7': 1, 'subject_75_Vid_7': 0, 'subject_76_Vid_6': 0, 'subject_76_Vid_7': 0, 'subject_77_Vid_6': 0, 'subject_77_Vid_1': 1, 'subject_77_Vid_2': 1, 'subject_77_Vid_3': 0, 'subject_77_Vid_4': 0, 'subject_77_Vid_5': 1, 'subject_78_Vid_6': 0, 'subject_79_Vid_7': 0, 'subject_80_Vid_6': 0, 'subject_80_Vid_1': 0, 'subject_80_Vid_2': 0, 'subject_80_Vid_3': 0, 'subject_80_Vid_4': 0, 'subject_80_Vid_5': 0, 'subject_81_Vid_7': 1, 'subject_82_Vid_7': 0, 'subject_83_Vid_7': 0, 'subject_84_Vid_6': 1, 'subject_84_Vid_1': 1, 'subject_84_Vid_2': 1, 'subject_84_Vid_3': 1, 'subject_84_Vid_4': 1, 'subject_84_Vid_5': 1, 'subject_85_Vid_7': 0, 'subject_86_Vid_7': 0, 'subject_77_Vid_7': 1, 'subject_34_Vid_2': 0, 'subject_34_Vid_3': 0, 'subject_34_Vid_4': 0, 'subject_87_Vid_3': 0}\n"
     ]
    }
   ],
   "source": [
    "ENGAGE_WILD_DATASET, BIN_CLASSIFICATION, N_CLASSES, DATASET_NAME, BASE_DATASET_DIR, ext = define_dataset(True, True)\n",
    "video2label, labels_list = get_video2label()\n",
    "print(labels_list)\n",
    "print(video2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14234aeb-1964-4608-acb7-62f1a822423c",
   "metadata": {},
   "source": [
    "### Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "634d7c96-03ca-4db1-9ccb-463ea129446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.std\n",
    "stat_name = \"std\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f403e3a1-ced7-4862-9534-4e5428722b87",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6f1ead8-4f92-4907-864e-cc9e6bd69df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6f391ff-749a-4de5-82d9-39e69bf1ad0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cfd17a5-aad8-48b5-881a-bcd61417ed0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4570191f-f073-4147-9474-209e16d95d63",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62680171-26d6-4e01-b3aa-8a8fc6d587c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "606c9512-2be0-4b78-867c-41ae1429dd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "094bd2ad-3de8-427b-b28b-bf52ab0a319a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2560) (5449,)\n",
      "(2284, 128, 2560) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36a585a5-3380-496f-9573-62889e5cbb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 07:06:57.092910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10858bd5-73a3-4dde-8ad9-84cb17b20664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 07:07:06.933872: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f07b81ff2b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-30 07:07:06.934044: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-30 07:07:06.938196: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-30 07:07:06.993674: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-07-30 07:07:07.046402: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 8s 109ms/step - loss: 0.3125 - acc: 0.8807 - auc: 0.9209 - binary_accuracy: 0.8807 - recall: 0.6660 - precision: 0.8886 - val_loss: 0.7877 - val_acc: 0.6432 - val_auc: 0.6720 - val_binary_accuracy: 0.6432 - val_recall: 0.5172 - val_precision: 0.4822\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1500 - acc: 0.9453 - auc: 0.9848 - binary_accuracy: 0.9453 - recall: 0.8760 - precision: 0.9285 - val_loss: 0.8964 - val_acc: 0.7229 - val_auc: 0.7030 - val_binary_accuracy: 0.7229 - val_recall: 0.5019 - val_precision: 0.6195\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0845 - acc: 0.9754 - auc: 0.9969 - binary_accuracy: 0.9754 - recall: 0.9409 - precision: 0.9721 - val_loss: 0.9080 - val_acc: 0.7053 - val_auc: 0.7138 - val_binary_accuracy: 0.7053 - val_recall: 0.5873 - val_precision: 0.5691\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0552 - acc: 0.9840 - auc: 0.9991 - binary_accuracy: 0.9840 - recall: 0.9621 - precision: 0.9817 - val_loss: 1.0142 - val_acc: 0.6918 - val_auc: 0.7139 - val_binary_accuracy: 0.6918 - val_recall: 0.4318 - val_precision: 0.5678\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0411 - acc: 0.9910 - auc: 0.9995 - binary_accuracy: 0.9910 - recall: 0.9807 - precision: 0.9877 - val_loss: 1.2630 - val_acc: 0.7382 - val_auc: 0.7000 - val_binary_accuracy: 0.7382 - val_recall: 0.3975 - val_precision: 0.7140\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.0347 - acc: 0.9910 - auc: 0.9996 - binary_accuracy: 0.9910 - recall: 0.9762 - precision: 0.9922 - val_loss: 1.1636 - val_acc: 0.7303 - val_auc: 0.7189 - val_binary_accuracy: 0.7303 - val_recall: 0.5631 - val_precision: 0.6182\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0182 - acc: 0.9976 - auc: 1.0000 - binary_accuracy: 0.9976 - recall: 0.9936 - precision: 0.9981 - val_loss: 1.2184 - val_acc: 0.7561 - val_auc: 0.7210 - val_binary_accuracy: 0.7561 - val_recall: 0.4726 - val_precision: 0.7218\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0134 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall: 0.9974 - precision: 1.0000 - val_loss: 1.2526 - val_acc: 0.7137 - val_auc: 0.7241 - val_binary_accuracy: 0.7137 - val_recall: 0.5745 - val_precision: 0.5850\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0095 - acc: 0.9991 - auc: 1.0000 - binary_accuracy: 0.9991 - recall: 0.9994 - precision: 0.9974 - val_loss: 1.3699 - val_acc: 0.7172 - val_auc: 0.6871 - val_binary_accuracy: 0.7172 - val_recall: 0.5299 - val_precision: 0.6003\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0060 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.4117 - val_acc: 0.7049 - val_auc: 0.6901 - val_binary_accuracy: 0.7049 - val_recall: 0.5376 - val_precision: 0.5757\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0049 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.4990 - val_acc: 0.6835 - val_auc: 0.6861 - val_binary_accuracy: 0.6835 - val_recall: 0.6127 - val_precision: 0.5344\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0040 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.5024 - val_acc: 0.7110 - val_auc: 0.6978 - val_binary_accuracy: 0.7110 - val_recall: 0.5274 - val_precision: 0.5889\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0031 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.5274 - val_acc: 0.7005 - val_auc: 0.6948 - val_binary_accuracy: 0.7005 - val_recall: 0.5427 - val_precision: 0.5672\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0030 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.5654 - val_acc: 0.7093 - val_auc: 0.6819 - val_binary_accuracy: 0.7093 - val_recall: 0.5962 - val_precision: 0.5742\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0024 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.5955 - val_acc: 0.6975 - val_auc: 0.6883 - val_binary_accuracy: 0.6975 - val_recall: 0.5618 - val_precision: 0.5596\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0019 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.6445 - val_acc: 0.7045 - val_auc: 0.6852 - val_binary_accuracy: 0.7045 - val_recall: 0.5860 - val_precision: 0.5679\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0016 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.6489 - val_acc: 0.7097 - val_auc: 0.6959 - val_binary_accuracy: 0.7097 - val_recall: 0.5325 - val_precision: 0.5854\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0015 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.6998 - val_acc: 0.6961 - val_auc: 0.6910 - val_binary_accuracy: 0.6961 - val_recall: 0.5490 - val_precision: 0.5590\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0012 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.7066 - val_acc: 0.7014 - val_auc: 0.6922 - val_binary_accuracy: 0.7014 - val_recall: 0.5682 - val_precision: 0.5653\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0011 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.7247 - val_acc: 0.6953 - val_auc: 0.6928 - val_binary_accuracy: 0.6953 - val_recall: 0.5427 - val_precision: 0.5583\n",
      "0.7876731157302856\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "189b6a6e-a2a2-4681-9871-04f93cb85ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4014914/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8793ed73-c69e-47ab-b2fe-28ed77ba2d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional Accuracy:  0.5416666666666666 MSE:  0.4583333333333333 UAR:  0.5504201680672269 Recall:  0.5714285714285714 Precision:  0.3333333333333333 F1:  0.4210526315789474\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.6092436974789917 Recall:  0.5714285714285714 Precision:  0.4 F1:  0.47058823529411764\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6239495798319328 Recall:  0.5714285714285714 Precision:  0.42105263157894735 F1:  0.48484848484848486\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6533613445378151 Recall:  0.5714285714285714 Precision:  0.47058823529411764 F1:  0.5161290322580646\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6176470588235294 Recall:  0.5 Precision:  0.4375 F1:  0.4666666666666667\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6323529411764706 Recall:  0.5 Precision:  0.4666666666666667 F1:  0.4827586206896552\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6617647058823529 Recall:  0.5 Precision:  0.5384615384615384 F1:  0.5185185185185186\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional Accuracy:  0.75 MSE:  0.25 UAR:  0.6764705882352942 Recall:  0.5 Precision:  0.5833333333333334 F1:  0.5384615384615384\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional Accuracy:  0.6875 MSE:  0.3125 UAR:  0.569327731092437 Recall:  0.2857142857142857 Precision:  0.4444444444444444 F1:  0.34782608695652173\n",
      "0.8 0.6764705882352942\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "edbf95d2-964a-45ac-b252-09ca08746246",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35308f28-c321-4299-96f9-33abd1627365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4014914/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0108e0d-6171-4f1f-b336-a51760d45f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.5208333333333334 MSE:  0.4791666666666667 UAR:  0.5777310924369747 Recall:  0.7142857142857143 Precision:  0.3448275862068966 F1:  0.46511627906976755\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5735294117647058 Recall:  0.5 Precision:  0.3684210526315789 F1:  0.4242424242424242\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.625 MSE:  0.375 UAR:  0.5882352941176471 Recall:  0.5 Precision:  0.3888888888888889 F1:  0.43750000000000006\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6029411764705883 Recall:  0.5 Precision:  0.4117647058823529 F1:  0.45161290322580644\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5819327731092437 Recall:  0.42857142857142855 Precision:  0.4 F1:  0.4137931034482759\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.634453781512605 Recall:  0.35714285714285715 Precision:  0.625 F1:  0.45454545454545453\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.5714285714285714 Recall:  0.14285714285714285 Precision:  1.0 F1:  0.25\n",
      "0.7 0.634453781512605\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1d590b-6168-4fb4-a3bf-a3414ea78f0d",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14bdda6b-0039-4425-bd27-6b56ed4b8e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ae86870-775e-49fd-81be-1a81f377679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9741e956-1fd5-4753-a103-38496ac6e26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2560) (5449,)\n",
      "(2284, 128, 2560) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43e7e8e8-cfbe-4cc2-a005-f31a43dc0b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9b771713-bbb2-4407-a8fd-cd7cac3b5e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 140ms/step - loss: 0.5918 - acc: 0.7847 - auc: 0.7871 - binary_accuracy: 0.7847 - recall_1: 0.5607 - precision_1: 0.6410 - val_loss: 0.8495 - val_acc: 0.6475 - val_auc: 0.6537 - val_binary_accuracy: 0.6475 - val_recall_1: 0.5758 - val_precision_1: 0.4892\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.2312 - acc: 0.9095 - auc: 0.9594 - binary_accuracy: 0.9095 - recall_1: 0.7868 - precision_1: 0.8838 - val_loss: 0.7742 - val_acc: 0.7408 - val_auc: 0.7044 - val_binary_accuracy: 0.7408 - val_recall_1: 0.5057 - val_precision_1: 0.6606\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 103ms/step - loss: 0.1426 - acc: 0.9549 - auc: 0.9865 - binary_accuracy: 0.9549 - recall_1: 0.8940 - precision_1: 0.9450 - val_loss: 1.0746 - val_acc: 0.6756 - val_auc: 0.7150 - val_binary_accuracy: 0.6756 - val_recall_1: 0.2140 - val_precision_1: 0.5753\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.1210 - acc: 0.9593 - auc: 0.9899 - binary_accuracy: 0.9593 - recall_1: 0.9075 - precision_1: 0.9477 - val_loss: 1.0406 - val_acc: 0.7172 - val_auc: 0.7272 - val_binary_accuracy: 0.7172 - val_recall_1: 0.4242 - val_precision_1: 0.6319\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0896 - acc: 0.9701 - auc: 0.9946 - binary_accuracy: 0.9701 - recall_1: 0.9345 - precision_1: 0.9598 - val_loss: 1.2989 - val_acc: 0.6856 - val_auc: 0.7472 - val_binary_accuracy: 0.6856 - val_recall_1: 0.2522 - val_precision_1: 0.6018\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 103ms/step - loss: 0.0617 - acc: 0.9824 - auc: 0.9973 - binary_accuracy: 0.9824 - recall_1: 0.9615 - precision_1: 0.9765 - val_loss: 1.2513 - val_acc: 0.7071 - val_auc: 0.7324 - val_binary_accuracy: 0.7071 - val_recall_1: 0.3643 - val_precision_1: 0.6272\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0498 - acc: 0.9861 - auc: 0.9988 - binary_accuracy: 0.9861 - recall_1: 0.9666 - precision_1: 0.9843 - val_loss: 1.4187 - val_acc: 0.6926 - val_auc: 0.7563 - val_binary_accuracy: 0.6926 - val_recall_1: 0.2573 - val_precision_1: 0.6293\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0340 - acc: 0.9921 - auc: 0.9995 - binary_accuracy: 0.9921 - recall_1: 0.9814 - precision_1: 0.9909 - val_loss: 1.2756 - val_acc: 0.7215 - val_auc: 0.7755 - val_binary_accuracy: 0.7215 - val_recall_1: 0.3796 - val_precision_1: 0.6667\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0192 - acc: 0.9978 - auc: 0.9999 - binary_accuracy: 0.9978 - recall_1: 0.9929 - precision_1: 0.9994 - val_loss: 1.5351 - val_acc: 0.7128 - val_auc: 0.7476 - val_binary_accuracy: 0.7128 - val_recall_1: 0.3236 - val_precision_1: 0.6702\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 103ms/step - loss: 0.0151 - acc: 0.9983 - auc: 1.0000 - binary_accuracy: 0.9983 - recall_1: 0.9968 - precision_1: 0.9974 - val_loss: 1.3556 - val_acc: 0.7456 - val_auc: 0.7595 - val_binary_accuracy: 0.7456 - val_recall_1: 0.4701 - val_precision_1: 0.6910\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0134 - acc: 0.9980 - auc: 1.0000 - binary_accuracy: 0.9980 - recall_1: 0.9949 - precision_1: 0.9981 - val_loss: 1.5372 - val_acc: 0.7316 - val_auc: 0.7560 - val_binary_accuracy: 0.7316 - val_recall_1: 0.4102 - val_precision_1: 0.6822\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0130 - acc: 0.9972 - auc: 0.9999 - binary_accuracy: 0.9972 - recall_1: 0.9949 - precision_1: 0.9955 - val_loss: 2.0147 - val_acc: 0.6940 - val_auc: 0.7257 - val_binary_accuracy: 0.6940 - val_recall_1: 0.2306 - val_precision_1: 0.6558\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0216 - acc: 0.9947 - auc: 0.9997 - binary_accuracy: 0.9947 - recall_1: 0.9878 - precision_1: 0.9935 - val_loss: 1.6828 - val_acc: 0.7482 - val_auc: 0.7529 - val_binary_accuracy: 0.7482 - val_recall_1: 0.4841 - val_precision_1: 0.6909\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0299 - acc: 0.9906 - auc: 0.9989 - binary_accuracy: 0.9906 - recall_1: 0.9827 - precision_1: 0.9846 - val_loss: 1.6251 - val_acc: 0.7754 - val_auc: 0.7863 - val_binary_accuracy: 0.7754 - val_recall_1: 0.6127 - val_precision_1: 0.6971\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0219 - acc: 0.9932 - auc: 0.9996 - binary_accuracy: 0.9932 - recall_1: 0.9865 - precision_1: 0.9897 - val_loss: 1.8373 - val_acc: 0.7382 - val_auc: 0.7654 - val_binary_accuracy: 0.7382 - val_recall_1: 0.4522 - val_precision_1: 0.6788\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0119 - acc: 0.9971 - auc: 0.9999 - binary_accuracy: 0.9971 - recall_1: 0.9942 - precision_1: 0.9955 - val_loss: 2.3806 - val_acc: 0.6870 - val_auc: 0.7152 - val_binary_accuracy: 0.6870 - val_recall_1: 0.2854 - val_precision_1: 0.5926\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0043 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_1: 0.9987 - precision_1: 0.9987 - val_loss: 1.9901 - val_acc: 0.7426 - val_auc: 0.7454 - val_binary_accuracy: 0.7426 - val_recall_1: 0.4586 - val_precision_1: 0.6883\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0039 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_1: 0.9994 - precision_1: 0.9981 - val_loss: 2.1846 - val_acc: 0.6961 - val_auc: 0.7334 - val_binary_accuracy: 0.6961 - val_recall_1: 0.3070 - val_precision_1: 0.6164\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0074 - acc: 0.9987 - auc: 0.9999 - binary_accuracy: 0.9987 - recall_1: 0.9968 - precision_1: 0.9987 - val_loss: 1.9295 - val_acc: 0.7518 - val_auc: 0.7615 - val_binary_accuracy: 0.7518 - val_recall_1: 0.4943 - val_precision_1: 0.6953\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0034 - acc: 0.9991 - auc: 1.0000 - binary_accuracy: 0.9991 - recall_1: 0.9987 - precision_1: 0.9981 - val_loss: 1.9903 - val_acc: 0.7491 - val_auc: 0.7626 - val_binary_accuracy: 0.7491 - val_recall_1: 0.4777 - val_precision_1: 0.6970\n",
      "0.7741798758506775\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e3b30fa-46c2-40ab-9ed9-738c5ecf10a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4014914/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3051e935-a4c3-4288-a630-a1aa8e4e8ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional Accuracy:  0.8125 MSE:  0.1875 UAR:  0.7626050420168067 Recall:  0.6428571428571429 Precision:  0.6923076923076923 F1:  0.6666666666666666\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional Accuracy:  0.8333333333333334 MSE:  0.16666666666666666 UAR:  0.7773109243697479 Recall:  0.6428571428571429 Precision:  0.75 F1:  0.6923076923076924\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional Accuracy:  0.8333333333333334 MSE:  0.16666666666666666 UAR:  0.7773109243697479 Recall:  0.6428571428571429 Precision:  0.75 F1:  0.6923076923076924\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional Accuracy:  0.8333333333333334 MSE:  0.16666666666666666 UAR:  0.7773109243697479 Recall:  0.6428571428571429 Precision:  0.75 F1:  0.6923076923076924\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional Accuracy:  0.8333333333333334 MSE:  0.16666666666666666 UAR:  0.7773109243697479 Recall:  0.6428571428571429 Precision:  0.75 F1:  0.6923076923076924\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional Accuracy:  0.8333333333333334 MSE:  0.16666666666666666 UAR:  0.7773109243697479 Recall:  0.6428571428571429 Precision:  0.75 F1:  0.6923076923076924\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional Accuracy:  0.8125 MSE:  0.1875 UAR:  0.7415966386554622 Recall:  0.5714285714285714 Precision:  0.7272727272727273 F1:  0.64\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional Accuracy:  0.7916666666666666 MSE:  0.20833333333333334 UAR:  0.7058823529411764 Recall:  0.5 Precision:  0.7 F1:  0.5833333333333334\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional Accuracy:  0.8125 MSE:  0.1875 UAR:  0.7205882352941176 Recall:  0.5 Precision:  0.7777777777777778 F1:  0.6086956521739131\n",
      "0.2 0.7773109243697479\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4aeb0ea3-a59f-4d1e-b9a4-b6975802aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60a4809e-8e51-4421-87b4-ca6a56f00037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4014914/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aa0beb9d-9295-4374-a538-8b974dbd0b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.5625 MSE:  0.4375 UAR:  0.6281512605042017 Recall:  0.7857142857142857 Precision:  0.3793103448275862 F1:  0.5116279069767441\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.703781512605042 Recall:  0.6428571428571429 Precision:  0.5294117647058824 F1:  0.5806451612903226\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.7331932773109244 Recall:  0.6428571428571429 Precision:  0.6 F1:  0.6206896551724138\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.8125 MSE:  0.1875 UAR:  0.7626050420168067 Recall:  0.6428571428571429 Precision:  0.6923076923076923 F1:  0.6666666666666666\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.8125 MSE:  0.1875 UAR:  0.7415966386554622 Recall:  0.5714285714285714 Precision:  0.7272727272727273 F1:  0.64\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.8333333333333334 MSE:  0.16666666666666666 UAR:  0.7563025210084033 Recall:  0.5714285714285714 Precision:  0.8 F1:  0.6666666666666666\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.8125 MSE:  0.1875 UAR:  0.6995798319327731 Recall:  0.42857142857142855 Precision:  0.8571428571428571 F1:  0.5714285714285714\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.8125 MSE:  0.1875 UAR:  0.6995798319327731 Recall:  0.42857142857142855 Precision:  0.8571428571428571 F1:  0.5714285714285714\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6281512605042017 Recall:  0.2857142857142857 Precision:  0.8 F1:  0.4210526315789473\n",
      "0.4 0.7626050420168067\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9677bbad-49c6-41a1-83b4-8715a05d64ac",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87a2de58-8279-49c4-822e-6735ad797aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4812a76a-f10c-4eca-a228-ff0fe3075cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f47049d-d760-421a-8788-2b6008124667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "27b3263a-4726-4159-9d54-d9670564b9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147,) (147,)\n",
      "(48,) (48,)\n",
      "(195,) (195,)\n",
      "[0 1] [141  54]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.759)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d2e5ff98-304e-45ee-a75f-a1739ede3fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3936e31-b87e-41b8-a0a5-5a5f8d567d99",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f35f0641-3b18-42a3-beb2-d3e85ce7e175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9e8b6c73-80c8-4f6c-86a1-d13c0292e160",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a58e0b8-2538-42a7-ae5a-d110e8b652cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 2560) (5631,)\n",
      "(2102, 128, 2560) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d7cd10aa-aa1b-4fd3-9d82-f09b0d260da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ff3f367f-1ceb-4d24-a077-a5384442d1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44/44 [==============================] - 5s 83ms/step - loss: 0.3716 - acc: 0.8430 - auc: 0.8928 - binary_accuracy: 0.8430 - recall_2: 0.6052 - precision_2: 0.8311 - val_loss: 0.7749 - val_acc: 0.6698 - val_auc: 0.6856 - val_binary_accuracy: 0.6698 - val_recall_2: 0.4567 - val_precision_2: 0.4538\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.1450 - acc: 0.9563 - auc: 0.9877 - binary_accuracy: 0.9563 - recall_2: 0.8910 - precision_2: 0.9620 - val_loss: 0.9226 - val_acc: 0.6613 - val_auc: 0.6917 - val_binary_accuracy: 0.6613 - val_recall_2: 0.5039 - val_precision_2: 0.4463\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0865 - acc: 0.9746 - auc: 0.9960 - binary_accuracy: 0.9746 - recall_2: 0.9426 - precision_2: 0.9728 - val_loss: 1.1081 - val_acc: 0.6613 - val_auc: 0.7015 - val_binary_accuracy: 0.6613 - val_recall_2: 0.4945 - val_precision_2: 0.4454\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0515 - acc: 0.9886 - auc: 0.9992 - binary_accuracy: 0.9886 - recall_2: 0.9713 - precision_2: 0.9910 - val_loss: 1.2214 - val_acc: 0.6893 - val_auc: 0.7125 - val_binary_accuracy: 0.6893 - val_recall_2: 0.4646 - val_precision_2: 0.4852\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0354 - acc: 0.9918 - auc: 0.9997 - binary_accuracy: 0.9918 - recall_2: 0.9813 - precision_2: 0.9917 - val_loss: 1.3244 - val_acc: 0.7055 - val_auc: 0.7030 - val_binary_accuracy: 0.7055 - val_recall_2: 0.5071 - val_precision_2: 0.5127\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0203 - acc: 0.9984 - auc: 1.0000 - binary_accuracy: 0.9984 - recall_2: 0.9982 - precision_2: 0.9965 - val_loss: 1.5204 - val_acc: 0.6889 - val_auc: 0.6889 - val_binary_accuracy: 0.6889 - val_recall_2: 0.4677 - val_precision_2: 0.4845\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0131 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_2: 0.9994 - precision_2: 0.9982 - val_loss: 1.5954 - val_acc: 0.7008 - val_auc: 0.6935 - val_binary_accuracy: 0.7008 - val_recall_2: 0.5228 - val_precision_2: 0.5046\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0094 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_2: 0.9994 - precision_2: 0.9994 - val_loss: 1.7367 - val_acc: 0.6927 - val_auc: 0.6891 - val_binary_accuracy: 0.6927 - val_recall_2: 0.4976 - val_precision_2: 0.4914\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0078 - acc: 0.9995 - auc: 1.0000 - binary_accuracy: 0.9995 - recall_2: 0.9994 - precision_2: 0.9988 - val_loss: 1.7580 - val_acc: 0.6984 - val_auc: 0.6882 - val_binary_accuracy: 0.6984 - val_recall_2: 0.5165 - val_precision_2: 0.5008\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0058 - acc: 0.9995 - auc: 1.0000 - binary_accuracy: 0.9995 - recall_2: 0.9994 - precision_2: 0.9988 - val_loss: 1.8344 - val_acc: 0.7022 - val_auc: 0.6958 - val_binary_accuracy: 0.7022 - val_recall_2: 0.5228 - val_precision_2: 0.5069\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.0048 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_2: 1.0000 - precision_2: 0.9994 - val_loss: 1.8852 - val_acc: 0.7022 - val_auc: 0.6939 - val_binary_accuracy: 0.7022 - val_recall_2: 0.5386 - val_precision_2: 0.5067\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.0035 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_2: 1.0000 - precision_2: 0.9994 - val_loss: 1.9795 - val_acc: 0.7103 - val_auc: 0.6860 - val_binary_accuracy: 0.7103 - val_recall_2: 0.5717 - val_precision_2: 0.5186\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0028 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.0042 - val_acc: 0.7041 - val_auc: 0.6794 - val_binary_accuracy: 0.7041 - val_recall_2: 0.5780 - val_precision_2: 0.5090\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0025 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.0925 - val_acc: 0.6998 - val_auc: 0.6791 - val_binary_accuracy: 0.6998 - val_recall_2: 0.5433 - val_precision_2: 0.5029\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0020 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.1306 - val_acc: 0.7055 - val_auc: 0.6821 - val_binary_accuracy: 0.7055 - val_recall_2: 0.5732 - val_precision_2: 0.5112\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0017 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.1228 - val_acc: 0.7022 - val_auc: 0.6788 - val_binary_accuracy: 0.7022 - val_recall_2: 0.5780 - val_precision_2: 0.5062\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.0015 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_2: 0.9994 - precision_2: 1.0000 - val_loss: 2.1580 - val_acc: 0.7122 - val_auc: 0.6865 - val_binary_accuracy: 0.7122 - val_recall_2: 0.6000 - val_precision_2: 0.5205\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0018 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_2: 1.0000 - precision_2: 0.9994 - val_loss: 2.2350 - val_acc: 0.6912 - val_auc: 0.6821 - val_binary_accuracy: 0.6912 - val_recall_2: 0.5024 - val_precision_2: 0.4893\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.0013 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.2721 - val_acc: 0.7088 - val_auc: 0.6810 - val_binary_accuracy: 0.7088 - val_recall_2: 0.5953 - val_precision_2: 0.5157\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.0013 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.2590 - val_acc: 0.7079 - val_auc: 0.6849 - val_binary_accuracy: 0.7079 - val_recall_2: 0.5622 - val_precision_2: 0.5152\n",
      "0.7748990654945374\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "155d28a2-e514-4504-a408-ad39c115abba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4014914/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9aa8aaa9-d2cb-4bd4-8d54-86784bf19586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6323529411764706 Recall:  0.5 Precision:  0.4666666666666667 F1:  0.4827586206896552\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6323529411764706 Recall:  0.5 Precision:  0.4666666666666667 F1:  0.4827586206896552\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6323529411764706 Recall:  0.5 Precision:  0.4666666666666667 F1:  0.4827586206896552\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6323529411764706 Recall:  0.5 Precision:  0.4666666666666667 F1:  0.4827586206896552\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.611344537815126 Recall:  0.42857142857142855 Precision:  0.46153846153846156 F1:  0.4444444444444445\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6260504201680672 Recall:  0.42857142857142855 Precision:  0.5 F1:  0.4615384615384615\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.569327731092437 Recall:  0.2857142857142857 Precision:  0.4444444444444444 F1:  0.34782608695652173\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.569327731092437 Recall:  0.2857142857142857 Precision:  0.4444444444444444 F1:  0.34782608695652173\n",
      "0.5 0.6470588235294117\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0c640ace-a303-4134-bc75-d62d821e070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c66ce3e8-dd9d-469c-b119-9b418973aa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4014914/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aad2aa4b-5b54-44a7-89cb-018b02a90ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.625 MSE:  0.375 UAR:  0.6932773109243697 Recall:  0.8571428571428571 Precision:  0.42857142857142855 F1:  0.5714285714285714\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.7016806722689075 Recall:  0.7857142857142857 Precision:  0.4583333333333333 F1:  0.5789473684210527\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6449579831932774 Recall:  0.6428571428571429 Precision:  0.42857142857142855 F1:  0.5142857142857143\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6407563025210083 Recall:  0.42857142857142855 Precision:  0.5454545454545454 F1:  0.4799999999999999\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6554621848739496 Recall:  0.42857142857142855 Precision:  0.6 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6491596638655462 Recall:  0.35714285714285715 Precision:  0.7142857142857143 F1:  0.4761904761904762\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6491596638655462 Recall:  0.35714285714285715 Precision:  0.7142857142857143 F1:  0.4761904761904762\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6491596638655462 Recall:  0.35714285714285715 Precision:  0.7142857142857143 F1:  0.4761904761904762\n",
      "0.2 0.7016806722689075\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bfcf66-775e-476e-9978-bde714e3c475",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d60a18f6-3b50-4b78-80a6-29ce5eca775f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0eae7c25-d0d7-4f2d-885c-400235e34fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b5e76e32-3321-4ad9-8dc8-b42e0ddefb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 2560) (5631,)\n",
      "(2102, 128, 2560) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "837444f0-d640-40bc-832a-f0180c2bfca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a5adfe0d-85c9-4ba6-a1ff-ce24ccaac64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44/44 [==============================] - 8s 168ms/step - loss: 0.5993 - acc: 0.7878 - auc: 0.8036 - binary_accuracy: 0.7878 - recall_3: 0.6098 - precision_3: 0.6631 - val_loss: 0.6822 - val_acc: 0.6817 - val_auc: 0.6883 - val_binary_accuracy: 0.6817 - val_recall_3: 0.2850 - val_precision_3: 0.4571\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.2049 - acc: 0.9215 - auc: 0.9697 - binary_accuracy: 0.9215 - recall_3: 0.8278 - precision_3: 0.9052 - val_loss: 0.8615 - val_acc: 0.7122 - val_auc: 0.6816 - val_binary_accuracy: 0.7122 - val_recall_3: 0.3953 - val_precision_3: 0.5318\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 4s 90ms/step - loss: 0.1210 - acc: 0.9549 - auc: 0.9905 - binary_accuracy: 0.9549 - recall_3: 0.9086 - precision_3: 0.9406 - val_loss: 0.8721 - val_acc: 0.7393 - val_auc: 0.7289 - val_binary_accuracy: 0.7393 - val_recall_3: 0.5764 - val_precision_3: 0.5674\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.0802 - acc: 0.9753 - auc: 0.9957 - binary_accuracy: 0.9753 - recall_3: 0.9484 - precision_3: 0.9695 - val_loss: 1.2375 - val_acc: 0.7222 - val_auc: 0.6932 - val_binary_accuracy: 0.7222 - val_recall_3: 0.3858 - val_precision_3: 0.5581\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0678 - acc: 0.9776 - auc: 0.9966 - binary_accuracy: 0.9776 - recall_3: 0.9531 - precision_3: 0.9725 - val_loss: 1.2947 - val_acc: 0.7184 - val_auc: 0.7018 - val_binary_accuracy: 0.7184 - val_recall_3: 0.3717 - val_precision_3: 0.5501\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0560 - acc: 0.9790 - auc: 0.9976 - binary_accuracy: 0.9790 - recall_3: 0.9602 - precision_3: 0.9704 - val_loss: 1.2551 - val_acc: 0.7193 - val_auc: 0.7293 - val_binary_accuracy: 0.7193 - val_recall_3: 0.5748 - val_precision_3: 0.5328\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0372 - acc: 0.9886 - auc: 0.9986 - binary_accuracy: 0.9886 - recall_3: 0.9801 - precision_3: 0.9824 - val_loss: 1.5555 - val_acc: 0.6984 - val_auc: 0.6967 - val_binary_accuracy: 0.6984 - val_recall_3: 0.5071 - val_precision_3: 0.5008\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0222 - acc: 0.9948 - auc: 0.9998 - binary_accuracy: 0.9948 - recall_3: 0.9912 - precision_3: 0.9918 - val_loss: 1.4482 - val_acc: 0.7203 - val_auc: 0.7204 - val_binary_accuracy: 0.7203 - val_recall_3: 0.4898 - val_precision_3: 0.5409\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0242 - acc: 0.9929 - auc: 0.9996 - binary_accuracy: 0.9929 - recall_3: 0.9848 - precision_3: 0.9917 - val_loss: 1.7579 - val_acc: 0.7141 - val_auc: 0.7120 - val_binary_accuracy: 0.7141 - val_recall_3: 0.4000 - val_precision_3: 0.5359\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.1447 - acc: 0.9554 - auc: 0.9849 - binary_accuracy: 0.9554 - recall_3: 0.9227 - precision_3: 0.9298 - val_loss: 1.7190 - val_acc: 0.6974 - val_auc: 0.6963 - val_binary_accuracy: 0.6974 - val_recall_3: 0.5827 - val_precision_3: 0.4993\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0443 - acc: 0.9858 - auc: 0.9972 - binary_accuracy: 0.9858 - recall_3: 0.9695 - precision_3: 0.9834 - val_loss: 1.7971 - val_acc: 0.6741 - val_auc: 0.6820 - val_binary_accuracy: 0.6741 - val_recall_3: 0.5276 - val_precision_3: 0.4653\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0219 - acc: 0.9943 - auc: 0.9997 - binary_accuracy: 0.9943 - recall_3: 0.9877 - precision_3: 0.9935 - val_loss: 1.7530 - val_acc: 0.6903 - val_auc: 0.6999 - val_binary_accuracy: 0.6903 - val_recall_3: 0.4866 - val_precision_3: 0.4874\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0231 - acc: 0.9933 - auc: 0.9989 - binary_accuracy: 0.9933 - recall_3: 0.9877 - precision_3: 0.9900 - val_loss: 1.8787 - val_acc: 0.6779 - val_auc: 0.6843 - val_binary_accuracy: 0.6779 - val_recall_3: 0.4551 - val_precision_3: 0.4661\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.0084 - acc: 0.9984 - auc: 1.0000 - binary_accuracy: 0.9984 - recall_3: 0.9965 - precision_3: 0.9982 - val_loss: 2.0328 - val_acc: 0.6798 - val_auc: 0.6776 - val_binary_accuracy: 0.6798 - val_recall_3: 0.4205 - val_precision_3: 0.4668\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.0065 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_3: 0.9988 - precision_3: 0.9988 - val_loss: 2.1406 - val_acc: 0.6846 - val_auc: 0.6713 - val_binary_accuracy: 0.6846 - val_recall_3: 0.3921 - val_precision_3: 0.4734\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0059 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_3: 0.9988 - precision_3: 0.9988 - val_loss: 2.1636 - val_acc: 0.6551 - val_auc: 0.6861 - val_binary_accuracy: 0.6551 - val_recall_3: 0.4756 - val_precision_3: 0.4352\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0039 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_3: 0.9994 - precision_3: 1.0000 - val_loss: 2.2946 - val_acc: 0.6665 - val_auc: 0.6766 - val_binary_accuracy: 0.6665 - val_recall_3: 0.4110 - val_precision_3: 0.4439\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0029 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_3: 0.9988 - precision_3: 1.0000 - val_loss: 2.4013 - val_acc: 0.6608 - val_auc: 0.6743 - val_binary_accuracy: 0.6608 - val_recall_3: 0.4205 - val_precision_3: 0.4363\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.0026 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 2.3555 - val_acc: 0.6603 - val_auc: 0.6869 - val_binary_accuracy: 0.6603 - val_recall_3: 0.4850 - val_precision_3: 0.4432\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0024 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_3: 1.0000 - precision_3: 0.9994 - val_loss: 2.4045 - val_acc: 0.6803 - val_auc: 0.6819 - val_binary_accuracy: 0.6803 - val_recall_3: 0.4268 - val_precision_3: 0.4680\n",
      "0.6822482347488403\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c51c4798-a69c-4796-b773-767a09c310c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4014914/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f1c3e890-06ea-4c66-baee-e877e63b6ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6176470588235294 Recall:  0.5 Precision:  0.4375 F1:  0.4666666666666667\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6176470588235294 Recall:  0.5 Precision:  0.4375 F1:  0.4666666666666667\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6323529411764706 Recall:  0.5 Precision:  0.4666666666666667 F1:  0.4827586206896552\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6260504201680672 Recall:  0.42857142857142855 Precision:  0.5 F1:  0.4615384615384615\n",
      "0.4 0.6470588235294117\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "21745e3f-dd52-448c-8950-e70659921e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8702c6cd-4445-4790-ab18-20b43b9f4969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4014914/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "558c17e6-9d6b-49da-bc50-c742ef1880c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.6785714285714286 Recall:  0.8571428571428571 Precision:  0.41379310344827586 F1:  0.5581395348837208\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.7163865546218487 Recall:  0.7857142857142857 Precision:  0.4782608695652174 F1:  0.5945945945945946\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6533613445378151 Recall:  0.5714285714285714 Precision:  0.47058823529411764 F1:  0.5161290322580646\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6050420168067226 Recall:  0.35714285714285715 Precision:  0.5 F1:  0.41666666666666663\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6134453781512605 Recall:  0.2857142857142857 Precision:  0.6666666666666666 F1:  0.4\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5567226890756303 Recall:  0.14285714285714285 Precision:  0.6666666666666666 F1:  0.23529411764705882\n",
      "0.2 0.7163865546218487\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671e642a-d61e-4756-aef2-bb03532ec868",
   "metadata": {},
   "source": [
    "### Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0096a65-d6b4-4981-ae21-a8933b44042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.max\n",
    "stat_name = \"max\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf4f808-12f4-4f00-9d6f-78aa0bf3e9d1",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a6b55a7-8034-4b99-ac86-19d1a7bad672",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1523c7f4-4b43-42df-9ed7-617aa551b9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b837bcf5-04d1-469b-8aa4-e1409a4ad5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1632637-12e5-43c0-b0ba-bb59462eadc6",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0bbe2ee2-44e1-46fb-8326-02bc02a77ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c48f4b0b-3c28-41c6-a3ec-224b5c387e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fdd3c9bd-d28e-49e4-aaed-f6323aef5b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2560) (5449,)\n",
      "(2284, 128, 2560) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02cce768-fe09-4225-a155-73080b17697b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 07:17:43.974052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af592b3d-5a83-4f1f-9f88-fdc9fcc9c85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 07:17:53.529710: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbadc14df40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-30 07:17:53.530074: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-30 07:17:53.534425: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-30 07:17:53.581539: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-07-30 07:17:53.646642: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 8s 110ms/step - loss: 0.3723 - acc: 0.8541 - auc: 0.8832 - binary_accuracy: 0.8541 - recall: 0.6513 - precision: 0.8009 - val_loss: 0.7008 - val_acc: 0.7452 - val_auc: 0.7242 - val_binary_accuracy: 0.7452 - val_recall: 0.5045 - val_precision: 0.6723\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.1272 - acc: 0.9638 - auc: 0.9940 - binary_accuracy: 0.9638 - recall: 0.9056 - precision: 0.9658 - val_loss: 0.7590 - val_acc: 0.7303 - val_auc: 0.7296 - val_binary_accuracy: 0.7303 - val_recall: 0.5682 - val_precision: 0.6169\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0557 - acc: 0.9890 - auc: 0.9997 - binary_accuracy: 0.9890 - recall: 0.9769 - precision: 0.9845 - val_loss: 0.8781 - val_acc: 0.7570 - val_auc: 0.7387 - val_binary_accuracy: 0.7570 - val_recall: 0.5682 - val_precision: 0.6737\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0225 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.9448 - val_acc: 0.7806 - val_auc: 0.7408 - val_binary_accuracy: 0.7806 - val_recall: 0.5682 - val_precision: 0.7336\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0126 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.0343 - val_acc: 0.7456 - val_auc: 0.7385 - val_binary_accuracy: 0.7456 - val_recall: 0.5682 - val_precision: 0.6483\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0070 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.1110 - val_acc: 0.7706 - val_auc: 0.7402 - val_binary_accuracy: 0.7706 - val_recall: 0.5682 - val_precision: 0.7068\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0046 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.1252 - val_acc: 0.7693 - val_auc: 0.7446 - val_binary_accuracy: 0.7693 - val_recall: 0.5682 - val_precision: 0.7035\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0034 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.1717 - val_acc: 0.7688 - val_auc: 0.7435 - val_binary_accuracy: 0.7688 - val_recall: 0.5682 - val_precision: 0.7024\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0025 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.2163 - val_acc: 0.7767 - val_auc: 0.7462 - val_binary_accuracy: 0.7767 - val_recall: 0.5682 - val_precision: 0.7229\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0020 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.2249 - val_acc: 0.7719 - val_auc: 0.7487 - val_binary_accuracy: 0.7719 - val_recall: 0.5682 - val_precision: 0.7102\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0016 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.2799 - val_acc: 0.7701 - val_auc: 0.7453 - val_binary_accuracy: 0.7701 - val_recall: 0.5682 - val_precision: 0.7057\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0013 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.3074 - val_acc: 0.7728 - val_auc: 0.7439 - val_binary_accuracy: 0.7728 - val_recall: 0.5682 - val_precision: 0.7125\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0011 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.3234 - val_acc: 0.7728 - val_auc: 0.7451 - val_binary_accuracy: 0.7728 - val_recall: 0.5682 - val_precision: 0.7125\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 9.7321e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.3430 - val_acc: 0.7531 - val_auc: 0.7482 - val_binary_accuracy: 0.7531 - val_recall: 0.5682 - val_precision: 0.6647\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 8.1330e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.3613 - val_acc: 0.7728 - val_auc: 0.7438 - val_binary_accuracy: 0.7728 - val_recall: 0.5682 - val_precision: 0.7125\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 6.7977e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.3931 - val_acc: 0.7728 - val_auc: 0.7419 - val_binary_accuracy: 0.7728 - val_recall: 0.5682 - val_precision: 0.7125\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 6.0516e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.4118 - val_acc: 0.7728 - val_auc: 0.7434 - val_binary_accuracy: 0.7728 - val_recall: 0.5682 - val_precision: 0.7125\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 5.3242e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.4241 - val_acc: 0.7728 - val_auc: 0.7449 - val_binary_accuracy: 0.7728 - val_recall: 0.5682 - val_precision: 0.7125\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 4.7800e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.4422 - val_acc: 0.7728 - val_auc: 0.7422 - val_binary_accuracy: 0.7728 - val_recall: 0.5682 - val_precision: 0.7125\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 4.2573e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.4589 - val_acc: 0.7728 - val_auc: 0.7406 - val_binary_accuracy: 0.7728 - val_recall: 0.5682 - val_precision: 0.7125\n",
      "0.7008012533187866\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a29d7a7-7184-4c7d-9c52-70dda758d8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4027200/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5557626c-f4fa-4e25-9b64-787cca642065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6386554621848739 Recall:  0.5714285714285714 Precision:  0.4444444444444444 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6911764705882353 Recall:  0.5 Precision:  0.6363636363636364 F1:  0.56\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6911764705882353 Recall:  0.5 Precision:  0.6363636363636364 F1:  0.56\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6911764705882353 Recall:  0.5 Precision:  0.6363636363636364 F1:  0.56\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional Accuracy:  0.7916666666666666 MSE:  0.20833333333333334 UAR:  0.7058823529411764 Recall:  0.5 Precision:  0.7 F1:  0.5833333333333334\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional Accuracy:  0.8125 MSE:  0.1875 UAR:  0.7205882352941176 Recall:  0.5 Precision:  0.7777777777777778 F1:  0.6086956521739131\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional Accuracy:  0.8125 MSE:  0.1875 UAR:  0.7205882352941176 Recall:  0.5 Precision:  0.7777777777777778 F1:  0.6086956521739131\n",
      "0.8 0.7205882352941176\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0cecedbb-dc74-44a2-ab1b-949f9b7624d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ddf37e5-0310-4739-b9f1-5ff148917b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4027200/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "69ff8ba2-7355-4a3a-8d31-7aaa30169ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.5208333333333334 MSE:  0.4791666666666667 UAR:  0.5357142857142857 Recall:  0.5714285714285714 Precision:  0.32 F1:  0.41025641025641024\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.5588235294117647 Recall:  0.5 Precision:  0.35 F1:  0.4117647058823529\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5735294117647058 Recall:  0.5 Precision:  0.3684210526315789 F1:  0.4242424242424242\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6617647058823529 Recall:  0.5 Precision:  0.5384615384615384 F1:  0.5185185185185186\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6701680672268907 Recall:  0.42857142857142855 Precision:  0.6666666666666666 F1:  0.5217391304347826\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.634453781512605 Recall:  0.35714285714285715 Precision:  0.625 F1:  0.45454545454545453\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5777310924369747 Recall:  0.21428571428571427 Precision:  0.6 F1:  0.3157894736842105\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5063025210084033 Recall:  0.07142857142857142 Precision:  0.3333333333333333 F1:  0.11764705882352941\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5357142857142857 Recall:  0.07142857142857142 Precision:  1.0 F1:  0.13333333333333333\n",
      "0.5 0.6701680672268907\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23e301d-31bb-424f-a82d-cdf366b49db7",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8cf03d56-38ce-46ce-a9c0-18b647c08141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5be30832-66ea-431f-be2e-dcccd79cf925",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99b3cb7b-a498-4d5a-ad24-bda81f00799e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2560) (5449,)\n",
      "(2284, 128, 2560) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "803e838f-d4f8-47be-8975-5d487c708c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "26ca876d-600f-496e-b993-2a4f2df0ab4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 8s 155ms/step - loss: 1.5761 - acc: 0.7234 - auc: 0.7081 - binary_accuracy: 0.7234 - recall_1: 0.5414 - precision_1: 0.5153 - val_loss: 1.2094 - val_acc: 0.6493 - val_auc: 0.6822 - val_binary_accuracy: 0.6493 - val_recall_1: 0.1108 - val_precision_1: 0.4579\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.2213 - acc: 0.9189 - auc: 0.9613 - binary_accuracy: 0.9189 - recall_1: 0.8182 - precision_1: 0.8890 - val_loss: 0.8240 - val_acc: 0.6528 - val_auc: 0.6992 - val_binary_accuracy: 0.6528 - val_recall_1: 0.3261 - val_precision_1: 0.4923\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.1190 - acc: 0.9660 - auc: 0.9940 - binary_accuracy: 0.9660 - recall_1: 0.9249 - precision_1: 0.9549 - val_loss: 0.9960 - val_acc: 0.6909 - val_auc: 0.6846 - val_binary_accuracy: 0.6909 - val_recall_1: 0.2586 - val_precision_1: 0.6208\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0755 - acc: 0.9846 - auc: 0.9981 - binary_accuracy: 0.9846 - recall_1: 0.9685 - precision_1: 0.9773 - val_loss: 0.8987 - val_acc: 0.6870 - val_auc: 0.7175 - val_binary_accuracy: 0.6870 - val_recall_1: 0.3439 - val_precision_1: 0.5745\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0409 - acc: 0.9954 - auc: 0.9998 - binary_accuracy: 0.9954 - recall_1: 0.9923 - precision_1: 0.9917 - val_loss: 0.9313 - val_acc: 0.7137 - val_auc: 0.7298 - val_binary_accuracy: 0.7137 - val_recall_1: 0.4446 - val_precision_1: 0.6155\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0261 - acc: 0.9980 - auc: 0.9999 - binary_accuracy: 0.9980 - recall_1: 0.9961 - precision_1: 0.9968 - val_loss: 1.0685 - val_acc: 0.7058 - val_auc: 0.7267 - val_binary_accuracy: 0.7058 - val_recall_1: 0.3439 - val_precision_1: 0.6323\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0194 - acc: 0.9985 - auc: 1.0000 - binary_accuracy: 0.9985 - recall_1: 0.9961 - precision_1: 0.9987 - val_loss: 1.1140 - val_acc: 0.7018 - val_auc: 0.7129 - val_binary_accuracy: 0.7018 - val_recall_1: 0.4115 - val_precision_1: 0.5959\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0123 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_1: 0.9981 - precision_1: 0.9994 - val_loss: 1.1572 - val_acc: 0.6948 - val_auc: 0.7195 - val_binary_accuracy: 0.6948 - val_recall_1: 0.4318 - val_precision_1: 0.5746\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 104ms/step - loss: 0.0076 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_1: 0.9987 - precision_1: 1.0000 - val_loss: 1.1992 - val_acc: 0.7084 - val_auc: 0.7242 - val_binary_accuracy: 0.7084 - val_recall_1: 0.4497 - val_precision_1: 0.6014\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0061 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_1: 0.9987 - precision_1: 1.0000 - val_loss: 1.2325 - val_acc: 0.6996 - val_auc: 0.7232 - val_binary_accuracy: 0.6996 - val_recall_1: 0.4420 - val_precision_1: 0.5832\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 103ms/step - loss: 0.0042 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 1.3115 - val_acc: 0.7032 - val_auc: 0.7215 - val_binary_accuracy: 0.7032 - val_recall_1: 0.4229 - val_precision_1: 0.5961\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0034 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 1.3569 - val_acc: 0.7049 - val_auc: 0.7209 - val_binary_accuracy: 0.7049 - val_recall_1: 0.4318 - val_precision_1: 0.5979\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 103ms/step - loss: 0.0026 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 1.3692 - val_acc: 0.7062 - val_auc: 0.7233 - val_binary_accuracy: 0.7062 - val_recall_1: 0.4357 - val_precision_1: 0.6000\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0021 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 1.4375 - val_acc: 0.7023 - val_auc: 0.7202 - val_binary_accuracy: 0.7023 - val_recall_1: 0.4153 - val_precision_1: 0.5960\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0018 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 1.4434 - val_acc: 0.7049 - val_auc: 0.7220 - val_binary_accuracy: 0.7049 - val_recall_1: 0.4318 - val_precision_1: 0.5979\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0015 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 1.4823 - val_acc: 0.7045 - val_auc: 0.7185 - val_binary_accuracy: 0.7045 - val_recall_1: 0.4306 - val_precision_1: 0.5972\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0013 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 1.4932 - val_acc: 0.7045 - val_auc: 0.7214 - val_binary_accuracy: 0.7045 - val_recall_1: 0.4357 - val_precision_1: 0.5958\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0012 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 1.5517 - val_acc: 0.7014 - val_auc: 0.7160 - val_binary_accuracy: 0.7014 - val_recall_1: 0.4102 - val_precision_1: 0.5952\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0010 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 1.5930 - val_acc: 0.7001 - val_auc: 0.7128 - val_binary_accuracy: 0.7001 - val_recall_1: 0.4038 - val_precision_1: 0.5936\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 9.3099e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 1.5534 - val_acc: 0.7005 - val_auc: 0.7204 - val_binary_accuracy: 0.7005 - val_recall_1: 0.4382 - val_precision_1: 0.5860\n",
      "0.8239837288856506\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aad77efb-dfcb-4109-aa07-5b97aa1ac8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4027200/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c5d22eef-4a43-4b61-9300-8311181ea948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6176470588235294 Recall:  0.5 Precision:  0.4375 F1:  0.4666666666666667\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6260504201680672 Recall:  0.42857142857142855 Precision:  0.5 F1:  0.4615384615384615\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional Accuracy:  0.75 MSE:  0.25 UAR:  0.6554621848739496 Recall:  0.42857142857142855 Precision:  0.6 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional Accuracy:  0.75 MSE:  0.25 UAR:  0.6554621848739496 Recall:  0.42857142857142855 Precision:  0.6 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional Accuracy:  0.75 MSE:  0.25 UAR:  0.6554621848739496 Recall:  0.42857142857142855 Precision:  0.6 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6197478991596639 Recall:  0.35714285714285715 Precision:  0.5555555555555556 F1:  0.43478260869565216\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional Accuracy:  0.75 MSE:  0.25 UAR:  0.634453781512605 Recall:  0.35714285714285715 Precision:  0.625 F1:  0.45454545454545453\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional Accuracy:  0.75 MSE:  0.25 UAR:  0.6134453781512605 Recall:  0.2857142857142857 Precision:  0.6666666666666666 F1:  0.4\n",
      "0.4 0.6554621848739496\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd747654-22f2-4d0e-8996-552ece373e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4590c3f8-27d1-486b-875b-b08909c9d5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4027200/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "390b8f4a-001d-49ec-bb24-2e32248a8006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.6785714285714286 Recall:  0.8571428571428571 Precision:  0.41379310344827586 F1:  0.5581395348837208\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6533613445378151 Recall:  0.5714285714285714 Precision:  0.47058823529411764 F1:  0.5161290322580646\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6260504201680672 Recall:  0.42857142857142855 Precision:  0.5 F1:  0.4615384615384615\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5903361344537815 Recall:  0.35714285714285715 Precision:  0.45454545454545453 F1:  0.4\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6050420168067226 Recall:  0.35714285714285715 Precision:  0.5 F1:  0.41666666666666663\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.634453781512605 Recall:  0.35714285714285715 Precision:  0.625 F1:  0.45454545454545453\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6134453781512605 Recall:  0.2857142857142857 Precision:  0.6666666666666666 F1:  0.4\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5567226890756303 Recall:  0.14285714285714285 Precision:  0.6666666666666666 F1:  0.23529411764705882\n",
      "0.1 0.6785714285714286\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac71908-4122-4cfd-9f00-6973bf65b4c7",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c2bff731-caa2-4f09-83f0-58c7bb5bc532",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "184e4b63-20e2-4ddd-a4c2-5b067abb33c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e745a3ad-464a-42e2-8ef1-727d25ca9466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "07c9bf86-b1ce-4216-a8c5-e202f8211f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147,) (147,)\n",
      "(48,) (48,)\n",
      "(195,) (195,)\n",
      "[0 1] [141  54]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.759)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7260c74e-6fd0-445d-ab06-6b439c7de819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2fd455-0612-41b9-835a-5d920fca36b8",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "659683bb-207c-4be1-8636-a2b414843e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c237a993-9ba6-44ad-ab4d-1d529316dc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "35d55d43-8b99-4042-b2d2-324cc0f8ea21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 2560) (5631,)\n",
      "(2102, 128, 2560) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4b65d76c-49a9-404f-8d35-23d03eb4d1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ceff91a5-ed9e-4bd5-9ae6-ebf95fc55b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44/44 [==============================] - 4s 74ms/step - loss: 0.4721 - acc: 0.7949 - auc: 0.8205 - binary_accuracy: 0.7949 - recall_2: 0.5489 - precision_2: 0.7088 - val_loss: 0.6953 - val_acc: 0.5951 - val_auc: 0.7154 - val_binary_accuracy: 0.5951 - val_recall_2: 0.3984 - val_precision_2: 0.3504\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.1780 - acc: 0.9469 - auc: 0.9814 - binary_accuracy: 0.9469 - recall_2: 0.8541 - precision_2: 0.9668 - val_loss: 0.9529 - val_acc: 0.6066 - val_auc: 0.7030 - val_binary_accuracy: 0.6066 - val_recall_2: 0.4787 - val_precision_2: 0.3800\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0862 - acc: 0.9798 - auc: 0.9976 - binary_accuracy: 0.9798 - recall_2: 0.9432 - precision_2: 0.9896 - val_loss: 1.1213 - val_acc: 0.6560 - val_auc: 0.6707 - val_binary_accuracy: 0.6560 - val_recall_2: 0.3984 - val_precision_2: 0.4259\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0427 - acc: 0.9941 - auc: 0.9999 - binary_accuracy: 0.9941 - recall_2: 0.9818 - precision_2: 0.9988 - val_loss: 1.2820 - val_acc: 0.6342 - val_auc: 0.6859 - val_binary_accuracy: 0.6342 - val_recall_2: 0.4724 - val_precision_2: 0.4087\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.0262 - acc: 0.9989 - auc: 1.0000 - binary_accuracy: 0.9989 - recall_2: 0.9971 - precision_2: 0.9994 - val_loss: 1.4945 - val_acc: 0.6108 - val_auc: 0.6704 - val_binary_accuracy: 0.6108 - val_recall_2: 0.4220 - val_precision_2: 0.3727\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0134 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_2: 0.9994 - precision_2: 1.0000 - val_loss: 1.6076 - val_acc: 0.6637 - val_auc: 0.6619 - val_binary_accuracy: 0.6637 - val_recall_2: 0.4016 - val_precision_2: 0.4381\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0088 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_2: 0.9994 - precision_2: 1.0000 - val_loss: 1.6819 - val_acc: 0.6522 - val_auc: 0.6610 - val_binary_accuracy: 0.6522 - val_recall_2: 0.4110 - val_precision_2: 0.4223\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0071 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.7749 - val_acc: 0.6494 - val_auc: 0.6597 - val_binary_accuracy: 0.6494 - val_recall_2: 0.4126 - val_precision_2: 0.4185\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0050 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.8627 - val_acc: 0.6670 - val_auc: 0.6566 - val_binary_accuracy: 0.6670 - val_recall_2: 0.4110 - val_precision_2: 0.4446\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0035 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.9108 - val_acc: 0.6522 - val_auc: 0.6542 - val_binary_accuracy: 0.6522 - val_recall_2: 0.4126 - val_precision_2: 0.4226\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.0028 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.9757 - val_acc: 0.6361 - val_auc: 0.6536 - val_binary_accuracy: 0.6361 - val_recall_2: 0.4142 - val_precision_2: 0.4009\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0023 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.0384 - val_acc: 0.6399 - val_auc: 0.6528 - val_binary_accuracy: 0.6399 - val_recall_2: 0.4094 - val_precision_2: 0.4050\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0019 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.0915 - val_acc: 0.6660 - val_auc: 0.6571 - val_binary_accuracy: 0.6660 - val_recall_2: 0.4063 - val_precision_2: 0.4425\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0017 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.1303 - val_acc: 0.6342 - val_auc: 0.6530 - val_binary_accuracy: 0.6342 - val_recall_2: 0.4205 - val_precision_2: 0.3997\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.0014 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.1545 - val_acc: 0.6598 - val_auc: 0.6558 - val_binary_accuracy: 0.6598 - val_recall_2: 0.4110 - val_precision_2: 0.4336\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0012 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.2072 - val_acc: 0.6546 - val_auc: 0.6569 - val_binary_accuracy: 0.6546 - val_recall_2: 0.4079 - val_precision_2: 0.4253\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0011 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.2473 - val_acc: 0.6422 - val_auc: 0.6573 - val_binary_accuracy: 0.6422 - val_recall_2: 0.4126 - val_precision_2: 0.4087\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 9.4335e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.2756 - val_acc: 0.6351 - val_auc: 0.6559 - val_binary_accuracy: 0.6351 - val_recall_2: 0.4220 - val_precision_2: 0.4012\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 8.4522e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.2955 - val_acc: 0.6432 - val_auc: 0.6585 - val_binary_accuracy: 0.6432 - val_recall_2: 0.4157 - val_precision_2: 0.4106\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 7.5379e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.3402 - val_acc: 0.6484 - val_auc: 0.6588 - val_binary_accuracy: 0.6484 - val_recall_2: 0.4110 - val_precision_2: 0.4169\n",
      "0.6952969431877136\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6b53229a-77fa-49da-aacf-006749c53731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4027200/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3bf17979-e3dd-4b72-a609-c879a76614be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced Accuracy:  0.625 MSE:  0.375 UAR:  0.5672268907563025 Recall:  0.42857142857142855 Precision:  0.375 F1:  0.39999999999999997\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced Accuracy:  0.625 MSE:  0.375 UAR:  0.5672268907563025 Recall:  0.42857142857142855 Precision:  0.375 F1:  0.39999999999999997\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5756302521008403 Recall:  0.35714285714285715 Precision:  0.4166666666666667 F1:  0.3846153846153846\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5756302521008403 Recall:  0.35714285714285715 Precision:  0.4166666666666667 F1:  0.3846153846153846\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6050420168067226 Recall:  0.35714285714285715 Precision:  0.5 F1:  0.41666666666666663\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6050420168067226 Recall:  0.35714285714285715 Precision:  0.5 F1:  0.41666666666666663\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6050420168067226 Recall:  0.35714285714285715 Precision:  0.5 F1:  0.41666666666666663\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6050420168067226 Recall:  0.35714285714285715 Precision:  0.5 F1:  0.41666666666666663\n",
      "0.6 0.6050420168067226\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "81d80c25-7b07-4ec2-a261-c8b45dff88d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "07a64468-3efb-43cf-9883-898f1fc478fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4027200/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cd31902f-a6c8-4118-b404-3ad2db54d7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.5416666666666666 MSE:  0.4583333333333333 UAR:  0.634453781512605 Recall:  0.8571428571428571 Precision:  0.375 F1:  0.5217391304347825\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.625 MSE:  0.375 UAR:  0.6302521008403361 Recall:  0.6428571428571429 Precision:  0.4090909090909091 F1:  0.5000000000000001\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6596638655462186 Recall:  0.6428571428571429 Precision:  0.45 F1:  0.5294117647058824\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.625 MSE:  0.375 UAR:  0.546218487394958 Recall:  0.35714285714285715 Precision:  0.35714285714285715 F1:  0.35714285714285715\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5609243697478992 Recall:  0.35714285714285715 Precision:  0.38461538461538464 F1:  0.3703703703703704\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5756302521008403 Recall:  0.35714285714285715 Precision:  0.4166666666666667 F1:  0.3846153846153846\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6197478991596639 Recall:  0.35714285714285715 Precision:  0.5555555555555556 F1:  0.43478260869565216\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.592436974789916 Recall:  0.21428571428571427 Precision:  0.75 F1:  0.3333333333333333\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5210084033613446 Recall:  0.07142857142857142 Precision:  0.5 F1:  0.125\n",
      "0.3 0.6596638655462186\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf835a9c-5077-47e2-96f2-2f7b47039cb2",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eddd5c5a-e35f-4613-bee8-89e1274bd15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1bc89c55-a68c-4087-bcf6-56be8834160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c9a4781a-3f06-4fe6-abd8-177e6b2a0082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 2560) (5631,)\n",
      "(2102, 128, 2560) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "db4af0fa-9381-4a59-86d1-117186dc3afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3977aa56-d2e8-4d5f-9c97-b51fe37a606d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44/44 [==============================] - 8s 168ms/step - loss: 1.2116 - acc: 0.7714 - auc: 0.7812 - binary_accuracy: 0.7714 - recall_3: 0.6333 - precision_3: 0.6206 - val_loss: 1.0200 - val_acc: 0.6042 - val_auc: 0.6351 - val_binary_accuracy: 0.6042 - val_recall_3: 0.5496 - val_precision_3: 0.3899\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 0.1467 - acc: 0.9515 - auc: 0.9866 - binary_accuracy: 0.9515 - recall_3: 0.8928 - precision_3: 0.9442 - val_loss: 0.9340 - val_acc: 0.6275 - val_auc: 0.6549 - val_binary_accuracy: 0.6275 - val_recall_3: 0.4173 - val_precision_3: 0.3909\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0680 - acc: 0.9876 - auc: 0.9990 - binary_accuracy: 0.9876 - recall_3: 0.9690 - precision_3: 0.9898 - val_loss: 1.1035 - val_acc: 0.6213 - val_auc: 0.6565 - val_binary_accuracy: 0.6213 - val_recall_3: 0.3732 - val_precision_3: 0.3732\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 5s 103ms/step - loss: 0.0379 - acc: 0.9940 - auc: 0.9997 - binary_accuracy: 0.9940 - recall_3: 0.9859 - precision_3: 0.9941 - val_loss: 1.2975 - val_acc: 0.6446 - val_auc: 0.6308 - val_binary_accuracy: 0.6446 - val_recall_3: 0.4205 - val_precision_3: 0.4133\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.0198 - acc: 0.9986 - auc: 1.0000 - binary_accuracy: 0.9986 - recall_3: 0.9965 - precision_3: 0.9988 - val_loss: 1.4142 - val_acc: 0.6403 - val_auc: 0.6274 - val_binary_accuracy: 0.6403 - val_recall_3: 0.4220 - val_precision_3: 0.4079\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.0120 - acc: 0.9995 - auc: 1.0000 - binary_accuracy: 0.9995 - recall_3: 0.9982 - precision_3: 1.0000 - val_loss: 1.5439 - val_acc: 0.6522 - val_auc: 0.5914 - val_binary_accuracy: 0.6522 - val_recall_3: 0.3780 - val_precision_3: 0.4167\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.0081 - acc: 0.9995 - auc: 1.0000 - binary_accuracy: 0.9995 - recall_3: 0.9982 - precision_3: 1.0000 - val_loss: 1.6381 - val_acc: 0.6537 - val_auc: 0.5967 - val_binary_accuracy: 0.6537 - val_recall_3: 0.4173 - val_precision_3: 0.4254\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0051 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_3: 0.9994 - precision_3: 1.0000 - val_loss: 1.7271 - val_acc: 0.6575 - val_auc: 0.5856 - val_binary_accuracy: 0.6575 - val_recall_3: 0.4110 - val_precision_3: 0.4300\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0043 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_3: 0.9994 - precision_3: 1.0000 - val_loss: 1.8166 - val_acc: 0.6551 - val_auc: 0.5757 - val_binary_accuracy: 0.6551 - val_recall_3: 0.3433 - val_precision_3: 0.4144\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.0037 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 1.9184 - val_acc: 0.6503 - val_auc: 0.5715 - val_binary_accuracy: 0.6503 - val_recall_3: 0.3764 - val_precision_3: 0.4135\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 5s 104ms/step - loss: 0.0023 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 1.9899 - val_acc: 0.6384 - val_auc: 0.5884 - val_binary_accuracy: 0.6384 - val_recall_3: 0.4331 - val_precision_3: 0.4074\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.0019 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 2.0304 - val_acc: 0.6394 - val_auc: 0.5853 - val_binary_accuracy: 0.6394 - val_recall_3: 0.4315 - val_precision_3: 0.4083\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0014 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 2.0697 - val_acc: 0.6499 - val_auc: 0.5787 - val_binary_accuracy: 0.6499 - val_recall_3: 0.4236 - val_precision_3: 0.4210\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.0012 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 2.1040 - val_acc: 0.6394 - val_auc: 0.5916 - val_binary_accuracy: 0.6394 - val_recall_3: 0.4346 - val_precision_3: 0.4089\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0011 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 2.1532 - val_acc: 0.6413 - val_auc: 0.5851 - val_binary_accuracy: 0.6413 - val_recall_3: 0.4315 - val_precision_3: 0.4108\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 8.9386e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 2.1874 - val_acc: 0.6518 - val_auc: 0.5779 - val_binary_accuracy: 0.6518 - val_recall_3: 0.4220 - val_precision_3: 0.4234\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 7.6760e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 2.2041 - val_acc: 0.6565 - val_auc: 0.5767 - val_binary_accuracy: 0.6565 - val_recall_3: 0.3937 - val_precision_3: 0.4259\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 6.7617e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 2.2375 - val_acc: 0.6570 - val_auc: 0.5760 - val_binary_accuracy: 0.6570 - val_recall_3: 0.4157 - val_precision_3: 0.4300\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 6.1662e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 2.2689 - val_acc: 0.6594 - val_auc: 0.5786 - val_binary_accuracy: 0.6594 - val_recall_3: 0.4047 - val_precision_3: 0.4319\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 5.4005e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 2.2958 - val_acc: 0.6594 - val_auc: 0.5789 - val_binary_accuracy: 0.6594 - val_recall_3: 0.4157 - val_precision_3: 0.4335\n",
      "0.9339626431465149\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6883f189-8f67-4809-99de-32609971bcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4027200/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "88b6068f-c732-4187-b2ec-24e7dd16cb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced Accuracy:  0.625 MSE:  0.375 UAR:  0.5882352941176471 Recall:  0.5 Precision:  0.3888888888888889 F1:  0.43750000000000006\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6029411764705883 Recall:  0.5 Precision:  0.4117647058823529 F1:  0.45161290322580644\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6260504201680672 Recall:  0.42857142857142855 Precision:  0.5 F1:  0.4615384615384615\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5903361344537815 Recall:  0.35714285714285715 Precision:  0.45454545454545453 F1:  0.4\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5903361344537815 Recall:  0.35714285714285715 Precision:  0.45454545454545453 F1:  0.4\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5903361344537815 Recall:  0.35714285714285715 Precision:  0.45454545454545453 F1:  0.4\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5903361344537815 Recall:  0.35714285714285715 Precision:  0.45454545454545453 F1:  0.4\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.569327731092437 Recall:  0.2857142857142857 Precision:  0.4444444444444444 F1:  0.34782608695652173\n",
      "0.4 0.6260504201680672\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f0d714d6-2d6c-436e-81dc-442a9cc14715",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "62a52370-3e0c-407f-b096-6b65f456b08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4027200/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d7190ac7-6ac6-43a6-9643-23e276d450da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.5625 MSE:  0.4375 UAR:  0.5861344537815126 Recall:  0.6428571428571429 Precision:  0.36 F1:  0.4615384615384615\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.625 MSE:  0.375 UAR:  0.6302521008403361 Recall:  0.6428571428571429 Precision:  0.4090909090909091 F1:  0.5000000000000001\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.625 MSE:  0.375 UAR:  0.6092436974789917 Recall:  0.5714285714285714 Precision:  0.4 F1:  0.47058823529411764\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6386554621848739 Recall:  0.5714285714285714 Precision:  0.4444444444444444 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5819327731092437 Recall:  0.42857142857142855 Precision:  0.4 F1:  0.4137931034482759\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.611344537815126 Recall:  0.42857142857142855 Precision:  0.46153846153846156 F1:  0.4444444444444445\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.611344537815126 Recall:  0.42857142857142855 Precision:  0.46153846153846156 F1:  0.4444444444444445\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5336134453781513 Recall:  0.21428571428571427 Precision:  0.375 F1:  0.2727272727272727\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.45588235294117646 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.4 0.6386554621848739\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956d63cd-4d28-4933-b603-baa894e7e83f",
   "metadata": {},
   "source": [
    "### STAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0bb9be4-3092-4bec-84ab-d8ad893629e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = compute_descriptor\n",
    "stat_name = \"STAT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404e64e3-f13f-47fc-8035-eb2a70e7b75e",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4cba168-1179-48b7-85da-73b4776871e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e33f684-3833-4521-a733-51f5f2739cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4ebb9dc-4636-4698-87f9-aebb2cd213be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd62ec-ef0a-477a-8178-c75f65958e12",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f113ed6e-9c91-4042-8d8f-5c0ffd3d4344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "125cd68b-a3f5-41ca-9d00-ef41b3d0be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ae748bc-ba96-4495-a499-fdf5026bb288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 3840) (5449,)\n",
      "(2284, 128, 3840) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1d9b4ce-b98f-4e58-91ea-2d6265b097a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 07:24:49.986587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1966592   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1970946 (7.52 MB)\n",
      "Trainable params: 1970946 (7.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17cdc14c-65bd-4860-92c8-7e7940ee9565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 07:25:03.152418: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2ec8232af0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-30 07:25:03.152594: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-30 07:25:03.156757: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-30 07:25:03.198857: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-07-30 07:25:03.250678: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 10s 159ms/step - loss: 0.4052 - acc: 0.8391 - auc: 0.8601 - binary_accuracy: 0.8391 - recall: 0.5382 - precision: 0.8414 - val_loss: 0.7601 - val_acc: 0.7084 - val_auc: 0.6645 - val_binary_accuracy: 0.7084 - val_recall: 0.2459 - val_precision: 0.7228\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.1796 - acc: 0.9352 - auc: 0.9801 - binary_accuracy: 0.9352 - recall: 0.8343 - precision: 0.9319 - val_loss: 0.9309 - val_acc: 0.6537 - val_auc: 0.6570 - val_binary_accuracy: 0.6537 - val_recall: 0.5070 - val_precision: 0.4963\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.1088 - acc: 0.9635 - auc: 0.9935 - binary_accuracy: 0.9635 - recall: 0.9242 - precision: 0.9467 - val_loss: 1.0701 - val_acc: 0.6821 - val_auc: 0.6794 - val_binary_accuracy: 0.6821 - val_recall: 0.4013 - val_precision: 0.5517\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.0668 - acc: 0.9846 - auc: 0.9985 - binary_accuracy: 0.9846 - recall: 0.9660 - precision: 0.9798 - val_loss: 1.1460 - val_acc: 0.6957 - val_auc: 0.7017 - val_binary_accuracy: 0.6957 - val_recall: 0.4178 - val_precision: 0.5795\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.0475 - acc: 0.9873 - auc: 0.9992 - binary_accuracy: 0.9873 - recall: 0.9672 - precision: 0.9882 - val_loss: 1.2157 - val_acc: 0.6782 - val_auc: 0.6876 - val_binary_accuracy: 0.6782 - val_recall: 0.5172 - val_precision: 0.5328\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.0277 - acc: 0.9960 - auc: 0.9999 - binary_accuracy: 0.9960 - recall: 0.9917 - precision: 0.9942 - val_loss: 1.2752 - val_acc: 0.6537 - val_auc: 0.6923 - val_binary_accuracy: 0.6537 - val_recall: 0.5019 - val_precision: 0.4962\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.0200 - acc: 0.9971 - auc: 1.0000 - binary_accuracy: 0.9971 - recall: 0.9923 - precision: 0.9974 - val_loss: 1.2530 - val_acc: 0.6996 - val_auc: 0.7142 - val_binary_accuracy: 0.6996 - val_recall: 0.4904 - val_precision: 0.5738\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.0137 - acc: 0.9994 - auc: 1.0000 - binary_accuracy: 0.9994 - recall: 0.9987 - precision: 0.9994 - val_loss: 1.3680 - val_acc: 0.7027 - val_auc: 0.7071 - val_binary_accuracy: 0.7027 - val_recall: 0.5070 - val_precision: 0.5768\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.0113 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall: 0.9987 - precision: 1.0000 - val_loss: 1.4306 - val_acc: 0.6799 - val_auc: 0.6953 - val_binary_accuracy: 0.6799 - val_recall: 0.5159 - val_precision: 0.5357\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.0080 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall: 0.9994 - precision: 0.9994 - val_loss: 1.4651 - val_acc: 0.6410 - val_auc: 0.7058 - val_binary_accuracy: 0.6410 - val_recall: 0.5121 - val_precision: 0.4791\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.0063 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.5767 - val_acc: 0.6813 - val_auc: 0.6926 - val_binary_accuracy: 0.6813 - val_recall: 0.4904 - val_precision: 0.5400\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.0049 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.6114 - val_acc: 0.6931 - val_auc: 0.6826 - val_binary_accuracy: 0.6931 - val_recall: 0.4866 - val_precision: 0.5618\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.0037 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall: 1.0000 - precision: 0.9994 - val_loss: 1.5918 - val_acc: 0.6515 - val_auc: 0.7093 - val_binary_accuracy: 0.6515 - val_recall: 0.5096 - val_precision: 0.4932\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.0032 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.6637 - val_acc: 0.6668 - val_auc: 0.6942 - val_binary_accuracy: 0.6668 - val_recall: 0.5248 - val_precision: 0.5150\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.0025 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.6990 - val_acc: 0.6651 - val_auc: 0.6957 - val_binary_accuracy: 0.6651 - val_recall: 0.5146 - val_precision: 0.5127\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.0022 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.6910 - val_acc: 0.6738 - val_auc: 0.6993 - val_binary_accuracy: 0.6738 - val_recall: 0.5096 - val_precision: 0.5263\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.0019 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.7624 - val_acc: 0.6996 - val_auc: 0.6890 - val_binary_accuracy: 0.6996 - val_recall: 0.5096 - val_precision: 0.5706\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.0016 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.7726 - val_acc: 0.6607 - val_auc: 0.6932 - val_binary_accuracy: 0.6607 - val_recall: 0.5223 - val_precision: 0.5062\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.0014 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.8197 - val_acc: 0.6629 - val_auc: 0.6877 - val_binary_accuracy: 0.6629 - val_recall: 0.5108 - val_precision: 0.5095\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.0013 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.8185 - val_acc: 0.6567 - val_auc: 0.6961 - val_binary_accuracy: 0.6567 - val_recall: 0.5210 - val_precision: 0.5006\n",
      "0.7600646615028381\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7a61e9f-4d8c-4c53-900f-51854c52539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4038218/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5612a979-c8b4-4f67-a208-a1904aab07a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.5208333333333334 MSE:  0.4791666666666667 UAR:  0.5357142857142857 Recall:  0.5714285714285714 Precision:  0.32 F1:  0.41025641025641024\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.5416666666666666 MSE:  0.4583333333333333 UAR:  0.5504201680672269 Recall:  0.5714285714285714 Precision:  0.3333333333333333 F1:  0.4210526315789474\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5945378151260504 Recall:  0.5714285714285714 Precision:  0.38095238095238093 F1:  0.4571428571428571\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.5588235294117647 Recall:  0.5 Precision:  0.35 F1:  0.4117647058823529\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.5588235294117647 Recall:  0.5 Precision:  0.35 F1:  0.4117647058823529\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5735294117647058 Recall:  0.5 Precision:  0.3684210526315789 F1:  0.4242424242424242\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6176470588235294 Recall:  0.5 Precision:  0.4375 F1:  0.4666666666666667\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6617647058823529 Recall:  0.5 Precision:  0.5384615384615384 F1:  0.5185185185185186\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.75 MSE:  0.25 UAR:  0.6764705882352942 Recall:  0.5 Precision:  0.5833333333333334 F1:  0.5384615384615384\n",
      "0.9 0.6764705882352942\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "825184ce-9e1f-487c-8132-3510d48458bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f3c33a2-bec6-4b21-b2df-b1b01a74f2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4038218/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac368311-0278-4fd9-a3e1-634bf2b711ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.5625 MSE:  0.4375 UAR:  0.5651260504201681 Recall:  0.5714285714285714 Precision:  0.34782608695652173 F1:  0.4324324324324324\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6176470588235294 Recall:  0.5 Precision:  0.4375 F1:  0.4666666666666667\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5903361344537815 Recall:  0.35714285714285715 Precision:  0.45454545454545453 F1:  0.4\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6134453781512605 Recall:  0.2857142857142857 Precision:  0.6666666666666666 F1:  0.4\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5777310924369747 Recall:  0.21428571428571427 Precision:  0.6 F1:  0.3157894736842105\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6071428571428571 Recall:  0.21428571428571427 Precision:  1.0 F1:  0.35294117647058826\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.5714285714285714 Recall:  0.14285714285714285 Precision:  1.0 F1:  0.25\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.5714285714285714 Recall:  0.14285714285714285 Precision:  1.0 F1:  0.25\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.2 0.6176470588235294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44e8bb0-65b3-4abe-8354-76f912f9722b",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9891e4f4-2b60-4131-8462-765765cd22a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86e5cf30-0a20-4559-bfab-9b68793a1c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f886fd1-4c63-4ef4-85bb-d51608f32b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 3840) (5449,)\n",
      "(2284, 128, 3840) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "479bce73-585c-4365-89f5-0c685dfdef77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 3840)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    3841      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29498882 (112.53 MB)\n",
      "Trainable params: 29498882 (112.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2cc2f86f-bc71-47bf-b472-cd5e2132f424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 13s 267ms/step - loss: 0.8178 - acc: 0.7937 - auc: 0.7978 - binary_accuracy: 0.7937 - recall_1: 0.6275 - precision_1: 0.6423 - val_loss: 0.9124 - val_acc: 0.7469 - val_auc: 0.6501 - val_binary_accuracy: 0.7469 - val_recall_1: 0.4089 - val_precision_1: 0.7379\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 9s 204ms/step - loss: 0.1831 - acc: 0.9378 - auc: 0.9740 - binary_accuracy: 0.9378 - recall_1: 0.8401 - precision_1: 0.9356 - val_loss: 0.9893 - val_acc: 0.6865 - val_auc: 0.6679 - val_binary_accuracy: 0.6865 - val_recall_1: 0.4255 - val_precision_1: 0.5576\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 8s 178ms/step - loss: 0.1127 - acc: 0.9642 - auc: 0.9914 - binary_accuracy: 0.9642 - recall_1: 0.9274 - precision_1: 0.9463 - val_loss: 1.2325 - val_acc: 0.6773 - val_auc: 0.6565 - val_binary_accuracy: 0.6773 - val_recall_1: 0.4408 - val_precision_1: 0.5373\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 8s 179ms/step - loss: 0.0860 - acc: 0.9721 - auc: 0.9940 - binary_accuracy: 0.9721 - recall_1: 0.9383 - precision_1: 0.9631 - val_loss: 1.2284 - val_acc: 0.6699 - val_auc: 0.6801 - val_binary_accuracy: 0.6699 - val_recall_1: 0.4573 - val_precision_1: 0.5226\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 8s 179ms/step - loss: 0.0619 - acc: 0.9807 - auc: 0.9973 - binary_accuracy: 0.9807 - recall_1: 0.9531 - precision_1: 0.9789 - val_loss: 1.3655 - val_acc: 0.6524 - val_auc: 0.6976 - val_binary_accuracy: 0.6524 - val_recall_1: 0.3796 - val_precision_1: 0.4926\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 8s 180ms/step - loss: 0.0330 - acc: 0.9916 - auc: 0.9996 - binary_accuracy: 0.9916 - recall_1: 0.9814 - precision_1: 0.9890 - val_loss: 1.7350 - val_acc: 0.6392 - val_auc: 0.6599 - val_binary_accuracy: 0.6392 - val_recall_1: 0.3083 - val_precision_1: 0.4627\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 8s 180ms/step - loss: 0.0290 - acc: 0.9921 - auc: 0.9995 - binary_accuracy: 0.9921 - recall_1: 0.9852 - precision_1: 0.9871 - val_loss: 1.5910 - val_acc: 0.6410 - val_auc: 0.6754 - val_binary_accuracy: 0.6410 - val_recall_1: 0.4268 - val_precision_1: 0.4752\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 8s 179ms/step - loss: 0.0134 - acc: 0.9978 - auc: 0.9999 - binary_accuracy: 0.9978 - recall_1: 0.9961 - precision_1: 0.9961 - val_loss: 1.7238 - val_acc: 0.6581 - val_auc: 0.6798 - val_binary_accuracy: 0.6581 - val_recall_1: 0.4433 - val_precision_1: 0.5029\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 8s 179ms/step - loss: 0.0069 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_1: 0.9987 - precision_1: 0.9987 - val_loss: 1.7973 - val_acc: 0.6633 - val_auc: 0.6734 - val_binary_accuracy: 0.6633 - val_recall_1: 0.4064 - val_precision_1: 0.5129\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 8s 178ms/step - loss: 0.0053 - acc: 0.9994 - auc: 1.0000 - binary_accuracy: 0.9994 - recall_1: 0.9994 - precision_1: 0.9987 - val_loss: 1.9653 - val_acc: 0.6436 - val_auc: 0.6577 - val_binary_accuracy: 0.6436 - val_recall_1: 0.3478 - val_precision_1: 0.4748\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 8s 180ms/step - loss: 0.0045 - acc: 0.9994 - auc: 1.0000 - binary_accuracy: 0.9994 - recall_1: 0.9987 - precision_1: 0.9994 - val_loss: 1.9237 - val_acc: 0.6410 - val_auc: 0.6698 - val_binary_accuracy: 0.6410 - val_recall_1: 0.4879 - val_precision_1: 0.4782\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 8s 179ms/step - loss: 0.0028 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 2.0181 - val_acc: 0.6480 - val_auc: 0.6636 - val_binary_accuracy: 0.6480 - val_recall_1: 0.4242 - val_precision_1: 0.4861\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 8s 180ms/step - loss: 0.0021 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 2.1345 - val_acc: 0.6489 - val_auc: 0.6517 - val_binary_accuracy: 0.6489 - val_recall_1: 0.4204 - val_precision_1: 0.4874\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 8s 180ms/step - loss: 0.0021 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 2.0908 - val_acc: 0.6506 - val_auc: 0.6605 - val_binary_accuracy: 0.6506 - val_recall_1: 0.4344 - val_precision_1: 0.4906\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 8s 179ms/step - loss: 0.0021 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 2.1434 - val_acc: 0.6449 - val_auc: 0.6576 - val_binary_accuracy: 0.6449 - val_recall_1: 0.4701 - val_precision_1: 0.4830\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 8s 180ms/step - loss: 0.0021 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_1: 1.0000 - precision_1: 0.9994 - val_loss: 2.1191 - val_acc: 0.6493 - val_auc: 0.6634 - val_binary_accuracy: 0.6493 - val_recall_1: 0.4968 - val_precision_1: 0.4899\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 8s 178ms/step - loss: 0.0011 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 2.2636 - val_acc: 0.6414 - val_auc: 0.6506 - val_binary_accuracy: 0.6414 - val_recall_1: 0.4127 - val_precision_1: 0.4751\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 8s 179ms/step - loss: 8.7256e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 2.3057 - val_acc: 0.6475 - val_auc: 0.6507 - val_binary_accuracy: 0.6475 - val_recall_1: 0.4471 - val_precision_1: 0.4861\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 8s 181ms/step - loss: 7.4486e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 2.3173 - val_acc: 0.6497 - val_auc: 0.6520 - val_binary_accuracy: 0.6497 - val_recall_1: 0.4548 - val_precision_1: 0.4897\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 8s 180ms/step - loss: 8.0688e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 2.4626 - val_acc: 0.6362 - val_auc: 0.6352 - val_binary_accuracy: 0.6362 - val_recall_1: 0.3529 - val_precision_1: 0.4617\n",
      "0.9123796224594116\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85210f6b-5a91-47ea-9e1f-84edc28d7ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4038218/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61e14c44-8aab-4e8b-8069-1859c3901f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6239495798319328 Recall:  0.5714285714285714 Precision:  0.42105263157894735 F1:  0.48484848484848486\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6029411764705883 Recall:  0.5 Precision:  0.4117647058823529 F1:  0.45161290322580644\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5315126050420168 Recall:  0.35714285714285715 Precision:  0.3333333333333333 F1:  0.3448275862068965\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5315126050420168 Recall:  0.35714285714285715 Precision:  0.3333333333333333 F1:  0.3448275862068965\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.5252100840336134 Recall:  0.2857142857142857 Precision:  0.3333333333333333 F1:  0.30769230769230765\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.5042016806722689 Recall:  0.21428571428571427 Precision:  0.3 F1:  0.25\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.51890756302521 Recall:  0.21428571428571427 Precision:  0.3333333333333333 F1:  0.2608695652173913\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.51890756302521 Recall:  0.21428571428571427 Precision:  0.3333333333333333 F1:  0.2608695652173913\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.51890756302521 Recall:  0.21428571428571427 Precision:  0.3333333333333333 F1:  0.2608695652173913\n",
      "0.1 0.6239495798319328\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d8d681ba-d645-4f6f-b977-1cd6334a2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "63036ae2-0b47-446f-8f82-20d889eba320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4038218/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5fff338-9a08-4173-8463-8a6a050b140b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.6008403361344539 Recall:  0.6428571428571429 Precision:  0.375 F1:  0.4736842105263159\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5945378151260504 Recall:  0.5714285714285714 Precision:  0.38095238095238093 F1:  0.4571428571428571\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.625 MSE:  0.375 UAR:  0.6092436974789917 Recall:  0.5714285714285714 Precision:  0.4 F1:  0.47058823529411764\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6029411764705883 Recall:  0.5 Precision:  0.4117647058823529 F1:  0.45161290322580644\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6617647058823529 Recall:  0.5 Precision:  0.5384615384615384 F1:  0.5185185185185186\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6554621848739496 Recall:  0.42857142857142855 Precision:  0.6 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6554621848739496 Recall:  0.42857142857142855 Precision:  0.6 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5777310924369747 Recall:  0.21428571428571427 Precision:  0.6 F1:  0.3157894736842105\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6071428571428571 Recall:  0.21428571428571427 Precision:  1.0 F1:  0.35294117647058826\n",
      "0.5 0.6617647058823529\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6595df78-c264-451b-9931-52eed307851c",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfeb12bf-8b02-45ad-92a2-5730229364b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ddb12f2-4747-4497-b005-3566a87bc3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43b41fd0-dec1-42d1-b7bc-6f1ddf6af8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6b9aab4-a888-43e0-9e3e-6c036c80176b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147, 2560) (147,)\n",
      "(48, 2560) (48,)\n",
      "(195, 2560) (195,)\n",
      "[0 1] [141  54]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.759)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bbf7fc54-2de1-4e92-a362-5bbc5c66e89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5ff124-2f93-4736-b8f4-baffd8ba8b17",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d0767b5-6c8a-4dc6-ac64-585091e61933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52be6759-059c-4478-8a38-bbb4c833f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a55bc299-8136-4cd7-8c58-accd61d3563a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 3840) (5631,)\n",
      "(2102, 128, 3840) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1675ffcd-d913-4120-8ce7-e50e426e089f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 07:39:08.167930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1966592   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1970946 (7.52 MB)\n",
      "Trainable params: 1970946 (7.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c4960d3-a455-410c-8949-2aa531512675",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fdfc4bcd-03e7-4bd9-9d00-be8dc5eab841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "00f9ec8a-e94d-4dc0-8e28-0d6e22c325c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6533613445378151 Recall:  0.5714285714285714 Precision:  0.47058823529411764 F1:  0.5161290322580646\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6680672268907563 Recall:  0.5714285714285714 Precision:  0.5 F1:  0.5333333333333333\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6323529411764706 Recall:  0.5 Precision:  0.4666666666666667 F1:  0.4827586206896552\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5609243697478992 Recall:  0.35714285714285715 Precision:  0.38461538461538464 F1:  0.3703703703703704\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5609243697478992 Recall:  0.35714285714285715 Precision:  0.38461538461538464 F1:  0.3703703703703704\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5903361344537815 Recall:  0.35714285714285715 Precision:  0.45454545454545453 F1:  0.4\n",
      "0.2 0.6680672268907563\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66e5e047-2190-46db-a38e-279e87ec422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    modelAtn.set_weights(best_model_weights)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3fee9185-8af6-4f28-a984-c25105680b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4c5f8e9-94e3-4fbd-8040-87049d4ad986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.6785714285714286 Recall:  0.8571428571428571 Precision:  0.41379310344827586 F1:  0.5581395348837208\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.7016806722689075 Recall:  0.7857142857142857 Precision:  0.4583333333333333 F1:  0.5789473684210527\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6449579831932774 Recall:  0.6428571428571429 Precision:  0.42857142857142855 F1:  0.5142857142857143\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6827731092436975 Recall:  0.5714285714285714 Precision:  0.5333333333333333 F1:  0.5517241379310344\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6260504201680672 Recall:  0.42857142857142855 Precision:  0.5 F1:  0.4615384615384615\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6554621848739496 Recall:  0.42857142857142855 Precision:  0.6 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6491596638655462 Recall:  0.35714285714285715 Precision:  0.7142857142857143 F1:  0.4761904761904762\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6491596638655462 Recall:  0.35714285714285715 Precision:  0.7142857142857143 F1:  0.4761904761904762\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6491596638655462 Recall:  0.35714285714285715 Precision:  0.7142857142857143 F1:  0.4761904761904762\n",
      "0.2 0.7016806722689075\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0422bf-9325-4770-abfb-fbb77298b929",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5597d72-77d6-4475-860d-145c40f9a505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb64287d-91a4-450e-b6e0-5ea4d1b26335",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea3efdce-24e1-46b1-aa49-1e1920d4df49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 3840) (5631,)\n",
      "(2102, 128, 3840) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ac112ae-6df6-4ef8-a4c0-6267e19e1fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 3840)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    3841      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29498882 (112.53 MB)\n",
      "Trainable params: 29498882 (112.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "387e145b-1fa0-412e-bd0d-bb6d119f5dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 07:39:49.605252: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x25ee422a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-30 07:39:49.605415: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-30 07:39:49.609556: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-30 07:39:49.656270: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-07-30 07:39:49.708038: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 16s 319ms/step - loss: 0.5446 - acc: 0.8439 - auc: 0.8782 - binary_accuracy: 0.8439 - recall_1: 0.7293 - precision_1: 0.7491 - val_loss: 1.0620 - val_acc: 0.5718 - val_auc: 0.6492 - val_binary_accuracy: 0.5718 - val_recall_1: 0.5780 - val_precision_1: 0.3674\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 0.1441 - acc: 0.9499 - auc: 0.9835 - binary_accuracy: 0.9499 - recall_1: 0.8910 - precision_1: 0.9406 - val_loss: 0.8972 - val_acc: 0.7350 - val_auc: 0.7195 - val_binary_accuracy: 0.7350 - val_recall_1: 0.4819 - val_precision_1: 0.5730\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.0828 - acc: 0.9705 - auc: 0.9953 - binary_accuracy: 0.9705 - recall_1: 0.9397 - precision_1: 0.9622 - val_loss: 1.0392 - val_acc: 0.6946 - val_auc: 0.7199 - val_binary_accuracy: 0.6946 - val_recall_1: 0.5480 - val_precision_1: 0.4950\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 8s 177ms/step - loss: 0.0497 - acc: 0.9860 - auc: 0.9981 - binary_accuracy: 0.9860 - recall_1: 0.9725 - precision_1: 0.9811 - val_loss: 1.2016 - val_acc: 0.6784 - val_auc: 0.6943 - val_binary_accuracy: 0.6784 - val_recall_1: 0.4315 - val_precision_1: 0.4652\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.0291 - acc: 0.9920 - auc: 0.9993 - binary_accuracy: 0.9920 - recall_1: 0.9807 - precision_1: 0.9929 - val_loss: 1.4856 - val_acc: 0.6560 - val_auc: 0.7086 - val_binary_accuracy: 0.6560 - val_recall_1: 0.6299 - val_precision_1: 0.4505\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 0.0196 - acc: 0.9956 - auc: 0.9995 - binary_accuracy: 0.9956 - recall_1: 0.9912 - precision_1: 0.9941 - val_loss: 1.4498 - val_acc: 0.6784 - val_auc: 0.6954 - val_binary_accuracy: 0.6784 - val_recall_1: 0.4992 - val_precision_1: 0.4696\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 8s 177ms/step - loss: 0.0123 - acc: 0.9977 - auc: 0.9999 - binary_accuracy: 0.9977 - recall_1: 0.9947 - precision_1: 0.9976 - val_loss: 1.5958 - val_acc: 0.6775 - val_auc: 0.6938 - val_binary_accuracy: 0.6775 - val_recall_1: 0.5370 - val_precision_1: 0.4703\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 8s 177ms/step - loss: 0.0080 - acc: 0.9991 - auc: 1.0000 - binary_accuracy: 0.9991 - recall_1: 0.9977 - precision_1: 0.9994 - val_loss: 1.6810 - val_acc: 0.6646 - val_auc: 0.6974 - val_binary_accuracy: 0.6646 - val_recall_1: 0.4913 - val_precision_1: 0.4496\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 0.0061 - acc: 0.9991 - auc: 1.0000 - binary_accuracy: 0.9991 - recall_1: 0.9977 - precision_1: 0.9994 - val_loss: 1.7859 - val_acc: 0.6456 - val_auc: 0.6914 - val_binary_accuracy: 0.6456 - val_recall_1: 0.4646 - val_precision_1: 0.4214\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 0.0267 - acc: 0.9909 - auc: 0.9992 - binary_accuracy: 0.9909 - recall_1: 0.9836 - precision_1: 0.9865 - val_loss: 2.1652 - val_acc: 0.6494 - val_auc: 0.6601 - val_binary_accuracy: 0.6494 - val_recall_1: 0.5165 - val_precision_1: 0.4327\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 0.0102 - acc: 0.9980 - auc: 0.9997 - binary_accuracy: 0.9980 - recall_1: 0.9959 - precision_1: 0.9977 - val_loss: 2.2432 - val_acc: 0.6213 - val_auc: 0.6454 - val_binary_accuracy: 0.6213 - val_recall_1: 0.4457 - val_precision_1: 0.3893\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 0.0073 - acc: 0.9984 - auc: 1.0000 - binary_accuracy: 0.9984 - recall_1: 0.9971 - precision_1: 0.9977 - val_loss: 2.3628 - val_acc: 0.6618 - val_auc: 0.6691 - val_binary_accuracy: 0.6618 - val_recall_1: 0.5669 - val_precision_1: 0.4523\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 0.0025 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_1: 0.9994 - precision_1: 1.0000 - val_loss: 2.3211 - val_acc: 0.6189 - val_auc: 0.6636 - val_binary_accuracy: 0.6189 - val_recall_1: 0.4126 - val_precision_1: 0.3797\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.0569 - acc: 0.9837 - auc: 0.9965 - binary_accuracy: 0.9837 - recall_1: 0.9742 - precision_1: 0.9719 - val_loss: 2.8214 - val_acc: 0.6508 - val_auc: 0.6909 - val_binary_accuracy: 0.6508 - val_recall_1: 0.5323 - val_precision_1: 0.4361\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.0086 - acc: 0.9979 - auc: 0.9997 - binary_accuracy: 0.9979 - recall_1: 0.9965 - precision_1: 0.9965 - val_loss: 2.7515 - val_acc: 0.6475 - val_auc: 0.6854 - val_binary_accuracy: 0.6475 - val_recall_1: 0.5276 - val_precision_1: 0.4317\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 0.0051 - acc: 0.9984 - auc: 1.0000 - binary_accuracy: 0.9984 - recall_1: 0.9977 - precision_1: 0.9971 - val_loss: 2.6271 - val_acc: 0.6832 - val_auc: 0.6880 - val_binary_accuracy: 0.6832 - val_recall_1: 0.4378 - val_precision_1: 0.4736\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 0.0028 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_1: 0.9994 - precision_1: 0.9994 - val_loss: 2.6400 - val_acc: 0.6675 - val_auc: 0.6912 - val_binary_accuracy: 0.6675 - val_recall_1: 0.4693 - val_precision_1: 0.4515\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 8s 177ms/step - loss: 8.9276e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 2.6399 - val_acc: 0.6618 - val_auc: 0.6955 - val_binary_accuracy: 0.6618 - val_recall_1: 0.4756 - val_precision_1: 0.4441\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 9s 205ms/step - loss: 5.7489e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 2.6688 - val_acc: 0.6698 - val_auc: 0.6912 - val_binary_accuracy: 0.6698 - val_recall_1: 0.4614 - val_precision_1: 0.4543\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 5.0782e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 2.6800 - val_acc: 0.6717 - val_auc: 0.6903 - val_binary_accuracy: 0.6717 - val_recall_1: 0.4488 - val_precision_1: 0.4560\n",
      "0.897188127040863\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7658dcd9-5206-4385-8576-d3b825f190f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "58be0e57-d1da-425b-9e8f-d526cf83b7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6596638655462186 Recall:  0.6428571428571429 Precision:  0.45 F1:  0.5294117647058824\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6386554621848739 Recall:  0.5714285714285714 Precision:  0.4444444444444444 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6533613445378151 Recall:  0.5714285714285714 Precision:  0.47058823529411764 F1:  0.5161290322580646\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6533613445378151 Recall:  0.5714285714285714 Precision:  0.47058823529411764 F1:  0.5161290322580646\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6533613445378151 Recall:  0.5714285714285714 Precision:  0.47058823529411764 F1:  0.5161290322580646\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6533613445378151 Recall:  0.5714285714285714 Precision:  0.47058823529411764 F1:  0.5161290322580646\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6176470588235294 Recall:  0.5 Precision:  0.4375 F1:  0.4666666666666667\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5819327731092437 Recall:  0.42857142857142855 Precision:  0.4 F1:  0.4137931034482759\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5819327731092437 Recall:  0.42857142857142855 Precision:  0.4 F1:  0.4137931034482759\n",
      "0.1 0.6596638655462186\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f162f19-90b9-4bfa-87c8-f6f9402a86b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    modelAtn.set_weights(best_model_weights)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2bc978df-734b-4c11-a362-86e05ae20a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b65dda6c-8539-4e7d-a1d7-a3540985a9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.625 MSE:  0.375 UAR:  0.6302521008403361 Recall:  0.6428571428571429 Precision:  0.4090909090909091 F1:  0.5000000000000001\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.625 MSE:  0.375 UAR:  0.6092436974789917 Recall:  0.5714285714285714 Precision:  0.4 F1:  0.47058823529411764\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6386554621848739 Recall:  0.5714285714285714 Precision:  0.4444444444444444 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6680672268907563 Recall:  0.5714285714285714 Precision:  0.5 F1:  0.5333333333333333\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6323529411764706 Recall:  0.5 Precision:  0.4666666666666667 F1:  0.4827586206896552\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6554621848739496 Recall:  0.42857142857142855 Precision:  0.6 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6554621848739496 Recall:  0.42857142857142855 Precision:  0.6 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.592436974789916 Recall:  0.21428571428571427 Precision:  0.75 F1:  0.3333333333333333\n",
      "0.4 0.6680672268907563\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7a9bbe-8439-4a4e-95ee-7eed003c7434",
   "metadata": {},
   "source": [
    "## MobileNet_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06db56e2-b51d-45c2-8e41-ef166bb7b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_key = 'mobilenet_7.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32be9f26-061d-4bd7-9362-979c1c2031b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['engaged', 'distracted']\n",
      "{'subject_1_Vid_1': 0, 'subject_1_Vid_2': 0, 'subject_1_Vid_3': 0, 'subject_1_Vid_4': 0, 'subject_1_Vid_5': 0, 'subject_31_Vid_6': 0, 'subject_2_Vid_6': 1, 'subject_3_Vid_6': 0, 'subject_3_Vid_1': 1, 'subject_3_Vid_2': 1, 'subject_3_Vid_3': 0, 'subject_3_Vid_4': 0, 'subject_3_Vid_5': 1, 'subject_3_Vid_7': 0, 'subject_4_Vid_6': 0, 'subject_5_Vid_6': 0, 'subject_6_Vid_6': 1, 'subject_7_Vid_1': 0, 'subject_7_Vid_2': 0, 'subject_7_Vid_3': 0, 'subject_7_Vid_4': 0, 'subject_7_Vid_5': 1, 'subject_8_Vid_6': 0, 'subject_9_Vid_6': 1, 'subject_10_Vid_6': 0, 'subject_11_Vid_6': 0, 'subject_12_Vid_6': 1, 'subject_13_Vid_6': 0, 'subject_14_Vid_6': 0, 'subject_15_Vid_6': 0, 'subject_16_Vid_6': 1, 'subject_17_Vid_6': 0, 'subject_18_Vid_6': 1, 'subject_19_Vid_6': 0, 'subject_20_Vid_6': 0, 'subject_20_Vid_1': 0, 'subject_20_Vid_2': 0, 'subject_20_Vid_3': 0, 'subject_20_Vid_4': 1, 'subject_20_Vid_5': 0, 'subject_20_Vid_5_1': 0, 'subject_20_Vid_5_2': 0, 'subject_20_Vid_7': 1, 'subject_21_Vid_5': 1, 'subject_22_Vid_5': 0, 'subject_23_Vid_5': 1, 'subject_24_Vid_5': 0, 'subject_25_Vid_5': 0, 'subject_26_Vid_1': 0, 'subject_26_Vid_2': 0, 'subject_26_Vid_3': 1, 'subject_26_Vid_4': 0, 'subject_26_Vid_5': 1, 'subject_26_Vid_5_1': 0, 'subject_26_Vid_5_2': 0, 'subject_26_Vid_7': 1, 'subject_27_Vid_1': 0, 'subject_29_Vid_6': 0, 'subject_29_Vid_7': 1, 'subject_30_Vid_1': 1, 'subject_30_Vid_2': 0, 'subject_30_Vid_3': 0, 'subject_30_Vid_4': 0, 'subject_30_Vid_5': 1, 'subject_32_Vid_6': 0, 'subject_32_Vid_1': 0, 'subject_32_Vid_2': 0, 'subject_32_Vid_3': 0, 'subject_32_Vid_4': 0, 'subject_32_Vid_5': 0, 'subject_32_Vid_7': 1, 'subject_33_Vid_1': 1, 'subject_33_Vid_2': 0, 'subject_33_Vid_3': 0, 'subject_33_Vid_4': 0, 'subject_33_Vid_7': 0, 'subject_34_Vid_7': 0, 'subject_34_Vid_1': 0, 'subject_34_Vid_5': 0, 'subject_35_Vid_6': 1, 'subject_35_Vid_7': 0, 'subject_36_Vid_7': 0, 'subject_37_Vid_7': 0, 'subject_38_Vid_7': 0, 'subject_39_Vid_6': 0, 'subject_39_Vid_7': 1, 'subject_40_Vid_6': 0, 'subject_40_Vid_7': 1, 'subject_41_Vid_6': 0, 'subject_41_Vid_2': 1, 'subject_41_Vid_3': 0, 'subject_41_Vid_4': 1, 'subject_41_Vid_5': 1, 'subject_41_Vid_5_1': 0, 'subject_41_Vid_5_2': 1, 'subject_41_Vid_7': 0, 'subject_42_Vid_7': 0, 'subject_43_Vid_7': 0, 'subject_44_Vid_7': 1, 'subject_45_Vid_7': 1, 'subject_46_Vid_6': 0, 'subject_47_Vid_6': 0, 'subject_48_Vid_6': 0, 'subject_48_Vid_7': 0, 'subject_49_Vid_7': 0, 'subject_50_Vid_6': 0, 'subject_50_Vid_1': 0, 'subject_50_Vid_2': 1, 'subject_50_Vid_3': 1, 'subject_50_Vid_4': 1, 'subject_50_Vid_5': 1, 'subject_51_Vid_7': 0, 'subject_52_Vid_7': 1, 'subject_53_Vid_2': 0, 'subject_53_Vid_3': 0, 'subject_53_Vid_4': 0, 'subject_53_Vid_5': 0, 'subject_54_Vid_6': 0, 'subject_55_Vid_6': 0, 'subject_56_Vid_6': 0, 'subject_56_Vid_1': 0, 'subject_56_Vid_2': 0, 'subject_56_Vid_3': 0, 'subject_56_Vid_4': 0, 'subject_56_Vid_5': 0, 'subject_57_Vid_7': 0, 'subject_58_Vid_6': 0, 'subject_58_Vid_7': 0, 'subject_59_Vid_7': 0, 'subject_60_Vid_6': 0, 'subject_60_Vid_7': 0, 'subject_62_Vid_6': 0, 'subject_62_Vid_1': 0, 'subject_62_Vid_2': 0, 'subject_62_Vid_3': 1, 'subject_62_Vid_4': 0, 'subject_62_Vid_5': 0, 'subject_62_Vid_7': 0, 'subject_63_Vid_7': 1, 'subject_64_Vid_6': 0, 'subject_64_Vid_7': 1, 'subject_65_Vid_6': 0, 'subject_66_Vid_6': 0, 'subject_66_Vid_7': 1, 'subject_67_Vid_6': 0, 'subject_67_Vid_1': 0, 'subject_67_Vid_2': 0, 'subject_67_Vid_4': 0, 'subject_67_Vid_5': 0, 'subject_68_Vid_6': 0, 'subject_68_Vid_7': 1, 'subject_69_Vid_6': 0, 'subject_69_Vid_7': 0, 'subject_70_Vid_6': 0, 'subject_70_Vid_1': 0, 'subject_70_Vid_2': 0, 'subject_70_Vid_3': 0, 'subject_70_Vid_4': 0, 'subject_70_Vid_5': 1, 'subject_72_Vid_6': 0, 'subject_73_Vid_6': 0, 'subject_73_Vid_7': 0, 'subject_74_Vid_7': 1, 'subject_75_Vid_7': 0, 'subject_76_Vid_6': 0, 'subject_76_Vid_7': 0, 'subject_77_Vid_6': 0, 'subject_77_Vid_1': 1, 'subject_77_Vid_2': 1, 'subject_77_Vid_3': 0, 'subject_77_Vid_4': 0, 'subject_77_Vid_5': 1, 'subject_78_Vid_6': 0, 'subject_79_Vid_7': 0, 'subject_80_Vid_6': 0, 'subject_80_Vid_1': 0, 'subject_80_Vid_2': 0, 'subject_80_Vid_3': 0, 'subject_80_Vid_4': 0, 'subject_80_Vid_5': 0, 'subject_81_Vid_7': 1, 'subject_82_Vid_7': 0, 'subject_83_Vid_7': 0, 'subject_84_Vid_6': 1, 'subject_84_Vid_1': 1, 'subject_84_Vid_2': 1, 'subject_84_Vid_3': 1, 'subject_84_Vid_4': 1, 'subject_84_Vid_5': 1, 'subject_85_Vid_7': 0, 'subject_86_Vid_7': 0, 'subject_77_Vid_7': 1, 'subject_34_Vid_2': 0, 'subject_34_Vid_3': 0, 'subject_34_Vid_4': 0, 'subject_87_Vid_3': 0}\n"
     ]
    }
   ],
   "source": [
    "ENGAGE_WILD_DATASET, BIN_CLASSIFICATION, N_CLASSES, DATASET_NAME, BASE_DATASET_DIR, ext = define_dataset(True, True)\n",
    "video2label, labels_list = get_video2label()\n",
    "print(labels_list)\n",
    "print(video2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4379ba-9bc6-4fbf-a5eb-909fafe465b7",
   "metadata": {},
   "source": [
    "### Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ec98c271-18aa-493e-acba-1461f0d91f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.std\n",
    "stat_name = \"std\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c604817-a029-42ba-83e5-1f57e824fa5a",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e632b343-0911-4b9a-8827-88944f3688be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "22f3452a-84e1-4ad5-827c-d30826a29df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bdafdc6c-6e48-449f-a848-05e701668789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5db959-16e4-43ba-ac0b-e01e6b6429b5",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f0c08d0-b7ce-43c3-ae5d-80b6d595b8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_std_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "605490db-686f-428a-b3ad-e4c5ed0257ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "da850ae6-fa37-4b2a-82e3-0e82d87cf51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2048) (5449,)\n",
      "(2284, 128, 2048) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "537e618f-b6e4-462a-b769-228b1270d613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9c0628a2-9caf-4a6c-ba66-16048437d065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 88ms/step - loss: 0.4456 - acc: 0.8064 - auc: 0.8214 - binary_accuracy: 0.8064 - recall_2: 0.4817 - precision_2: 0.7515 - val_loss: 0.6893 - val_acc: 0.6475 - val_auc: 0.6929 - val_binary_accuracy: 0.6475 - val_recall_2: 0.2701 - val_precision_2: 0.4775\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.2183 - acc: 0.9169 - auc: 0.9671 - binary_accuracy: 0.9169 - recall_2: 0.8112 - precision_2: 0.8882 - val_loss: 0.8184 - val_acc: 0.6690 - val_auc: 0.6946 - val_binary_accuracy: 0.6690 - val_recall_2: 0.1427 - val_precision_2: 0.5744\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.1261 - acc: 0.9552 - auc: 0.9915 - binary_accuracy: 0.9552 - recall_2: 0.8844 - precision_2: 0.9556 - val_loss: 0.7918 - val_acc: 0.6957 - val_auc: 0.7102 - val_binary_accuracy: 0.6957 - val_recall_2: 0.3376 - val_precision_2: 0.6023\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.0837 - acc: 0.9727 - auc: 0.9968 - binary_accuracy: 0.9727 - recall_2: 0.9416 - precision_2: 0.9619 - val_loss: 1.1134 - val_acc: 0.6957 - val_auc: 0.6675 - val_binary_accuracy: 0.6957 - val_recall_2: 0.2242 - val_precision_2: 0.6718\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0565 - acc: 0.9839 - auc: 0.9989 - binary_accuracy: 0.9839 - recall_2: 0.9576 - precision_2: 0.9855 - val_loss: 1.0597 - val_acc: 0.6708 - val_auc: 0.6795 - val_binary_accuracy: 0.6708 - val_recall_2: 0.5096 - val_precision_2: 0.5215\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.0375 - acc: 0.9943 - auc: 0.9998 - binary_accuracy: 0.9943 - recall_2: 0.9839 - precision_2: 0.9961 - val_loss: 1.2594 - val_acc: 0.6581 - val_auc: 0.6595 - val_binary_accuracy: 0.6581 - val_recall_2: 0.2968 - val_precision_2: 0.5043\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.0251 - acc: 0.9972 - auc: 1.0000 - binary_accuracy: 0.9972 - recall_2: 0.9917 - precision_2: 0.9987 - val_loss: 1.3066 - val_acc: 0.6436 - val_auc: 0.6514 - val_binary_accuracy: 0.6436 - val_recall_2: 0.4127 - val_precision_2: 0.4786\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.0175 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_2: 0.9981 - precision_2: 0.9994 - val_loss: 1.4270 - val_acc: 0.6283 - val_auc: 0.6369 - val_binary_accuracy: 0.6283 - val_recall_2: 0.3643 - val_precision_2: 0.4497\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0141 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_2: 0.9994 - precision_2: 1.0000 - val_loss: 1.4597 - val_acc: 0.6327 - val_auc: 0.6308 - val_binary_accuracy: 0.6327 - val_recall_2: 0.4369 - val_precision_2: 0.4635\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0098 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.5394 - val_acc: 0.6327 - val_auc: 0.6262 - val_binary_accuracy: 0.6327 - val_recall_2: 0.4471 - val_precision_2: 0.4643\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0078 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.6954 - val_acc: 0.6151 - val_auc: 0.6153 - val_binary_accuracy: 0.6151 - val_recall_2: 0.2637 - val_precision_2: 0.4075\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.0064 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.6745 - val_acc: 0.6252 - val_auc: 0.6187 - val_binary_accuracy: 0.6252 - val_recall_2: 0.4191 - val_precision_2: 0.4513\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0052 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.7435 - val_acc: 0.6178 - val_auc: 0.6121 - val_binary_accuracy: 0.6178 - val_recall_2: 0.3924 - val_precision_2: 0.4375\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0039 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.7891 - val_acc: 0.6138 - val_auc: 0.6114 - val_binary_accuracy: 0.6138 - val_recall_2: 0.3745 - val_precision_2: 0.4292\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0031 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.8460 - val_acc: 0.6020 - val_auc: 0.6067 - val_binary_accuracy: 0.6020 - val_recall_2: 0.3325 - val_precision_2: 0.4040\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0026 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.8635 - val_acc: 0.5963 - val_auc: 0.6012 - val_binary_accuracy: 0.5963 - val_recall_2: 0.3312 - val_precision_2: 0.3957\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0023 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.9298 - val_acc: 0.5968 - val_auc: 0.6010 - val_binary_accuracy: 0.5968 - val_recall_2: 0.3363 - val_precision_2: 0.3976\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0020 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.9610 - val_acc: 0.5937 - val_auc: 0.6001 - val_binary_accuracy: 0.5937 - val_recall_2: 0.3439 - val_precision_2: 0.3953\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.0018 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.0488 - val_acc: 0.5898 - val_auc: 0.5935 - val_binary_accuracy: 0.5898 - val_recall_2: 0.2917 - val_precision_2: 0.3754\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0017 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.0560 - val_acc: 0.5898 - val_auc: 0.5950 - val_binary_accuracy: 0.5898 - val_recall_2: 0.3159 - val_precision_2: 0.3827\n",
      "0.6893184185028076\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8653a050-0bc7-43bf-afea-c8aacc51f1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4e720122-1dd2-4b53-bc88-28b05003c8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional Accuracy:  0.5416666666666666 MSE:  0.4583333333333333 UAR:  0.5084033613445378 Recall:  0.42857142857142855 Precision:  0.3 F1:  0.3529411764705882\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.5672268907563025 Recall:  0.42857142857142855 Precision:  0.375 F1:  0.39999999999999997\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5315126050420168 Recall:  0.35714285714285715 Precision:  0.3333333333333333 F1:  0.3448275862068965\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5315126050420168 Recall:  0.35714285714285715 Precision:  0.3333333333333333 F1:  0.3448275862068965\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5105042016806722 Recall:  0.2857142857142857 Precision:  0.3076923076923077 F1:  0.29629629629629634\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5105042016806722 Recall:  0.2857142857142857 Precision:  0.3076923076923077 F1:  0.29629629629629634\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5399159663865546 Recall:  0.2857142857142857 Precision:  0.36363636363636365 F1:  0.32\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.51890756302521 Recall:  0.21428571428571427 Precision:  0.3333333333333333 F1:  0.2608695652173913\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5273109243697479 Recall:  0.14285714285714285 Precision:  0.4 F1:  0.21052631578947364\n",
      "0.2 0.5672268907563025\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cb95f85b-4cd4-417a-b3be-fe67e86e35f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fc2d6fc5-38f3-4a1b-b8d9-206b554a9b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "72c7240d-0830-41f1-b48c-6d0f08667ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.4791666666666667 MSE:  0.5208333333333334 UAR:  0.5903361344537815 Recall:  0.8571428571428571 Precision:  0.34285714285714286 F1:  0.4897959183673469\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.7247899159663866 Recall:  0.7142857142857143 Precision:  0.5263157894736842 F1:  0.6060606060606061\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6554621848739496 Recall:  0.42857142857142855 Precision:  0.6 F1:  0.5\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5630252100840336 Recall:  0.21428571428571427 Precision:  0.5 F1:  0.3\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.49159663865546216 Recall:  0.07142857142857142 Precision:  0.25 F1:  0.11111111111111112\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5063025210084033 Recall:  0.07142857142857142 Precision:  0.3333333333333333 F1:  0.11764705882352941\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5210084033613446 Recall:  0.07142857142857142 Precision:  0.5 F1:  0.125\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.2 0.7247899159663866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f83970-d331-4bb4-8c13-e8bf8e32d8c5",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "773e12f1-cb18-4996-905f-c80405c49d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_std_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "df0996e0-0709-4cb8-a908-3e1b2dfe5642",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "57095026-0b27-4d5f-8ba8-e1a5ff0cbe14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2048) (5449,)\n",
      "(2284, 128, 2048) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ebb813bf-d6a9-4d92-a28b-befb86b3948e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bfedf4f5-dceb-4047-bac6-711c36949547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 137ms/step - loss: 0.5493 - acc: 0.7932 - auc: 0.7957 - binary_accuracy: 0.7932 - recall_3: 0.5549 - precision_3: 0.6656 - val_loss: 0.6722 - val_acc: 0.6848 - val_auc: 0.6613 - val_binary_accuracy: 0.6848 - val_recall_3: 0.4255 - val_precision_3: 0.5539\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.2095 - acc: 0.9286 - auc: 0.9708 - binary_accuracy: 0.9286 - recall_3: 0.8420 - precision_3: 0.9017 - val_loss: 0.7188 - val_acc: 0.7097 - val_auc: 0.6857 - val_binary_accuracy: 0.7097 - val_recall_3: 0.3465 - val_precision_3: 0.6445\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.1524 - acc: 0.9435 - auc: 0.9828 - binary_accuracy: 0.9435 - recall_3: 0.8741 - precision_3: 0.9240 - val_loss: 0.7936 - val_acc: 0.6515 - val_auc: 0.6645 - val_binary_accuracy: 0.6515 - val_recall_3: 0.4229 - val_precision_3: 0.4919\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0990 - acc: 0.9670 - auc: 0.9944 - binary_accuracy: 0.9670 - recall_3: 0.9229 - precision_3: 0.9599 - val_loss: 0.7759 - val_acc: 0.6541 - val_auc: 0.7028 - val_binary_accuracy: 0.6541 - val_recall_3: 0.5414 - val_precision_3: 0.4971\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0678 - acc: 0.9791 - auc: 0.9975 - binary_accuracy: 0.9791 - recall_3: 0.9531 - precision_3: 0.9731 - val_loss: 0.8344 - val_acc: 0.6331 - val_auc: 0.7045 - val_binary_accuracy: 0.6331 - val_recall_3: 0.4803 - val_precision_3: 0.4672\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0478 - acc: 0.9864 - auc: 0.9990 - binary_accuracy: 0.9864 - recall_3: 0.9711 - precision_3: 0.9812 - val_loss: 1.0916 - val_acc: 0.6173 - val_auc: 0.6458 - val_binary_accuracy: 0.6173 - val_recall_3: 0.4752 - val_precision_3: 0.4467\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0327 - acc: 0.9921 - auc: 0.9993 - binary_accuracy: 0.9921 - recall_3: 0.9801 - precision_3: 0.9922 - val_loss: 1.1268 - val_acc: 0.6677 - val_auc: 0.6431 - val_binary_accuracy: 0.6677 - val_recall_3: 0.4038 - val_precision_3: 0.5214\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0218 - acc: 0.9963 - auc: 0.9999 - binary_accuracy: 0.9963 - recall_3: 0.9929 - precision_3: 0.9942 - val_loss: 1.2154 - val_acc: 0.6528 - val_auc: 0.6319 - val_binary_accuracy: 0.6528 - val_recall_3: 0.3898 - val_precision_3: 0.4935\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0136 - acc: 0.9980 - auc: 1.0000 - binary_accuracy: 0.9980 - recall_3: 0.9968 - precision_3: 0.9961 - val_loss: 1.2538 - val_acc: 0.6427 - val_auc: 0.6367 - val_binary_accuracy: 0.6427 - val_recall_3: 0.4573 - val_precision_3: 0.4793\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0118 - acc: 0.9980 - auc: 1.0000 - binary_accuracy: 0.9980 - recall_3: 0.9968 - precision_3: 0.9961 - val_loss: 1.2100 - val_acc: 0.6528 - val_auc: 0.6605 - val_binary_accuracy: 0.6528 - val_recall_3: 0.4854 - val_precision_3: 0.4948\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0100 - acc: 0.9987 - auc: 1.0000 - binary_accuracy: 0.9987 - recall_3: 0.9974 - precision_3: 0.9981 - val_loss: 1.3990 - val_acc: 0.6808 - val_auc: 0.6348 - val_binary_accuracy: 0.6808 - val_recall_3: 0.4051 - val_precision_3: 0.5483\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0087 - acc: 0.9983 - auc: 1.0000 - binary_accuracy: 0.9983 - recall_3: 0.9968 - precision_3: 0.9974 - val_loss: 1.4049 - val_acc: 0.6537 - val_auc: 0.6364 - val_binary_accuracy: 0.6537 - val_recall_3: 0.4446 - val_precision_3: 0.4957\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0050 - acc: 0.9994 - auc: 1.0000 - binary_accuracy: 0.9994 - recall_3: 1.0000 - precision_3: 0.9981 - val_loss: 1.4246 - val_acc: 0.6147 - val_auc: 0.6408 - val_binary_accuracy: 0.6147 - val_recall_3: 0.5261 - val_precision_3: 0.4484\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0054 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_3: 0.9994 - precision_3: 1.0000 - val_loss: 1.4936 - val_acc: 0.6694 - val_auc: 0.6407 - val_binary_accuracy: 0.6694 - val_recall_3: 0.4471 - val_precision_3: 0.5223\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0104 - acc: 0.9976 - auc: 1.0000 - binary_accuracy: 0.9976 - recall_3: 0.9961 - precision_3: 0.9955 - val_loss: 1.5697 - val_acc: 0.6546 - val_auc: 0.6327 - val_binary_accuracy: 0.6546 - val_recall_3: 0.4892 - val_precision_3: 0.4974\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0110 - acc: 0.9952 - auc: 0.9999 - binary_accuracy: 0.9952 - recall_3: 0.9910 - precision_3: 0.9923 - val_loss: 1.7352 - val_acc: 0.6791 - val_auc: 0.6461 - val_binary_accuracy: 0.6791 - val_recall_3: 0.3796 - val_precision_3: 0.5478\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0054 - acc: 0.9991 - auc: 1.0000 - binary_accuracy: 0.9991 - recall_3: 0.9987 - precision_3: 0.9981 - val_loss: 1.5921 - val_acc: 0.6703 - val_auc: 0.6503 - val_binary_accuracy: 0.6703 - val_recall_3: 0.4280 - val_precision_3: 0.5250\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0043 - acc: 0.9991 - auc: 1.0000 - binary_accuracy: 0.9991 - recall_3: 0.9974 - precision_3: 0.9994 - val_loss: 1.7323 - val_acc: 0.6559 - val_auc: 0.6310 - val_binary_accuracy: 0.6559 - val_recall_3: 0.4140 - val_precision_3: 0.4992\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0013 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 1.7658 - val_acc: 0.6594 - val_auc: 0.6242 - val_binary_accuracy: 0.6594 - val_recall_3: 0.4268 - val_precision_3: 0.5053\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 9.1206e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 1.7790 - val_acc: 0.6585 - val_auc: 0.6302 - val_binary_accuracy: 0.6585 - val_recall_3: 0.4561 - val_precision_3: 0.5035\n",
      "0.6722456812858582\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "702ae742-1b78-4342-b1e7-52669e4a74b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fce99a5b-0bb5-45e7-8d25-91a21daa8d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.6365546218487395 Recall:  0.7142857142857143 Precision:  0.4 F1:  0.5128205128205129\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.6512605042016807 Recall:  0.7142857142857143 Precision:  0.4166666666666667 F1:  0.5263157894736842\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6596638655462186 Recall:  0.6428571428571429 Precision:  0.45 F1:  0.5294117647058824\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6239495798319328 Recall:  0.5714285714285714 Precision:  0.42105263157894735 F1:  0.48484848484848486\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6239495798319328 Recall:  0.5714285714285714 Precision:  0.42105263157894735 F1:  0.48484848484848486\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6533613445378151 Recall:  0.5714285714285714 Precision:  0.47058823529411764 F1:  0.5161290322580646\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6176470588235294 Recall:  0.5 Precision:  0.4375 F1:  0.4666666666666667\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6176470588235294 Recall:  0.5 Precision:  0.4375 F1:  0.4666666666666667\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6323529411764706 Recall:  0.5 Precision:  0.4666666666666667 F1:  0.4827586206896552\n",
      "0.3 0.6596638655462186\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7bfc9ac6-8615-4363-9d44-e02d9ef8081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b719d35e-7c8a-4964-a311-a3ea24e2a1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d71ff922-921b-4aa1-9a3f-c648df9e63a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.375 MSE:  0.625 UAR:  0.5378151260504201 Recall:  0.9285714285714286 Precision:  0.30952380952380953 F1:  0.46428571428571436\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.5 MSE:  0.5 UAR:  0.6260504201680672 Recall:  0.9285714285714286 Precision:  0.3611111111111111 F1:  0.52\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.5416666666666666 MSE:  0.4583333333333333 UAR:  0.6554621848739496 Recall:  0.9285714285714286 Precision:  0.38235294117647056 F1:  0.5416666666666667\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.7584033613445378 Recall:  0.9285714285714286 Precision:  0.48148148148148145 F1:  0.6341463414634146\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.7100840336134454 Recall:  0.7142857142857143 Precision:  0.5 F1:  0.588235294117647\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.569327731092437 Recall:  0.2857142857142857 Precision:  0.4444444444444444 F1:  0.34782608695652173\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.542016806722689 Recall:  0.14285714285714285 Precision:  0.5 F1:  0.22222222222222224\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.5714285714285714 Recall:  0.14285714285714285 Precision:  1.0 F1:  0.25\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5357142857142857 Recall:  0.07142857142857142 Precision:  1.0 F1:  0.13333333333333333\n",
      "0.4 0.7584033613445378\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f656968c-eb67-459d-bff3-9e0a511fca62",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a69355e0-28c9-4082-8f19-c44dfa8bb30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "17e3f1be-5a1c-4ec1-bcef-f251c4259e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "58944233-29d4-4646-a767-03bbf3738b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "52c767ac-0bdc-4ffa-8ced-23183568075c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147,) (147,)\n",
      "(48,) (48,)\n",
      "(195,) (195,)\n",
      "[0 1] [141  54]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.759)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ef05bda7-a42f-42f3-94e7-35535bcdfc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036cbc86-ba85-4e33-9dca-40c7604331c4",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eba90268-6dce-4a4d-8e97-02e1018cb2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_std_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b0e74705-c9df-4fa3-806e-2b956b1922fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "081a003b-c7e0-451b-9d46-0aacbab9f323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 2048) (5631,)\n",
      "(2102, 128, 2048) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0d5e7802-2d68-4435-8fdd-423f05b65e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "82910270-3350-4056-a878-f4416e47ced3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44/44 [==============================] - 4s 61ms/step - loss: 0.3941 - acc: 0.8283 - auc: 0.8757 - binary_accuracy: 0.8283 - recall_4: 0.5595 - precision_4: 0.8162 - val_loss: 0.6503 - val_acc: 0.7174 - val_auc: 0.6976 - val_binary_accuracy: 0.7174 - val_recall_4: 0.5465 - val_precision_4: 0.5314\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1789 - acc: 0.9357 - auc: 0.9808 - binary_accuracy: 0.9357 - recall_4: 0.8535 - precision_4: 0.9286 - val_loss: 0.8561 - val_acc: 0.6422 - val_auc: 0.6693 - val_binary_accuracy: 0.6422 - val_recall_4: 0.5449 - val_precision_4: 0.4277\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.0990 - acc: 0.9663 - auc: 0.9958 - binary_accuracy: 0.9663 - recall_4: 0.9080 - precision_4: 0.9792 - val_loss: 0.9587 - val_acc: 0.6584 - val_auc: 0.6736 - val_binary_accuracy: 0.6584 - val_recall_4: 0.4945 - val_precision_4: 0.4416\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0633 - acc: 0.9845 - auc: 0.9987 - binary_accuracy: 0.9845 - recall_4: 0.9584 - precision_4: 0.9903 - val_loss: 1.0479 - val_acc: 0.6974 - val_auc: 0.6797 - val_binary_accuracy: 0.6974 - val_recall_4: 0.3969 - val_precision_4: 0.4990\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0416 - acc: 0.9906 - auc: 0.9998 - binary_accuracy: 0.9906 - recall_4: 0.9777 - precision_4: 0.9911 - val_loss: 1.2626 - val_acc: 0.7103 - val_auc: 0.6602 - val_binary_accuracy: 0.7103 - val_recall_4: 0.3638 - val_precision_4: 0.5298\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0310 - acc: 0.9940 - auc: 0.9999 - binary_accuracy: 0.9940 - recall_4: 0.9859 - precision_4: 0.9941 - val_loss: 1.2527 - val_acc: 0.7079 - val_auc: 0.6749 - val_binary_accuracy: 0.7079 - val_recall_4: 0.3701 - val_precision_4: 0.5234\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0211 - acc: 0.9972 - auc: 1.0000 - binary_accuracy: 0.9972 - recall_4: 0.9947 - precision_4: 0.9959 - val_loss: 1.3511 - val_acc: 0.7031 - val_auc: 0.6725 - val_binary_accuracy: 0.7031 - val_recall_4: 0.3969 - val_precision_4: 0.5112\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0153 - acc: 0.9986 - auc: 1.0000 - binary_accuracy: 0.9986 - recall_4: 0.9977 - precision_4: 0.9977 - val_loss: 1.4308 - val_acc: 0.7046 - val_auc: 0.6692 - val_binary_accuracy: 0.7046 - val_recall_4: 0.3701 - val_precision_4: 0.5154\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0112 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_4: 0.9988 - precision_4: 0.9988 - val_loss: 1.5544 - val_acc: 0.7098 - val_auc: 0.6693 - val_binary_accuracy: 0.7098 - val_recall_4: 0.3685 - val_precision_4: 0.5282\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0088 - acc: 0.9995 - auc: 1.0000 - binary_accuracy: 0.9995 - recall_4: 0.9988 - precision_4: 0.9994 - val_loss: 1.5280 - val_acc: 0.7108 - val_auc: 0.6753 - val_binary_accuracy: 0.7108 - val_recall_4: 0.3858 - val_precision_4: 0.5292\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0065 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_4: 1.0000 - precision_4: 0.9994 - val_loss: 1.5406 - val_acc: 0.7155 - val_auc: 0.6821 - val_binary_accuracy: 0.7155 - val_recall_4: 0.4094 - val_precision_4: 0.5383\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0056 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_4: 1.0000 - precision_4: 1.0000 - val_loss: 1.6207 - val_acc: 0.7108 - val_auc: 0.6766 - val_binary_accuracy: 0.7108 - val_recall_4: 0.4283 - val_precision_4: 0.5261\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0045 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_4: 1.0000 - precision_4: 1.0000 - val_loss: 1.6638 - val_acc: 0.7122 - val_auc: 0.6743 - val_binary_accuracy: 0.7122 - val_recall_4: 0.4031 - val_precision_4: 0.5311\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0038 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_4: 1.0000 - precision_4: 1.0000 - val_loss: 1.7112 - val_acc: 0.7088 - val_auc: 0.6751 - val_binary_accuracy: 0.7088 - val_recall_4: 0.4063 - val_precision_4: 0.5233\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0030 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_4: 1.0000 - precision_4: 1.0000 - val_loss: 1.7255 - val_acc: 0.7127 - val_auc: 0.6873 - val_binary_accuracy: 0.7127 - val_recall_4: 0.3984 - val_precision_4: 0.5326\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.0026 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_4: 1.0000 - precision_4: 1.0000 - val_loss: 1.7906 - val_acc: 0.7165 - val_auc: 0.6872 - val_binary_accuracy: 0.7165 - val_recall_4: 0.3795 - val_precision_4: 0.5440\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.0023 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_4: 1.0000 - precision_4: 1.0000 - val_loss: 1.8556 - val_acc: 0.7103 - val_auc: 0.6837 - val_binary_accuracy: 0.7103 - val_recall_4: 0.3717 - val_precision_4: 0.5291\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0020 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_4: 1.0000 - precision_4: 1.0000 - val_loss: 1.8321 - val_acc: 0.7131 - val_auc: 0.6842 - val_binary_accuracy: 0.7131 - val_recall_4: 0.3969 - val_precision_4: 0.5339\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0018 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_4: 1.0000 - precision_4: 1.0000 - val_loss: 1.8709 - val_acc: 0.7122 - val_auc: 0.6849 - val_binary_accuracy: 0.7122 - val_recall_4: 0.3937 - val_precision_4: 0.5319\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.0015 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_4: 1.0000 - precision_4: 1.0000 - val_loss: 1.9244 - val_acc: 0.7150 - val_auc: 0.6840 - val_binary_accuracy: 0.7150 - val_recall_4: 0.3780 - val_precision_4: 0.5405\n",
      "0.6503463387489319\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ab0823c3-d0d5-4ac1-85d9-0f872165074d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d13c44c3-6ae8-4c4e-b754-0a499767a691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced Accuracy:  0.75 MSE:  0.25 UAR:  0.6764705882352942 Recall:  0.5 Precision:  0.5833333333333334 F1:  0.5384615384615384\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6197478991596639 Recall:  0.35714285714285715 Precision:  0.5555555555555556 F1:  0.43478260869565216\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced Accuracy:  0.75 MSE:  0.25 UAR:  0.634453781512605 Recall:  0.35714285714285715 Precision:  0.625 F1:  0.45454545454545453\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "0.1 0.6764705882352942\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f56f22e8-9e64-4ffc-8d23-32504224e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ee348feb-81cc-4bea-a738-6ff57ef7fbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0873991c-6685-4894-8afe-e30d95b6d9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.5 MSE:  0.5 UAR:  0.6260504201680672 Recall:  0.9285714285714286 Precision:  0.3611111111111111 F1:  0.52\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.6428571428571428 Recall:  0.7857142857142857 Precision:  0.39285714285714285 F1:  0.5238095238095237\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.6008403361344539 Recall:  0.6428571428571429 Precision:  0.375 F1:  0.4736842105263159\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6890756302521008 Recall:  0.6428571428571429 Precision:  0.5 F1:  0.5625000000000001\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6974789915966386 Recall:  0.5714285714285714 Precision:  0.5714285714285714 F1:  0.5714285714285714\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6260504201680672 Recall:  0.42857142857142855 Precision:  0.5 F1:  0.4615384615384615\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6197478991596639 Recall:  0.35714285714285715 Precision:  0.5555555555555556 F1:  0.43478260869565216\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6134453781512605 Recall:  0.2857142857142857 Precision:  0.6666666666666666 F1:  0.4\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.592436974789916 Recall:  0.21428571428571427 Precision:  0.75 F1:  0.3333333333333333\n",
      "0.5 0.6974789915966386\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81276529-9ebb-4dac-8e69-8a9e3a7c9046",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9f652128-8e3d-47e8-a2d3-058f7653aa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0dc69551-d50a-46ab-a797-a40c44ff6fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f23b600a-0e37-42e8-8770-487299d53d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 2048) (5631,)\n",
      "(2102, 128, 2048) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a8d1f206-a36b-403f-9a57-3f83dccc5e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_2 (Attention)     (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention_2[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention_2[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a026a1c4-5dc0-4ec2-8be7-01263d9d6ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44/44 [==============================] - 6s 111ms/step - loss: 0.5453 - acc: 0.7906 - auc: 0.8068 - binary_accuracy: 0.7906 - recall_5: 0.5946 - precision_5: 0.6758 - val_loss: 0.6830 - val_acc: 0.6603 - val_auc: 0.6268 - val_binary_accuracy: 0.6603 - val_recall_5: 0.4031 - val_precision_5: 0.4332\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.1889 - acc: 0.9352 - auc: 0.9804 - binary_accuracy: 0.9352 - recall_5: 0.8436 - precision_5: 0.9363 - val_loss: 0.7894 - val_acc: 0.6456 - val_auc: 0.6385 - val_binary_accuracy: 0.6456 - val_recall_5: 0.4331 - val_precision_5: 0.4167\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.1139 - acc: 0.9639 - auc: 0.9934 - binary_accuracy: 0.9639 - recall_5: 0.9203 - precision_5: 0.9591 - val_loss: 0.8956 - val_acc: 0.6618 - val_auc: 0.6308 - val_binary_accuracy: 0.6618 - val_recall_5: 0.3701 - val_precision_5: 0.4304\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0641 - acc: 0.9808 - auc: 0.9984 - binary_accuracy: 0.9808 - recall_5: 0.9543 - precision_5: 0.9819 - val_loss: 1.1442 - val_acc: 0.6598 - val_auc: 0.6061 - val_binary_accuracy: 0.6598 - val_recall_5: 0.3354 - val_precision_5: 0.4209\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0420 - acc: 0.9888 - auc: 0.9994 - binary_accuracy: 0.9888 - recall_5: 0.9754 - precision_5: 0.9875 - val_loss: 1.3030 - val_acc: 0.6346 - val_auc: 0.5862 - val_binary_accuracy: 0.6346 - val_recall_5: 0.3764 - val_precision_5: 0.3912\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0518 - acc: 0.9840 - auc: 0.9979 - binary_accuracy: 0.9840 - recall_5: 0.9678 - precision_5: 0.9793 - val_loss: 1.3257 - val_acc: 0.6760 - val_auc: 0.5927 - val_binary_accuracy: 0.6760 - val_recall_5: 0.3921 - val_precision_5: 0.4577\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 0.0405 - acc: 0.9874 - auc: 0.9990 - binary_accuracy: 0.9874 - recall_5: 0.9760 - precision_5: 0.9823 - val_loss: 1.5190 - val_acc: 0.6803 - val_auc: 0.6062 - val_binary_accuracy: 0.6803 - val_recall_5: 0.3118 - val_precision_5: 0.4573\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0178 - acc: 0.9948 - auc: 0.9999 - binary_accuracy: 0.9948 - recall_5: 0.9877 - precision_5: 0.9953 - val_loss: 1.6097 - val_acc: 0.6537 - val_auc: 0.5952 - val_binary_accuracy: 0.6537 - val_recall_5: 0.3559 - val_precision_5: 0.4147\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 0.0119 - acc: 0.9977 - auc: 1.0000 - binary_accuracy: 0.9977 - recall_5: 0.9941 - precision_5: 0.9982 - val_loss: 1.6691 - val_acc: 0.6389 - val_auc: 0.5965 - val_binary_accuracy: 0.6389 - val_recall_5: 0.3827 - val_precision_5: 0.3984\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 0.0089 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_5: 0.9988 - precision_5: 0.9988 - val_loss: 1.7715 - val_acc: 0.6717 - val_auc: 0.6078 - val_binary_accuracy: 0.6717 - val_recall_5: 0.3307 - val_precision_5: 0.4421\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0065 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_5: 0.9988 - precision_5: 1.0000 - val_loss: 1.7709 - val_acc: 0.6270 - val_auc: 0.5925 - val_binary_accuracy: 0.6270 - val_recall_5: 0.4220 - val_precision_5: 0.3912\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 3s 68ms/step - loss: 0.0059 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_5: 0.9994 - precision_5: 1.0000 - val_loss: 1.7812 - val_acc: 0.6503 - val_auc: 0.6074 - val_binary_accuracy: 0.6503 - val_recall_5: 0.3654 - val_precision_5: 0.4113\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 3s 68ms/step - loss: 0.0039 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_5: 0.9994 - precision_5: 1.0000 - val_loss: 1.8388 - val_acc: 0.6422 - val_auc: 0.6026 - val_binary_accuracy: 0.6422 - val_recall_5: 0.3638 - val_precision_5: 0.3990\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 3s 68ms/step - loss: 0.0032 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_5: 1.0000 - precision_5: 1.0000 - val_loss: 1.8864 - val_acc: 0.6380 - val_auc: 0.5974 - val_binary_accuracy: 0.6380 - val_recall_5: 0.3717 - val_precision_5: 0.3946\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0027 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_5: 1.0000 - precision_5: 1.0000 - val_loss: 1.9557 - val_acc: 0.6608 - val_auc: 0.6027 - val_binary_accuracy: 0.6608 - val_recall_5: 0.3276 - val_precision_5: 0.4211\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0020 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_5: 1.0000 - precision_5: 1.0000 - val_loss: 1.9513 - val_acc: 0.6470 - val_auc: 0.6012 - val_binary_accuracy: 0.6470 - val_recall_5: 0.3449 - val_precision_5: 0.4018\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 3s 68ms/step - loss: 0.0017 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_5: 1.0000 - precision_5: 1.0000 - val_loss: 2.0283 - val_acc: 0.6541 - val_auc: 0.5980 - val_binary_accuracy: 0.6541 - val_recall_5: 0.3323 - val_precision_5: 0.4105\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0015 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_5: 1.0000 - precision_5: 1.0000 - val_loss: 2.0847 - val_acc: 0.6432 - val_auc: 0.5955 - val_binary_accuracy: 0.6432 - val_recall_5: 0.3276 - val_precision_5: 0.3917\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0014 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_5: 1.0000 - precision_5: 1.0000 - val_loss: 2.1263 - val_acc: 0.6622 - val_auc: 0.5987 - val_binary_accuracy: 0.6622 - val_recall_5: 0.3181 - val_precision_5: 0.4217\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 3s 67ms/step - loss: 0.0013 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_5: 1.0000 - precision_5: 1.0000 - val_loss: 2.1336 - val_acc: 0.6418 - val_auc: 0.5940 - val_binary_accuracy: 0.6418 - val_recall_5: 0.3417 - val_precision_5: 0.3931\n",
      "0.6829870939254761\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cdb14140-c92b-4272-a0ea-f595eeeada70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6aff4392-197b-4bbb-b89c-fb21b046c336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6449579831932774 Recall:  0.6428571428571429 Precision:  0.42857142857142855 F1:  0.5142857142857143\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6029411764705883 Recall:  0.5 Precision:  0.4117647058823529 F1:  0.45161290322580644\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced Accuracy:  0.625 MSE:  0.375 UAR:  0.5672268907563025 Recall:  0.42857142857142855 Precision:  0.375 F1:  0.39999999999999997\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced Accuracy:  0.625 MSE:  0.375 UAR:  0.5672268907563025 Recall:  0.42857142857142855 Precision:  0.375 F1:  0.39999999999999997\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5819327731092437 Recall:  0.42857142857142855 Precision:  0.4 F1:  0.4137931034482759\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5819327731092437 Recall:  0.42857142857142855 Precision:  0.4 F1:  0.4137931034482759\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6050420168067226 Recall:  0.35714285714285715 Precision:  0.5 F1:  0.41666666666666663\n",
      "0.1 0.6449579831932774\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b292dbed-e65d-478f-bf59-19de43315826",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d214ac9b-1512-4367-a1e1-ecc8735b6f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8cc07d5d-cdf9-4fee-9a65-f8c8dc8592fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.375 MSE:  0.625 UAR:  0.5378151260504201 Recall:  0.9285714285714286 Precision:  0.30952380952380953 F1:  0.46428571428571436\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.5416666666666666 MSE:  0.4583333333333333 UAR:  0.6554621848739496 Recall:  0.9285714285714286 Precision:  0.38235294117647056 F1:  0.5416666666666667\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.5625 MSE:  0.4375 UAR:  0.6281512605042017 Recall:  0.7857142857142857 Precision:  0.3793103448275862 F1:  0.5116279069767441\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.5625 MSE:  0.4375 UAR:  0.5651260504201681 Recall:  0.5714285714285714 Precision:  0.34782608695652173 F1:  0.4324324324324324\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.5588235294117647 Recall:  0.5 Precision:  0.35 F1:  0.4117647058823529\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.5378151260504201 Recall:  0.42857142857142855 Precision:  0.3333333333333333 F1:  0.375\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5819327731092437 Recall:  0.42857142857142855 Precision:  0.4 F1:  0.4137931034482759\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5777310924369747 Recall:  0.21428571428571427 Precision:  0.6 F1:  0.3157894736842105\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.5714285714285714 Recall:  0.14285714285714285 Precision:  1.0 F1:  0.25\n",
      "0.2 0.6554621848739496\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a70ed6-c182-4a59-9703-ba1cf64aa090",
   "metadata": {},
   "source": [
    "### Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "105112a2-c080-4f99-8c04-8d8e49c3ae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.max\n",
    "stat_name = \"max\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375d9213-e641-4647-93b2-85f48e3d4997",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "95d555a7-9e6f-464a-8655-24d31d2e1bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2757dd90-cdad-4062-af5c-89cd0d9da117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6b4b79fe-40c4-481c-a392-e7b9509f3e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d53790-53a9-49ac-b9d3-4aa4beb7e72f",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4848a5dd-a3ef-40a1-956a-d7e9f619adab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_max_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "932fd504-3080-4ff9-81d4-6bb7222cc219",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4823bafd-f6f1-46fb-8593-fef87b457479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2048) (5449,)\n",
      "(2284, 128, 2048) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "39bc57a4-e15c-47fd-a970-456cf921eccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "17ef6cda-5856-484e-a2c1-ee0e28dd379d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 4s 66ms/step - loss: 0.6302 - acc: 0.7288 - auc: 0.6793 - binary_accuracy: 0.7288 - recall_6: 0.3455 - precision_6: 0.5396 - val_loss: 0.6465 - val_acc: 0.5898 - val_auc: 0.6219 - val_binary_accuracy: 0.5898 - val_recall_6: 0.0994 - val_precision_6: 0.2532\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.3227 - acc: 0.8873 - auc: 0.9345 - binary_accuracy: 0.8873 - recall_6: 0.6808 - precision_6: 0.9006 - val_loss: 0.7450 - val_acc: 0.6116 - val_auc: 0.6218 - val_binary_accuracy: 0.6116 - val_recall_6: 0.1465 - val_precision_6: 0.3464\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.2100 - acc: 0.9312 - auc: 0.9718 - binary_accuracy: 0.9312 - recall_6: 0.8247 - precision_6: 0.9264 - val_loss: 0.8559 - val_acc: 0.6620 - val_auc: 0.5774 - val_binary_accuracy: 0.6620 - val_recall_6: 0.1631 - val_precision_6: 0.5267\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.1303 - acc: 0.9631 - auc: 0.9936 - binary_accuracy: 0.9631 - recall_6: 0.8927 - precision_6: 0.9761 - val_loss: 0.8566 - val_acc: 0.6016 - val_auc: 0.6039 - val_binary_accuracy: 0.6016 - val_recall_6: 0.2293 - val_precision_6: 0.3711\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.0752 - acc: 0.9899 - auc: 0.9996 - binary_accuracy: 0.9899 - recall_6: 0.9705 - precision_6: 0.9941 - val_loss: 0.9253 - val_acc: 0.5959 - val_auc: 0.6041 - val_binary_accuracy: 0.5959 - val_recall_6: 0.2968 - val_precision_6: 0.3858\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0492 - acc: 0.9963 - auc: 1.0000 - binary_accuracy: 0.9963 - recall_6: 0.9884 - precision_6: 0.9987 - val_loss: 1.2670 - val_acc: 0.6642 - val_auc: 0.5615 - val_binary_accuracy: 0.6642 - val_recall_6: 0.1465 - val_precision_6: 0.5425\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0304 - acc: 0.9991 - auc: 1.0000 - binary_accuracy: 0.9991 - recall_6: 0.9974 - precision_6: 0.9994 - val_loss: 1.1441 - val_acc: 0.5788 - val_auc: 0.5911 - val_binary_accuracy: 0.5788 - val_recall_6: 0.2446 - val_precision_6: 0.3422\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0203 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_6: 0.9994 - precision_6: 1.0000 - val_loss: 1.2192 - val_acc: 0.5823 - val_auc: 0.5918 - val_binary_accuracy: 0.5823 - val_recall_6: 0.2624 - val_precision_6: 0.3546\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0139 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_6: 0.9994 - precision_6: 1.0000 - val_loss: 1.2721 - val_acc: 0.5954 - val_auc: 0.5926 - val_binary_accuracy: 0.5954 - val_recall_6: 0.3032 - val_precision_6: 0.3870\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0106 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_6: 1.0000 - precision_6: 1.0000 - val_loss: 1.4021 - val_acc: 0.5867 - val_auc: 0.5811 - val_binary_accuracy: 0.5867 - val_recall_6: 0.2318 - val_precision_6: 0.3480\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0082 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_6: 1.0000 - precision_6: 1.0000 - val_loss: 1.4052 - val_acc: 0.5906 - val_auc: 0.5857 - val_binary_accuracy: 0.5906 - val_recall_6: 0.2777 - val_precision_6: 0.3720\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.0069 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_6: 1.0000 - precision_6: 1.0000 - val_loss: 1.4921 - val_acc: 0.5863 - val_auc: 0.5821 - val_binary_accuracy: 0.5863 - val_recall_6: 0.2510 - val_precision_6: 0.3556\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0053 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_6: 1.0000 - precision_6: 1.0000 - val_loss: 1.4963 - val_acc: 0.6025 - val_auc: 0.5866 - val_binary_accuracy: 0.6025 - val_recall_6: 0.2930 - val_precision_6: 0.3945\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.0044 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_6: 1.0000 - precision_6: 1.0000 - val_loss: 1.5591 - val_acc: 0.5963 - val_auc: 0.5850 - val_binary_accuracy: 0.5963 - val_recall_6: 0.2637 - val_precision_6: 0.3757\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.0038 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_6: 1.0000 - precision_6: 1.0000 - val_loss: 1.5871 - val_acc: 0.6042 - val_auc: 0.5888 - val_binary_accuracy: 0.6042 - val_recall_6: 0.2841 - val_precision_6: 0.3947\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0032 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_6: 1.0000 - precision_6: 1.0000 - val_loss: 1.6706 - val_acc: 0.6033 - val_auc: 0.5825 - val_binary_accuracy: 0.6033 - val_recall_6: 0.2382 - val_precision_6: 0.3778\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0027 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_6: 1.0000 - precision_6: 1.0000 - val_loss: 1.7297 - val_acc: 0.6033 - val_auc: 0.5743 - val_binary_accuracy: 0.6033 - val_recall_6: 0.2255 - val_precision_6: 0.3726\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.0024 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_6: 1.0000 - precision_6: 1.0000 - val_loss: 1.6779 - val_acc: 0.6130 - val_auc: 0.5879 - val_binary_accuracy: 0.6130 - val_recall_6: 0.3159 - val_precision_6: 0.4168\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.0021 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_6: 1.0000 - precision_6: 1.0000 - val_loss: 1.7371 - val_acc: 0.6081 - val_auc: 0.5828 - val_binary_accuracy: 0.6081 - val_recall_6: 0.2688 - val_precision_6: 0.3966\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0019 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_6: 1.0000 - precision_6: 1.0000 - val_loss: 1.7727 - val_acc: 0.6095 - val_auc: 0.5803 - val_binary_accuracy: 0.6095 - val_recall_6: 0.2611 - val_precision_6: 0.3965\n",
      "0.6465309262275696\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "da4a1ad4-f7d3-40ca-baf0-75ea6b906d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b69305da-d50b-42eb-9c14-33f2efce6188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional Accuracy:  0.5625 MSE:  0.4375 UAR:  0.5441176470588236 Recall:  0.5 Precision:  0.3333333333333333 F1:  0.4\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.5378151260504201 Recall:  0.42857142857142855 Precision:  0.3333333333333333 F1:  0.375\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5315126050420168 Recall:  0.35714285714285715 Precision:  0.3333333333333333 F1:  0.3448275862068965\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.546218487394958 Recall:  0.35714285714285715 Precision:  0.35714285714285715 F1:  0.35714285714285715\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5399159663865546 Recall:  0.2857142857142857 Precision:  0.36363636363636365 F1:  0.32\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.5042016806722689 Recall:  0.21428571428571427 Precision:  0.3 F1:  0.25\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.4831932773109243 Recall:  0.14285714285714285 Precision:  0.25 F1:  0.18181818181818182\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5126050420168067 Recall:  0.14285714285714285 Precision:  0.3333333333333333 F1:  0.2\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5567226890756303 Recall:  0.14285714285714285 Precision:  0.6666666666666666 F1:  0.23529411764705882\n",
      "0.9 0.5567226890756303\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5cd6a93a-db61-44cc-8680-a63c63cc7316",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "15ab486a-c60b-43fc-86b3-57eab5c44bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d1d45959-bd25-4f72-81c7-6761d2bb8581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.3125 MSE:  0.6875 UAR:  0.5147058823529411 Recall:  1.0 Precision:  0.2978723404255319 F1:  0.45901639344262296\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.5208333333333334 MSE:  0.4791666666666667 UAR:  0.6407563025210085 Recall:  0.9285714285714286 Precision:  0.37142857142857144 F1:  0.5306122448979592\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.5625 MSE:  0.4375 UAR:  0.5441176470588236 Recall:  0.5 Precision:  0.3333333333333333 F1:  0.4\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5336134453781513 Recall:  0.21428571428571427 Precision:  0.375 F1:  0.2727272727272727\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.49159663865546216 Recall:  0.07142857142857142 Precision:  0.25 F1:  0.11111111111111112\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5063025210084033 Recall:  0.07142857142857142 Precision:  0.3333333333333333 F1:  0.11764705882352941\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.4852941176470588 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.2 0.6407563025210085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dad4a7-4195-48d3-8082-279e8967d21d",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8900bb06-b9a4-4ab2-af3f-f675710701ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_max_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "56b2c73b-8a37-4792-a7bd-476959fe290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2f833da7-7cf8-4efe-8cac-11a3c49488a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2048) (5449,)\n",
      "(2284, 128, 2048) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "217780ed-a2cb-4a9f-8823-a4e4ca3a9eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_3 (Attention)     (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention_3[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention_3[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "761bdab9-80f1-4ff0-b535-e131642aaecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 110ms/step - loss: 3.1838 - acc: 0.6818 - auc: 0.6361 - binary_accuracy: 0.6818 - recall_7: 0.4483 - precision_7: 0.4437 - val_loss: 1.0201 - val_acc: 0.6502 - val_auc: 0.6093 - val_binary_accuracy: 0.6502 - val_recall_7: 0.1172 - val_precision_7: 0.4646\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.3023 - acc: 0.8789 - auc: 0.9268 - binary_accuracy: 0.8789 - recall_7: 0.7405 - precision_7: 0.8183 - val_loss: 0.7808 - val_acc: 0.6467 - val_auc: 0.5626 - val_binary_accuracy: 0.6467 - val_recall_7: 0.3146 - val_precision_7: 0.4787\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.1850 - acc: 0.9383 - auc: 0.9809 - binary_accuracy: 0.9383 - recall_7: 0.8504 - precision_7: 0.9278 - val_loss: 0.8676 - val_acc: 0.6454 - val_auc: 0.5438 - val_binary_accuracy: 0.6454 - val_recall_7: 0.1885 - val_precision_7: 0.4611\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.1295 - acc: 0.9659 - auc: 0.9946 - binary_accuracy: 0.9659 - recall_7: 0.9146 - precision_7: 0.9641 - val_loss: 0.9136 - val_acc: 0.6300 - val_auc: 0.5597 - val_binary_accuracy: 0.6300 - val_recall_7: 0.3006 - val_precision_7: 0.4436\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0841 - acc: 0.9846 - auc: 0.9989 - binary_accuracy: 0.9846 - recall_7: 0.9634 - precision_7: 0.9823 - val_loss: 1.0994 - val_acc: 0.6327 - val_auc: 0.5229 - val_binary_accuracy: 0.6327 - val_recall_7: 0.1898 - val_precision_7: 0.4233\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0565 - acc: 0.9941 - auc: 0.9998 - binary_accuracy: 0.9941 - recall_7: 0.9839 - precision_7: 0.9955 - val_loss: 1.0483 - val_acc: 0.5613 - val_auc: 0.5497 - val_binary_accuracy: 0.5613 - val_recall_7: 0.3452 - val_precision_7: 0.3570\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0442 - acc: 0.9965 - auc: 0.9998 - binary_accuracy: 0.9965 - recall_7: 0.9917 - precision_7: 0.9961 - val_loss: 1.3385 - val_acc: 0.6375 - val_auc: 0.5132 - val_binary_accuracy: 0.6375 - val_recall_7: 0.2166 - val_precision_7: 0.4439\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0341 - acc: 0.9972 - auc: 0.9998 - binary_accuracy: 0.9972 - recall_7: 0.9968 - precision_7: 0.9936 - val_loss: 1.1952 - val_acc: 0.5736 - val_auc: 0.5440 - val_binary_accuracy: 0.5736 - val_recall_7: 0.2675 - val_precision_7: 0.3448\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0222 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_7: 0.9994 - precision_7: 0.9981 - val_loss: 1.3136 - val_acc: 0.5968 - val_auc: 0.5343 - val_binary_accuracy: 0.5968 - val_recall_7: 0.2561 - val_precision_7: 0.3736\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0168 - acc: 0.9989 - auc: 1.0000 - binary_accuracy: 0.9989 - recall_7: 0.9994 - precision_7: 0.9968 - val_loss: 1.3898 - val_acc: 0.6046 - val_auc: 0.5333 - val_binary_accuracy: 0.6046 - val_recall_7: 0.2459 - val_precision_7: 0.3829\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0111 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_7: 0.9994 - precision_7: 0.9994 - val_loss: 1.3922 - val_acc: 0.5718 - val_auc: 0.5321 - val_binary_accuracy: 0.5718 - val_recall_7: 0.2662 - val_precision_7: 0.3421\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0092 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_7: 1.0000 - precision_7: 0.9994 - val_loss: 1.5273 - val_acc: 0.5976 - val_auc: 0.5435 - val_binary_accuracy: 0.5976 - val_recall_7: 0.2357 - val_precision_7: 0.3671\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0076 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_7: 1.0000 - precision_7: 0.9994 - val_loss: 1.4526 - val_acc: 0.5661 - val_auc: 0.5365 - val_binary_accuracy: 0.5661 - val_recall_7: 0.2764 - val_precision_7: 0.3391\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0062 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_7: 1.0000 - precision_7: 0.9994 - val_loss: 1.5274 - val_acc: 0.5648 - val_auc: 0.5247 - val_binary_accuracy: 0.5648 - val_recall_7: 0.2713 - val_precision_7: 0.3354\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0051 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_7: 1.0000 - precision_7: 0.9994 - val_loss: 1.6340 - val_acc: 0.5836 - val_auc: 0.5202 - val_binary_accuracy: 0.5836 - val_recall_7: 0.2586 - val_precision_7: 0.3549\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0052 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_7: 0.9994 - precision_7: 0.9994 - val_loss: 1.7369 - val_acc: 0.5902 - val_auc: 0.5139 - val_binary_accuracy: 0.5902 - val_recall_7: 0.2497 - val_precision_7: 0.3610\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0037 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_7: 1.0000 - precision_7: 1.0000 - val_loss: 1.6406 - val_acc: 0.5644 - val_auc: 0.5190 - val_binary_accuracy: 0.5644 - val_recall_7: 0.2713 - val_precision_7: 0.3349\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0030 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_7: 1.0000 - precision_7: 1.0000 - val_loss: 1.7172 - val_acc: 0.5788 - val_auc: 0.5145 - val_binary_accuracy: 0.5788 - val_recall_7: 0.2675 - val_precision_7: 0.3518\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0026 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_7: 1.0000 - precision_7: 1.0000 - val_loss: 1.7813 - val_acc: 0.5771 - val_auc: 0.5053 - val_binary_accuracy: 0.5771 - val_recall_7: 0.2637 - val_precision_7: 0.3479\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0023 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_7: 1.0000 - precision_7: 1.0000 - val_loss: 1.7356 - val_acc: 0.5652 - val_auc: 0.5139 - val_binary_accuracy: 0.5652 - val_recall_7: 0.2713 - val_precision_7: 0.3360\n",
      "0.7807735204696655\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "71ced305-d4bb-4028-afe5-30da4f5cfdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a00bb3b6-adfc-42dd-bd86-5745803a78eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional Accuracy:  0.5625 MSE:  0.4375 UAR:  0.5861344537815126 Recall:  0.6428571428571429 Precision:  0.36 F1:  0.4615384615384615\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.6302521008403361 Recall:  0.6428571428571429 Precision:  0.4090909090909091 F1:  0.5000000000000001\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5525210084033614 Recall:  0.42857142857142855 Precision:  0.35294117647058826 F1:  0.3870967741935484\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.5672268907563025 Recall:  0.42857142857142855 Precision:  0.375 F1:  0.39999999999999997\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.5672268907563025 Recall:  0.42857142857142855 Precision:  0.375 F1:  0.39999999999999997\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.4957983193277311 Recall:  0.2857142857142857 Precision:  0.2857142857142857 F1:  0.2857142857142857\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5105042016806722 Recall:  0.2857142857142857 Precision:  0.3076923076923077 F1:  0.29629629629629634\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.5252100840336134 Recall:  0.2857142857142857 Precision:  0.3333333333333333 F1:  0.30769230769230765\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5399159663865546 Recall:  0.2857142857142857 Precision:  0.36363636363636365 F1:  0.32\n",
      "0.2 0.6302521008403361\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "231f46bd-cc16-4db5-9fee-dbc158caaa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "badb5173-d967-4b2a-aee1-75b2f5bdd295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d16209ac-98c6-4acc-ae5d-b44054a45b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.3541666666666667 MSE:  0.6458333333333334 UAR:  0.5441176470588235 Recall:  1.0 Precision:  0.3111111111111111 F1:  0.4745762711864407\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.375 MSE:  0.625 UAR:  0.5168067226890756 Recall:  0.8571428571428571 Precision:  0.3 F1:  0.4444444444444444\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.4583333333333333 MSE:  0.5416666666666666 UAR:  0.5756302521008403 Recall:  0.8571428571428571 Precision:  0.3333333333333333 F1:  0.48\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.625 MSE:  0.375 UAR:  0.6302521008403361 Recall:  0.6428571428571429 Precision:  0.4090909090909091 F1:  0.5000000000000001\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6617647058823529 Recall:  0.5 Precision:  0.5384615384615384 F1:  0.5185185185185186\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6491596638655462 Recall:  0.35714285714285715 Precision:  0.7142857142857143 F1:  0.4761904761904762\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6491596638655462 Recall:  0.35714285714285715 Precision:  0.7142857142857143 F1:  0.4761904761904762\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5567226890756303 Recall:  0.14285714285714285 Precision:  0.6666666666666666 F1:  0.23529411764705882\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5357142857142857 Recall:  0.07142857142857142 Precision:  1.0 F1:  0.13333333333333333\n",
      "0.5 0.6617647058823529\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5427606c-8791-4339-9599-e124dd3f164b",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "825b34f3-a700-48a6-8386-a07c1a3ff565",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "570cc58d-61f6-4f83-9c2a-76b0f79a0888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dd646970-fcb2-475c-9c2e-54b6adf5658f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8e9d270d-ebdb-49f6-ac6a-cf9648f32337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147,) (147,)\n",
      "(48,) (48,)\n",
      "(195,) (195,)\n",
      "[0 1] [141  54]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.759)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f140789c-4ac7-4971-82bf-857727fcbb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087a013b-0d41-4f23-85d7-9d70b297c638",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9abf70bd-8e74-4a12-8645-8e7caec10f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_max_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "41b19e76-1b79-412a-aa91-f52f6024c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d316180c-1da7-4716-93ae-8f3e809e9a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 2048) (5631,)\n",
      "(2102, 128, 2048) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ff4752f0-93d9-416d-970b-1bb0a9fbe0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7db1e610-7725-4ba0-904d-12ab6fdcda05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44/44 [==============================] - 4s 61ms/step - loss: 0.6190 - acc: 0.7223 - auc: 0.7111 - binary_accuracy: 0.7223 - recall_8: 0.3849 - precision_8: 0.5611 - val_loss: 0.6488 - val_acc: 0.6151 - val_auc: 0.5859 - val_binary_accuracy: 0.6151 - val_recall_8: 0.0945 - val_precision_8: 0.2041\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.3018 - acc: 0.8863 - auc: 0.9412 - binary_accuracy: 0.8863 - recall_8: 0.7036 - precision_8: 0.8996 - val_loss: 0.6827 - val_acc: 0.6813 - val_auc: 0.6146 - val_binary_accuracy: 0.6813 - val_recall_8: 0.3638 - val_precision_8: 0.4648\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1704 - acc: 0.9533 - auc: 0.9885 - binary_accuracy: 0.9533 - recall_8: 0.8735 - precision_8: 0.9694 - val_loss: 0.8436 - val_acc: 0.6518 - val_auc: 0.6007 - val_binary_accuracy: 0.6518 - val_recall_8: 0.3370 - val_precision_8: 0.4076\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0926 - acc: 0.9792 - auc: 0.9988 - binary_accuracy: 0.9792 - recall_8: 0.9361 - precision_8: 0.9950 - val_loss: 0.9732 - val_acc: 0.6427 - val_auc: 0.6070 - val_binary_accuracy: 0.6427 - val_recall_8: 0.4331 - val_precision_8: 0.4129\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.0518 - acc: 0.9959 - auc: 0.9999 - binary_accuracy: 0.9959 - recall_8: 0.9877 - precision_8: 0.9988 - val_loss: 1.1110 - val_acc: 0.6365 - val_auc: 0.6158 - val_binary_accuracy: 0.6365 - val_recall_8: 0.4441 - val_precision_8: 0.4069\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0308 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_8: 0.9982 - precision_8: 0.9994 - val_loss: 1.1762 - val_acc: 0.6532 - val_auc: 0.6093 - val_binary_accuracy: 0.6532 - val_recall_8: 0.4205 - val_precision_8: 0.4252\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0200 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_8: 0.9988 - precision_8: 1.0000 - val_loss: 1.2922 - val_acc: 0.6427 - val_auc: 0.6139 - val_binary_accuracy: 0.6427 - val_recall_8: 0.4409 - val_precision_8: 0.4142\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0138 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_8: 0.9994 - precision_8: 1.0000 - val_loss: 1.3740 - val_acc: 0.6522 - val_auc: 0.6177 - val_binary_accuracy: 0.6522 - val_recall_8: 0.4394 - val_precision_8: 0.4266\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0099 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_8: 1.0000 - precision_8: 1.0000 - val_loss: 1.4435 - val_acc: 0.6494 - val_auc: 0.6218 - val_binary_accuracy: 0.6494 - val_recall_8: 0.4346 - val_precision_8: 0.4220\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.0072 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_8: 0.9994 - precision_8: 1.0000 - val_loss: 1.4866 - val_acc: 0.6441 - val_auc: 0.6290 - val_binary_accuracy: 0.6441 - val_recall_8: 0.4425 - val_precision_8: 0.4163\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.0059 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_8: 0.9994 - precision_8: 1.0000 - val_loss: 1.5485 - val_acc: 0.6437 - val_auc: 0.6244 - val_binary_accuracy: 0.6437 - val_recall_8: 0.4409 - val_precision_8: 0.4154\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0045 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_8: 1.0000 - precision_8: 1.0000 - val_loss: 1.5932 - val_acc: 0.6427 - val_auc: 0.6274 - val_binary_accuracy: 0.6427 - val_recall_8: 0.4425 - val_precision_8: 0.4145\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.0038 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_8: 0.9994 - precision_8: 1.0000 - val_loss: 1.6401 - val_acc: 0.6494 - val_auc: 0.6197 - val_binary_accuracy: 0.6494 - val_recall_8: 0.4173 - val_precision_8: 0.4193\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0031 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_8: 1.0000 - precision_8: 1.0000 - val_loss: 1.6849 - val_acc: 0.6503 - val_auc: 0.6119 - val_binary_accuracy: 0.6503 - val_recall_8: 0.4094 - val_precision_8: 0.4194\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0027 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_8: 1.0000 - precision_8: 1.0000 - val_loss: 1.7103 - val_acc: 0.6503 - val_auc: 0.6214 - val_binary_accuracy: 0.6503 - val_recall_8: 0.4283 - val_precision_8: 0.4224\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0022 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_8: 1.0000 - precision_8: 1.0000 - val_loss: 1.7474 - val_acc: 0.6475 - val_auc: 0.6247 - val_binary_accuracy: 0.6475 - val_recall_8: 0.4378 - val_precision_8: 0.4199\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0019 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_8: 1.0000 - precision_8: 1.0000 - val_loss: 1.7846 - val_acc: 0.6484 - val_auc: 0.6234 - val_binary_accuracy: 0.6484 - val_recall_8: 0.4378 - val_precision_8: 0.4212\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0017 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_8: 1.0000 - precision_8: 1.0000 - val_loss: 1.8122 - val_acc: 0.6508 - val_auc: 0.6180 - val_binary_accuracy: 0.6508 - val_recall_8: 0.4047 - val_precision_8: 0.4192\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0015 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_8: 1.0000 - precision_8: 1.0000 - val_loss: 1.8381 - val_acc: 0.6480 - val_auc: 0.6205 - val_binary_accuracy: 0.6480 - val_recall_8: 0.4378 - val_precision_8: 0.4206\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0013 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_8: 1.0000 - precision_8: 1.0000 - val_loss: 1.8633 - val_acc: 0.6518 - val_auc: 0.6187 - val_binary_accuracy: 0.6518 - val_recall_8: 0.4299 - val_precision_8: 0.4246\n",
      "0.6487721800804138\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b1fb2825-af62-4d99-a046-d5f4c77afec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7408d730-891d-4822-8224-986e040585fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6176470588235294 Recall:  0.5 Precision:  0.4375 F1:  0.4666666666666667\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5819327731092437 Recall:  0.42857142857142855 Precision:  0.4 F1:  0.4137931034482759\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5819327731092437 Recall:  0.42857142857142855 Precision:  0.4 F1:  0.4137931034482759\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.611344537815126 Recall:  0.42857142857142855 Precision:  0.46153846153846156 F1:  0.4444444444444445\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.611344537815126 Recall:  0.42857142857142855 Precision:  0.46153846153846156 F1:  0.4444444444444445\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5756302521008403 Recall:  0.35714285714285715 Precision:  0.4166666666666667 F1:  0.3846153846153846\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5903361344537815 Recall:  0.35714285714285715 Precision:  0.45454545454545453 F1:  0.4\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.569327731092437 Recall:  0.2857142857142857 Precision:  0.4444444444444444 F1:  0.34782608695652173\n",
      "0.1 0.6176470588235294\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "484af713-90c0-495d-a9c8-7ce2b63f6c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "15782efe-e18e-4b63-846f-4c172f6c8035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5e8ab221-b93c-4405-8336-fbc607fe2dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.4166666666666667 MSE:  0.5833333333333334 UAR:  0.5882352941176471 Recall:  1.0 Precision:  0.3333333333333333 F1:  0.5\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.5 MSE:  0.5 UAR:  0.5840336134453781 Recall:  0.7857142857142857 Precision:  0.34375 F1:  0.4782608695652174\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.5 MSE:  0.5 UAR:  0.45798319327731096 Recall:  0.35714285714285715 Precision:  0.25 F1:  0.2941176470588235\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.4747899159663866 Recall:  0.21428571428571427 Precision:  0.25 F1:  0.23076923076923075\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5126050420168067 Recall:  0.14285714285714285 Precision:  0.3333333333333333 F1:  0.2\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5063025210084033 Recall:  0.07142857142857142 Precision:  0.3333333333333333 F1:  0.11764705882352941\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5063025210084033 Recall:  0.07142857142857142 Precision:  0.3333333333333333 F1:  0.11764705882352941\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.5882352941176471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7aadfe-7d79-4642-b62b-b10a159b1f3a",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0029b249-9723-4469-ac6a-4451eb6debe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_max_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ad95ca45-be66-4a87-9bde-0fcce4110465",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "00619164-4fec-4efd-a4b3-e7e86b24412e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 2048) (5631,)\n",
      "(2102, 128, 2048) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "15d3b104-d439-47a5-8438-3e4b81cfa2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_4 (Attention)     (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention_4[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention_4[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c3222580-4fdc-4fa5-9e0e-437eb20a67a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44/44 [==============================] - 6s 108ms/step - loss: 1.0655 - acc: 0.7862 - auc: 0.7845 - binary_accuracy: 0.7862 - recall_9: 0.6233 - precision_9: 0.6548 - val_loss: 0.8465 - val_acc: 0.6089 - val_auc: 0.5998 - val_binary_accuracy: 0.6089 - val_recall_9: 0.3543 - val_precision_9: 0.3532\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 0.1544 - acc: 0.9494 - auc: 0.9865 - binary_accuracy: 0.9494 - recall_9: 0.8822 - precision_9: 0.9472 - val_loss: 0.9989 - val_acc: 0.5966 - val_auc: 0.6011 - val_binary_accuracy: 0.5966 - val_recall_9: 0.1969 - val_precision_9: 0.2700\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 0.0840 - acc: 0.9805 - auc: 0.9981 - binary_accuracy: 0.9805 - recall_9: 0.9514 - precision_9: 0.9836 - val_loss: 1.2105 - val_acc: 0.5861 - val_auc: 0.5777 - val_binary_accuracy: 0.5861 - val_recall_9: 0.1591 - val_precision_9: 0.2311\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0461 - acc: 0.9954 - auc: 0.9999 - binary_accuracy: 0.9954 - recall_9: 0.9912 - precision_9: 0.9935 - val_loss: 1.4838 - val_acc: 0.5875 - val_auc: 0.5504 - val_binary_accuracy: 0.5875 - val_recall_9: 0.0740 - val_precision_9: 0.1442\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 0.0350 - acc: 0.9941 - auc: 0.9999 - binary_accuracy: 0.9941 - recall_9: 0.9854 - precision_9: 0.9953 - val_loss: 1.5506 - val_acc: 0.5699 - val_auc: 0.5473 - val_binary_accuracy: 0.5699 - val_recall_9: 0.1386 - val_precision_9: 0.1978\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 3s 67ms/step - loss: 0.0155 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 1.7683 - val_acc: 0.5604 - val_auc: 0.5318 - val_binary_accuracy: 0.5604 - val_recall_9: 0.0772 - val_precision_9: 0.1266\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0105 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 1.7934 - val_acc: 0.5690 - val_auc: 0.5314 - val_binary_accuracy: 0.5690 - val_recall_9: 0.1339 - val_precision_9: 0.1927\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0075 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 1.8658 - val_acc: 0.5633 - val_auc: 0.5351 - val_binary_accuracy: 0.5633 - val_recall_9: 0.1150 - val_precision_9: 0.1702\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0059 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 1.9428 - val_acc: 0.5652 - val_auc: 0.5256 - val_binary_accuracy: 0.5652 - val_recall_9: 0.1291 - val_precision_9: 0.1851\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0046 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 1.9782 - val_acc: 0.5628 - val_auc: 0.5187 - val_binary_accuracy: 0.5628 - val_recall_9: 0.1150 - val_precision_9: 0.1698\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0038 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 1.9786 - val_acc: 0.5747 - val_auc: 0.5427 - val_binary_accuracy: 0.5747 - val_recall_9: 0.2173 - val_precision_9: 0.2579\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0033 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 2.0945 - val_acc: 0.5614 - val_auc: 0.5263 - val_binary_accuracy: 0.5614 - val_recall_9: 0.1260 - val_precision_9: 0.1790\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 0.0027 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 2.1326 - val_acc: 0.5728 - val_auc: 0.5294 - val_binary_accuracy: 0.5728 - val_recall_9: 0.1732 - val_precision_9: 0.2277\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0022 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 2.2374 - val_acc: 0.5599 - val_auc: 0.5158 - val_binary_accuracy: 0.5599 - val_recall_9: 0.1118 - val_precision_9: 0.1644\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0018 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 2.2695 - val_acc: 0.5657 - val_auc: 0.5194 - val_binary_accuracy: 0.5657 - val_recall_9: 0.1354 - val_precision_9: 0.1911\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0016 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 2.3616 - val_acc: 0.5623 - val_auc: 0.5060 - val_binary_accuracy: 0.5623 - val_recall_9: 0.1181 - val_precision_9: 0.1724\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0014 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 2.3799 - val_acc: 0.5642 - val_auc: 0.5131 - val_binary_accuracy: 0.5642 - val_recall_9: 0.1291 - val_precision_9: 0.1843\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0012 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 2.4077 - val_acc: 0.5699 - val_auc: 0.5136 - val_binary_accuracy: 0.5699 - val_recall_9: 0.1512 - val_precision_9: 0.2082\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 0.0010 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 2.4676 - val_acc: 0.5618 - val_auc: 0.5056 - val_binary_accuracy: 0.5618 - val_recall_9: 0.1197 - val_precision_9: 0.1735\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 3s 67ms/step - loss: 9.2233e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 2.4901 - val_acc: 0.5671 - val_auc: 0.5080 - val_binary_accuracy: 0.5671 - val_recall_9: 0.1386 - val_precision_9: 0.1951\n",
      "0.8465239405632019\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "abe8cdf3-c0d4-421b-8d87-754744dcc064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e746f185-2f42-4e22-87c9-1ea4e38051cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5399159663865546 Recall:  0.2857142857142857 Precision:  0.36363636363636365 F1:  0.32\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.4684873949579832 Recall:  0.14285714285714285 Precision:  0.2222222222222222 F1:  0.17391304347826086\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.4684873949579832 Recall:  0.14285714285714285 Precision:  0.2222222222222222 F1:  0.17391304347826086\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.4684873949579832 Recall:  0.14285714285714285 Precision:  0.2222222222222222 F1:  0.17391304347826086\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.4684873949579832 Recall:  0.14285714285714285 Precision:  0.2222222222222222 F1:  0.17391304347826086\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.4684873949579832 Recall:  0.14285714285714285 Precision:  0.2222222222222222 F1:  0.17391304347826086\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.4474789915966386 Recall:  0.07142857142857142 Precision:  0.14285714285714285 F1:  0.09523809523809523\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced Accuracy:  0.625 MSE:  0.375 UAR:  0.4621848739495798 Recall:  0.07142857142857142 Precision:  0.16666666666666666 F1:  0.1\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.476890756302521 Recall:  0.07142857142857142 Precision:  0.2 F1:  0.10526315789473682\n",
      "0.1 0.5399159663865546\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b01f3f07-eff4-4a6e-9548-b306629677eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "83647194-c352-4844-a159-890145ed137d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "324c8ad9-a58c-46cc-b953-0c4c6e7f2402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.4791666666666667 MSE:  0.5208333333333334 UAR:  0.5903361344537815 Recall:  0.8571428571428571 Precision:  0.34285714285714286 F1:  0.4897959183673469\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.5208333333333334 MSE:  0.4791666666666667 UAR:  0.5987394957983193 Recall:  0.7857142857142857 Precision:  0.3548387096774194 F1:  0.48888888888888893\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.657563025210084 Recall:  0.7857142857142857 Precision:  0.4074074074074074 F1:  0.5365853658536585\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6239495798319328 Recall:  0.5714285714285714 Precision:  0.42105263157894735 F1:  0.48484848484848486\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.625 MSE:  0.375 UAR:  0.546218487394958 Recall:  0.35714285714285715 Precision:  0.35714285714285715 F1:  0.35714285714285715\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5609243697478992 Recall:  0.35714285714285715 Precision:  0.38461538461538464 F1:  0.3703703703703704\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5903361344537815 Recall:  0.35714285714285715 Precision:  0.45454545454545453 F1:  0.4\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5483193277310924 Recall:  0.21428571428571427 Precision:  0.42857142857142855 F1:  0.2857142857142857\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.45588235294117646 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.3 0.657563025210084\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda36c01-50ce-4528-8b49-0acdeab5f377",
   "metadata": {},
   "source": [
    "### STAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70effef6-d8d6-400b-8e07-cc42331388f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = compute_descriptor\n",
    "stat_name = \"STAT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b51565-821f-4bef-a206-842230dac71a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "450698b7-20bd-4fff-ace8-fa15ad9c9a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a9040385-d454-44fa-846f-6aaecfc2433d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c6e409d7-4f1e-423b-8873-f1805a4efbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb17a33b-087d-4eaf-b2b8-dc948a8f17f7",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ac333c5a-f95b-4244-b6ee-1b5f8678b370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7c453eb0-6306-44ea-bc53-31f64e2650b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "85661bc2-7aa6-431c-a57c-2485b243599b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 3072) (5449,)\n",
      "(2284, 128, 3072) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "dc5a9f59-1cba-4993-a80d-7b45519bb2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1573376   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1576962 (6.02 MB)\n",
      "Trainable params: 1576962 (6.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "55dd90aa-e5ef-4a50-b75f-ff59b5108641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 94ms/step - loss: 0.4465 - acc: 0.8012 - auc: 0.8244 - binary_accuracy: 0.8012 - recall_10: 0.5067 - precision_10: 0.7147 - val_loss: 0.6960 - val_acc: 0.6585 - val_auc: 0.6723 - val_binary_accuracy: 0.6585 - val_recall_10: 0.3019 - val_precision_10: 0.5053\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.2180 - acc: 0.9095 - auc: 0.9672 - binary_accuracy: 0.9095 - recall_10: 0.7938 - precision_10: 0.8778 - val_loss: 0.8028 - val_acc: 0.6546 - val_auc: 0.6677 - val_binary_accuracy: 0.6546 - val_recall_10: 0.1962 - val_precision_10: 0.4936\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.1432 - acc: 0.9424 - auc: 0.9876 - binary_accuracy: 0.9424 - recall_10: 0.8696 - precision_10: 0.9242 - val_loss: 0.7691 - val_acc: 0.6563 - val_auc: 0.6781 - val_binary_accuracy: 0.6563 - val_recall_10: 0.2803 - val_precision_10: 0.5000\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0962 - acc: 0.9673 - auc: 0.9950 - binary_accuracy: 0.9673 - recall_10: 0.9287 - precision_10: 0.9557 - val_loss: 0.8402 - val_acc: 0.6944 - val_auc: 0.6787 - val_binary_accuracy: 0.6944 - val_recall_10: 0.2803 - val_precision_10: 0.6232\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.0639 - acc: 0.9809 - auc: 0.9987 - binary_accuracy: 0.9809 - recall_10: 0.9518 - precision_10: 0.9808 - val_loss: 0.9629 - val_acc: 0.6690 - val_auc: 0.6604 - val_binary_accuracy: 0.6690 - val_recall_10: 0.4166 - val_precision_10: 0.5232\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.0498 - acc: 0.9873 - auc: 0.9992 - binary_accuracy: 0.9873 - recall_10: 0.9737 - precision_10: 0.9819 - val_loss: 1.1731 - val_acc: 0.6567 - val_auc: 0.6416 - val_binary_accuracy: 0.6567 - val_recall_10: 0.2522 - val_precision_10: 0.5013\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.0303 - acc: 0.9965 - auc: 0.9999 - binary_accuracy: 0.9965 - recall_10: 0.9917 - precision_10: 0.9961 - val_loss: 1.1640 - val_acc: 0.6655 - val_auc: 0.6475 - val_binary_accuracy: 0.6655 - val_recall_10: 0.3299 - val_precision_10: 0.5211\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0262 - acc: 0.9950 - auc: 0.9999 - binary_accuracy: 0.9950 - recall_10: 0.9897 - precision_10: 0.9929 - val_loss: 1.2941 - val_acc: 0.6651 - val_auc: 0.6456 - val_binary_accuracy: 0.6651 - val_recall_10: 0.3439 - val_precision_10: 0.5192\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.0166 - acc: 0.9991 - auc: 1.0000 - binary_accuracy: 0.9991 - recall_10: 0.9987 - precision_10: 0.9981 - val_loss: 1.3687 - val_acc: 0.6309 - val_auc: 0.6239 - val_binary_accuracy: 0.6309 - val_recall_10: 0.4064 - val_precision_10: 0.4583\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0126 - acc: 0.9991 - auc: 1.0000 - binary_accuracy: 0.9991 - recall_10: 0.9981 - precision_10: 0.9987 - val_loss: 1.4045 - val_acc: 0.6305 - val_auc: 0.6202 - val_binary_accuracy: 0.6305 - val_recall_10: 0.4166 - val_precision_10: 0.4586\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0101 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_10: 1.0000 - precision_10: 0.9994 - val_loss: 1.4889 - val_acc: 0.6243 - val_auc: 0.6165 - val_binary_accuracy: 0.6243 - val_recall_10: 0.3936 - val_precision_10: 0.4472\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0077 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_10: 1.0000 - precision_10: 0.9994 - val_loss: 1.5534 - val_acc: 0.6182 - val_auc: 0.6124 - val_binary_accuracy: 0.6182 - val_recall_10: 0.3554 - val_precision_10: 0.4326\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.0061 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_10: 1.0000 - precision_10: 0.9987 - val_loss: 1.6238 - val_acc: 0.6143 - val_auc: 0.6098 - val_binary_accuracy: 0.6143 - val_recall_10: 0.3490 - val_precision_10: 0.4255\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0052 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_10: 1.0000 - precision_10: 0.9994 - val_loss: 1.6620 - val_acc: 0.6169 - val_auc: 0.6075 - val_binary_accuracy: 0.6169 - val_recall_10: 0.3376 - val_precision_10: 0.4274\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0053 - acc: 0.9994 - auc: 1.0000 - binary_accuracy: 0.9994 - recall_10: 0.9987 - precision_10: 0.9994 - val_loss: 1.7031 - val_acc: 0.6130 - val_auc: 0.6107 - val_binary_accuracy: 0.6130 - val_recall_10: 0.3452 - val_precision_10: 0.4228\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0038 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_10: 1.0000 - precision_10: 1.0000 - val_loss: 1.7756 - val_acc: 0.6130 - val_auc: 0.6061 - val_binary_accuracy: 0.6130 - val_recall_10: 0.3389 - val_precision_10: 0.4216\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.0030 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_10: 1.0000 - precision_10: 1.0000 - val_loss: 1.7657 - val_acc: 0.6156 - val_auc: 0.6058 - val_binary_accuracy: 0.6156 - val_recall_10: 0.3783 - val_precision_10: 0.4323\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.0027 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_10: 1.0000 - precision_10: 1.0000 - val_loss: 1.8403 - val_acc: 0.6156 - val_auc: 0.6115 - val_binary_accuracy: 0.6156 - val_recall_10: 0.3083 - val_precision_10: 0.4194\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.0024 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_10: 1.0000 - precision_10: 1.0000 - val_loss: 1.8061 - val_acc: 0.6169 - val_auc: 0.6063 - val_binary_accuracy: 0.6169 - val_recall_10: 0.3936 - val_precision_10: 0.4364\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.0021 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_10: 1.0000 - precision_10: 1.0000 - val_loss: 2.0041 - val_acc: 0.6121 - val_auc: 0.6156 - val_binary_accuracy: 0.6121 - val_recall_10: 0.2242 - val_precision_10: 0.3885\n",
      "0.6960271000862122\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a935710e-f47e-4b16-bee8-73291eee8112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "026c9001-619c-421a-9c27-a42fb97302bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.5625 MSE:  0.4375 UAR:  0.523109243697479 Recall:  0.42857142857142855 Precision:  0.3157894736842105 F1:  0.36363636363636365\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.5168067226890757 Recall:  0.35714285714285715 Precision:  0.3125 F1:  0.3333333333333333\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5105042016806722 Recall:  0.2857142857142857 Precision:  0.3076923076923077 F1:  0.29629629629629634\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5399159663865546 Recall:  0.2857142857142857 Precision:  0.36363636363636365 F1:  0.32\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.51890756302521 Recall:  0.21428571428571427 Precision:  0.3333333333333333 F1:  0.2608695652173913\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.51890756302521 Recall:  0.21428571428571427 Precision:  0.3333333333333333 F1:  0.2608695652173913\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5483193277310924 Recall:  0.21428571428571427 Precision:  0.42857142857142855 F1:  0.2857142857142857\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5777310924369747 Recall:  0.21428571428571427 Precision:  0.6 F1:  0.3157894736842105\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.75 MSE:  0.25 UAR:  0.592436974789916 Recall:  0.21428571428571427 Precision:  0.75 F1:  0.3333333333333333\n",
      "0.9 0.592436974789916\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "177c6f4f-3131-48f1-a933-a43fecbd0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "454cdb88-3838-414b-ba95-45004fed656b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9bfc0290-811a-420e-9424-c176c6cf04d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.4791666666666667 MSE:  0.5208333333333334 UAR:  0.6113445378151261 Recall:  0.9285714285714286 Precision:  0.35135135135135137 F1:  0.5098039215686275\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6659663865546219 Recall:  0.7142857142857143 Precision:  0.43478260869565216 F1:  0.5405405405405405\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6911764705882353 Recall:  0.5 Precision:  0.6363636363636364 F1:  0.56\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5630252100840336 Recall:  0.21428571428571427 Precision:  0.5 F1:  0.3\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5273109243697479 Recall:  0.14285714285714285 Precision:  0.4 F1:  0.21052631578947364\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.49159663865546216 Recall:  0.07142857142857142 Precision:  0.25 F1:  0.11111111111111112\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5210084033613446 Recall:  0.07142857142857142 Precision:  0.5 F1:  0.125\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.3 0.6911764705882353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a75538-24c3-46fb-b317-c15bce4281ff",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f4632151-5142-4326-8fc8-05559d18ef5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d222dd91-89cd-4b46-b6d6-053721610bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7295c39a-aacd-420e-917d-fea0ebd0bb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 3072) (5449,)\n",
      "(2284, 128, 3072) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "49d4f07d-cb66-4d54-a480-5ff9b7dd6a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_5 (Attention)     (None, None, 3072)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['attention_5[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['attention_5[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 1)                    3073      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18880514 (72.02 MB)\n",
      "Trainable params: 18880514 (72.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "365bb602-b139-4151-a3ee-2d09f07ffd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 9s 181ms/step - loss: 0.8626 - acc: 0.7851 - auc: 0.7786 - binary_accuracy: 0.7851 - recall_11: 0.5793 - precision_11: 0.6361 - val_loss: 0.7451 - val_acc: 0.6213 - val_auc: 0.6604 - val_binary_accuracy: 0.6213 - val_recall_11: 0.1554 - val_precision_11: 0.3765\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.1910 - acc: 0.9284 - auc: 0.9751 - binary_accuracy: 0.9284 - recall_11: 0.8382 - precision_11: 0.9044 - val_loss: 0.7915 - val_acc: 0.6694 - val_auc: 0.6388 - val_binary_accuracy: 0.6694 - val_recall_11: 0.3389 - val_precision_11: 0.5299\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 6s 130ms/step - loss: 0.1192 - acc: 0.9604 - auc: 0.9929 - binary_accuracy: 0.9604 - recall_11: 0.9094 - precision_11: 0.9497 - val_loss: 0.7957 - val_acc: 0.6677 - val_auc: 0.6517 - val_binary_accuracy: 0.6677 - val_recall_11: 0.3643 - val_precision_11: 0.5238\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 5s 124ms/step - loss: 0.0777 - acc: 0.9783 - auc: 0.9968 - binary_accuracy: 0.9783 - recall_11: 0.9538 - precision_11: 0.9700 - val_loss: 0.9277 - val_acc: 0.6051 - val_auc: 0.6224 - val_binary_accuracy: 0.6051 - val_recall_11: 0.4102 - val_precision_11: 0.4231\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 6s 130ms/step - loss: 0.0507 - acc: 0.9875 - auc: 0.9991 - binary_accuracy: 0.9875 - recall_11: 0.9743 - precision_11: 0.9819 - val_loss: 1.1552 - val_acc: 0.5972 - val_auc: 0.5963 - val_binary_accuracy: 0.5972 - val_recall_11: 0.2522 - val_precision_11: 0.3729\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0385 - acc: 0.9910 - auc: 0.9993 - binary_accuracy: 0.9910 - recall_11: 0.9782 - precision_11: 0.9902 - val_loss: 1.1056 - val_acc: 0.5898 - val_auc: 0.6361 - val_binary_accuracy: 0.5898 - val_recall_11: 0.5452 - val_precision_11: 0.4246\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0346 - acc: 0.9916 - auc: 0.9991 - binary_accuracy: 0.9916 - recall_11: 0.9807 - precision_11: 0.9896 - val_loss: 1.1737 - val_acc: 0.5937 - val_auc: 0.6411 - val_binary_accuracy: 0.5937 - val_recall_11: 0.4777 - val_precision_11: 0.4199\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 6s 130ms/step - loss: 0.0557 - acc: 0.9798 - auc: 0.9975 - binary_accuracy: 0.9798 - recall_11: 0.9615 - precision_11: 0.9677 - val_loss: 1.5133 - val_acc: 0.6480 - val_auc: 0.5737 - val_binary_accuracy: 0.6480 - val_recall_11: 0.2318 - val_precision_11: 0.4752\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0211 - acc: 0.9947 - auc: 0.9994 - binary_accuracy: 0.9947 - recall_11: 0.9878 - precision_11: 0.9935 - val_loss: 1.4806 - val_acc: 0.5832 - val_auc: 0.5884 - val_binary_accuracy: 0.5832 - val_recall_11: 0.3401 - val_precision_11: 0.3809\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0113 - acc: 0.9985 - auc: 0.9996 - binary_accuracy: 0.9985 - recall_11: 0.9974 - precision_11: 0.9974 - val_loss: 1.6837 - val_acc: 0.5639 - val_auc: 0.5660 - val_binary_accuracy: 0.5639 - val_recall_11: 0.3210 - val_precision_11: 0.3524\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0062 - acc: 0.9991 - auc: 1.0000 - binary_accuracy: 0.9991 - recall_11: 0.9974 - precision_11: 0.9994 - val_loss: 1.6462 - val_acc: 0.5727 - val_auc: 0.5792 - val_binary_accuracy: 0.5727 - val_recall_11: 0.4025 - val_precision_11: 0.3840\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0045 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_11: 0.9987 - precision_11: 1.0000 - val_loss: 1.7269 - val_acc: 0.5525 - val_auc: 0.5765 - val_binary_accuracy: 0.5525 - val_recall_11: 0.4599 - val_precision_11: 0.3764\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0051 - acc: 0.9998 - auc: 0.9997 - binary_accuracy: 0.9998 - recall_11: 0.9994 - precision_11: 1.0000 - val_loss: 1.8486 - val_acc: 0.5368 - val_auc: 0.5726 - val_binary_accuracy: 0.5368 - val_recall_11: 0.5567 - val_precision_11: 0.3810\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0040 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_11: 0.9994 - precision_11: 1.0000 - val_loss: 1.9046 - val_acc: 0.5381 - val_auc: 0.5773 - val_binary_accuracy: 0.5381 - val_recall_11: 0.5720 - val_precision_11: 0.3844\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0053 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_11: 0.9987 - precision_11: 0.9987 - val_loss: 1.8540 - val_acc: 0.5648 - val_auc: 0.5825 - val_binary_accuracy: 0.5648 - val_recall_11: 0.5159 - val_precision_11: 0.3974\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 5s 126ms/step - loss: 0.0025 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_11: 1.0000 - precision_11: 1.0000 - val_loss: 1.8222 - val_acc: 0.5727 - val_auc: 0.5682 - val_binary_accuracy: 0.5727 - val_recall_11: 0.3771 - val_precision_11: 0.3780\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 5s 126ms/step - loss: 0.0035 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_11: 0.9994 - precision_11: 0.9994 - val_loss: 2.2142 - val_acc: 0.5184 - val_auc: 0.5503 - val_binary_accuracy: 0.5184 - val_recall_11: 0.5707 - val_precision_11: 0.3699\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 5s 127ms/step - loss: 0.0021 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_11: 1.0000 - precision_11: 0.9994 - val_loss: 1.9467 - val_acc: 0.5539 - val_auc: 0.5675 - val_binary_accuracy: 0.5539 - val_recall_11: 0.4382 - val_precision_11: 0.3731\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0011 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_11: 1.0000 - precision_11: 1.0000 - val_loss: 2.0309 - val_acc: 0.5517 - val_auc: 0.5617 - val_binary_accuracy: 0.5517 - val_recall_11: 0.4420 - val_precision_11: 0.3719\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 6s 131ms/step - loss: 9.0873e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_11: 1.0000 - precision_11: 1.0000 - val_loss: 2.0718 - val_acc: 0.5460 - val_auc: 0.5587 - val_binary_accuracy: 0.5460 - val_recall_11: 0.4268 - val_precision_11: 0.3633\n",
      "0.7450645565986633\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "178aa29c-8b19-4b53-991d-8fb7737613a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3927caaa-7800-46ee-8b9c-698f01a52929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.5416666666666666 MSE:  0.4583333333333333 UAR:  0.592436974789916 Recall:  0.7142857142857143 Precision:  0.35714285714285715 F1:  0.4761904761904762\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.5208333333333334 MSE:  0.4791666666666667 UAR:  0.5567226890756303 Recall:  0.6428571428571429 Precision:  0.3333333333333333 F1:  0.43902439024390244\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.5 MSE:  0.5 UAR:  0.5210084033613445 Recall:  0.5714285714285714 Precision:  0.3076923076923077 F1:  0.4\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.5208333333333334 MSE:  0.4791666666666667 UAR:  0.5357142857142857 Recall:  0.5714285714285714 Precision:  0.32 F1:  0.41025641025641024\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.5208333333333334 MSE:  0.4791666666666667 UAR:  0.5357142857142857 Recall:  0.5714285714285714 Precision:  0.32 F1:  0.41025641025641024\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.5416666666666666 MSE:  0.4583333333333333 UAR:  0.5504201680672269 Recall:  0.5714285714285714 Precision:  0.3333333333333333 F1:  0.4210526315789474\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.5416666666666666 MSE:  0.4583333333333333 UAR:  0.5084033613445378 Recall:  0.42857142857142855 Precision:  0.3 F1:  0.3529411764705882\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.5416666666666666 MSE:  0.4583333333333333 UAR:  0.4873949579831933 Recall:  0.35714285714285715 Precision:  0.2777777777777778 F1:  0.31250000000000006\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5105042016806722 Recall:  0.2857142857142857 Precision:  0.3076923076923077 F1:  0.29629629629629634\n",
      "0.1 0.592436974789916\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d0c64119-6f0d-4147-ac3d-4c866836a29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "bfe10083-a048-49eb-9995-b97d20a47472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b9046195-56f8-4558-9f2a-70efe47c5472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.5 MSE:  0.5 UAR:  0.5840336134453781 Recall:  0.7857142857142857 Precision:  0.34375 F1:  0.4782608695652174\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.625 MSE:  0.375 UAR:  0.6302521008403361 Recall:  0.6428571428571429 Precision:  0.4090909090909091 F1:  0.5000000000000001\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6911764705882353 Recall:  0.5 Precision:  0.6363636363636364 F1:  0.56\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5063025210084033 Recall:  0.07142857142857142 Precision:  0.3333333333333333 F1:  0.11764705882352941\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5357142857142857 Recall:  0.07142857142857142 Precision:  1.0 F1:  0.13333333333333333\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5357142857142857 Recall:  0.07142857142857142 Precision:  1.0 F1:  0.13333333333333333\n",
      "0.4 0.6911764705882353\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d32b1-03fc-4ca4-bc11-333e741a5a7c",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "491ce530-0fb8-4b6e-b6d9-c1d3f0550227",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c79d316-39b9-436b-a54b-9d562125daa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ccd3531-b083-4e02-b89e-26e7ec455fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58f619ca-8ca0-4103-a841-847c58acf4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147, 2048) (147,)\n",
      "(48, 2048) (48,)\n",
      "(195, 2048) (195,)\n",
      "[0 1] [141  54]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.759)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36812f26-f97d-4317-96b8-2b138ba31341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4acc34-36d8-4fc1-95b6-502f61f4f0ff",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67d1fe28-1877-4f6d-b063-e79cf0897eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d079d16-1e3e-4fb8-a58b-89d091954d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "648be070-d781-47fc-8998-1a95ee41f8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 3072) (5631,)\n",
      "(2102, 128, 3072) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "593fa723-b8bc-4b86-b8f0-c860011e3993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 08:14:20.359963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1573376   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1576962 (6.02 MB)\n",
      "Trainable params: 1576962 (6.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4eb34668-fc19-4b8d-8721-e6b5a315bbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 08:14:31.460675: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f36bbf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-30 08:14:31.460844: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-30 08:14:31.464965: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-30 08:14:31.510415: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-07-30 08:14:31.563412: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 8s 123ms/step - loss: 0.3858 - acc: 0.8304 - auc: 0.8784 - binary_accuracy: 0.8304 - recall: 0.6104 - precision: 0.7823 - val_loss: 0.7626 - val_acc: 0.6665 - val_auc: 0.6457 - val_binary_accuracy: 0.6665 - val_recall: 0.3291 - val_precision: 0.4318\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.1524 - acc: 0.9433 - auc: 0.9869 - binary_accuracy: 0.9433 - recall: 0.8670 - precision: 0.9415 - val_loss: 0.9998 - val_acc: 0.6056 - val_auc: 0.6323 - val_binary_accuracy: 0.6056 - val_recall: 0.2520 - val_precision: 0.3113\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.0812 - acc: 0.9718 - auc: 0.9975 - binary_accuracy: 0.9718 - recall: 0.9262 - precision: 0.9796 - val_loss: 1.1166 - val_acc: 0.6598 - val_auc: 0.6427 - val_binary_accuracy: 0.6598 - val_recall: 0.3669 - val_precision: 0.4267\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.0486 - acc: 0.9874 - auc: 0.9995 - binary_accuracy: 0.9874 - recall: 0.9649 - precision: 0.9934 - val_loss: 1.2219 - val_acc: 0.6746 - val_auc: 0.6649 - val_binary_accuracy: 0.6746 - val_recall: 0.3811 - val_precision: 0.4540\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.0304 - acc: 0.9957 - auc: 0.9999 - binary_accuracy: 0.9957 - recall: 0.9889 - precision: 0.9970 - val_loss: 1.2785 - val_acc: 0.6941 - val_auc: 0.6713 - val_binary_accuracy: 0.6941 - val_recall: 0.4016 - val_precision: 0.4923\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.0234 - acc: 0.9957 - auc: 0.9999 - binary_accuracy: 0.9957 - recall: 0.9895 - precision: 0.9965 - val_loss: 1.3624 - val_acc: 0.7036 - val_auc: 0.6779 - val_binary_accuracy: 0.7036 - val_recall: 0.4646 - val_precision: 0.5104\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.0183 - acc: 0.9970 - auc: 1.0000 - binary_accuracy: 0.9970 - recall: 0.9930 - precision: 0.9971 - val_loss: 1.5535 - val_acc: 0.6970 - val_auc: 0.6722 - val_binary_accuracy: 0.6970 - val_recall: 0.3606 - val_precision: 0.4978\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.0099 - acc: 0.9995 - auc: 1.0000 - binary_accuracy: 0.9995 - recall: 0.9988 - precision: 0.9994 - val_loss: 1.5459 - val_acc: 0.7074 - val_auc: 0.6753 - val_binary_accuracy: 0.7074 - val_recall: 0.4031 - val_precision: 0.5203\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.0069 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall: 0.9994 - precision: 0.9994 - val_loss: 1.6713 - val_acc: 0.7150 - val_auc: 0.6686 - val_binary_accuracy: 0.7150 - val_recall: 0.3638 - val_precision: 0.5423\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.0054 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall: 0.9994 - precision: 0.9994 - val_loss: 1.6704 - val_acc: 0.7060 - val_auc: 0.6747 - val_binary_accuracy: 0.7060 - val_recall: 0.4189 - val_precision: 0.5165\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.0042 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall: 1.0000 - precision: 0.9994 - val_loss: 1.7844 - val_acc: 0.7117 - val_auc: 0.6670 - val_binary_accuracy: 0.7117 - val_recall: 0.3732 - val_precision: 0.5326\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.0034 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.8123 - val_acc: 0.7093 - val_auc: 0.6736 - val_binary_accuracy: 0.7093 - val_recall: 0.3984 - val_precision: 0.5249\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.0033 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.8047 - val_acc: 0.7012 - val_auc: 0.6750 - val_binary_accuracy: 0.7012 - val_recall: 0.4142 - val_precision: 0.5067\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.0023 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.8749 - val_acc: 0.7060 - val_auc: 0.6720 - val_binary_accuracy: 0.7060 - val_recall: 0.3969 - val_precision: 0.5175\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.0020 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.8857 - val_acc: 0.7060 - val_auc: 0.6739 - val_binary_accuracy: 0.7060 - val_recall: 0.4094 - val_precision: 0.5169\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.0017 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.9161 - val_acc: 0.7027 - val_auc: 0.6748 - val_binary_accuracy: 0.7027 - val_recall: 0.4142 - val_precision: 0.5097\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.0014 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.9330 - val_acc: 0.7036 - val_auc: 0.6770 - val_binary_accuracy: 0.7036 - val_recall: 0.4189 - val_precision: 0.5115\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.0012 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.9804 - val_acc: 0.7031 - val_auc: 0.6770 - val_binary_accuracy: 0.7031 - val_recall: 0.4220 - val_precision: 0.5105\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.0011 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 2.0085 - val_acc: 0.7017 - val_auc: 0.6774 - val_binary_accuracy: 0.7017 - val_recall: 0.4063 - val_precision: 0.5079\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 9.8342e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 2.0640 - val_acc: 0.7065 - val_auc: 0.6728 - val_binary_accuracy: 0.7065 - val_recall: 0.3969 - val_precision: 0.5185\n",
      "0.7625898718833923\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b00f562-ee20-4eda-b476-fd056294ca0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4087404/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51e7e492-e8bb-456b-9169-88547350501e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6176470588235294 Recall:  0.5 Precision:  0.4375 F1:  0.4666666666666667\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6407563025210083 Recall:  0.42857142857142855 Precision:  0.5454545454545454 F1:  0.4799999999999999\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.75 MSE:  0.25 UAR:  0.6554621848739496 Recall:  0.42857142857142855 Precision:  0.6 F1:  0.5\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.75 MSE:  0.25 UAR:  0.634453781512605 Recall:  0.35714285714285715 Precision:  0.625 F1:  0.45454545454545453\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "0.3 0.6554621848739496\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ca9870e-ac9c-4ed9-86aa-09c1529969ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90de8cb9-7713-4d5e-8314-628c91916b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4087404/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a7e94a3-8e25-4b59-ba42-bd5453468ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.5208333333333334 MSE:  0.4791666666666667 UAR:  0.5777310924369747 Recall:  0.7142857142857143 Precision:  0.3448275862068966 F1:  0.46511627906976755\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6596638655462186 Recall:  0.6428571428571429 Precision:  0.45 F1:  0.5294117647058824\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6533613445378151 Recall:  0.5714285714285714 Precision:  0.47058823529411764 F1:  0.5161290322580646\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6050420168067226 Recall:  0.35714285714285715 Precision:  0.5 F1:  0.41666666666666663\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5840336134453781 Recall:  0.2857142857142857 Precision:  0.5 F1:  0.36363636363636365\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5630252100840336 Recall:  0.21428571428571427 Precision:  0.5 F1:  0.3\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.592436974789916 Recall:  0.21428571428571427 Precision:  0.75 F1:  0.3333333333333333\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.5714285714285714 Recall:  0.14285714285714285 Precision:  1.0 F1:  0.25\n",
      "0.2 0.6596638655462186\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cd3671-5192-4c16-8264-fd46d08a4900",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d696040-17fe-4d3f-a598-9d20fec27e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab03fed4-6cd7-4462-b0ae-130a6418eea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d025517-89fb-4cdf-bf69-4306b16a45e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 3072) (5631,)\n",
      "(2102, 128, 3072) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7f65b27-d7ff-4a8f-8804-a25eeb0a3cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 08:30:39.929705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 3072)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    3073      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18880514 (72.02 MB)\n",
      "Trainable params: 18880514 (72.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9dcdbc9c-66dc-4064-9460-e7cdbd23db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e81117d-15ce-4532-9d80-524d1127fcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4095000/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13347845-daa4-4a6b-918c-a2730823ceab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6386554621848739 Recall:  0.5714285714285714 Precision:  0.4444444444444444 F1:  0.5\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6533613445378151 Recall:  0.5714285714285714 Precision:  0.47058823529411764 F1:  0.5161290322580646\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6260504201680672 Recall:  0.42857142857142855 Precision:  0.5 F1:  0.4615384615384615\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6407563025210083 Recall:  0.42857142857142855 Precision:  0.5454545454545454 F1:  0.4799999999999999\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6407563025210083 Recall:  0.42857142857142855 Precision:  0.5454545454545454 F1:  0.4799999999999999\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6407563025210083 Recall:  0.42857142857142855 Precision:  0.5454545454545454 F1:  0.4799999999999999\n",
      "0.2 0.6533613445378151\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e31fae0-8882-4e26-b58c-72a27f9f547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    modelAtn.set_weights(best_model_weights)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91c22d6d-fc86-42bc-9b1b-791e0bc24892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4095000/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f34d57d-8a9a-438e-9470-48f3e1f9e6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.4375 MSE:  0.5625 UAR:  0.5819327731092437 Recall:  0.9285714285714286 Precision:  0.3333333333333333 F1:  0.4905660377358491\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.6785714285714286 Recall:  0.8571428571428571 Precision:  0.41379310344827586 F1:  0.5581395348837208\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.73109243697479 Recall:  0.7857142857142857 Precision:  0.5 F1:  0.6111111111111112\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6827731092436975 Recall:  0.5714285714285714 Precision:  0.5333333333333333 F1:  0.5517241379310344\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6764705882352942 Recall:  0.5 Precision:  0.5833333333333334 F1:  0.5384615384615384\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6407563025210083 Recall:  0.42857142857142855 Precision:  0.5454545454545454 F1:  0.4799999999999999\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6197478991596639 Recall:  0.35714285714285715 Precision:  0.5555555555555556 F1:  0.43478260869565216\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5483193277310924 Recall:  0.21428571428571427 Precision:  0.42857142857142855 F1:  0.2857142857142857\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6071428571428571 Recall:  0.21428571428571427 Precision:  1.0 F1:  0.35294117647058826\n",
      "0.3 0.73109243697479\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0ab158-318f-445a-b774-8f15055a2ae5",
   "metadata": {},
   "source": [
    "# DAiSEE dataset (4 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23a7dc29-b807-451a-b8a8-b60a1bc6f017",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_DIR = DATA_DIR + 'features_DAiSEE/'\n",
    "WEIGHTS_DIR = DATA_DIR + 'weights_DAiSEE/'\n",
    "TABLE_NAME = '02_DAiSEE_4_classes.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756e5a1-ebff-4271-a7d5-db3925d92d4a",
   "metadata": {},
   "source": [
    "## enet_b0_8_best_afew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5ee3138-e033-4ae4-83eb-3d4a54d6f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_key = 'enet_b0_8_best_afew.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "606239de-c805-4079-9451-8be70a198e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['very distracted', 'distracted', 'engaged', 'very engaged']\n",
      "{'1100011002': 0.66, '1100011003': 0.66, '1100011004': 1.0, '1100011005': 1.0, '1100011006': 1.0, '1100011007': 0.66, '1100011008': 1.0, '1100011009': 0.66, '1100011010': 1.0, '1100011011': 1.0, '1100011012': 0.66, '1100011013': 1.0, '1100011014': 1.0, '1100011015': 1.0, '1100011016': 1.0, '1100011017': 1.0, '1100011018': 1.0, '1100011019': 1.0, '1100011020': 1.0, '1100011021': 1.0, '1100011022': 1.0, '1100011023': 1.0, '1100011025': 1.0, '1100011026': 1.0, '1100011027': 1.0, '1100011028': 1.0, '1100011029': 1.0, '1100011031': 1.0, '1100011032': 1.0, '1100011034': 1.0, '1100011035': 1.0, '1100011037': 1.0, '1100011038': 1.0, '1100011040': 0.66, '1100011046': 1.0, '1100011047': 1.0, '1100011048': 0.66, '1100011049': 1.0, '1100011050': 1.0, '1100011051': 1.0, '1100011052': 1.0, '1100011053': 1.0, '1100011054': 1.0, '1100011055': 1.0, '1100011056': 1.0, '1100011057': 1.0, '1100011058': 1.0, '1100011059': 1.0, '1100011060': 1.0, '1100011062': 1.0, '1100011063': 1.0, '1100011064': 1.0, '1100011066': 1.0, '1100011067': 1.0, '1100011068': 1.0, '1100011069': 1.0, '1100011070': 1.0, '1100011071': 1.0, '1100011072': 1.0, '1100011073': 1.0, '1100011075': 1.0, '1100011076': 1.0, '1100011078': 0.66, '1100011079': 1.0, '1100011080': 1.0, '1100011081': 1.0, '1100011082': 1.0, '1100011083': 1.0, '1100012001': 1.0, '1100012003': 1.0, '1100012007': 1.0, '1100012008': 1.0, '1100012009': 1.0, '1100012010': 1.0, '1100012011': 1.0, '1100012013': 1.0, '1100012014': 1.0, '1100012015': 1.0, '1100012016': 1.0, '1100012017': 1.0, '1100012018': 1.0, '1100012021': 0.66, '1100012022': 1.0, '1100012023': 1.0, '1100012025': 1.0, '1100012026': 1.0, '1100012027': 1.0, '1100012028': 1.0, '1100012030': 1.0, '1100012031': 1.0, '1100012032': 1.0, '1100012033': 1.0, '1100012036': 1.0, '1100012037': 1.0, '1100012038': 1.0, '1100012041': 1.0, '1100012042': 0.66, '1100012045': 0.66, '1100012046': 1.0, '1100012047': 0.66, '1100012049': 1.0, '1100012050': 1.0, '1100012051': 1.0, '1100012052': 1.0, '1100012057': 1.0, '1100012059': 1.0, '1100012060': 1.0, '1100012061': 1.0, '1100012062': 1.0, '1100012063': 1.0, '1100012064': 1.0, '1100012065': 1.0, '1100012066': 1.0, '1100012069': 1.0, '1100021001': 0.66, '1100021003': 0.33, '1100021015': 0.66, '1100021038': 0.66, '1100021039': 0.66, '1100021040': 1.0, '1100021045': 1.0, '1100021050': 1.0, '1100021055': 0.33, '1100022001': 1.0, '1100022002': 0.66, '1100022003': 1.0, '1100022004': 1.0, '1100022005': 0.33, '1100022008': 0.66, '1100022009': 1.0, '1100022014': 1.0, '1100022019': 1.0, '1100022020': 0.66, '1100022021': 0.66, '1100022022': 0.66, '1100022026': 1.0, '1100022027': 1.0, '1100022028': 1.0, '1100022029': 1.0, '1100022031': 1.0, '1100022035': 0.66, '1100022038': 1.0, '1100022039': 1.0, '1100022045': 1.0, '1100022046': 1.0, '1100022047': 1.0, '1100022048': 0.66, '1100022049': 0.66, '1100022051': 1.0, '1100022052': 0.66, '1100022053': 0.66, '1100022054': 0.66, '1100022055': 0.66, '1100022056': 1.0, '1100022057': 0.66, '1100041006': 1.0, '1100041015': 1.0, '1100041016': 1.0, '1100041017': 0.66, '1100041018': 0.66, '1100041021': 0.66, '1100041022': 0.66, '1100041023': 0.66, '1100041024': 0.66, '1100041029': 1.0, '1100041034': 0.66, '1100041044': 0.66, '1100041051': 1.0, '1100041052': 0.66, '1100042009': 0.66, '1100042010': 0.66, '1100042011': 0.66, '1100042017': 0.66, '1100042018': 0.66, '1100042019': 1.0, '1100042020': 1.0, '1100042023': 0.33, '1100042024': 0.66, '1100042025': 0.66, '1100042026': 0.33, '1100042029': 1.0, '1100042030': 0.66, '1100042031': 1.0, '1100042034': 0.66, '1100042040': 0.66, '1100042041': 1.0, '1100042058': 0.66, '1100042059': 0.66, '1100042060': 0.66, '1100051002': 0.66, '1100051004': 0.66, '1100051006': 0.66, '1100051007': 0.33, '1100051008': 0.66, '1100051009': 0.66, '1100051011': 0.66, '1100051012': 0.66, '1100051013': 0.66, '1100051014': 0.66, '1100051016': 0.33, '1100051017': 0.66, '1100051019': 1.0, '1100051020': 0.66, '1100051021': 0.66, '1100051022': 0.66, '1100051023': 0.66, '1100051024': 0.66, '1100051025': 0.66, '1100051026': 0.66, '1100051028': 0.66, '1100051029': 0.66, '1100051030': 0.33, '1100051031': 0.33, '1100051032': 1.0, '1100051033': 0.66, '1100051034': 0.66, '1100051035': 0.66, '1100051036': 0.66, '1100051037': 0.66, '1100051039': 0.66, '1100051041': 1.0, '1100051042': 0.66, '1100051044': 0.66, '1100051045': 1.0, '1100051046': 0.66, '1100051048': 0.66, '1100051049': 0.66, '1100051050': 1.0, '1100051051': 0.66, '1100051052': 0.66, '1100051053': 0.33, '1100051054': 0.66, '1100051055': 0.66, '1100051056': 0.66, '1100051057': 1.0, '1100051059': 1.0, '1100051061': 0.66, '1100051062': 1.0, '1100051064': 1.0, '1100051065': 0.66, '1100051066': 1.0, '1100051067': 1.0, '1100051068': 1.0, '1100051071': 1.0, '1100051076': 0.66, '1100051078': 0.66, '1100051079': 1.0, '1100052001': 0.66, '1100052002': 0.66, '1100052006': 0.66, '1100052007': 0.66, '1100052008': 1.0, '1100052009': 0.66, '1100052014': 0.33, '1100052023': 0.66, '1100052024': 0.66, '1100052026': 0.66, '1100052027': 0.66, '1100052028': 1.0, '1100052030': 0.66, '1100052031': 0.66, '1100052032': 0.66, '1100052033': 0.66, '1100052035': 0.66, '1100052036': 0.66, '1100052037': 0.66, '1100052038': 0.66, '1100052039': 0.66, '1100052040': 1.0, '1100052041': 0.66, '1100052047': 0.66, '1100052048': 0.66, '1100052049': 0.66, '1100052051': 0.66, '1100052055': 0.66, '1100052057': 0.66, '1100052060': 1.0, '1100052061': 0.66, '1100052062': 0.66, '1100052065': 1.0, '1100052068': 0.66, '1100052070': 0.66, '1100061009': 1.0, '1100061010': 1.0, '1100061011': 1.0, '1100061012': 0.66, '1100061013': 1.0, '1100061015': 0.66, '1100061016': 0.66, '1100061018': 0.66, '1100061019': 0.66, '1100061022': 1.0, '1100061023': 0.66, '1100061025': 0.66, '1100061027': 1.0, '1100061028': 0.66, '1100061030': 0.66, '1100061031': 0.66, '1100061032': 0.66, '1100061033': 1.0, '1100061034': 0.66, '1100061035': 0.66, '1100061036': 1.0, '1100061038': 1.0, '1100061039': 0.66, '1100061040': 1.0, '1100061042': 1.0, '1100061043': 1.0, '1100061044': 0.66, '1100061046': 1.0, '1100061047': 1.0, '1100061048': 1.0, '1100061049': 0.66, '1100061050': 0.66, '1100061051': 1.0, '1100061053': 0.66, '1100061057': 0.66, '1100061058': 0.66, '1100061061': 1.0, '1100061063': 1.0, '1100061064': 1.0, '1100061067': 1.0, '1100061068': 1.0, '1100061069': 1.0, '1100061073': 0.66, '1100061074': 0.66, '1100061077': 0.66, '1100061078': 0.66, '1100062004': 1.0, '1100062005': 1.0, '1100062007': 1.0, '1100062008': 0.33, '1100062009': 1.0, '1100062016': 0.66, '1100062017': 1.0, '1100062024': 0.66, '1100062028': 0.66, '1100062029': 0.66, '1100062036': 0.66, '1100062037': 0.66, '1100062044': 0.66, '1100062045': 0.33, '1100062046': 0.66, '1100062049': 0.33, '1100062051': 0.66, '1100062053': 1.0, '1100062054': 0.66, '1100062059': 0.66, '1100062060': 0.66, '1100062061': 0.66, '1100062062': 0.66, '1100062063': 0.66, '1100062064': 0.66, '1100062065': 0.66, '1100062066': 1.0, '1100062067': 1.0, '1100062068': 0.66, '1100062069': 0.66, '1100062070': 0.66, '1100062071': 1.0, '1100062072': 1.0, '1100071005': 0.66, '1100071006': 0.66, '1100071007': 0.66, '1100071008': 1.0, '1100071009': 0.66, '1100071010': 0.66, '1100071011': 0.66, '1100071012': 1.0, '1100071013': 0.66, '1100071014': 1.0, '1100071015': 0.66, '1100071016': 1.0, '1100071017': 0.66, '1100071018': 0.66, '1100071019': 0.66, '1100071020': 0.66, '1100071021': 1.0, '1100071022': 0.66, '1100071023': 0.66, '1100071024': 0.66, '1100071026': 0.66, '1100071027': 0.66, '1100071028': 0.66, '1100071029': 0.66, '1100071030': 1.0, '1100071031': 1.0, '1100071032': 0.66, '1100071033': 0.66, '1100071034': 1.0, '1100071035': 0.66, '1100071036': 0.66, '1100071037': 0.66, '1100071040': 1.0, '1100071041': 0.66, '1100071042': 0.66, '1100071043': 1.0, '1100071044': 0.66, '1100071045': 0.66, '1100071046': 0.66, '1100071047': 0.66, '1100071049': 0.66, '1100071050': 1.0, '1100071052': 0.66, '1100071054': 0.66, '1100071055': 1.0, '1100071056': 0.66, '1100071057': 1.0, '1100071058': 0.66, '1100071059': 0.66, '1100071060': 0.66, '1100071061': 1.0, '1100071062': 0.66, '1100071063': 1.0, '1100071064': 1.0, '1100071065': 0.66, '1100071066': 0.66, '1100071067': 1.0, '1100071069': 0.66, '1100071070': 1.0, '1100071071': 0.66, '1100071072': 0.66, '1100071073': 0.66, '1100071074': 0.66, '1100071075': 0.66, '1100071076': 0.66, '1100071077': 1.0, '1100071078': 1.0, '1100071079': 1.0, '1100071080': 1.0, '1100071081': 1.0, '1100072001': 0.66, '1100072002': 1.0, '1100072003': 1.0, '1100072004': 0.66, '1100072006': 0.66, '1100072007': 0.66, '1100072008': 0.66, '1100072009': 1.0, '1100072010': 0.66, '1100072011': 1.0, '1100072012': 1.0, '1100072013': 0.66, '1100072014': 0.66, '1100072015': 0.66, '1100072016': 0.66, '1100072021': 0.66, '1100072022': 0.66, '1100072023': 1.0, '1100072024': 0.66, '1100072027': 0.66, '1100072028': 0.66, '1100072029': 0.66, '1100072030': 0.66, '1100072031': 0.66, '1100072032': 1.0, '1100072033': 1.0, '1100072034': 0.66, '1100072036': 0.66, '1100072037': 0.66, '1100072038': 0.66, '1100072039': 0.66, '1100072040': 0.66, '1100072042': 0.66, '1100072043': 1.0, '1100072045': 0.66, '1100072047': 1.0, '1100072048': 0.66, '1100072049': 0.66, '1100072050': 0.66, '1100072051': 1.0, '1100072052': 1.0, '1100072053': 0.66, '1100072054': 0.66, '1100072056': 0.66, '1100072057': 0.66, '1100072058': 1.0, '1100072059': 0.66, '1100072060': 0.66, '1100072061': 0.66, '1100072062': 0.66, '1100072063': 1.0, '1100072065': 0.66, '1100072066': 1.0, '1100072067': 0.66, '1100072068': 0.66, '1100072069': 0.66, '1100072070': 0.66, '1100072071': 0.66, '1100072072': 0.66, '1100072073': 0.66, '1100072074': 1.0, '1100072075': 0.66, '1100072076': 0.66, '1100072077': 1.0, '1100072078': 1.0, '1100072079': 0.66, '1100072080': 0.66, '1100072081': 0.66, '1100072082': 1.0, '1100072083': 0.66, '1100072084': 0.66, '1100072085': 0.66, '1100081044': 0.66, '1100081045': 0.66, '1100081046': 0.66, '1100081047': 1.0, '1100081048': 1.0, '1100082002': 1.0, '1100082003': 1.0, '1100082018': 0.66, '1100082027': 0.66, '1100102003': 0.66, '1100111001': 1.0, '1100111002': 1.0, '1100111003': 0.66, '1100111008': 0.66, '1100111009': 0.66, '1100111010': 1.0, '1100111011': 0.66, '1100111012': 0.66, '1100111013': 0.66, '1100111014': 0.66, '1100111016': 0.66, '1100111017': 0.66, '1100111018': 0.66, '1100111019': 0.66, '1100111021': 0.66, '1100111023': 1.0, '1100111025': 1.0, '1100111026': 0.66, '1100111027': 1.0, '1100111029': 0.66, '1100111030': 1.0, '1100111032': 0.66, '1100112001': 0.66, '1100112002': 0.33, '1100112003': 1.0, '1100112004': 1.0, '1100112006': 0.33, '1100112007': 1.0, '1100112008': 1.0, '1100112009': 1.0, '1100112010': 0.66, '1100112011': 0.66, '1100112012': 1.0, '1100112013': 0.66, '1100112014': 0.66, '1100112015': 1.0, '1100112016': 1.0, '1100112017': 1.0, '1100112018': 1.0, '1100112021': 0.66, '1100112022': 0.66, '1100112024': 1.0, '1100112025': 0.66, '1100112026': 0.66, '1100112029': 1.0, '1100112030': 1.0, '1100112033': 1.0, '1100112035': 0.66, '1100112036': 1.0, '1100112037': 1.0, '1100112038': 0.66, '1100112039': 1.0, '1100112040': 0.66, '1100112041': 0.66, '1100112042': 1.0, '1100112043': 0.66, '1100112044': 0.66, '1100112045': 0.66, '1100112047': 1.0, '1100112048': 0.66, '1100112051': 1.0, '1100112052': 1.0, '1100112053': 1.0, '1100112056': 0.66, '1100112057': 1.0, '1100112058': 0.66, '1100112059': 1.0, '1100112060': 1.0, '1100112061': 0.66, '1100112062': 0.66, '1100112063': 0.66, '1100112064': 1.0, '1100112065': 0.66, '1100112066': 1.0, '1100112068': 1.0, '1100121002': 1.0, '1100121003': 0.66, '1100121004': 1.0, '1100121005': 1.0, '1100121006': 1.0, '1100121007': 1.0, '1100121008': 1.0, '1100121009': 1.0, '1100121010': 1.0, '1100121011': 1.0, '1100121012': 1.0, '1100121015': 0.66, '1100121016': 1.0, '1100121017': 1.0, '1100121018': 0.66, '1100121019': 0.66, '1100121020': 1.0, '1100121024': 0.66, '1100121025': 0.66, '1100121028': 1.0, '1100121031': 0.66, '1100121032': 1.0, '1100121033': 0.66, '1100121034': 0.66, '1100121035': 1.0, '1100121036': 0.66, '1100121038': 1.0, '1100121040': 1.0, '1100121041': 0.66, '1100121042': 0.66, '1100121044': 1.0, '1100121045': 1.0, '1100121047': 1.0, '1100121049': 0.66, '1100121050': 1.0, '1100121052': 0.66, '1100121053': 1.0, '1100121054': 1.0, '1100121056': 0.66, '1100121057': 1.0, '1100121059': 0.66, '1100121060': 0.66, '1100121061': 0.66, '1100121064': 1.0, '1100122001': 0.66, '1100122002': 0.66, '1100122003': 0.66, '1100122005': 0.66, '1100122006': 1.0, '1100122007': 1.0, '1100122008': 1.0, '1100122009': 0.66, '1100122010': 1.0, '1100122011': 1.0, '1100122012': 1.0, '1100122013': 1.0, '1100122014': 1.0, '1100122015': 0.66, '1100122017': 0.66, '1100122018': 1.0, '1100122019': 1.0, '1100122020': 1.0, '1100122021': 0.66, '1100122023': 0.66, '1100122024': 1.0, '1100122025': 0.66, '1100122026': 0.66, '1100122031': 1.0, '1100122032': 1.0, '1100122033': 0.66, '1100122034': 1.0, '1100122035': 0.66, '1100122036': 1.0, '1100122037': 1.0, '1100122038': 1.0, '1100122039': 1.0, '1100122040': 0.66, '1100122041': 0.66, '1100122045': 0.66, '1100122047': 0.66, '1100122048': 1.0, '1100122050': 1.0, '1100122051': 0.66, '1100122052': 1.0, '1100122053': 0.66, '1100122054': 0.66, '1100122056': 0.33, '1100131006': 1.0, '1100131007': 0.66, '1100131009': 1.0, '1100131010': 1.0, '1100131011': 1.0, '1100131012': 1.0, '1100131017': 0.0, '1100131019': 1.0, '1100141001': 1.0, '1100141002': 0.66, '1100141003': 1.0, '1100141004': 1.0, '1100141005': 0.66, '1100141006': 0.66, '1100141007': 1.0, '1100141008': 0.66, '1100141009': 0.66, '1100141010': 1.0, '1100141011': 0.66, '1100141012': 0.66, '1100141013': 0.33, '1100141014': 0.66, '1100141015': 0.66, '1100141016': 1.0, '1100141017': 0.66, '1100141019': 0.66, '1100141020': 0.66, '1100141021': 0.66, '1100141023': 1.0, '1100141027': 0.33, '1100141028': 0.66, '1100141029': 0.66, '1100141030': 0.66, '1100141031': 0.66, '1100141032': 0.66, '1100141033': 0.66, '1100141034': 0.66, '1100141035': 0.66, '1100141036': 0.66, '1100141039': 1.0, '1100141040': 0.66, '1100141042': 0.66, '1100141044': 0.66, '1100141045': 1.0, '1100141046': 0.66, '1100141049': 0.66, '1100141050': 0.66, '1100141052': 0.66, '1100141053': 0.66, '1100141054': 1.0, '1100141055': 1.0, '1100141056': 0.66, '1100141057': 0.66, '1100142002': 1.0, '1100142003': 0.66, '1100142004': 0.66, '1100142007': 0.66, '1100142008': 0.66, '1100142009': 0.66, '1100142010': 0.66, '1100142011': 1.0, '1100142013': 0.66, '1100142014': 0.66, '1100142015': 0.66, '1100142017': 0.66, '1100142018': 0.66, '1100142019': 0.66, '1100142021': 1.0, '1100142022': 0.66, '1100142023': 0.66, '1100142024': 0.66, '1100142027': 1.0, '1100142028': 0.66, '1100142029': 1.0, '1100142030': 0.66, '1100142031': 0.66, '1100142032': 1.0, '1100142033': 0.33, '1100142034': 1.0, '1100142035': 1.0, '1100142038': 0.66, '1100142041': 1.0, '1100142043': 0.66, '1100142044': 0.66, '1100142045': 0.66, '1100142046': 1.0, '1100142048': 1.0, '1100142049': 0.66, '1100142050': 0.66, '1100142051': 0.66, '1100142052': 0.66, '1100142053': 1.0, '1100142056': 1.0, '1100142057': 1.0, '1100142058': 0.66, '1100142059': 0.66, '1100142060': 0.66, '1100151003': 0.66, '1100151004': 1.0, '1100151008': 1.0, '1100151009': 0.66, '1100151010': 0.66, '1100151011': 0.33, '1100151012': 0.66, '1100151013': 0.66, '1100151014': 1.0, '1100151015': 0.66, '1100151016': 0.66, '1100151017': 0.66, '1100151018': 0.66, '1100151019': 0.66, '1100151020': 0.66, '1100151021': 1.0, '1100151022': 1.0, '1100151023': 0.66, '1100151024': 0.66, '1100151028': 0.66, '1100151030': 0.66, '1100151032': 1.0, '1100151033': 0.66, '1100151035': 1.0, '1100151037': 1.0, '1100151038': 0.66, '1100151039': 0.66, '1100151040': 1.0, '1100151042': 1.0, '1100151043': 0.66, '1100151044': 0.66, '1100151047': 0.66, '1100151049': 1.0, '1100151050': 0.66, '1100151051': 0.66, '1100151052': 1.0, '1100151054': 1.0, '1100151055': 0.66, '1100151056': 1.0, '1100151057': 0.33, '1100151058': 0.66, '1100151062': 0.66, '1100152001': 0.66, '1100152004': 1.0, '1100152005': 0.66, '1100152006': 0.66, '1100152008': 0.66, '1100152009': 0.66, '1100152010': 0.33, '1100152013': 1.0, '1100152014': 0.66, '1100152015': 0.66, '1100152017': 0.33, '1100152019': 1.0, '1100152020': 1.0, '1100152022': 0.66, '1100152024': 0.66, '1100152025': 0.66, '1100152026': 0.66, '1100152027': 1.0, '1100152031': 0.33, '1100152032': 0.66, '1100152039': 1.0, '1100152040': 0.66, '1100152041': 0.66, '1100152042': 0.66, '1100152043': 0.66, '1100152048': 0.66, '1100152049': 0.66, '1100152050': 0.66, '1100152051': 0.66, '1100152055': 0.33, '1100152056': 0.66, '1100152061': 0.66, '1100152062': 0.66, '1100152067': 0.66, '1100152069': 0.66, '1100152070': 0.0, '1100161002': 0.66, '1100161004': 1.0, '1100161011': 1.0, '1100161012': 1.0, '1100161013': 0.66, '1100161014': 0.66, '1100161015': 1.0, '1100161016': 0.66, '1100161020': 1.0, '1100161021': 1.0, '1100161022': 0.66, '1100161023': 0.66, '1100161028': 0.66, '1100161029': 0.66, '1100161032': 0.66, '1100161035': 0.66, '1100161036': 0.66, '1100161038': 0.66, '1100161039': 1.0, '1100161041': 1.0, '1100161043': 1.0, '1100161044': 0.66, '1100161045': 0.66, '1100161046': 0.66, '1100161048': 0.66, '1100161050': 1.0, '1100161053': 0.33, '1100162005': 0.33, '1100162007': 0.66, '1100162011': 0.66, '1100162016': 0.33, '1100171001': 0.66, '1100171002': 0.66, '1100171004': 0.0, '1100171005': 0.66, '1100171007': 0.66, '1100171008': 0.0, '1100171009': 0.66, '1100171010': 0.66, '1100171011': 1.0, '1100171012': 0.66, '1100171013': 0.66, '1100171015': 0.66, '1100171016': 0.66, '1100171017': 0.66, '1100171019': 0.66, '1100171021': 1.0, '1100171022': 0.66, '1100171023': 0.66, '1100171031': 0.66, '1100171035': 0.66, '1100171036': 0.66, '1100171038': 1.0, '1100171039': 1.0, '1100171040': 1.0, '1100171041': 0.66, '1100171043': 0.66, '1100171045': 0.66, '1100171049': 0.66, '1100171055': 0.66, '1100171056': 1.0, '1100171057': 0.66, '1100171059': 0.33, '1100171061': 1.0, '1100171063': 1.0, '1100171064': 1.0, '1100171065': 0.66, '1100171067': 0.66, '1100171069': 1.0, '1100171070': 0.66, '1100171071': 1.0, '1100171072': 0.66, '1100171073': 1.0, '1100171074': 0.66, '1100171075': 0.66, '1100171076': 0.66, '1100171077': 1.0, '1100171078': 1.0, '1100171080': 0.66, '1100171083': 0.66, '1100172003': 0.66, '1100172004': 0.66, '1100172007': 0.66, '1100172012': 0.33, '1100172013': 0.66, '1100172014': 0.66, '1100172015': 0.66, '1100172016': 0.66, '1100172017': 0.33, '1100172018': 1.0, '1100172020': 0.66, '1100172021': 0.66, '1100172022': 0.66, '1100172026': 0.66, '1100172028': 0.66, '1100172030': 1.0, '1100172032': 0.66, '1100172033': 0.33, '1100172034': 0.33, '1100172035': 1.0, '1100172037': 0.66, '1100172039': 0.66, '1100172042': 0.66, '1100172043': 0.33, '1100172047': 1.0, '1100172050': 0.66, '1100172058': 0.33, '1100172063': 1.0, '1100172066': 0.66, '1100411010': 0.66, '1100411011': 1.0, '1100411012': 0.66, '1100411013': 1.0, '1100411015': 1.0, '1100411016': 1.0, '1100411018': 0.66, '1100411020': 0.66, '1100411023': 1.0, '1100411036': 0.66, '1100411041': 1.0, '1100411045': 1.0, '1100411047': 0.66, '1100411048': 0.66, '1100411049': 0.66, '1100411050': 1.0, '1100411051': 1.0, '1100411053': 1.0, '1100411054': 0.66, '1100411055': 0.66, '1100411057': 0.66, '1100412001': 1.0, '1100412003': 0.66, '1100412010': 0.66, '1100412018': 0.0, '1100412033': 0.33, '1100412038': 0.66, '1100412039': 0.33, '1100412040': 0.66, '1110031003': 0.66, '1110031007': 1.0, '1110031010': 0.33, '1110031011': 0.66, '1110031012': 1.0, '1110031014': 0.66, '1110031019': 0.66, '1110031020': 0.66, '1110031021': 0.66, '1110031025': 0.0, '1110031027': 0.33, '1110031031': 1.0, '1110031033': 0.33, '1110031037': 1.0, '1110031038': 0.0, '1110031039': 0.66, '1110031040': 1.0, '1110031042': 0.66, '1110031048': 0.66, '1110031049': 0.66, '1110031050': 1.0, '1110031056': 0.33, '1110031061': 0.66, '1110031062': 0.66, '1110031063': 0.0, '1110031064': 0.66, '1110031065': 1.0, '1110032002': 1.0, '1110032004': 0.66, '1110032006': 1.0, '1110032008': 0.66, '1110032010': 0.66, '1110032014': 0.33, '1110032015': 1.0, '1110032018': 1.0, '1110032019': 0.66, '1110032020': 0.66, '1110032021': 0.66, '1110032022': 0.66, '1110032023': 0.66, '1110032024': 1.0, '1110032025': 0.66, '1110032027': 0.33, '1110032029': 1.0, '1110032031': 0.66, '1110032032': 1.0, '1110032033': 1.0, '1110032034': 0.66, '1110032036': 1.0, '1110032037': 0.66, '1110032042': 0.66, '1110032043': 0.33, '1110032045': 0.66, '1110032047': 0.66, '1110032048': 0.66, '1110032049': 0.66, '1110032050': 1.0, '1110032051': 0.66, '1110032052': 1.0, '1110032053': 0.66, '1110032055': 0.66, '1110032056': 0.66, '1110032058': 1.0, '1110032059': 0.66, '1110032060': 1.0, '1110032061': 0.66, '1110032062': 0.66, '1110032063': 0.66, '1813740111': 1.0, '1813740112': 0.66, '1813740115': 1.0, '1813740116': 1.0, '1813740118': 0.66, '1813740119': 0.66, '1813740122': 0.66, '1813740123': 1.0, '1813740124': 0.66, '1813740126': 1.0, '1813740127': 1.0, '1813740128': 1.0, '1813740131': 0.66, '1813740133': 1.0, '1813740135': 0.66, '1813740137': 0.66, '1813740138': 0.0, '1813740143': 0.66, '1813740144': 0.66, '1813740149': 1.0, '181374015': 0.66, '1813740150': 0.66, '1813740153': 0.66, '1813740155': 0.66, '1813740157': 0.66, '1813740159': 0.66, '181374016': 1.0, '1813740162': 1.0, '1813740164': 1.0, '1813740165': 1.0, '1813740167': 1.0, '1813740168': 1.0, '1813740169': 0.66, '181374017': 0.66, '1813740171': 0.66, '1813740172': 1.0, '1813740173': 0.66, '1813740174': 1.0, '1813740176': 0.66, '1813740178': 0.66, '1813740179': 0.66, '1813740180': 0.66, '1813740181': 1.0, '1813740182': 1.0, '1813740183': 0.66, '1813740184': 0.33, '1813740185': 0.33, '181374019': 1.0, '1813740210': 1.0, '1813740211': 1.0, '1813740212': 0.66, '1813740213': 0.66, '1813740214': 1.0, '1813740218': 1.0, '1813740219': 1.0, '1813740220': 1.0, '1813740221': 1.0, '1813740224': 0.66, '1813740225': 0.66, '1813740226': 1.0, '1813740227': 0.66, '1813740229': 0.66, '181374023': 0.66, '1813740231': 1.0, '1813740232': 0.66, '1813740233': 0.66, '1813740234': 1.0, '1813740235': 0.66, '1813740236': 1.0, '1813740237': 1.0, '1813740238': 1.0, '181374024': 1.0, '1813740240': 1.0, '1813740241': 1.0, '1813740242': 1.0, '1813740243': 1.0, '1813740245': 1.0, '1813740249': 1.0, '181374025': 1.0, '1813740250': 0.66, '1813740251': 1.0, '1813740252': 1.0, '1813740253': 0.66, '1813740255': 1.0, '1813740256': 1.0, '1813740257': 1.0, '1813740258': 1.0, '1813740259': 1.0, '181374026': 0.66, '1813740260': 0.66, '1813740261': 1.0, '1813740262': 1.0, '1813740263': 1.0, '1813740264': 1.0, '1813740265': 1.0, '1813740266': 1.0, '1813740267': 0.66, '1813740268': 1.0, '1813740269': 0.66, '181374027': 0.66, '1813740270': 1.0, '1813740271': 0.66, '1813740272': 1.0, '1813740273': 1.0, '1813740274': 1.0, '1813740275': 0.66, '1813740276': 1.0, '1813740277': 1.0, '1813740278': 0.66, '1813740279': 1.0, '181374028': 1.0, '181374029': 1.0, '2000481035': 0.66, '2000481036': 1.0, '2000481037': 1.0, '2000481038': 1.0, '2000481039': 0.66, '2000481040': 0.66, '2000481041': 0.66, '2000481043': 0.66, '2000481048': 0.66, '2000482008': 0.66, '2000482009': 1.0, '2000482012': 0.66, '2000482018': 0.66, '2000482021': 0.66, '2000482034': 0.66, '2000482037': 0.66, '2000482038': 0.66, '2000482039': 1.0, '2000482041': 1.0, '2000482042': 0.66, '2000482043': 1.0, '2000482044': 0.66, '2000482049': 0.66, '2000482050': 0.66, '2000482052': 0.66, '2000482059': 1.0, '2000482065': 0.66, '2000482066': 1.0, '2000482067': 1.0, '2000482068': 1.0, '2000482070': 0.66, '2000491062': 0.66, '2000491064': 0.66, '2000491065': 0.66, '2000491066': 1.0, '2000491067': 0.66, '2000491068': 0.66, '2000491070': 0.66, '2000491072': 1.0, '2000491074': 0.66, '2000491075': 0.66, '2000491076': 0.66, '2000491077': 0.33, '2000491078': 0.66, '2000491079': 1.0, '2000501001': 1.0, '2000501002': 0.66, '2000501003': 0.66, '2000501004': 1.0, '2000501006': 0.33, '2000501009': 1.0, '2000501010': 1.0, '2000501011': 1.0, '2000501012': 0.66, '2000501014': 0.66, '2000501015': 1.0, '2000501016': 1.0, '2000501018': 0.66, '2000501019': 1.0, '2000501020': 1.0, '2000501021': 1.0, '2000501023': 1.0, '2000501027': 0.66, '2000501028': 0.66, '2000501030': 0.33, '2000501031': 0.66, '2000501032': 1.0, '2000501033': 1.0, '2000501035': 0.66, '2000501036': 1.0, '2000501037': 1.0, '2000501038': 1.0, '2000501039': 1.0, '2000501040': 1.0, '2000501041': 1.0, '2000501042': 0.66, '2000501043': 0.66, '2000501044': 1.0, '2000501045': 0.66, '2000501046': 0.66, '2000501049': 1.0, '2000501050': 0.66, '2000501051': 0.66, '2000501052': 1.0, '2000501053': 0.66, '2000501054': 1.0, '2000501056': 0.66, '2000501057': 0.66, '2000501060': 1.0, '2000501061': 0.66, '2000501062': 0.66, '2000501063': 1.0, '2000501065': 1.0, '2000501066': 1.0, '2000501067': 0.66, '2000501071': 1.0, '2000501074': 0.66, '2000501075': 1.0, '2000501076': 1.0, '2000501078': 1.0, '2000502002': 0.66, '2000502005': 0.66, '2000502006': 0.66, '2000502007': 0.66, '2000502009': 0.66, '2000502010': 1.0, '2000502012': 0.66, '2000502013': 1.0, '2000502014': 1.0, '2000502015': 0.66, '2000502019': 0.66, '2000502020': 0.66, '2000502023': 0.66, '2000502025': 1.0, '2000502033': 0.66, '2000502036': 0.66, '2000502037': 0.66, '2000502039': 0.66, '2000502040': 1.0, '2000502041': 0.66, '2000502043': 0.66, '2000502044': 1.0, '2000502045': 1.0, '2000502047': 1.0, '2000502048': 1.0, '2000502049': 0.66, '2000502050': 0.66, '2000502051': 0.66, '2000502053': 0.33, '2000502054': 1.0, '2000502055': 1.0, '2000502056': 0.66, '2000502057': 1.0, '2000502058': 0.66, '2000502059': 0.66, '2000502061': 0.66, '2000502062': 0.66, '2000502063': 0.66, '2000502065': 0.33, '2000502066': 0.66, '2000502067': 0.66, '2000502069': 0.66, '2000502070': 0.66, '2000502072': 0.66, '2000502073': 0.66, '2000502075': 0.66, '2000502076': 0.66, '2000502077': 0.66, '2000502078': 0.66, '2000502081': 0.33, '2000502084': 0.66, '2000502087': 0.66, '2000502088': 0.66, '2000502090': 0.66, '2000541001': 0.66, '2000541002': 0.66, '2000541003': 0.66, '2000541006': 0.66, '2000541007': 1.0, '2000541010': 1.0, '2000541011': 0.66, '2000541014': 1.0, '2000541015': 0.66, '2000541016': 0.66, '2000541018': 0.66, '2000541019': 1.0, '2000541020': 1.0, '2000541021': 1.0, '2000541022': 1.0, '2000541023': 0.66, '2000541024': 1.0, '2000541025': 1.0, '2000541027': 0.66, '2000541028': 1.0, '2000541029': 0.66, '2000541030': 1.0, '2000541031': 1.0, '2000541032': 1.0, '2000541034': 0.66, '2000541035': 0.66, '2000541038': 0.66, '2000541039': 0.66, '2000541040': 0.66, '2000541041': 0.66, '2000541043': 1.0, '2000541044': 1.0, '2000541045': 0.66, '2000541046': 0.66, '2000541049': 0.66, '2000541050': 1.0, '2000541051': 0.66, '2000541052': 0.66, '2000541053': 0.66, '2000541054': 0.66, '2000541055': 1.0, '2000541056': 1.0, '2000541057': 0.66, '2000541059': 1.0, '2000541062': 1.0, '2000541064': 0.66, '2000541066': 0.66, '2000541067': 0.66, '2000541068': 0.66, '2000541069': 0.66, '2000541070': 0.66, '2000541071': 0.66, '2000541072': 1.0, '2000541073': 1.0, '2000541074': 1.0, '2000541075': 0.66, '2000541076': 1.0, '2000541077': 0.66, '2000541079': 0.66, '2000541080': 1.0, '2000541081': 1.0, '2000542001': 0.66, '2000542002': 0.66, '2000542007': 0.66, '2000542008': 0.66, '2000542009': 0.66, '2000542010': 0.66, '2000542013': 1.0, '2000542015': 1.0, '2000542016': 0.66, '2000542021': 0.66, '2000542022': 0.66, '2000542025': 1.0, '2000542026': 1.0, '2000542027': 1.0, '2000542029': 1.0, '2000542030': 1.0, '2000542032': 0.66, '2000542033': 1.0, '2000542034': 0.66, '2000542035': 1.0, '2000542036': 0.66, '2000542042': 1.0, '2000542049': 0.66, '2000542050': 1.0, '2000542051': 0.66, '2000542052': 1.0, '2000542054': 0.66, '2000542056': 0.66, '2026140111': 1.0, '2026140113': 1.0, '2026140116': 1.0, '2026140117': 1.0, '2026140118': 0.66, '2026140119': 1.0, '2026140120': 1.0, '2026140122': 1.0, '2026140124': 0.66, '2026140125': 1.0, '2026140126': 0.66, '2026140128': 0.66, '2026140129': 1.0, '2026140130': 1.0, '2026140131': 1.0, '2026140133': 1.0, '2026140134': 1.0, '2026140135': 0.66, '2026140138': 1.0, '2026140141': 1.0, '2026140145': 0.66, '2026140147': 1.0, '2026140149': 0.66, '202614015': 1.0, '2026140151': 1.0, '2026140154': 0.66, '2026140158': 1.0, '2026140159': 1.0, '202614016': 1.0, '2026140160': 0.66, '2026140161': 1.0, '2026140165': 1.0, '2026140169': 1.0, '202614017': 1.0, '2026140170': 0.66, '2026140172': 0.66, '202614018': 1.0, '202614019': 0.66, '202614020': 1.0, '202614021': 1.0, '2026140210': 0.66, '2026140212': 1.0, '2026140213': 0.66, '2026140220': 0.66, '2026140221': 1.0, '2026140223': 1.0, '2026140224': 1.0, '2026140225': 0.66, '202614023': 1.0, '2026140230': 0.66, '2026140233': 0.66, '2026140236': 1.0, '2026140237': 0.66, '2026140239': 0.66, '2026140241': 1.0, '2026140243': 1.0, '2026140246': 1.0, '2026140247': 1.0, '2026140249': 1.0, '202614025': 1.0, '2026140250': 1.0, '2026140253': 0.66, '2026140254': 0.66, '2026140255': 0.66, '2026140257': 0.33, '2026140259': 1.0, '2026140260': 1.0, '2026140263': 0.66, '2026140264': 0.33, '2026140272': 1.0, '2026140273': 0.33, '2026140275': 1.0, '2026140276': 1.0, '2026140277': 1.0, '2026140279': 1.0, '2026140281': 1.0, '202614029': 0.66, '205601011': 1.0, '2056010112': 0.66, '2056010113': 0.66, '2056010114': 0.66, '2056010116': 0.66, '2056010118': 0.66, '2056010119': 0.66, '205601012': 0.66, '2056010120': 1.0, '2056010122': 1.0, '2056010123': 1.0, '2056010124': 1.0, '2056010126': 0.66, '2056010130': 0.66, '2056010133': 1.0, '2056010134': 0.0, '2056010136': 0.66, '2056010137': 0.66, '2056010139': 1.0, '2056010141': 1.0, '2056010142': 0.66, '2056010148': 0.66, '2056010149': 0.66, '2056010153': 1.0, '2056010155': 1.0, '2056010156': 0.66, '2056010157': 0.66, '205601016': 1.0, '2056010160': 1.0, '2056010162': 0.66, '2056010164': 0.66, '2056010165': 0.66, '2056010167': 1.0, '205601017': 1.0, '205601018': 0.66, '2056010210': 0.66, '2056010212': 1.0, '2056010213': 0.66, '2056010214': 1.0, '2056010215': 0.66, '2056010218': 1.0, '2056010219': 0.66, '2056010222': 0.66, '2056010224': 0.33, '2056010225': 1.0, '2056010226': 1.0, '2056010228': 1.0, '2056010229': 1.0, '2056010230': 1.0, '2056010232': 1.0, '2056010233': 1.0, '2056010234': 0.66, '2056010235': 1.0, '2056010236': 0.66, '2056010238': 1.0, '2056010239': 1.0, '205601024': 0.66, '2056010240': 0.66, '2056010241': 0.66, '2056010242': 0.66, '2056010244': 0.66, '2056010245': 0.66, '2056010247': 1.0, '2056010249': 1.0, '205601025': 1.0, '2056010250': 0.66, '2056010252': 0.66, '2056010253': 1.0, '2056010254': 1.0, '2056010255': 1.0, '2056010258': 0.66, '2056010260': 1.0, '2056010261': 0.66, '2056010262': 1.0, '2056010263': 1.0, '2056010265': 1.0, '2056010267': 0.66, '2056010269': 1.0, '205601027': 1.0, '2056010272': 0.66, '2056010274': 0.66, '2056010275': 1.0, '2056010276': 1.0, '2056010277': 1.0, '2056010279': 0.66, '205601028': 0.66, '2056010281': 1.0, '2056010283': 0.66, '2100511002': 1.0, '2100511003': 1.0, '2100511005': 0.66, '2100511008': 1.0, '2100511011': 0.66, '2100511012': 1.0, '2100511013': 0.66, '2100511015': 0.66, '2100511016': 1.0, '2100511018': 1.0, '2100511019': 0.66, '2100511024': 0.66, '2100511026': 0.66, '2100511027': 0.66, '2100511028': 1.0, '2100511031': 1.0, '2100511032': 0.66, '2100511034': 0.66, '2100511035': 0.66, '2100511036': 0.66, '2100511038': 1.0, '2100511039': 0.66, '2100511040': 1.0, '2100511044': 0.66, '2100511048': 0.66, '2100511057': 1.0, '2100511058': 1.0, '2100511059': 0.66, '2100511060': 1.0, '2100511061': 0.66, '2100511062': 1.0, '2100511063': 1.0, '2100511064': 0.66, '2100511065': 1.0, '2100511067': 1.0, '2100511069': 0.33, '2100511070': 0.66, '2100511071': 1.0, '2100511072': 1.0, '2100511073': 1.0, '2100511074': 1.0, '2100511076': 0.66, '2100511077': 1.0, '2100511078': 1.0, '2100511079': 1.0, '2100511080': 1.0, '2100511081': 0.66, '2100511082': 1.0, '2100512001': 1.0, '2100512002': 0.66, '2100512003': 0.66, '2100512006': 0.66, '2100512007': 1.0, '2100512009': 1.0, '2100512010': 1.0, '2100512011': 0.66, '2100512012': 1.0, '2100512014': 1.0, '2100512015': 0.66, '2100512016': 1.0, '2100512017': 1.0, '2100512018': 0.66, '2100512020': 1.0, '2100512021': 1.0, '2100512025': 1.0, '2100512026': 0.66, '2100512028': 0.66, '2100512029': 1.0, '2100512032': 1.0, '2100512034': 1.0, '2100512035': 0.66, '2100512036': 0.66, '2100512037': 0.66, '2100512038': 1.0, '2100512039': 0.66, '2100512041': 0.66, '2100512042': 1.0, '2100512044': 0.66, '2100512045': 0.66, '2100512051': 0.33, '2100512052': 1.0, '2100512053': 1.0, '2100512055': 0.66, '2100512057': 1.0, '2100512058': 1.0, '2100512061': 1.0, '2100512062': 1.0, '2100512063': 1.0, '2100512064': 0.33, '2100512065': 0.66, '2100521002': 1.0, '2100521005': 1.0, '2100521006': 1.0, '2100521008': 1.0, '2100521009': 0.66, '2100521010': 0.66, '2100521013': 0.66, '2100521014': 0.66, '2100521015': 1.0, '2100521016': 1.0, '2100521017': 0.66, '2100521018': 0.66, '2100521021': 1.0, '2100521022': 0.66, '2100521023': 0.66, '2100521024': 0.66, '2100521025': 0.66, '2100521026': 0.66, '2100521027': 0.66, '2100521028': 0.66, '2100521029': 1.0, '2100521030': 0.66, '2100521031': 0.66, '2100521032': 0.33, '2100521033': 1.0, '2100521034': 0.66, '2100521035': 0.66, '2100521037': 1.0, '2100521038': 0.66, '2100521039': 0.66, '2100521040': 1.0, '2100521041': 0.66, '2100521042': 0.66, '2100521043': 0.66, '2100521044': 1.0, '2100521046': 0.66, '2100521047': 0.66, '2100521048': 0.66, '2100521049': 0.66, '2100521050': 0.66, '2100521051': 0.66, '2100521052': 0.66, '2100521054': 0.66, '2100521055': 0.66, '2100521056': 0.66, '2100521057': 0.66, '2100521059': 1.0, '2100521060': 0.66, '2100521061': 0.66, '2100521062': 0.66, '2100521063': 0.66, '2100521067': 0.66, '2100521069': 0.66, '2100521070': 0.66, '2100521072': 1.0, '2100521073': 0.66, '2100521074': 1.0, '2100521075': 0.66, '2100521076': 1.0, '2100521077': 0.66, '2100521078': 1.0, '2100521079': 0.66, '2100522001': 0.66, '2100522004': 1.0, '2100522005': 0.66, '2100522006': 0.66, '2100522007': 1.0, '2100522008': 0.66, '2100522009': 1.0, '2100522010': 0.66, '2100522011': 0.66, '2100522012': 0.66, '2100522013': 0.66, '2100522018': 0.66, '2100522019': 1.0, '2100522020': 0.66, '2100522021': 0.66, '2100522023': 1.0, '2100522024': 1.0, '2100522026': 1.0, '2100522028': 0.66, '2100522031': 1.0, '2100522033': 0.66, '2100522034': 0.66, '2100522035': 0.66, '2100522036': 0.66, '2100522038': 0.66, '2100522039': 0.66, '2100522040': 0.66, '2100522041': 0.66, '2100522042': 0.66, '2100522046': 0.66, '2100522047': 0.66, '2100522048': 0.66, '2100522049': 1.0, '2100522050': 0.66, '2100522051': 0.66, '2100522052': 0.66, '2100522053': 0.66, '2100522054': 1.0, '2100522055': 1.0, '2100522056': 0.66, '2100522059': 0.66, '2100522060': 0.66, '2100522061': 0.66, '2100522062': 0.66, '2100522063': 1.0, '2100522064': 0.66, '2100522067': 0.66, '2100522068': 0.66, '2100522070': 0.66, '2100531001': 1.0, '2100531002': 0.66, '2100531003': 1.0, '2100531004': 1.0, '2100531006': 1.0, '2100531007': 0.66, '2100531008': 0.66, '2100531009': 1.0, '2100531010': 1.0, '2100531012': 1.0, '2100531013': 0.66, '2100531014': 1.0, '2100531015': 1.0, '2100531016': 0.66, '2100531017': 0.66, '2100531018': 1.0, '2100531019': 1.0, '2100531021': 1.0, '2100531022': 0.66, '2100531023': 1.0, '2100531024': 1.0, '2100531025': 0.66, '2100531026': 0.66, '2100531027': 1.0, '2100531028': 1.0, '2100531030': 0.66, '2100531031': 0.66, '2100531033': 0.66, '2100531034': 1.0, '2100531035': 1.0, '2100531036': 0.66, '2100531037': 0.66, '2100531040': 1.0, '2100531041': 0.66, '2100531042': 1.0, '2100531043': 1.0, '2100531044': 1.0, '2100531045': 1.0, '2100531047': 1.0, '2100531048': 0.66, '2100531049': 1.0, '2100531050': 0.66, '2100531051': 1.0, '2100531052': 1.0, '2100531053': 0.66, '2100531054': 0.33, '2100531055': 1.0, '2100531056': 0.66, '2100531057': 1.0, '2100531058': 1.0, '2100531059': 0.66, '2100531060': 1.0, '2100531061': 0.66, '2100531063': 1.0, '2100531064': 0.66, '2100531065': 0.66, '2100531066': 1.0, '2100531067': 1.0, '2100531068': 1.0, '2100531070': 0.66, '2100531071': 0.66, '2100531072': 0.66, '2100531073': 0.66, '2100531074': 1.0, '2100531076': 1.0, '2100531077': 1.0, '2100531078': 1.0, '2100531079': 1.0, '2100531080': 1.0, '2100531081': 0.66, '2100531082': 1.0, '2100531084': 1.0, '2100532002': 0.66, '2100532003': 0.66, '2100532004': 0.66, '2100532005': 1.0, '2100532007': 0.66, '2100532008': 0.66, '2100532010': 0.66, '2100532012': 0.66, '2100532013': 0.66, '2100532015': 0.66, '2100532016': 0.33, '2100532017': 1.0, '2100532019': 0.66, '2100532020': 0.66, '2100532022': 0.0, '2100532023': 0.66, '2100532024': 1.0, '2100532025': 1.0, '2100532026': 1.0, '2100532027': 1.0, '2100532028': 1.0, '2100532029': 0.66, '2100532030': 0.66, '2100532031': 0.66, '2100532032': 1.0, '2100532033': 0.66, '2100532034': 0.66, '2100532037': 1.0, '2100532042': 0.66, '2100532043': 1.0, '2100532044': 0.66, '2100532045': 0.66, '2100532046': 1.0, '2100532047': 0.66, '2100532048': 1.0, '2100532050': 1.0, '2100532052': 0.66, '2100532053': 1.0, '2100532054': 1.0, '2100532055': 1.0, '2100532056': 0.66, '2100532057': 0.66, '2100532058': 1.0, '2100532059': 1.0, '2100532060': 1.0, '2100532061': 1.0, '2100532062': 0.66, '2100532063': 1.0, '2100532064': 1.0, '2100532066': 1.0, '2100532067': 0.66, '2100532068': 1.0, '2100532070': 1.0, '2100532071': 1.0, '2100532072': 0.66, '2100551002': 0.66, '2100551005': 0.0, '2100551006': 0.66, '2100551007': 1.0, '2100551010': 0.33, '2100551011': 0.66, '2100551013': 1.0, '2100551014': 0.66, '2100551015': 0.66, '2100551016': 0.66, '2100551017': 1.0, '2100551018': 1.0, '2100551019': 1.0, '2100551020': 0.66, '2100551021': 1.0, '2100551022': 0.66, '2100551023': 0.66, '2100551024': 1.0, '2100551025': 0.66, '2100551027': 0.66, '2100551028': 1.0, '2100551029': 0.66, '2100551032': 0.33, '2100551033': 0.66, '2100551034': 0.66, '2100551035': 0.33, '2100551036': 0.66, '2100551037': 0.66, '2100551039': 0.66, '2100551041': 0.66, '2100551042': 0.33, '2100551043': 0.66, '2100551044': 0.66, '2100551045': 0.66, '2100551046': 0.66, '2100551049': 1.0, '2100551050': 1.0, '2100551051': 0.66, '2100551052': 0.66, '2100551053': 1.0, '2100551054': 0.66, '2100551055': 0.66, '2100551056': 1.0, '2100551057': 1.0, '2100551059': 0.66, '2100551060': 1.0, '2100551061': 0.66, '2100551062': 0.66, '2100551063': 0.66, '2100551064': 0.66, '2100551065': 0.66, '2100551066': 1.0, '2100551067': 0.66, '2100551068': 1.0, '2100551069': 1.0, '2100551071': 1.0, '2100551072': 0.66, '2100551073': 0.66, '2100551074': 0.66, '2100551075': 0.66, '2100551076': 1.0, '2100551077': 0.66, '2100551079': 0.66, '2100551080': 1.0, '2100551081': 0.66, '2100552002': 1.0, '2100552003': 0.66, '2100552004': 0.66, '2100552005': 0.66, '2100552006': 0.66, '2100552007': 0.66, '2100552008': 0.66, '2100552009': 1.0, '2100552010': 0.66, '2100552011': 0.66, '2100552012': 0.66, '2100552013': 0.66, '2100552014': 0.66, '2100552015': 1.0, '2100552016': 0.66, '2100552017': 0.66, '2100552018': 0.66, '2100552019': 1.0, '2100552021': 0.66, '2100552022': 1.0, '2100552023': 0.66, '2100552024': 0.66, '2100552025': 1.0, '2100552027': 1.0, '2100552028': 1.0, '2100552029': 1.0, '2100552030': 1.0, '2100552031': 0.66, '2100552032': 1.0, '2100552033': 1.0, '2100552034': 1.0, '2100552035': 0.66, '2100552037': 0.66, '2100552038': 0.66, '2100552039': 0.66, '2100552041': 0.66, '2100552042': 1.0, '2100552043': 0.66, '2100552044': 1.0, '2100552045': 0.66, '2100552047': 1.0, '2100552048': 0.33, '2100552051': 1.0, '2100552052': 1.0, '2100552053': 0.66, '2100552055': 0.66, '2100552057': 1.0, '2100552059': 1.0, '2100552060': 0.66, '2100552061': 1.0, '2100552062': 0.66, '2100552063': 0.33, '2100552065': 0.66, '2100552066': 0.66, '2100552068': 0.66, '2100552072': 0.66, '2100561006': 0.66, '2100561010': 0.66, '2100561011': 0.66, '2100561013': 1.0, '2100561014': 1.0, '2100561015': 0.66, '2100561016': 0.66, '2100561018': 1.0, '2100561019': 1.0, '2100561020': 1.0, '2100561021': 1.0, '2100561022': 0.66, '2100561023': 1.0, '2100561024': 0.66, '2100561027': 1.0, '2100561029': 1.0, '2100561032': 0.66, '2100561038': 0.66, '2100561043': 1.0, '2100561044': 1.0, '2100561046': 1.0, '2100561051': 0.66, '2100561052': 1.0, '2100561053': 1.0, '2100561054': 0.66, '2100561056': 0.66, '2100561057': 1.0, '2100561058': 1.0, '2100561059': 1.0, '2100561062': 1.0, '2100561063': 0.66, '2100561064': 1.0, '2100561065': 1.0, '2100561070': 1.0, '2100561071': 0.66, '2100561074': 1.0, '2100561079': 0.66, '2100562001': 1.0, '2100562002': 1.0, '2100562003': 1.0, '2100562004': 1.0, '2100562005': 0.66, '2100562007': 1.0, '2100562008': 0.66, '2100562009': 1.0, '2100562010': 1.0, '2100562011': 1.0, '2100562012': 1.0, '2100562013': 0.66, '2100562014': 1.0, '2100562015': 1.0, '2100562017': 1.0, '2100562018': 1.0, '2100562019': 0.33, '2100562020': 0.66, '2100562024': 0.33, '2100562026': 0.66, '2100562027': 0.66, '2100562029': 1.0, '2100562030': 0.66, '2100562032': 0.66, '2100562033': 0.66, '2100562034': 1.0, '2100562035': 1.0, '2100562037': 1.0, '2100562038': 0.66, '2100562039': 0.66, '2100562040': 0.66, '2100562042': 1.0, '2100562043': 0.66, '2100562044': 0.66, '2100562046': 0.66, '2100562047': 1.0, '2100562048': 1.0, '2100562049': 0.66, '2100562050': 0.66, '2100562051': 0.66, '2100562053': 1.0, '2100562054': 0.66, '2100562055': 0.66, '2100562056': 1.0, '2100562058': 1.0, '2100562059': 1.0, '2100562060': 0.66, '2100562061': 1.0, '2100571001': 0.66, '2100571002': 0.33, '2100571004': 0.66, '2100571007': 0.33, '2100571008': 1.0, '2100571009': 0.66, '2100571011': 0.66, '2100571012': 0.66, '2100571013': 1.0, '2100571015': 0.66, '2100571017': 0.66, '2100571018': 0.66, '2100571019': 0.66, '2100571020': 0.66, '2100571021': 0.33, '2100571022': 0.66, '2100571023': 0.33, '2100571024': 0.66, '2100571025': 0.66, '2100571027': 0.66, '2100571029': 0.66, '2100571030': 0.66, '2100571031': 0.66, '2100571033': 0.66, '2100571034': 0.66, '2100571036': 0.66, '2100571038': 0.33, '2100571039': 0.66, '2100571040': 1.0, '2100571041': 1.0, '2100571042': 1.0, '2100571044': 0.33, '2100571045': 1.0, '2100571046': 1.0, '2100571047': 0.66, '2100571048': 1.0, '2100571049': 0.33, '2100571050': 0.66, '2100571051': 0.66, '2100571052': 0.66, '2100571053': 0.66, '2100571055': 1.0, '2100571056': 0.66, '2100571057': 0.66, '2100571058': 0.66, '2100571061': 0.66, '2100571062': 0.33, '2100571063': 0.66, '2100571064': 0.66, '2100571065': 1.0, '2100571066': 0.66, '2100571067': 0.66, '2100571068': 0.66, '2100571069': 0.66, '2100571070': 0.66, '2100571072': 1.0, '2100571073': 0.66, '2100571074': 0.66, '2100571075': 1.0, '2100571077': 1.0, '2100571078': 1.0, '2100571079': 0.66, '2100571081': 1.0, '2100571082': 0.66, '2100572001': 0.66, '2100572002': 1.0, '2100572004': 0.66, '2100572006': 1.0, '2100572009': 0.66, '2100572010': 1.0, '2100572011': 1.0, '2100572012': 0.66, '2100572013': 1.0, '2100572015': 1.0, '2100572017': 1.0, '2100572018': 1.0, '2100572019': 0.66, '2100572020': 0.66, '2100572021': 0.33, '2100572023': 0.66, '2100572024': 1.0, '2100572025': 0.66, '2100572026': 0.66, '2100572027': 0.66, '2100572028': 0.66, '2100572029': 0.66, '2100572030': 0.66, '2100572032': 0.66, '2100572033': 1.0, '2100572034': 0.66, '2100572036': 0.66, '2100572038': 0.66, '2100572039': 1.0, '2100572040': 0.66, '2100572041': 1.0, '2100572042': 0.66, '2100572043': 0.66, '2100572044': 0.66, '2100572045': 0.66, '2100572046': 1.0, '2100572047': 1.0, '2100572048': 1.0, '2100572050': 1.0, '2100572051': 1.0, '2100572054': 0.66, '2100572055': 1.0, '2100572056': 1.0, '2100572057': 0.33, '2100572058': 0.66, '2100572059': 0.66, '2100572060': 0.66, '2100572061': 0.66, '2100572062': 1.0, '2100572063': 0.66, '2100572064': 1.0, '2100572067': 0.66, '2100572068': 0.66, '2100572069': 0.66, '2100581001': 0.33, '2100581002': 1.0, '2100581003': 0.66, '2100581004': 0.66, '2100581005': 0.66, '2100581006': 0.66, '2100581007': 1.0, '2100581009': 0.66, '2100581010': 0.66, '2100581011': 1.0, '2100581012': 1.0, '2100581013': 0.66, '2100581014': 1.0, '2100581015': 1.0, '2100581018': 1.0, '2100581019': 1.0, '2100581021': 0.33, '2100581022': 0.66, '2100581024': 0.66, '2100581025': 1.0, '2100581026': 0.66, '2100581027': 0.66, '2100581028': 1.0, '2100581029': 0.66, '2100581030': 0.66, '2100581034': 0.66, '2100581035': 0.66, '2100581036': 1.0, '2100581037': 1.0, '2100581038': 0.66, '2100581039': 0.66, '2100581040': 0.66, '2100581041': 0.66, '2100581042': 0.66, '2100581044': 0.66, '2100581045': 0.66, '2100581051': 0.66, '2100581054': 1.0, '2100581056': 1.0, '2100581057': 1.0, '2100581058': 1.0, '2100581059': 0.66, '2100581061': 0.66, '2100581062': 1.0, '2100581064': 1.0, '2100581066': 0.66, '2100581067': 0.66, '2100581068': 0.66, '2100581069': 0.66, '2100581070': 0.66, '2100581071': 0.66, '2100581072': 0.66, '2100581073': 0.66, '2100581074': 0.66, '2100581075': 1.0, '2100581076': 0.66, '2100581077': 1.0, '2100582001': 0.66, '2100582002': 0.66, '2100582003': 1.0, '2100582004': 1.0, '2100582005': 1.0, '2100582006': 0.66, '2100582008': 0.66, '2100582009': 1.0, '2100582012': 0.66, '2100582013': 0.66, '2100582015': 0.66, '2100582017': 0.66, '2100582019': 0.66, '2100582020': 0.66, '2100582021': 0.66, '2100582023': 0.66, '2100582024': 0.66, '2100582025': 1.0, '2100582026': 1.0, '2100582027': 0.33, '2100582028': 0.66, '2100582038': 0.66, '2100582043': 1.0, '2100582044': 0.66, '2100582045': 0.66, '2100582046': 0.66, '2100582048': 1.0, '2100582050': 0.66, '2100582051': 0.66, '2100582052': 0.0, '2100582053': 1.0, '2100582054': 0.66, '2100582055': 0.0, '2100582056': 0.0, '2100582057': 0.0, '2100582058': 0.0, '2100582060': 0.0, '2100582061': 0.33, '2100582062': 0.0, '2100582064': 1.0, '2100582067': 0.66, '2100582069': 0.66, '2100591002': 1.0, '2100591003': 1.0, '2100591004': 1.0, '2100591005': 1.0, '2100591006': 1.0, '2100591007': 1.0, '2100591008': 1.0, '2100591010': 1.0, '2100591013': 0.66, '2100591015': 0.66, '2100591016': 1.0, '2100591017': 0.66, '2100591019': 0.66, '2100591020': 1.0, '2100591021': 0.66, '2100591022': 1.0, '2100591023': 0.66, '2100591025': 1.0, '2100591026': 0.66, '2100591027': 0.66, '2100591028': 0.66, '2100591030': 0.66, '2100591034': 1.0, '2100591035': 1.0, '2100591036': 1.0, '2100591037': 0.66, '2100591038': 0.66, '2100591039': 0.66, '2100591040': 1.0, '2100591041': 0.66, '2100591042': 1.0, '2100591043': 0.66, '2100591044': 1.0, '2100591045': 0.66, '2100591046': 0.33, '2100591047': 1.0, '2100591048': 1.0, '2100591049': 0.66, '2100591050': 1.0, '2100591053': 1.0, '2100591054': 1.0, '2100591055': 1.0, '2100591056': 1.0, '2100591057': 1.0, '2100591059': 1.0, '2100591060': 0.66, '2100591061': 1.0, '2100591062': 0.66, '2100591064': 0.66, '2100591065': 1.0, '2100591066': 1.0, '2100591067': 1.0, '2100591068': 1.0, '2100591069': 1.0, '2100591070': 1.0, '2100591072': 1.0, '2100591073': 1.0, '2100591074': 1.0, '2100591075': 1.0, '2100591076': 1.0, '2100591077': 1.0, '2100591078': 1.0, '2100591080': 1.0, '2100591081': 0.66, '2100591082': 1.0, '2100592002': 1.0, '2100592003': 1.0, '2100592004': 0.66, '2100592005': 1.0, '2100592007': 1.0, '2100592009': 1.0, '2100592010': 1.0, '2100592011': 0.66, '2100592012': 1.0, '2100592013': 0.66, '2100592014': 0.66, '2100592015': 1.0, '2100592016': 1.0, '2100592017': 1.0, '2100592018': 0.66, '2100592019': 1.0, '2100592020': 1.0, '2100592021': 1.0, '2100592022': 0.66, '2100592023': 1.0, '2100592024': 1.0, '2100592025': 0.66, '2100592026': 1.0, '2100592027': 0.66, '2100592028': 1.0, '2100592029': 1.0, '2100592030': 0.66, '2100592032': 1.0, '2100592033': 1.0, '2100592034': 1.0, '2100592035': 0.66, '2100592036': 0.66, '2100592038': 0.66, '2100592040': 0.66, '2100592041': 1.0, '2100592042': 1.0, '2100592043': 0.66, '2100592044': 1.0, '2100592046': 0.66, '2100592047': 1.0, '2100592048': 0.66, '2100592049': 1.0, '2100592052': 0.66, '2100592053': 1.0, '2100592054': 0.66, '2100592056': 0.66, '2100592057': 0.66, '2100592058': 0.66, '2100592059': 1.0, '2100592060': 0.66, '2100592064': 0.66, '2100592065': 0.66, '2100592066': 0.66, '2100592067': 1.0, '2100592068': 0.66, '2100592069': 1.0, '2100592070': 0.66, '2100592071': 0.66, '2100592072': 1.0, '2100601001': 1.0, '2100601002': 1.0, '2100601004': 0.66, '2100601005': 0.66, '2100601006': 0.66, '2100601007': 0.66, '2100601008': 1.0, '2100601009': 0.66, '2100601010': 1.0, '2100601011': 1.0, '2100601012': 0.33, '2100601013': 0.66, '2100601014': 1.0, '2100601015': 0.66, '2100601016': 1.0, '2100601017': 1.0, '2100601018': 0.33, '2100601020': 1.0, '2100601021': 0.66, '2100601023': 0.66, '2100601024': 0.66, '2100601025': 0.66, '2100601027': 0.66, '2100601028': 0.66, '2100601029': 0.66, '2100601030': 1.0, '2100601031': 0.66, '2100601032': 0.66, '2100601033': 1.0, '2100601035': 1.0, '2100601036': 0.66, '2100601037': 1.0, '2100601038': 1.0, '2100601039': 0.66, '2100601040': 1.0, '2100601041': 1.0, '2100601042': 1.0, '2100601043': 1.0, '2100601044': 1.0, '2100601045': 1.0, '2100601046': 1.0, '2100601049': 0.66, '2100601050': 0.66, '2100601052': 0.66, '2100601053': 0.66, '2100601054': 0.66, '2100601055': 1.0, '2100601056': 0.66, '2100601057': 1.0, '2100601059': 0.66, '2100601062': 1.0, '2100601063': 1.0, '2100601064': 0.66, '2100601065': 1.0, '2100601066': 1.0, '2100601067': 1.0, '2100601068': 0.66, '2100601069': 1.0, '2100601071': 1.0, '2100601073': 1.0, '2100601074': 0.66, '2100601075': 0.66, '2100601077': 1.0, '2100601078': 0.66, '2100602001': 0.66, '2100602002': 0.66, '2100602003': 0.66, '2100602004': 0.66, '2100602005': 0.66, '2100602006': 1.0, '2100602008': 0.66, '2100602009': 0.66, '2100602010': 1.0, '2100602011': 0.66, '2100602012': 0.66, '2100602014': 0.66, '2100602015': 0.66, '2100602017': 1.0, '2100602018': 0.66, '2100602019': 0.66, '2100602020': 1.0, '2100602022': 0.66, '2100602023': 0.66, '2100602024': 0.66, '2100602025': 1.0, '2100602026': 0.66, '2100602027': 1.0, '2100602028': 0.66, '2100602029': 0.66, '2100602030': 0.66, '2100602032': 0.66, '2100602033': 1.0, '2100602034': 0.66, '2100602035': 0.66, '2100602036': 0.66, '2100602038': 0.66, '2100602040': 0.66, '2100602041': 0.0, '2100602042': 0.66, '2100602043': 1.0, '2100602044': 0.66, '2100602046': 0.66, '2100602047': 1.0, '2100602049': 1.0, '2100602050': 1.0, '2100602051': 0.66, '2100602052': 1.0, '2100602053': 0.66, '2100602054': 1.0, '2100602056': 0.66, '2100602058': 0.66, '2100602059': 0.66, '2100602060': 0.66, '2100602061': 0.66, '2100602062': 1.0, '2100602063': 1.0, '2100602065': 0.66, '2100602067': 1.0, '2100602068': 0.66, '2100602069': 0.66, '2100602072': 1.0, '2100611002': 1.0, '2100611003': 1.0, '2100611004': 1.0, '2100611005': 0.66, '2100611006': 0.66, '2100611010': 0.66, '2100611011': 1.0, '2100611012': 1.0, '2100611013': 1.0, '2100611014': 1.0, '2100611015': 1.0, '2100611016': 0.66, '2100611017': 0.66, '2100611018': 0.66, '2100611019': 0.66, '2100611021': 1.0, '2100611023': 0.66, '2100611024': 1.0, '2100611025': 1.0, '2100611026': 1.0, '2100611027': 0.33, '2100611028': 0.66, '2100611029': 0.66, '2100611031': 0.66, '2100611032': 1.0, '2100611034': 1.0, '2100611035': 1.0, '2100611036': 0.66, '2100611037': 0.66, '2100611038': 1.0, '2100611039': 1.0, '2100611040': 0.66, '2100611041': 1.0, '2100611042': 0.66, '2100611043': 0.66, '2100611044': 1.0, '2100611045': 0.66, '2100611046': 1.0, '2100611047': 0.66, '2100611048': 1.0, '2100611049': 1.0, '2100611050': 0.66, '2100611051': 1.0, '2100611052': 0.66, '2100611055': 1.0, '2100611056': 1.0, '2100611057': 0.66, '2100611058': 0.66, '2100611059': 1.0, '2100611060': 0.66, '2100611061': 1.0, '2100611062': 0.66, '2100611063': 1.0, '2100611064': 1.0, '2100611066': 1.0, '2100611067': 0.66, '2100611068': 0.66, '2100611069': 1.0, '2100611070': 0.66, '2100611071': 0.66, '2100611075': 0.66, '2100611076': 1.0, '2100611077': 1.0, '2100611078': 0.66, '2100611079': 0.66, '2100611081': 1.0, '2100611083': 0.66, '2100612001': 1.0, '2100612002': 1.0, '2100612003': 0.66, '2100612005': 0.66, '2100612006': 0.66, '2100612007': 1.0, '2100612008': 1.0, '2100612009': 0.33, '2100612010': 1.0, '2100612011': 1.0, '2100612012': 1.0, '2100612014': 1.0, '2100612015': 1.0, '2100612020': 1.0, '2100612022': 1.0, '2100612024': 1.0, '2100612025': 1.0, '2100612026': 1.0, '2100612027': 0.66, '2100612028': 0.66, '2100612029': 1.0, '2100612030': 0.66, '2100612031': 1.0, '2100612033': 0.66, '2100612034': 0.66, '2100612035': 1.0, '2100612037': 0.66, '2100612038': 1.0, '2100612040': 1.0, '2100612041': 0.66, '2100612042': 0.66, '2100612043': 1.0, '2100612044': 0.66, '2100612045': 1.0, '2100612046': 1.0, '2100612047': 1.0, '2100612048': 1.0, '2100612051': 1.0, '2100612053': 1.0, '2100612056': 0.66, '2100612057': 1.0, '2100612058': 1.0, '2100612059': 1.0, '2100612060': 1.0, '2100612061': 1.0, '2100612062': 1.0, '2100612063': 0.66, '2100612064': 0.66, '2100612065': 1.0, '2100612066': 1.0, '2100612067': 1.0, '2100612068': 0.66, '2100612069': 0.66, '2100612070': 0.66, '2100612071': 0.66, '2100612072': 1.0, '2260510110': 0.66, '2260510113': 1.0, '2260510114': 0.66, '2260510115': 1.0, '2260510116': 0.66, '2260510118': 0.66, '2260510122': 0.66, '2260510124': 0.66, '2260510125': 0.66, '2260510126': 0.66, '2260510127': 1.0, '2260510129': 0.66, '226051013': 0.66, '2260510131': 0.66, '2260510134': 0.66, '2260510136': 0.66, '2260510138': 0.66, '2260510139': 0.66, '226051014': 0.66, '2260510140': 1.0, '2260510141': 0.66, '2260510142': 0.66, '2260510143': 0.66, '2260510146': 1.0, '2260510147': 0.66, '2260510148': 0.66, '2260510151': 1.0, '2260510152': 1.0, '2260510155': 0.33, '2260510156': 0.66, '2260510158': 0.66, '2260510159': 0.66, '226051016': 0.66, '2260510160': 0.66, '2260510162': 0.66, '2260510163': 0.33, '2260510167': 0.66, '2260510168': 1.0, '226051017': 0.66, '2260510172': 1.0, '2260510174': 0.66, '2260510176': 0.66, '2260510177': 0.33, '2260510180': 0.66, '2260510182': 0.66, '2260510183': 0.66, '2260510185': 0.66, '226051019': 1.0, '226051021': 0.66, '2260510212': 1.0, '2260510213': 1.0, '2260510214': 1.0, '2260510217': 0.66, '226051022': 1.0, '2260510220': 1.0, '2260510221': 0.66, '2260510222': 1.0, '2260510223': 1.0, '2260510227': 1.0, '2260510228': 0.66, '2260510229': 1.0, '226051023': 1.0, '2260510230': 1.0, '2260510231': 1.0, '2260510232': 1.0, '2260510233': 1.0, '2260510237': 1.0, '2260510238': 1.0, '2260510240': 1.0, '2260510241': 1.0, '2260510242': 1.0, '2260510243': 1.0, '2260510244': 1.0, '2260510247': 1.0, '2260510248': 1.0, '226051025': 1.0, '2260510250': 0.66, '2260510252': 1.0, '2260510253': 1.0, '2260510254': 0.66, '2260510257': 0.66, '2260510258': 1.0, '2260510259': 1.0, '226051026': 1.0, '2260510260': 1.0, '2260510262': 0.66, '2260510266': 1.0, '2260510267': 1.0, '226051027': 1.0, '2260510270': 1.0, '2260510271': 0.66, '2260510272': 1.0, '2260510276': 0.66, '2260510277': 0.66, '2260510278': 1.0, '240846010': 1.0, '240846011': 1.0, '2408460110': 1.0, '2408460111': 0.66, '2408460118': 0.33, '240846012': 0.66, '2408460120': 0.66, '2408460123': 1.0, '2408460125': 1.0, '2408460126': 0.66, '2408460127': 0.66, '2408460129': 0.66, '240846013': 0.66, '2408460130': 0.66, '2408460131': 0.66, '2408460132': 0.66, '2408460133': 1.0, '2408460134': 1.0, '2408460135': 1.0, '2408460137': 0.33, '2408460139': 1.0, '2408460143': 0.66, '2408460145': 1.0, '2408460146': 1.0, '2408460148': 0.66, '2408460149': 0.66, '240846015': 0.66, '2408460150': 0.66, '2408460151': 1.0, '2408460152': 1.0, '2408460154': 1.0, '2408460155': 1.0, '2408460156': 0.66, '2408460158': 0.66, '2408460159': 0.66, '240846016': 0.66, '2408460163': 0.66, '2408460166': 0.66, '240846017': 0.66, '240846018': 0.66, '240846019': 0.66, '2408460211': 0.66, '2408460212': 1.0, '2408460213': 1.0, '2408460215': 1.0, '2408460217': 0.66, '2408460219': 0.66, '240846022': 0.66, '2408460220': 1.0, '2408460221': 1.0, '2408460222': 0.66, '2408460223': 0.66, '2408460225': 1.0, '2408460226': 0.66, '2408460227': 1.0, '2408460229': 0.66, '240846023': 0.66, '2408460234': 0.66, '2408460236': 1.0, '2408460237': 1.0, '2408460238': 0.66, '240846024': 0.66, '2408460240': 0.66, '2408460242': 1.0, '2408460243': 1.0, '2408460244': 0.66, '2408460246': 1.0, '2408460247': 1.0, '2408460249': 1.0, '2408460252': 1.0, '2408460254': 0.66, '2408460255': 1.0, '2408460257': 1.0, '2408460260': 1.0, '2408460261': 1.0, '2408460265': 1.0, '2408460266': 1.0, '2408460268': 1.0, '2408460269': 0.66, '240846027': 0.66, '2408460271': 0.66, '2408460272': 0.66, '2408460274': 0.66, '2408460276': 1.0, '2408460277': 1.0, '2408460278': 0.66, '240846028': 0.66, '2408460280': 1.0, '240846029': 0.66, '24851011': 0.66, '248510111': 1.0, '248510112': 1.0, '248510114': 0.66, '248510116': 1.0, '248510117': 1.0, '248510118': 0.66, '248510119': 1.0, '248510120': 1.0, '248510125': 1.0, '248510127': 0.66, '248510128': 1.0, '248510129': 1.0, '24851013': 1.0, '248510131': 0.66, '248510136': 1.0, '248510137': 1.0, '24851014': 0.66, '248510142': 0.66, '248510147': 1.0, '248510148': 1.0, '24851015': 1.0, '248510150': 1.0, '248510151': 1.0, '248510153': 0.66, '248510155': 1.0, '248510156': 0.66, '248510157': 0.66, '248510160': 1.0, '248510161': 1.0, '248510163': 0.66, '248510164': 1.0, '248510167': 1.0, '248510170': 1.0, '24851018': 1.0, '24851019': 1.0, '248510211': 1.0, '248510212': 1.0, '248510213': 0.66, '248510214': 0.66, '248510215': 1.0, '248510216': 1.0, '24851022': 1.0, '248510220': 1.0, '248510223': 1.0, '248510225': 1.0, '248510227': 1.0, '248510229': 1.0, '248510230': 1.0, '248510232': 1.0, '248510233': 1.0, '248510235': 1.0, '248510236': 1.0, '24851024': 1.0, '248510241': 1.0, '248510242': 1.0, '248510245': 1.0, '248510246': 1.0, '248510248': 1.0, '248510249': 1.0, '248510250': 0.66, '248510251': 1.0, '248510253': 1.0, '248510255': 1.0, '248510256': 1.0, '248510259': 1.0, '24851026': 1.0, '248510260': 1.0, '248510262': 1.0, '248510264': 0.66, '248510265': 1.0, '248510267': 1.0, '248510268': 1.0, '24851027': 1.0, '248510271': 1.0, '248510272': 1.0, '248510273': 1.0, '248510276': 1.0, '248510278': 0.66, '24851028': 1.0, '2904280110': 1.0, '29042801110': 1.0, '29042801170': 1.0, '29042801180': 0.66, '2904280120': 1.0, '29042801220': 0.66, '29042801230': 1.0, '29042801250': 1.0, '29042801260': 1.0, '29042801290': 1.0, '29042801300': 1.0, '29042801320': 1.0, '29042801340': 1.0, '29042801350': 1.0, '29042801370': 0.33, '29042801390': 1.0, '2904280140': 0.66, '29042801440': 0.66, '29042801450': 1.0, '29042801470': 1.0, '29042801480': 0.66, '2904280150': 1.0, '29042801500': 1.0, '29042801550': 0.66, '29042801570': 0.66, '29042801580': 1.0, '2904280160': 0.66, '29042801600': 1.0, '29042801630': 1.0, '29042801640': 1.0, '29042801650': 0.66, '29042801680': 0.66, '29042801690': 0.66, '2904280170': 0.66, '29042801710': 1.0, '29042801740': 1.0, '29042801750': 1.0, '29042801770': 1.0, '29042801780': 0.66, '29042801790': 0.66, '2904280180': 1.0, '2904280190': 1.0, '29042802110': 0.66, '29042802140': 0.66, '29042802150': 0.66, '29042802180': 1.0, '29042802200': 1.0, '29042802220': 1.0, '29042802240': 1.0, '29042802260': 1.0, '29042802280': 1.0, '2904280230': 1.0, '29042802310': 1.0, '29042802320': 1.0, '29042802340': 1.0, '29042802350': 1.0, '29042802380': 0.66, '29042802390': 0.66, '29042802410': 1.0, '29042802420': 1.0, '29042802430': 1.0, '29042802440': 1.0, '29042802450': 1.0, '29042802460': 1.0, '29042802470': 1.0, '29042802480': 1.0, '2904280250': 0.66, '29042802500': 1.0, '29042802510': 1.0, '29042802520': 1.0, '29042802530': 1.0, '29042802560': 1.0, '29042802570': 1.0, '2904280260': 0.33, '29042802600': 0.66, '29042802640': 1.0, '29042802660': 0.66, '29042802670': 1.0, '29042802680': 1.0, '29042802690': 1.0, '2904280270': 0.66, '29042802700': 1.0, '29042802720': 1.0, '29042802740': 1.0, '29042802750': 1.0, '29042802760': 1.0, '29042802770': 0.66, '29042802790': 1.0, '2904280280': 1.0, '29042802800': 1.0, '29042802830': 1.0, '29042802860': 1.0, '2904280290': 0.66, '303830110': 0.66, '303830113': 0.33, '303830115': 0.66, '303830117': 1.0, '303830118': 1.0, '303830121': 1.0, '303830122': 1.0, '303830123': 0.66, '303830126': 0.33, '303830127': 1.0, '303830128': 0.66, '30383013': 1.0, '303830131': 0.66, '303830132': 0.66, '303830133': 0.66, '303830138': 1.0, '303830139': 0.33, '30383014': 1.0, '303830141': 1.0, '303830143': 0.66, '303830144': 1.0, '303830146': 0.66, '303830147': 1.0, '303830148': 0.66, '303830149': 0.0, '30383015': 0.66, '303830151': 1.0, '303830155': 0.33, '303830156': 1.0, '303830157': 1.0, '303830158': 1.0, '303830159': 0.66, '30383016': 1.0, '303830160': 0.66, '303830161': 0.66, '303830162': 1.0, '303830166': 1.0, '303830167': 0.66, '303830169': 0.66, '303830171': 1.0, '303830174': 1.0, '303830175': 0.66, '303830178': 0.66, '303830182': 1.0, '303830183': 0.66, '303830184': 1.0, '303830210': 1.0, '303830211': 1.0, '303830212': 1.0, '303830216': 0.66, '303830217': 1.0, '303830218': 0.66, '30383022': 0.66, '303830220': 1.0, '303830221': 1.0, '303830223': 1.0, '303830224': 0.66, '303830225': 0.66, '303830227': 1.0, '303830229': 0.66, '30383023': 0.33, '303830234': 1.0, '303830236': 1.0, '303830239': 1.0, '303830240': 1.0, '303830241': 1.0, '303830242': 1.0, '303830245': 1.0, '303830246': 0.66, '303830247': 1.0, '303830249': 1.0, '30383025': 0.66, '303830250': 0.66, '303830255': 1.0, '303830258': 1.0, '303830259': 1.0, '303830263': 1.0, '303830269': 0.66, '303830270': 1.0, '303830273': 1.0, '303830274': 1.0, '303830278': 0.66, '30383028': 1.0, '3100621001': 1.0, '3100621002': 1.0, '3100621003': 1.0, '3100621004': 0.66, '3100621005': 1.0, '3100621007': 1.0, '3100621009': 0.66, '3100621010': 1.0, '3100621011': 1.0, '3100621012': 0.66, '3100621013': 1.0, '3100621014': 1.0, '3100621016': 1.0, '3100621018': 0.66, '3100621019': 0.66, '3100621020': 0.66, '3100621022': 0.66, '3100621023': 1.0, '3100621024': 1.0, '3100621025': 0.66, '3100621026': 1.0, '3100621027': 1.0, '3100621028': 1.0, '3100621030': 0.66, '3100621031': 1.0, '3100621032': 0.66, '3100621033': 1.0, '3100621034': 0.66, '3100621035': 0.66, '3100621037': 0.33, '3100621039': 1.0, '3100621040': 1.0, '3100621041': 1.0, '3100621042': 0.66, '3100621043': 1.0, '3100621045': 1.0, '3100621046': 1.0, '3100621047': 1.0, '3100621048': 1.0, '3100621049': 1.0, '3100621051': 0.66, '3100621052': 0.66, '3100621053': 1.0, '3100621055': 1.0, '3100621057': 1.0, '3100621058': 1.0, '3100621059': 1.0, '3100621061': 0.66, '3100621062': 0.66, '3100621063': 1.0, '3100621064': 1.0, '3100622001': 0.66, '3100622002': 1.0, '3100622003': 1.0, '3100622006': 0.66, '3100622007': 1.0, '3100622008': 1.0, '3100622009': 0.66, '3100622011': 1.0, '3100622013': 1.0, '3100622015': 1.0, '3100622019': 0.66, '3100622020': 0.66, '3100622021': 0.66, '3100622023': 1.0, '3100622024': 0.66, '3100622026': 0.66, '3100622027': 0.66, '3100622033': 0.66, '3100622034': 1.0, '3100622036': 1.0, '3100622037': 0.66, '3100622038': 1.0, '3100622040': 1.0, '3100622041': 1.0, '3100622042': 1.0, '3100622043': 1.0, '3100622044': 0.66, '3100622045': 1.0, '3100622047': 1.0, '3100622048': 1.0, '3100622049': 0.66, '3100622051': 1.0, '3100622053': 0.66, '3100622054': 1.0, '3100622057': 0.66, '3100631001': 1.0, '3100631002': 1.0, '3100631003': 0.66, '3100631004': 1.0, '3100631005': 0.66, '3100631006': 1.0, '3100631008': 1.0, '3100631009': 1.0, '3100631010': 1.0, '3100631011': 1.0, '3100631013': 0.66, '3100631014': 0.66, '3100631015': 0.66, '3100631016': 1.0, '3100631018': 0.66, '3100631019': 1.0, '3100631022': 0.66, '3100631023': 0.66, '3100631025': 1.0, '3100631026': 1.0, '3100631027': 0.66, '3100631029': 1.0, '3100631032': 1.0, '3100631035': 1.0, '3100631037': 1.0, '3100631042': 0.66, '3100631043': 1.0, '3100631044': 1.0, '3100631045': 1.0, '3100631046': 1.0, '3100631047': 1.0, '3100631048': 0.66, '3100631049': 0.66, '3100631051': 1.0, '3100631052': 1.0, '3100631053': 0.66, '3100631054': 1.0, '3100631055': 0.66, '3100631056': 1.0, '3100631057': 0.66, '3100631058': 1.0, '3100631059': 1.0, '3100631062': 1.0, '3100632001': 0.66, '3100632002': 1.0, '3100632003': 0.66, '3100632004': 1.0, '3100632007': 1.0, '3100632008': 0.66, '3100632011': 0.66, '3100632012': 0.66, '3100632015': 1.0, '3100632016': 0.66, '3100632017': 1.0, '3100632018': 0.66, '3100632019': 1.0, '3100632021': 0.66, '3100632023': 1.0, '3100632024': 1.0, '3100632025': 1.0, '3100632026': 0.66, '3100632027': 1.0, '3100632030': 0.66, '3100632031': 1.0, '3100632039': 0.66, '3100632041': 1.0, '3100632042': 1.0, '3100632043': 1.0, '3100632044': 1.0, '3100632045': 0.66, '3100641002': 0.66, '3100641003': 0.33, '3100641004': 0.33, '3100641006': 0.33, '3100641007': 0.66, '3100641008': 0.66, '3100641023': 0.33, '3100642002': 1.0, '3100642003': 0.66, '3100642005': 0.66, '3100642006': 0.66, '3100642007': 0.33, '3100642008': 1.0, '3100642009': 1.0, '3100642011': 1.0, '3100642012': 0.66, '3100642013': 1.0, '3100642015': 0.66, '3100642017': 0.33, '3100642019': 1.0, '3100642020': 1.0, '3100642021': 0.66, '3100642022': 0.66, '3100642024': 1.0, '3100642025': 0.66, '3100642026': 0.66, '3100642027': 0.66, '3100642028': 0.66, '3100642030': 0.66, '3100642031': 0.66, '3100642032': 0.66, '3100642033': 1.0, '3100642034': 0.66, '3100642035': 0.66, '3100642036': 0.33, '3100642037': 0.66, '3100642038': 0.66, '3100642040': 0.66, '3100642045': 0.66, '3100642047': 1.0, '3100642052': 0.66, '3100642054': 1.0, '3100642055': 0.33, '3100642056': 1.0, '3100642057': 0.66, '3100642058': 0.66, '3100642060': 0.66, '3100642061': 0.66, '3100642063': 0.66, '3100642064': 0.66, '3100642066': 1.0, '3100642069': 0.66, '3100642070': 0.66, '3100661002': 0.66, '3100661007': 1.0, '3100661009': 0.66, '3100661015': 0.66, '3100661016': 1.0, '3100661022': 0.66, '3100661023': 0.66, '3100661024': 0.66, '3100661025': 0.66, '3100661027': 0.66, '3100661028': 0.66, '3100661029': 1.0, '3100661031': 0.66, '3100661032': 1.0, '3100661033': 0.66, '3100661036': 0.66, '3100661037': 0.66, '3100661038': 0.66, '3100661040': 0.66, '3100661043': 0.66, '3100661044': 0.66, '3100661046': 1.0, '3100661049': 0.66, '3100661050': 0.66, '3100662014': 1.0, '3100662015': 1.0, '3100662016': 0.66, '3100662017': 0.66, '3100662020': 1.0, '3100662022': 0.66, '3100662023': 0.66, '3100662026': 1.0, '3100662029': 0.66, '3100662032': 0.66, '3100662035': 0.66, '3100662036': 0.66, '3100662037': 0.33, '3100662045': 1.0, '3100662046': 0.66, '3100662048': 1.0, '3100662049': 1.0, '3100662050': 0.66, '3100662052': 1.0, '3100662053': 0.66, '3100662055': 0.66, '3100681001': 0.66, '3100681002': 0.66, '3100681005': 1.0, '3100681006': 1.0, '3100681015': 0.33, '3100681017': 0.33, '3100681018': 0.33, '3100681042': 0.33, '3100681043': 0.66, '3100681044': 1.0, '3100681045': 0.66, '3100681046': 0.66, '3100682001': 0.66, '3100682002': 1.0, '3100682003': 0.66, '3100682007': 1.0, '3100682008': 0.66, '3100682030': 0.66, '3100682040': 0.66, '3100691005': 0.66, '3100691006': 0.66, '3100691007': 0.66, '3100691011': 0.66, '3100691012': 0.66, '3100691021': 0.66, '3100691026': 0.66, '3100691042': 0.66, '3100691045': 0.66, '3100691048': 0.66, '3100692002': 0.66, '3100692005': 1.0, '3100692006': 0.66, '3100692007': 0.66, '3100692009': 1.0, '3100692010': 0.66, '3100692011': 1.0, '3100692012': 0.66, '3100692013': 0.66, '3100692015': 0.33, '3100692016': 0.66, '3100692020': 0.66, '3100692022': 0.66, '3100692023': 0.66, '3100692024': 0.66, '3100692025': 0.66, '3100692028': 0.66, '3100692029': 1.0, '3100692032': 0.66, '3100692034': 1.0, '3100692035': 1.0, '3100692038': 0.66, '3100692039': 0.66, '3100692045': 1.0, '3100692052': 0.66, '3100692054': 0.66, '3100692055': 0.66, '3100692056': 0.66, '3100701001': 0.66, '3100701002': 1.0, '3100701004': 1.0, '3100701005': 1.0, '3100701008': 0.66, '3100701009': 0.66, '3100701010': 0.33, '3100701011': 0.66, '3100701012': 1.0, '3100701013': 1.0, '3100701014': 0.66, '3100701015': 0.66, '3100701016': 1.0, '3100701019': 0.66, '3100701021': 0.66, '3100701022': 0.66, '3100701023': 0.33, '3100701024': 0.66, '3100701029': 0.66, '3100701031': 1.0, '3100701032': 0.66, '3100701036': 0.66, '3100701043': 0.66, '3100701044': 0.66, '3100701050': 0.66, '3100701051': 0.66, '3100701056': 1.0, '3100701057': 0.66, '3100701058': 1.0, '3100701061': 0.66, '3100701063': 0.66, '3100701072': 1.0, '3100701073': 0.66, '3100702004': 0.66, '3100702005': 1.0, '3100702006': 0.66, '3100702010': 0.66, '3100702012': 1.0, '3100702013': 1.0, '3100702016': 1.0, '3100702017': 0.66, '3100702019': 0.66, '3100702020': 0.66, '3100702021': 0.66, '3100702022': 0.66, '3100702023': 0.66, '3100702024': 0.66, '3100702025': 1.0, '3100702026': 0.66, '3100702027': 0.66, '3100702028': 0.66, '3100702029': 0.66, '3100702030': 0.66, '3100702031': 0.66, '3100702033': 0.66, '3100702034': 0.66, '3100702035': 0.66, '3100702036': 1.0, '3100702037': 1.0, '3100702038': 0.33, '3100702039': 1.0, '3100702040': 1.0, '3100702041': 1.0, '3100702043': 1.0, '3100702044': 0.66, '3100702045': 1.0, '3100702046': 1.0, '3100702047': 1.0, '3100702048': 1.0, '3100702051': 0.66, '3100702052': 1.0, '3100702054': 0.66, '3100702055': 0.66, '3100702059': 1.0, '3100702060': 0.66, '3100702061': 0.66, '3100702062': 0.66, '3100702063': 0.66, '3100702064': 0.66, '3100702065': 1.0, '3100702066': 0.66, '3100702067': 1.0, '3100702068': 0.66, '3100711007': 0.66, '3100711009': 0.66, '3100711042': 0.66, '3100711043': 1.0, '3100711049': 0.66, '3100711050': 0.66, '3100711051': 1.0, '3100711052': 0.66, '3100712014': 0.66, '3100721002': 0.66, '3100721003': 1.0, '3100721004': 1.0, '3100721005': 0.66, '3100721006': 0.66, '3100721007': 0.66, '3100721008': 0.66, '3100721011': 0.66, '3100721012': 1.0, '3100721013': 0.66, '3100721014': 1.0, '3100721015': 1.0, '3100721016': 1.0, '3100721018': 1.0, '3100721019': 1.0, '3100721020': 1.0, '3100721021': 0.66, '3100721022': 1.0, '3100721023': 1.0, '3100721024': 1.0, '3100721028': 0.66, '3100721029': 1.0, '3100721030': 1.0, '3100721031': 0.33, '3100721032': 1.0, '3100721033': 0.66, '3100721034': 0.66, '3100721036': 0.66, '3100721038': 0.66, '3100721039': 1.0, '3100721040': 1.0, '3100721041': 1.0, '3100721042': 1.0, '3100721044': 0.66, '3100721045': 1.0, '3100721046': 1.0, '3100721047': 1.0, '3100721048': 0.66, '3100721049': 0.66, '3100721050': 0.66, '3100721051': 1.0, '3100721052': 1.0, '3100721053': 0.66, '3100721054': 1.0, '3100721055': 1.0, '3100721056': 1.0, '3100721057': 1.0, '3100721058': 0.66, '3100721059': 1.0, '3100721060': 1.0, '3100721062': 1.0, '3100721063': 1.0, '3100721064': 1.0, '3100721065': 1.0, '3100721066': 1.0, '3100721068': 1.0, '3100721070': 1.0, '3100721071': 0.66, '3100721072': 0.66, '3100722003': 0.66, '3100722004': 1.0, '3100722005': 1.0, '3100722006': 0.66, '3100722007': 1.0, '3100722012': 1.0, '3100722013': 1.0, '3100722014': 1.0, '3100722016': 1.0, '3100722017': 1.0, '3100722020': 1.0, '3100722021': 1.0, '3100722022': 1.0, '3100722023': 1.0, '3100722024': 0.66, '3100722025': 1.0, '3100722026': 1.0, '3100722027': 0.66, '3100722030': 0.66, '3100722031': 1.0, '3100722032': 0.66, '3100722033': 0.66, '3100722034': 1.0, '3100722036': 0.66, '3100722038': 1.0, '3100722039': 1.0, '3100722040': 1.0, '3100722042': 1.0, '3100722044': 1.0, '3100722045': 0.66, '3100722046': 0.66, '3100722047': 1.0, '3100722048': 0.66, '3100722054': 1.0, '3100722055': 1.0, '3100722057': 1.0, '3100722059': 1.0, '3100722061': 1.0, '3100722062': 1.0, '3100722063': 1.0, '3100722064': 1.0, '3100722065': 1.0, '3100722066': 1.0, '3100722067': 1.0, '3100722068': 1.0, '3100722069': 1.0, '3100722070': 1.0, '3100722072': 1.0, '3100722073': 1.0, '3100722074': 0.66, '3100722076': 1.0, '3100722077': 1.0, '3100722078': 1.0, '3100722079': 1.0, '3100731001': 0.66, '3100731006': 0.66, '3100731007': 0.66, '3100731008': 0.66, '3100731009': 0.66, '3100731011': 0.66, '3100731012': 1.0, '3100731013': 1.0, '3100731014': 0.66, '3100731025': 1.0, '3100731026': 1.0, '3100731028': 0.66, '3100731029': 1.0, '3100731030': 0.66, '3100731031': 0.66, '3100731037': 1.0, '3100731038': 1.0, '3100731050': 0.66, '3100731052': 1.0, '3100731054': 1.0, '3100731056': 0.66, '3100731057': 1.0, '3100731058': 1.0, '3100732001': 1.0, '3100732002': 1.0, '3100732003': 0.66, '3100732006': 1.0, '3100732013': 0.66, '3100732014': 1.0, '3100732015': 0.66, '3100732017': 0.66, '3100732018': 1.0, '3100732020': 0.66, '3100732021': 0.66, '3100732022': 0.66, '3100732023': 0.66, '3100732025': 0.66, '3100732027': 0.66, '3100732028': 1.0, '3100732029': 1.0, '3100732031': 0.66, '3100732036': 0.66, '3100732040': 1.0, '3100732041': 0.66, '3100732042': 1.0, '3100732067': 1.0, '3100741001': 0.66, '3100741002': 0.66, '3100741003': 1.0, '3100741004': 1.0, '3100741011': 1.0, '3100741012': 0.66, '3100741013': 0.66, '3100741014': 0.66, '3100741016': 1.0, '3100741017': 1.0, '3100741018': 1.0, '3100741019': 1.0, '3100741020': 1.0, '3100741022': 1.0, '3100741023': 1.0, '3100741024': 1.0, '3100741025': 1.0, '3100741026': 1.0, '3100741027': 0.66, '3100741028': 0.66, '3100741029': 1.0, '3100741030': 0.66, '3100741032': 1.0, '3100741034': 1.0, '3100741035': 1.0, '3100741036': 1.0, '3100741037': 0.66, '3100741038': 1.0, '3100741039': 1.0, '3100741042': 1.0, '3100741043': 0.66, '3100741044': 1.0, '3100741045': 1.0, '3100741047': 1.0, '3100741049': 0.66, '3100741053': 0.66, '3100741054': 0.66, '3100741056': 0.66, '3100741057': 1.0, '3100741058': 1.0, '3100741059': 1.0, '3100741060': 1.0, '3100741061': 1.0, '3100741063': 1.0, '3100741064': 0.66, '3100741065': 1.0, '3100741066': 0.33, '3100741068': 0.66, '3100741069': 1.0, '3100741070': 1.0, '3100741071': 1.0, '3100741072': 1.0, '3100741073': 0.66, '3100741074': 1.0, '3100741075': 0.66, '3100741076': 1.0, '3100741077': 1.0, '3100741079': 1.0, '3100742001': 0.66, '3100742003': 0.66, '3100742004': 0.66, '3100742005': 0.66, '3100742007': 0.66, '3100742010': 0.66, '3100742011': 1.0, '3100742012': 1.0, '3100742013': 1.0, '3100742014': 0.66, '3100742015': 0.66, '3100742016': 0.66, '3100742018': 1.0, '3100742020': 0.66, '3100742021': 0.66, '3100742022': 1.0, '3100742023': 0.66, '3100742024': 1.0, '3100742025': 0.66, '3100742027': 0.66, '3100742028': 1.0, '3100742033': 1.0, '3100742034': 0.66, '3100742037': 0.66, '3100742038': 0.66, '3100742041': 1.0, '3100742042': 1.0, '3100742044': 0.66, '3100742045': 1.0, '3100742046': 0.66, '3100742047': 0.66, '3100742048': 0.66, '3100742050': 0.66, '3100742051': 0.66, '3100742052': 0.66, '3100742053': 0.66, '3100742054': 0.66, '3100742055': 0.66, '3100742056': 0.66, '3100742057': 1.0, '3100742058': 0.33, '3100742059': 1.0, '3100742060': 1.0, '3100742061': 0.66, '3100742062': 0.66, '3100742063': 0.66, '3100742065': 0.66, '3100742067': 1.0, '3100742068': 1.0, '3100751003': 0.66, '3100751004': 0.66, '3100751005': 0.66, '3100751006': 0.33, '3100751007': 0.0, '3100751008': 0.33, '3100751009': 1.0, '3100751010': 0.0, '3100751011': 1.0, '3100751012': 0.33, '3100751014': 0.66, '3100751015': 0.66, '3100751016': 0.66, '3100751017': 0.66, '3100751018': 1.0, '3100751019': 0.33, '3100751020': 1.0, '3100751021': 0.66, '3100751022': 0.66, '3100751024': 1.0, '3100751026': 0.66, '3100751027': 0.66, '3100751028': 0.66, '3100751032': 1.0, '3100751033': 0.66, '3100751034': 0.66, '3100751035': 0.66, '3100751037': 0.66, '3100751039': 0.66, '3100751040': 1.0, '3100751041': 0.66, '3100751043': 1.0, '3100751044': 1.0, '3100751045': 0.66, '3100751048': 0.66, '3100751050': 0.66, '3100751055': 1.0, '3100751056': 0.33, '3100751057': 0.33, '3100751058': 0.66, '3100751059': 0.66, '3100751063': 0.66, '3100751064': 0.66, '3100751065': 0.66, '3100751068': 1.0, '3100751069': 0.66, '3100751070': 0.66, '3100751072': 0.66, '3100751073': 1.0, '3100751074': 0.66, '3100751075': 1.0, '3100751076': 0.66, '3100751077': 0.66, '3100751078': 0.66, '3100751079': 0.66, '3100752001': 0.66, '3100752002': 1.0, '3100752003': 0.66, '3100752004': 0.66, '3100752005': 0.66, '3100752007': 0.66, '3100752008': 0.66, '3100752009': 0.66, '3100752010': 0.66, '3100752012': 0.66, '3100752014': 0.33, '3100752015': 1.0, '3100752016': 0.66, '3100752017': 0.66, '3100752018': 1.0, '3100752019': 1.0, '3100752020': 0.66, '3100752021': 0.33, '3100752022': 0.66, '3100752023': 0.66, '3100752026': 0.66, '3100752027': 0.66, '3100752029': 0.66, '3100752030': 0.33, '3100752032': 0.66, '3100752034': 1.0, '3100752035': 0.66, '3100752036': 0.66, '3100752037': 0.33, '3100752038': 0.66, '3100752039': 0.66, '3100752040': 1.0, '3100752041': 1.0, '3100752042': 0.66, '3100752043': 0.66, '3100752044': 1.0, '3100752045': 1.0, '3100752046': 0.66, '3100752047': 0.66, '3100752048': 0.33, '3100752049': 0.66, '3100752050': 1.0, '3100752051': 0.33, '3100752052': 1.0, '3100752054': 0.66, '3100752055': 0.33, '3100752056': 0.66, '3100752057': 0.66, '3100752058': 1.0, '3100752059': 0.66, '3100752060': 0.66, '3100752061': 0.66, '3100752063': 0.66, '3100752068': 0.66, '3100761003': 0.33, '3100761004': 1.0, '3100761005': 0.33, '3100761007': 0.66, '3100761008': 0.33, '3100761013': 0.66, '3100761014': 0.66, '3100761015': 0.66, '3100761016': 0.66, '3100761017': 0.66, '3100761019': 0.66, '3100761020': 1.0, '3100761021': 1.0, '3100761023': 0.66, '3100761027': 1.0, '3100761028': 1.0, '3100761029': 1.0, '3100761030': 0.66, '3100761031': 0.66, '3100761034': 0.66, '3100761042': 0.66, '3100761046': 0.66, '3100761047': 0.66, '3100761048': 1.0, '3100761049': 0.66, '3100761050': 0.66, '3100761051': 0.66, '3100761056': 0.66, '3100761062': 0.66, '3100761063': 1.0, '3100762003': 0.66, '3100762004': 0.33, '3100762005': 0.66, '3100762007': 1.0, '3100762012': 0.66, '3100762013': 0.66, '3100762016': 0.66, '3100762027': 0.33, '3100762029': 1.0, '3100762030': 0.33, '3100762052': 0.66, '3100762053': 0.66, '3100762055': 0.33, '3100771001': 0.33, '3100771002': 0.66, '3100771003': 1.0, '3100771005': 0.66, '3100771007': 0.33, '3100771008': 0.66, '3100771009': 0.66, '3100771012': 1.0, '3100771014': 0.66, '3100771016': 0.66, '3100771018': 0.66, '3100771019': 0.66, '3100771020': 0.66, '3100771021': 0.66, '3100771022': 0.66, '3100771024': 0.66, '3100771027': 0.66, '3100771028': 0.66, '3100771029': 0.66, '3100771030': 0.66, '3100771031': 0.66, '3100771032': 0.66, '3100771033': 0.66, '3100771034': 0.66, '3100771036': 0.66, '3100771037': 0.66, '3100771039': 0.66, '3100771040': 0.66, '3100771041': 1.0, '3100771042': 1.0, '3100771043': 0.66, '3100771046': 0.66, '3100771047': 0.66, '3100771048': 1.0, '3100771049': 0.66, '3100771050': 1.0, '3100771052': 0.66, '3100771054': 0.66, '3100771055': 0.66, '3100771056': 1.0, '3100771057': 1.0, '3100771058': 1.0, '3100771059': 1.0, '3100771062': 0.66, '3100771063': 1.0, '3100771064': 0.66, '3100771065': 0.66, '3100771066': 0.66, '3100771067': 0.66, '3100771068': 0.66, '3100771069': 0.66, '3100771071': 0.66, '3100771072': 1.0, '3100771073': 0.66, '3100771075': 0.66, '3100771076': 1.0, '3100771077': 1.0, '3100771078': 0.66, '3100771080': 0.66, '3100771081': 1.0, '3100772002': 1.0, '3100772004': 0.66, '3100772005': 0.66, '3100772006': 0.66, '3100772007': 1.0, '3100772008': 1.0, '3100772009': 0.66, '3100772010': 1.0, '3100772011': 1.0, '3100772013': 0.66, '3100772014': 1.0, '3100772015': 1.0, '3100772018': 1.0, '3100772019': 1.0, '3100772020': 0.66, '3100772021': 1.0, '3100772022': 1.0, '3100772023': 0.66, '3100772024': 1.0, '3100772025': 0.66, '3100772026': 1.0, '3100772027': 1.0, '3100772028': 1.0, '3100772029': 0.66, '3100772031': 0.66, '3100772032': 1.0, '3100772033': 1.0, '3100772034': 0.66, '3100772035': 0.66, '3100772036': 1.0, '3100772037': 1.0, '3100772039': 1.0, '3100772040': 1.0, '3100772041': 1.0, '3100772042': 1.0, '3100772043': 0.66, '3100772045': 0.66, '3100772046': 0.66, '3100772048': 0.66, '3100772050': 0.66, '3100772051': 0.33, '3100772052': 0.66, '3100772053': 1.0, '3100772054': 1.0, '3100772055': 1.0, '3100772056': 1.0, '3100772058': 1.0, '3100772059': 1.0, '3100772063': 0.66, '3100772065': 1.0, '3100772066': 0.66, '3100772067': 0.66, '3100772068': 0.66, '3100772069': 1.0, '3100781001': 0.66, '3100781002': 0.33, '3100781004': 0.66, '3100781006': 1.0, '3100781007': 0.33, '3100781008': 1.0, '3100781009': 1.0, '3100781010': 0.66, '3100781011': 1.0, '3100781013': 0.66, '3100781015': 0.66, '3100781016': 1.0, '3100781017': 0.66, '3100781019': 1.0, '3100781020': 1.0, '3100781021': 1.0, '3100781023': 1.0, '3100781024': 1.0, '3100781027': 1.0, '3100781029': 1.0, '3100781030': 1.0, '3100781031': 1.0, '3100781032': 0.66, '3100781033': 0.66, '3100781034': 0.33, '3100781036': 1.0, '3100781038': 0.66, '3100781040': 1.0, '3100781041': 1.0, '3100781043': 1.0, '3100781044': 0.66, '3100781046': 1.0, '3100781047': 1.0, '3100781048': 1.0, '3100781051': 1.0, '3100781052': 1.0, '3100781053': 1.0, '3100781054': 1.0, '3100781055': 1.0, '3100781056': 1.0, '3100781057': 0.66, '3100781058': 1.0, '3100781059': 0.66, '3100781061': 1.0, '3100781062': 1.0, '3100781064': 1.0, '3100781065': 0.66, '3100781066': 0.66, '3100781068': 0.66, '3100781069': 1.0, '3100781070': 0.66, '3100781071': 0.66, '3100781073': 0.66, '3100781074': 1.0, '3100781075': 1.0, '3100781076': 1.0, '3100781078': 1.0, '3100781079': 1.0, '3100781080': 1.0, '3100781081': 1.0, '3100782001': 0.66, '3100782003': 1.0, '3100782004': 1.0, '3100782005': 1.0, '3100782006': 0.66, '3100782008': 1.0, '3100782010': 0.66, '3100782011': 1.0, '3100782012': 1.0, '3100782013': 0.66, '3100782014': 1.0, '3100782015': 1.0, '3100782016': 1.0, '3100782017': 1.0, '3100782018': 0.66, '3100782019': 1.0, '3100782021': 1.0, '3100782022': 1.0, '3100782023': 1.0, '3100782024': 1.0, '3100782025': 1.0, '3100782026': 0.66, '3100782027': 1.0, '3100782028': 0.66, '3100782031': 0.66, '3100782032': 1.0, '3100782033': 1.0, '3100782035': 0.66, '3100782036': 0.66, '3100782037': 0.66, '3100782038': 1.0, '3100782039': 0.66, '3100782042': 1.0, '3100782043': 1.0, '3100782045': 1.0, '3100782046': 1.0, '3100782047': 1.0, '3100782049': 1.0, '3100782050': 0.66, '3100782053': 1.0, '3100782054': 0.66, '3100782055': 0.66, '3100782057': 1.0, '3100782058': 1.0, '3100782059': 0.66, '3100782061': 1.0, '3100782062': 1.0, '3100782063': 0.66, '3100782064': 1.0, '3100782065': 1.0, '3100782066': 1.0, '3100782067': 0.33, '3100782068': 1.0, '3100782069': 0.66, '3100782071': 0.66, '3100782072': 0.66, '3100791004': 1.0, '3100791006': 0.66, '3100791007': 0.66, '3100791008': 1.0, '3100791016': 0.66, '3100791018': 0.66, '3100791020': 1.0, '3100791021': 1.0, '3100791026': 1.0, '3100791028': 0.66, '3100791031': 1.0, '3100791033': 1.0, '3100791034': 1.0, '3100791035': 1.0, '3100791042': 1.0, '3100791044': 0.66, '3100791045': 1.0, '3100791046': 0.66, '3100791047': 1.0, '3100791049': 0.66, '3100791050': 0.66, '3100791052': 1.0, '3100791054': 0.66, '3100791056': 0.66, '3100791058': 0.33, '3100791059': 1.0, '3100791060': 1.0, '3100791061': 1.0, '3100791062': 0.66, '3100791063': 0.66, '3100791064': 1.0, '3100791065': 0.66, '3100791066': 0.66, '3100791067': 0.66, '3100791069': 0.66, '3100791070': 0.66, '3100791071': 1.0, '3100791072': 0.66, '3100791073': 0.66, '3100792002': 0.66, '3100792003': 0.66, '3100792004': 0.66, '3100792005': 0.66, '3100792006': 0.66, '3100792007': 1.0, '3100792008': 0.66, '3100792009': 0.66, '3100792010': 0.66, '3100792011': 0.66, '3100792013': 0.66, '3100792014': 1.0, '3100792015': 0.66, '3100792016': 0.66, '3100792019': 1.0, '3100792020': 0.66, '3100792021': 0.66, '3100792022': 0.66, '3100792023': 0.66, '3100792024': 0.66, '3100792025': 0.66, '3100792027': 1.0, '3100792028': 0.66, '3100792030': 0.66, '3100792031': 1.0, '3100792032': 0.66, '3100792033': 0.66, '3100792035': 0.66, '3100792036': 0.66, '3100792037': 0.66, '3100792038': 0.66, '3100792039': 0.66, '3100792040': 0.66, '3100792041': 0.66, '3100792042': 1.0, '3100792043': 0.66, '3100792044': 0.66, '3100792045': 0.33, '3100792046': 1.0, '3100792048': 1.0, '3100792050': 0.66, '3100792051': 0.66, '3100792052': 0.66, '3100792053': 0.66, '3100792057': 0.66, '3100792058': 0.66, '3100792060': 0.66, '3100792069': 0.66, '3100801006': 0.66, '3100802001': 1.0, '3100802028': 1.0, '3100811002': 0.66, '3100811018': 0.66, '3100811027': 0.66, '3100811034': 0.66, '3100811035': 0.66, '3100811036': 1.0, '3100811037': 0.66, '3100811038': 0.66, '3100811039': 0.66, '3100811040': 1.0, '3100811041': 1.0, '3100811042': 0.66, '3100811043': 0.66, '3100811045': 0.66, '3100811046': 0.66, '3100811047': 0.66, '3100811050': 1.0, '3100811051': 0.66, '3100811053': 0.66, '3100811054': 0.66, '3100811055': 0.66, '3100811056': 1.0, '3100811059': 0.66, '3100811060': 1.0, '3100811061': 0.66, '3100811063': 1.0, '3100811068': 0.66, '3100811075': 0.66, '3100812003': 1.0, '3100812004': 0.66, '3100812005': 1.0, '3100812006': 1.0, '3100812007': 0.66, '3100812008': 1.0, '3100812013': 1.0, '3100812014': 0.66, '3100812016': 0.66, '3100812017': 1.0, '3100812018': 0.66, '3100812019': 0.66, '3100812020': 0.66, '3100812021': 0.66, '3100812026': 0.66, '3100812027': 0.66, '3100812028': 0.33, '3100812040': 0.66, '3100821004': 0.66, '3100821015': 0.66, '3100821016': 1.0, '3100821019': 0.66, '3100821020': 1.0, '3100821021': 0.66, '3100821022': 0.33, '3100821030': 1.0, '3100821031': 0.66, '3100821032': 0.33, '3100821033': 0.0, '3100821034': 1.0, '3100821035': 1.0, '3100821036': 1.0, '3100821037': 0.66, '3100821038': 0.33, '3100821039': 0.66, '3100821040': 0.66, '3100821041': 0.66, '3100821042': 1.0, '3100821045': 0.66, '3100821046': 0.66, '3100821047': 0.66, '3100821048': 0.33, '3100821049': 1.0, '3100821051': 1.0, '3100821052': 0.0, '3100821054': 0.66, '3100821055': 0.66, '3100821057': 0.33, '3100821067': 0.66, '3100821068': 1.0, '3100821069': 0.0, '3100821075': 0.0, '3100822001': 0.66, '3100822011': 0.33, '3100822012': 0.66, '3100822014': 0.66, '3100822030': 1.0, '3100822031': 0.0, '3100822044': 1.0, '3100822050': 1.0, '3100822051': 1.0, '3100822057': 1.0, '3100822058': 1.0, '3100822059': 0.66, '3100822064': 1.0, '3100822065': 0.33, '3100822066': 0.0, '3100822067': 0.66, '3100822068': 0.66, '3100822069': 1.0, '3100822070': 0.66, '3100822075': 1.0, '3100822080': 0.66, '3100831003': 0.66, '3100831004': 1.0, '3100831006': 0.66, '3100831007': 1.0, '3100831008': 1.0, '3100831010': 0.66, '3100831011': 0.66, '3100831013': 0.66, '3100831014': 0.66, '3100831015': 0.66, '3100831016': 0.66, '3100831018': 0.66, '3100831019': 1.0, '3100831020': 1.0, '3100831022': 1.0, '3100831024': 0.66, '3100831026': 1.0, '3100831027': 1.0, '3100831028': 0.66, '3100831029': 0.66, '3100831032': 0.66, '3100831033': 0.66, '3100831035': 1.0, '3100831036': 0.66, '3100831037': 0.66, '3100831044': 0.66, '3100831045': 1.0, '3100831046': 1.0, '3100831047': 1.0, '3344630110': 1.0, '33446301100': 0.66, '33446301101': 0.66, '33446301103': 1.0, '33446301104': 0.66, '33446301107': 1.0, '3344630112': 1.0, '3344630113': 0.66, '3344630115': 1.0, '3344630116': 0.66, '3344630117': 1.0, '3344630119': 0.66, '334463012': 1.0, '3344630120': 1.0, '3344630121': 0.33, '3344630127': 0.66, '3344630130': 1.0, '3344630131': 0.33, '3344630132': 0.66, '3344630133': 0.66, '3344630136': 0.66, '3344630139': 0.66, '334463014': 0.66, '3344630140': 1.0, '3344630141': 0.66, '3344630142': 1.0, '3344630143': 1.0, '3344630146': 0.66, '3344630147': 0.66, '3344630148': 1.0, '3344630149': 1.0, '3344630150': 0.66, '3344630151': 0.66, '3344630153': 0.66, '3344630156': 0.66, '3344630161': 1.0, '3344630162': 0.33, '3344630163': 1.0, '3344630164': 0.66, '3344630166': 0.66, '3344630170': 1.0, '3344630171': 0.66, '3344630172': 0.66, '3344630173': 1.0, '3344630176': 1.0, '3344630179': 0.66, '3344630180': 0.66, '3344630181': 0.66, '3344630182': 0.66, '3344630184': 1.0, '3344630185': 0.66, '3344630186': 0.66, '3344630188': 1.0, '3344630189': 1.0, '334463019': 0.66, '3344630190': 1.0, '3344630196': 0.66, '3344630197': 0.66, '3344630198': 1.0, '3344630199': 0.66, '334463021': 1.0, '3344630210': 0.66, '3344630211': 0.33, '3344630213': 1.0, '3344630215': 1.0, '3344630216': 1.0, '3344630219': 1.0, '334463022': 0.66, '3344630220': 1.0, '3344630221': 0.66, '3344630224': 0.66, '3344630225': 1.0, '3344630226': 0.66, '3344630231': 0.66, '3344630232': 0.66, '3344630233': 0.66, '3344630236': 1.0, '3344630238': 0.66, '3344630240': 1.0, '3344630241': 1.0, '3344630242': 1.0, '3344630243': 1.0, '3344630245': 1.0, '3344630247': 1.0, '3344630248': 0.66, '334463025': 0.66, '3344630251': 1.0, '3344630252': 0.66, '3344630255': 0.66, '3344630257': 1.0, '334463026': 0.66, '3344630260': 1.0, '3344630262': 0.66, '3344630264': 0.66, '3344630265': 1.0, '3344630266': 0.66, '3344630267': 0.66, '334463027': 0.66, '3344630270': 0.66, '3344630271': 1.0, '3344630273': 0.66, '3344630276': 0.66, '3344630278': 1.0, '334463028': 1.0, '3344630280': 0.66, '3344630281': 0.66, '3344630282': 0.33, '334463029': 1.0, '33702101100': 1.0, '33702101110': 1.0, '33702101130': 1.0, '33702101140': 1.0, '33702101150': 1.0, '33702101180': 0.66, '33702101200': 1.0, '33702101210': 1.0, '33702101250': 0.66, '33702101260': 1.0, '33702101270': 1.0, '33702101280': 1.0, '33702101290': 0.66, '33702101300': 1.0, '33702101340': 1.0, '33702101350': 1.0, '33702101360': 1.0, '33702101370': 1.0, '33702101410': 1.0, '33702101430': 0.66, '33702101450': 0.66, '33702101460': 1.0, '33702101470': 0.66, '33702101480': 0.66, '33702101490': 0.66, '3370210150': 0.66, '33702101500': 1.0, '33702101530': 1.0, '33702101540': 0.66, '33702101550': 1.0, '33702101580': 1.0, '33702101590': 1.0, '33702101600': 0.66, '33702101620': 0.66, '33702101630': 1.0, '33702101640': 1.0, '33702101650': 1.0, '33702101660': 1.0, '33702101700': 1.0, '33702101710': 1.0, '33702101730': 1.0, '33702101740': 1.0, '33702101750': 1.0, '33702101760': 1.0, '3370210180': 1.0, '33702102100': 1.0, '33702102110': 1.0, '33702102130': 0.66, '33702102140': 0.66, '33702102160': 1.0, '33702102170': 1.0, '33702102180': 1.0, '33702102190': 1.0, '33702102200': 1.0, '33702102220': 0.66, '33702102230': 1.0, '33702102240': 1.0, '33702102250': 1.0, '33702102280': 1.0, '3370210230': 1.0, '33702102300': 1.0, '33702102310': 1.0, '33702102330': 1.0, '33702102350': 1.0, '33702102390': 1.0, '3370210240': 1.0, '33702102400': 1.0, '33702102420': 1.0, '33702102430': 1.0, '33702102470': 0.66, '33702102500': 1.0, '33702102530': 1.0, '33702102540': 1.0, '33702102550': 1.0, '33702102570': 1.0, '33702102580': 1.0, '33702102590': 1.0, '3370210260': 1.0, '33702102600': 1.0, '33702102640': 0.66, '33702102670': 1.0, '33702102690': 1.0, '33702102710': 1.0, '33702102740': 1.0, '3370210280': 1.0, '33702102820': 1.0, '33702102840': 1.0, '33702102850': 1.0, '33702102870': 1.0, '33702102880': 1.0, '342227010': 1.0, '342227011': 1.0, '3422270111': 0.33, '3422270112': 1.0, '3422270115': 0.66, '3422270116': 1.0, '3422270117': 0.66, '3422270118': 0.66, '3422270121': 1.0, '3422270122': 1.0, '3422270123': 1.0, '3422270126': 0.66, '3422270127': 1.0, '3422270128': 1.0, '3422270129': 0.33, '342227013': 1.0, '3422270130': 0.66, '3422270131': 0.66, '3422270133': 1.0, '3422270134': 1.0, '3422270135': 0.66, '3422270138': 1.0, '3422270139': 1.0, '3422270140': 1.0, '3422270141': 0.66, '3422270142': 0.66, '3422270143': 1.0, '3422270144': 1.0, '3422270149': 0.66, '3422270151': 0.66, '3422270152': 0.66, '3422270153': 0.66, '3422270154': 1.0, '3422270155': 0.66, '3422270157': 0.66, '3422270158': 0.66, '3422270160': 0.66, '3422270165': 1.0, '3422270166': 1.0, '3422270167': 0.33, '3422270168': 1.0, '3422270169': 1.0, '3422270171': 0.66, '3422270172': 1.0, '342227020': 1.0, '342227021': 1.0, '3422270210': 1.0, '3422270211': 1.0, '3422270212': 0.66, '3422270213': 1.0, '3422270215': 0.66, '3422270216': 1.0, '3422270217': 1.0, '3422270219': 0.66, '3422270220': 0.66, '3422270221': 0.66, '3422270222': 1.0, '3422270223': 1.0, '3422270224': 1.0, '3422270225': 0.66, '3422270227': 0.66, '342227023': 1.0, '3422270230': 0.66, '3422270238': 1.0, '3422270239': 1.0, '342227024': 1.0, '3422270240': 0.66, '3422270241': 1.0, '3422270242': 1.0, '3422270244': 0.66, '3422270245': 1.0, '3422270246': 0.66, '3422270247': 1.0, '3422270249': 0.66, '342227025': 1.0, '3422270250': 1.0, '3422270251': 0.66, '3422270252': 1.0, '3422270253': 1.0, '3422270254': 1.0, '3422270255': 1.0, '3422270256': 1.0, '3422270257': 0.66, '3422270261': 1.0, '3422270262': 0.66, '3422270263': 1.0, '3422270264': 1.0, '3422270267': 1.0, '3422270268': 1.0, '3422270269': 1.0, '342227027': 1.0, '3422270274': 0.66, '3422270278': 1.0, '3422270279': 1.0, '3422270280': 1.0, '3422270281': 1.0, '342227029': 1.0, '350361011': 0.66, '3503610110': 1.0, '3503610111': 1.0, '3503610112': 1.0, '3503610113': 0.66, '3503610114': 0.66, '3503610115': 0.66, '3503610116': 1.0, '3503610117': 1.0, '3503610118': 1.0, '3503610119': 1.0, '350361012': 1.0, '3503610120': 0.66, '3503610121': 1.0, '3503610122': 1.0, '3503610123': 1.0, '3503610124': 1.0, '3503610125': 1.0, '3503610126': 1.0, '3503610127': 0.66, '3503610128': 1.0, '3503610129': 0.66, '350361013': 0.66, '3503610130': 1.0, '3503610131': 1.0, '3503610132': 1.0, '3503610133': 0.66, '3503610134': 1.0, '3503610135': 1.0, '3503610136': 1.0, '3503610137': 0.66, '3503610138': 1.0, '3503610139': 0.66, '350361014': 1.0, '3503610140': 1.0, '3503610141': 1.0, '3503610142': 0.66, '3503610143': 1.0, '3503610144': 1.0, '3503610145': 1.0, '3503610146': 1.0, '3503610147': 1.0, '3503610148': 1.0, '3503610149': 0.66, '350361015': 1.0, '3503610150': 1.0, '3503610151': 1.0, '3503610152': 1.0, '3503610154': 1.0, '3503610156': 1.0, '3503610157': 0.66, '3503610158': 0.33, '350361016': 0.66, '3503610163': 1.0, '3503610168': 0.0, '350361017': 1.0, '350361019': 1.0, '350361021': 1.0, '3503610210': 1.0, '3503610212': 1.0, '3503610213': 0.66, '3503610214': 0.66, '3503610217': 1.0, '350361022': 0.66, '3503610223': 1.0, '3503610224': 1.0, '3503610225': 1.0, '3503610226': 1.0, '3503610227': 1.0, '3503610228': 1.0, '350361023': 1.0, '3503610230': 1.0, '3503610231': 1.0, '3503610233': 1.0, '3503610234': 0.66, '3503610235': 1.0, '3503610236': 1.0, '3503610237': 1.0, '3503610238': 1.0, '350361024': 1.0, '3503610240': 1.0, '3503610241': 0.66, '3503610242': 1.0, '3503610245': 1.0, '3503610246': 1.0, '3503610248': 1.0, '3503610250': 1.0, '3503610251': 0.66, '3503610252': 1.0, '3503610253': 1.0, '3503610254': 1.0, '3503610255': 0.66, '3503610256': 1.0, '3503610257': 1.0, '350361026': 1.0, '3503610260': 1.0, '3503610261': 1.0, '3503610264': 1.0, '3503610265': 0.66, '3503610266': 1.0, '3503610267': 1.0, '3503610268': 1.0, '3503610269': 0.66, '3503610270': 1.0, '3503610272': 0.66, '3503610273': 1.0, '3503610275': 0.66, '3503610276': 0.66, '3503610277': 1.0, '3503610278': 0.66, '3503610279': 1.0, '350361028': 0.33, '350361029': 0.66, '4000181002': 0.66, '4000181004': 0.33, '4000181005': 0.66, '4000181006': 0.66, '4000181007': 0.66, '4000181008': 0.66, '4000181010': 0.66, '4000181011': 0.66, '4000181012': 0.66, '4000181013': 1.0, '4000181014': 1.0, '4000181015': 0.33, '4000181016': 0.66, '4000181017': 0.66, '4000181019': 0.66, '4000181020': 1.0, '4000181022': 1.0, '4000181023': 0.66, '4000181024': 1.0, '4000181026': 1.0, '4000181027': 0.66, '4000181028': 1.0, '4000181029': 0.66, '4000181030': 1.0, '4000181031': 0.66, '4000181032': 0.66, '4000181033': 1.0, '4000181035': 1.0, '4000181036': 0.66, '4000181037': 0.66, '4000181039': 0.66, '4000181041': 1.0, '4000181042': 1.0, '4000181043': 0.66, '4000181044': 1.0, '4000181045': 0.66, '4000181046': 0.66, '4000181047': 0.66, '4000181048': 1.0, '4000181049': 1.0, '4000181053': 0.66, '4000181054': 0.66, '4000181055': 0.66, '4000181056': 1.0, '4000181057': 0.66, '4000181060': 0.66, '4000181061': 1.0, '4000181062': 0.66, '4000181063': 0.66, '4000181064': 0.66, '4000181065': 0.66, '4000181066': 1.0, '4000181067': 0.66, '4000181068': 0.66, '4000181069': 0.66, '4000181070': 1.0, '4000181072': 0.66, '4000181073': 0.66, '4000181074': 0.66, '4000181075': 0.66, '4000181076': 0.66, '4000181077': 0.66, '4000181078': 1.0, '4000181079': 0.66, '4000181080': 1.0, '4000182003': 1.0, '4000182004': 0.66, '4000182005': 0.66, '4000182006': 0.66, '4000182007': 1.0, '4000182008': 0.66, '4000182009': 1.0, '4000182010': 1.0, '4000182011': 0.66, '4000182013': 1.0, '4000182014': 1.0, '4000182015': 0.66, '4000182016': 0.66, '4000182017': 1.0, '4000182018': 0.66, '4000182020': 1.0, '4000182022': 0.66, '4000182024': 0.66, '4000182025': 1.0, '4000182026': 0.66, '4000182027': 0.66, '4000182028': 0.66, '4000182029': 0.66, '4000182030': 1.0, '4000182031': 0.66, '4000182032': 1.0, '4000182033': 0.66, '4000182035': 0.33, '4000182036': 0.66, '4000182037': 0.66, '4000182038': 0.66, '4000182039': 0.66, '4000182040': 1.0, '4000182041': 1.0, '4000182042': 1.0, '4000182044': 1.0, '4000182046': 0.66, '4000182047': 0.66, '4000182049': 1.0, '4000182050': 0.66, '4000182051': 0.66, '4000182053': 0.66, '4000182054': 0.66, '4000182055': 0.66, '4000182058': 0.66, '4000182059': 1.0, '4000182060': 1.0, '4000182062': 0.66, '4000182063': 0.66, '4000182064': 1.0, '4000182067': 0.66, '4000182068': 0.66, '4000182069': 0.66, '4000221001': 0.66, '4000221002': 1.0, '4000221006': 0.66, '4000221008': 1.0, '4000221009': 0.66, '4000221010': 0.66, '4000221011': 0.66, '4000221013': 0.66, '4000221014': 0.66, '4000221015': 0.66, '4000221016': 1.0, '4000221017': 1.0, '4000221018': 0.66, '4000221024': 0.66, '4000221033': 0.66, '4000221034': 0.66, '4000221035': 0.66, '4000221036': 0.66, '4000221040': 0.33, '4000221041': 0.66, '4000221042': 1.0, '4000221054': 0.66, '4000221055': 0.66, '4000221061': 1.0, '4000221062': 1.0, '4000221064': 0.66, '4000221065': 0.66, '4000221066': 0.66, '4000221067': 0.66, '4000221071': 0.66, '4000221072': 0.66, '4000222001': 1.0, '4000222003': 0.66, '4000222004': 1.0, '4000222007': 0.66, '4000222012': 1.0, '4000222013': 0.66, '4000222014': 0.66, '4000222015': 0.66, '4000222017': 0.66, '4000222031': 0.33, '4000222032': 0.0, '4000222035': 0.66, '4000222036': 0.33, '4000222038': 1.0, '4000222039': 1.0, '4000222040': 0.66, '4000222041': 0.33, '4000222042': 0.66, '4000222044': 0.66, '4000222045': 0.66, '4000222046': 1.0, '4000222051': 0.66, '4000222052': 0.66, '4000222054': 1.0, '4000222056': 0.66, '4000222057': 0.66, '4000222068': 0.66, '4000222069': 0.66, '4000222070': 1.0, '4000231001': 1.0, '4000231008': 0.66, '4000231010': 0.66, '4000231011': 1.0, '4000231012': 1.0, '4000231013': 0.66, '4000231014': 0.66, '4000231021': 1.0, '4000231032': 1.0, '4000231033': 0.66, '4000231034': 0.66, '4000231037': 1.0, '4000231038': 1.0, '4000231047': 0.66, '4000231049': 0.66, '4000231052': 0.66, '4000231060': 0.66, '4000231061': 0.66, '4000231063': 0.66, '4000231065': 1.0, '4000231070': 1.0, '4000231071': 0.66, '4000231073': 0.66, '4000231074': 1.0, '4000231081': 1.0, '4000232001': 0.66, '4000232004': 0.66, '4000232005': 0.66, '4000232006': 0.66, '4000232007': 1.0, '4000232010': 0.66, '4000232016': 1.0, '4000232017': 1.0, '4000232018': 1.0, '4000232022': 0.66, '4000232024': 0.66, '4000232027': 1.0, '4000232034': 0.66, '4000232035': 1.0, '4000232036': 1.0, '4000232037': 0.66, '4000232038': 0.66, '4000232042': 0.66, '4000232044': 1.0, '4000232045': 1.0, '4000232048': 0.66, '4000232051': 0.66, '4000232054': 0.66, '4000232059': 0.66, '4000232062': 0.66, '4000232065': 0.66, '4000232068': 1.0, '4000232071': 0.33, '4000232072': 0.66, '4000301002': 0.66, '4000301003': 0.66, '4000301005': 0.33, '4000301006': 0.33, '4000301007': 0.66, '4000301008': 0.66, '4000301010': 0.33, '4000301011': 0.0, '4000301012': 0.66, '4000301013': 0.66, '4000301014': 0.66, '4000301015': 0.66, '4000301016': 0.66, '4000301018': 0.66, '4000301019': 0.66, '4000301020': 0.66, '4000301021': 0.33, '4000301022': 1.0, '4000301023': 1.0, '4000301025': 1.0, '4000301026': 0.66, '4000301027': 0.66, '4000301028': 0.0, '4000301030': 0.0, '4000301031': 0.66, '4000301032': 1.0, '4000301034': 0.66, '4000301038': 1.0, '4000301039': 1.0, '4000301040': 1.0, '4000301041': 1.0, '4000301042': 0.0, '4000301043': 1.0, '4000301044': 0.66, '4000301045': 1.0, '4000301047': 1.0, '4000301049': 0.33, '4000301052': 1.0, '4000301053': 0.66, '4000301054': 0.66, '4000301055': 0.33, '4000301056': 0.66, '4000301057': 0.66, '4000301058': 0.66, '4000301059': 0.66, '4000301060': 0.33, '4000301061': 0.66, '4000301062': 0.66, '4000301063': 1.0, '4000301064': 0.66, '4000301065': 0.33, '4000301066': 0.33, '4000301067': 0.33, '4000301068': 0.66, '4000301069': 0.66, '4000301070': 0.0, '4000301071': 0.66, '4000301072': 1.0, '4000301073': 1.0, '4000301074': 0.66, '4000301076': 0.66, '4000301079': 0.66, '4000331001': 0.66, '4000331002': 0.66, '4000331003': 1.0, '4000331004': 1.0, '4000331005': 1.0, '4000331006': 1.0, '4000331007': 0.66, '4000331008': 1.0, '4000331011': 1.0, '4000331012': 1.0, '4000331013': 0.66, '4000331015': 0.66, '4000331017': 0.66, '4000331019': 1.0, '4000331020': 1.0, '4000331021': 0.66, '4000331022': 0.66, '4000331023': 1.0, '4000331025': 1.0, '4000331027': 1.0, '4000331029': 0.66, '4000331030': 0.66, '4000331031': 0.66, '4000331032': 0.66, '4000331033': 1.0, '4000331035': 1.0, '4000331036': 0.66, '4000331037': 0.66, '4000331038': 1.0, '4000331039': 0.66, '4000331040': 0.66, '4000331041': 0.66, '4000331042': 1.0, '4000331043': 1.0, '4000331044': 1.0, '4000331045': 0.66, '4000331046': 0.66, '4000331051': 0.66, '4000331052': 1.0, '4000331053': 1.0, '4000331054': 0.66, '4000331055': 0.66, '4000331056': 0.66, '4000331057': 1.0, '4000331058': 0.66, '4000331060': 0.66, '4000331062': 0.66, '4000331063': 0.66, '4000331064': 0.66, '4000331067': 1.0, '4000331068': 0.66, '4000331069': 0.66, '4000332001': 0.66, '4000332002': 0.66, '4000332007': 0.66, '4000332008': 1.0, '4000332009': 0.66, '4000332010': 0.66, '4000332012': 0.66, '4000332013': 0.66, '4000332014': 1.0, '4000332015': 0.66, '4000332017': 1.0, '4000332019': 0.66, '4000332020': 0.66, '4000332021': 0.66, '4000332022': 0.66, '4000332023': 0.66, '4000332025': 1.0, '4000332027': 0.66, '4000332030': 1.0, '4000332031': 0.66, '4000332032': 0.66, '4000332034': 1.0, '4000332035': 0.66, '4000332036': 1.0, '4000332037': 1.0, '4000332038': 0.66, '4000332039': 0.66, '4000332041': 1.0, '4000332044': 1.0, '4000332045': 1.0, '4000332046': 0.66, '4000332048': 1.0, '4000332050': 1.0, '4000332051': 0.66, '4000332052': 0.66, '4000332057': 0.66, '4000332059': 0.66, '4000332060': 1.0, '4000332061': 0.66, '4000332062': 0.66, '4000332063': 1.0, '4000332064': 0.66, '4000332066': 1.0, '4000332067': 1.0, '4000332068': 1.0, '4000332071': 0.66, '4000332072': 0.66, '4000332073': 0.66, '4000332074': 1.0, '4000332075': 0.66, '4000332077': 1.0, '4000332078': 0.66, '4000332079': 1.0, '4000332080': 1.0, '4000332081': 0.66, '4000332082': 0.33, '401835011': 1.0, '4018350112': 0.66, '4018350115': 1.0, '4018350116': 0.66, '4018350118': 1.0, '4018350119': 0.66, '4018350120': 1.0, '4018350121': 1.0, '4018350122': 0.66, '4018350126': 0.66, '4018350127': 0.66, '401835013': 1.0, '4018350130': 1.0, '4018350132': 1.0, '4018350134': 1.0, '4018350136': 1.0, '4018350137': 1.0, '4018350138': 1.0, '4018350139': 1.0, '4018350140': 1.0, '4018350141': 1.0, '4018350143': 1.0, '4018350144': 0.66, '4018350145': 0.66, '4018350146': 1.0, '4018350147': 0.66, '4018350149': 1.0, '401835015': 0.33, '4018350150': 0.66, '4018350152': 1.0, '4018350156': 1.0, '4018350157': 1.0, '4018350159': 1.0, '4018350160': 1.0, '4018350161': 1.0, '4018350162': 1.0, '4018350163': 1.0, '4018350166': 1.0, '4018350167': 1.0, '401835017': 0.66, '401835018': 1.0, '401835021': 0.66, '4018350213': 1.0, '4018350215': 0.66, '4018350217': 0.66, '4018350219': 0.66, '4018350220': 1.0, '4018350221': 0.66, '4018350222': 1.0, '4018350223': 1.0, '4018350224': 0.66, '4018350225': 1.0, '4018350226': 1.0, '4018350227': 1.0, '4018350231': 0.66, '4018350232': 1.0, '4018350233': 0.66, '4018350234': 1.0, '4018350236': 1.0, '4018350239': 0.66, '401835024': 0.66, '4018350240': 0.66, '4018350241': 1.0, '4018350244': 1.0, '4018350247': 0.66, '4018350251': 0.66, '4018350254': 1.0, '4018350256': 1.0, '4018350257': 1.0, '4018350258': 1.0, '4018350259': 0.66, '4018350260': 1.0, '4018350261': 1.0, '4018350263': 0.66, '4018350268': 1.0, '4018350269': 1.0, '4018350274': 0.66, '4018350276': 1.0, '4018350277': 0.66, '4018350279': 0.66, '401835028': 1.0, '4018350281': 0.66, '4018350282': 0.33, '4100191001': 0.66, '4100191002': 0.66, '4100191003': 1.0, '4100191004': 1.0, '4100191006': 0.66, '4100191007': 0.66, '4100191008': 0.33, '4100191010': 0.66, '4100191012': 0.66, '4100191014': 0.66, '4100191016': 0.66, '4100191017': 0.66, '4100191018': 1.0, '4100191020': 1.0, '4100191021': 0.66, '4100191023': 0.66, '4100191024': 0.66, '4100191025': 0.66, '4100191026': 0.66, '4100191030': 1.0, '4100191031': 0.66, '4100191032': 0.66, '4100191033': 0.0, '4100191034': 1.0, '4100191035': 0.66, '4100191038': 0.66, '4100191039': 0.66, '4100191041': 0.33, '4100191042': 0.66, '4100191043': 0.66, '4100191045': 0.66, '4100191046': 0.66, '4100191052': 0.66, '4100191053': 0.66, '4100192001': 0.66, '4100192002': 0.66, '4100192003': 0.66, '4100192004': 0.66, '4100192005': 0.66, '4100192006': 1.0, '4100192007': 0.66, '4100192010': 0.33, '4100192011': 0.33, '4100192012': 0.66, '4100192013': 0.66, '4100192014': 1.0, '4100192015': 0.33, '4100192016': 0.33, '4100192019': 0.66, '4100192020': 0.66, '4100192022': 0.66, '4100192023': 1.0, '4100192024': 0.66, '4100192025': 1.0, '4100192026': 0.0, '4100192027': 0.66, '4100192028': 1.0, '4100192029': 0.0, '4100192031': 0.33, '4100192032': 1.0, '4100192033': 0.66, '4100192034': 0.66, '4100192036': 0.66, '4100192037': 0.66, '4100192038': 0.66, '4100192039': 0.66, '4100192040': 0.66, '4100192043': 0.66, '4100192044': 0.66, '4100192045': 0.66, '4100192046': 0.66, '4100192047': 1.0, '4100192048': 0.66, '4100192049': 0.33, '4100192050': 0.66, '4100192051': 0.66, '4100192052': 0.66, '4100192053': 0.33, '4100192054': 0.66, '4100192055': 0.66, '4100192056': 0.66, '4100192057': 1.0, '4100192058': 0.66, '4100192060': 0.33, '4100192061': 0.66, '4100192062': 1.0, '4100192063': 0.66, '4100192066': 0.66, '4100192068': 0.66, '4100201001': 1.0, '4100201003': 0.66, '4100201004': 1.0, '4100201005': 0.66, '4100201006': 0.66, '4100201007': 0.66, '4100201008': 1.0, '4100201009': 0.66, '4100201010': 1.0, '4100201011': 0.66, '4100201013': 1.0, '4100201014': 1.0, '4100201016': 0.66, '4100201017': 1.0, '4100201018': 1.0, '4100201020': 1.0, '4100201021': 0.66, '4100201022': 1.0, '4100201023': 1.0, '4100201024': 1.0, '4100201025': 1.0, '4100201026': 0.66, '4100201027': 0.66, '4100201030': 0.33, '4100201031': 1.0, '4100201032': 0.33, '4100201033': 0.66, '4100201034': 0.66, '4100201035': 1.0, '4100201039': 0.33, '4100201040': 1.0, '4100201041': 0.66, '4100201042': 1.0, '4100201043': 0.33, '4100201044': 0.66, '4100201045': 0.66, '4100201046': 0.66, '4100201048': 0.66, '4100201049': 1.0, '4100201051': 1.0, '4100201052': 0.66, '4100201053': 0.66, '4100201054': 1.0, '4100201055': 1.0, '4100201056': 0.66, '4100201058': 1.0, '4100201059': 0.66, '4100201060': 0.66, '4100201061': 0.0, '4100201062': 1.0, '4100201063': 0.66, '4100201064': 0.66, '4100201068': 1.0, '4100201069': 1.0, '4100201071': 0.66, '4100201072': 1.0, '4100201073': 1.0, '4100201074': 0.66, '4100201075': 1.0, '4100201076': 0.66, '4100201078': 1.0, '4100201079': 1.0, '4100201081': 0.66, '4100201082': 0.66, '4100202001': 0.66, '4100202004': 0.66, '4100202005': 0.66, '4100202006': 0.66, '4100202007': 1.0, '4100202008': 1.0, '4100202009': 1.0, '4100202010': 0.66, '4100202011': 0.66, '4100202012': 0.66, '4100202013': 0.66, '4100202014': 0.33, '4100202015': 1.0, '4100202016': 1.0, '4100202017': 1.0, '4100202018': 0.66, '4100202019': 1.0, '4100202021': 1.0, '4100202022': 0.66, '4100202023': 1.0, '4100202024': 0.66, '4100202025': 0.66, '4100202032': 0.66, '4100202037': 0.66, '4100202039': 0.66, '4100202040': 0.66, '4100202041': 1.0, '4100202042': 0.66, '4100202043': 1.0, '4100202045': 0.66, '4100202046': 0.33, '4100202048': 0.66, '4100202052': 0.66, '4100202053': 0.66, '4100202054': 1.0, '4100202055': 1.0, '4100202056': 0.66, '4100202063': 1.0, '4100202065': 0.33, '4100202067': 1.0, '4100202068': 0.66, '4100241001': 0.66, '4100241002': 0.66, '4100241003': 0.66, '4100241004': 0.66, '4100241006': 0.66, '4100241007': 0.66, '4100241008': 0.66, '4100241009': 0.66, '4100241011': 0.66, '4100241013': 0.66, '4100241016': 1.0, '4100241017': 0.66, '4100241018': 1.0, '4100241020': 0.66, '4100241029': 0.33, '4100241030': 0.66, '4100241031': 0.66, '4100241042': 0.66, '4100241045': 0.66, '4100241046': 1.0, '4100241049': 0.66, '4100241051': 1.0, '4100241052': 1.0, '4100241053': 1.0, '4100241054': 0.66, '4100241055': 0.33, '4100241056': 1.0, '4100241059': 0.33, '4100241060': 1.0, '4100241061': 1.0, '4100241062': 0.66, '4100241063': 1.0, '4100241064': 0.66, '4100241068': 0.33, '4100241069': 1.0, '4100241075': 1.0, '4100242001': 0.66, '4100242002': 0.66, '4100242003': 0.33, '4100242004': 1.0, '4100242005': 0.66, '4100242006': 0.66, '4100242008': 0.66, '4100242011': 0.66, '4100242020': 0.66, '4100242021': 0.66, '4100242029': 0.66, '4100242031': 0.66, '4100242032': 0.0, '4100242033': 0.33, '4100242034': 0.66, '4100242035': 0.33, '4100242036': 0.66, '4100242037': 0.66, '4100242038': 0.66, '4100242040': 0.66, '4100242045': 0.66, '4100242048': 1.0, '4100242050': 0.66, '4100242053': 0.66, '4100242054': 0.66, '4100242057': 0.33, '4100242059': 0.66, '4100242060': 0.66, '4100242063': 0.33, '4100242065': 0.66, '4100242066': 0.66, '4100242067': 0.66, '4100251003': 0.66, '4100251004': 1.0, '4100251005': 1.0, '4100251006': 0.33, '4100251010': 1.0, '4100251011': 0.66, '4100251012': 0.66, '4100251013': 0.66, '4100251014': 0.66, '4100251015': 1.0, '4100251016': 0.33, '4100251017': 0.66, '4100251018': 0.66, '4100251019': 0.66, '4100251020': 0.33, '4100251021': 0.33, '4100251022': 0.66, '4100251024': 0.33, '4100251026': 1.0, '4100251027': 0.33, '4100251028': 0.33, '4100251029': 0.33, '4100251030': 0.66, '4100251031': 0.66, '4100251032': 0.33, '4100251033': 0.33, '4100251034': 0.66, '4100251035': 0.66, '4100251036': 0.33, '4100251038': 0.33, '4100251039': 0.66, '4100251040': 0.66, '4100251041': 0.33, '4100251042': 0.66, '4100251044': 0.66, '4100251046': 0.33, '4100251047': 0.66, '4100251048': 0.66, '4100251049': 0.33, '4100251051': 0.66, '4100251052': 0.66, '4100251053': 1.0, '4100251054': 1.0, '4100251056': 0.66, '4100251057': 0.0, '4100251059': 0.66, '4100251060': 0.66, '4100251061': 0.33, '4100251062': 0.66, '4100251063': 0.66, '4100251064': 0.66, '4100251065': 0.66, '4100251068': 0.33, '4100251069': 0.66, '4100251070': 0.66, '4100252001': 0.66, '4100252003': 0.66, '4100252004': 1.0, '4100252005': 0.66, '4100252007': 1.0, '4100252010': 0.66, '4100252011': 0.66, '4100252012': 1.0, '4100252013': 0.66, '4100252014': 0.66, '4100252015': 0.66, '4100252016': 0.66, '4100252019': 0.66, '4100252021': 0.66, '4100252022': 0.66, '4100252023': 0.66, '4100252024': 1.0, '4100252027': 0.66, '4100252031': 1.0, '4100252032': 0.66, '4100252033': 0.66, '4100252034': 0.66, '4100252035': 0.66, '4100252036': 0.33, '4100252037': 1.0, '4100252038': 0.66, '4100252039': 0.66, '4100252040': 0.66, '4100252041': 0.33, '4100252043': 1.0, '4100252044': 0.33, '4100252045': 1.0, '4100252048': 0.66, '4100252049': 1.0, '4100252050': 1.0, '4100252051': 1.0, '4100252053': 0.66, '4100252054': 0.66, '4100252055': 0.66, '4100252056': 1.0, '4100252057': 1.0, '4100252058': 0.66, '4100252060': 0.66, '4100252061': 0.33, '4100252062': 1.0, '4100252063': 1.0, '4100252066': 0.66, '4100252069': 0.66, '4100252070': 1.0, '4100252071': 0.66, '4100252072': 1.0, '4100252073': 0.66, '4100252074': 0.66, '4100252075': 0.66, '4100252076': 0.66, '4100252078': 0.66, '4100252081': 0.66, '4100261001': 0.66, '4100261002': 0.66, '4100261003': 1.0, '4100261004': 0.66, '4100261005': 0.33, '4100261006': 0.33, '4100261007': 1.0, '4100261010': 0.66, '4100261012': 0.66, '4100261013': 0.66, '4100261015': 0.66, '4100261016': 1.0, '4100261020': 0.66, '4100261023': 0.66, '4100261025': 0.66, '4100261027': 0.33, '4100261028': 0.66, '4100261029': 0.66, '4100261030': 0.33, '4100261031': 0.66, '4100261032': 0.66, '4100261033': 1.0, '4100261034': 0.33, '4100261035': 1.0, '4100261036': 0.66, '4100261038': 0.66, '4100261041': 0.33, '4100261044': 0.66, '4100261045': 0.66, '4100261046': 0.66, '4100261047': 0.66, '4100261048': 0.66, '4100261049': 0.66, '4100261050': 0.33, '4100261055': 1.0, '4100261056': 0.33, '4100261057': 0.66, '4100261058': 0.33, '4100261060': 0.66, '4100261061': 0.66, '4100262001': 0.66, '4100262003': 0.66, '4100262004': 0.33, '4100262006': 0.0, '4100262007': 0.66, '4100262008': 0.66, '4100262009': 0.66, '4100262010': 0.66, '4100262014': 0.66, '4100262015': 1.0, '4100262016': 0.66, '4100262017': 1.0, '4100262018': 0.66, '4100262019': 0.66, '4100262020': 0.66, '4100262022': 0.66, '4100262023': 0.66, '4100262024': 0.66, '4100262025': 0.66, '4100262027': 0.66, '4100262034': 0.33, '4100262035': 0.66, '4100262037': 1.0, '4100262038': 0.66, '4100262040': 0.66, '4100262041': 0.66, '4100262042': 0.66, '4100262043': 1.0, '4100262044': 0.66, '4100262045': 0.66, '4100262046': 1.0, '4100262047': 0.66, '4100262052': 0.66, '4100262053': 0.66, '4100262056': 0.33, '4100262057': 0.66, '4100262060': 0.66, '4100262063': 0.66, '4100262064': 0.66, '4100262065': 0.66, '4100262066': 0.66, '4100262067': 0.66, '4100262068': 0.66, '4100262069': 1.0, '4100262070': 0.66, '4100271007': 0.66, '4100271008': 0.66, '4100271009': 0.66, '4100271010': 1.0, '4100271011': 1.0, '4100271012': 0.66, '4100271026': 0.66, '4100271028': 0.66, '4100271029': 0.66, '4100271030': 0.66, '4100271032': 1.0, '4100271033': 1.0, '4100271034': 1.0, '4100271038': 0.33, '4100271039': 0.66, '4100271041': 0.33, '4100271042': 0.66, '4100271043': 1.0, '4100271056': 0.33, '4100272024': 0.66, '4100272029': 1.0, '4100272033': 1.0, '4100272034': 0.66, '4100272036': 1.0, '4100272037': 0.66, '4100272043': 1.0, '4100272051': 0.66, '4100272052': 0.66, '4100272056': 1.0, '4100281001': 0.66, '4100281002': 0.66, '4100281015': 0.66, '4100281016': 0.66, '4100281019': 1.0, '4100281022': 0.66, '4100281023': 0.66, '4100281027': 0.66, '4100281029': 0.66, '4100281030': 0.66, '4100281032': 0.33, '4100281033': 0.66, '4100281034': 0.66, '4100281035': 0.66, '4100281036': 0.66, '4100281037': 0.66, '4100281041': 1.0, '4100281042': 0.66, '4100281045': 0.66, '4100281046': 0.33, '4100281048': 0.66, '4100281049': 0.66, '4100281050': 0.66, '4100281052': 0.66, '4100281053': 0.33, '4100281054': 0.66, '4100281057': 0.66, '4100281058': 0.66, '4100281059': 0.66, '4100281060': 1.0, '4100281061': 0.66, '4100281062': 0.66, '4100281063': 0.66, '4100281066': 0.66, '4100281067': 0.0, '4100281068': 0.66, '4100281070': 0.33, '4100281072': 0.66, '4100281075': 0.66, '4100281076': 0.33, '4100281078': 1.0, '4100281079': 0.66, '4100281080': 0.66, '4100281081': 0.66, '4100282001': 0.66, '4100282002': 0.66, '4100282003': 1.0, '4100282004': 0.66, '4100282005': 0.66, '4100282007': 0.66, '4100282008': 0.66, '4100282009': 0.33, '4100282012': 0.66, '4100282013': 0.66, '4100282014': 1.0, '4100282015': 0.66, '4100282017': 1.0, '4100282018': 0.66, '4100282019': 1.0, '4100282020': 1.0, '4100282021': 1.0, '4100282022': 1.0, '4100282023': 0.66, '4100282024': 1.0, '4100282033': 0.66, '4100282043': 0.66, '4100282048': 0.66, '4100282053': 1.0, '4100282057': 0.66, '4100282058': 0.66, '4100282066': 0.33, '4100282067': 0.66, '4100282068': 0.66, '4100282070': 0.66, '4100291002': 0.66, '4100291003': 1.0, '4100291004': 0.66, '4100291005': 0.66, '4100291006': 0.33, '4100291007': 0.33, '4100291008': 0.66, '4100291009': 0.66, '4100291010': 0.33, '4100291011': 0.66, '4100291012': 0.66, '4100291014': 0.66, '4100291015': 0.66, '4100291016': 0.66, '4100291017': 0.66, '4100291018': 0.66, '4100291019': 0.33, '4100291021': 0.66, '4100291022': 0.66, '4100291025': 0.66, '4100291026': 0.33, '4100291027': 0.33, '4100291028': 0.66, '4100291032': 0.33, '4100291033': 0.66, '4100291034': 0.66, '4100291036': 0.33, '4100291037': 0.66, '4100291039': 0.66, '4100291040': 0.66, '4100291041': 0.33, '4100291043': 0.66, '4100291046': 0.66, '4100291047': 0.66, '4100291048': 0.66, '4100291049': 0.66, '4100291050': 0.66, '4100291051': 0.66, '4100291055': 0.66, '4100291056': 0.66, '4100291059': 0.66, '4100291060': 1.0, '4100291061': 0.66, '4100291062': 0.66, '4100291063': 1.0, '4100291064': 1.0, '4100291065': 0.66, '4100291070': 0.33, '4100291073': 0.33, '4100291074': 0.66, '4100291076': 0.66, '4100291077': 0.66, '4100291078': 0.33, '4100291079': 0.66, '4100291080': 0.66, '4100291081': 0.33, '4100291082': 0.33, '4100291083': 0.66, '4100291084': 0.33, '4100292001': 0.66, '4100292003': 0.66, '4100292005': 0.66, '4100292008': 0.66, '4100292010': 0.66, '4100292016': 0.66, '4100292019': 0.66, '4100292020': 0.66, '4100292021': 1.0, '4100292022': 0.66, '4100292023': 0.66, '4100292024': 1.0, '4100292025': 0.66, '4100292026': 0.66, '4100292027': 0.66, '4100292028': 0.66, '4100292035': 0.66, '4100292036': 1.0, '4100292037': 0.66, '4100292040': 0.66, '4100292041': 0.66, '4100292042': 1.0, '4100292043': 0.66, '4100292044': 1.0, '4100292045': 1.0, '4100292046': 1.0, '4100292048': 0.33, '4100292049': 0.66, '4100292050': 0.66, '4100292052': 0.66, '4100292053': 0.66, '4100292056': 0.66, '4100292057': 0.66, '4100292059': 0.66, '4100292060': 0.66, '4100292061': 1.0, '4100292062': 0.66, '4100292063': 0.66, '4100292064': 1.0, '4100292065': 0.66, '4100292066': 1.0, '4100292067': 1.0, '4100292068': 1.0, '4100292069': 0.66, '4100292070': 0.66, '4100292071': 0.66, '4100292072': 1.0, '4100292073': 1.0, '4100292074': 0.66, '4100292075': 1.0, '4100292077': 0.66, '4100292078': 1.0, '4100292079': 0.66, '4100292081': 1.0, '4100292083': 1.0, '4100292084': 0.66, '4100292085': 1.0, '4100292087': 0.66, '4100292088': 0.66, '4100302002': 1.0, '4100302013': 0.33, '4100302014': 1.0, '4100302016': 0.33, '4100302017': 0.66, '4100302018': 0.33, '4100302019': 0.66, '4100302020': 0.66, '4100302024': 0.66, '4100302028': 1.0, '4100302030': 0.33, '4100302040': 0.0, '4100302041': 0.66, '4100302042': 0.0, '4100302043': 0.33, '4100302044': 0.0, '4100302045': 0.0, '4100302046': 0.66, '4100302047': 0.66, '4100302048': 0.33, '4100302049': 1.0, '4100302050': 0.66, '4100302051': 0.66, '4100302052': 0.66, '4100302053': 0.66, '4100302054': 1.0, '4100302055': 0.33, '4100302058': 0.0, '4100302061': 0.66, '4100302063': 0.66, '4100302064': 0.0, '4100302066': 0.33, '4100302067': 1.0, '4100302068': 0.66, '4100302069': 1.0, '4100321001': 0.33, '4100321002': 0.66, '4100321003': 1.0, '4100321004': 0.66, '4100321005': 1.0, '4100321006': 0.66, '4100321008': 0.66, '4100321009': 0.33, '4100321010': 1.0, '4100321011': 0.66, '4100321012': 0.66, '4100321014': 0.66, '4100321015': 1.0, '4100321016': 0.66, '4100321019': 0.33, '4100321020': 0.66, '4100321021': 0.66, '4100321022': 1.0, '4100321023': 1.0, '4100321024': 1.0, '4100321026': 1.0, '4100321027': 1.0, '4100321028': 1.0, '4100321029': 0.66, '4100321030': 1.0, '4100321032': 1.0, '4100321033': 0.66, '4100321034': 0.66, '4100321037': 1.0, '4100321038': 1.0, '4100321039': 0.66, '4100321041': 1.0, '4100321042': 0.33, '4100321043': 0.33, '4100321044': 0.33, '4100321045': 0.66, '4100321046': 1.0, '4100321049': 1.0, '4100321051': 0.66, '4100321052': 1.0, '4100321053': 0.66, '4100322001': 0.66, '4100322007': 1.0, '4100322025': 0.66, '4100322031': 0.66, '4100322032': 0.33, '4100322033': 0.66, '4100322034': 0.66, '4100322035': 0.66, '4100322037': 0.66, '4100322038': 0.66, '4100322039': 0.66, '4100322040': 1.0, '4100322041': 0.66, '4100322042': 1.0, '4100322044': 1.0, '4100322045': 1.0, '4100322048': 0.66, '4100322051': 1.0, '4100322052': 1.0, '4100322053': 0.66, '4100322055': 0.66, '4100322056': 0.66, '4100322057': 0.66, '4100322058': 0.66, '4100322059': 1.0, '4100322060': 0.66, '4100322061': 0.66, '4110211001': 0.33, '4110211004': 0.33, '4110211005': 0.33, '4110211006': 0.66, '4110211007': 0.66, '4110211008': 0.66, '4110211009': 0.66, '4110211011': 0.66, '4110211013': 0.33, '4110211014': 0.33, '4110211015': 0.0, '4110211016': 1.0, '4110211018': 0.66, '4110211019': 1.0, '4110211020': 0.66, '4110211021': 0.33, '4110211022': 0.33, '4110211023': 0.33, '4110211024': 0.66, '4110211025': 0.0, '4110211026': 0.66, '4110211027': 0.33, '4110211028': 0.33, '4110211030': 0.66, '4110211032': 0.66, '4110211033': 0.66, '4110211034': 0.66, '4110211035': 0.66, '4110211036': 0.33, '4110211037': 0.66, '4110211038': 0.33, '4110211039': 0.33, '4110211040': 0.0, '4110211041': 0.66, '4110211043': 0.66, '4110211044': 1.0, '4110211045': 0.33, '4110211046': 1.0, '4110211047': 1.0, '4110211048': 0.66, '4110211049': 0.66, '4110211050': 0.66, '4110211051': 1.0, '4110211052': 0.66, '4110211053': 0.33, '4110211054': 0.66, '4110211055': 0.33, '4110211056': 1.0, '4110211057': 0.66, '4110211058': 1.0, '4110211060': 0.66, '4110211061': 0.0, '4110211062': 0.66, '4110211063': 0.66, '4110211064': 0.66, '4110211065': 0.66, '4110211067': 1.0, '4110211068': 0.66, '4110211072': 0.66, '4110211073': 0.66, '4110211075': 0.33, '4110211076': 1.0, '4110211078': 0.33, '4110211079': 0.66, '4110211080': 0.66, '4110212003': 0.66, '4110212004': 0.66, '4110212007': 0.66, '4110212008': 0.66, '4110212009': 0.66, '4110212010': 0.66, '4110212011': 0.66, '4110212013': 1.0, '4110212014': 1.0, '4110212015': 0.66, '4110212016': 0.66, '4110212017': 0.66, '4110212018': 0.66, '4110212019': 0.66, '4110212021': 1.0, '4110212023': 0.66, '4110212024': 0.66, '4110212026': 0.66, '4110212027': 0.66, '4110212029': 0.66, '4110212030': 1.0, '4110212033': 0.66, '4110212034': 0.33, '4110212035': 0.66, '4110212036': 0.33, '4110212038': 0.66, '4110212039': 1.0, '4110212041': 0.66, '4110212042': 0.66, '4110212044': 1.0, '4110212045': 0.66, '4110212046': 0.66, '4110212047': 1.0, '4110212049': 0.33, '4110212050': 0.66, '4110212051': 0.33, '4110212052': 1.0, '4110212053': 0.66, '4110212054': 0.66, '4110212055': 0.66, '4110212056': 0.66, '4110212059': 0.66, '4110212061': 0.66, '4110212062': 0.33, '4110212063': 0.66, '4110212064': 0.66, '4110212069': 0.66, '4110311001': 1.0, '4110311003': 1.0, '4110311004': 1.0, '4110311005': 0.66, '4110311006': 0.33, '4110311012': 0.66, '4110311015': 1.0, '4110311017': 0.66, '4110311018': 1.0, '4110311019': 0.66, '4110311020': 0.66, '4110311021': 0.66, '4110311023': 0.33, '4110311030': 0.66, '4110311031': 1.0, '4110311032': 0.66, '4110311033': 0.66, '4110311034': 0.66, '4110311036': 1.0, '4110311037': 1.0, '4110311038': 1.0, '4110311042': 1.0, '4110311043': 1.0, '4110311044': 0.66, '4110311045': 0.33, '4110311046': 0.66, '4110311048': 0.33, '4110311049': 0.66, '4110311050': 0.66, '4110311053': 1.0, '4110311054': 0.33, '4110311057': 0.66, '4110311061': 0.66, '4110311062': 0.33, '4110311064': 0.66, '4110311065': 0.66, '4110311067': 0.66, '4110311068': 0.66, '4110311072': 0.66, '4110312006': 1.0, '4110312007': 0.66, '4110312008': 0.66, '4110312009': 0.33, '4110312013': 0.66, '4110312023': 1.0, '4110312024': 1.0, '4110312025': 1.0, '4110312027': 0.66, '4110312030': 1.0, '4110312031': 0.66, '4110312048': 0.66, '4110312049': 0.66, '4110312078': 1.0, '414081010': 1.0, '414081011': 1.0, '4140810110': 1.0, '4140810114': 1.0, '4140810117': 1.0, '4140810122': 1.0, '4140810124': 1.0, '4140810125': 1.0, '4140810126': 1.0, '4140810127': 1.0, '4140810128': 1.0, '4140810129': 0.66, '414081013': 0.66, '4140810132': 1.0, '4140810133': 1.0, '4140810135': 0.66, '4140810136': 1.0, '4140810138': 1.0, '4140810139': 0.66, '4140810140': 0.66, '4140810142': 1.0, '4140810143': 1.0, '4140810144': 1.0, '4140810145': 1.0, '4140810146': 1.0, '4140810148': 1.0, '414081015': 0.66, '4140810150': 1.0, '4140810151': 1.0, '4140810152': 1.0, '4140810153': 0.33, '4140810154': 1.0, '4140810158': 1.0, '4140810159': 0.66, '414081016': 1.0, '4140810162': 0.33, '4140810163': 1.0, '4140810164': 1.0, '4140810165': 1.0, '414081017': 1.0, '4140810171': 0.66, '4140810173': 1.0, '4140810175': 1.0, '4140810176': 1.0, '4140810179': 0.66, '414081018': 1.0, '4140810180': 1.0, '4140810181': 1.0, '4140810182': 1.0, '4140810183': 1.0, '4140810184': 0.66, '4140810185': 1.0, '414081019': 1.0, '414081021': 1.0, '4140810210': 0.33, '4140810211': 1.0, '4140810212': 0.66, '4140810215': 0.66, '4140810217': 0.33, '4140810219': 0.33, '4140810220': 1.0, '4140810221': 0.66, '4140810222': 1.0, '4140810223': 1.0, '4140810224': 1.0, '4140810225': 0.66, '4140810226': 0.66, '4140810228': 1.0, '4140810229': 1.0, '414081023': 1.0, '4140810230': 1.0, '4140810233': 1.0, '4140810234': 0.66, '4140810237': 1.0, '4140810239': 1.0, '4140810240': 1.0, '4140810242': 0.66, '4140810244': 0.66, '4140810246': 1.0, '4140810247': 0.66, '4140810249': 0.66, '414081025': 1.0, '4140810250': 0.66, '4140810251': 1.0, '4140810252': 1.0, '4140810253': 0.66, '4140810254': 1.0, '4140810255': 1.0, '4140810256': 1.0, '4140810257': 0.66, '4140810258': 1.0, '4140810259': 1.0, '414081026': 1.0, '4140810264': 1.0, '4140810265': 1.0, '4140810266': 1.0, '4140810268': 1.0, '4140810269': 1.0, '414081027': 1.0, '4140810270': 0.66, '4140810271': 1.0, '4140810272': 0.33, '4140810273': 0.66, '4140810274': 1.0, '4140810276': 1.0, '4140810277': 1.0, '4140810278': 0.66, '4140810279': 1.0, '414081028': 0.66, '4140810280': 1.0, '414081029': 0.66, '459999011': 1.0, '4599990110': 0.66, '4599990112': 1.0, '4599990113': 1.0, '4599990114': 1.0, '4599990116': 1.0, '4599990117': 1.0, '4599990118': 1.0, '4599990119': 1.0, '459999012': 0.66, '4599990120': 0.66, '4599990125': 1.0, '4599990126': 0.66, '4599990128': 1.0, '4599990129': 0.66, '459999013': 1.0, '4599990130': 1.0, '4599990131': 1.0, '4599990132': 0.33, '4599990133': 0.66, '4599990134': 1.0, '4599990136': 1.0, '4599990137': 1.0, '4599990139': 1.0, '4599990141': 1.0, '4599990144': 1.0, '4599990146': 1.0, '4599990148': 0.66, '4599990149': 1.0, '4599990153': 1.0, '4599990154': 1.0, '4599990155': 1.0, '459999016': 1.0, '4599990163': 0.66, '4599990165': 1.0, '4599990166': 1.0, '4599990168': 1.0, '459999017': 0.66, '4599990171': 1.0, '459999021': 1.0, '4599990211': 1.0, '4599990212': 1.0, '4599990214': 0.66, '4599990216': 1.0, '4599990218': 1.0, '459999022': 1.0, '4599990221': 1.0, '4599990222': 1.0, '4599990223': 1.0, '4599990224': 1.0, '4599990226': 1.0, '4599990231': 1.0, '4599990233': 0.66, '4599990234': 1.0, '4599990235': 0.33, '4599990238': 1.0, '459999024': 1.0, '4599990240': 1.0, '4599990241': 1.0, '4599990243': 0.66, '4599990244': 1.0, '4599990245': 0.66, '4599990246': 1.0, '4599990247': 1.0, '4599990248': 0.66, '4599990249': 1.0, '459999025': 1.0, '4599990253': 1.0, '4599990254': 1.0, '4599990255': 0.66, '4599990256': 1.0, '4599990263': 1.0, '4599990264': 0.66, '4599990269': 0.66, '4599990270': 1.0, '4599990272': 0.66, '4599990273': 1.0, '4599990274': 1.0, '4599990275': 1.0, '4599990276': 0.66, '459999028': 0.66, '4599990283': 1.0, '5000391001': 0.66, '5000391002': 0.66, '5000391004': 1.0, '5000391005': 0.66, '5000391007': 1.0, '5000391008': 0.66, '5000391010': 0.66, '5000391012': 0.66, '5000391013': 1.0, '5000391014': 0.66, '5000391015': 1.0, '5000391016': 1.0, '5000391017': 0.33, '5000391019': 0.66, '5000391020': 0.66, '5000391022': 1.0, '5000391023': 0.66, '5000391024': 0.66, '5000391026': 0.66, '5000391028': 1.0, '5000391029': 0.66, '5000391030': 1.0, '5000391031': 1.0, '5000391032': 1.0, '5000391034': 0.66, '5000391035': 1.0, '5000391036': 0.66, '5000391037': 1.0, '5000391038': 0.66, '5000391040': 0.66, '5000391045': 0.33, '5000391046': 0.66, '5000391047': 1.0, '5000391049': 0.66, '5000391050': 0.66, '5000391054': 0.66, '5000391055': 0.33, '5000391056': 0.33, '5000391059': 0.66, '5000391060': 0.33, '5000391061': 0.66, '5000391062': 1.0, '5000391063': 1.0, '5000391064': 0.66, '5000391065': 0.66, '5000391066': 1.0, '5000391067': 0.66, '5000391068': 1.0, '5000391069': 1.0, '5000391070': 0.66, '5000391071': 0.66, '5000391072': 0.66, '5000391073': 0.66, '5000391074': 0.66, '5000391076': 0.66, '5000391078': 0.66, '5000391079': 0.66, '5000391080': 1.0, '5000391081': 0.66, '5000392001': 0.66, '5000392002': 0.66, '5000392003': 1.0, '5000392006': 0.66, '5000392007': 0.66, '5000392010': 1.0, '5000392011': 0.66, '5000392015': 0.66, '5000392016': 0.66, '5000392017': 0.66, '5000392018': 0.66, '5000392019': 0.66, '5000392020': 0.66, '5000392021': 0.66, '5000392022': 0.66, '5000392025': 0.66, '5000392026': 0.66, '5000392027': 0.66, '5000392029': 0.66, '5000392033': 0.33, '5000392035': 0.66, '5000392036': 1.0, '5000392038': 0.66, '5000392039': 0.66, '5000392040': 1.0, '5000392041': 1.0, '5000392042': 0.66, '5000392044': 0.66, '5000392047': 0.66, '5000392048': 0.66, '5000392049': 1.0, '5000392050': 1.0, '5000392051': 1.0, '5000392052': 0.33, '5000392053': 0.66, '5000392054': 0.66, '5000392055': 0.66, '5000392056': 0.66, '5000392058': 0.66, '5000392060': 0.33, '5000392062': 0.66, '5000392063': 0.66, '5000392064': 0.66, '5000392065': 0.66, '5000392066': 0.66, '5000392067': 0.66, '5000392070': 0.66, '5000392071': 0.66, '5000392072': 0.66, '5000431019': 0.66, '5000431020': 1.0, '5000431021': 1.0, '5000431022': 0.66, '5000431023': 1.0, '5000431025': 0.66, '5000431026': 0.66, '5000431049': 1.0, '5000431050': 1.0, '5000432001': 1.0, '5000432003': 0.66, '5000432006': 0.66, '5000432059': 1.0, '5000441001': 0.66, '5000441002': 0.66, '5000441003': 0.66, '5000441005': 0.66, '5000441006': 0.66, '5000441007': 0.66, '5000441008': 0.66, '5000441009': 1.0, '5000441010': 0.66, '5000441012': 0.66, '5000441013': 0.66, '5000441014': 0.66, '5000441015': 0.66, '5000441016': 1.0, '5000441017': 0.66, '5000441018': 1.0, '5000441021': 1.0, '5000441022': 0.66, '5000441023': 1.0, '5000441024': 0.33, '5000441027': 1.0, '5000441030': 0.66, '5000441031': 0.66, '5000441032': 0.66, '5000441033': 0.66, '5000441034': 0.66, '5000441035': 1.0, '5000441037': 0.66, '5000441038': 1.0, '5000441039': 1.0, '5000441040': 1.0, '5000441041': 1.0, '5000441042': 0.66, '5000441043': 0.66, '5000441044': 0.66, '5000441045': 0.66, '5000441046': 1.0, '5000441047': 0.66, '5000441048': 0.66, '5000441050': 0.66, '5000441051': 0.66, '5000441052': 0.66, '5000441053': 1.0, '5000441054': 0.66, '5000441055': 1.0, '5000441058': 0.33, '5000441059': 0.66, '5000441061': 1.0, '5000441062': 0.66, '5000441064': 0.66, '5000441065': 0.66, '5000441066': 0.66, '5000441067': 0.33, '5000441068': 0.66, '5000441069': 0.66, '5000441070': 1.0, '5000441071': 1.0, '5000441072': 1.0, '5000442001': 1.0, '5000442002': 0.66, '5000442003': 0.66, '5000442004': 0.66, '5000442005': 0.66, '5000442007': 0.66, '5000442008': 0.66, '5000442009': 1.0, '5000442010': 0.66, '5000442014': 1.0, '5000442015': 0.66, '5000442016': 0.66, '5000442019': 0.66, '5000442021': 0.66, '5000442022': 1.0, '5000442024': 0.66, '5000442025': 0.66, '5000442026': 0.66, '5000442027': 1.0, '5000442028': 0.66, '5000442029': 1.0, '5000442033': 0.66, '5000442034': 1.0, '5000442035': 1.0, '5000442036': 0.66, '5000442037': 1.0, '5000442038': 1.0, '5000442039': 1.0, '5000442040': 1.0, '5000442042': 0.66, '5000442043': 1.0, '5000442045': 1.0, '5000442047': 0.66, '5000442048': 0.66, '5000442050': 0.66, '5000442051': 0.66, '5000442052': 0.66, '5000442053': 0.66, '5000442054': 1.0, '5000442055': 1.0, '5000442056': 0.66, '5000442057': 1.0, '5000442058': 1.0, '5000442059': 1.0, '5000442060': 0.66, '5000442062': 0.66, '5000442063': 1.0, '5000442064': 1.0, '5000442065': 1.0, '5000442066': 1.0, '5000442067': 0.66, '5000442068': 1.0, '5000442069': 1.0, '5000442070': 1.0, '5000442072': 0.66, '5000442073': 1.0, '5000442074': 0.66, '5000442075': 0.66, '5000442076': 0.66, '5000442077': 0.66, '5000442078': 0.66, '5000671001': 1.0, '5000671002': 0.66, '5000671003': 0.66, '5000671004': 1.0, '5000671005': 0.66, '5000671006': 0.66, '5000671008': 1.0, '5000671009': 0.66, '5000671010': 1.0, '5000671011': 1.0, '5000671012': 1.0, '5000671013': 0.66, '5000671014': 1.0, '5000671015': 1.0, '5000671016': 0.66, '5000671017': 0.66, '5000671018': 1.0, '5000671019': 0.66, '5000671020': 0.66, '5000671022': 0.66, '5000671023': 1.0, '5000671024': 0.66, '5000671026': 1.0, '5000671027': 0.66, '5000671028': 1.0, '5000671029': 0.66, '5000671030': 1.0, '5000671031': 0.66, '5000671032': 1.0, '5000671033': 1.0, '5000671034': 0.66, '5000671035': 1.0, '5000671036': 0.66, '5000671037': 0.66, '5000671038': 0.66, '5000671039': 0.66, '5000671040': 0.66, '5000671041': 0.33, '5000671042': 0.33, '5000671043': 0.66, '5000671046': 0.66, '5000671047': 0.66, '5000671048': 0.33, '5000671049': 0.33, '5000671050': 0.66, '5000671051': 0.66, '5000671053': 0.66, '5000671055': 0.66, '5000671056': 1.0, '5000671057': 0.66, '5000671058': 0.33, '5000671059': 0.66, '5000671060': 0.66, '5000671061': 0.33, '5000671062': 0.66, '5000671063': 0.66, '5000671064': 1.0, '5000671065': 0.66, '5000671066': 0.66, '5000671067': 0.66, '5000671069': 0.33, '5000671070': 0.33, '5000671071': 0.66, '5000672002': 0.66, '5000672004': 0.66, '5000672005': 0.66, '5000672006': 1.0, '5000672007': 0.66, '5000672008': 0.66, '5000672010': 0.66, '5000672011': 1.0, '5000672012': 0.66, '5000672013': 1.0, '5000672014': 1.0, '5000672016': 0.66, '5000672017': 0.66, '5000672019': 1.0, '5000672020': 1.0, '5000672021': 1.0, '5000672022': 1.0, '5000672023': 0.66, '5000672024': 0.66, '5000672025': 1.0, '5000672026': 1.0, '5000672027': 0.66, '5000672030': 0.66, '5000672031': 0.66, '5000672033': 0.66, '5000672034': 0.66, '5000672035': 1.0, '5000672036': 0.66, '5000672038': 1.0, '5000672042': 1.0, '5000672043': 1.0, '5000672044': 1.0, '5000672045': 1.0, '5000672046': 0.66, '5000672047': 0.66, '5000672048': 0.66, '5000672049': 0.66, '5000672050': 0.66, '5000672051': 1.0, '5000672052': 1.0, '5000672053': 0.66, '5000672054': 1.0, '5000672055': 1.0, '5000672056': 1.0, '5000672057': 0.66, '5000672058': 0.66, '5000672059': 0.66, '5000672060': 0.66, '5000672062': 1.0, '5000672064': 0.66, '5000672065': 0.66, '5000672066': 0.66, '5000672067': 0.66, '5000672068': 0.66, '5000672070': 1.0, '5000672071': 0.66, '5000672072': 0.66, '5000672074': 1.0, '5000672075': 1.0, '5000672076': 1.0, '5000672077': 0.66, '5000672081': 0.66, '5000672082': 0.66, '5000951001': 0.66, '5000951002': 0.66, '5000951003': 1.0, '5000951004': 0.66, '5000951005': 0.66, '5000951006': 0.66, '5000951007': 1.0, '5000951008': 0.66, '5000951009': 1.0, '5000951010': 0.66, '5000951011': 1.0, '5000951012': 0.66, '5000951013': 0.66, '5000951015': 1.0, '5000951016': 0.66, '5000951017': 0.66, '5000951018': 0.66, '5000951019': 0.33, '5000951021': 0.66, '5000951023': 0.33, '5000951024': 0.33, '5000951025': 0.66, '5000951027': 0.33, '5000951028': 1.0, '5000951033': 0.66, '5000951034': 0.66, '5000951035': 0.66, '5000951037': 0.66, '5000951039': 0.66, '5000951040': 1.0, '5000951042': 0.66, '5000951043': 1.0, '5000951044': 0.66, '5000951045': 0.66, '5000951047': 0.66, '5000951049': 1.0, '5000951051': 1.0, '5000951052': 0.66, '5000951053': 0.66, '5000951054': 1.0, '5000951055': 0.66, '5000951056': 1.0, '5000951057': 1.0, '5000951058': 1.0, '5000951060': 1.0, '5000951061': 0.66, '5000951062': 0.66, '5000951063': 0.66, '5000951065': 1.0, '5000951066': 0.66, '5000951067': 0.66, '5000952002': 0.66, '5000952003': 0.66, '5000952004': 0.66, '5000952005': 1.0, '5000952007': 1.0, '5000952008': 1.0, '5000952011': 0.66, '5000952013': 0.66, '5000952014': 0.66, '5000952015': 1.0, '5000952016': 0.66, '5000952017': 0.66, '5000952018': 0.66, '5000952020': 0.66, '5000952021': 0.66, '5000952022': 0.66, '5000952023': 1.0, '5000952024': 0.66, '5000952025': 1.0, '5000952026': 1.0, '5000952027': 0.66, '5000952028': 0.66, '5000952029': 0.66, '5000952031': 0.66, '5000952032': 0.66, '5000952033': 0.66, '5000952034': 0.33, '5000952035': 0.66, '5000952036': 0.66, '5000952038': 1.0, '5000952040': 1.0, '5000952041': 0.66, '5000952042': 0.66, '5000952044': 0.66, '5000952045': 0.66, '5000952046': 1.0, '5000952048': 0.66, '5000952050': 1.0, '5000952052': 0.66, '5000952053': 1.0, '5000952054': 0.66, '5000952055': 0.66, '5000952060': 0.66, '5000952061': 0.66, '5000952062': 0.33, '5000952063': 0.66, '5000952064': 1.0, '5000952065': 0.66, '5000952066': 0.66, '5000952068': 1.0, '5000952069': 0.66, '5000952070': 1.0, '5000952071': 0.66, '5000952072': 1.0, '5000952073': 0.66, '5000952075': 0.66, '5000952076': 1.0, '5000952077': 0.66, '5000952078': 0.66, '5000952080': 1.0, '5000952083': 0.33, '5100091001': 0.66, '5100091003': 1.0, '5100091004': 1.0, '5100091005': 0.66, '5100091006': 0.66, '5100091007': 1.0, '5100091008': 1.0, '5100091009': 0.66, '5100091010': 1.0, '5100091012': 0.66, '5100091017': 0.66, '5100091019': 0.66, '5100091020': 1.0, '5100091025': 0.66, '5100091026': 1.0, '5100091027': 0.66, '5100091028': 0.66, '5100091032': 1.0, '5100091033': 0.66, '5100091034': 1.0, '5100091035': 1.0, '5100091036': 1.0, '5100091038': 1.0, '5100091039': 1.0, '5100091042': 1.0, '5100091046': 1.0, '5100091049': 0.33, '5100091050': 0.66, '5100091051': 0.66, '5100091053': 0.66, '5100091055': 1.0, '5100091056': 0.66, '5100091057': 0.66, '5100091058': 0.66, '5100091059': 0.66, '5100091062': 0.66, '5100091064': 0.66, '5100091065': 1.0, '5100091066': 0.66, '5100091067': 1.0, '5100091068': 0.66, '5100091069': 1.0, '5100092002': 1.0, '5100092003': 1.0, '5100092005': 1.0, '5100092006': 1.0, '5100092008': 1.0, '5100092010': 1.0, '5100092011': 0.66, '5100092013': 1.0, '5100092017': 0.66, '5100092019': 1.0, '5100092021': 0.66, '5100092022': 1.0, '5100092023': 1.0, '5100092026': 1.0, '5100092027': 1.0, '5100092032': 0.66, '5100092033': 1.0, '5100092034': 0.66, '5100092035': 0.66, '5100092037': 0.66, '5100092038': 0.66, '5100092039': 1.0, '5100092040': 1.0, '5100092041': 0.66, '5100092042': 1.0, '5100092043': 0.66, '5100092044': 1.0, '5100092045': 1.0, '5100092053': 0.66, '5100092056': 0.66, '5100092057': 0.66, '5100092060': 1.0, '5100092061': 1.0, '5100092062': 0.66, '5100092063': 0.66, '5100092064': 1.0, '5100092065': 0.66, '5100092067': 1.0, '5100092068': 0.66, '5100092069': 1.0, '5100092071': 1.0, '5100092072': 1.0, '5100341002': 0.66, '5100341003': 0.66, '5100341004': 1.0, '5100341005': 0.66, '5100341006': 0.66, '5100341008': 0.66, '5100341009': 0.66, '5100341010': 0.66, '5100341012': 1.0, '5100341013': 0.66, '5100341014': 1.0, '5100341015': 0.66, '5100341016': 0.66, '5100341017': 0.66, '5100341019': 0.66, '5100341020': 1.0, '5100341021': 1.0, '5100341022': 0.66, '5100341023': 0.66, '5100341024': 1.0, '5100341025': 0.66, '5100341026': 1.0, '5100341027': 1.0, '5100341028': 0.66, '5100341030': 0.66, '5100341031': 1.0, '5100341032': 0.66, '5100341033': 0.66, '5100341034': 1.0, '5100341035': 0.66, '5100341037': 0.66, '5100341038': 0.66, '5100341039': 1.0, '5100341042': 0.66, '5100341043': 0.33, '5100341046': 0.66, '5100341048': 1.0, '5100341050': 1.0, '5100341052': 1.0, '5100341054': 1.0, '5100341055': 1.0, '5100341056': 0.66, '5100341057': 0.66, '5100341058': 1.0, '5100341061': 0.66, '5100341062': 1.0, '5100341065': 1.0, '5100341067': 1.0, '5100341068': 1.0, '5100341070': 1.0, '5100341071': 1.0, '5100341072': 1.0, '5100341074': 0.33, '5100341075': 1.0, '5100341076': 1.0, '5100341077': 0.66, '5100341078': 1.0, '5100341079': 1.0, '5100342002': 1.0, '5100342003': 0.66, '5100342007': 1.0, '5100342008': 0.66, '5100342009': 0.66, '5100342012': 0.66, '5100342016': 0.66, '5100342017': 1.0, '5100342018': 0.66, '5100342020': 1.0, '5100342022': 0.0, '5100342023': 0.33, '5100342024': 0.33, '5100342025': 0.66, '5100342028': 0.33, '5100342030': 0.66, '5100342031': 0.66, '5100342034': 0.66, '5100342036': 0.33, '5100342042': 0.66, '5100342043': 0.66, '5100342045': 0.66, '5100342048': 0.33, '5100351001': 0.33, '5100351002': 0.33, '5100351004': 0.66, '5100351005': 0.66, '5100351007': 0.66, '5100351009': 0.66, '5100351010': 0.66, '5100351012': 1.0, '5100351013': 0.33, '5100351015': 0.66, '5100351016': 0.66, '5100351019': 0.66, '5100351020': 0.66, '5100351021': 0.66, '5100351022': 0.0, '5100351023': 0.66, '5100351024': 0.66, '5100351025': 0.66, '5100351026': 1.0, '5100351032': 1.0, '5100351034': 1.0, '5100351035': 0.66, '5100351036': 0.66, '5100351038': 0.66, '5100351039': 1.0, '5100351040': 0.66, '5100351042': 0.33, '5100351043': 1.0, '5100351044': 0.66, '5100351045': 0.66, '5100351046': 1.0, '5100351049': 1.0, '5100351051': 1.0, '5100351054': 0.66, '5100351058': 0.66, '5100352001': 0.66, '5100352002': 0.66, '5100352003': 0.66, '5100352004': 1.0, '5100352005': 0.66, '5100352006': 0.66, '5100352007': 1.0, '5100352008': 0.66, '5100352009': 1.0, '5100352011': 0.66, '5100352012': 0.66, '5100352013': 1.0, '5100352014': 0.66, '5100352015': 0.66, '5100352016': 0.66, '5100352017': 1.0, '5100352018': 0.66, '5100352020': 1.0, '5100352021': 0.66, '5100352022': 0.33, '5100352026': 1.0, '5100352027': 1.0, '5100352028': 0.66, '5100352030': 1.0, '5100352031': 1.0, '5100352032': 0.66, '5100352033': 0.66, '5100352034': 0.66, '5100352035': 0.66, '5100352037': 0.66, '5100352038': 1.0, '5100352039': 1.0, '5100352041': 0.66, '5100352042': 0.66, '5100352043': 0.33, '5100352044': 0.66, '5100352045': 1.0, '5100352046': 1.0, '5100352049': 0.66, '5100352050': 0.66, '5100352051': 0.66, '5100352052': 1.0, '5100352054': 0.33, '5100352055': 1.0, '5100352056': 0.66, '5100352057': 0.66, '5100352060': 0.66, '5100352061': 0.66, '5100352063': 0.66, '5100361009': 0.66, '5100361056': 0.66, '5100362028': 1.0, '5100362029': 0.66, '5100362030': 1.0, '5100362052': 0.66, '5100371022': 0.66, '5100371023': 1.0, '5100371024': 0.66, '5100371026': 1.0, '5100371027': 1.0, '5100371042': 1.0, '5100371055': 0.66, '5100371056': 0.66, '5100371067': 0.66, '5100371079': 0.66, '5100372001': 1.0, '5100372002': 0.66, '5100372003': 0.66, '5100372005': 0.66, '5100372006': 1.0, '5100372007': 1.0, '5100372009': 1.0, '5100372011': 1.0, '5100372015': 1.0, '5100372016': 1.0, '5100372017': 1.0, '5100372018': 1.0, '5100372019': 0.66, '5100372020': 1.0, '5100372021': 0.66, '5100372022': 1.0, '5100372023': 1.0, '5100372026': 1.0, '5100372027': 1.0, '5100372028': 0.66, '5100372069': 1.0, '5100381002': 1.0, '5100381003': 1.0, '5100381004': 0.66, '5100381005': 0.66, '5100381006': 0.66, '5100381007': 0.66, '5100381008': 0.66, '5100381009': 0.66, '5100381010': 0.66, '5100381011': 1.0, '5100381012': 1.0, '5100381015': 1.0, '5100381016': 1.0, '5100381017': 0.66, '5100381018': 0.66, '5100381019': 1.0, '5100381020': 0.66, '5100381021': 0.66, '5100381022': 0.66, '5100381023': 1.0, '5100381024': 1.0, '5100381026': 0.66, '5100381027': 1.0, '5100381028': 1.0, '5100381029': 1.0, '5100381031': 0.66, '5100381032': 0.66, '5100381034': 1.0, '5100381035': 0.66, '5100381037': 0.66, '5100381038': 0.66, '5100381039': 0.66, '5100381040': 1.0, '5100381041': 1.0, '5100381042': 0.66, '5100381043': 0.66, '5100381044': 0.66, '5100381045': 1.0, '5100381046': 1.0, '5100381047': 1.0, '5100381048': 1.0, '5100381049': 0.66, '5100381050': 1.0, '5100381051': 0.66, '5100381052': 1.0, '5100381053': 1.0, '5100381054': 0.66, '5100381055': 0.66, '5100381056': 1.0, '5100381058': 0.66, '5100381059': 1.0, '5100381060': 0.66, '5100381061': 0.66, '5100381063': 0.66, '5100381065': 0.66, '5100381066': 0.66, '5100381067': 0.66, '5100381069': 0.66, '5100382001': 0.66, '5100382003': 1.0, '5100382007': 0.66, '5100382008': 0.66, '5100382010': 1.0, '5100382011': 1.0, '5100382012': 1.0, '5100382013': 1.0, '5100382014': 1.0, '5100382015': 0.66, '5100382016': 1.0, '5100382018': 1.0, '5100382019': 1.0, '5100382020': 0.66, '5100382021': 1.0, '5100382022': 1.0, '5100382023': 1.0, '5100382025': 1.0, '5100382026': 1.0, '5100382027': 1.0, '5100382028': 0.66, '5100382029': 1.0, '5100382030': 1.0, '5100382031': 0.66, '5100382032': 0.66, '5100382033': 1.0, '5100382034': 0.66, '5100382035': 0.66, '5100382036': 1.0, '5100382037': 0.66, '5100382038': 1.0, '5100382039': 1.0, '5100382040': 0.66, '5100382042': 1.0, '5100382045': 1.0, '5100382046': 0.66, '5100382048': 0.66, '5100382050': 1.0, '5100382051': 0.66, '5100382052': 1.0, '5100382053': 1.0, '5100382054': 0.66, '5100382055': 1.0, '5100382056': 1.0, '5100382057': 1.0, '5100382058': 0.66, '5100382059': 0.66, '5100382060': 1.0, '5100382061': 1.0, '5100382062': 1.0, '5100382063': 1.0, '5100382064': 1.0, '5100382065': 1.0, '5100382066': 0.66, '5100382067': 0.66, '5100382068': 1.0, '5100382069': 0.66, '5100382070': 1.0, '5100382071': 1.0, '5100382072': 1.0, '5100382073': 0.66, '5100382075': 0.66, '5100382076': 0.66, '5100382077': 0.66, '5100382078': 0.66, '5100382079': 0.66, '5100401001': 0.66, '5100401003': 0.66, '5100401005': 0.66, '5100401006': 0.66, '5100401007': 1.0, '5100401008': 1.0, '5100401010': 0.66, '5100401011': 0.66, '5100401012': 0.66, '5100401014': 1.0, '5100401015': 0.66, '5100401016': 0.66, '5100401018': 0.66, '5100401021': 1.0, '5100401022': 1.0, '5100401023': 0.33, '5100401025': 1.0, '5100401026': 1.0, '5100401028': 0.66, '5100401029': 0.66, '5100401030': 1.0, '5100401031': 0.66, '5100401032': 0.66, '5100401033': 0.66, '5100401034': 0.33, '5100401035': 0.66, '5100401036': 0.66, '5100401038': 1.0, '5100401039': 0.66, '5100401040': 0.66, '5100401042': 0.66, '5100401043': 0.33, '5100401044': 1.0, '5100401045': 1.0, '5100401046': 0.66, '5100401047': 0.66, '5100401048': 0.66, '5100401049': 0.66, '5100401050': 0.66, '5100401051': 0.66, '5100401053': 1.0, '5100401054': 0.66, '5100401055': 0.66, '5100401056': 1.0, '5100401057': 1.0, '5100401059': 0.66, '5100401060': 0.66, '5100401061': 0.66, '5100401062': 1.0, '5100401063': 0.66, '5100401064': 0.66, '5100401065': 0.33, '5100401066': 1.0, '5100401067': 0.66, '5100401069': 1.0, '5100401070': 0.66, '5100401071': 0.66, '5100401072': 1.0, '5100401073': 0.66, '5100401074': 1.0, '5100401075': 0.66, '5100401076': 0.66, '5100401077': 0.66, '5100401078': 0.66, '5100402001': 0.33, '5100402002': 0.66, '5100402004': 1.0, '5100402005': 1.0, '5100402007': 0.66, '5100402008': 1.0, '5100402009': 0.66, '5100402011': 0.66, '5100402012': 0.66, '5100402015': 0.66, '5100402016': 0.66, '5100402017': 0.66, '5100402019': 1.0, '5100402020': 0.66, '5100402023': 1.0, '5100402024': 1.0, '5100402028': 0.66, '5100402029': 0.66, '5100402031': 0.66, '5100402032': 1.0, '5100402033': 0.66, '5100402034': 0.66, '5100402035': 1.0, '5100402036': 0.66, '5100402037': 0.66, '5100402038': 1.0, '5100402039': 0.66, '5100402040': 1.0, '5100402046': 0.66, '5100402047': 0.66, '5100402048': 0.66, '5100402049': 1.0, '5100402050': 0.66, '5100402051': 0.66, '5100402052': 0.66, '5100402053': 0.66, '5100402054': 0.66, '5100402055': 0.66, '5100402057': 0.66, '5100402058': 0.66, '5100402059': 0.66, '5100402062': 0.33, '5100402063': 0.33, '5100402065': 1.0, '5100402066': 0.66, '5100402067': 0.66, '5100402068': 0.66, '5100402069': 0.66, '5100421001': 1.0, '5100421002': 0.66, '5100421003': 1.0, '5100421005': 1.0, '5100421007': 0.66, '5100421009': 0.66, '5100421011': 0.66, '5100421012': 1.0, '5100421013': 0.66, '5100421015': 1.0, '5100421016': 1.0, '5100421017': 0.66, '5100421018': 0.66, '5100421019': 1.0, '5100421020': 0.66, '5100421021': 1.0, '5100421024': 1.0, '5100421025': 0.66, '5100421026': 1.0, '5100421027': 0.66, '5100421029': 1.0, '5100421032': 1.0, '5100421033': 1.0, '5100421034': 1.0, '5100421038': 0.66, '5100421039': 1.0, '5100421040': 0.66, '5100421041': 0.66, '5100421043': 0.66, '5100421045': 0.66, '5100421047': 0.66, '5100421048': 1.0, '5100421049': 1.0, '5100421050': 0.66, '5100421051': 0.66, '5100421052': 0.66, '5100421053': 1.0, '5100421054': 0.66, '5100421056': 1.0, '5100421057': 1.0, '5100421058': 0.66, '5100421059': 0.66, '5100421060': 0.66, '5100421061': 0.66, '5100421062': 1.0, '5100421063': 0.66, '5100421064': 1.0, '5100421065': 1.0, '5100421067': 0.66, '5100421068': 1.0, '5100421069': 0.66, '5100421070': 1.0, '5100421071': 0.66, '5100421072': 0.66, '5100421073': 1.0, '5100421074': 0.66, '5100421076': 1.0, '5100421078': 1.0, '5100421079': 1.0, '5100421080': 1.0, '5100421081': 1.0, '5100422002': 0.66, '5100422003': 0.66, '5100422004': 1.0, '5100422005': 0.66, '5100422006': 1.0, '5100422007': 0.66, '5100422008': 0.66, '5100422009': 0.66, '5100422011': 0.66, '5100422012': 1.0, '5100422013': 0.66, '5100422014': 0.66, '5100422016': 0.66, '5100422017': 1.0, '5100422018': 0.66, '5100422019': 1.0, '5100422022': 0.66, '5100422023': 0.66, '5100422024': 0.66, '5100422025': 1.0, '5100422026': 1.0, '5100422027': 0.66, '5100422028': 1.0, '5100422029': 0.66, '5100422030': 0.66, '5100422033': 0.66, '5100422034': 0.66, '5100422035': 0.66, '5100422036': 1.0, '5100422037': 0.66, '5100422038': 1.0, '5100422039': 1.0, '5100422041': 0.66, '5100422042': 1.0, '5100422044': 0.66, '5100422045': 0.66, '5100422046': 1.0, '5100422047': 0.66, '5100422049': 0.66, '5100422050': 1.0, '5100422051': 0.66, '5100422052': 0.66, '5100422055': 1.0, '5100422056': 1.0, '5100422057': 0.66, '5100422058': 0.66, '5100422059': 1.0, '5100422060': 0.66, '5100422061': 1.0, '5100422062': 0.66, '5100422063': 1.0, '5100422065': 1.0, '5100422066': 0.66, '5100422067': 0.66, '5100422068': 0.66, '5100422069': 0.66, '5100422071': 1.0, '5100422072': 0.66, '5100422073': 0.66, '5100422074': 0.66, '5100422075': 1.0, '5100422077': 0.66, '5100422078': 0.66, '5100422079': 1.0, '5100422080': 0.66, '5100422081': 0.66, '5100422084': 0.66, '5100422085': 0.66, '5100451001': 0.66, '5100451003': 1.0, '5100451004': 1.0, '5100451006': 1.0, '5100451007': 1.0, '5100451012': 1.0, '5100451013': 1.0, '5100451015': 1.0, '5100451016': 1.0, '5100451017': 0.66, '5100451018': 1.0, '5100451019': 1.0, '5100451020': 0.66, '5100451024': 1.0, '5100451026': 1.0, '5100451027': 1.0, '5100451033': 0.66, '5100451034': 1.0, '5100451035': 1.0, '5100451036': 0.66, '5100451038': 0.66, '5100451041': 1.0, '5100451043': 0.66, '5100451044': 1.0, '5100451045': 0.66, '5100451049': 1.0, '5100451050': 1.0, '5100451051': 0.66, '5100451052': 1.0, '5100451055': 0.66, '5100451056': 1.0, '5100451059': 1.0, '5100451060': 1.0, '5100451061': 1.0, '5100451064': 0.66, '5100451065': 1.0, '5100451066': 0.66, '5100451067': 1.0, '5100451070': 1.0, '5100451071': 1.0, '5100452002': 0.66, '5100452004': 1.0, '5100452005': 0.66, '5100452006': 1.0, '5100452007': 0.66, '5100452008': 1.0, '5100452009': 1.0, '5100452010': 0.66, '5100452011': 0.66, '5100452012': 1.0, '5100452013': 1.0, '5100452014': 1.0, '5100452016': 0.33, '5100452017': 1.0, '5100452018': 1.0, '5100452021': 0.66, '5100452023': 0.66, '5100452025': 0.66, '5100452027': 0.66, '5100452028': 1.0, '5100452030': 1.0, '5100452031': 1.0, '5100452032': 0.66, '5100452033': 0.66, '5100452034': 1.0, '5100452035': 0.66, '5100452036': 1.0, '5100452037': 1.0, '5100452038': 1.0, '5100452039': 0.66, '5100452040': 0.66, '5100452047': 1.0, '5100452049': 1.0, '5100452050': 1.0, '5100452053': 0.66, '5100452054': 1.0, '5100452055': 0.66, '5100452059': 1.0, '5100452060': 1.0, '5100452061': 0.66, '5100452065': 1.0, '5100452066': 1.0, '5100452067': 1.0, '5100452076': 1.0, '5100452078': 1.0, '5100452079': 1.0, '5100452080': 1.0, '5100452081': 0.66, '5100461004': 0.66, '5100461005': 0.66, '5100461006': 0.66, '5100461007': 0.33, '5100461008': 0.66, '5100461009': 1.0, '5100461010': 0.66, '5100461011': 0.66, '5100461014': 0.66, '5100461015': 1.0, '5100461016': 0.66, '5100461017': 1.0, '5100461018': 0.66, '5100461020': 0.66, '5100461021': 0.66, '5100461022': 1.0, '5100461023': 1.0, '5100461025': 0.66, '5100461029': 0.66, '5100461030': 1.0, '5100461031': 0.66, '5100461032': 0.66, '5100461033': 0.66, '5100461034': 0.66, '5100461035': 0.66, '5100461036': 0.66, '5100461037': 0.66, '5100461038': 0.66, '5100461039': 1.0, '5100461040': 0.66, '5100461042': 1.0, '5100461043': 0.66, '5100461044': 1.0, '5100461046': 0.66, '5100461047': 0.66, '5100461048': 0.66, '5100461049': 0.66, '5100461050': 0.66, '5100461051': 1.0, '5100461052': 0.66, '5100461053': 1.0, '5100461054': 0.66, '5100461055': 1.0, '5100461056': 1.0, '5100461057': 0.66, '5100461058': 0.66, '5100461061': 1.0, '5100461062': 0.66, '5100461063': 0.66, '5100461064': 1.0, '5100461065': 1.0, '5100461066': 1.0, '5100461067': 0.66, '5100461068': 0.66, '5100461069': 1.0, '5100462001': 0.66, '5100462002': 0.66, '5100462003': 0.33, '5100462005': 0.66, '5100462009': 0.66, '5100462010': 1.0, '5100462011': 1.0, '5100462012': 0.66, '5100462014': 1.0, '5100462015': 0.66, '5100462016': 0.66, '5100462017': 0.66, '5100462018': 0.66, '5100462019': 0.66, '5100462021': 1.0, '5100462022': 0.66, '5100462023': 0.66, '5100462024': 0.66, '5100462025': 0.66, '5100462026': 1.0, '5100462027': 0.66, '5100462028': 1.0, '5100462029': 1.0, '5100462031': 0.66, '5100462032': 0.66, '5100462033': 0.66, '5100462035': 1.0, '5100462037': 1.0, '5100462038': 0.66, '5100462039': 0.66, '5100462040': 0.66, '5100462041': 1.0, '5100462042': 0.66, '5100462043': 0.66, '5100462044': 0.66, '5100462045': 0.66, '5100462046': 0.66, '5100462047': 1.0, '5100462048': 0.66, '5100462050': 0.66, '5100462051': 0.66, '5100462052': 0.66, '5100462053': 1.0, '5100462054': 0.66, '5100462055': 1.0, '5100462057': 0.66, '5100462058': 1.0, '5100462059': 0.66, '5100462061': 0.66, '5100462062': 0.66, '5100462063': 1.0, '5100462064': 1.0, '5100462066': 0.66, '5100462067': 0.66, '5100462068': 0.66, '5100462069': 1.0, '5100462070': 1.0, '5100462071': 0.66, '5100462072': 1.0, '5100462074': 0.66, '5100462075': 1.0, '5100462077': 1.0, '5100462078': 0.66, '5100462079': 0.66, '5100462080': 0.66, '5100462081': 0.66, '5100462082': 0.66, '5100471001': 0.66, '5100471002': 1.0, '5100471003': 1.0, '5100471011': 0.66, '5100471012': 0.66, '5100471013': 0.66, '5100471015': 0.66, '5100471016': 1.0, '5100471018': 0.66, '5100471019': 1.0, '5100471020': 0.66, '5100471021': 0.66, '5100471023': 0.66, '5100471026': 1.0, '5100471027': 0.66, '5100471028': 1.0, '5100471029': 0.66, '5100471030': 1.0, '5100471031': 0.66, '5100471034': 0.66, '5100471037': 1.0, '5100471038': 1.0, '5100471039': 1.0, '5100471041': 1.0, '5100471042': 0.66, '5100471044': 0.66, '5100471045': 0.66, '5100471047': 1.0, '5100471049': 0.66, '5100471050': 1.0, '5100471051': 0.66, '5100471052': 0.66, '5100471054': 0.66, '5100471056': 0.66, '5100471057': 1.0, '5100471058': 0.66, '5100471059': 0.66, '5100471060': 0.66, '5100471062': 1.0, '5100471063': 1.0, '5100471065': 0.66, '5100471068': 0.66, '5100471069': 1.0, '5100471070': 0.66, '5100471072': 0.66, '5100471074': 0.66, '5100471075': 0.66, '5100471080': 0.66, '5100471081': 0.66, '5100472001': 0.33, '5100472002': 0.66, '5100472003': 0.66, '5100472004': 1.0, '5100472005': 0.66, '5100472007': 1.0, '5100472009': 1.0, '5100472010': 1.0, '5100472011': 0.66, '5100472012': 0.66, '5100472014': 0.66, '5100472019': 0.66, '5100472020': 1.0, '5100472021': 1.0, '5100472027': 1.0, '5100472030': 0.66, '5100472031': 0.66, '5100472032': 1.0, '5100472035': 0.66, '5100472039': 0.66, '5100472040': 0.66, '5100472041': 1.0, '5100472042': 0.66, '5100472044': 0.66, '5100472045': 1.0, '5100472047': 0.66, '5100472050': 0.66, '5100472052': 1.0, '5100472053': 0.66, '5100472054': 0.66, '5100472058': 0.33, '5100472060': 0.66, '5100472063': 0.66, '5100472064': 0.66, '5221290110': 1.0, '5221290111': 1.0, '5221290112': 1.0, '5221290114': 1.0, '5221290115': 0.66, '5221290116': 0.66, '5221290118': 1.0, '5221290119': 1.0, '5221290121': 1.0, '5221290122': 1.0, '5221290123': 0.66, '5221290124': 1.0, '5221290126': 1.0, '5221290127': 1.0, '5221290129': 1.0, '522129013': 1.0, '5221290131': 0.66, '5221290132': 1.0, '5221290134': 1.0, '5221290135': 1.0, '5221290137': 1.0, '5221290138': 1.0, '5221290140': 1.0, '5221290141': 1.0, '5221290142': 0.66, '5221290144': 1.0, '5221290145': 1.0, '5221290147': 1.0, '5221290149': 1.0, '5221290150': 1.0, '5221290151': 1.0, '5221290155': 1.0, '5221290158': 1.0, '522129016': 1.0, '5221290161': 0.66, '5221290162': 0.66, '5221290163': 0.66, '5221290164': 0.66, '5221290165': 1.0, '5221290166': 1.0, '5221290167': 1.0, '5221290169': 1.0, '522129017': 1.0, '5221290171': 0.66, '5221290172': 1.0, '5221290173': 1.0, '5221290174': 1.0, '5221290175': 1.0, '5221290177': 1.0, '5221290178': 1.0, '5221290179': 0.66, '522129018': 0.66, '5221290180': 1.0, '5221290184': 0.66, '522129021': 0.66, '5221290210': 1.0, '5221290212': 1.0, '5221290213': 1.0, '5221290214': 1.0, '5221290215': 1.0, '5221290216': 1.0, '5221290217': 1.0, '522129022': 1.0, '5221290220': 1.0, '5221290221': 1.0, '5221290222': 1.0, '5221290223': 1.0, '5221290226': 1.0, '5221290227': 0.66, '5221290228': 0.66, '5221290230': 0.66, '5221290231': 1.0, '5221290235': 0.66, '5221290237': 0.66, '5221290238': 1.0, '5221290239': 1.0, '522129024': 0.66, '5221290240': 1.0, '5221290242': 1.0, '5221290247': 1.0, '5221290249': 1.0, '522129025': 1.0, '5221290250': 0.66, '5221290251': 1.0, '5221290252': 1.0, '5221290253': 1.0, '5221290254': 1.0, '5221290255': 1.0, '5221290256': 1.0, '5221290257': 0.66, '5221290258': 1.0, '5221290259': 1.0, '522129026': 1.0, '5221290263': 1.0, '5221290264': 1.0, '5221290266': 1.0, '5221290268': 1.0, '5221290269': 0.66, '522129027': 1.0, '5221290270': 1.0, '5221290271': 0.66, '5221290272': 0.66, '5221290273': 1.0, '5221290274': 1.0, '5221290275': 0.66, '5221290279': 1.0, '5221290280': 0.33, '5221290282': 1.0, '5221290284': 1.0, '5564630110': 0.66, '5564630112': 0.66, '5564630115': 0.66, '5564630117': 1.0, '556463012': 1.0, '5564630121': 1.0, '5564630122': 0.66, '5564630123': 1.0, '5564630126': 0.0, '5564630127': 1.0, '5564630128': 1.0, '5564630129': 1.0, '556463013': 1.0, '5564630130': 0.66, '5564630132': 0.33, '5564630133': 0.66, '5564630134': 0.66, '5564630135': 1.0, '5564630137': 0.33, '5564630138': 0.33, '5564630139': 0.66, '556463014': 0.33, '5564630140': 0.66, '5564630141': 0.33, '5564630142': 0.66, '5564630143': 0.66, '5564630145': 1.0, '5564630147': 0.66, '5564630148': 1.0, '5564630149': 0.66, '5564630150': 0.66, '5564630152': 0.66, '5564630153': 1.0, '5564630154': 0.33, '5564630156': 0.33, '5564630157': 1.0, '5564630158': 1.0, '556463016': 1.0, '5564630160': 0.66, '5564630161': 0.66, '5564630162': 1.0, '5564630163': 1.0, '5564630165': 0.66, '5564630166': 0.66, '5564630167': 1.0, '5564630168': 0.33, '556463018': 1.0, '556463019': 0.66, '5564630211': 0.33, '5564630212': 0.66, '5564630213': 1.0, '5564630215': 0.66, '5564630216': 1.0, '5564630217': 1.0, '5564630218': 0.66, '5564630219': 0.66, '556463022': 0.33, '5564630221': 1.0, '5564630222': 1.0, '5564630226': 0.33, '5564630228': 1.0, '5564630229': 1.0, '5564630230': 1.0, '5564630232': 0.66, '5564630233': 0.66, '5564630234': 1.0, '5564630235': 0.66, '5564630236': 1.0, '5564630237': 1.0, '5564630238': 0.33, '556463024': 1.0, '5564630240': 0.66, '5564630241': 1.0, '5564630247': 1.0, '5564630249': 1.0, '556463025': 0.33, '5564630252': 0.66, '5564630253': 1.0, '5564630254': 1.0, '5564630256': 0.66, '5564630257': 0.33, '5564630258': 1.0, '556463026': 0.66, '5564630261': 1.0, '5564630262': 1.0, '5564630264': 0.66, '5564630265': 1.0, '5564630269': 0.66, '556463027': 1.0, '5564630273': 0.66, '5564630275': 0.66, '5564630276': 1.0, '556463028': 0.66, '5564630281': 1.0, '556463029': 0.66, '567496011': 1.0, '5674960111': 0.66, '5674960114': 1.0, '5674960115': 0.66, '5674960116': 1.0, '5674960117': 0.66, '5674960118': 0.66, '5674960121': 1.0, '5674960123': 1.0, '5674960124': 0.66, '5674960125': 1.0, '5674960126': 1.0, '567496013': 0.66, '5674960131': 0.66, '5674960132': 1.0, '5674960134': 1.0, '5674960136': 0.66, '5674960138': 0.66, '567496014': 1.0, '5674960142': 0.66, '5674960144': 1.0, '5674960145': 1.0, '5674960146': 1.0, '5674960148': 1.0, '5674960151': 1.0, '5674960153': 1.0, '5674960154': 1.0, '5674960155': 0.33, '5674960156': 0.66, '5674960157': 0.66, '5674960158': 0.66, '5674960160': 1.0, '5674960161': 0.66, '5674960166': 1.0, '567496017': 0.66, '5674960170': 1.0, '567496018': 0.66, '567496019': 1.0, '567496021': 0.33, '5674960211': 0.66, '5674960215': 1.0, '5674960216': 1.0, '5674960219': 1.0, '567496022': 0.33, '5674960220': 1.0, '5674960221': 1.0, '5674960222': 0.33, '5674960224': 1.0, '5674960225': 0.0, '5674960227': 1.0, '5674960228': 1.0, '5674960229': 0.66, '5674960230': 1.0, '5674960234': 0.66, '5674960235': 0.66, '567496024': 0.66, '5674960242': 0.66, '5674960246': 1.0, '5674960249': 0.66, '5674960251': 1.0, '5674960252': 0.66, '5674960255': 0.66, '5674960257': 0.66, '567496026': 1.0, '5674960261': 0.66, '5674960264': 1.0, '5674960268': 1.0, '5674960272': 1.0, '5674960273': 0.66, '5674960274': 1.0, '5674960275': 1.0, '5674960276': 1.0, '5674960277': 1.0, '5674960278': 1.0, '5674960279': 1.0, '567496028': 0.66, '5674960281': 1.0, '5674960282': 1.0, '5674960283': 0.0, '567496029': 1.0, '5912920111': 0.66, '5912920112': 1.0, '5912920113': 1.0, '5912920114': 0.66, '5912920119': 1.0, '5912920121': 1.0, '5912920123': 1.0, '5912920124': 0.66, '5912920125': 0.66, '5912920126': 1.0, '5912920127': 1.0, '5912920128': 0.33, '5912920129': 0.66, '5912920131': 1.0, '5912920133': 0.66, '5912920135': 1.0, '5912920137': 1.0, '5912920140': 1.0, '5912920142': 1.0, '5912920143': 0.66, '5912920145': 0.66, '5912920146': 0.66, '5912920147': 1.0, '5912920148': 1.0, '5912920149': 0.66, '591292015': 1.0, '5912920151': 1.0, '5912920152': 1.0, '5912920154': 1.0, '5912920156': 1.0, '5912920158': 1.0, '5912920159': 1.0, '5912920160': 1.0, '5912920163': 0.66, '5912920167': 0.66, '5912920168': 1.0, '5912920169': 0.66, '5912920170': 1.0, '5912920171': 1.0, '5912920172': 1.0, '591292019': 1.0, '591292021': 1.0, '5912920211': 1.0, '5912920212': 1.0, '5912920213': 1.0, '5912920216': 1.0, '5912920217': 0.66, '5912920220': 0.66, '5912920222': 1.0, '5912920223': 0.66, '5912920225': 1.0, '5912920227': 1.0, '5912920228': 0.66, '5912920230': 1.0, '5912920231': 1.0, '5912920233': 1.0, '5912920234': 0.66, '5912920235': 1.0, '5912920236': 1.0, '5912920239': 0.66, '591292024': 1.0, '5912920240': 1.0, '5912920241': 1.0, '5912920242': 0.66, '5912920243': 0.66, '5912920244': 0.66, '5912920245': 1.0, '5912920249': 1.0, '5912920250': 1.0, '5912920256': 1.0, '5912920260': 1.0, '5912920263': 1.0, '5912920265': 1.0, '5912920266': 0.66, '5912920267': 1.0, '5912920268': 1.0, '5912920273': 1.0, '5912920274': 1.0, '5912920275': 1.0, '5912920276': 1.0, '5912920277': 1.0, '5912920279': 1.0, '5912920280': 1.0, '769862011': 1.0, '7698620112': 1.0, '7698620113': 1.0, '7698620115': 1.0, '7698620116': 1.0, '7698620118': 0.66, '7698620120': 1.0, '7698620122': 1.0, '7698620123': 1.0, '7698620126': 1.0, '7698620129': 1.0, '7698620130': 0.66, '7698620131': 0.66, '7698620132': 1.0, '7698620133': 1.0, '7698620134': 1.0, '7698620136': 0.66, '7698620138': 1.0, '7698620139': 1.0, '769862014': 1.0, '7698620141': 1.0, '7698620144': 1.0, '7698620145': 0.66, '7698620149': 1.0, '769862015': 0.66, '7698620150': 1.0, '7698620151': 1.0, '7698620152': 1.0, '7698620153': 1.0, '7698620156': 0.66, '7698620158': 1.0, '769862016': 0.66, '7698620160': 1.0, '7698620161': 1.0, '7698620163': 1.0, '7698620165': 1.0, '7698620166': 0.66, '7698620167': 1.0, '7698620169': 1.0, '769862017': 0.33, '7698620170': 0.66, '7698620171': 1.0, '769862018': 1.0, '769862019': 1.0, '769862021': 1.0, '7698620211': 1.0, '7698620212': 1.0, '7698620217': 1.0, '7698620218': 1.0, '769862022': 1.0, '7698620221': 1.0, '7698620222': 1.0, '7698620224': 1.0, '7698620225': 0.66, '7698620227': 0.66, '7698620229': 0.66, '7698620230': 1.0, '7698620231': 1.0, '7698620233': 0.33, '7698620236': 0.66, '7698620238': 1.0, '7698620239': 1.0, '7698620240': 1.0, '7698620241': 0.66, '7698620244': 1.0, '7698620245': 1.0, '7698620248': 0.66, '7698620250': 1.0, '7698620252': 0.33, '7698620253': 0.66, '7698620255': 0.66, '7698620256': 1.0, '7698620257': 1.0, '7698620258': 1.0, '7698620260': 0.66, '7698620261': 1.0, '7698620262': 0.66, '7698620264': 0.66, '7698620265': 1.0, '7698620267': 1.0, '7698620268': 1.0, '769862027': 1.0, '7698620270': 1.0, '7698620272': 1.0, '7698620274': 1.0, '7698620275': 1.0, '7698620278': 0.66, '769862028': 1.0, '7698620281': 1.0, '7698620283': 1.0, '7994020110': 1.0, '79940201100': 0.66, '79940201110': 1.0, '79940201140': 1.0, '79940201150': 1.0, '79940201160': 1.0, '79940201180': 1.0, '79940201210': 1.0, '79940201230': 1.0, '79940201250': 1.0, '79940201270': 0.66, '7994020130': 0.66, '79940201300': 0.33, '79940201320': 1.0, '79940201330': 1.0, '79940201340': 1.0, '79940201350': 1.0, '79940201360': 1.0, '79940201370': 0.66, '79940201380': 1.0, '79940201390': 0.33, '7994020140': 0.66, '79940201410': 1.0, '79940201420': 1.0, '79940201430': 1.0, '79940201470': 1.0, '79940201490': 1.0, '79940201510': 0.66, '79940201560': 0.66, '79940201570': 1.0, '79940201580': 0.66, '7994020160': 1.0, '79940201620': 1.0, '79940201650': 0.66, '79940201660': 0.33, '79940201690': 1.0, '79940201700': 0.66, '79940201710': 1.0, '79940201720': 1.0, '79940201730': 0.66, '79940201740': 1.0, '79940201750': 0.66, '79940201760': 1.0, '79940201770': 1.0, '79940201780': 1.0, '79940201790': 0.33, '79940201810': 1.0, '79940201820': 1.0, '79940201850': 0.66, '79940201860': 1.0, '79940201880': 1.0, '79940201930': 0.66, '79940201950': 1.0, '79940202100': 1.0, '79940202120': 1.0, '79940202130': 0.66, '79940202140': 0.66, '79940202160': 1.0, '79940202170': 0.66, '79940202180': 0.66, '79940202190': 0.66, '79940202200': 1.0, '79940202210': 0.66, '79940202220': 0.66, '79940202230': 1.0, '79940202270': 0.33, '79940202280': 0.33, '7994020230': 0.33, '79940202300': 0.66, '79940202310': 0.33, '79940202320': 1.0, '79940202340': 0.66, '79940202350': 0.66, '79940202370': 1.0, '79940202390': 0.66, '79940202400': 0.66, '79940202410': 0.66, '79940202450': 0.66, '79940202470': 0.66, '79940202480': 0.66, '79940202490': 0.33, '7994020250': 1.0, '79940202510': 0.66, '79940202520': 1.0, '79940202540': 1.0, '79940202560': 1.0, '79940202570': 1.0, '79940202580': 0.66, '79940202620': 1.0, '79940202690': 1.0, '7994020270': 1.0, '79940202700': 1.0, '79940202710': 0.66, '79940202750': 0.66, '79940202760': 1.0, '79940202790': 1.0, '7994020280': 0.66, '79940202800': 0.33, '79940202820': 0.66, '79940202840': 0.33, '79940202850': 0.33, '79940202860': 0.33, '79940202870': 0.66, '79940202890': 1.0, '7994020290': 1.0, '8263820112': 1.0, '8263820113': 0.66, '8263820120': 0.66, '8263820123': 0.66, '8263820124': 0.66, '8263820126': 1.0, '8263820132': 1.0, '8263820135': 0.66, '8263820136': 1.0, '8263820138': 0.66, '8263820139': 0.66, '8263820140': 0.66, '8263820141': 0.66, '8263820144': 1.0, '8263820145': 0.66, '8263820146': 0.66, '8263820147': 1.0, '8263820148': 1.0, '826382015': 0.66, '8263820150': 1.0, '8263820151': 1.0, '8263820152': 0.66, '8263820155': 0.66, '8263820156': 0.66, '8263820159': 1.0, '826382016': 1.0, '8263820160': 1.0, '8263820162': 1.0, '8263820165': 1.0, '8263820169': 0.66, '8263820170': 1.0, '826382018': 1.0, '826382021': 0.66, '8263820210': 0.66, '8263820211': 1.0, '8263820212': 1.0, '8263820213': 0.66, '8263820214': 1.0, '8263820221': 1.0, '8263820223': 0.66, '8263820224': 0.66, '8263820227': 0.66, '8263820228': 0.66, '826382023': 1.0, '8263820231': 1.0, '8263820233': 1.0, '8263820234': 1.0, '8263820235': 1.0, '8263820237': 1.0, '8263820239': 1.0, '826382024': 0.33, '8263820240': 1.0, '8263820242': 0.66, '8263820243': 1.0, '8263820245': 0.66, '8263820246': 1.0, '8263820247': 0.66, '8263820251': 1.0, '8263820253': 0.66, '8263820254': 1.0, '8263820255': 0.66, '8263820256': 0.66, '8263820257': 0.66, '8263820259': 1.0, '826382026': 1.0, '8263820260': 0.66, '8263820264': 1.0, '8263820265': 0.66, '8263820266': 0.66, '8263820268': 1.0, '8263820269': 0.66, '826382027': 0.66, '8263820272': 1.0, '8263820273': 1.0, '8263820275': 0.66, '8263820277': 0.66, '8263820278': 0.66, '8263820279': 1.0, '826382028': 0.66, '826412010': 1.0, '8264120110': 0.66, '8264120111': 0.66, '8264120112': 0.66, '8264120113': 1.0, '8264120116': 0.33, '8264120117': 1.0, '8264120119': 1.0, '8264120120': 0.33, '8264120121': 0.66, '8264120122': 0.66, '8264120123': 0.33, '8264120124': 0.66, '8264120125': 0.66, '8264120126': 0.66, '8264120127': 0.33, '826412013': 0.33, '8264120131': 0.66, '8264120132': 0.66, '8264120136': 0.66, '8264120139': 1.0, '8264120141': 0.66, '8264120144': 1.0, '8264120145': 1.0, '8264120146': 1.0, '8264120149': 0.66, '8264120150': 0.33, '8264120156': 0.33, '8264120157': 0.66, '8264120159': 0.66, '8264120165': 1.0, '8264120166': 1.0, '8264120169': 0.33, '826412017': 0.66, '826412018': 0.66, '826412019': 0.66, '8264120210': 0.66, '8264120211': 0.33, '8264120213': 1.0, '8264120215': 1.0, '8264120216': 1.0, '8264120218': 1.0, '8264120219': 1.0, '8264120220': 0.66, '8264120221': 1.0, '8264120223': 0.66, '8264120224': 1.0, '8264120227': 1.0, '8264120228': 1.0, '8264120229': 0.66, '826412023': 1.0, '8264120231': 0.33, '8264120232': 0.66, '8264120233': 1.0, '8264120234': 0.66, '8264120239': 0.33, '826412024': 1.0, '8264120240': 0.0, '8264120241': 0.66, '8264120242': 0.66, '8264120243': 0.33, '8264120245': 0.66, '8264120247': 1.0, '8264120248': 0.66, '8264120249': 0.33, '826412025': 0.66, '8264120254': 0.33, '8264120256': 0.33, '8264120257': 1.0, '8264120258': 0.66, '8264120261': 0.33, '8264120262': 0.33, '8264120263': 0.33, '8264120265': 0.33, '8264120266': 0.33, '8264120268': 1.0, '8264120269': 0.33, '826412027': 0.66, '8264120274': 1.0, '8264120275': 1.0, '8264120279': 0.33, '8264120280': 0.66, '8264120282': 0.33, '8264120284': 0.33, '88265401100': 1.0, '88265401130': 1.0, '88265401140': 1.0, '88265401150': 1.0, '88265401160': 1.0, '88265401170': 0.66, '88265401190': 1.0, '8826540120': 1.0, '88265401200': 0.66, '88265401240': 1.0, '88265401260': 1.0, '88265401270': 1.0, '88265401280': 1.0, '88265401300': 1.0, '88265401320': 1.0, '88265401350': 1.0, '88265401360': 1.0, '88265401380': 1.0, '88265401390': 1.0, '88265401400': 1.0, '88265401410': 1.0, '88265401420': 0.66, '88265401430': 1.0, '88265401450': 1.0, '88265401470': 0.66, '88265401480': 1.0, '88265401490': 1.0, '8826540150': 1.0, '88265401520': 1.0, '88265401550': 1.0, '88265401630': 0.66, '88265401640': 0.66, '88265401660': 1.0, '88265401690': 1.0, '8826540170': 1.0, '88265401730': 1.0, '88265401740': 1.0, '88265401750': 0.33, '8826540180': 1.0, '88265402120': 1.0, '88265402150': 1.0, '88265402160': 0.66, '88265402170': 1.0, '88265402180': 0.66, '88265402190': 1.0, '88265402200': 1.0, '88265402230': 0.66, '88265402240': 0.66, '88265402270': 0.66, '8826540230': 1.0, '88265402300': 1.0, '88265402310': 1.0, '88265402320': 0.66, '88265402330': 1.0, '88265402340': 0.66, '88265402350': 1.0, '88265402370': 1.0, '88265402380': 1.0, '8826540240': 1.0, '88265402400': 0.66, '88265402420': 1.0, '88265402440': 0.66, '88265402450': 1.0, '88265402480': 0.66, '88265402490': 1.0, '88265402500': 1.0, '88265402520': 1.0, '88265402540': 0.66, '88265402570': 0.66, '88265402580': 1.0, '88265402590': 1.0, '8826540260': 0.66, '88265402600': 0.66, '88265402630': 1.0, '88265402660': 1.0, '88265402690': 1.0, '8826540270': 1.0, '88265402700': 1.0, '88265402770': 1.0, '88265402780': 1.0, '88265402790': 0.66, '8826540280': 0.66, '88265402800': 1.0, '88265402810': 1.0, '88265402820': 1.0, '88265402840': 1.0, '88265402850': 1.0, '88265402880': 0.66, '88265402890': 1.0, '8826540290': 1.0, '88265402900': 1.0, '907001100': 1.0, '9070011010': 0.66, '9070011020': 1.0, '9070011060': 1.0, '9070011090': 0.66, '907001110': 1.0, '9070011110': 1.0, '907001120': 0.66, '907001150': 1.0, '907001160': 0.66, '907001170': 1.0, '907001180': 1.0, '907001210': 1.0, '907001220': 1.0, '907001240': 1.0, '907001270': 0.66, '907001280': 1.0, '907001310': 1.0, '907001340': 1.0, '907001350': 1.0, '907001360': 1.0, '907001370': 1.0, '907001400': 1.0, '907001430': 0.66, '907001450': 1.0, '907001480': 0.33, '907001490': 1.0, '90700150': 1.0, '907001500': 1.0, '907001520': 1.0, '907001550': 1.0, '907001560': 0.66, '907001570': 1.0, '907001580': 1.0, '90700160': 1.0, '907001600': 1.0, '907001620': 1.0, '907001650': 0.66, '907001670': 1.0, '907001680': 1.0, '90700170': 1.0, '907001730': 1.0, '907001740': 0.66, '907001780': 1.0, '907001790': 1.0, '90700180': 1.0, '907001820': 1.0, '907001840': 1.0, '907001850': 1.0, '907001860': 1.0, '90700190': 1.0, '907001910': 0.66, '907001940': 1.0, '907001950': 0.33, '907001970': 1.0, '9289010111': 0.66, '9289010112': 0.66, '9289010113': 0.66, '9289010114': 0.33, '9289010115': 1.0, '9289010117': 1.0, '9289010118': 1.0, '9289010119': 1.0, '9289010120': 0.66, '9289010121': 0.66, '9289010127': 0.66, '928901013': 1.0, '9289010131': 0.66, '9289010132': 0.66, '9289010133': 1.0, '9289010134': 1.0, '9289010138': 0.66, '9289010139': 0.66, '928901014': 0.33, '9289010143': 0.66, '9289010144': 0.66, '9289010145': 0.33, '9289010147': 0.66, '9289010149': 1.0, '9289010150': 1.0, '9289010151': 1.0, '9289010152': 0.33, '9289010153': 0.66, '9289010154': 0.66, '9289010155': 1.0, '9289010157': 1.0, '9289010158': 1.0, '928901016': 0.66, '9289010160': 1.0, '9289010161': 0.66, '9289010163': 1.0, '9289010166': 0.66, '9289010167': 1.0, '928901018': 1.0, '9289010210': 1.0, '9289010211': 0.66, '9289010216': 1.0, '9289010221': 1.0, '9289010222': 1.0, '9289010223': 1.0, '9289010227': 1.0, '9289010229': 1.0, '928901023': 1.0, '9289010230': 1.0, '9289010231': 0.66, '9289010232': 1.0, '9289010233': 1.0, '9289010235': 1.0, '9289010242': 1.0, '9289010243': 1.0, '9289010244': 1.0, '9289010245': 1.0, '9289010248': 1.0, '9289010249': 1.0, '928901025': 1.0, '9289010250': 0.66, '9289010251': 1.0, '9289010253': 1.0, '9289010254': 0.66, '9289010257': 1.0, '9289010259': 1.0, '928901026': 1.0, '9289010261': 1.0, '9289010262': 1.0, '9289010263': 0.66, '9289010265': 1.0, '9289010266': 1.0, '9289010267': 1.0, '9289010268': 1.0, '9289010269': 1.0, '9289010270': 1.0, '9289010271': 0.66, '9289010273': 1.0, '9289010274': 1.0, '9289010275': 1.0, '9289010276': 0.33, '9289010278': 1.0, '928901028': 1.0, '928901029': 1.0, '940328011': 1.0, '9403280110': 1.0, '9403280112': 1.0, '9403280114': 1.0, '9403280115': 0.66, '9403280116': 1.0, '9403280117': 1.0, '940328012': 1.0, '9403280126': 1.0, '9403280129': 1.0, '9403280132': 1.0, '9403280134': 0.66, '9403280136': 1.0, '9403280138': 0.66, '940328014': 1.0, '9403280140': 0.66, '9403280143': 0.66, '9403280145': 0.66, '9403280146': 0.66, '9403280147': 1.0, '9403280149': 1.0, '9403280150': 1.0, '9403280151': 0.66, '9403280152': 0.66, '9403280155': 1.0, '9403280156': 1.0, '9403280157': 0.66, '9403280159': 1.0, '940328016': 1.0, '9403280164': 1.0, '9403280165': 0.66, '9403280167': 1.0, '940328017': 1.0, '940328018': 1.0, '9403280212': 1.0, '9403280213': 0.66, '9403280217': 0.66, '9403280218': 0.66, '9403280219': 0.66, '940328022': 1.0, '9403280227': 0.66, '9403280229': 1.0, '9403280234': 1.0, '9403280235': 0.66, '9403280236': 0.66, '9403280238': 0.66, '9403280241': 1.0, '9403280243': 1.0, '9403280245': 1.0, '9403280246': 1.0, '9403280247': 0.66, '9403280249': 1.0, '9403280250': 0.66, '9403280251': 0.66, '9403280254': 1.0, '9403280255': 1.0, '9403280256': 1.0, '9403280259': 1.0, '9403280260': 1.0, '9403280262': 1.0, '9403280265': 1.0, '9403280266': 1.0, '9403280271': 0.33, '9403280272': 1.0, '9403280273': 0.66, '9403280277': 1.0, '9403280279': 1.0, '9877360111': 1.0, '9877360113': 0.66, '9877360114': 1.0, '9877360115': 1.0, '9877360116': 0.66, '9877360117': 0.66, '9877360120': 0.33, '9877360121': 0.66, '9877360124': 1.0, '9877360125': 1.0, '9877360126': 1.0, '9877360127': 0.66, '9877360128': 1.0, '9877360130': 0.66, '9877360131': 1.0, '9877360132': 0.66, '9877360133': 0.0, '9877360134': 1.0, '9877360135': 0.66, '9877360138': 0.66, '987736014': 1.0, '9877360140': 1.0, '9877360141': 1.0, '9877360143': 1.0, '9877360147': 1.0, '9877360149': 1.0, '987736015': 0.66, '9877360151': 1.0, '9877360152': 1.0, '9877360154': 0.66, '9877360156': 1.0, '9877360157': 0.33, '9877360158': 1.0, '9877360159': 1.0, '987736016': 1.0, '9877360163': 0.66, '9877360164': 1.0, '9877360165': 1.0, '9877360166': 1.0, '9877360168': 1.0, '9877360169': 0.33}\n"
     ]
    }
   ],
   "source": [
    "ENGAGE_WILD_DATASET, BIN_CLASSIFICATION, N_CLASSES, DATASET_NAME, BASE_DATASET_DIR, ext = define_dataset(False, False)\n",
    "video2label, labels_list = get_video2label()\n",
    "print(labels_list)\n",
    "print(video2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ccd708-d304-40a1-8b47-2d4094a798c0",
   "metadata": {},
   "source": [
    "### Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92034688-5c7e-4798-bf28-fee79a30908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.std\n",
    "stat_name = \"std\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a817f14-3441-41b8-b8c4-5ca679e9a9b7",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef84d332-6baa-46e8-b75b-f956cc666cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ab7055d-93a3-482c-b2f6-aebf5577a70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96288b48-4ee1-4575-b42e-ebf2fee7670e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 34/5482: 0.6202116016052536%\n",
      "0.33 214/5482: 3.903684786574243%\n",
      "0.66 2649/5482: 48.32178037212696%\n",
      "1.0 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0.0 4/1723: 0.2321532211259431%\n",
      "0.33 81/1723: 4.7011027278003485%\n",
      "0.66 861/1723: 49.97098084735926%\n",
      "1.0 777/1723: 45.095763203714455%\n",
      "val:\n",
      "0.0 23/1720: 1.3372093023255813%\n",
      "0.33 160/1720: 9.30232558139535%\n",
      "0.66 912/1720: 53.02325581395349%\n",
      "1.0 625/1720: 36.33720930232558%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d589b4-8321-4e06-887d-191f0551ed7a",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bf77f8a-0d5f-4a6b-a9b6-26b8c63b3d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_std_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3821728d-913f-486f-b958-b5af23d8523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d18c313-f89b-4469-9dc1-764c58545099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7066054a-f186-4d25-9ba4-3a9d0e95afe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 07:01:38.946316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43e73374-bd60-4a45-928b-d4480d3d6473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 07:01:51.048901: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7eee0bd8e490 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-05 07:01:51.049059: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-08-05 07:01:51.053350: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 07:01:51.086992: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-08-05 07:01:51.138453: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 5s 84ms/step - loss: 0.0467 - mae: 0.1792 - val_loss: 0.0499 - val_mae: 0.1833\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0352 - mae: 0.1603 - val_loss: 0.0498 - val_mae: 0.1834\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0342 - mae: 0.1571 - val_loss: 0.0511 - val_mae: 0.1879\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0334 - mae: 0.1539 - val_loss: 0.0523 - val_mae: 0.1896\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0329 - mae: 0.1528 - val_loss: 0.0544 - val_mae: 0.1955\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0324 - mae: 0.1524 - val_loss: 0.0507 - val_mae: 0.1853\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0322 - mae: 0.1508 - val_loss: 0.0499 - val_mae: 0.1849\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0318 - mae: 0.1496 - val_loss: 0.0488 - val_mae: 0.1811\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0318 - mae: 0.1498 - val_loss: 0.0491 - val_mae: 0.1817\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0315 - mae: 0.1486 - val_loss: 0.0482 - val_mae: 0.1781\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0312 - mae: 0.1482 - val_loss: 0.0500 - val_mae: 0.1840\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0309 - mae: 0.1477 - val_loss: 0.0494 - val_mae: 0.1828\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0311 - mae: 0.1474 - val_loss: 0.0542 - val_mae: 0.1947\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0305 - mae: 0.1462 - val_loss: 0.0498 - val_mae: 0.1849\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0301 - mae: 0.1453 - val_loss: 0.0519 - val_mae: 0.1900\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0306 - mae: 0.1462 - val_loss: 0.0492 - val_mae: 0.1815\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0298 - mae: 0.1450 - val_loss: 0.0521 - val_mae: 0.1889\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0295 - mae: 0.1434 - val_loss: 0.0515 - val_mae: 0.1862\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0290 - mae: 0.1427 - val_loss: 0.0525 - val_mae: 0.1882\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.0299 - mae: 0.1437 - val_loss: 0.0520 - val_mae: 0.1886\n",
      "0.04820723831653595\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03e74e3a-aa03-4d2e-84e3-3f1e088a1caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11e84413-edb4-43b8-a26f-0bc36c0a7ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_single_attention_traditional Accuracy:  0.5217643644805572 MSE:  0.038047092321387664 UAR:  0.2804014816209938 Recall:  N/A Precision:  N/A F1:  0.25784831847775197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5217643644805572,\n",
       " 0.038047092321387664,\n",
       " 0.2804014816209938,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.25784831847775197)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b8ac7ce-ecb1-42f0-9aa7-086b4da3a058",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7810fdb7-93a7-4214-97d6-accb73551cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26467b11-7b70-41a4-8977-798a0e4c2e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_single_attention_traditional_best Accuracy:  0.5368543238537434 MSE:  0.03966343271742339 UAR:  0.29005864168465795 Recall:  N/A Precision:  N/A F1:  0.2859987189068005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5368543238537434,\n",
       " 0.03966343271742339,\n",
       " 0.29005864168465795,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.2859987189068005)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b8d7a7-a421-4a5f-85de-6eb4f3f536d1",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e14626f-1b4f-4c2e-b73e-93e5a63f1f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93590354-df00-4777-98bf-2961f3db973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf65658b-65e8-4a5d-ab34-51c5ab13e931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cbb1b8d3-e357-4c2a-8254-1b3dd1a11bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "235d4024-9f86-492e-8251-dc24dd9225d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 120ms/step - loss: 0.0812 - mae: 0.2005 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "0.11642508953809738\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "034fefa8-cdec-4aba-b868-933ef4adcb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "54a9a2d1-b5f4-4af7-9d5c-34cfe449db50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_traditional Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "debff917-a1bc-4103-9513-b795274ea828",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3e27e6a1-d45c-4ff7-9449-58911a392318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d4ae1a5-2cb9-49c6-b014-a222ec99e91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_traditional_best Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778ba15b-4f17-45a4-80d3-8b68e8c1388b",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c923ed91-caef-460e-a1aa-67319ae5282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "42ba3ee3-7a1e-4d27-bf25-9bfb603f9ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a3b1405b-107f-473a-b4c0-ede100c676d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 34/5482: 0.6202116016052536%\n",
      "0.33 214/5482: 3.903684786574243%\n",
      "0.66 2649/5482: 48.32178037212696%\n",
      "1.0 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0.0 4/1723: 0.2321532211259431%\n",
      "0.33 81/1723: 4.7011027278003485%\n",
      "0.66 861/1723: 49.97098084735926%\n",
      "1.0 777/1723: 45.095763203714455%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "67c80de3-2c85-4413-a0cf-824b17183133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482,) (5482,)\n",
      "(1723,) (1723,)\n",
      "(7205,) (7205,)\n",
      "[0.   0.33 0.66 1.  ] [  38  295 3510 3362]\n",
      "7205\n",
      "5474\n",
      "1731\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e5eee050-fce2-4ba4-9ad5-2dc37d504680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 28/5474: 0.5115089514066496%\n",
      "0.33 224/5474: 4.092071611253197%\n",
      "0.66 2667/5474: 48.72122762148338%\n",
      "1.0 2555/5474: 46.67519181585678%\n",
      "test:\n",
      "0.0 10/1731: 0.5777007510109763%\n",
      "0.33 71/1731: 4.101675332177932%\n",
      "0.66 843/1731: 48.7001733102253%\n",
      "1.0 807/1731: 46.62045060658579%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad450dd6-3c9b-4dd2-98e1-5233da6f9646",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1dd93e6f-e5a4-403a-88be-cfa5ad8e974c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_std_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1dec7a40-0555-47a3-8a20-687bdb90d1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b24e8344-bdd2-44ee-93ac-d02e47b110ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 2560) (5474,)\n",
      "(1731, 128, 2560) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "22223435-54ea-4175-b18c-52c1aae7b967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "175191c1-3964-44c8-b148-f774e2eca6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 4s 62ms/step - loss: 0.0455 - mae: 0.1805 - val_loss: 0.0361 - val_mae: 0.1671\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0358 - mae: 0.1640 - val_loss: 0.0343 - val_mae: 0.1609\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0346 - mae: 0.1598 - val_loss: 0.0336 - val_mae: 0.1579\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0337 - mae: 0.1572 - val_loss: 0.0336 - val_mae: 0.1591\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0331 - mae: 0.1559 - val_loss: 0.0339 - val_mae: 0.1540\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0331 - mae: 0.1555 - val_loss: 0.0343 - val_mae: 0.1544\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0328 - mae: 0.1542 - val_loss: 0.0335 - val_mae: 0.1533\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0322 - mae: 0.1526 - val_loss: 0.0340 - val_mae: 0.1574\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0321 - mae: 0.1520 - val_loss: 0.0337 - val_mae: 0.1546\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0317 - mae: 0.1513 - val_loss: 0.0337 - val_mae: 0.1561\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0316 - mae: 0.1504 - val_loss: 0.0337 - val_mae: 0.1536\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0314 - mae: 0.1503 - val_loss: 0.0335 - val_mae: 0.1528\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0309 - mae: 0.1484 - val_loss: 0.0344 - val_mae: 0.1575\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0310 - mae: 0.1491 - val_loss: 0.0348 - val_mae: 0.1546\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0307 - mae: 0.1476 - val_loss: 0.0338 - val_mae: 0.1518\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0308 - mae: 0.1482 - val_loss: 0.0339 - val_mae: 0.1554\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0299 - mae: 0.1453 - val_loss: 0.0344 - val_mae: 0.1563\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0295 - mae: 0.1453 - val_loss: 0.0346 - val_mae: 0.1551\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0292 - mae: 0.1437 - val_loss: 0.0345 - val_mae: 0.1564\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.0291 - mae: 0.1440 - val_loss: 0.0344 - val_mae: 0.1545\n",
      "0.03346310928463936\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "33a92363-a6d1-4e11-9440-1019b3c00d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0deafeb4-16f7-45f7-894a-2cc43419ddbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_single_attention_balanced Accuracy:  0.5771230502599654 MSE:  0.03434189749156464 UAR:  0.32464645258206026 Recall:  N/A Precision:  N/A F1:  0.31959519092782207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5771230502599654,\n",
       " 0.03434189749156464,\n",
       " 0.32464645258206026,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.31959519092782207)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "38a448e5-747f-411a-8b72-b73c53ad2173",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cbaa3ea3-352d-4139-ab49-2cec1d2362e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a53636c4-2733-499a-9a12-ef75d1fa386a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_single_attention_balanced_best Accuracy:  0.6077411900635471 MSE:  0.03344626485229473 UAR:  0.3238047218162814 Recall:  N/A Precision:  N/A F1:  0.313621256796059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6077411900635471,\n",
       " 0.03344626485229473,\n",
       " 0.3238047218162814,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.313621256796059)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd929ea3-6902-4ac5-aa52-17a446505804",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "57d8c6b3-298c-431d-83ba-480aba374299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d4effd30-ee3b-4feb-9467-9d22dc0f3ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a3b8932c-5f9f-4d6c-bc65-23fd8e8913e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 2560) (5474,)\n",
      "(1731, 128, 2560) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "01ada3ee-fccd-4e58-94af-aa1a36486559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ff1f78e3-c557-4133-8cb7-1aeab1723a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 125ms/step - loss: 0.0812 - mae: 0.2012 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "0.08048681914806366\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "17388a1e-fc3f-4c97-9d4b-664b14161873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dad43b85-0c67-48f1-a23e-abb66209c48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5945256c-398e-4218-b70c-5f6ed350d84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cce4646a-cd0b-4964-be28-b8c8dbf2ba4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7e018315-7fde-4a94-aecc-9be226b9d154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced_best Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f86c59f-3dd0-4f52-a6c1-93a65c892c95",
   "metadata": {},
   "source": [
    "### Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "90a40a74-d38f-4375-af1b-372f5e7d5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.max\n",
    "stat_name = \"max\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380bf5d8-c712-46bf-9b44-eb7fcd187494",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "20904bcf-18d3-4602-adc5-2ad29ebea2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8609dba0-50ab-49c0-80d3-55c5516dba84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0650e4d4-55a2-47e2-a8c7-9f114b3ce951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 34/5482: 0.6202116016052536%\n",
      "0.33 214/5482: 3.903684786574243%\n",
      "0.66 2649/5482: 48.32178037212696%\n",
      "1.0 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0.0 4/1723: 0.2321532211259431%\n",
      "0.33 81/1723: 4.7011027278003485%\n",
      "0.66 861/1723: 49.97098084735926%\n",
      "1.0 777/1723: 45.095763203714455%\n",
      "val:\n",
      "0.0 23/1720: 1.3372093023255813%\n",
      "0.33 160/1720: 9.30232558139535%\n",
      "0.66 912/1720: 53.02325581395349%\n",
      "1.0 625/1720: 36.33720930232558%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6ad2cb-0bbd-4016-a9d1-5983bc17e3c5",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d1845384-398b-40fa-9500-47c1cf0ad2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_max_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "954093f9-22a0-44ca-a20f-6bccb70b4f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c9d2ff48-d8c1-495b-9b15-487180700a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "66e24caf-9172-4a3c-a950-8033474f1447",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e0c42d09-06d8-43c5-b902-d1a8b16407bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0808 - mae: 0.2002 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0794 - mae: 0.1967 - val_loss: 0.1156 - val_mae: 0.2562\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0563 - mae: 0.1804 - val_loss: 0.0745 - val_mae: 0.2193\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0373 - mae: 0.1596 - val_loss: 0.0519 - val_mae: 0.1882\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0344 - mae: 0.1553 - val_loss: 0.0517 - val_mae: 0.1882\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0343 - mae: 0.1551 - val_loss: 0.0542 - val_mae: 0.1952\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0328 - mae: 0.1523 - val_loss: 0.0578 - val_mae: 0.2019\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0333 - mae: 0.1532 - val_loss: 0.0521 - val_mae: 0.1852\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0332 - mae: 0.1526 - val_loss: 0.0545 - val_mae: 0.1942\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0314 - mae: 0.1488 - val_loss: 0.0547 - val_mae: 0.1948\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0308 - mae: 0.1490 - val_loss: 0.0532 - val_mae: 0.1916\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0307 - mae: 0.1469 - val_loss: 0.0552 - val_mae: 0.1972\n",
      "0.051714181900024414\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a39c035c-05af-4e96-97a5-7ca282a27cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1be202e0-1032-4dc3-b8dc-575a3f6fb02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_max_single_attention_traditional Accuracy:  0.5252466627974464 MSE:  0.03956373653398682 UAR:  0.28726490718360637 Recall:  N/A Precision:  N/A F1:  0.2729057554923391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5252466627974464,\n",
       " 0.03956373653398682,\n",
       " 0.28726490718360637,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.2729057554923391)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "69512da1-0677-4c01-b946-f92c7db18706",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d3c98fa9-3bd0-4a79-a65d-90247e1cd978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1b6337fe-da6d-491f-976f-03f87fc4e3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_max_single_attention_traditional_best Accuracy:  0.5206035983749274 MSE:  0.03961097842999725 UAR:  0.28506758791311637 Recall:  N/A Precision:  N/A F1:  0.2698112420225823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5206035983749274,\n",
       " 0.03961097842999725,\n",
       " 0.28506758791311637,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.2698112420225823)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4846c289-46b0-47c0-9589-1964c975573b",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0108304f-4668-4498-9fbd-fcb66e3a1431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_max_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "73b9696a-9c8e-4d14-830a-c55065bb10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b579f60d-e7bd-4492-a80f-bfe6ff01b09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "add3378e-e230-4d0c-906b-3e37371f242e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_2 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_2[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_2[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "af87244d-d897-4b28-b0fc-bbd6ddce9307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 120ms/step - loss: 0.0815 - mae: 0.2004 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "0.11642508953809738\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "339e67cd-ba0f-476f-a89c-7f36d5ffed17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "414e0dc6-64f2-4313-a2a0-0ddb08d8ce69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_max_self_attention_traditional Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7a2123b9-24be-4a20-b74d-28c90606f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "048139d2-9f20-44e3-b40b-20500f485a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f299da4e-9e2a-4287-857b-05abd351d900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_max_self_attention_traditional_best Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124a2b31-b4bf-4fe2-9bc1-21c65a70414a",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7ae55394-8484-4088-ad49-ef616e179321",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0b8a5e7e-0af8-4e46-8f4d-aa5a569f67b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3bac9f14-02e2-4a39-bc09-603c16a7e707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 34/5482: 0.6202116016052536%\n",
      "0.33 214/5482: 3.903684786574243%\n",
      "0.66 2649/5482: 48.32178037212696%\n",
      "1.0 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0.0 4/1723: 0.2321532211259431%\n",
      "0.33 81/1723: 4.7011027278003485%\n",
      "0.66 861/1723: 49.97098084735926%\n",
      "1.0 777/1723: 45.095763203714455%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "df96814f-0003-4163-b1fe-6bb3c362f623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482,) (5482,)\n",
      "(1723,) (1723,)\n",
      "(7205,) (7205,)\n",
      "[0.   0.33 0.66 1.  ] [  38  295 3510 3362]\n",
      "7205\n",
      "5474\n",
      "1731\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6920a04f-d0d9-4bc3-ac8f-e647c1bedf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 28/5474: 0.5115089514066496%\n",
      "0.33 224/5474: 4.092071611253197%\n",
      "0.66 2667/5474: 48.72122762148338%\n",
      "1.0 2555/5474: 46.67519181585678%\n",
      "test:\n",
      "0.0 10/1731: 0.5777007510109763%\n",
      "0.33 71/1731: 4.101675332177932%\n",
      "0.66 843/1731: 48.7001733102253%\n",
      "1.0 807/1731: 46.62045060658579%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f482fcd-8a81-46f0-b16b-dbe3c31636ec",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "518b1316-a87e-4565-a360-d437624a998a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_max_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ed711e71-76dc-4739-9593-b63095a605fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "813ef643-175c-45ea-982d-f95c62eeb984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 2560) (5474,)\n",
      "(1731, 128, 2560) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ba9ad0b5-b8b3-4742-ac01-27b8a47273c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "434a60e5-0e16-497b-8d72-579727832f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 4s 63ms/step - loss: 0.0801 - mae: 0.2012 - val_loss: 0.0793 - val_mae: 0.1980\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0594 - mae: 0.1835 - val_loss: 0.0372 - val_mae: 0.1688\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0361 - mae: 0.1611 - val_loss: 0.0343 - val_mae: 0.1594\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0344 - mae: 0.1577 - val_loss: 0.0337 - val_mae: 0.1567\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0341 - mae: 0.1569 - val_loss: 0.0341 - val_mae: 0.1557\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0334 - mae: 0.1545 - val_loss: 0.0344 - val_mae: 0.1556\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0330 - mae: 0.1540 - val_loss: 0.0337 - val_mae: 0.1540\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0325 - mae: 0.1527 - val_loss: 0.0336 - val_mae: 0.1554\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0316 - mae: 0.1507 - val_loss: 0.0345 - val_mae: 0.1553\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0314 - mae: 0.1496 - val_loss: 0.0343 - val_mae: 0.1546\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0307 - mae: 0.1483 - val_loss: 0.0344 - val_mae: 0.1562\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0305 - mae: 0.1479 - val_loss: 0.0340 - val_mae: 0.1531\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0302 - mae: 0.1462 - val_loss: 0.0345 - val_mae: 0.1539\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0295 - mae: 0.1454 - val_loss: 0.0343 - val_mae: 0.1559\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0292 - mae: 0.1440 - val_loss: 0.0354 - val_mae: 0.1580\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0290 - mae: 0.1433 - val_loss: 0.0357 - val_mae: 0.1595\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0288 - mae: 0.1424 - val_loss: 0.0347 - val_mae: 0.1555\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0282 - mae: 0.1411 - val_loss: 0.0354 - val_mae: 0.1536\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0282 - mae: 0.1400 - val_loss: 0.0363 - val_mae: 0.1600\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.0283 - mae: 0.1409 - val_loss: 0.0352 - val_mae: 0.1555\n",
      "0.033625755459070206\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0472bf93-b1ac-4a52-86ee-94e8a5ce36bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "730de4cc-50cd-4c18-881e-7a2c9dc05f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_max_single_attention_balanced Accuracy:  0.5597920277296361 MSE:  0.03518569922096237 UAR:  0.30947250441400515 Recall:  N/A Precision:  N/A F1:  0.2954889341453528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5597920277296361,\n",
       " 0.03518569922096237,\n",
       " 0.30947250441400515,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.2954889341453528)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2c6211cd-d39d-4e79-97e5-378112373a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "80ee2257-4dd3-4969-b833-a70c73388058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "25874644-813d-4b73-b8d1-cb00c10632d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_max_single_attention_balanced_best Accuracy:  0.560369728480647 MSE:  0.03360795267187779 UAR:  0.2972544506034829 Recall:  N/A Precision:  N/A F1:  0.26869345457200394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.560369728480647,\n",
       " 0.03360795267187779,\n",
       " 0.2972544506034829,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.26869345457200394)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2c58c9-585a-4289-ac5d-fa783bb3ebc8",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "102e9030-f76c-4462-90ba-85282d8ddc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_max_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "803299a0-b513-4c54-82d7-e14c569a6866",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e7196d48-82f4-466c-b097-89e35cdb1a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 2560) (5474,)\n",
      "(1731, 128, 2560) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "35b3fbba-0b1e-433c-b6e8-ed76f2e80fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_3 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_3[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_3[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ca0e8dab-037f-4326-92a3-0b6974fe8341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 121ms/step - loss: 0.0814 - mae: 0.2014 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "0.08048681914806366\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "81c8d1d1-f129-43b5-ada1-3754e689a342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a162b1f7-4f37-483d-b6f6-e4539bd3ef51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_max_self_attention_balanced Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "50d5d33c-5300-40e7-b1e1-3313cc2b61f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "81baa7b8-d221-4722-aef9-6a37a0e5870a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "903be646-7c77-49a3-8a06-c4b44bdeb8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_max_self_attention_balanced_best Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d29a7f-6df3-49ea-8d3a-e26345f0e584",
   "metadata": {},
   "source": [
    "### STAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ec5db598-4a55-4c87-be61-cc68b9f85fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = compute_descriptor\n",
    "stat_name = \"STAT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a527a3-7d0f-4370-9722-a450bb5d25b4",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6821047d-72d0-466a-a3bb-3e5f3335ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5d2489be-026d-48e9-a0e4-b81afaef1214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "caec6f9b-7ea2-4e00-ac4b-04ffdc7cb3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 34/5482: 0.6202116016052536%\n",
      "0.33 214/5482: 3.903684786574243%\n",
      "0.66 2649/5482: 48.32178037212696%\n",
      "1.0 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0.0 4/1723: 0.2321532211259431%\n",
      "0.33 81/1723: 4.7011027278003485%\n",
      "0.66 861/1723: 49.97098084735926%\n",
      "1.0 777/1723: 45.095763203714455%\n",
      "val:\n",
      "0.0 23/1720: 1.3372093023255813%\n",
      "0.33 160/1720: 9.30232558139535%\n",
      "0.66 912/1720: 53.02325581395349%\n",
      "1.0 625/1720: 36.33720930232558%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d660459f-1a25-4025-9aab-b58275fde1d0",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "52cd73c6-46b8-4859-9cf9-77477a8de686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_STAT_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f26c2c3d-42b3-419c-b568-4048d082af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8693426f-8353-4ba7-8c18-e5704a8add77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 3840) (5482,)\n",
      "(1723, 128, 3840) (1723,)\n",
      "(1720, 128, 3840) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5aa3b2fa-53cc-486d-9a70-96e0c513b64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1966592   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1970946 (7.52 MB)\n",
      "Trainable params: 1970946 (7.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "da4e5b6c-f89c-4244-b20c-499c6f2a0a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 95ms/step - loss: 0.0802 - mae: 0.1991 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.0796 - mae: 0.1966 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.0796 - mae: 0.1966 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.0771 - mae: 0.1934 - val_loss: 0.1094 - val_mae: 0.2470\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.0609 - mae: 0.1796 - val_loss: 0.0515 - val_mae: 0.1784\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.0357 - mae: 0.1600 - val_loss: 0.0515 - val_mae: 0.1875\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.0338 - mae: 0.1547 - val_loss: 0.0500 - val_mae: 0.1845\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.0331 - mae: 0.1537 - val_loss: 0.0569 - val_mae: 0.1982\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.0332 - mae: 0.1524 - val_loss: 0.0506 - val_mae: 0.1860\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 2s 41ms/step - loss: 0.0326 - mae: 0.1514 - val_loss: 0.0516 - val_mae: 0.1871\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.0320 - mae: 0.1503 - val_loss: 0.0490 - val_mae: 0.1797\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.0319 - mae: 0.1496 - val_loss: 0.0490 - val_mae: 0.1787\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.0317 - mae: 0.1490 - val_loss: 0.0507 - val_mae: 0.1858\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.0312 - mae: 0.1478 - val_loss: 0.0495 - val_mae: 0.1827\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.0308 - mae: 0.1469 - val_loss: 0.0513 - val_mae: 0.1869\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.0308 - mae: 0.1468 - val_loss: 0.0504 - val_mae: 0.1823\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.0305 - mae: 0.1458 - val_loss: 0.0521 - val_mae: 0.1879\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.0301 - mae: 0.1451 - val_loss: 0.0510 - val_mae: 0.1855\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.0304 - mae: 0.1455 - val_loss: 0.0518 - val_mae: 0.1849\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.0304 - mae: 0.1451 - val_loss: 0.0530 - val_mae: 0.1847\n",
      "0.048994023352861404\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "dc9e37ac-959d-4418-8872-90ebfc734a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0051a46b-351a-4647-bd9f-2c23b45a950e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_STAT_single_attention_traditional Accuracy:  0.5502031340684852 MSE:  0.04595219703537471 UAR:  0.3021430257202615 Recall:  N/A Precision:  N/A F1:  0.3037438085935406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5502031340684852,\n",
       " 0.04595219703537471,\n",
       " 0.3021430257202615,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.3037438085935406)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "739fb4d3-2101-4bf2-88f0-d42cdf192027",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a39d386b-5949-4f43-8878-621b41c24012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cda97860-b6ba-443e-a26a-1dae360dd719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_STAT_single_attention_traditional_best Accuracy:  0.522344747533372 MSE:  0.037993142095166056 UAR:  0.28458888621490247 Recall:  N/A Precision:  N/A F1:  0.2748328939305298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.522344747533372,\n",
       " 0.037993142095166056,\n",
       " 0.28458888621490247,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.2748328939305298)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4d7ce9-4ff6-4c6e-bd16-4f825c362920",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bbf9f05a-a82b-4ecd-8965-aec247fb9d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_STAT_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2817d739-d67b-4b1c-a3df-3a99e83ab1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9cf4a51f-0fdb-4e7e-822c-c1535d473ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 3840) (5482,)\n",
      "(1723, 128, 3840) (1723,)\n",
      "(1720, 128, 3840) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "10abfa94-1d01-4646-950c-6283fbf0d5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " attention_4 (Attention)     (None, None, 3840)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['attention_4[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['attention_4[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 1)                    3841      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29498882 (112.53 MB)\n",
      "Trainable params: 29498882 (112.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f82dadef-128f-4551-a170-558d441617e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 10s 215ms/step - loss: 0.0822 - mae: 0.2014 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 7s 168ms/step - loss: 0.0798 - mae: 0.1969 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 7s 168ms/step - loss: 0.0798 - mae: 0.1969 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 7s 171ms/step - loss: 0.0798 - mae: 0.1969 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 7s 168ms/step - loss: 0.0798 - mae: 0.1969 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 7s 169ms/step - loss: 0.0798 - mae: 0.1969 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 7s 168ms/step - loss: 0.0798 - mae: 0.1969 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 7s 169ms/step - loss: 0.0798 - mae: 0.1969 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 7s 169ms/step - loss: 0.0798 - mae: 0.1969 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 7s 169ms/step - loss: 0.0798 - mae: 0.1969 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 7s 167ms/step - loss: 0.0798 - mae: 0.1969 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 7s 169ms/step - loss: 0.0798 - mae: 0.1969 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 7s 170ms/step - loss: 0.0798 - mae: 0.1969 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 7s 168ms/step - loss: 0.0798 - mae: 0.1969 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 7s 167ms/step - loss: 0.0798 - mae: 0.1969 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 7s 168ms/step - loss: 0.0798 - mae: 0.1969 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 7s 172ms/step - loss: 0.0798 - mae: 0.1969 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 7s 168ms/step - loss: 0.0798 - mae: 0.1969 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 7s 170ms/step - loss: 0.0798 - mae: 0.1969 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 7s 168ms/step - loss: 0.0798 - mae: 0.1969 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "0.11642508953809738\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a6fb674b-7bc9-40b7-b3a1-71757059175b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5c547fb4-a884-4660-b23f-fe6dd0dd51ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_STAT_self_attention_traditional Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2939f456-670c-4cbe-be3a-266b5fde77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4197bd48-87ce-4252-a4ab-78c2a4316d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "637ce0bd-c972-4bbb-8e67-fb698def3d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_STAT_self_attention_traditional_best Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9211c524-bb3b-4354-9b99-2e083a3eca82",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "24e92c44-d1b4-41d4-9bf2-ecb92aa527ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "676e8906-a2a1-49a5-83f3-b10e9d99730f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "92c12bc5-f865-4e93-826f-2a302ad14ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 34/5482: 0.6202116016052536%\n",
      "0.33 214/5482: 3.903684786574243%\n",
      "0.66 2649/5482: 48.32178037212696%\n",
      "1.0 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0.0 4/1723: 0.2321532211259431%\n",
      "0.33 81/1723: 4.7011027278003485%\n",
      "0.66 861/1723: 49.97098084735926%\n",
      "1.0 777/1723: 45.095763203714455%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b24d1220-1a5f-44c0-bbe8-ae9e4ca79989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 2560) (5482,)\n",
      "(1723, 2560) (1723,)\n",
      "(7205, 2560) (7205,)\n",
      "[0.   0.33 0.66 1.  ] [  38  295 3510 3362]\n",
      "7205\n",
      "5474\n",
      "1731\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "24ae2432-c381-4b0b-ba12-123a8bc9a44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 28/5474: 0.5115089514066496%\n",
      "0.33 224/5474: 4.092071611253197%\n",
      "0.66 2667/5474: 48.72122762148338%\n",
      "1.0 2555/5474: 46.67519181585678%\n",
      "test:\n",
      "0.0 10/1731: 0.5777007510109763%\n",
      "0.33 71/1731: 4.101675332177932%\n",
      "0.66 843/1731: 48.7001733102253%\n",
      "1.0 807/1731: 46.62045060658579%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b1d885-2b87-496c-a9b6-77948a6895de",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7a747d95-6a44-4558-a867-516281a74d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_STAT_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0b05d068-8e69-460e-b69c-034a02afaf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "47f78703-1839-42af-b14f-f7597f46a29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 3840) (5474,)\n",
      "(1731, 128, 3840) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9eb7a4c4-deda-41a4-806c-112ecb322e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1966592   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1970946 (7.52 MB)\n",
      "Trainable params: 1970946 (7.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e637dad1-ef3d-49cf-9d26-62f439abdef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 91ms/step - loss: 0.0772 - mae: 0.1978 - val_loss: 0.0693 - val_mae: 0.1895\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.0427 - mae: 0.1726 - val_loss: 0.0354 - val_mae: 0.1619\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.0351 - mae: 0.1594 - val_loss: 0.0342 - val_mae: 0.1568\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.0344 - mae: 0.1578 - val_loss: 0.0347 - val_mae: 0.1605\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.0338 - mae: 0.1570 - val_loss: 0.0338 - val_mae: 0.1580\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.0336 - mae: 0.1555 - val_loss: 0.0347 - val_mae: 0.1563\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.0331 - mae: 0.1537 - val_loss: 0.0353 - val_mae: 0.1608\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.0330 - mae: 0.1536 - val_loss: 0.0344 - val_mae: 0.1591\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.0322 - mae: 0.1521 - val_loss: 0.0335 - val_mae: 0.1551\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.0318 - mae: 0.1512 - val_loss: 0.0337 - val_mae: 0.1556\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.0319 - mae: 0.1510 - val_loss: 0.0341 - val_mae: 0.1545\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.0312 - mae: 0.1498 - val_loss: 0.0338 - val_mae: 0.1571\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.0311 - mae: 0.1493 - val_loss: 0.0341 - val_mae: 0.1542\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.0313 - mae: 0.1493 - val_loss: 0.0338 - val_mae: 0.1549\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.0305 - mae: 0.1476 - val_loss: 0.0341 - val_mae: 0.1554\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.0305 - mae: 0.1473 - val_loss: 0.0350 - val_mae: 0.1587\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.0300 - mae: 0.1461 - val_loss: 0.0346 - val_mae: 0.1552\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.0296 - mae: 0.1454 - val_loss: 0.0353 - val_mae: 0.1585\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.0292 - mae: 0.1434 - val_loss: 0.0343 - val_mae: 0.1551\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.0289 - mae: 0.1437 - val_loss: 0.0348 - val_mae: 0.1549\n",
      "0.03347734734416008\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "75cf2adf-94cd-4b7e-b5e6-d52fed1eac56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "cba5ef2d-6e02-4ce7-8209-c881efcd6a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_STAT_single_attention_balanced Accuracy:  0.561525129982669 MSE:  0.03476576609587698 UAR:  0.3544130253569821 Recall:  N/A Precision:  N/A F1:  0.36654019677001815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.561525129982669,\n",
       " 0.03476576609587698,\n",
       " 0.3544130253569821,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.36654019677001815)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c4cece9c-1335-4f76-b4ad-a074ad3feaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "af37168a-e64c-4280-988b-1d457d3ed2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ae043a6d-d03b-4b19-ab25-2ee85a9944b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_STAT_single_attention_balanced_best Accuracy:  0.5927209705372617 MSE:  0.03347231848271875 UAR:  0.3198743675412443 Recall:  N/A Precision:  N/A F1:  0.3066718194009703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5927209705372617,\n",
       " 0.03347231848271875,\n",
       " 0.3198743675412443,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.3066718194009703)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1329796f-1a2d-496f-96cb-501127c78595",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "387d3efb-8181-43b3-b45e-6a09a0b3a4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_STAT_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ea881a83-bc71-4511-8c73-aafe64783e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "127b8f85-af49-4c40-9c00-b99580b7950d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 3840) (5474,)\n",
      "(1731, 128, 3840) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "71ee0bbf-5870-485a-b30e-288a1aec8db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " attention_5 (Attention)     (None, None, 3840)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['attention_5[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['attention_5[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 1)                    3841      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29498882 (112.53 MB)\n",
      "Trainable params: 29498882 (112.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7c62b3b3-988b-496f-b616-aaf4dcb72d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 10s 215ms/step - loss: 0.0813 - mae: 0.2015 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 7s 168ms/step - loss: 0.0800 - mae: 0.1984 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 7s 168ms/step - loss: 0.0800 - mae: 0.1984 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 7s 169ms/step - loss: 0.0800 - mae: 0.1984 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 7s 168ms/step - loss: 0.0800 - mae: 0.1984 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 7s 169ms/step - loss: 0.0800 - mae: 0.1984 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 7s 167ms/step - loss: 0.0800 - mae: 0.1984 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 7s 168ms/step - loss: 0.0800 - mae: 0.1984 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 7s 168ms/step - loss: 0.0800 - mae: 0.1984 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 7s 168ms/step - loss: 0.0800 - mae: 0.1984 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 7s 169ms/step - loss: 0.0800 - mae: 0.1984 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 7s 171ms/step - loss: 0.0800 - mae: 0.1984 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 7s 169ms/step - loss: 0.0800 - mae: 0.1984 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 7s 169ms/step - loss: 0.0800 - mae: 0.1984 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 7s 169ms/step - loss: 0.0800 - mae: 0.1984 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 7s 168ms/step - loss: 0.0800 - mae: 0.1984 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 7s 169ms/step - loss: 0.0800 - mae: 0.1984 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 7s 168ms/step - loss: 0.0800 - mae: 0.1984 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 7s 170ms/step - loss: 0.0800 - mae: 0.1984 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 7s 168ms/step - loss: 0.0800 - mae: 0.1984 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "0.08048681914806366\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "0aceabc2-743a-4f95-95ef-bc364ac68787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f6dea702-f034-4784-b8c1-695175a6b961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_STAT_self_attention_balanced Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c4ae577d-533e-4f66-b8ed-e0c4a61a6429",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0c583cfc-9248-4d7c-af1d-661a34ae76d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "7fe440f5-9930-4e2d-91cb-6cf60ed4dbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_STAT_self_attention_balanced_best Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c269d7c8-5485-416c-9068-1b3218fdda39",
   "metadata": {},
   "source": [
    "## MobileNet_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "373618c1-1854-4ecf-be7b-2ac345083791",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_key = 'mobilenet_7.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d48bce1a-b00d-4ab7-bedf-620c5f087632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['very distracted', 'distracted', 'engaged', 'very engaged']\n",
      "{'1100011002': 0.66, '1100011003': 0.66, '1100011004': 1.0, '1100011005': 1.0, '1100011006': 1.0, '1100011007': 0.66, '1100011008': 1.0, '1100011009': 0.66, '1100011010': 1.0, '1100011011': 1.0, '1100011012': 0.66, '1100011013': 1.0, '1100011014': 1.0, '1100011015': 1.0, '1100011016': 1.0, '1100011017': 1.0, '1100011018': 1.0, '1100011019': 1.0, '1100011020': 1.0, '1100011021': 1.0, '1100011022': 1.0, '1100011023': 1.0, '1100011025': 1.0, '1100011026': 1.0, '1100011027': 1.0, '1100011028': 1.0, '1100011029': 1.0, '1100011031': 1.0, '1100011032': 1.0, '1100011034': 1.0, '1100011035': 1.0, '1100011037': 1.0, '1100011038': 1.0, '1100011040': 0.66, '1100011046': 1.0, '1100011047': 1.0, '1100011048': 0.66, '1100011049': 1.0, '1100011050': 1.0, '1100011051': 1.0, '1100011052': 1.0, '1100011053': 1.0, '1100011054': 1.0, '1100011055': 1.0, '1100011056': 1.0, '1100011057': 1.0, '1100011058': 1.0, '1100011059': 1.0, '1100011060': 1.0, '1100011062': 1.0, '1100011063': 1.0, '1100011064': 1.0, '1100011066': 1.0, '1100011067': 1.0, '1100011068': 1.0, '1100011069': 1.0, '1100011070': 1.0, '1100011071': 1.0, '1100011072': 1.0, '1100011073': 1.0, '1100011075': 1.0, '1100011076': 1.0, '1100011078': 0.66, '1100011079': 1.0, '1100011080': 1.0, '1100011081': 1.0, '1100011082': 1.0, '1100011083': 1.0, '1100012001': 1.0, '1100012003': 1.0, '1100012007': 1.0, '1100012008': 1.0, '1100012009': 1.0, '1100012010': 1.0, '1100012011': 1.0, '1100012013': 1.0, '1100012014': 1.0, '1100012015': 1.0, '1100012016': 1.0, '1100012017': 1.0, '1100012018': 1.0, '1100012021': 0.66, '1100012022': 1.0, '1100012023': 1.0, '1100012025': 1.0, '1100012026': 1.0, '1100012027': 1.0, '1100012028': 1.0, '1100012030': 1.0, '1100012031': 1.0, '1100012032': 1.0, '1100012033': 1.0, '1100012036': 1.0, '1100012037': 1.0, '1100012038': 1.0, '1100012041': 1.0, '1100012042': 0.66, '1100012045': 0.66, '1100012046': 1.0, '1100012047': 0.66, '1100012049': 1.0, '1100012050': 1.0, '1100012051': 1.0, '1100012052': 1.0, '1100012057': 1.0, '1100012059': 1.0, '1100012060': 1.0, '1100012061': 1.0, '1100012062': 1.0, '1100012063': 1.0, '1100012064': 1.0, '1100012065': 1.0, '1100012066': 1.0, '1100012069': 1.0, '1100021001': 0.66, '1100021003': 0.33, '1100021015': 0.66, '1100021038': 0.66, '1100021039': 0.66, '1100021040': 1.0, '1100021045': 1.0, '1100021050': 1.0, '1100021055': 0.33, '1100022001': 1.0, '1100022002': 0.66, '1100022003': 1.0, '1100022004': 1.0, '1100022005': 0.33, '1100022008': 0.66, '1100022009': 1.0, '1100022014': 1.0, '1100022019': 1.0, '1100022020': 0.66, '1100022021': 0.66, '1100022022': 0.66, '1100022026': 1.0, '1100022027': 1.0, '1100022028': 1.0, '1100022029': 1.0, '1100022031': 1.0, '1100022035': 0.66, '1100022038': 1.0, '1100022039': 1.0, '1100022045': 1.0, '1100022046': 1.0, '1100022047': 1.0, '1100022048': 0.66, '1100022049': 0.66, '1100022051': 1.0, '1100022052': 0.66, '1100022053': 0.66, '1100022054': 0.66, '1100022055': 0.66, '1100022056': 1.0, '1100022057': 0.66, '1100041006': 1.0, '1100041015': 1.0, '1100041016': 1.0, '1100041017': 0.66, '1100041018': 0.66, '1100041021': 0.66, '1100041022': 0.66, '1100041023': 0.66, '1100041024': 0.66, '1100041029': 1.0, '1100041034': 0.66, '1100041044': 0.66, '1100041051': 1.0, '1100041052': 0.66, '1100042009': 0.66, '1100042010': 0.66, '1100042011': 0.66, '1100042017': 0.66, '1100042018': 0.66, '1100042019': 1.0, '1100042020': 1.0, '1100042023': 0.33, '1100042024': 0.66, '1100042025': 0.66, '1100042026': 0.33, '1100042029': 1.0, '1100042030': 0.66, '1100042031': 1.0, '1100042034': 0.66, '1100042040': 0.66, '1100042041': 1.0, '1100042058': 0.66, '1100042059': 0.66, '1100042060': 0.66, '1100051002': 0.66, '1100051004': 0.66, '1100051006': 0.66, '1100051007': 0.33, '1100051008': 0.66, '1100051009': 0.66, '1100051011': 0.66, '1100051012': 0.66, '1100051013': 0.66, '1100051014': 0.66, '1100051016': 0.33, '1100051017': 0.66, '1100051019': 1.0, '1100051020': 0.66, '1100051021': 0.66, '1100051022': 0.66, '1100051023': 0.66, '1100051024': 0.66, '1100051025': 0.66, '1100051026': 0.66, '1100051028': 0.66, '1100051029': 0.66, '1100051030': 0.33, '1100051031': 0.33, '1100051032': 1.0, '1100051033': 0.66, '1100051034': 0.66, '1100051035': 0.66, '1100051036': 0.66, '1100051037': 0.66, '1100051039': 0.66, '1100051041': 1.0, '1100051042': 0.66, '1100051044': 0.66, '1100051045': 1.0, '1100051046': 0.66, '1100051048': 0.66, '1100051049': 0.66, '1100051050': 1.0, '1100051051': 0.66, '1100051052': 0.66, '1100051053': 0.33, '1100051054': 0.66, '1100051055': 0.66, '1100051056': 0.66, '1100051057': 1.0, '1100051059': 1.0, '1100051061': 0.66, '1100051062': 1.0, '1100051064': 1.0, '1100051065': 0.66, '1100051066': 1.0, '1100051067': 1.0, '1100051068': 1.0, '1100051071': 1.0, '1100051076': 0.66, '1100051078': 0.66, '1100051079': 1.0, '1100052001': 0.66, '1100052002': 0.66, '1100052006': 0.66, '1100052007': 0.66, '1100052008': 1.0, '1100052009': 0.66, '1100052014': 0.33, '1100052023': 0.66, '1100052024': 0.66, '1100052026': 0.66, '1100052027': 0.66, '1100052028': 1.0, '1100052030': 0.66, '1100052031': 0.66, '1100052032': 0.66, '1100052033': 0.66, '1100052035': 0.66, '1100052036': 0.66, '1100052037': 0.66, '1100052038': 0.66, '1100052039': 0.66, '1100052040': 1.0, '1100052041': 0.66, '1100052047': 0.66, '1100052048': 0.66, '1100052049': 0.66, '1100052051': 0.66, '1100052055': 0.66, '1100052057': 0.66, '1100052060': 1.0, '1100052061': 0.66, '1100052062': 0.66, '1100052065': 1.0, '1100052068': 0.66, '1100052070': 0.66, '1100061009': 1.0, '1100061010': 1.0, '1100061011': 1.0, '1100061012': 0.66, '1100061013': 1.0, '1100061015': 0.66, '1100061016': 0.66, '1100061018': 0.66, '1100061019': 0.66, '1100061022': 1.0, '1100061023': 0.66, '1100061025': 0.66, '1100061027': 1.0, '1100061028': 0.66, '1100061030': 0.66, '1100061031': 0.66, '1100061032': 0.66, '1100061033': 1.0, '1100061034': 0.66, '1100061035': 0.66, '1100061036': 1.0, '1100061038': 1.0, '1100061039': 0.66, '1100061040': 1.0, '1100061042': 1.0, '1100061043': 1.0, '1100061044': 0.66, '1100061046': 1.0, '1100061047': 1.0, '1100061048': 1.0, '1100061049': 0.66, '1100061050': 0.66, '1100061051': 1.0, '1100061053': 0.66, '1100061057': 0.66, '1100061058': 0.66, '1100061061': 1.0, '1100061063': 1.0, '1100061064': 1.0, '1100061067': 1.0, '1100061068': 1.0, '1100061069': 1.0, '1100061073': 0.66, '1100061074': 0.66, '1100061077': 0.66, '1100061078': 0.66, '1100062004': 1.0, '1100062005': 1.0, '1100062007': 1.0, '1100062008': 0.33, '1100062009': 1.0, '1100062016': 0.66, '1100062017': 1.0, '1100062024': 0.66, '1100062028': 0.66, '1100062029': 0.66, '1100062036': 0.66, '1100062037': 0.66, '1100062044': 0.66, '1100062045': 0.33, '1100062046': 0.66, '1100062049': 0.33, '1100062051': 0.66, '1100062053': 1.0, '1100062054': 0.66, '1100062059': 0.66, '1100062060': 0.66, '1100062061': 0.66, '1100062062': 0.66, '1100062063': 0.66, '1100062064': 0.66, '1100062065': 0.66, '1100062066': 1.0, '1100062067': 1.0, '1100062068': 0.66, '1100062069': 0.66, '1100062070': 0.66, '1100062071': 1.0, '1100062072': 1.0, '1100071005': 0.66, '1100071006': 0.66, '1100071007': 0.66, '1100071008': 1.0, '1100071009': 0.66, '1100071010': 0.66, '1100071011': 0.66, '1100071012': 1.0, '1100071013': 0.66, '1100071014': 1.0, '1100071015': 0.66, '1100071016': 1.0, '1100071017': 0.66, '1100071018': 0.66, '1100071019': 0.66, '1100071020': 0.66, '1100071021': 1.0, '1100071022': 0.66, '1100071023': 0.66, '1100071024': 0.66, '1100071026': 0.66, '1100071027': 0.66, '1100071028': 0.66, '1100071029': 0.66, '1100071030': 1.0, '1100071031': 1.0, '1100071032': 0.66, '1100071033': 0.66, '1100071034': 1.0, '1100071035': 0.66, '1100071036': 0.66, '1100071037': 0.66, '1100071040': 1.0, '1100071041': 0.66, '1100071042': 0.66, '1100071043': 1.0, '1100071044': 0.66, '1100071045': 0.66, '1100071046': 0.66, '1100071047': 0.66, '1100071049': 0.66, '1100071050': 1.0, '1100071052': 0.66, '1100071054': 0.66, '1100071055': 1.0, '1100071056': 0.66, '1100071057': 1.0, '1100071058': 0.66, '1100071059': 0.66, '1100071060': 0.66, '1100071061': 1.0, '1100071062': 0.66, '1100071063': 1.0, '1100071064': 1.0, '1100071065': 0.66, '1100071066': 0.66, '1100071067': 1.0, '1100071069': 0.66, '1100071070': 1.0, '1100071071': 0.66, '1100071072': 0.66, '1100071073': 0.66, '1100071074': 0.66, '1100071075': 0.66, '1100071076': 0.66, '1100071077': 1.0, '1100071078': 1.0, '1100071079': 1.0, '1100071080': 1.0, '1100071081': 1.0, '1100072001': 0.66, '1100072002': 1.0, '1100072003': 1.0, '1100072004': 0.66, '1100072006': 0.66, '1100072007': 0.66, '1100072008': 0.66, '1100072009': 1.0, '1100072010': 0.66, '1100072011': 1.0, '1100072012': 1.0, '1100072013': 0.66, '1100072014': 0.66, '1100072015': 0.66, '1100072016': 0.66, '1100072021': 0.66, '1100072022': 0.66, '1100072023': 1.0, '1100072024': 0.66, '1100072027': 0.66, '1100072028': 0.66, '1100072029': 0.66, '1100072030': 0.66, '1100072031': 0.66, '1100072032': 1.0, '1100072033': 1.0, '1100072034': 0.66, '1100072036': 0.66, '1100072037': 0.66, '1100072038': 0.66, '1100072039': 0.66, '1100072040': 0.66, '1100072042': 0.66, '1100072043': 1.0, '1100072045': 0.66, '1100072047': 1.0, '1100072048': 0.66, '1100072049': 0.66, '1100072050': 0.66, '1100072051': 1.0, '1100072052': 1.0, '1100072053': 0.66, '1100072054': 0.66, '1100072056': 0.66, '1100072057': 0.66, '1100072058': 1.0, '1100072059': 0.66, '1100072060': 0.66, '1100072061': 0.66, '1100072062': 0.66, '1100072063': 1.0, '1100072065': 0.66, '1100072066': 1.0, '1100072067': 0.66, '1100072068': 0.66, '1100072069': 0.66, '1100072070': 0.66, '1100072071': 0.66, '1100072072': 0.66, '1100072073': 0.66, '1100072074': 1.0, '1100072075': 0.66, '1100072076': 0.66, '1100072077': 1.0, '1100072078': 1.0, '1100072079': 0.66, '1100072080': 0.66, '1100072081': 0.66, '1100072082': 1.0, '1100072083': 0.66, '1100072084': 0.66, '1100072085': 0.66, '1100081044': 0.66, '1100081045': 0.66, '1100081046': 0.66, '1100081047': 1.0, '1100081048': 1.0, '1100082002': 1.0, '1100082003': 1.0, '1100082018': 0.66, '1100082027': 0.66, '1100102003': 0.66, '1100111001': 1.0, '1100111002': 1.0, '1100111003': 0.66, '1100111008': 0.66, '1100111009': 0.66, '1100111010': 1.0, '1100111011': 0.66, '1100111012': 0.66, '1100111013': 0.66, '1100111014': 0.66, '1100111016': 0.66, '1100111017': 0.66, '1100111018': 0.66, '1100111019': 0.66, '1100111021': 0.66, '1100111023': 1.0, '1100111025': 1.0, '1100111026': 0.66, '1100111027': 1.0, '1100111029': 0.66, '1100111030': 1.0, '1100111032': 0.66, '1100112001': 0.66, '1100112002': 0.33, '1100112003': 1.0, '1100112004': 1.0, '1100112006': 0.33, '1100112007': 1.0, '1100112008': 1.0, '1100112009': 1.0, '1100112010': 0.66, '1100112011': 0.66, '1100112012': 1.0, '1100112013': 0.66, '1100112014': 0.66, '1100112015': 1.0, '1100112016': 1.0, '1100112017': 1.0, '1100112018': 1.0, '1100112021': 0.66, '1100112022': 0.66, '1100112024': 1.0, '1100112025': 0.66, '1100112026': 0.66, '1100112029': 1.0, '1100112030': 1.0, '1100112033': 1.0, '1100112035': 0.66, '1100112036': 1.0, '1100112037': 1.0, '1100112038': 0.66, '1100112039': 1.0, '1100112040': 0.66, '1100112041': 0.66, '1100112042': 1.0, '1100112043': 0.66, '1100112044': 0.66, '1100112045': 0.66, '1100112047': 1.0, '1100112048': 0.66, '1100112051': 1.0, '1100112052': 1.0, '1100112053': 1.0, '1100112056': 0.66, '1100112057': 1.0, '1100112058': 0.66, '1100112059': 1.0, '1100112060': 1.0, '1100112061': 0.66, '1100112062': 0.66, '1100112063': 0.66, '1100112064': 1.0, '1100112065': 0.66, '1100112066': 1.0, '1100112068': 1.0, '1100121002': 1.0, '1100121003': 0.66, '1100121004': 1.0, '1100121005': 1.0, '1100121006': 1.0, '1100121007': 1.0, '1100121008': 1.0, '1100121009': 1.0, '1100121010': 1.0, '1100121011': 1.0, '1100121012': 1.0, '1100121015': 0.66, '1100121016': 1.0, '1100121017': 1.0, '1100121018': 0.66, '1100121019': 0.66, '1100121020': 1.0, '1100121024': 0.66, '1100121025': 0.66, '1100121028': 1.0, '1100121031': 0.66, '1100121032': 1.0, '1100121033': 0.66, '1100121034': 0.66, '1100121035': 1.0, '1100121036': 0.66, '1100121038': 1.0, '1100121040': 1.0, '1100121041': 0.66, '1100121042': 0.66, '1100121044': 1.0, '1100121045': 1.0, '1100121047': 1.0, '1100121049': 0.66, '1100121050': 1.0, '1100121052': 0.66, '1100121053': 1.0, '1100121054': 1.0, '1100121056': 0.66, '1100121057': 1.0, '1100121059': 0.66, '1100121060': 0.66, '1100121061': 0.66, '1100121064': 1.0, '1100122001': 0.66, '1100122002': 0.66, '1100122003': 0.66, '1100122005': 0.66, '1100122006': 1.0, '1100122007': 1.0, '1100122008': 1.0, '1100122009': 0.66, '1100122010': 1.0, '1100122011': 1.0, '1100122012': 1.0, '1100122013': 1.0, '1100122014': 1.0, '1100122015': 0.66, '1100122017': 0.66, '1100122018': 1.0, '1100122019': 1.0, '1100122020': 1.0, '1100122021': 0.66, '1100122023': 0.66, '1100122024': 1.0, '1100122025': 0.66, '1100122026': 0.66, '1100122031': 1.0, '1100122032': 1.0, '1100122033': 0.66, '1100122034': 1.0, '1100122035': 0.66, '1100122036': 1.0, '1100122037': 1.0, '1100122038': 1.0, '1100122039': 1.0, '1100122040': 0.66, '1100122041': 0.66, '1100122045': 0.66, '1100122047': 0.66, '1100122048': 1.0, '1100122050': 1.0, '1100122051': 0.66, '1100122052': 1.0, '1100122053': 0.66, '1100122054': 0.66, '1100122056': 0.33, '1100131006': 1.0, '1100131007': 0.66, '1100131009': 1.0, '1100131010': 1.0, '1100131011': 1.0, '1100131012': 1.0, '1100131017': 0.0, '1100131019': 1.0, '1100141001': 1.0, '1100141002': 0.66, '1100141003': 1.0, '1100141004': 1.0, '1100141005': 0.66, '1100141006': 0.66, '1100141007': 1.0, '1100141008': 0.66, '1100141009': 0.66, '1100141010': 1.0, '1100141011': 0.66, '1100141012': 0.66, '1100141013': 0.33, '1100141014': 0.66, '1100141015': 0.66, '1100141016': 1.0, '1100141017': 0.66, '1100141019': 0.66, '1100141020': 0.66, '1100141021': 0.66, '1100141023': 1.0, '1100141027': 0.33, '1100141028': 0.66, '1100141029': 0.66, '1100141030': 0.66, '1100141031': 0.66, '1100141032': 0.66, '1100141033': 0.66, '1100141034': 0.66, '1100141035': 0.66, '1100141036': 0.66, '1100141039': 1.0, '1100141040': 0.66, '1100141042': 0.66, '1100141044': 0.66, '1100141045': 1.0, '1100141046': 0.66, '1100141049': 0.66, '1100141050': 0.66, '1100141052': 0.66, '1100141053': 0.66, '1100141054': 1.0, '1100141055': 1.0, '1100141056': 0.66, '1100141057': 0.66, '1100142002': 1.0, '1100142003': 0.66, '1100142004': 0.66, '1100142007': 0.66, '1100142008': 0.66, '1100142009': 0.66, '1100142010': 0.66, '1100142011': 1.0, '1100142013': 0.66, '1100142014': 0.66, '1100142015': 0.66, '1100142017': 0.66, '1100142018': 0.66, '1100142019': 0.66, '1100142021': 1.0, '1100142022': 0.66, '1100142023': 0.66, '1100142024': 0.66, '1100142027': 1.0, '1100142028': 0.66, '1100142029': 1.0, '1100142030': 0.66, '1100142031': 0.66, '1100142032': 1.0, '1100142033': 0.33, '1100142034': 1.0, '1100142035': 1.0, '1100142038': 0.66, '1100142041': 1.0, '1100142043': 0.66, '1100142044': 0.66, '1100142045': 0.66, '1100142046': 1.0, '1100142048': 1.0, '1100142049': 0.66, '1100142050': 0.66, '1100142051': 0.66, '1100142052': 0.66, '1100142053': 1.0, '1100142056': 1.0, '1100142057': 1.0, '1100142058': 0.66, '1100142059': 0.66, '1100142060': 0.66, '1100151003': 0.66, '1100151004': 1.0, '1100151008': 1.0, '1100151009': 0.66, '1100151010': 0.66, '1100151011': 0.33, '1100151012': 0.66, '1100151013': 0.66, '1100151014': 1.0, '1100151015': 0.66, '1100151016': 0.66, '1100151017': 0.66, '1100151018': 0.66, '1100151019': 0.66, '1100151020': 0.66, '1100151021': 1.0, '1100151022': 1.0, '1100151023': 0.66, '1100151024': 0.66, '1100151028': 0.66, '1100151030': 0.66, '1100151032': 1.0, '1100151033': 0.66, '1100151035': 1.0, '1100151037': 1.0, '1100151038': 0.66, '1100151039': 0.66, '1100151040': 1.0, '1100151042': 1.0, '1100151043': 0.66, '1100151044': 0.66, '1100151047': 0.66, '1100151049': 1.0, '1100151050': 0.66, '1100151051': 0.66, '1100151052': 1.0, '1100151054': 1.0, '1100151055': 0.66, '1100151056': 1.0, '1100151057': 0.33, '1100151058': 0.66, '1100151062': 0.66, '1100152001': 0.66, '1100152004': 1.0, '1100152005': 0.66, '1100152006': 0.66, '1100152008': 0.66, '1100152009': 0.66, '1100152010': 0.33, '1100152013': 1.0, '1100152014': 0.66, '1100152015': 0.66, '1100152017': 0.33, '1100152019': 1.0, '1100152020': 1.0, '1100152022': 0.66, '1100152024': 0.66, '1100152025': 0.66, '1100152026': 0.66, '1100152027': 1.0, '1100152031': 0.33, '1100152032': 0.66, '1100152039': 1.0, '1100152040': 0.66, '1100152041': 0.66, '1100152042': 0.66, '1100152043': 0.66, '1100152048': 0.66, '1100152049': 0.66, '1100152050': 0.66, '1100152051': 0.66, '1100152055': 0.33, '1100152056': 0.66, '1100152061': 0.66, '1100152062': 0.66, '1100152067': 0.66, '1100152069': 0.66, '1100152070': 0.0, '1100161002': 0.66, '1100161004': 1.0, '1100161011': 1.0, '1100161012': 1.0, '1100161013': 0.66, '1100161014': 0.66, '1100161015': 1.0, '1100161016': 0.66, '1100161020': 1.0, '1100161021': 1.0, '1100161022': 0.66, '1100161023': 0.66, '1100161028': 0.66, '1100161029': 0.66, '1100161032': 0.66, '1100161035': 0.66, '1100161036': 0.66, '1100161038': 0.66, '1100161039': 1.0, '1100161041': 1.0, '1100161043': 1.0, '1100161044': 0.66, '1100161045': 0.66, '1100161046': 0.66, '1100161048': 0.66, '1100161050': 1.0, '1100161053': 0.33, '1100162005': 0.33, '1100162007': 0.66, '1100162011': 0.66, '1100162016': 0.33, '1100171001': 0.66, '1100171002': 0.66, '1100171004': 0.0, '1100171005': 0.66, '1100171007': 0.66, '1100171008': 0.0, '1100171009': 0.66, '1100171010': 0.66, '1100171011': 1.0, '1100171012': 0.66, '1100171013': 0.66, '1100171015': 0.66, '1100171016': 0.66, '1100171017': 0.66, '1100171019': 0.66, '1100171021': 1.0, '1100171022': 0.66, '1100171023': 0.66, '1100171031': 0.66, '1100171035': 0.66, '1100171036': 0.66, '1100171038': 1.0, '1100171039': 1.0, '1100171040': 1.0, '1100171041': 0.66, '1100171043': 0.66, '1100171045': 0.66, '1100171049': 0.66, '1100171055': 0.66, '1100171056': 1.0, '1100171057': 0.66, '1100171059': 0.33, '1100171061': 1.0, '1100171063': 1.0, '1100171064': 1.0, '1100171065': 0.66, '1100171067': 0.66, '1100171069': 1.0, '1100171070': 0.66, '1100171071': 1.0, '1100171072': 0.66, '1100171073': 1.0, '1100171074': 0.66, '1100171075': 0.66, '1100171076': 0.66, '1100171077': 1.0, '1100171078': 1.0, '1100171080': 0.66, '1100171083': 0.66, '1100172003': 0.66, '1100172004': 0.66, '1100172007': 0.66, '1100172012': 0.33, '1100172013': 0.66, '1100172014': 0.66, '1100172015': 0.66, '1100172016': 0.66, '1100172017': 0.33, '1100172018': 1.0, '1100172020': 0.66, '1100172021': 0.66, '1100172022': 0.66, '1100172026': 0.66, '1100172028': 0.66, '1100172030': 1.0, '1100172032': 0.66, '1100172033': 0.33, '1100172034': 0.33, '1100172035': 1.0, '1100172037': 0.66, '1100172039': 0.66, '1100172042': 0.66, '1100172043': 0.33, '1100172047': 1.0, '1100172050': 0.66, '1100172058': 0.33, '1100172063': 1.0, '1100172066': 0.66, '1100411010': 0.66, '1100411011': 1.0, '1100411012': 0.66, '1100411013': 1.0, '1100411015': 1.0, '1100411016': 1.0, '1100411018': 0.66, '1100411020': 0.66, '1100411023': 1.0, '1100411036': 0.66, '1100411041': 1.0, '1100411045': 1.0, '1100411047': 0.66, '1100411048': 0.66, '1100411049': 0.66, '1100411050': 1.0, '1100411051': 1.0, '1100411053': 1.0, '1100411054': 0.66, '1100411055': 0.66, '1100411057': 0.66, '1100412001': 1.0, '1100412003': 0.66, '1100412010': 0.66, '1100412018': 0.0, '1100412033': 0.33, '1100412038': 0.66, '1100412039': 0.33, '1100412040': 0.66, '1110031003': 0.66, '1110031007': 1.0, '1110031010': 0.33, '1110031011': 0.66, '1110031012': 1.0, '1110031014': 0.66, '1110031019': 0.66, '1110031020': 0.66, '1110031021': 0.66, '1110031025': 0.0, '1110031027': 0.33, '1110031031': 1.0, '1110031033': 0.33, '1110031037': 1.0, '1110031038': 0.0, '1110031039': 0.66, '1110031040': 1.0, '1110031042': 0.66, '1110031048': 0.66, '1110031049': 0.66, '1110031050': 1.0, '1110031056': 0.33, '1110031061': 0.66, '1110031062': 0.66, '1110031063': 0.0, '1110031064': 0.66, '1110031065': 1.0, '1110032002': 1.0, '1110032004': 0.66, '1110032006': 1.0, '1110032008': 0.66, '1110032010': 0.66, '1110032014': 0.33, '1110032015': 1.0, '1110032018': 1.0, '1110032019': 0.66, '1110032020': 0.66, '1110032021': 0.66, '1110032022': 0.66, '1110032023': 0.66, '1110032024': 1.0, '1110032025': 0.66, '1110032027': 0.33, '1110032029': 1.0, '1110032031': 0.66, '1110032032': 1.0, '1110032033': 1.0, '1110032034': 0.66, '1110032036': 1.0, '1110032037': 0.66, '1110032042': 0.66, '1110032043': 0.33, '1110032045': 0.66, '1110032047': 0.66, '1110032048': 0.66, '1110032049': 0.66, '1110032050': 1.0, '1110032051': 0.66, '1110032052': 1.0, '1110032053': 0.66, '1110032055': 0.66, '1110032056': 0.66, '1110032058': 1.0, '1110032059': 0.66, '1110032060': 1.0, '1110032061': 0.66, '1110032062': 0.66, '1110032063': 0.66, '1813740111': 1.0, '1813740112': 0.66, '1813740115': 1.0, '1813740116': 1.0, '1813740118': 0.66, '1813740119': 0.66, '1813740122': 0.66, '1813740123': 1.0, '1813740124': 0.66, '1813740126': 1.0, '1813740127': 1.0, '1813740128': 1.0, '1813740131': 0.66, '1813740133': 1.0, '1813740135': 0.66, '1813740137': 0.66, '1813740138': 0.0, '1813740143': 0.66, '1813740144': 0.66, '1813740149': 1.0, '181374015': 0.66, '1813740150': 0.66, '1813740153': 0.66, '1813740155': 0.66, '1813740157': 0.66, '1813740159': 0.66, '181374016': 1.0, '1813740162': 1.0, '1813740164': 1.0, '1813740165': 1.0, '1813740167': 1.0, '1813740168': 1.0, '1813740169': 0.66, '181374017': 0.66, '1813740171': 0.66, '1813740172': 1.0, '1813740173': 0.66, '1813740174': 1.0, '1813740176': 0.66, '1813740178': 0.66, '1813740179': 0.66, '1813740180': 0.66, '1813740181': 1.0, '1813740182': 1.0, '1813740183': 0.66, '1813740184': 0.33, '1813740185': 0.33, '181374019': 1.0, '1813740210': 1.0, '1813740211': 1.0, '1813740212': 0.66, '1813740213': 0.66, '1813740214': 1.0, '1813740218': 1.0, '1813740219': 1.0, '1813740220': 1.0, '1813740221': 1.0, '1813740224': 0.66, '1813740225': 0.66, '1813740226': 1.0, '1813740227': 0.66, '1813740229': 0.66, '181374023': 0.66, '1813740231': 1.0, '1813740232': 0.66, '1813740233': 0.66, '1813740234': 1.0, '1813740235': 0.66, '1813740236': 1.0, '1813740237': 1.0, '1813740238': 1.0, '181374024': 1.0, '1813740240': 1.0, '1813740241': 1.0, '1813740242': 1.0, '1813740243': 1.0, '1813740245': 1.0, '1813740249': 1.0, '181374025': 1.0, '1813740250': 0.66, '1813740251': 1.0, '1813740252': 1.0, '1813740253': 0.66, '1813740255': 1.0, '1813740256': 1.0, '1813740257': 1.0, '1813740258': 1.0, '1813740259': 1.0, '181374026': 0.66, '1813740260': 0.66, '1813740261': 1.0, '1813740262': 1.0, '1813740263': 1.0, '1813740264': 1.0, '1813740265': 1.0, '1813740266': 1.0, '1813740267': 0.66, '1813740268': 1.0, '1813740269': 0.66, '181374027': 0.66, '1813740270': 1.0, '1813740271': 0.66, '1813740272': 1.0, '1813740273': 1.0, '1813740274': 1.0, '1813740275': 0.66, '1813740276': 1.0, '1813740277': 1.0, '1813740278': 0.66, '1813740279': 1.0, '181374028': 1.0, '181374029': 1.0, '2000481035': 0.66, '2000481036': 1.0, '2000481037': 1.0, '2000481038': 1.0, '2000481039': 0.66, '2000481040': 0.66, '2000481041': 0.66, '2000481043': 0.66, '2000481048': 0.66, '2000482008': 0.66, '2000482009': 1.0, '2000482012': 0.66, '2000482018': 0.66, '2000482021': 0.66, '2000482034': 0.66, '2000482037': 0.66, '2000482038': 0.66, '2000482039': 1.0, '2000482041': 1.0, '2000482042': 0.66, '2000482043': 1.0, '2000482044': 0.66, '2000482049': 0.66, '2000482050': 0.66, '2000482052': 0.66, '2000482059': 1.0, '2000482065': 0.66, '2000482066': 1.0, '2000482067': 1.0, '2000482068': 1.0, '2000482070': 0.66, '2000491062': 0.66, '2000491064': 0.66, '2000491065': 0.66, '2000491066': 1.0, '2000491067': 0.66, '2000491068': 0.66, '2000491070': 0.66, '2000491072': 1.0, '2000491074': 0.66, '2000491075': 0.66, '2000491076': 0.66, '2000491077': 0.33, '2000491078': 0.66, '2000491079': 1.0, '2000501001': 1.0, '2000501002': 0.66, '2000501003': 0.66, '2000501004': 1.0, '2000501006': 0.33, '2000501009': 1.0, '2000501010': 1.0, '2000501011': 1.0, '2000501012': 0.66, '2000501014': 0.66, '2000501015': 1.0, '2000501016': 1.0, '2000501018': 0.66, '2000501019': 1.0, '2000501020': 1.0, '2000501021': 1.0, '2000501023': 1.0, '2000501027': 0.66, '2000501028': 0.66, '2000501030': 0.33, '2000501031': 0.66, '2000501032': 1.0, '2000501033': 1.0, '2000501035': 0.66, '2000501036': 1.0, '2000501037': 1.0, '2000501038': 1.0, '2000501039': 1.0, '2000501040': 1.0, '2000501041': 1.0, '2000501042': 0.66, '2000501043': 0.66, '2000501044': 1.0, '2000501045': 0.66, '2000501046': 0.66, '2000501049': 1.0, '2000501050': 0.66, '2000501051': 0.66, '2000501052': 1.0, '2000501053': 0.66, '2000501054': 1.0, '2000501056': 0.66, '2000501057': 0.66, '2000501060': 1.0, '2000501061': 0.66, '2000501062': 0.66, '2000501063': 1.0, '2000501065': 1.0, '2000501066': 1.0, '2000501067': 0.66, '2000501071': 1.0, '2000501074': 0.66, '2000501075': 1.0, '2000501076': 1.0, '2000501078': 1.0, '2000502002': 0.66, '2000502005': 0.66, '2000502006': 0.66, '2000502007': 0.66, '2000502009': 0.66, '2000502010': 1.0, '2000502012': 0.66, '2000502013': 1.0, '2000502014': 1.0, '2000502015': 0.66, '2000502019': 0.66, '2000502020': 0.66, '2000502023': 0.66, '2000502025': 1.0, '2000502033': 0.66, '2000502036': 0.66, '2000502037': 0.66, '2000502039': 0.66, '2000502040': 1.0, '2000502041': 0.66, '2000502043': 0.66, '2000502044': 1.0, '2000502045': 1.0, '2000502047': 1.0, '2000502048': 1.0, '2000502049': 0.66, '2000502050': 0.66, '2000502051': 0.66, '2000502053': 0.33, '2000502054': 1.0, '2000502055': 1.0, '2000502056': 0.66, '2000502057': 1.0, '2000502058': 0.66, '2000502059': 0.66, '2000502061': 0.66, '2000502062': 0.66, '2000502063': 0.66, '2000502065': 0.33, '2000502066': 0.66, '2000502067': 0.66, '2000502069': 0.66, '2000502070': 0.66, '2000502072': 0.66, '2000502073': 0.66, '2000502075': 0.66, '2000502076': 0.66, '2000502077': 0.66, '2000502078': 0.66, '2000502081': 0.33, '2000502084': 0.66, '2000502087': 0.66, '2000502088': 0.66, '2000502090': 0.66, '2000541001': 0.66, '2000541002': 0.66, '2000541003': 0.66, '2000541006': 0.66, '2000541007': 1.0, '2000541010': 1.0, '2000541011': 0.66, '2000541014': 1.0, '2000541015': 0.66, '2000541016': 0.66, '2000541018': 0.66, '2000541019': 1.0, '2000541020': 1.0, '2000541021': 1.0, '2000541022': 1.0, '2000541023': 0.66, '2000541024': 1.0, '2000541025': 1.0, '2000541027': 0.66, '2000541028': 1.0, '2000541029': 0.66, '2000541030': 1.0, '2000541031': 1.0, '2000541032': 1.0, '2000541034': 0.66, '2000541035': 0.66, '2000541038': 0.66, '2000541039': 0.66, '2000541040': 0.66, '2000541041': 0.66, '2000541043': 1.0, '2000541044': 1.0, '2000541045': 0.66, '2000541046': 0.66, '2000541049': 0.66, '2000541050': 1.0, '2000541051': 0.66, '2000541052': 0.66, '2000541053': 0.66, '2000541054': 0.66, '2000541055': 1.0, '2000541056': 1.0, '2000541057': 0.66, '2000541059': 1.0, '2000541062': 1.0, '2000541064': 0.66, '2000541066': 0.66, '2000541067': 0.66, '2000541068': 0.66, '2000541069': 0.66, '2000541070': 0.66, '2000541071': 0.66, '2000541072': 1.0, '2000541073': 1.0, '2000541074': 1.0, '2000541075': 0.66, '2000541076': 1.0, '2000541077': 0.66, '2000541079': 0.66, '2000541080': 1.0, '2000541081': 1.0, '2000542001': 0.66, '2000542002': 0.66, '2000542007': 0.66, '2000542008': 0.66, '2000542009': 0.66, '2000542010': 0.66, '2000542013': 1.0, '2000542015': 1.0, '2000542016': 0.66, '2000542021': 0.66, '2000542022': 0.66, '2000542025': 1.0, '2000542026': 1.0, '2000542027': 1.0, '2000542029': 1.0, '2000542030': 1.0, '2000542032': 0.66, '2000542033': 1.0, '2000542034': 0.66, '2000542035': 1.0, '2000542036': 0.66, '2000542042': 1.0, '2000542049': 0.66, '2000542050': 1.0, '2000542051': 0.66, '2000542052': 1.0, '2000542054': 0.66, '2000542056': 0.66, '2026140111': 1.0, '2026140113': 1.0, '2026140116': 1.0, '2026140117': 1.0, '2026140118': 0.66, '2026140119': 1.0, '2026140120': 1.0, '2026140122': 1.0, '2026140124': 0.66, '2026140125': 1.0, '2026140126': 0.66, '2026140128': 0.66, '2026140129': 1.0, '2026140130': 1.0, '2026140131': 1.0, '2026140133': 1.0, '2026140134': 1.0, '2026140135': 0.66, '2026140138': 1.0, '2026140141': 1.0, '2026140145': 0.66, '2026140147': 1.0, '2026140149': 0.66, '202614015': 1.0, '2026140151': 1.0, '2026140154': 0.66, '2026140158': 1.0, '2026140159': 1.0, '202614016': 1.0, '2026140160': 0.66, '2026140161': 1.0, '2026140165': 1.0, '2026140169': 1.0, '202614017': 1.0, '2026140170': 0.66, '2026140172': 0.66, '202614018': 1.0, '202614019': 0.66, '202614020': 1.0, '202614021': 1.0, '2026140210': 0.66, '2026140212': 1.0, '2026140213': 0.66, '2026140220': 0.66, '2026140221': 1.0, '2026140223': 1.0, '2026140224': 1.0, '2026140225': 0.66, '202614023': 1.0, '2026140230': 0.66, '2026140233': 0.66, '2026140236': 1.0, '2026140237': 0.66, '2026140239': 0.66, '2026140241': 1.0, '2026140243': 1.0, '2026140246': 1.0, '2026140247': 1.0, '2026140249': 1.0, '202614025': 1.0, '2026140250': 1.0, '2026140253': 0.66, '2026140254': 0.66, '2026140255': 0.66, '2026140257': 0.33, '2026140259': 1.0, '2026140260': 1.0, '2026140263': 0.66, '2026140264': 0.33, '2026140272': 1.0, '2026140273': 0.33, '2026140275': 1.0, '2026140276': 1.0, '2026140277': 1.0, '2026140279': 1.0, '2026140281': 1.0, '202614029': 0.66, '205601011': 1.0, '2056010112': 0.66, '2056010113': 0.66, '2056010114': 0.66, '2056010116': 0.66, '2056010118': 0.66, '2056010119': 0.66, '205601012': 0.66, '2056010120': 1.0, '2056010122': 1.0, '2056010123': 1.0, '2056010124': 1.0, '2056010126': 0.66, '2056010130': 0.66, '2056010133': 1.0, '2056010134': 0.0, '2056010136': 0.66, '2056010137': 0.66, '2056010139': 1.0, '2056010141': 1.0, '2056010142': 0.66, '2056010148': 0.66, '2056010149': 0.66, '2056010153': 1.0, '2056010155': 1.0, '2056010156': 0.66, '2056010157': 0.66, '205601016': 1.0, '2056010160': 1.0, '2056010162': 0.66, '2056010164': 0.66, '2056010165': 0.66, '2056010167': 1.0, '205601017': 1.0, '205601018': 0.66, '2056010210': 0.66, '2056010212': 1.0, '2056010213': 0.66, '2056010214': 1.0, '2056010215': 0.66, '2056010218': 1.0, '2056010219': 0.66, '2056010222': 0.66, '2056010224': 0.33, '2056010225': 1.0, '2056010226': 1.0, '2056010228': 1.0, '2056010229': 1.0, '2056010230': 1.0, '2056010232': 1.0, '2056010233': 1.0, '2056010234': 0.66, '2056010235': 1.0, '2056010236': 0.66, '2056010238': 1.0, '2056010239': 1.0, '205601024': 0.66, '2056010240': 0.66, '2056010241': 0.66, '2056010242': 0.66, '2056010244': 0.66, '2056010245': 0.66, '2056010247': 1.0, '2056010249': 1.0, '205601025': 1.0, '2056010250': 0.66, '2056010252': 0.66, '2056010253': 1.0, '2056010254': 1.0, '2056010255': 1.0, '2056010258': 0.66, '2056010260': 1.0, '2056010261': 0.66, '2056010262': 1.0, '2056010263': 1.0, '2056010265': 1.0, '2056010267': 0.66, '2056010269': 1.0, '205601027': 1.0, '2056010272': 0.66, '2056010274': 0.66, '2056010275': 1.0, '2056010276': 1.0, '2056010277': 1.0, '2056010279': 0.66, '205601028': 0.66, '2056010281': 1.0, '2056010283': 0.66, '2100511002': 1.0, '2100511003': 1.0, '2100511005': 0.66, '2100511008': 1.0, '2100511011': 0.66, '2100511012': 1.0, '2100511013': 0.66, '2100511015': 0.66, '2100511016': 1.0, '2100511018': 1.0, '2100511019': 0.66, '2100511024': 0.66, '2100511026': 0.66, '2100511027': 0.66, '2100511028': 1.0, '2100511031': 1.0, '2100511032': 0.66, '2100511034': 0.66, '2100511035': 0.66, '2100511036': 0.66, '2100511038': 1.0, '2100511039': 0.66, '2100511040': 1.0, '2100511044': 0.66, '2100511048': 0.66, '2100511057': 1.0, '2100511058': 1.0, '2100511059': 0.66, '2100511060': 1.0, '2100511061': 0.66, '2100511062': 1.0, '2100511063': 1.0, '2100511064': 0.66, '2100511065': 1.0, '2100511067': 1.0, '2100511069': 0.33, '2100511070': 0.66, '2100511071': 1.0, '2100511072': 1.0, '2100511073': 1.0, '2100511074': 1.0, '2100511076': 0.66, '2100511077': 1.0, '2100511078': 1.0, '2100511079': 1.0, '2100511080': 1.0, '2100511081': 0.66, '2100511082': 1.0, '2100512001': 1.0, '2100512002': 0.66, '2100512003': 0.66, '2100512006': 0.66, '2100512007': 1.0, '2100512009': 1.0, '2100512010': 1.0, '2100512011': 0.66, '2100512012': 1.0, '2100512014': 1.0, '2100512015': 0.66, '2100512016': 1.0, '2100512017': 1.0, '2100512018': 0.66, '2100512020': 1.0, '2100512021': 1.0, '2100512025': 1.0, '2100512026': 0.66, '2100512028': 0.66, '2100512029': 1.0, '2100512032': 1.0, '2100512034': 1.0, '2100512035': 0.66, '2100512036': 0.66, '2100512037': 0.66, '2100512038': 1.0, '2100512039': 0.66, '2100512041': 0.66, '2100512042': 1.0, '2100512044': 0.66, '2100512045': 0.66, '2100512051': 0.33, '2100512052': 1.0, '2100512053': 1.0, '2100512055': 0.66, '2100512057': 1.0, '2100512058': 1.0, '2100512061': 1.0, '2100512062': 1.0, '2100512063': 1.0, '2100512064': 0.33, '2100512065': 0.66, '2100521002': 1.0, '2100521005': 1.0, '2100521006': 1.0, '2100521008': 1.0, '2100521009': 0.66, '2100521010': 0.66, '2100521013': 0.66, '2100521014': 0.66, '2100521015': 1.0, '2100521016': 1.0, '2100521017': 0.66, '2100521018': 0.66, '2100521021': 1.0, '2100521022': 0.66, '2100521023': 0.66, '2100521024': 0.66, '2100521025': 0.66, '2100521026': 0.66, '2100521027': 0.66, '2100521028': 0.66, '2100521029': 1.0, '2100521030': 0.66, '2100521031': 0.66, '2100521032': 0.33, '2100521033': 1.0, '2100521034': 0.66, '2100521035': 0.66, '2100521037': 1.0, '2100521038': 0.66, '2100521039': 0.66, '2100521040': 1.0, '2100521041': 0.66, '2100521042': 0.66, '2100521043': 0.66, '2100521044': 1.0, '2100521046': 0.66, '2100521047': 0.66, '2100521048': 0.66, '2100521049': 0.66, '2100521050': 0.66, '2100521051': 0.66, '2100521052': 0.66, '2100521054': 0.66, '2100521055': 0.66, '2100521056': 0.66, '2100521057': 0.66, '2100521059': 1.0, '2100521060': 0.66, '2100521061': 0.66, '2100521062': 0.66, '2100521063': 0.66, '2100521067': 0.66, '2100521069': 0.66, '2100521070': 0.66, '2100521072': 1.0, '2100521073': 0.66, '2100521074': 1.0, '2100521075': 0.66, '2100521076': 1.0, '2100521077': 0.66, '2100521078': 1.0, '2100521079': 0.66, '2100522001': 0.66, '2100522004': 1.0, '2100522005': 0.66, '2100522006': 0.66, '2100522007': 1.0, '2100522008': 0.66, '2100522009': 1.0, '2100522010': 0.66, '2100522011': 0.66, '2100522012': 0.66, '2100522013': 0.66, '2100522018': 0.66, '2100522019': 1.0, '2100522020': 0.66, '2100522021': 0.66, '2100522023': 1.0, '2100522024': 1.0, '2100522026': 1.0, '2100522028': 0.66, '2100522031': 1.0, '2100522033': 0.66, '2100522034': 0.66, '2100522035': 0.66, '2100522036': 0.66, '2100522038': 0.66, '2100522039': 0.66, '2100522040': 0.66, '2100522041': 0.66, '2100522042': 0.66, '2100522046': 0.66, '2100522047': 0.66, '2100522048': 0.66, '2100522049': 1.0, '2100522050': 0.66, '2100522051': 0.66, '2100522052': 0.66, '2100522053': 0.66, '2100522054': 1.0, '2100522055': 1.0, '2100522056': 0.66, '2100522059': 0.66, '2100522060': 0.66, '2100522061': 0.66, '2100522062': 0.66, '2100522063': 1.0, '2100522064': 0.66, '2100522067': 0.66, '2100522068': 0.66, '2100522070': 0.66, '2100531001': 1.0, '2100531002': 0.66, '2100531003': 1.0, '2100531004': 1.0, '2100531006': 1.0, '2100531007': 0.66, '2100531008': 0.66, '2100531009': 1.0, '2100531010': 1.0, '2100531012': 1.0, '2100531013': 0.66, '2100531014': 1.0, '2100531015': 1.0, '2100531016': 0.66, '2100531017': 0.66, '2100531018': 1.0, '2100531019': 1.0, '2100531021': 1.0, '2100531022': 0.66, '2100531023': 1.0, '2100531024': 1.0, '2100531025': 0.66, '2100531026': 0.66, '2100531027': 1.0, '2100531028': 1.0, '2100531030': 0.66, '2100531031': 0.66, '2100531033': 0.66, '2100531034': 1.0, '2100531035': 1.0, '2100531036': 0.66, '2100531037': 0.66, '2100531040': 1.0, '2100531041': 0.66, '2100531042': 1.0, '2100531043': 1.0, '2100531044': 1.0, '2100531045': 1.0, '2100531047': 1.0, '2100531048': 0.66, '2100531049': 1.0, '2100531050': 0.66, '2100531051': 1.0, '2100531052': 1.0, '2100531053': 0.66, '2100531054': 0.33, '2100531055': 1.0, '2100531056': 0.66, '2100531057': 1.0, '2100531058': 1.0, '2100531059': 0.66, '2100531060': 1.0, '2100531061': 0.66, '2100531063': 1.0, '2100531064': 0.66, '2100531065': 0.66, '2100531066': 1.0, '2100531067': 1.0, '2100531068': 1.0, '2100531070': 0.66, '2100531071': 0.66, '2100531072': 0.66, '2100531073': 0.66, '2100531074': 1.0, '2100531076': 1.0, '2100531077': 1.0, '2100531078': 1.0, '2100531079': 1.0, '2100531080': 1.0, '2100531081': 0.66, '2100531082': 1.0, '2100531084': 1.0, '2100532002': 0.66, '2100532003': 0.66, '2100532004': 0.66, '2100532005': 1.0, '2100532007': 0.66, '2100532008': 0.66, '2100532010': 0.66, '2100532012': 0.66, '2100532013': 0.66, '2100532015': 0.66, '2100532016': 0.33, '2100532017': 1.0, '2100532019': 0.66, '2100532020': 0.66, '2100532022': 0.0, '2100532023': 0.66, '2100532024': 1.0, '2100532025': 1.0, '2100532026': 1.0, '2100532027': 1.0, '2100532028': 1.0, '2100532029': 0.66, '2100532030': 0.66, '2100532031': 0.66, '2100532032': 1.0, '2100532033': 0.66, '2100532034': 0.66, '2100532037': 1.0, '2100532042': 0.66, '2100532043': 1.0, '2100532044': 0.66, '2100532045': 0.66, '2100532046': 1.0, '2100532047': 0.66, '2100532048': 1.0, '2100532050': 1.0, '2100532052': 0.66, '2100532053': 1.0, '2100532054': 1.0, '2100532055': 1.0, '2100532056': 0.66, '2100532057': 0.66, '2100532058': 1.0, '2100532059': 1.0, '2100532060': 1.0, '2100532061': 1.0, '2100532062': 0.66, '2100532063': 1.0, '2100532064': 1.0, '2100532066': 1.0, '2100532067': 0.66, '2100532068': 1.0, '2100532070': 1.0, '2100532071': 1.0, '2100532072': 0.66, '2100551002': 0.66, '2100551005': 0.0, '2100551006': 0.66, '2100551007': 1.0, '2100551010': 0.33, '2100551011': 0.66, '2100551013': 1.0, '2100551014': 0.66, '2100551015': 0.66, '2100551016': 0.66, '2100551017': 1.0, '2100551018': 1.0, '2100551019': 1.0, '2100551020': 0.66, '2100551021': 1.0, '2100551022': 0.66, '2100551023': 0.66, '2100551024': 1.0, '2100551025': 0.66, '2100551027': 0.66, '2100551028': 1.0, '2100551029': 0.66, '2100551032': 0.33, '2100551033': 0.66, '2100551034': 0.66, '2100551035': 0.33, '2100551036': 0.66, '2100551037': 0.66, '2100551039': 0.66, '2100551041': 0.66, '2100551042': 0.33, '2100551043': 0.66, '2100551044': 0.66, '2100551045': 0.66, '2100551046': 0.66, '2100551049': 1.0, '2100551050': 1.0, '2100551051': 0.66, '2100551052': 0.66, '2100551053': 1.0, '2100551054': 0.66, '2100551055': 0.66, '2100551056': 1.0, '2100551057': 1.0, '2100551059': 0.66, '2100551060': 1.0, '2100551061': 0.66, '2100551062': 0.66, '2100551063': 0.66, '2100551064': 0.66, '2100551065': 0.66, '2100551066': 1.0, '2100551067': 0.66, '2100551068': 1.0, '2100551069': 1.0, '2100551071': 1.0, '2100551072': 0.66, '2100551073': 0.66, '2100551074': 0.66, '2100551075': 0.66, '2100551076': 1.0, '2100551077': 0.66, '2100551079': 0.66, '2100551080': 1.0, '2100551081': 0.66, '2100552002': 1.0, '2100552003': 0.66, '2100552004': 0.66, '2100552005': 0.66, '2100552006': 0.66, '2100552007': 0.66, '2100552008': 0.66, '2100552009': 1.0, '2100552010': 0.66, '2100552011': 0.66, '2100552012': 0.66, '2100552013': 0.66, '2100552014': 0.66, '2100552015': 1.0, '2100552016': 0.66, '2100552017': 0.66, '2100552018': 0.66, '2100552019': 1.0, '2100552021': 0.66, '2100552022': 1.0, '2100552023': 0.66, '2100552024': 0.66, '2100552025': 1.0, '2100552027': 1.0, '2100552028': 1.0, '2100552029': 1.0, '2100552030': 1.0, '2100552031': 0.66, '2100552032': 1.0, '2100552033': 1.0, '2100552034': 1.0, '2100552035': 0.66, '2100552037': 0.66, '2100552038': 0.66, '2100552039': 0.66, '2100552041': 0.66, '2100552042': 1.0, '2100552043': 0.66, '2100552044': 1.0, '2100552045': 0.66, '2100552047': 1.0, '2100552048': 0.33, '2100552051': 1.0, '2100552052': 1.0, '2100552053': 0.66, '2100552055': 0.66, '2100552057': 1.0, '2100552059': 1.0, '2100552060': 0.66, '2100552061': 1.0, '2100552062': 0.66, '2100552063': 0.33, '2100552065': 0.66, '2100552066': 0.66, '2100552068': 0.66, '2100552072': 0.66, '2100561006': 0.66, '2100561010': 0.66, '2100561011': 0.66, '2100561013': 1.0, '2100561014': 1.0, '2100561015': 0.66, '2100561016': 0.66, '2100561018': 1.0, '2100561019': 1.0, '2100561020': 1.0, '2100561021': 1.0, '2100561022': 0.66, '2100561023': 1.0, '2100561024': 0.66, '2100561027': 1.0, '2100561029': 1.0, '2100561032': 0.66, '2100561038': 0.66, '2100561043': 1.0, '2100561044': 1.0, '2100561046': 1.0, '2100561051': 0.66, '2100561052': 1.0, '2100561053': 1.0, '2100561054': 0.66, '2100561056': 0.66, '2100561057': 1.0, '2100561058': 1.0, '2100561059': 1.0, '2100561062': 1.0, '2100561063': 0.66, '2100561064': 1.0, '2100561065': 1.0, '2100561070': 1.0, '2100561071': 0.66, '2100561074': 1.0, '2100561079': 0.66, '2100562001': 1.0, '2100562002': 1.0, '2100562003': 1.0, '2100562004': 1.0, '2100562005': 0.66, '2100562007': 1.0, '2100562008': 0.66, '2100562009': 1.0, '2100562010': 1.0, '2100562011': 1.0, '2100562012': 1.0, '2100562013': 0.66, '2100562014': 1.0, '2100562015': 1.0, '2100562017': 1.0, '2100562018': 1.0, '2100562019': 0.33, '2100562020': 0.66, '2100562024': 0.33, '2100562026': 0.66, '2100562027': 0.66, '2100562029': 1.0, '2100562030': 0.66, '2100562032': 0.66, '2100562033': 0.66, '2100562034': 1.0, '2100562035': 1.0, '2100562037': 1.0, '2100562038': 0.66, '2100562039': 0.66, '2100562040': 0.66, '2100562042': 1.0, '2100562043': 0.66, '2100562044': 0.66, '2100562046': 0.66, '2100562047': 1.0, '2100562048': 1.0, '2100562049': 0.66, '2100562050': 0.66, '2100562051': 0.66, '2100562053': 1.0, '2100562054': 0.66, '2100562055': 0.66, '2100562056': 1.0, '2100562058': 1.0, '2100562059': 1.0, '2100562060': 0.66, '2100562061': 1.0, '2100571001': 0.66, '2100571002': 0.33, '2100571004': 0.66, '2100571007': 0.33, '2100571008': 1.0, '2100571009': 0.66, '2100571011': 0.66, '2100571012': 0.66, '2100571013': 1.0, '2100571015': 0.66, '2100571017': 0.66, '2100571018': 0.66, '2100571019': 0.66, '2100571020': 0.66, '2100571021': 0.33, '2100571022': 0.66, '2100571023': 0.33, '2100571024': 0.66, '2100571025': 0.66, '2100571027': 0.66, '2100571029': 0.66, '2100571030': 0.66, '2100571031': 0.66, '2100571033': 0.66, '2100571034': 0.66, '2100571036': 0.66, '2100571038': 0.33, '2100571039': 0.66, '2100571040': 1.0, '2100571041': 1.0, '2100571042': 1.0, '2100571044': 0.33, '2100571045': 1.0, '2100571046': 1.0, '2100571047': 0.66, '2100571048': 1.0, '2100571049': 0.33, '2100571050': 0.66, '2100571051': 0.66, '2100571052': 0.66, '2100571053': 0.66, '2100571055': 1.0, '2100571056': 0.66, '2100571057': 0.66, '2100571058': 0.66, '2100571061': 0.66, '2100571062': 0.33, '2100571063': 0.66, '2100571064': 0.66, '2100571065': 1.0, '2100571066': 0.66, '2100571067': 0.66, '2100571068': 0.66, '2100571069': 0.66, '2100571070': 0.66, '2100571072': 1.0, '2100571073': 0.66, '2100571074': 0.66, '2100571075': 1.0, '2100571077': 1.0, '2100571078': 1.0, '2100571079': 0.66, '2100571081': 1.0, '2100571082': 0.66, '2100572001': 0.66, '2100572002': 1.0, '2100572004': 0.66, '2100572006': 1.0, '2100572009': 0.66, '2100572010': 1.0, '2100572011': 1.0, '2100572012': 0.66, '2100572013': 1.0, '2100572015': 1.0, '2100572017': 1.0, '2100572018': 1.0, '2100572019': 0.66, '2100572020': 0.66, '2100572021': 0.33, '2100572023': 0.66, '2100572024': 1.0, '2100572025': 0.66, '2100572026': 0.66, '2100572027': 0.66, '2100572028': 0.66, '2100572029': 0.66, '2100572030': 0.66, '2100572032': 0.66, '2100572033': 1.0, '2100572034': 0.66, '2100572036': 0.66, '2100572038': 0.66, '2100572039': 1.0, '2100572040': 0.66, '2100572041': 1.0, '2100572042': 0.66, '2100572043': 0.66, '2100572044': 0.66, '2100572045': 0.66, '2100572046': 1.0, '2100572047': 1.0, '2100572048': 1.0, '2100572050': 1.0, '2100572051': 1.0, '2100572054': 0.66, '2100572055': 1.0, '2100572056': 1.0, '2100572057': 0.33, '2100572058': 0.66, '2100572059': 0.66, '2100572060': 0.66, '2100572061': 0.66, '2100572062': 1.0, '2100572063': 0.66, '2100572064': 1.0, '2100572067': 0.66, '2100572068': 0.66, '2100572069': 0.66, '2100581001': 0.33, '2100581002': 1.0, '2100581003': 0.66, '2100581004': 0.66, '2100581005': 0.66, '2100581006': 0.66, '2100581007': 1.0, '2100581009': 0.66, '2100581010': 0.66, '2100581011': 1.0, '2100581012': 1.0, '2100581013': 0.66, '2100581014': 1.0, '2100581015': 1.0, '2100581018': 1.0, '2100581019': 1.0, '2100581021': 0.33, '2100581022': 0.66, '2100581024': 0.66, '2100581025': 1.0, '2100581026': 0.66, '2100581027': 0.66, '2100581028': 1.0, '2100581029': 0.66, '2100581030': 0.66, '2100581034': 0.66, '2100581035': 0.66, '2100581036': 1.0, '2100581037': 1.0, '2100581038': 0.66, '2100581039': 0.66, '2100581040': 0.66, '2100581041': 0.66, '2100581042': 0.66, '2100581044': 0.66, '2100581045': 0.66, '2100581051': 0.66, '2100581054': 1.0, '2100581056': 1.0, '2100581057': 1.0, '2100581058': 1.0, '2100581059': 0.66, '2100581061': 0.66, '2100581062': 1.0, '2100581064': 1.0, '2100581066': 0.66, '2100581067': 0.66, '2100581068': 0.66, '2100581069': 0.66, '2100581070': 0.66, '2100581071': 0.66, '2100581072': 0.66, '2100581073': 0.66, '2100581074': 0.66, '2100581075': 1.0, '2100581076': 0.66, '2100581077': 1.0, '2100582001': 0.66, '2100582002': 0.66, '2100582003': 1.0, '2100582004': 1.0, '2100582005': 1.0, '2100582006': 0.66, '2100582008': 0.66, '2100582009': 1.0, '2100582012': 0.66, '2100582013': 0.66, '2100582015': 0.66, '2100582017': 0.66, '2100582019': 0.66, '2100582020': 0.66, '2100582021': 0.66, '2100582023': 0.66, '2100582024': 0.66, '2100582025': 1.0, '2100582026': 1.0, '2100582027': 0.33, '2100582028': 0.66, '2100582038': 0.66, '2100582043': 1.0, '2100582044': 0.66, '2100582045': 0.66, '2100582046': 0.66, '2100582048': 1.0, '2100582050': 0.66, '2100582051': 0.66, '2100582052': 0.0, '2100582053': 1.0, '2100582054': 0.66, '2100582055': 0.0, '2100582056': 0.0, '2100582057': 0.0, '2100582058': 0.0, '2100582060': 0.0, '2100582061': 0.33, '2100582062': 0.0, '2100582064': 1.0, '2100582067': 0.66, '2100582069': 0.66, '2100591002': 1.0, '2100591003': 1.0, '2100591004': 1.0, '2100591005': 1.0, '2100591006': 1.0, '2100591007': 1.0, '2100591008': 1.0, '2100591010': 1.0, '2100591013': 0.66, '2100591015': 0.66, '2100591016': 1.0, '2100591017': 0.66, '2100591019': 0.66, '2100591020': 1.0, '2100591021': 0.66, '2100591022': 1.0, '2100591023': 0.66, '2100591025': 1.0, '2100591026': 0.66, '2100591027': 0.66, '2100591028': 0.66, '2100591030': 0.66, '2100591034': 1.0, '2100591035': 1.0, '2100591036': 1.0, '2100591037': 0.66, '2100591038': 0.66, '2100591039': 0.66, '2100591040': 1.0, '2100591041': 0.66, '2100591042': 1.0, '2100591043': 0.66, '2100591044': 1.0, '2100591045': 0.66, '2100591046': 0.33, '2100591047': 1.0, '2100591048': 1.0, '2100591049': 0.66, '2100591050': 1.0, '2100591053': 1.0, '2100591054': 1.0, '2100591055': 1.0, '2100591056': 1.0, '2100591057': 1.0, '2100591059': 1.0, '2100591060': 0.66, '2100591061': 1.0, '2100591062': 0.66, '2100591064': 0.66, '2100591065': 1.0, '2100591066': 1.0, '2100591067': 1.0, '2100591068': 1.0, '2100591069': 1.0, '2100591070': 1.0, '2100591072': 1.0, '2100591073': 1.0, '2100591074': 1.0, '2100591075': 1.0, '2100591076': 1.0, '2100591077': 1.0, '2100591078': 1.0, '2100591080': 1.0, '2100591081': 0.66, '2100591082': 1.0, '2100592002': 1.0, '2100592003': 1.0, '2100592004': 0.66, '2100592005': 1.0, '2100592007': 1.0, '2100592009': 1.0, '2100592010': 1.0, '2100592011': 0.66, '2100592012': 1.0, '2100592013': 0.66, '2100592014': 0.66, '2100592015': 1.0, '2100592016': 1.0, '2100592017': 1.0, '2100592018': 0.66, '2100592019': 1.0, '2100592020': 1.0, '2100592021': 1.0, '2100592022': 0.66, '2100592023': 1.0, '2100592024': 1.0, '2100592025': 0.66, '2100592026': 1.0, '2100592027': 0.66, '2100592028': 1.0, '2100592029': 1.0, '2100592030': 0.66, '2100592032': 1.0, '2100592033': 1.0, '2100592034': 1.0, '2100592035': 0.66, '2100592036': 0.66, '2100592038': 0.66, '2100592040': 0.66, '2100592041': 1.0, '2100592042': 1.0, '2100592043': 0.66, '2100592044': 1.0, '2100592046': 0.66, '2100592047': 1.0, '2100592048': 0.66, '2100592049': 1.0, '2100592052': 0.66, '2100592053': 1.0, '2100592054': 0.66, '2100592056': 0.66, '2100592057': 0.66, '2100592058': 0.66, '2100592059': 1.0, '2100592060': 0.66, '2100592064': 0.66, '2100592065': 0.66, '2100592066': 0.66, '2100592067': 1.0, '2100592068': 0.66, '2100592069': 1.0, '2100592070': 0.66, '2100592071': 0.66, '2100592072': 1.0, '2100601001': 1.0, '2100601002': 1.0, '2100601004': 0.66, '2100601005': 0.66, '2100601006': 0.66, '2100601007': 0.66, '2100601008': 1.0, '2100601009': 0.66, '2100601010': 1.0, '2100601011': 1.0, '2100601012': 0.33, '2100601013': 0.66, '2100601014': 1.0, '2100601015': 0.66, '2100601016': 1.0, '2100601017': 1.0, '2100601018': 0.33, '2100601020': 1.0, '2100601021': 0.66, '2100601023': 0.66, '2100601024': 0.66, '2100601025': 0.66, '2100601027': 0.66, '2100601028': 0.66, '2100601029': 0.66, '2100601030': 1.0, '2100601031': 0.66, '2100601032': 0.66, '2100601033': 1.0, '2100601035': 1.0, '2100601036': 0.66, '2100601037': 1.0, '2100601038': 1.0, '2100601039': 0.66, '2100601040': 1.0, '2100601041': 1.0, '2100601042': 1.0, '2100601043': 1.0, '2100601044': 1.0, '2100601045': 1.0, '2100601046': 1.0, '2100601049': 0.66, '2100601050': 0.66, '2100601052': 0.66, '2100601053': 0.66, '2100601054': 0.66, '2100601055': 1.0, '2100601056': 0.66, '2100601057': 1.0, '2100601059': 0.66, '2100601062': 1.0, '2100601063': 1.0, '2100601064': 0.66, '2100601065': 1.0, '2100601066': 1.0, '2100601067': 1.0, '2100601068': 0.66, '2100601069': 1.0, '2100601071': 1.0, '2100601073': 1.0, '2100601074': 0.66, '2100601075': 0.66, '2100601077': 1.0, '2100601078': 0.66, '2100602001': 0.66, '2100602002': 0.66, '2100602003': 0.66, '2100602004': 0.66, '2100602005': 0.66, '2100602006': 1.0, '2100602008': 0.66, '2100602009': 0.66, '2100602010': 1.0, '2100602011': 0.66, '2100602012': 0.66, '2100602014': 0.66, '2100602015': 0.66, '2100602017': 1.0, '2100602018': 0.66, '2100602019': 0.66, '2100602020': 1.0, '2100602022': 0.66, '2100602023': 0.66, '2100602024': 0.66, '2100602025': 1.0, '2100602026': 0.66, '2100602027': 1.0, '2100602028': 0.66, '2100602029': 0.66, '2100602030': 0.66, '2100602032': 0.66, '2100602033': 1.0, '2100602034': 0.66, '2100602035': 0.66, '2100602036': 0.66, '2100602038': 0.66, '2100602040': 0.66, '2100602041': 0.0, '2100602042': 0.66, '2100602043': 1.0, '2100602044': 0.66, '2100602046': 0.66, '2100602047': 1.0, '2100602049': 1.0, '2100602050': 1.0, '2100602051': 0.66, '2100602052': 1.0, '2100602053': 0.66, '2100602054': 1.0, '2100602056': 0.66, '2100602058': 0.66, '2100602059': 0.66, '2100602060': 0.66, '2100602061': 0.66, '2100602062': 1.0, '2100602063': 1.0, '2100602065': 0.66, '2100602067': 1.0, '2100602068': 0.66, '2100602069': 0.66, '2100602072': 1.0, '2100611002': 1.0, '2100611003': 1.0, '2100611004': 1.0, '2100611005': 0.66, '2100611006': 0.66, '2100611010': 0.66, '2100611011': 1.0, '2100611012': 1.0, '2100611013': 1.0, '2100611014': 1.0, '2100611015': 1.0, '2100611016': 0.66, '2100611017': 0.66, '2100611018': 0.66, '2100611019': 0.66, '2100611021': 1.0, '2100611023': 0.66, '2100611024': 1.0, '2100611025': 1.0, '2100611026': 1.0, '2100611027': 0.33, '2100611028': 0.66, '2100611029': 0.66, '2100611031': 0.66, '2100611032': 1.0, '2100611034': 1.0, '2100611035': 1.0, '2100611036': 0.66, '2100611037': 0.66, '2100611038': 1.0, '2100611039': 1.0, '2100611040': 0.66, '2100611041': 1.0, '2100611042': 0.66, '2100611043': 0.66, '2100611044': 1.0, '2100611045': 0.66, '2100611046': 1.0, '2100611047': 0.66, '2100611048': 1.0, '2100611049': 1.0, '2100611050': 0.66, '2100611051': 1.0, '2100611052': 0.66, '2100611055': 1.0, '2100611056': 1.0, '2100611057': 0.66, '2100611058': 0.66, '2100611059': 1.0, '2100611060': 0.66, '2100611061': 1.0, '2100611062': 0.66, '2100611063': 1.0, '2100611064': 1.0, '2100611066': 1.0, '2100611067': 0.66, '2100611068': 0.66, '2100611069': 1.0, '2100611070': 0.66, '2100611071': 0.66, '2100611075': 0.66, '2100611076': 1.0, '2100611077': 1.0, '2100611078': 0.66, '2100611079': 0.66, '2100611081': 1.0, '2100611083': 0.66, '2100612001': 1.0, '2100612002': 1.0, '2100612003': 0.66, '2100612005': 0.66, '2100612006': 0.66, '2100612007': 1.0, '2100612008': 1.0, '2100612009': 0.33, '2100612010': 1.0, '2100612011': 1.0, '2100612012': 1.0, '2100612014': 1.0, '2100612015': 1.0, '2100612020': 1.0, '2100612022': 1.0, '2100612024': 1.0, '2100612025': 1.0, '2100612026': 1.0, '2100612027': 0.66, '2100612028': 0.66, '2100612029': 1.0, '2100612030': 0.66, '2100612031': 1.0, '2100612033': 0.66, '2100612034': 0.66, '2100612035': 1.0, '2100612037': 0.66, '2100612038': 1.0, '2100612040': 1.0, '2100612041': 0.66, '2100612042': 0.66, '2100612043': 1.0, '2100612044': 0.66, '2100612045': 1.0, '2100612046': 1.0, '2100612047': 1.0, '2100612048': 1.0, '2100612051': 1.0, '2100612053': 1.0, '2100612056': 0.66, '2100612057': 1.0, '2100612058': 1.0, '2100612059': 1.0, '2100612060': 1.0, '2100612061': 1.0, '2100612062': 1.0, '2100612063': 0.66, '2100612064': 0.66, '2100612065': 1.0, '2100612066': 1.0, '2100612067': 1.0, '2100612068': 0.66, '2100612069': 0.66, '2100612070': 0.66, '2100612071': 0.66, '2100612072': 1.0, '2260510110': 0.66, '2260510113': 1.0, '2260510114': 0.66, '2260510115': 1.0, '2260510116': 0.66, '2260510118': 0.66, '2260510122': 0.66, '2260510124': 0.66, '2260510125': 0.66, '2260510126': 0.66, '2260510127': 1.0, '2260510129': 0.66, '226051013': 0.66, '2260510131': 0.66, '2260510134': 0.66, '2260510136': 0.66, '2260510138': 0.66, '2260510139': 0.66, '226051014': 0.66, '2260510140': 1.0, '2260510141': 0.66, '2260510142': 0.66, '2260510143': 0.66, '2260510146': 1.0, '2260510147': 0.66, '2260510148': 0.66, '2260510151': 1.0, '2260510152': 1.0, '2260510155': 0.33, '2260510156': 0.66, '2260510158': 0.66, '2260510159': 0.66, '226051016': 0.66, '2260510160': 0.66, '2260510162': 0.66, '2260510163': 0.33, '2260510167': 0.66, '2260510168': 1.0, '226051017': 0.66, '2260510172': 1.0, '2260510174': 0.66, '2260510176': 0.66, '2260510177': 0.33, '2260510180': 0.66, '2260510182': 0.66, '2260510183': 0.66, '2260510185': 0.66, '226051019': 1.0, '226051021': 0.66, '2260510212': 1.0, '2260510213': 1.0, '2260510214': 1.0, '2260510217': 0.66, '226051022': 1.0, '2260510220': 1.0, '2260510221': 0.66, '2260510222': 1.0, '2260510223': 1.0, '2260510227': 1.0, '2260510228': 0.66, '2260510229': 1.0, '226051023': 1.0, '2260510230': 1.0, '2260510231': 1.0, '2260510232': 1.0, '2260510233': 1.0, '2260510237': 1.0, '2260510238': 1.0, '2260510240': 1.0, '2260510241': 1.0, '2260510242': 1.0, '2260510243': 1.0, '2260510244': 1.0, '2260510247': 1.0, '2260510248': 1.0, '226051025': 1.0, '2260510250': 0.66, '2260510252': 1.0, '2260510253': 1.0, '2260510254': 0.66, '2260510257': 0.66, '2260510258': 1.0, '2260510259': 1.0, '226051026': 1.0, '2260510260': 1.0, '2260510262': 0.66, '2260510266': 1.0, '2260510267': 1.0, '226051027': 1.0, '2260510270': 1.0, '2260510271': 0.66, '2260510272': 1.0, '2260510276': 0.66, '2260510277': 0.66, '2260510278': 1.0, '240846010': 1.0, '240846011': 1.0, '2408460110': 1.0, '2408460111': 0.66, '2408460118': 0.33, '240846012': 0.66, '2408460120': 0.66, '2408460123': 1.0, '2408460125': 1.0, '2408460126': 0.66, '2408460127': 0.66, '2408460129': 0.66, '240846013': 0.66, '2408460130': 0.66, '2408460131': 0.66, '2408460132': 0.66, '2408460133': 1.0, '2408460134': 1.0, '2408460135': 1.0, '2408460137': 0.33, '2408460139': 1.0, '2408460143': 0.66, '2408460145': 1.0, '2408460146': 1.0, '2408460148': 0.66, '2408460149': 0.66, '240846015': 0.66, '2408460150': 0.66, '2408460151': 1.0, '2408460152': 1.0, '2408460154': 1.0, '2408460155': 1.0, '2408460156': 0.66, '2408460158': 0.66, '2408460159': 0.66, '240846016': 0.66, '2408460163': 0.66, '2408460166': 0.66, '240846017': 0.66, '240846018': 0.66, '240846019': 0.66, '2408460211': 0.66, '2408460212': 1.0, '2408460213': 1.0, '2408460215': 1.0, '2408460217': 0.66, '2408460219': 0.66, '240846022': 0.66, '2408460220': 1.0, '2408460221': 1.0, '2408460222': 0.66, '2408460223': 0.66, '2408460225': 1.0, '2408460226': 0.66, '2408460227': 1.0, '2408460229': 0.66, '240846023': 0.66, '2408460234': 0.66, '2408460236': 1.0, '2408460237': 1.0, '2408460238': 0.66, '240846024': 0.66, '2408460240': 0.66, '2408460242': 1.0, '2408460243': 1.0, '2408460244': 0.66, '2408460246': 1.0, '2408460247': 1.0, '2408460249': 1.0, '2408460252': 1.0, '2408460254': 0.66, '2408460255': 1.0, '2408460257': 1.0, '2408460260': 1.0, '2408460261': 1.0, '2408460265': 1.0, '2408460266': 1.0, '2408460268': 1.0, '2408460269': 0.66, '240846027': 0.66, '2408460271': 0.66, '2408460272': 0.66, '2408460274': 0.66, '2408460276': 1.0, '2408460277': 1.0, '2408460278': 0.66, '240846028': 0.66, '2408460280': 1.0, '240846029': 0.66, '24851011': 0.66, '248510111': 1.0, '248510112': 1.0, '248510114': 0.66, '248510116': 1.0, '248510117': 1.0, '248510118': 0.66, '248510119': 1.0, '248510120': 1.0, '248510125': 1.0, '248510127': 0.66, '248510128': 1.0, '248510129': 1.0, '24851013': 1.0, '248510131': 0.66, '248510136': 1.0, '248510137': 1.0, '24851014': 0.66, '248510142': 0.66, '248510147': 1.0, '248510148': 1.0, '24851015': 1.0, '248510150': 1.0, '248510151': 1.0, '248510153': 0.66, '248510155': 1.0, '248510156': 0.66, '248510157': 0.66, '248510160': 1.0, '248510161': 1.0, '248510163': 0.66, '248510164': 1.0, '248510167': 1.0, '248510170': 1.0, '24851018': 1.0, '24851019': 1.0, '248510211': 1.0, '248510212': 1.0, '248510213': 0.66, '248510214': 0.66, '248510215': 1.0, '248510216': 1.0, '24851022': 1.0, '248510220': 1.0, '248510223': 1.0, '248510225': 1.0, '248510227': 1.0, '248510229': 1.0, '248510230': 1.0, '248510232': 1.0, '248510233': 1.0, '248510235': 1.0, '248510236': 1.0, '24851024': 1.0, '248510241': 1.0, '248510242': 1.0, '248510245': 1.0, '248510246': 1.0, '248510248': 1.0, '248510249': 1.0, '248510250': 0.66, '248510251': 1.0, '248510253': 1.0, '248510255': 1.0, '248510256': 1.0, '248510259': 1.0, '24851026': 1.0, '248510260': 1.0, '248510262': 1.0, '248510264': 0.66, '248510265': 1.0, '248510267': 1.0, '248510268': 1.0, '24851027': 1.0, '248510271': 1.0, '248510272': 1.0, '248510273': 1.0, '248510276': 1.0, '248510278': 0.66, '24851028': 1.0, '2904280110': 1.0, '29042801110': 1.0, '29042801170': 1.0, '29042801180': 0.66, '2904280120': 1.0, '29042801220': 0.66, '29042801230': 1.0, '29042801250': 1.0, '29042801260': 1.0, '29042801290': 1.0, '29042801300': 1.0, '29042801320': 1.0, '29042801340': 1.0, '29042801350': 1.0, '29042801370': 0.33, '29042801390': 1.0, '2904280140': 0.66, '29042801440': 0.66, '29042801450': 1.0, '29042801470': 1.0, '29042801480': 0.66, '2904280150': 1.0, '29042801500': 1.0, '29042801550': 0.66, '29042801570': 0.66, '29042801580': 1.0, '2904280160': 0.66, '29042801600': 1.0, '29042801630': 1.0, '29042801640': 1.0, '29042801650': 0.66, '29042801680': 0.66, '29042801690': 0.66, '2904280170': 0.66, '29042801710': 1.0, '29042801740': 1.0, '29042801750': 1.0, '29042801770': 1.0, '29042801780': 0.66, '29042801790': 0.66, '2904280180': 1.0, '2904280190': 1.0, '29042802110': 0.66, '29042802140': 0.66, '29042802150': 0.66, '29042802180': 1.0, '29042802200': 1.0, '29042802220': 1.0, '29042802240': 1.0, '29042802260': 1.0, '29042802280': 1.0, '2904280230': 1.0, '29042802310': 1.0, '29042802320': 1.0, '29042802340': 1.0, '29042802350': 1.0, '29042802380': 0.66, '29042802390': 0.66, '29042802410': 1.0, '29042802420': 1.0, '29042802430': 1.0, '29042802440': 1.0, '29042802450': 1.0, '29042802460': 1.0, '29042802470': 1.0, '29042802480': 1.0, '2904280250': 0.66, '29042802500': 1.0, '29042802510': 1.0, '29042802520': 1.0, '29042802530': 1.0, '29042802560': 1.0, '29042802570': 1.0, '2904280260': 0.33, '29042802600': 0.66, '29042802640': 1.0, '29042802660': 0.66, '29042802670': 1.0, '29042802680': 1.0, '29042802690': 1.0, '2904280270': 0.66, '29042802700': 1.0, '29042802720': 1.0, '29042802740': 1.0, '29042802750': 1.0, '29042802760': 1.0, '29042802770': 0.66, '29042802790': 1.0, '2904280280': 1.0, '29042802800': 1.0, '29042802830': 1.0, '29042802860': 1.0, '2904280290': 0.66, '303830110': 0.66, '303830113': 0.33, '303830115': 0.66, '303830117': 1.0, '303830118': 1.0, '303830121': 1.0, '303830122': 1.0, '303830123': 0.66, '303830126': 0.33, '303830127': 1.0, '303830128': 0.66, '30383013': 1.0, '303830131': 0.66, '303830132': 0.66, '303830133': 0.66, '303830138': 1.0, '303830139': 0.33, '30383014': 1.0, '303830141': 1.0, '303830143': 0.66, '303830144': 1.0, '303830146': 0.66, '303830147': 1.0, '303830148': 0.66, '303830149': 0.0, '30383015': 0.66, '303830151': 1.0, '303830155': 0.33, '303830156': 1.0, '303830157': 1.0, '303830158': 1.0, '303830159': 0.66, '30383016': 1.0, '303830160': 0.66, '303830161': 0.66, '303830162': 1.0, '303830166': 1.0, '303830167': 0.66, '303830169': 0.66, '303830171': 1.0, '303830174': 1.0, '303830175': 0.66, '303830178': 0.66, '303830182': 1.0, '303830183': 0.66, '303830184': 1.0, '303830210': 1.0, '303830211': 1.0, '303830212': 1.0, '303830216': 0.66, '303830217': 1.0, '303830218': 0.66, '30383022': 0.66, '303830220': 1.0, '303830221': 1.0, '303830223': 1.0, '303830224': 0.66, '303830225': 0.66, '303830227': 1.0, '303830229': 0.66, '30383023': 0.33, '303830234': 1.0, '303830236': 1.0, '303830239': 1.0, '303830240': 1.0, '303830241': 1.0, '303830242': 1.0, '303830245': 1.0, '303830246': 0.66, '303830247': 1.0, '303830249': 1.0, '30383025': 0.66, '303830250': 0.66, '303830255': 1.0, '303830258': 1.0, '303830259': 1.0, '303830263': 1.0, '303830269': 0.66, '303830270': 1.0, '303830273': 1.0, '303830274': 1.0, '303830278': 0.66, '30383028': 1.0, '3100621001': 1.0, '3100621002': 1.0, '3100621003': 1.0, '3100621004': 0.66, '3100621005': 1.0, '3100621007': 1.0, '3100621009': 0.66, '3100621010': 1.0, '3100621011': 1.0, '3100621012': 0.66, '3100621013': 1.0, '3100621014': 1.0, '3100621016': 1.0, '3100621018': 0.66, '3100621019': 0.66, '3100621020': 0.66, '3100621022': 0.66, '3100621023': 1.0, '3100621024': 1.0, '3100621025': 0.66, '3100621026': 1.0, '3100621027': 1.0, '3100621028': 1.0, '3100621030': 0.66, '3100621031': 1.0, '3100621032': 0.66, '3100621033': 1.0, '3100621034': 0.66, '3100621035': 0.66, '3100621037': 0.33, '3100621039': 1.0, '3100621040': 1.0, '3100621041': 1.0, '3100621042': 0.66, '3100621043': 1.0, '3100621045': 1.0, '3100621046': 1.0, '3100621047': 1.0, '3100621048': 1.0, '3100621049': 1.0, '3100621051': 0.66, '3100621052': 0.66, '3100621053': 1.0, '3100621055': 1.0, '3100621057': 1.0, '3100621058': 1.0, '3100621059': 1.0, '3100621061': 0.66, '3100621062': 0.66, '3100621063': 1.0, '3100621064': 1.0, '3100622001': 0.66, '3100622002': 1.0, '3100622003': 1.0, '3100622006': 0.66, '3100622007': 1.0, '3100622008': 1.0, '3100622009': 0.66, '3100622011': 1.0, '3100622013': 1.0, '3100622015': 1.0, '3100622019': 0.66, '3100622020': 0.66, '3100622021': 0.66, '3100622023': 1.0, '3100622024': 0.66, '3100622026': 0.66, '3100622027': 0.66, '3100622033': 0.66, '3100622034': 1.0, '3100622036': 1.0, '3100622037': 0.66, '3100622038': 1.0, '3100622040': 1.0, '3100622041': 1.0, '3100622042': 1.0, '3100622043': 1.0, '3100622044': 0.66, '3100622045': 1.0, '3100622047': 1.0, '3100622048': 1.0, '3100622049': 0.66, '3100622051': 1.0, '3100622053': 0.66, '3100622054': 1.0, '3100622057': 0.66, '3100631001': 1.0, '3100631002': 1.0, '3100631003': 0.66, '3100631004': 1.0, '3100631005': 0.66, '3100631006': 1.0, '3100631008': 1.0, '3100631009': 1.0, '3100631010': 1.0, '3100631011': 1.0, '3100631013': 0.66, '3100631014': 0.66, '3100631015': 0.66, '3100631016': 1.0, '3100631018': 0.66, '3100631019': 1.0, '3100631022': 0.66, '3100631023': 0.66, '3100631025': 1.0, '3100631026': 1.0, '3100631027': 0.66, '3100631029': 1.0, '3100631032': 1.0, '3100631035': 1.0, '3100631037': 1.0, '3100631042': 0.66, '3100631043': 1.0, '3100631044': 1.0, '3100631045': 1.0, '3100631046': 1.0, '3100631047': 1.0, '3100631048': 0.66, '3100631049': 0.66, '3100631051': 1.0, '3100631052': 1.0, '3100631053': 0.66, '3100631054': 1.0, '3100631055': 0.66, '3100631056': 1.0, '3100631057': 0.66, '3100631058': 1.0, '3100631059': 1.0, '3100631062': 1.0, '3100632001': 0.66, '3100632002': 1.0, '3100632003': 0.66, '3100632004': 1.0, '3100632007': 1.0, '3100632008': 0.66, '3100632011': 0.66, '3100632012': 0.66, '3100632015': 1.0, '3100632016': 0.66, '3100632017': 1.0, '3100632018': 0.66, '3100632019': 1.0, '3100632021': 0.66, '3100632023': 1.0, '3100632024': 1.0, '3100632025': 1.0, '3100632026': 0.66, '3100632027': 1.0, '3100632030': 0.66, '3100632031': 1.0, '3100632039': 0.66, '3100632041': 1.0, '3100632042': 1.0, '3100632043': 1.0, '3100632044': 1.0, '3100632045': 0.66, '3100641002': 0.66, '3100641003': 0.33, '3100641004': 0.33, '3100641006': 0.33, '3100641007': 0.66, '3100641008': 0.66, '3100641023': 0.33, '3100642002': 1.0, '3100642003': 0.66, '3100642005': 0.66, '3100642006': 0.66, '3100642007': 0.33, '3100642008': 1.0, '3100642009': 1.0, '3100642011': 1.0, '3100642012': 0.66, '3100642013': 1.0, '3100642015': 0.66, '3100642017': 0.33, '3100642019': 1.0, '3100642020': 1.0, '3100642021': 0.66, '3100642022': 0.66, '3100642024': 1.0, '3100642025': 0.66, '3100642026': 0.66, '3100642027': 0.66, '3100642028': 0.66, '3100642030': 0.66, '3100642031': 0.66, '3100642032': 0.66, '3100642033': 1.0, '3100642034': 0.66, '3100642035': 0.66, '3100642036': 0.33, '3100642037': 0.66, '3100642038': 0.66, '3100642040': 0.66, '3100642045': 0.66, '3100642047': 1.0, '3100642052': 0.66, '3100642054': 1.0, '3100642055': 0.33, '3100642056': 1.0, '3100642057': 0.66, '3100642058': 0.66, '3100642060': 0.66, '3100642061': 0.66, '3100642063': 0.66, '3100642064': 0.66, '3100642066': 1.0, '3100642069': 0.66, '3100642070': 0.66, '3100661002': 0.66, '3100661007': 1.0, '3100661009': 0.66, '3100661015': 0.66, '3100661016': 1.0, '3100661022': 0.66, '3100661023': 0.66, '3100661024': 0.66, '3100661025': 0.66, '3100661027': 0.66, '3100661028': 0.66, '3100661029': 1.0, '3100661031': 0.66, '3100661032': 1.0, '3100661033': 0.66, '3100661036': 0.66, '3100661037': 0.66, '3100661038': 0.66, '3100661040': 0.66, '3100661043': 0.66, '3100661044': 0.66, '3100661046': 1.0, '3100661049': 0.66, '3100661050': 0.66, '3100662014': 1.0, '3100662015': 1.0, '3100662016': 0.66, '3100662017': 0.66, '3100662020': 1.0, '3100662022': 0.66, '3100662023': 0.66, '3100662026': 1.0, '3100662029': 0.66, '3100662032': 0.66, '3100662035': 0.66, '3100662036': 0.66, '3100662037': 0.33, '3100662045': 1.0, '3100662046': 0.66, '3100662048': 1.0, '3100662049': 1.0, '3100662050': 0.66, '3100662052': 1.0, '3100662053': 0.66, '3100662055': 0.66, '3100681001': 0.66, '3100681002': 0.66, '3100681005': 1.0, '3100681006': 1.0, '3100681015': 0.33, '3100681017': 0.33, '3100681018': 0.33, '3100681042': 0.33, '3100681043': 0.66, '3100681044': 1.0, '3100681045': 0.66, '3100681046': 0.66, '3100682001': 0.66, '3100682002': 1.0, '3100682003': 0.66, '3100682007': 1.0, '3100682008': 0.66, '3100682030': 0.66, '3100682040': 0.66, '3100691005': 0.66, '3100691006': 0.66, '3100691007': 0.66, '3100691011': 0.66, '3100691012': 0.66, '3100691021': 0.66, '3100691026': 0.66, '3100691042': 0.66, '3100691045': 0.66, '3100691048': 0.66, '3100692002': 0.66, '3100692005': 1.0, '3100692006': 0.66, '3100692007': 0.66, '3100692009': 1.0, '3100692010': 0.66, '3100692011': 1.0, '3100692012': 0.66, '3100692013': 0.66, '3100692015': 0.33, '3100692016': 0.66, '3100692020': 0.66, '3100692022': 0.66, '3100692023': 0.66, '3100692024': 0.66, '3100692025': 0.66, '3100692028': 0.66, '3100692029': 1.0, '3100692032': 0.66, '3100692034': 1.0, '3100692035': 1.0, '3100692038': 0.66, '3100692039': 0.66, '3100692045': 1.0, '3100692052': 0.66, '3100692054': 0.66, '3100692055': 0.66, '3100692056': 0.66, '3100701001': 0.66, '3100701002': 1.0, '3100701004': 1.0, '3100701005': 1.0, '3100701008': 0.66, '3100701009': 0.66, '3100701010': 0.33, '3100701011': 0.66, '3100701012': 1.0, '3100701013': 1.0, '3100701014': 0.66, '3100701015': 0.66, '3100701016': 1.0, '3100701019': 0.66, '3100701021': 0.66, '3100701022': 0.66, '3100701023': 0.33, '3100701024': 0.66, '3100701029': 0.66, '3100701031': 1.0, '3100701032': 0.66, '3100701036': 0.66, '3100701043': 0.66, '3100701044': 0.66, '3100701050': 0.66, '3100701051': 0.66, '3100701056': 1.0, '3100701057': 0.66, '3100701058': 1.0, '3100701061': 0.66, '3100701063': 0.66, '3100701072': 1.0, '3100701073': 0.66, '3100702004': 0.66, '3100702005': 1.0, '3100702006': 0.66, '3100702010': 0.66, '3100702012': 1.0, '3100702013': 1.0, '3100702016': 1.0, '3100702017': 0.66, '3100702019': 0.66, '3100702020': 0.66, '3100702021': 0.66, '3100702022': 0.66, '3100702023': 0.66, '3100702024': 0.66, '3100702025': 1.0, '3100702026': 0.66, '3100702027': 0.66, '3100702028': 0.66, '3100702029': 0.66, '3100702030': 0.66, '3100702031': 0.66, '3100702033': 0.66, '3100702034': 0.66, '3100702035': 0.66, '3100702036': 1.0, '3100702037': 1.0, '3100702038': 0.33, '3100702039': 1.0, '3100702040': 1.0, '3100702041': 1.0, '3100702043': 1.0, '3100702044': 0.66, '3100702045': 1.0, '3100702046': 1.0, '3100702047': 1.0, '3100702048': 1.0, '3100702051': 0.66, '3100702052': 1.0, '3100702054': 0.66, '3100702055': 0.66, '3100702059': 1.0, '3100702060': 0.66, '3100702061': 0.66, '3100702062': 0.66, '3100702063': 0.66, '3100702064': 0.66, '3100702065': 1.0, '3100702066': 0.66, '3100702067': 1.0, '3100702068': 0.66, '3100711007': 0.66, '3100711009': 0.66, '3100711042': 0.66, '3100711043': 1.0, '3100711049': 0.66, '3100711050': 0.66, '3100711051': 1.0, '3100711052': 0.66, '3100712014': 0.66, '3100721002': 0.66, '3100721003': 1.0, '3100721004': 1.0, '3100721005': 0.66, '3100721006': 0.66, '3100721007': 0.66, '3100721008': 0.66, '3100721011': 0.66, '3100721012': 1.0, '3100721013': 0.66, '3100721014': 1.0, '3100721015': 1.0, '3100721016': 1.0, '3100721018': 1.0, '3100721019': 1.0, '3100721020': 1.0, '3100721021': 0.66, '3100721022': 1.0, '3100721023': 1.0, '3100721024': 1.0, '3100721028': 0.66, '3100721029': 1.0, '3100721030': 1.0, '3100721031': 0.33, '3100721032': 1.0, '3100721033': 0.66, '3100721034': 0.66, '3100721036': 0.66, '3100721038': 0.66, '3100721039': 1.0, '3100721040': 1.0, '3100721041': 1.0, '3100721042': 1.0, '3100721044': 0.66, '3100721045': 1.0, '3100721046': 1.0, '3100721047': 1.0, '3100721048': 0.66, '3100721049': 0.66, '3100721050': 0.66, '3100721051': 1.0, '3100721052': 1.0, '3100721053': 0.66, '3100721054': 1.0, '3100721055': 1.0, '3100721056': 1.0, '3100721057': 1.0, '3100721058': 0.66, '3100721059': 1.0, '3100721060': 1.0, '3100721062': 1.0, '3100721063': 1.0, '3100721064': 1.0, '3100721065': 1.0, '3100721066': 1.0, '3100721068': 1.0, '3100721070': 1.0, '3100721071': 0.66, '3100721072': 0.66, '3100722003': 0.66, '3100722004': 1.0, '3100722005': 1.0, '3100722006': 0.66, '3100722007': 1.0, '3100722012': 1.0, '3100722013': 1.0, '3100722014': 1.0, '3100722016': 1.0, '3100722017': 1.0, '3100722020': 1.0, '3100722021': 1.0, '3100722022': 1.0, '3100722023': 1.0, '3100722024': 0.66, '3100722025': 1.0, '3100722026': 1.0, '3100722027': 0.66, '3100722030': 0.66, '3100722031': 1.0, '3100722032': 0.66, '3100722033': 0.66, '3100722034': 1.0, '3100722036': 0.66, '3100722038': 1.0, '3100722039': 1.0, '3100722040': 1.0, '3100722042': 1.0, '3100722044': 1.0, '3100722045': 0.66, '3100722046': 0.66, '3100722047': 1.0, '3100722048': 0.66, '3100722054': 1.0, '3100722055': 1.0, '3100722057': 1.0, '3100722059': 1.0, '3100722061': 1.0, '3100722062': 1.0, '3100722063': 1.0, '3100722064': 1.0, '3100722065': 1.0, '3100722066': 1.0, '3100722067': 1.0, '3100722068': 1.0, '3100722069': 1.0, '3100722070': 1.0, '3100722072': 1.0, '3100722073': 1.0, '3100722074': 0.66, '3100722076': 1.0, '3100722077': 1.0, '3100722078': 1.0, '3100722079': 1.0, '3100731001': 0.66, '3100731006': 0.66, '3100731007': 0.66, '3100731008': 0.66, '3100731009': 0.66, '3100731011': 0.66, '3100731012': 1.0, '3100731013': 1.0, '3100731014': 0.66, '3100731025': 1.0, '3100731026': 1.0, '3100731028': 0.66, '3100731029': 1.0, '3100731030': 0.66, '3100731031': 0.66, '3100731037': 1.0, '3100731038': 1.0, '3100731050': 0.66, '3100731052': 1.0, '3100731054': 1.0, '3100731056': 0.66, '3100731057': 1.0, '3100731058': 1.0, '3100732001': 1.0, '3100732002': 1.0, '3100732003': 0.66, '3100732006': 1.0, '3100732013': 0.66, '3100732014': 1.0, '3100732015': 0.66, '3100732017': 0.66, '3100732018': 1.0, '3100732020': 0.66, '3100732021': 0.66, '3100732022': 0.66, '3100732023': 0.66, '3100732025': 0.66, '3100732027': 0.66, '3100732028': 1.0, '3100732029': 1.0, '3100732031': 0.66, '3100732036': 0.66, '3100732040': 1.0, '3100732041': 0.66, '3100732042': 1.0, '3100732067': 1.0, '3100741001': 0.66, '3100741002': 0.66, '3100741003': 1.0, '3100741004': 1.0, '3100741011': 1.0, '3100741012': 0.66, '3100741013': 0.66, '3100741014': 0.66, '3100741016': 1.0, '3100741017': 1.0, '3100741018': 1.0, '3100741019': 1.0, '3100741020': 1.0, '3100741022': 1.0, '3100741023': 1.0, '3100741024': 1.0, '3100741025': 1.0, '3100741026': 1.0, '3100741027': 0.66, '3100741028': 0.66, '3100741029': 1.0, '3100741030': 0.66, '3100741032': 1.0, '3100741034': 1.0, '3100741035': 1.0, '3100741036': 1.0, '3100741037': 0.66, '3100741038': 1.0, '3100741039': 1.0, '3100741042': 1.0, '3100741043': 0.66, '3100741044': 1.0, '3100741045': 1.0, '3100741047': 1.0, '3100741049': 0.66, '3100741053': 0.66, '3100741054': 0.66, '3100741056': 0.66, '3100741057': 1.0, '3100741058': 1.0, '3100741059': 1.0, '3100741060': 1.0, '3100741061': 1.0, '3100741063': 1.0, '3100741064': 0.66, '3100741065': 1.0, '3100741066': 0.33, '3100741068': 0.66, '3100741069': 1.0, '3100741070': 1.0, '3100741071': 1.0, '3100741072': 1.0, '3100741073': 0.66, '3100741074': 1.0, '3100741075': 0.66, '3100741076': 1.0, '3100741077': 1.0, '3100741079': 1.0, '3100742001': 0.66, '3100742003': 0.66, '3100742004': 0.66, '3100742005': 0.66, '3100742007': 0.66, '3100742010': 0.66, '3100742011': 1.0, '3100742012': 1.0, '3100742013': 1.0, '3100742014': 0.66, '3100742015': 0.66, '3100742016': 0.66, '3100742018': 1.0, '3100742020': 0.66, '3100742021': 0.66, '3100742022': 1.0, '3100742023': 0.66, '3100742024': 1.0, '3100742025': 0.66, '3100742027': 0.66, '3100742028': 1.0, '3100742033': 1.0, '3100742034': 0.66, '3100742037': 0.66, '3100742038': 0.66, '3100742041': 1.0, '3100742042': 1.0, '3100742044': 0.66, '3100742045': 1.0, '3100742046': 0.66, '3100742047': 0.66, '3100742048': 0.66, '3100742050': 0.66, '3100742051': 0.66, '3100742052': 0.66, '3100742053': 0.66, '3100742054': 0.66, '3100742055': 0.66, '3100742056': 0.66, '3100742057': 1.0, '3100742058': 0.33, '3100742059': 1.0, '3100742060': 1.0, '3100742061': 0.66, '3100742062': 0.66, '3100742063': 0.66, '3100742065': 0.66, '3100742067': 1.0, '3100742068': 1.0, '3100751003': 0.66, '3100751004': 0.66, '3100751005': 0.66, '3100751006': 0.33, '3100751007': 0.0, '3100751008': 0.33, '3100751009': 1.0, '3100751010': 0.0, '3100751011': 1.0, '3100751012': 0.33, '3100751014': 0.66, '3100751015': 0.66, '3100751016': 0.66, '3100751017': 0.66, '3100751018': 1.0, '3100751019': 0.33, '3100751020': 1.0, '3100751021': 0.66, '3100751022': 0.66, '3100751024': 1.0, '3100751026': 0.66, '3100751027': 0.66, '3100751028': 0.66, '3100751032': 1.0, '3100751033': 0.66, '3100751034': 0.66, '3100751035': 0.66, '3100751037': 0.66, '3100751039': 0.66, '3100751040': 1.0, '3100751041': 0.66, '3100751043': 1.0, '3100751044': 1.0, '3100751045': 0.66, '3100751048': 0.66, '3100751050': 0.66, '3100751055': 1.0, '3100751056': 0.33, '3100751057': 0.33, '3100751058': 0.66, '3100751059': 0.66, '3100751063': 0.66, '3100751064': 0.66, '3100751065': 0.66, '3100751068': 1.0, '3100751069': 0.66, '3100751070': 0.66, '3100751072': 0.66, '3100751073': 1.0, '3100751074': 0.66, '3100751075': 1.0, '3100751076': 0.66, '3100751077': 0.66, '3100751078': 0.66, '3100751079': 0.66, '3100752001': 0.66, '3100752002': 1.0, '3100752003': 0.66, '3100752004': 0.66, '3100752005': 0.66, '3100752007': 0.66, '3100752008': 0.66, '3100752009': 0.66, '3100752010': 0.66, '3100752012': 0.66, '3100752014': 0.33, '3100752015': 1.0, '3100752016': 0.66, '3100752017': 0.66, '3100752018': 1.0, '3100752019': 1.0, '3100752020': 0.66, '3100752021': 0.33, '3100752022': 0.66, '3100752023': 0.66, '3100752026': 0.66, '3100752027': 0.66, '3100752029': 0.66, '3100752030': 0.33, '3100752032': 0.66, '3100752034': 1.0, '3100752035': 0.66, '3100752036': 0.66, '3100752037': 0.33, '3100752038': 0.66, '3100752039': 0.66, '3100752040': 1.0, '3100752041': 1.0, '3100752042': 0.66, '3100752043': 0.66, '3100752044': 1.0, '3100752045': 1.0, '3100752046': 0.66, '3100752047': 0.66, '3100752048': 0.33, '3100752049': 0.66, '3100752050': 1.0, '3100752051': 0.33, '3100752052': 1.0, '3100752054': 0.66, '3100752055': 0.33, '3100752056': 0.66, '3100752057': 0.66, '3100752058': 1.0, '3100752059': 0.66, '3100752060': 0.66, '3100752061': 0.66, '3100752063': 0.66, '3100752068': 0.66, '3100761003': 0.33, '3100761004': 1.0, '3100761005': 0.33, '3100761007': 0.66, '3100761008': 0.33, '3100761013': 0.66, '3100761014': 0.66, '3100761015': 0.66, '3100761016': 0.66, '3100761017': 0.66, '3100761019': 0.66, '3100761020': 1.0, '3100761021': 1.0, '3100761023': 0.66, '3100761027': 1.0, '3100761028': 1.0, '3100761029': 1.0, '3100761030': 0.66, '3100761031': 0.66, '3100761034': 0.66, '3100761042': 0.66, '3100761046': 0.66, '3100761047': 0.66, '3100761048': 1.0, '3100761049': 0.66, '3100761050': 0.66, '3100761051': 0.66, '3100761056': 0.66, '3100761062': 0.66, '3100761063': 1.0, '3100762003': 0.66, '3100762004': 0.33, '3100762005': 0.66, '3100762007': 1.0, '3100762012': 0.66, '3100762013': 0.66, '3100762016': 0.66, '3100762027': 0.33, '3100762029': 1.0, '3100762030': 0.33, '3100762052': 0.66, '3100762053': 0.66, '3100762055': 0.33, '3100771001': 0.33, '3100771002': 0.66, '3100771003': 1.0, '3100771005': 0.66, '3100771007': 0.33, '3100771008': 0.66, '3100771009': 0.66, '3100771012': 1.0, '3100771014': 0.66, '3100771016': 0.66, '3100771018': 0.66, '3100771019': 0.66, '3100771020': 0.66, '3100771021': 0.66, '3100771022': 0.66, '3100771024': 0.66, '3100771027': 0.66, '3100771028': 0.66, '3100771029': 0.66, '3100771030': 0.66, '3100771031': 0.66, '3100771032': 0.66, '3100771033': 0.66, '3100771034': 0.66, '3100771036': 0.66, '3100771037': 0.66, '3100771039': 0.66, '3100771040': 0.66, '3100771041': 1.0, '3100771042': 1.0, '3100771043': 0.66, '3100771046': 0.66, '3100771047': 0.66, '3100771048': 1.0, '3100771049': 0.66, '3100771050': 1.0, '3100771052': 0.66, '3100771054': 0.66, '3100771055': 0.66, '3100771056': 1.0, '3100771057': 1.0, '3100771058': 1.0, '3100771059': 1.0, '3100771062': 0.66, '3100771063': 1.0, '3100771064': 0.66, '3100771065': 0.66, '3100771066': 0.66, '3100771067': 0.66, '3100771068': 0.66, '3100771069': 0.66, '3100771071': 0.66, '3100771072': 1.0, '3100771073': 0.66, '3100771075': 0.66, '3100771076': 1.0, '3100771077': 1.0, '3100771078': 0.66, '3100771080': 0.66, '3100771081': 1.0, '3100772002': 1.0, '3100772004': 0.66, '3100772005': 0.66, '3100772006': 0.66, '3100772007': 1.0, '3100772008': 1.0, '3100772009': 0.66, '3100772010': 1.0, '3100772011': 1.0, '3100772013': 0.66, '3100772014': 1.0, '3100772015': 1.0, '3100772018': 1.0, '3100772019': 1.0, '3100772020': 0.66, '3100772021': 1.0, '3100772022': 1.0, '3100772023': 0.66, '3100772024': 1.0, '3100772025': 0.66, '3100772026': 1.0, '3100772027': 1.0, '3100772028': 1.0, '3100772029': 0.66, '3100772031': 0.66, '3100772032': 1.0, '3100772033': 1.0, '3100772034': 0.66, '3100772035': 0.66, '3100772036': 1.0, '3100772037': 1.0, '3100772039': 1.0, '3100772040': 1.0, '3100772041': 1.0, '3100772042': 1.0, '3100772043': 0.66, '3100772045': 0.66, '3100772046': 0.66, '3100772048': 0.66, '3100772050': 0.66, '3100772051': 0.33, '3100772052': 0.66, '3100772053': 1.0, '3100772054': 1.0, '3100772055': 1.0, '3100772056': 1.0, '3100772058': 1.0, '3100772059': 1.0, '3100772063': 0.66, '3100772065': 1.0, '3100772066': 0.66, '3100772067': 0.66, '3100772068': 0.66, '3100772069': 1.0, '3100781001': 0.66, '3100781002': 0.33, '3100781004': 0.66, '3100781006': 1.0, '3100781007': 0.33, '3100781008': 1.0, '3100781009': 1.0, '3100781010': 0.66, '3100781011': 1.0, '3100781013': 0.66, '3100781015': 0.66, '3100781016': 1.0, '3100781017': 0.66, '3100781019': 1.0, '3100781020': 1.0, '3100781021': 1.0, '3100781023': 1.0, '3100781024': 1.0, '3100781027': 1.0, '3100781029': 1.0, '3100781030': 1.0, '3100781031': 1.0, '3100781032': 0.66, '3100781033': 0.66, '3100781034': 0.33, '3100781036': 1.0, '3100781038': 0.66, '3100781040': 1.0, '3100781041': 1.0, '3100781043': 1.0, '3100781044': 0.66, '3100781046': 1.0, '3100781047': 1.0, '3100781048': 1.0, '3100781051': 1.0, '3100781052': 1.0, '3100781053': 1.0, '3100781054': 1.0, '3100781055': 1.0, '3100781056': 1.0, '3100781057': 0.66, '3100781058': 1.0, '3100781059': 0.66, '3100781061': 1.0, '3100781062': 1.0, '3100781064': 1.0, '3100781065': 0.66, '3100781066': 0.66, '3100781068': 0.66, '3100781069': 1.0, '3100781070': 0.66, '3100781071': 0.66, '3100781073': 0.66, '3100781074': 1.0, '3100781075': 1.0, '3100781076': 1.0, '3100781078': 1.0, '3100781079': 1.0, '3100781080': 1.0, '3100781081': 1.0, '3100782001': 0.66, '3100782003': 1.0, '3100782004': 1.0, '3100782005': 1.0, '3100782006': 0.66, '3100782008': 1.0, '3100782010': 0.66, '3100782011': 1.0, '3100782012': 1.0, '3100782013': 0.66, '3100782014': 1.0, '3100782015': 1.0, '3100782016': 1.0, '3100782017': 1.0, '3100782018': 0.66, '3100782019': 1.0, '3100782021': 1.0, '3100782022': 1.0, '3100782023': 1.0, '3100782024': 1.0, '3100782025': 1.0, '3100782026': 0.66, '3100782027': 1.0, '3100782028': 0.66, '3100782031': 0.66, '3100782032': 1.0, '3100782033': 1.0, '3100782035': 0.66, '3100782036': 0.66, '3100782037': 0.66, '3100782038': 1.0, '3100782039': 0.66, '3100782042': 1.0, '3100782043': 1.0, '3100782045': 1.0, '3100782046': 1.0, '3100782047': 1.0, '3100782049': 1.0, '3100782050': 0.66, '3100782053': 1.0, '3100782054': 0.66, '3100782055': 0.66, '3100782057': 1.0, '3100782058': 1.0, '3100782059': 0.66, '3100782061': 1.0, '3100782062': 1.0, '3100782063': 0.66, '3100782064': 1.0, '3100782065': 1.0, '3100782066': 1.0, '3100782067': 0.33, '3100782068': 1.0, '3100782069': 0.66, '3100782071': 0.66, '3100782072': 0.66, '3100791004': 1.0, '3100791006': 0.66, '3100791007': 0.66, '3100791008': 1.0, '3100791016': 0.66, '3100791018': 0.66, '3100791020': 1.0, '3100791021': 1.0, '3100791026': 1.0, '3100791028': 0.66, '3100791031': 1.0, '3100791033': 1.0, '3100791034': 1.0, '3100791035': 1.0, '3100791042': 1.0, '3100791044': 0.66, '3100791045': 1.0, '3100791046': 0.66, '3100791047': 1.0, '3100791049': 0.66, '3100791050': 0.66, '3100791052': 1.0, '3100791054': 0.66, '3100791056': 0.66, '3100791058': 0.33, '3100791059': 1.0, '3100791060': 1.0, '3100791061': 1.0, '3100791062': 0.66, '3100791063': 0.66, '3100791064': 1.0, '3100791065': 0.66, '3100791066': 0.66, '3100791067': 0.66, '3100791069': 0.66, '3100791070': 0.66, '3100791071': 1.0, '3100791072': 0.66, '3100791073': 0.66, '3100792002': 0.66, '3100792003': 0.66, '3100792004': 0.66, '3100792005': 0.66, '3100792006': 0.66, '3100792007': 1.0, '3100792008': 0.66, '3100792009': 0.66, '3100792010': 0.66, '3100792011': 0.66, '3100792013': 0.66, '3100792014': 1.0, '3100792015': 0.66, '3100792016': 0.66, '3100792019': 1.0, '3100792020': 0.66, '3100792021': 0.66, '3100792022': 0.66, '3100792023': 0.66, '3100792024': 0.66, '3100792025': 0.66, '3100792027': 1.0, '3100792028': 0.66, '3100792030': 0.66, '3100792031': 1.0, '3100792032': 0.66, '3100792033': 0.66, '3100792035': 0.66, '3100792036': 0.66, '3100792037': 0.66, '3100792038': 0.66, '3100792039': 0.66, '3100792040': 0.66, '3100792041': 0.66, '3100792042': 1.0, '3100792043': 0.66, '3100792044': 0.66, '3100792045': 0.33, '3100792046': 1.0, '3100792048': 1.0, '3100792050': 0.66, '3100792051': 0.66, '3100792052': 0.66, '3100792053': 0.66, '3100792057': 0.66, '3100792058': 0.66, '3100792060': 0.66, '3100792069': 0.66, '3100801006': 0.66, '3100802001': 1.0, '3100802028': 1.0, '3100811002': 0.66, '3100811018': 0.66, '3100811027': 0.66, '3100811034': 0.66, '3100811035': 0.66, '3100811036': 1.0, '3100811037': 0.66, '3100811038': 0.66, '3100811039': 0.66, '3100811040': 1.0, '3100811041': 1.0, '3100811042': 0.66, '3100811043': 0.66, '3100811045': 0.66, '3100811046': 0.66, '3100811047': 0.66, '3100811050': 1.0, '3100811051': 0.66, '3100811053': 0.66, '3100811054': 0.66, '3100811055': 0.66, '3100811056': 1.0, '3100811059': 0.66, '3100811060': 1.0, '3100811061': 0.66, '3100811063': 1.0, '3100811068': 0.66, '3100811075': 0.66, '3100812003': 1.0, '3100812004': 0.66, '3100812005': 1.0, '3100812006': 1.0, '3100812007': 0.66, '3100812008': 1.0, '3100812013': 1.0, '3100812014': 0.66, '3100812016': 0.66, '3100812017': 1.0, '3100812018': 0.66, '3100812019': 0.66, '3100812020': 0.66, '3100812021': 0.66, '3100812026': 0.66, '3100812027': 0.66, '3100812028': 0.33, '3100812040': 0.66, '3100821004': 0.66, '3100821015': 0.66, '3100821016': 1.0, '3100821019': 0.66, '3100821020': 1.0, '3100821021': 0.66, '3100821022': 0.33, '3100821030': 1.0, '3100821031': 0.66, '3100821032': 0.33, '3100821033': 0.0, '3100821034': 1.0, '3100821035': 1.0, '3100821036': 1.0, '3100821037': 0.66, '3100821038': 0.33, '3100821039': 0.66, '3100821040': 0.66, '3100821041': 0.66, '3100821042': 1.0, '3100821045': 0.66, '3100821046': 0.66, '3100821047': 0.66, '3100821048': 0.33, '3100821049': 1.0, '3100821051': 1.0, '3100821052': 0.0, '3100821054': 0.66, '3100821055': 0.66, '3100821057': 0.33, '3100821067': 0.66, '3100821068': 1.0, '3100821069': 0.0, '3100821075': 0.0, '3100822001': 0.66, '3100822011': 0.33, '3100822012': 0.66, '3100822014': 0.66, '3100822030': 1.0, '3100822031': 0.0, '3100822044': 1.0, '3100822050': 1.0, '3100822051': 1.0, '3100822057': 1.0, '3100822058': 1.0, '3100822059': 0.66, '3100822064': 1.0, '3100822065': 0.33, '3100822066': 0.0, '3100822067': 0.66, '3100822068': 0.66, '3100822069': 1.0, '3100822070': 0.66, '3100822075': 1.0, '3100822080': 0.66, '3100831003': 0.66, '3100831004': 1.0, '3100831006': 0.66, '3100831007': 1.0, '3100831008': 1.0, '3100831010': 0.66, '3100831011': 0.66, '3100831013': 0.66, '3100831014': 0.66, '3100831015': 0.66, '3100831016': 0.66, '3100831018': 0.66, '3100831019': 1.0, '3100831020': 1.0, '3100831022': 1.0, '3100831024': 0.66, '3100831026': 1.0, '3100831027': 1.0, '3100831028': 0.66, '3100831029': 0.66, '3100831032': 0.66, '3100831033': 0.66, '3100831035': 1.0, '3100831036': 0.66, '3100831037': 0.66, '3100831044': 0.66, '3100831045': 1.0, '3100831046': 1.0, '3100831047': 1.0, '3344630110': 1.0, '33446301100': 0.66, '33446301101': 0.66, '33446301103': 1.0, '33446301104': 0.66, '33446301107': 1.0, '3344630112': 1.0, '3344630113': 0.66, '3344630115': 1.0, '3344630116': 0.66, '3344630117': 1.0, '3344630119': 0.66, '334463012': 1.0, '3344630120': 1.0, '3344630121': 0.33, '3344630127': 0.66, '3344630130': 1.0, '3344630131': 0.33, '3344630132': 0.66, '3344630133': 0.66, '3344630136': 0.66, '3344630139': 0.66, '334463014': 0.66, '3344630140': 1.0, '3344630141': 0.66, '3344630142': 1.0, '3344630143': 1.0, '3344630146': 0.66, '3344630147': 0.66, '3344630148': 1.0, '3344630149': 1.0, '3344630150': 0.66, '3344630151': 0.66, '3344630153': 0.66, '3344630156': 0.66, '3344630161': 1.0, '3344630162': 0.33, '3344630163': 1.0, '3344630164': 0.66, '3344630166': 0.66, '3344630170': 1.0, '3344630171': 0.66, '3344630172': 0.66, '3344630173': 1.0, '3344630176': 1.0, '3344630179': 0.66, '3344630180': 0.66, '3344630181': 0.66, '3344630182': 0.66, '3344630184': 1.0, '3344630185': 0.66, '3344630186': 0.66, '3344630188': 1.0, '3344630189': 1.0, '334463019': 0.66, '3344630190': 1.0, '3344630196': 0.66, '3344630197': 0.66, '3344630198': 1.0, '3344630199': 0.66, '334463021': 1.0, '3344630210': 0.66, '3344630211': 0.33, '3344630213': 1.0, '3344630215': 1.0, '3344630216': 1.0, '3344630219': 1.0, '334463022': 0.66, '3344630220': 1.0, '3344630221': 0.66, '3344630224': 0.66, '3344630225': 1.0, '3344630226': 0.66, '3344630231': 0.66, '3344630232': 0.66, '3344630233': 0.66, '3344630236': 1.0, '3344630238': 0.66, '3344630240': 1.0, '3344630241': 1.0, '3344630242': 1.0, '3344630243': 1.0, '3344630245': 1.0, '3344630247': 1.0, '3344630248': 0.66, '334463025': 0.66, '3344630251': 1.0, '3344630252': 0.66, '3344630255': 0.66, '3344630257': 1.0, '334463026': 0.66, '3344630260': 1.0, '3344630262': 0.66, '3344630264': 0.66, '3344630265': 1.0, '3344630266': 0.66, '3344630267': 0.66, '334463027': 0.66, '3344630270': 0.66, '3344630271': 1.0, '3344630273': 0.66, '3344630276': 0.66, '3344630278': 1.0, '334463028': 1.0, '3344630280': 0.66, '3344630281': 0.66, '3344630282': 0.33, '334463029': 1.0, '33702101100': 1.0, '33702101110': 1.0, '33702101130': 1.0, '33702101140': 1.0, '33702101150': 1.0, '33702101180': 0.66, '33702101200': 1.0, '33702101210': 1.0, '33702101250': 0.66, '33702101260': 1.0, '33702101270': 1.0, '33702101280': 1.0, '33702101290': 0.66, '33702101300': 1.0, '33702101340': 1.0, '33702101350': 1.0, '33702101360': 1.0, '33702101370': 1.0, '33702101410': 1.0, '33702101430': 0.66, '33702101450': 0.66, '33702101460': 1.0, '33702101470': 0.66, '33702101480': 0.66, '33702101490': 0.66, '3370210150': 0.66, '33702101500': 1.0, '33702101530': 1.0, '33702101540': 0.66, '33702101550': 1.0, '33702101580': 1.0, '33702101590': 1.0, '33702101600': 0.66, '33702101620': 0.66, '33702101630': 1.0, '33702101640': 1.0, '33702101650': 1.0, '33702101660': 1.0, '33702101700': 1.0, '33702101710': 1.0, '33702101730': 1.0, '33702101740': 1.0, '33702101750': 1.0, '33702101760': 1.0, '3370210180': 1.0, '33702102100': 1.0, '33702102110': 1.0, '33702102130': 0.66, '33702102140': 0.66, '33702102160': 1.0, '33702102170': 1.0, '33702102180': 1.0, '33702102190': 1.0, '33702102200': 1.0, '33702102220': 0.66, '33702102230': 1.0, '33702102240': 1.0, '33702102250': 1.0, '33702102280': 1.0, '3370210230': 1.0, '33702102300': 1.0, '33702102310': 1.0, '33702102330': 1.0, '33702102350': 1.0, '33702102390': 1.0, '3370210240': 1.0, '33702102400': 1.0, '33702102420': 1.0, '33702102430': 1.0, '33702102470': 0.66, '33702102500': 1.0, '33702102530': 1.0, '33702102540': 1.0, '33702102550': 1.0, '33702102570': 1.0, '33702102580': 1.0, '33702102590': 1.0, '3370210260': 1.0, '33702102600': 1.0, '33702102640': 0.66, '33702102670': 1.0, '33702102690': 1.0, '33702102710': 1.0, '33702102740': 1.0, '3370210280': 1.0, '33702102820': 1.0, '33702102840': 1.0, '33702102850': 1.0, '33702102870': 1.0, '33702102880': 1.0, '342227010': 1.0, '342227011': 1.0, '3422270111': 0.33, '3422270112': 1.0, '3422270115': 0.66, '3422270116': 1.0, '3422270117': 0.66, '3422270118': 0.66, '3422270121': 1.0, '3422270122': 1.0, '3422270123': 1.0, '3422270126': 0.66, '3422270127': 1.0, '3422270128': 1.0, '3422270129': 0.33, '342227013': 1.0, '3422270130': 0.66, '3422270131': 0.66, '3422270133': 1.0, '3422270134': 1.0, '3422270135': 0.66, '3422270138': 1.0, '3422270139': 1.0, '3422270140': 1.0, '3422270141': 0.66, '3422270142': 0.66, '3422270143': 1.0, '3422270144': 1.0, '3422270149': 0.66, '3422270151': 0.66, '3422270152': 0.66, '3422270153': 0.66, '3422270154': 1.0, '3422270155': 0.66, '3422270157': 0.66, '3422270158': 0.66, '3422270160': 0.66, '3422270165': 1.0, '3422270166': 1.0, '3422270167': 0.33, '3422270168': 1.0, '3422270169': 1.0, '3422270171': 0.66, '3422270172': 1.0, '342227020': 1.0, '342227021': 1.0, '3422270210': 1.0, '3422270211': 1.0, '3422270212': 0.66, '3422270213': 1.0, '3422270215': 0.66, '3422270216': 1.0, '3422270217': 1.0, '3422270219': 0.66, '3422270220': 0.66, '3422270221': 0.66, '3422270222': 1.0, '3422270223': 1.0, '3422270224': 1.0, '3422270225': 0.66, '3422270227': 0.66, '342227023': 1.0, '3422270230': 0.66, '3422270238': 1.0, '3422270239': 1.0, '342227024': 1.0, '3422270240': 0.66, '3422270241': 1.0, '3422270242': 1.0, '3422270244': 0.66, '3422270245': 1.0, '3422270246': 0.66, '3422270247': 1.0, '3422270249': 0.66, '342227025': 1.0, '3422270250': 1.0, '3422270251': 0.66, '3422270252': 1.0, '3422270253': 1.0, '3422270254': 1.0, '3422270255': 1.0, '3422270256': 1.0, '3422270257': 0.66, '3422270261': 1.0, '3422270262': 0.66, '3422270263': 1.0, '3422270264': 1.0, '3422270267': 1.0, '3422270268': 1.0, '3422270269': 1.0, '342227027': 1.0, '3422270274': 0.66, '3422270278': 1.0, '3422270279': 1.0, '3422270280': 1.0, '3422270281': 1.0, '342227029': 1.0, '350361011': 0.66, '3503610110': 1.0, '3503610111': 1.0, '3503610112': 1.0, '3503610113': 0.66, '3503610114': 0.66, '3503610115': 0.66, '3503610116': 1.0, '3503610117': 1.0, '3503610118': 1.0, '3503610119': 1.0, '350361012': 1.0, '3503610120': 0.66, '3503610121': 1.0, '3503610122': 1.0, '3503610123': 1.0, '3503610124': 1.0, '3503610125': 1.0, '3503610126': 1.0, '3503610127': 0.66, '3503610128': 1.0, '3503610129': 0.66, '350361013': 0.66, '3503610130': 1.0, '3503610131': 1.0, '3503610132': 1.0, '3503610133': 0.66, '3503610134': 1.0, '3503610135': 1.0, '3503610136': 1.0, '3503610137': 0.66, '3503610138': 1.0, '3503610139': 0.66, '350361014': 1.0, '3503610140': 1.0, '3503610141': 1.0, '3503610142': 0.66, '3503610143': 1.0, '3503610144': 1.0, '3503610145': 1.0, '3503610146': 1.0, '3503610147': 1.0, '3503610148': 1.0, '3503610149': 0.66, '350361015': 1.0, '3503610150': 1.0, '3503610151': 1.0, '3503610152': 1.0, '3503610154': 1.0, '3503610156': 1.0, '3503610157': 0.66, '3503610158': 0.33, '350361016': 0.66, '3503610163': 1.0, '3503610168': 0.0, '350361017': 1.0, '350361019': 1.0, '350361021': 1.0, '3503610210': 1.0, '3503610212': 1.0, '3503610213': 0.66, '3503610214': 0.66, '3503610217': 1.0, '350361022': 0.66, '3503610223': 1.0, '3503610224': 1.0, '3503610225': 1.0, '3503610226': 1.0, '3503610227': 1.0, '3503610228': 1.0, '350361023': 1.0, '3503610230': 1.0, '3503610231': 1.0, '3503610233': 1.0, '3503610234': 0.66, '3503610235': 1.0, '3503610236': 1.0, '3503610237': 1.0, '3503610238': 1.0, '350361024': 1.0, '3503610240': 1.0, '3503610241': 0.66, '3503610242': 1.0, '3503610245': 1.0, '3503610246': 1.0, '3503610248': 1.0, '3503610250': 1.0, '3503610251': 0.66, '3503610252': 1.0, '3503610253': 1.0, '3503610254': 1.0, '3503610255': 0.66, '3503610256': 1.0, '3503610257': 1.0, '350361026': 1.0, '3503610260': 1.0, '3503610261': 1.0, '3503610264': 1.0, '3503610265': 0.66, '3503610266': 1.0, '3503610267': 1.0, '3503610268': 1.0, '3503610269': 0.66, '3503610270': 1.0, '3503610272': 0.66, '3503610273': 1.0, '3503610275': 0.66, '3503610276': 0.66, '3503610277': 1.0, '3503610278': 0.66, '3503610279': 1.0, '350361028': 0.33, '350361029': 0.66, '4000181002': 0.66, '4000181004': 0.33, '4000181005': 0.66, '4000181006': 0.66, '4000181007': 0.66, '4000181008': 0.66, '4000181010': 0.66, '4000181011': 0.66, '4000181012': 0.66, '4000181013': 1.0, '4000181014': 1.0, '4000181015': 0.33, '4000181016': 0.66, '4000181017': 0.66, '4000181019': 0.66, '4000181020': 1.0, '4000181022': 1.0, '4000181023': 0.66, '4000181024': 1.0, '4000181026': 1.0, '4000181027': 0.66, '4000181028': 1.0, '4000181029': 0.66, '4000181030': 1.0, '4000181031': 0.66, '4000181032': 0.66, '4000181033': 1.0, '4000181035': 1.0, '4000181036': 0.66, '4000181037': 0.66, '4000181039': 0.66, '4000181041': 1.0, '4000181042': 1.0, '4000181043': 0.66, '4000181044': 1.0, '4000181045': 0.66, '4000181046': 0.66, '4000181047': 0.66, '4000181048': 1.0, '4000181049': 1.0, '4000181053': 0.66, '4000181054': 0.66, '4000181055': 0.66, '4000181056': 1.0, '4000181057': 0.66, '4000181060': 0.66, '4000181061': 1.0, '4000181062': 0.66, '4000181063': 0.66, '4000181064': 0.66, '4000181065': 0.66, '4000181066': 1.0, '4000181067': 0.66, '4000181068': 0.66, '4000181069': 0.66, '4000181070': 1.0, '4000181072': 0.66, '4000181073': 0.66, '4000181074': 0.66, '4000181075': 0.66, '4000181076': 0.66, '4000181077': 0.66, '4000181078': 1.0, '4000181079': 0.66, '4000181080': 1.0, '4000182003': 1.0, '4000182004': 0.66, '4000182005': 0.66, '4000182006': 0.66, '4000182007': 1.0, '4000182008': 0.66, '4000182009': 1.0, '4000182010': 1.0, '4000182011': 0.66, '4000182013': 1.0, '4000182014': 1.0, '4000182015': 0.66, '4000182016': 0.66, '4000182017': 1.0, '4000182018': 0.66, '4000182020': 1.0, '4000182022': 0.66, '4000182024': 0.66, '4000182025': 1.0, '4000182026': 0.66, '4000182027': 0.66, '4000182028': 0.66, '4000182029': 0.66, '4000182030': 1.0, '4000182031': 0.66, '4000182032': 1.0, '4000182033': 0.66, '4000182035': 0.33, '4000182036': 0.66, '4000182037': 0.66, '4000182038': 0.66, '4000182039': 0.66, '4000182040': 1.0, '4000182041': 1.0, '4000182042': 1.0, '4000182044': 1.0, '4000182046': 0.66, '4000182047': 0.66, '4000182049': 1.0, '4000182050': 0.66, '4000182051': 0.66, '4000182053': 0.66, '4000182054': 0.66, '4000182055': 0.66, '4000182058': 0.66, '4000182059': 1.0, '4000182060': 1.0, '4000182062': 0.66, '4000182063': 0.66, '4000182064': 1.0, '4000182067': 0.66, '4000182068': 0.66, '4000182069': 0.66, '4000221001': 0.66, '4000221002': 1.0, '4000221006': 0.66, '4000221008': 1.0, '4000221009': 0.66, '4000221010': 0.66, '4000221011': 0.66, '4000221013': 0.66, '4000221014': 0.66, '4000221015': 0.66, '4000221016': 1.0, '4000221017': 1.0, '4000221018': 0.66, '4000221024': 0.66, '4000221033': 0.66, '4000221034': 0.66, '4000221035': 0.66, '4000221036': 0.66, '4000221040': 0.33, '4000221041': 0.66, '4000221042': 1.0, '4000221054': 0.66, '4000221055': 0.66, '4000221061': 1.0, '4000221062': 1.0, '4000221064': 0.66, '4000221065': 0.66, '4000221066': 0.66, '4000221067': 0.66, '4000221071': 0.66, '4000221072': 0.66, '4000222001': 1.0, '4000222003': 0.66, '4000222004': 1.0, '4000222007': 0.66, '4000222012': 1.0, '4000222013': 0.66, '4000222014': 0.66, '4000222015': 0.66, '4000222017': 0.66, '4000222031': 0.33, '4000222032': 0.0, '4000222035': 0.66, '4000222036': 0.33, '4000222038': 1.0, '4000222039': 1.0, '4000222040': 0.66, '4000222041': 0.33, '4000222042': 0.66, '4000222044': 0.66, '4000222045': 0.66, '4000222046': 1.0, '4000222051': 0.66, '4000222052': 0.66, '4000222054': 1.0, '4000222056': 0.66, '4000222057': 0.66, '4000222068': 0.66, '4000222069': 0.66, '4000222070': 1.0, '4000231001': 1.0, '4000231008': 0.66, '4000231010': 0.66, '4000231011': 1.0, '4000231012': 1.0, '4000231013': 0.66, '4000231014': 0.66, '4000231021': 1.0, '4000231032': 1.0, '4000231033': 0.66, '4000231034': 0.66, '4000231037': 1.0, '4000231038': 1.0, '4000231047': 0.66, '4000231049': 0.66, '4000231052': 0.66, '4000231060': 0.66, '4000231061': 0.66, '4000231063': 0.66, '4000231065': 1.0, '4000231070': 1.0, '4000231071': 0.66, '4000231073': 0.66, '4000231074': 1.0, '4000231081': 1.0, '4000232001': 0.66, '4000232004': 0.66, '4000232005': 0.66, '4000232006': 0.66, '4000232007': 1.0, '4000232010': 0.66, '4000232016': 1.0, '4000232017': 1.0, '4000232018': 1.0, '4000232022': 0.66, '4000232024': 0.66, '4000232027': 1.0, '4000232034': 0.66, '4000232035': 1.0, '4000232036': 1.0, '4000232037': 0.66, '4000232038': 0.66, '4000232042': 0.66, '4000232044': 1.0, '4000232045': 1.0, '4000232048': 0.66, '4000232051': 0.66, '4000232054': 0.66, '4000232059': 0.66, '4000232062': 0.66, '4000232065': 0.66, '4000232068': 1.0, '4000232071': 0.33, '4000232072': 0.66, '4000301002': 0.66, '4000301003': 0.66, '4000301005': 0.33, '4000301006': 0.33, '4000301007': 0.66, '4000301008': 0.66, '4000301010': 0.33, '4000301011': 0.0, '4000301012': 0.66, '4000301013': 0.66, '4000301014': 0.66, '4000301015': 0.66, '4000301016': 0.66, '4000301018': 0.66, '4000301019': 0.66, '4000301020': 0.66, '4000301021': 0.33, '4000301022': 1.0, '4000301023': 1.0, '4000301025': 1.0, '4000301026': 0.66, '4000301027': 0.66, '4000301028': 0.0, '4000301030': 0.0, '4000301031': 0.66, '4000301032': 1.0, '4000301034': 0.66, '4000301038': 1.0, '4000301039': 1.0, '4000301040': 1.0, '4000301041': 1.0, '4000301042': 0.0, '4000301043': 1.0, '4000301044': 0.66, '4000301045': 1.0, '4000301047': 1.0, '4000301049': 0.33, '4000301052': 1.0, '4000301053': 0.66, '4000301054': 0.66, '4000301055': 0.33, '4000301056': 0.66, '4000301057': 0.66, '4000301058': 0.66, '4000301059': 0.66, '4000301060': 0.33, '4000301061': 0.66, '4000301062': 0.66, '4000301063': 1.0, '4000301064': 0.66, '4000301065': 0.33, '4000301066': 0.33, '4000301067': 0.33, '4000301068': 0.66, '4000301069': 0.66, '4000301070': 0.0, '4000301071': 0.66, '4000301072': 1.0, '4000301073': 1.0, '4000301074': 0.66, '4000301076': 0.66, '4000301079': 0.66, '4000331001': 0.66, '4000331002': 0.66, '4000331003': 1.0, '4000331004': 1.0, '4000331005': 1.0, '4000331006': 1.0, '4000331007': 0.66, '4000331008': 1.0, '4000331011': 1.0, '4000331012': 1.0, '4000331013': 0.66, '4000331015': 0.66, '4000331017': 0.66, '4000331019': 1.0, '4000331020': 1.0, '4000331021': 0.66, '4000331022': 0.66, '4000331023': 1.0, '4000331025': 1.0, '4000331027': 1.0, '4000331029': 0.66, '4000331030': 0.66, '4000331031': 0.66, '4000331032': 0.66, '4000331033': 1.0, '4000331035': 1.0, '4000331036': 0.66, '4000331037': 0.66, '4000331038': 1.0, '4000331039': 0.66, '4000331040': 0.66, '4000331041': 0.66, '4000331042': 1.0, '4000331043': 1.0, '4000331044': 1.0, '4000331045': 0.66, '4000331046': 0.66, '4000331051': 0.66, '4000331052': 1.0, '4000331053': 1.0, '4000331054': 0.66, '4000331055': 0.66, '4000331056': 0.66, '4000331057': 1.0, '4000331058': 0.66, '4000331060': 0.66, '4000331062': 0.66, '4000331063': 0.66, '4000331064': 0.66, '4000331067': 1.0, '4000331068': 0.66, '4000331069': 0.66, '4000332001': 0.66, '4000332002': 0.66, '4000332007': 0.66, '4000332008': 1.0, '4000332009': 0.66, '4000332010': 0.66, '4000332012': 0.66, '4000332013': 0.66, '4000332014': 1.0, '4000332015': 0.66, '4000332017': 1.0, '4000332019': 0.66, '4000332020': 0.66, '4000332021': 0.66, '4000332022': 0.66, '4000332023': 0.66, '4000332025': 1.0, '4000332027': 0.66, '4000332030': 1.0, '4000332031': 0.66, '4000332032': 0.66, '4000332034': 1.0, '4000332035': 0.66, '4000332036': 1.0, '4000332037': 1.0, '4000332038': 0.66, '4000332039': 0.66, '4000332041': 1.0, '4000332044': 1.0, '4000332045': 1.0, '4000332046': 0.66, '4000332048': 1.0, '4000332050': 1.0, '4000332051': 0.66, '4000332052': 0.66, '4000332057': 0.66, '4000332059': 0.66, '4000332060': 1.0, '4000332061': 0.66, '4000332062': 0.66, '4000332063': 1.0, '4000332064': 0.66, '4000332066': 1.0, '4000332067': 1.0, '4000332068': 1.0, '4000332071': 0.66, '4000332072': 0.66, '4000332073': 0.66, '4000332074': 1.0, '4000332075': 0.66, '4000332077': 1.0, '4000332078': 0.66, '4000332079': 1.0, '4000332080': 1.0, '4000332081': 0.66, '4000332082': 0.33, '401835011': 1.0, '4018350112': 0.66, '4018350115': 1.0, '4018350116': 0.66, '4018350118': 1.0, '4018350119': 0.66, '4018350120': 1.0, '4018350121': 1.0, '4018350122': 0.66, '4018350126': 0.66, '4018350127': 0.66, '401835013': 1.0, '4018350130': 1.0, '4018350132': 1.0, '4018350134': 1.0, '4018350136': 1.0, '4018350137': 1.0, '4018350138': 1.0, '4018350139': 1.0, '4018350140': 1.0, '4018350141': 1.0, '4018350143': 1.0, '4018350144': 0.66, '4018350145': 0.66, '4018350146': 1.0, '4018350147': 0.66, '4018350149': 1.0, '401835015': 0.33, '4018350150': 0.66, '4018350152': 1.0, '4018350156': 1.0, '4018350157': 1.0, '4018350159': 1.0, '4018350160': 1.0, '4018350161': 1.0, '4018350162': 1.0, '4018350163': 1.0, '4018350166': 1.0, '4018350167': 1.0, '401835017': 0.66, '401835018': 1.0, '401835021': 0.66, '4018350213': 1.0, '4018350215': 0.66, '4018350217': 0.66, '4018350219': 0.66, '4018350220': 1.0, '4018350221': 0.66, '4018350222': 1.0, '4018350223': 1.0, '4018350224': 0.66, '4018350225': 1.0, '4018350226': 1.0, '4018350227': 1.0, '4018350231': 0.66, '4018350232': 1.0, '4018350233': 0.66, '4018350234': 1.0, '4018350236': 1.0, '4018350239': 0.66, '401835024': 0.66, '4018350240': 0.66, '4018350241': 1.0, '4018350244': 1.0, '4018350247': 0.66, '4018350251': 0.66, '4018350254': 1.0, '4018350256': 1.0, '4018350257': 1.0, '4018350258': 1.0, '4018350259': 0.66, '4018350260': 1.0, '4018350261': 1.0, '4018350263': 0.66, '4018350268': 1.0, '4018350269': 1.0, '4018350274': 0.66, '4018350276': 1.0, '4018350277': 0.66, '4018350279': 0.66, '401835028': 1.0, '4018350281': 0.66, '4018350282': 0.33, '4100191001': 0.66, '4100191002': 0.66, '4100191003': 1.0, '4100191004': 1.0, '4100191006': 0.66, '4100191007': 0.66, '4100191008': 0.33, '4100191010': 0.66, '4100191012': 0.66, '4100191014': 0.66, '4100191016': 0.66, '4100191017': 0.66, '4100191018': 1.0, '4100191020': 1.0, '4100191021': 0.66, '4100191023': 0.66, '4100191024': 0.66, '4100191025': 0.66, '4100191026': 0.66, '4100191030': 1.0, '4100191031': 0.66, '4100191032': 0.66, '4100191033': 0.0, '4100191034': 1.0, '4100191035': 0.66, '4100191038': 0.66, '4100191039': 0.66, '4100191041': 0.33, '4100191042': 0.66, '4100191043': 0.66, '4100191045': 0.66, '4100191046': 0.66, '4100191052': 0.66, '4100191053': 0.66, '4100192001': 0.66, '4100192002': 0.66, '4100192003': 0.66, '4100192004': 0.66, '4100192005': 0.66, '4100192006': 1.0, '4100192007': 0.66, '4100192010': 0.33, '4100192011': 0.33, '4100192012': 0.66, '4100192013': 0.66, '4100192014': 1.0, '4100192015': 0.33, '4100192016': 0.33, '4100192019': 0.66, '4100192020': 0.66, '4100192022': 0.66, '4100192023': 1.0, '4100192024': 0.66, '4100192025': 1.0, '4100192026': 0.0, '4100192027': 0.66, '4100192028': 1.0, '4100192029': 0.0, '4100192031': 0.33, '4100192032': 1.0, '4100192033': 0.66, '4100192034': 0.66, '4100192036': 0.66, '4100192037': 0.66, '4100192038': 0.66, '4100192039': 0.66, '4100192040': 0.66, '4100192043': 0.66, '4100192044': 0.66, '4100192045': 0.66, '4100192046': 0.66, '4100192047': 1.0, '4100192048': 0.66, '4100192049': 0.33, '4100192050': 0.66, '4100192051': 0.66, '4100192052': 0.66, '4100192053': 0.33, '4100192054': 0.66, '4100192055': 0.66, '4100192056': 0.66, '4100192057': 1.0, '4100192058': 0.66, '4100192060': 0.33, '4100192061': 0.66, '4100192062': 1.0, '4100192063': 0.66, '4100192066': 0.66, '4100192068': 0.66, '4100201001': 1.0, '4100201003': 0.66, '4100201004': 1.0, '4100201005': 0.66, '4100201006': 0.66, '4100201007': 0.66, '4100201008': 1.0, '4100201009': 0.66, '4100201010': 1.0, '4100201011': 0.66, '4100201013': 1.0, '4100201014': 1.0, '4100201016': 0.66, '4100201017': 1.0, '4100201018': 1.0, '4100201020': 1.0, '4100201021': 0.66, '4100201022': 1.0, '4100201023': 1.0, '4100201024': 1.0, '4100201025': 1.0, '4100201026': 0.66, '4100201027': 0.66, '4100201030': 0.33, '4100201031': 1.0, '4100201032': 0.33, '4100201033': 0.66, '4100201034': 0.66, '4100201035': 1.0, '4100201039': 0.33, '4100201040': 1.0, '4100201041': 0.66, '4100201042': 1.0, '4100201043': 0.33, '4100201044': 0.66, '4100201045': 0.66, '4100201046': 0.66, '4100201048': 0.66, '4100201049': 1.0, '4100201051': 1.0, '4100201052': 0.66, '4100201053': 0.66, '4100201054': 1.0, '4100201055': 1.0, '4100201056': 0.66, '4100201058': 1.0, '4100201059': 0.66, '4100201060': 0.66, '4100201061': 0.0, '4100201062': 1.0, '4100201063': 0.66, '4100201064': 0.66, '4100201068': 1.0, '4100201069': 1.0, '4100201071': 0.66, '4100201072': 1.0, '4100201073': 1.0, '4100201074': 0.66, '4100201075': 1.0, '4100201076': 0.66, '4100201078': 1.0, '4100201079': 1.0, '4100201081': 0.66, '4100201082': 0.66, '4100202001': 0.66, '4100202004': 0.66, '4100202005': 0.66, '4100202006': 0.66, '4100202007': 1.0, '4100202008': 1.0, '4100202009': 1.0, '4100202010': 0.66, '4100202011': 0.66, '4100202012': 0.66, '4100202013': 0.66, '4100202014': 0.33, '4100202015': 1.0, '4100202016': 1.0, '4100202017': 1.0, '4100202018': 0.66, '4100202019': 1.0, '4100202021': 1.0, '4100202022': 0.66, '4100202023': 1.0, '4100202024': 0.66, '4100202025': 0.66, '4100202032': 0.66, '4100202037': 0.66, '4100202039': 0.66, '4100202040': 0.66, '4100202041': 1.0, '4100202042': 0.66, '4100202043': 1.0, '4100202045': 0.66, '4100202046': 0.33, '4100202048': 0.66, '4100202052': 0.66, '4100202053': 0.66, '4100202054': 1.0, '4100202055': 1.0, '4100202056': 0.66, '4100202063': 1.0, '4100202065': 0.33, '4100202067': 1.0, '4100202068': 0.66, '4100241001': 0.66, '4100241002': 0.66, '4100241003': 0.66, '4100241004': 0.66, '4100241006': 0.66, '4100241007': 0.66, '4100241008': 0.66, '4100241009': 0.66, '4100241011': 0.66, '4100241013': 0.66, '4100241016': 1.0, '4100241017': 0.66, '4100241018': 1.0, '4100241020': 0.66, '4100241029': 0.33, '4100241030': 0.66, '4100241031': 0.66, '4100241042': 0.66, '4100241045': 0.66, '4100241046': 1.0, '4100241049': 0.66, '4100241051': 1.0, '4100241052': 1.0, '4100241053': 1.0, '4100241054': 0.66, '4100241055': 0.33, '4100241056': 1.0, '4100241059': 0.33, '4100241060': 1.0, '4100241061': 1.0, '4100241062': 0.66, '4100241063': 1.0, '4100241064': 0.66, '4100241068': 0.33, '4100241069': 1.0, '4100241075': 1.0, '4100242001': 0.66, '4100242002': 0.66, '4100242003': 0.33, '4100242004': 1.0, '4100242005': 0.66, '4100242006': 0.66, '4100242008': 0.66, '4100242011': 0.66, '4100242020': 0.66, '4100242021': 0.66, '4100242029': 0.66, '4100242031': 0.66, '4100242032': 0.0, '4100242033': 0.33, '4100242034': 0.66, '4100242035': 0.33, '4100242036': 0.66, '4100242037': 0.66, '4100242038': 0.66, '4100242040': 0.66, '4100242045': 0.66, '4100242048': 1.0, '4100242050': 0.66, '4100242053': 0.66, '4100242054': 0.66, '4100242057': 0.33, '4100242059': 0.66, '4100242060': 0.66, '4100242063': 0.33, '4100242065': 0.66, '4100242066': 0.66, '4100242067': 0.66, '4100251003': 0.66, '4100251004': 1.0, '4100251005': 1.0, '4100251006': 0.33, '4100251010': 1.0, '4100251011': 0.66, '4100251012': 0.66, '4100251013': 0.66, '4100251014': 0.66, '4100251015': 1.0, '4100251016': 0.33, '4100251017': 0.66, '4100251018': 0.66, '4100251019': 0.66, '4100251020': 0.33, '4100251021': 0.33, '4100251022': 0.66, '4100251024': 0.33, '4100251026': 1.0, '4100251027': 0.33, '4100251028': 0.33, '4100251029': 0.33, '4100251030': 0.66, '4100251031': 0.66, '4100251032': 0.33, '4100251033': 0.33, '4100251034': 0.66, '4100251035': 0.66, '4100251036': 0.33, '4100251038': 0.33, '4100251039': 0.66, '4100251040': 0.66, '4100251041': 0.33, '4100251042': 0.66, '4100251044': 0.66, '4100251046': 0.33, '4100251047': 0.66, '4100251048': 0.66, '4100251049': 0.33, '4100251051': 0.66, '4100251052': 0.66, '4100251053': 1.0, '4100251054': 1.0, '4100251056': 0.66, '4100251057': 0.0, '4100251059': 0.66, '4100251060': 0.66, '4100251061': 0.33, '4100251062': 0.66, '4100251063': 0.66, '4100251064': 0.66, '4100251065': 0.66, '4100251068': 0.33, '4100251069': 0.66, '4100251070': 0.66, '4100252001': 0.66, '4100252003': 0.66, '4100252004': 1.0, '4100252005': 0.66, '4100252007': 1.0, '4100252010': 0.66, '4100252011': 0.66, '4100252012': 1.0, '4100252013': 0.66, '4100252014': 0.66, '4100252015': 0.66, '4100252016': 0.66, '4100252019': 0.66, '4100252021': 0.66, '4100252022': 0.66, '4100252023': 0.66, '4100252024': 1.0, '4100252027': 0.66, '4100252031': 1.0, '4100252032': 0.66, '4100252033': 0.66, '4100252034': 0.66, '4100252035': 0.66, '4100252036': 0.33, '4100252037': 1.0, '4100252038': 0.66, '4100252039': 0.66, '4100252040': 0.66, '4100252041': 0.33, '4100252043': 1.0, '4100252044': 0.33, '4100252045': 1.0, '4100252048': 0.66, '4100252049': 1.0, '4100252050': 1.0, '4100252051': 1.0, '4100252053': 0.66, '4100252054': 0.66, '4100252055': 0.66, '4100252056': 1.0, '4100252057': 1.0, '4100252058': 0.66, '4100252060': 0.66, '4100252061': 0.33, '4100252062': 1.0, '4100252063': 1.0, '4100252066': 0.66, '4100252069': 0.66, '4100252070': 1.0, '4100252071': 0.66, '4100252072': 1.0, '4100252073': 0.66, '4100252074': 0.66, '4100252075': 0.66, '4100252076': 0.66, '4100252078': 0.66, '4100252081': 0.66, '4100261001': 0.66, '4100261002': 0.66, '4100261003': 1.0, '4100261004': 0.66, '4100261005': 0.33, '4100261006': 0.33, '4100261007': 1.0, '4100261010': 0.66, '4100261012': 0.66, '4100261013': 0.66, '4100261015': 0.66, '4100261016': 1.0, '4100261020': 0.66, '4100261023': 0.66, '4100261025': 0.66, '4100261027': 0.33, '4100261028': 0.66, '4100261029': 0.66, '4100261030': 0.33, '4100261031': 0.66, '4100261032': 0.66, '4100261033': 1.0, '4100261034': 0.33, '4100261035': 1.0, '4100261036': 0.66, '4100261038': 0.66, '4100261041': 0.33, '4100261044': 0.66, '4100261045': 0.66, '4100261046': 0.66, '4100261047': 0.66, '4100261048': 0.66, '4100261049': 0.66, '4100261050': 0.33, '4100261055': 1.0, '4100261056': 0.33, '4100261057': 0.66, '4100261058': 0.33, '4100261060': 0.66, '4100261061': 0.66, '4100262001': 0.66, '4100262003': 0.66, '4100262004': 0.33, '4100262006': 0.0, '4100262007': 0.66, '4100262008': 0.66, '4100262009': 0.66, '4100262010': 0.66, '4100262014': 0.66, '4100262015': 1.0, '4100262016': 0.66, '4100262017': 1.0, '4100262018': 0.66, '4100262019': 0.66, '4100262020': 0.66, '4100262022': 0.66, '4100262023': 0.66, '4100262024': 0.66, '4100262025': 0.66, '4100262027': 0.66, '4100262034': 0.33, '4100262035': 0.66, '4100262037': 1.0, '4100262038': 0.66, '4100262040': 0.66, '4100262041': 0.66, '4100262042': 0.66, '4100262043': 1.0, '4100262044': 0.66, '4100262045': 0.66, '4100262046': 1.0, '4100262047': 0.66, '4100262052': 0.66, '4100262053': 0.66, '4100262056': 0.33, '4100262057': 0.66, '4100262060': 0.66, '4100262063': 0.66, '4100262064': 0.66, '4100262065': 0.66, '4100262066': 0.66, '4100262067': 0.66, '4100262068': 0.66, '4100262069': 1.0, '4100262070': 0.66, '4100271007': 0.66, '4100271008': 0.66, '4100271009': 0.66, '4100271010': 1.0, '4100271011': 1.0, '4100271012': 0.66, '4100271026': 0.66, '4100271028': 0.66, '4100271029': 0.66, '4100271030': 0.66, '4100271032': 1.0, '4100271033': 1.0, '4100271034': 1.0, '4100271038': 0.33, '4100271039': 0.66, '4100271041': 0.33, '4100271042': 0.66, '4100271043': 1.0, '4100271056': 0.33, '4100272024': 0.66, '4100272029': 1.0, '4100272033': 1.0, '4100272034': 0.66, '4100272036': 1.0, '4100272037': 0.66, '4100272043': 1.0, '4100272051': 0.66, '4100272052': 0.66, '4100272056': 1.0, '4100281001': 0.66, '4100281002': 0.66, '4100281015': 0.66, '4100281016': 0.66, '4100281019': 1.0, '4100281022': 0.66, '4100281023': 0.66, '4100281027': 0.66, '4100281029': 0.66, '4100281030': 0.66, '4100281032': 0.33, '4100281033': 0.66, '4100281034': 0.66, '4100281035': 0.66, '4100281036': 0.66, '4100281037': 0.66, '4100281041': 1.0, '4100281042': 0.66, '4100281045': 0.66, '4100281046': 0.33, '4100281048': 0.66, '4100281049': 0.66, '4100281050': 0.66, '4100281052': 0.66, '4100281053': 0.33, '4100281054': 0.66, '4100281057': 0.66, '4100281058': 0.66, '4100281059': 0.66, '4100281060': 1.0, '4100281061': 0.66, '4100281062': 0.66, '4100281063': 0.66, '4100281066': 0.66, '4100281067': 0.0, '4100281068': 0.66, '4100281070': 0.33, '4100281072': 0.66, '4100281075': 0.66, '4100281076': 0.33, '4100281078': 1.0, '4100281079': 0.66, '4100281080': 0.66, '4100281081': 0.66, '4100282001': 0.66, '4100282002': 0.66, '4100282003': 1.0, '4100282004': 0.66, '4100282005': 0.66, '4100282007': 0.66, '4100282008': 0.66, '4100282009': 0.33, '4100282012': 0.66, '4100282013': 0.66, '4100282014': 1.0, '4100282015': 0.66, '4100282017': 1.0, '4100282018': 0.66, '4100282019': 1.0, '4100282020': 1.0, '4100282021': 1.0, '4100282022': 1.0, '4100282023': 0.66, '4100282024': 1.0, '4100282033': 0.66, '4100282043': 0.66, '4100282048': 0.66, '4100282053': 1.0, '4100282057': 0.66, '4100282058': 0.66, '4100282066': 0.33, '4100282067': 0.66, '4100282068': 0.66, '4100282070': 0.66, '4100291002': 0.66, '4100291003': 1.0, '4100291004': 0.66, '4100291005': 0.66, '4100291006': 0.33, '4100291007': 0.33, '4100291008': 0.66, '4100291009': 0.66, '4100291010': 0.33, '4100291011': 0.66, '4100291012': 0.66, '4100291014': 0.66, '4100291015': 0.66, '4100291016': 0.66, '4100291017': 0.66, '4100291018': 0.66, '4100291019': 0.33, '4100291021': 0.66, '4100291022': 0.66, '4100291025': 0.66, '4100291026': 0.33, '4100291027': 0.33, '4100291028': 0.66, '4100291032': 0.33, '4100291033': 0.66, '4100291034': 0.66, '4100291036': 0.33, '4100291037': 0.66, '4100291039': 0.66, '4100291040': 0.66, '4100291041': 0.33, '4100291043': 0.66, '4100291046': 0.66, '4100291047': 0.66, '4100291048': 0.66, '4100291049': 0.66, '4100291050': 0.66, '4100291051': 0.66, '4100291055': 0.66, '4100291056': 0.66, '4100291059': 0.66, '4100291060': 1.0, '4100291061': 0.66, '4100291062': 0.66, '4100291063': 1.0, '4100291064': 1.0, '4100291065': 0.66, '4100291070': 0.33, '4100291073': 0.33, '4100291074': 0.66, '4100291076': 0.66, '4100291077': 0.66, '4100291078': 0.33, '4100291079': 0.66, '4100291080': 0.66, '4100291081': 0.33, '4100291082': 0.33, '4100291083': 0.66, '4100291084': 0.33, '4100292001': 0.66, '4100292003': 0.66, '4100292005': 0.66, '4100292008': 0.66, '4100292010': 0.66, '4100292016': 0.66, '4100292019': 0.66, '4100292020': 0.66, '4100292021': 1.0, '4100292022': 0.66, '4100292023': 0.66, '4100292024': 1.0, '4100292025': 0.66, '4100292026': 0.66, '4100292027': 0.66, '4100292028': 0.66, '4100292035': 0.66, '4100292036': 1.0, '4100292037': 0.66, '4100292040': 0.66, '4100292041': 0.66, '4100292042': 1.0, '4100292043': 0.66, '4100292044': 1.0, '4100292045': 1.0, '4100292046': 1.0, '4100292048': 0.33, '4100292049': 0.66, '4100292050': 0.66, '4100292052': 0.66, '4100292053': 0.66, '4100292056': 0.66, '4100292057': 0.66, '4100292059': 0.66, '4100292060': 0.66, '4100292061': 1.0, '4100292062': 0.66, '4100292063': 0.66, '4100292064': 1.0, '4100292065': 0.66, '4100292066': 1.0, '4100292067': 1.0, '4100292068': 1.0, '4100292069': 0.66, '4100292070': 0.66, '4100292071': 0.66, '4100292072': 1.0, '4100292073': 1.0, '4100292074': 0.66, '4100292075': 1.0, '4100292077': 0.66, '4100292078': 1.0, '4100292079': 0.66, '4100292081': 1.0, '4100292083': 1.0, '4100292084': 0.66, '4100292085': 1.0, '4100292087': 0.66, '4100292088': 0.66, '4100302002': 1.0, '4100302013': 0.33, '4100302014': 1.0, '4100302016': 0.33, '4100302017': 0.66, '4100302018': 0.33, '4100302019': 0.66, '4100302020': 0.66, '4100302024': 0.66, '4100302028': 1.0, '4100302030': 0.33, '4100302040': 0.0, '4100302041': 0.66, '4100302042': 0.0, '4100302043': 0.33, '4100302044': 0.0, '4100302045': 0.0, '4100302046': 0.66, '4100302047': 0.66, '4100302048': 0.33, '4100302049': 1.0, '4100302050': 0.66, '4100302051': 0.66, '4100302052': 0.66, '4100302053': 0.66, '4100302054': 1.0, '4100302055': 0.33, '4100302058': 0.0, '4100302061': 0.66, '4100302063': 0.66, '4100302064': 0.0, '4100302066': 0.33, '4100302067': 1.0, '4100302068': 0.66, '4100302069': 1.0, '4100321001': 0.33, '4100321002': 0.66, '4100321003': 1.0, '4100321004': 0.66, '4100321005': 1.0, '4100321006': 0.66, '4100321008': 0.66, '4100321009': 0.33, '4100321010': 1.0, '4100321011': 0.66, '4100321012': 0.66, '4100321014': 0.66, '4100321015': 1.0, '4100321016': 0.66, '4100321019': 0.33, '4100321020': 0.66, '4100321021': 0.66, '4100321022': 1.0, '4100321023': 1.0, '4100321024': 1.0, '4100321026': 1.0, '4100321027': 1.0, '4100321028': 1.0, '4100321029': 0.66, '4100321030': 1.0, '4100321032': 1.0, '4100321033': 0.66, '4100321034': 0.66, '4100321037': 1.0, '4100321038': 1.0, '4100321039': 0.66, '4100321041': 1.0, '4100321042': 0.33, '4100321043': 0.33, '4100321044': 0.33, '4100321045': 0.66, '4100321046': 1.0, '4100321049': 1.0, '4100321051': 0.66, '4100321052': 1.0, '4100321053': 0.66, '4100322001': 0.66, '4100322007': 1.0, '4100322025': 0.66, '4100322031': 0.66, '4100322032': 0.33, '4100322033': 0.66, '4100322034': 0.66, '4100322035': 0.66, '4100322037': 0.66, '4100322038': 0.66, '4100322039': 0.66, '4100322040': 1.0, '4100322041': 0.66, '4100322042': 1.0, '4100322044': 1.0, '4100322045': 1.0, '4100322048': 0.66, '4100322051': 1.0, '4100322052': 1.0, '4100322053': 0.66, '4100322055': 0.66, '4100322056': 0.66, '4100322057': 0.66, '4100322058': 0.66, '4100322059': 1.0, '4100322060': 0.66, '4100322061': 0.66, '4110211001': 0.33, '4110211004': 0.33, '4110211005': 0.33, '4110211006': 0.66, '4110211007': 0.66, '4110211008': 0.66, '4110211009': 0.66, '4110211011': 0.66, '4110211013': 0.33, '4110211014': 0.33, '4110211015': 0.0, '4110211016': 1.0, '4110211018': 0.66, '4110211019': 1.0, '4110211020': 0.66, '4110211021': 0.33, '4110211022': 0.33, '4110211023': 0.33, '4110211024': 0.66, '4110211025': 0.0, '4110211026': 0.66, '4110211027': 0.33, '4110211028': 0.33, '4110211030': 0.66, '4110211032': 0.66, '4110211033': 0.66, '4110211034': 0.66, '4110211035': 0.66, '4110211036': 0.33, '4110211037': 0.66, '4110211038': 0.33, '4110211039': 0.33, '4110211040': 0.0, '4110211041': 0.66, '4110211043': 0.66, '4110211044': 1.0, '4110211045': 0.33, '4110211046': 1.0, '4110211047': 1.0, '4110211048': 0.66, '4110211049': 0.66, '4110211050': 0.66, '4110211051': 1.0, '4110211052': 0.66, '4110211053': 0.33, '4110211054': 0.66, '4110211055': 0.33, '4110211056': 1.0, '4110211057': 0.66, '4110211058': 1.0, '4110211060': 0.66, '4110211061': 0.0, '4110211062': 0.66, '4110211063': 0.66, '4110211064': 0.66, '4110211065': 0.66, '4110211067': 1.0, '4110211068': 0.66, '4110211072': 0.66, '4110211073': 0.66, '4110211075': 0.33, '4110211076': 1.0, '4110211078': 0.33, '4110211079': 0.66, '4110211080': 0.66, '4110212003': 0.66, '4110212004': 0.66, '4110212007': 0.66, '4110212008': 0.66, '4110212009': 0.66, '4110212010': 0.66, '4110212011': 0.66, '4110212013': 1.0, '4110212014': 1.0, '4110212015': 0.66, '4110212016': 0.66, '4110212017': 0.66, '4110212018': 0.66, '4110212019': 0.66, '4110212021': 1.0, '4110212023': 0.66, '4110212024': 0.66, '4110212026': 0.66, '4110212027': 0.66, '4110212029': 0.66, '4110212030': 1.0, '4110212033': 0.66, '4110212034': 0.33, '4110212035': 0.66, '4110212036': 0.33, '4110212038': 0.66, '4110212039': 1.0, '4110212041': 0.66, '4110212042': 0.66, '4110212044': 1.0, '4110212045': 0.66, '4110212046': 0.66, '4110212047': 1.0, '4110212049': 0.33, '4110212050': 0.66, '4110212051': 0.33, '4110212052': 1.0, '4110212053': 0.66, '4110212054': 0.66, '4110212055': 0.66, '4110212056': 0.66, '4110212059': 0.66, '4110212061': 0.66, '4110212062': 0.33, '4110212063': 0.66, '4110212064': 0.66, '4110212069': 0.66, '4110311001': 1.0, '4110311003': 1.0, '4110311004': 1.0, '4110311005': 0.66, '4110311006': 0.33, '4110311012': 0.66, '4110311015': 1.0, '4110311017': 0.66, '4110311018': 1.0, '4110311019': 0.66, '4110311020': 0.66, '4110311021': 0.66, '4110311023': 0.33, '4110311030': 0.66, '4110311031': 1.0, '4110311032': 0.66, '4110311033': 0.66, '4110311034': 0.66, '4110311036': 1.0, '4110311037': 1.0, '4110311038': 1.0, '4110311042': 1.0, '4110311043': 1.0, '4110311044': 0.66, '4110311045': 0.33, '4110311046': 0.66, '4110311048': 0.33, '4110311049': 0.66, '4110311050': 0.66, '4110311053': 1.0, '4110311054': 0.33, '4110311057': 0.66, '4110311061': 0.66, '4110311062': 0.33, '4110311064': 0.66, '4110311065': 0.66, '4110311067': 0.66, '4110311068': 0.66, '4110311072': 0.66, '4110312006': 1.0, '4110312007': 0.66, '4110312008': 0.66, '4110312009': 0.33, '4110312013': 0.66, '4110312023': 1.0, '4110312024': 1.0, '4110312025': 1.0, '4110312027': 0.66, '4110312030': 1.0, '4110312031': 0.66, '4110312048': 0.66, '4110312049': 0.66, '4110312078': 1.0, '414081010': 1.0, '414081011': 1.0, '4140810110': 1.0, '4140810114': 1.0, '4140810117': 1.0, '4140810122': 1.0, '4140810124': 1.0, '4140810125': 1.0, '4140810126': 1.0, '4140810127': 1.0, '4140810128': 1.0, '4140810129': 0.66, '414081013': 0.66, '4140810132': 1.0, '4140810133': 1.0, '4140810135': 0.66, '4140810136': 1.0, '4140810138': 1.0, '4140810139': 0.66, '4140810140': 0.66, '4140810142': 1.0, '4140810143': 1.0, '4140810144': 1.0, '4140810145': 1.0, '4140810146': 1.0, '4140810148': 1.0, '414081015': 0.66, '4140810150': 1.0, '4140810151': 1.0, '4140810152': 1.0, '4140810153': 0.33, '4140810154': 1.0, '4140810158': 1.0, '4140810159': 0.66, '414081016': 1.0, '4140810162': 0.33, '4140810163': 1.0, '4140810164': 1.0, '4140810165': 1.0, '414081017': 1.0, '4140810171': 0.66, '4140810173': 1.0, '4140810175': 1.0, '4140810176': 1.0, '4140810179': 0.66, '414081018': 1.0, '4140810180': 1.0, '4140810181': 1.0, '4140810182': 1.0, '4140810183': 1.0, '4140810184': 0.66, '4140810185': 1.0, '414081019': 1.0, '414081021': 1.0, '4140810210': 0.33, '4140810211': 1.0, '4140810212': 0.66, '4140810215': 0.66, '4140810217': 0.33, '4140810219': 0.33, '4140810220': 1.0, '4140810221': 0.66, '4140810222': 1.0, '4140810223': 1.0, '4140810224': 1.0, '4140810225': 0.66, '4140810226': 0.66, '4140810228': 1.0, '4140810229': 1.0, '414081023': 1.0, '4140810230': 1.0, '4140810233': 1.0, '4140810234': 0.66, '4140810237': 1.0, '4140810239': 1.0, '4140810240': 1.0, '4140810242': 0.66, '4140810244': 0.66, '4140810246': 1.0, '4140810247': 0.66, '4140810249': 0.66, '414081025': 1.0, '4140810250': 0.66, '4140810251': 1.0, '4140810252': 1.0, '4140810253': 0.66, '4140810254': 1.0, '4140810255': 1.0, '4140810256': 1.0, '4140810257': 0.66, '4140810258': 1.0, '4140810259': 1.0, '414081026': 1.0, '4140810264': 1.0, '4140810265': 1.0, '4140810266': 1.0, '4140810268': 1.0, '4140810269': 1.0, '414081027': 1.0, '4140810270': 0.66, '4140810271': 1.0, '4140810272': 0.33, '4140810273': 0.66, '4140810274': 1.0, '4140810276': 1.0, '4140810277': 1.0, '4140810278': 0.66, '4140810279': 1.0, '414081028': 0.66, '4140810280': 1.0, '414081029': 0.66, '459999011': 1.0, '4599990110': 0.66, '4599990112': 1.0, '4599990113': 1.0, '4599990114': 1.0, '4599990116': 1.0, '4599990117': 1.0, '4599990118': 1.0, '4599990119': 1.0, '459999012': 0.66, '4599990120': 0.66, '4599990125': 1.0, '4599990126': 0.66, '4599990128': 1.0, '4599990129': 0.66, '459999013': 1.0, '4599990130': 1.0, '4599990131': 1.0, '4599990132': 0.33, '4599990133': 0.66, '4599990134': 1.0, '4599990136': 1.0, '4599990137': 1.0, '4599990139': 1.0, '4599990141': 1.0, '4599990144': 1.0, '4599990146': 1.0, '4599990148': 0.66, '4599990149': 1.0, '4599990153': 1.0, '4599990154': 1.0, '4599990155': 1.0, '459999016': 1.0, '4599990163': 0.66, '4599990165': 1.0, '4599990166': 1.0, '4599990168': 1.0, '459999017': 0.66, '4599990171': 1.0, '459999021': 1.0, '4599990211': 1.0, '4599990212': 1.0, '4599990214': 0.66, '4599990216': 1.0, '4599990218': 1.0, '459999022': 1.0, '4599990221': 1.0, '4599990222': 1.0, '4599990223': 1.0, '4599990224': 1.0, '4599990226': 1.0, '4599990231': 1.0, '4599990233': 0.66, '4599990234': 1.0, '4599990235': 0.33, '4599990238': 1.0, '459999024': 1.0, '4599990240': 1.0, '4599990241': 1.0, '4599990243': 0.66, '4599990244': 1.0, '4599990245': 0.66, '4599990246': 1.0, '4599990247': 1.0, '4599990248': 0.66, '4599990249': 1.0, '459999025': 1.0, '4599990253': 1.0, '4599990254': 1.0, '4599990255': 0.66, '4599990256': 1.0, '4599990263': 1.0, '4599990264': 0.66, '4599990269': 0.66, '4599990270': 1.0, '4599990272': 0.66, '4599990273': 1.0, '4599990274': 1.0, '4599990275': 1.0, '4599990276': 0.66, '459999028': 0.66, '4599990283': 1.0, '5000391001': 0.66, '5000391002': 0.66, '5000391004': 1.0, '5000391005': 0.66, '5000391007': 1.0, '5000391008': 0.66, '5000391010': 0.66, '5000391012': 0.66, '5000391013': 1.0, '5000391014': 0.66, '5000391015': 1.0, '5000391016': 1.0, '5000391017': 0.33, '5000391019': 0.66, '5000391020': 0.66, '5000391022': 1.0, '5000391023': 0.66, '5000391024': 0.66, '5000391026': 0.66, '5000391028': 1.0, '5000391029': 0.66, '5000391030': 1.0, '5000391031': 1.0, '5000391032': 1.0, '5000391034': 0.66, '5000391035': 1.0, '5000391036': 0.66, '5000391037': 1.0, '5000391038': 0.66, '5000391040': 0.66, '5000391045': 0.33, '5000391046': 0.66, '5000391047': 1.0, '5000391049': 0.66, '5000391050': 0.66, '5000391054': 0.66, '5000391055': 0.33, '5000391056': 0.33, '5000391059': 0.66, '5000391060': 0.33, '5000391061': 0.66, '5000391062': 1.0, '5000391063': 1.0, '5000391064': 0.66, '5000391065': 0.66, '5000391066': 1.0, '5000391067': 0.66, '5000391068': 1.0, '5000391069': 1.0, '5000391070': 0.66, '5000391071': 0.66, '5000391072': 0.66, '5000391073': 0.66, '5000391074': 0.66, '5000391076': 0.66, '5000391078': 0.66, '5000391079': 0.66, '5000391080': 1.0, '5000391081': 0.66, '5000392001': 0.66, '5000392002': 0.66, '5000392003': 1.0, '5000392006': 0.66, '5000392007': 0.66, '5000392010': 1.0, '5000392011': 0.66, '5000392015': 0.66, '5000392016': 0.66, '5000392017': 0.66, '5000392018': 0.66, '5000392019': 0.66, '5000392020': 0.66, '5000392021': 0.66, '5000392022': 0.66, '5000392025': 0.66, '5000392026': 0.66, '5000392027': 0.66, '5000392029': 0.66, '5000392033': 0.33, '5000392035': 0.66, '5000392036': 1.0, '5000392038': 0.66, '5000392039': 0.66, '5000392040': 1.0, '5000392041': 1.0, '5000392042': 0.66, '5000392044': 0.66, '5000392047': 0.66, '5000392048': 0.66, '5000392049': 1.0, '5000392050': 1.0, '5000392051': 1.0, '5000392052': 0.33, '5000392053': 0.66, '5000392054': 0.66, '5000392055': 0.66, '5000392056': 0.66, '5000392058': 0.66, '5000392060': 0.33, '5000392062': 0.66, '5000392063': 0.66, '5000392064': 0.66, '5000392065': 0.66, '5000392066': 0.66, '5000392067': 0.66, '5000392070': 0.66, '5000392071': 0.66, '5000392072': 0.66, '5000431019': 0.66, '5000431020': 1.0, '5000431021': 1.0, '5000431022': 0.66, '5000431023': 1.0, '5000431025': 0.66, '5000431026': 0.66, '5000431049': 1.0, '5000431050': 1.0, '5000432001': 1.0, '5000432003': 0.66, '5000432006': 0.66, '5000432059': 1.0, '5000441001': 0.66, '5000441002': 0.66, '5000441003': 0.66, '5000441005': 0.66, '5000441006': 0.66, '5000441007': 0.66, '5000441008': 0.66, '5000441009': 1.0, '5000441010': 0.66, '5000441012': 0.66, '5000441013': 0.66, '5000441014': 0.66, '5000441015': 0.66, '5000441016': 1.0, '5000441017': 0.66, '5000441018': 1.0, '5000441021': 1.0, '5000441022': 0.66, '5000441023': 1.0, '5000441024': 0.33, '5000441027': 1.0, '5000441030': 0.66, '5000441031': 0.66, '5000441032': 0.66, '5000441033': 0.66, '5000441034': 0.66, '5000441035': 1.0, '5000441037': 0.66, '5000441038': 1.0, '5000441039': 1.0, '5000441040': 1.0, '5000441041': 1.0, '5000441042': 0.66, '5000441043': 0.66, '5000441044': 0.66, '5000441045': 0.66, '5000441046': 1.0, '5000441047': 0.66, '5000441048': 0.66, '5000441050': 0.66, '5000441051': 0.66, '5000441052': 0.66, '5000441053': 1.0, '5000441054': 0.66, '5000441055': 1.0, '5000441058': 0.33, '5000441059': 0.66, '5000441061': 1.0, '5000441062': 0.66, '5000441064': 0.66, '5000441065': 0.66, '5000441066': 0.66, '5000441067': 0.33, '5000441068': 0.66, '5000441069': 0.66, '5000441070': 1.0, '5000441071': 1.0, '5000441072': 1.0, '5000442001': 1.0, '5000442002': 0.66, '5000442003': 0.66, '5000442004': 0.66, '5000442005': 0.66, '5000442007': 0.66, '5000442008': 0.66, '5000442009': 1.0, '5000442010': 0.66, '5000442014': 1.0, '5000442015': 0.66, '5000442016': 0.66, '5000442019': 0.66, '5000442021': 0.66, '5000442022': 1.0, '5000442024': 0.66, '5000442025': 0.66, '5000442026': 0.66, '5000442027': 1.0, '5000442028': 0.66, '5000442029': 1.0, '5000442033': 0.66, '5000442034': 1.0, '5000442035': 1.0, '5000442036': 0.66, '5000442037': 1.0, '5000442038': 1.0, '5000442039': 1.0, '5000442040': 1.0, '5000442042': 0.66, '5000442043': 1.0, '5000442045': 1.0, '5000442047': 0.66, '5000442048': 0.66, '5000442050': 0.66, '5000442051': 0.66, '5000442052': 0.66, '5000442053': 0.66, '5000442054': 1.0, '5000442055': 1.0, '5000442056': 0.66, '5000442057': 1.0, '5000442058': 1.0, '5000442059': 1.0, '5000442060': 0.66, '5000442062': 0.66, '5000442063': 1.0, '5000442064': 1.0, '5000442065': 1.0, '5000442066': 1.0, '5000442067': 0.66, '5000442068': 1.0, '5000442069': 1.0, '5000442070': 1.0, '5000442072': 0.66, '5000442073': 1.0, '5000442074': 0.66, '5000442075': 0.66, '5000442076': 0.66, '5000442077': 0.66, '5000442078': 0.66, '5000671001': 1.0, '5000671002': 0.66, '5000671003': 0.66, '5000671004': 1.0, '5000671005': 0.66, '5000671006': 0.66, '5000671008': 1.0, '5000671009': 0.66, '5000671010': 1.0, '5000671011': 1.0, '5000671012': 1.0, '5000671013': 0.66, '5000671014': 1.0, '5000671015': 1.0, '5000671016': 0.66, '5000671017': 0.66, '5000671018': 1.0, '5000671019': 0.66, '5000671020': 0.66, '5000671022': 0.66, '5000671023': 1.0, '5000671024': 0.66, '5000671026': 1.0, '5000671027': 0.66, '5000671028': 1.0, '5000671029': 0.66, '5000671030': 1.0, '5000671031': 0.66, '5000671032': 1.0, '5000671033': 1.0, '5000671034': 0.66, '5000671035': 1.0, '5000671036': 0.66, '5000671037': 0.66, '5000671038': 0.66, '5000671039': 0.66, '5000671040': 0.66, '5000671041': 0.33, '5000671042': 0.33, '5000671043': 0.66, '5000671046': 0.66, '5000671047': 0.66, '5000671048': 0.33, '5000671049': 0.33, '5000671050': 0.66, '5000671051': 0.66, '5000671053': 0.66, '5000671055': 0.66, '5000671056': 1.0, '5000671057': 0.66, '5000671058': 0.33, '5000671059': 0.66, '5000671060': 0.66, '5000671061': 0.33, '5000671062': 0.66, '5000671063': 0.66, '5000671064': 1.0, '5000671065': 0.66, '5000671066': 0.66, '5000671067': 0.66, '5000671069': 0.33, '5000671070': 0.33, '5000671071': 0.66, '5000672002': 0.66, '5000672004': 0.66, '5000672005': 0.66, '5000672006': 1.0, '5000672007': 0.66, '5000672008': 0.66, '5000672010': 0.66, '5000672011': 1.0, '5000672012': 0.66, '5000672013': 1.0, '5000672014': 1.0, '5000672016': 0.66, '5000672017': 0.66, '5000672019': 1.0, '5000672020': 1.0, '5000672021': 1.0, '5000672022': 1.0, '5000672023': 0.66, '5000672024': 0.66, '5000672025': 1.0, '5000672026': 1.0, '5000672027': 0.66, '5000672030': 0.66, '5000672031': 0.66, '5000672033': 0.66, '5000672034': 0.66, '5000672035': 1.0, '5000672036': 0.66, '5000672038': 1.0, '5000672042': 1.0, '5000672043': 1.0, '5000672044': 1.0, '5000672045': 1.0, '5000672046': 0.66, '5000672047': 0.66, '5000672048': 0.66, '5000672049': 0.66, '5000672050': 0.66, '5000672051': 1.0, '5000672052': 1.0, '5000672053': 0.66, '5000672054': 1.0, '5000672055': 1.0, '5000672056': 1.0, '5000672057': 0.66, '5000672058': 0.66, '5000672059': 0.66, '5000672060': 0.66, '5000672062': 1.0, '5000672064': 0.66, '5000672065': 0.66, '5000672066': 0.66, '5000672067': 0.66, '5000672068': 0.66, '5000672070': 1.0, '5000672071': 0.66, '5000672072': 0.66, '5000672074': 1.0, '5000672075': 1.0, '5000672076': 1.0, '5000672077': 0.66, '5000672081': 0.66, '5000672082': 0.66, '5000951001': 0.66, '5000951002': 0.66, '5000951003': 1.0, '5000951004': 0.66, '5000951005': 0.66, '5000951006': 0.66, '5000951007': 1.0, '5000951008': 0.66, '5000951009': 1.0, '5000951010': 0.66, '5000951011': 1.0, '5000951012': 0.66, '5000951013': 0.66, '5000951015': 1.0, '5000951016': 0.66, '5000951017': 0.66, '5000951018': 0.66, '5000951019': 0.33, '5000951021': 0.66, '5000951023': 0.33, '5000951024': 0.33, '5000951025': 0.66, '5000951027': 0.33, '5000951028': 1.0, '5000951033': 0.66, '5000951034': 0.66, '5000951035': 0.66, '5000951037': 0.66, '5000951039': 0.66, '5000951040': 1.0, '5000951042': 0.66, '5000951043': 1.0, '5000951044': 0.66, '5000951045': 0.66, '5000951047': 0.66, '5000951049': 1.0, '5000951051': 1.0, '5000951052': 0.66, '5000951053': 0.66, '5000951054': 1.0, '5000951055': 0.66, '5000951056': 1.0, '5000951057': 1.0, '5000951058': 1.0, '5000951060': 1.0, '5000951061': 0.66, '5000951062': 0.66, '5000951063': 0.66, '5000951065': 1.0, '5000951066': 0.66, '5000951067': 0.66, '5000952002': 0.66, '5000952003': 0.66, '5000952004': 0.66, '5000952005': 1.0, '5000952007': 1.0, '5000952008': 1.0, '5000952011': 0.66, '5000952013': 0.66, '5000952014': 0.66, '5000952015': 1.0, '5000952016': 0.66, '5000952017': 0.66, '5000952018': 0.66, '5000952020': 0.66, '5000952021': 0.66, '5000952022': 0.66, '5000952023': 1.0, '5000952024': 0.66, '5000952025': 1.0, '5000952026': 1.0, '5000952027': 0.66, '5000952028': 0.66, '5000952029': 0.66, '5000952031': 0.66, '5000952032': 0.66, '5000952033': 0.66, '5000952034': 0.33, '5000952035': 0.66, '5000952036': 0.66, '5000952038': 1.0, '5000952040': 1.0, '5000952041': 0.66, '5000952042': 0.66, '5000952044': 0.66, '5000952045': 0.66, '5000952046': 1.0, '5000952048': 0.66, '5000952050': 1.0, '5000952052': 0.66, '5000952053': 1.0, '5000952054': 0.66, '5000952055': 0.66, '5000952060': 0.66, '5000952061': 0.66, '5000952062': 0.33, '5000952063': 0.66, '5000952064': 1.0, '5000952065': 0.66, '5000952066': 0.66, '5000952068': 1.0, '5000952069': 0.66, '5000952070': 1.0, '5000952071': 0.66, '5000952072': 1.0, '5000952073': 0.66, '5000952075': 0.66, '5000952076': 1.0, '5000952077': 0.66, '5000952078': 0.66, '5000952080': 1.0, '5000952083': 0.33, '5100091001': 0.66, '5100091003': 1.0, '5100091004': 1.0, '5100091005': 0.66, '5100091006': 0.66, '5100091007': 1.0, '5100091008': 1.0, '5100091009': 0.66, '5100091010': 1.0, '5100091012': 0.66, '5100091017': 0.66, '5100091019': 0.66, '5100091020': 1.0, '5100091025': 0.66, '5100091026': 1.0, '5100091027': 0.66, '5100091028': 0.66, '5100091032': 1.0, '5100091033': 0.66, '5100091034': 1.0, '5100091035': 1.0, '5100091036': 1.0, '5100091038': 1.0, '5100091039': 1.0, '5100091042': 1.0, '5100091046': 1.0, '5100091049': 0.33, '5100091050': 0.66, '5100091051': 0.66, '5100091053': 0.66, '5100091055': 1.0, '5100091056': 0.66, '5100091057': 0.66, '5100091058': 0.66, '5100091059': 0.66, '5100091062': 0.66, '5100091064': 0.66, '5100091065': 1.0, '5100091066': 0.66, '5100091067': 1.0, '5100091068': 0.66, '5100091069': 1.0, '5100092002': 1.0, '5100092003': 1.0, '5100092005': 1.0, '5100092006': 1.0, '5100092008': 1.0, '5100092010': 1.0, '5100092011': 0.66, '5100092013': 1.0, '5100092017': 0.66, '5100092019': 1.0, '5100092021': 0.66, '5100092022': 1.0, '5100092023': 1.0, '5100092026': 1.0, '5100092027': 1.0, '5100092032': 0.66, '5100092033': 1.0, '5100092034': 0.66, '5100092035': 0.66, '5100092037': 0.66, '5100092038': 0.66, '5100092039': 1.0, '5100092040': 1.0, '5100092041': 0.66, '5100092042': 1.0, '5100092043': 0.66, '5100092044': 1.0, '5100092045': 1.0, '5100092053': 0.66, '5100092056': 0.66, '5100092057': 0.66, '5100092060': 1.0, '5100092061': 1.0, '5100092062': 0.66, '5100092063': 0.66, '5100092064': 1.0, '5100092065': 0.66, '5100092067': 1.0, '5100092068': 0.66, '5100092069': 1.0, '5100092071': 1.0, '5100092072': 1.0, '5100341002': 0.66, '5100341003': 0.66, '5100341004': 1.0, '5100341005': 0.66, '5100341006': 0.66, '5100341008': 0.66, '5100341009': 0.66, '5100341010': 0.66, '5100341012': 1.0, '5100341013': 0.66, '5100341014': 1.0, '5100341015': 0.66, '5100341016': 0.66, '5100341017': 0.66, '5100341019': 0.66, '5100341020': 1.0, '5100341021': 1.0, '5100341022': 0.66, '5100341023': 0.66, '5100341024': 1.0, '5100341025': 0.66, '5100341026': 1.0, '5100341027': 1.0, '5100341028': 0.66, '5100341030': 0.66, '5100341031': 1.0, '5100341032': 0.66, '5100341033': 0.66, '5100341034': 1.0, '5100341035': 0.66, '5100341037': 0.66, '5100341038': 0.66, '5100341039': 1.0, '5100341042': 0.66, '5100341043': 0.33, '5100341046': 0.66, '5100341048': 1.0, '5100341050': 1.0, '5100341052': 1.0, '5100341054': 1.0, '5100341055': 1.0, '5100341056': 0.66, '5100341057': 0.66, '5100341058': 1.0, '5100341061': 0.66, '5100341062': 1.0, '5100341065': 1.0, '5100341067': 1.0, '5100341068': 1.0, '5100341070': 1.0, '5100341071': 1.0, '5100341072': 1.0, '5100341074': 0.33, '5100341075': 1.0, '5100341076': 1.0, '5100341077': 0.66, '5100341078': 1.0, '5100341079': 1.0, '5100342002': 1.0, '5100342003': 0.66, '5100342007': 1.0, '5100342008': 0.66, '5100342009': 0.66, '5100342012': 0.66, '5100342016': 0.66, '5100342017': 1.0, '5100342018': 0.66, '5100342020': 1.0, '5100342022': 0.0, '5100342023': 0.33, '5100342024': 0.33, '5100342025': 0.66, '5100342028': 0.33, '5100342030': 0.66, '5100342031': 0.66, '5100342034': 0.66, '5100342036': 0.33, '5100342042': 0.66, '5100342043': 0.66, '5100342045': 0.66, '5100342048': 0.33, '5100351001': 0.33, '5100351002': 0.33, '5100351004': 0.66, '5100351005': 0.66, '5100351007': 0.66, '5100351009': 0.66, '5100351010': 0.66, '5100351012': 1.0, '5100351013': 0.33, '5100351015': 0.66, '5100351016': 0.66, '5100351019': 0.66, '5100351020': 0.66, '5100351021': 0.66, '5100351022': 0.0, '5100351023': 0.66, '5100351024': 0.66, '5100351025': 0.66, '5100351026': 1.0, '5100351032': 1.0, '5100351034': 1.0, '5100351035': 0.66, '5100351036': 0.66, '5100351038': 0.66, '5100351039': 1.0, '5100351040': 0.66, '5100351042': 0.33, '5100351043': 1.0, '5100351044': 0.66, '5100351045': 0.66, '5100351046': 1.0, '5100351049': 1.0, '5100351051': 1.0, '5100351054': 0.66, '5100351058': 0.66, '5100352001': 0.66, '5100352002': 0.66, '5100352003': 0.66, '5100352004': 1.0, '5100352005': 0.66, '5100352006': 0.66, '5100352007': 1.0, '5100352008': 0.66, '5100352009': 1.0, '5100352011': 0.66, '5100352012': 0.66, '5100352013': 1.0, '5100352014': 0.66, '5100352015': 0.66, '5100352016': 0.66, '5100352017': 1.0, '5100352018': 0.66, '5100352020': 1.0, '5100352021': 0.66, '5100352022': 0.33, '5100352026': 1.0, '5100352027': 1.0, '5100352028': 0.66, '5100352030': 1.0, '5100352031': 1.0, '5100352032': 0.66, '5100352033': 0.66, '5100352034': 0.66, '5100352035': 0.66, '5100352037': 0.66, '5100352038': 1.0, '5100352039': 1.0, '5100352041': 0.66, '5100352042': 0.66, '5100352043': 0.33, '5100352044': 0.66, '5100352045': 1.0, '5100352046': 1.0, '5100352049': 0.66, '5100352050': 0.66, '5100352051': 0.66, '5100352052': 1.0, '5100352054': 0.33, '5100352055': 1.0, '5100352056': 0.66, '5100352057': 0.66, '5100352060': 0.66, '5100352061': 0.66, '5100352063': 0.66, '5100361009': 0.66, '5100361056': 0.66, '5100362028': 1.0, '5100362029': 0.66, '5100362030': 1.0, '5100362052': 0.66, '5100371022': 0.66, '5100371023': 1.0, '5100371024': 0.66, '5100371026': 1.0, '5100371027': 1.0, '5100371042': 1.0, '5100371055': 0.66, '5100371056': 0.66, '5100371067': 0.66, '5100371079': 0.66, '5100372001': 1.0, '5100372002': 0.66, '5100372003': 0.66, '5100372005': 0.66, '5100372006': 1.0, '5100372007': 1.0, '5100372009': 1.0, '5100372011': 1.0, '5100372015': 1.0, '5100372016': 1.0, '5100372017': 1.0, '5100372018': 1.0, '5100372019': 0.66, '5100372020': 1.0, '5100372021': 0.66, '5100372022': 1.0, '5100372023': 1.0, '5100372026': 1.0, '5100372027': 1.0, '5100372028': 0.66, '5100372069': 1.0, '5100381002': 1.0, '5100381003': 1.0, '5100381004': 0.66, '5100381005': 0.66, '5100381006': 0.66, '5100381007': 0.66, '5100381008': 0.66, '5100381009': 0.66, '5100381010': 0.66, '5100381011': 1.0, '5100381012': 1.0, '5100381015': 1.0, '5100381016': 1.0, '5100381017': 0.66, '5100381018': 0.66, '5100381019': 1.0, '5100381020': 0.66, '5100381021': 0.66, '5100381022': 0.66, '5100381023': 1.0, '5100381024': 1.0, '5100381026': 0.66, '5100381027': 1.0, '5100381028': 1.0, '5100381029': 1.0, '5100381031': 0.66, '5100381032': 0.66, '5100381034': 1.0, '5100381035': 0.66, '5100381037': 0.66, '5100381038': 0.66, '5100381039': 0.66, '5100381040': 1.0, '5100381041': 1.0, '5100381042': 0.66, '5100381043': 0.66, '5100381044': 0.66, '5100381045': 1.0, '5100381046': 1.0, '5100381047': 1.0, '5100381048': 1.0, '5100381049': 0.66, '5100381050': 1.0, '5100381051': 0.66, '5100381052': 1.0, '5100381053': 1.0, '5100381054': 0.66, '5100381055': 0.66, '5100381056': 1.0, '5100381058': 0.66, '5100381059': 1.0, '5100381060': 0.66, '5100381061': 0.66, '5100381063': 0.66, '5100381065': 0.66, '5100381066': 0.66, '5100381067': 0.66, '5100381069': 0.66, '5100382001': 0.66, '5100382003': 1.0, '5100382007': 0.66, '5100382008': 0.66, '5100382010': 1.0, '5100382011': 1.0, '5100382012': 1.0, '5100382013': 1.0, '5100382014': 1.0, '5100382015': 0.66, '5100382016': 1.0, '5100382018': 1.0, '5100382019': 1.0, '5100382020': 0.66, '5100382021': 1.0, '5100382022': 1.0, '5100382023': 1.0, '5100382025': 1.0, '5100382026': 1.0, '5100382027': 1.0, '5100382028': 0.66, '5100382029': 1.0, '5100382030': 1.0, '5100382031': 0.66, '5100382032': 0.66, '5100382033': 1.0, '5100382034': 0.66, '5100382035': 0.66, '5100382036': 1.0, '5100382037': 0.66, '5100382038': 1.0, '5100382039': 1.0, '5100382040': 0.66, '5100382042': 1.0, '5100382045': 1.0, '5100382046': 0.66, '5100382048': 0.66, '5100382050': 1.0, '5100382051': 0.66, '5100382052': 1.0, '5100382053': 1.0, '5100382054': 0.66, '5100382055': 1.0, '5100382056': 1.0, '5100382057': 1.0, '5100382058': 0.66, '5100382059': 0.66, '5100382060': 1.0, '5100382061': 1.0, '5100382062': 1.0, '5100382063': 1.0, '5100382064': 1.0, '5100382065': 1.0, '5100382066': 0.66, '5100382067': 0.66, '5100382068': 1.0, '5100382069': 0.66, '5100382070': 1.0, '5100382071': 1.0, '5100382072': 1.0, '5100382073': 0.66, '5100382075': 0.66, '5100382076': 0.66, '5100382077': 0.66, '5100382078': 0.66, '5100382079': 0.66, '5100401001': 0.66, '5100401003': 0.66, '5100401005': 0.66, '5100401006': 0.66, '5100401007': 1.0, '5100401008': 1.0, '5100401010': 0.66, '5100401011': 0.66, '5100401012': 0.66, '5100401014': 1.0, '5100401015': 0.66, '5100401016': 0.66, '5100401018': 0.66, '5100401021': 1.0, '5100401022': 1.0, '5100401023': 0.33, '5100401025': 1.0, '5100401026': 1.0, '5100401028': 0.66, '5100401029': 0.66, '5100401030': 1.0, '5100401031': 0.66, '5100401032': 0.66, '5100401033': 0.66, '5100401034': 0.33, '5100401035': 0.66, '5100401036': 0.66, '5100401038': 1.0, '5100401039': 0.66, '5100401040': 0.66, '5100401042': 0.66, '5100401043': 0.33, '5100401044': 1.0, '5100401045': 1.0, '5100401046': 0.66, '5100401047': 0.66, '5100401048': 0.66, '5100401049': 0.66, '5100401050': 0.66, '5100401051': 0.66, '5100401053': 1.0, '5100401054': 0.66, '5100401055': 0.66, '5100401056': 1.0, '5100401057': 1.0, '5100401059': 0.66, '5100401060': 0.66, '5100401061': 0.66, '5100401062': 1.0, '5100401063': 0.66, '5100401064': 0.66, '5100401065': 0.33, '5100401066': 1.0, '5100401067': 0.66, '5100401069': 1.0, '5100401070': 0.66, '5100401071': 0.66, '5100401072': 1.0, '5100401073': 0.66, '5100401074': 1.0, '5100401075': 0.66, '5100401076': 0.66, '5100401077': 0.66, '5100401078': 0.66, '5100402001': 0.33, '5100402002': 0.66, '5100402004': 1.0, '5100402005': 1.0, '5100402007': 0.66, '5100402008': 1.0, '5100402009': 0.66, '5100402011': 0.66, '5100402012': 0.66, '5100402015': 0.66, '5100402016': 0.66, '5100402017': 0.66, '5100402019': 1.0, '5100402020': 0.66, '5100402023': 1.0, '5100402024': 1.0, '5100402028': 0.66, '5100402029': 0.66, '5100402031': 0.66, '5100402032': 1.0, '5100402033': 0.66, '5100402034': 0.66, '5100402035': 1.0, '5100402036': 0.66, '5100402037': 0.66, '5100402038': 1.0, '5100402039': 0.66, '5100402040': 1.0, '5100402046': 0.66, '5100402047': 0.66, '5100402048': 0.66, '5100402049': 1.0, '5100402050': 0.66, '5100402051': 0.66, '5100402052': 0.66, '5100402053': 0.66, '5100402054': 0.66, '5100402055': 0.66, '5100402057': 0.66, '5100402058': 0.66, '5100402059': 0.66, '5100402062': 0.33, '5100402063': 0.33, '5100402065': 1.0, '5100402066': 0.66, '5100402067': 0.66, '5100402068': 0.66, '5100402069': 0.66, '5100421001': 1.0, '5100421002': 0.66, '5100421003': 1.0, '5100421005': 1.0, '5100421007': 0.66, '5100421009': 0.66, '5100421011': 0.66, '5100421012': 1.0, '5100421013': 0.66, '5100421015': 1.0, '5100421016': 1.0, '5100421017': 0.66, '5100421018': 0.66, '5100421019': 1.0, '5100421020': 0.66, '5100421021': 1.0, '5100421024': 1.0, '5100421025': 0.66, '5100421026': 1.0, '5100421027': 0.66, '5100421029': 1.0, '5100421032': 1.0, '5100421033': 1.0, '5100421034': 1.0, '5100421038': 0.66, '5100421039': 1.0, '5100421040': 0.66, '5100421041': 0.66, '5100421043': 0.66, '5100421045': 0.66, '5100421047': 0.66, '5100421048': 1.0, '5100421049': 1.0, '5100421050': 0.66, '5100421051': 0.66, '5100421052': 0.66, '5100421053': 1.0, '5100421054': 0.66, '5100421056': 1.0, '5100421057': 1.0, '5100421058': 0.66, '5100421059': 0.66, '5100421060': 0.66, '5100421061': 0.66, '5100421062': 1.0, '5100421063': 0.66, '5100421064': 1.0, '5100421065': 1.0, '5100421067': 0.66, '5100421068': 1.0, '5100421069': 0.66, '5100421070': 1.0, '5100421071': 0.66, '5100421072': 0.66, '5100421073': 1.0, '5100421074': 0.66, '5100421076': 1.0, '5100421078': 1.0, '5100421079': 1.0, '5100421080': 1.0, '5100421081': 1.0, '5100422002': 0.66, '5100422003': 0.66, '5100422004': 1.0, '5100422005': 0.66, '5100422006': 1.0, '5100422007': 0.66, '5100422008': 0.66, '5100422009': 0.66, '5100422011': 0.66, '5100422012': 1.0, '5100422013': 0.66, '5100422014': 0.66, '5100422016': 0.66, '5100422017': 1.0, '5100422018': 0.66, '5100422019': 1.0, '5100422022': 0.66, '5100422023': 0.66, '5100422024': 0.66, '5100422025': 1.0, '5100422026': 1.0, '5100422027': 0.66, '5100422028': 1.0, '5100422029': 0.66, '5100422030': 0.66, '5100422033': 0.66, '5100422034': 0.66, '5100422035': 0.66, '5100422036': 1.0, '5100422037': 0.66, '5100422038': 1.0, '5100422039': 1.0, '5100422041': 0.66, '5100422042': 1.0, '5100422044': 0.66, '5100422045': 0.66, '5100422046': 1.0, '5100422047': 0.66, '5100422049': 0.66, '5100422050': 1.0, '5100422051': 0.66, '5100422052': 0.66, '5100422055': 1.0, '5100422056': 1.0, '5100422057': 0.66, '5100422058': 0.66, '5100422059': 1.0, '5100422060': 0.66, '5100422061': 1.0, '5100422062': 0.66, '5100422063': 1.0, '5100422065': 1.0, '5100422066': 0.66, '5100422067': 0.66, '5100422068': 0.66, '5100422069': 0.66, '5100422071': 1.0, '5100422072': 0.66, '5100422073': 0.66, '5100422074': 0.66, '5100422075': 1.0, '5100422077': 0.66, '5100422078': 0.66, '5100422079': 1.0, '5100422080': 0.66, '5100422081': 0.66, '5100422084': 0.66, '5100422085': 0.66, '5100451001': 0.66, '5100451003': 1.0, '5100451004': 1.0, '5100451006': 1.0, '5100451007': 1.0, '5100451012': 1.0, '5100451013': 1.0, '5100451015': 1.0, '5100451016': 1.0, '5100451017': 0.66, '5100451018': 1.0, '5100451019': 1.0, '5100451020': 0.66, '5100451024': 1.0, '5100451026': 1.0, '5100451027': 1.0, '5100451033': 0.66, '5100451034': 1.0, '5100451035': 1.0, '5100451036': 0.66, '5100451038': 0.66, '5100451041': 1.0, '5100451043': 0.66, '5100451044': 1.0, '5100451045': 0.66, '5100451049': 1.0, '5100451050': 1.0, '5100451051': 0.66, '5100451052': 1.0, '5100451055': 0.66, '5100451056': 1.0, '5100451059': 1.0, '5100451060': 1.0, '5100451061': 1.0, '5100451064': 0.66, '5100451065': 1.0, '5100451066': 0.66, '5100451067': 1.0, '5100451070': 1.0, '5100451071': 1.0, '5100452002': 0.66, '5100452004': 1.0, '5100452005': 0.66, '5100452006': 1.0, '5100452007': 0.66, '5100452008': 1.0, '5100452009': 1.0, '5100452010': 0.66, '5100452011': 0.66, '5100452012': 1.0, '5100452013': 1.0, '5100452014': 1.0, '5100452016': 0.33, '5100452017': 1.0, '5100452018': 1.0, '5100452021': 0.66, '5100452023': 0.66, '5100452025': 0.66, '5100452027': 0.66, '5100452028': 1.0, '5100452030': 1.0, '5100452031': 1.0, '5100452032': 0.66, '5100452033': 0.66, '5100452034': 1.0, '5100452035': 0.66, '5100452036': 1.0, '5100452037': 1.0, '5100452038': 1.0, '5100452039': 0.66, '5100452040': 0.66, '5100452047': 1.0, '5100452049': 1.0, '5100452050': 1.0, '5100452053': 0.66, '5100452054': 1.0, '5100452055': 0.66, '5100452059': 1.0, '5100452060': 1.0, '5100452061': 0.66, '5100452065': 1.0, '5100452066': 1.0, '5100452067': 1.0, '5100452076': 1.0, '5100452078': 1.0, '5100452079': 1.0, '5100452080': 1.0, '5100452081': 0.66, '5100461004': 0.66, '5100461005': 0.66, '5100461006': 0.66, '5100461007': 0.33, '5100461008': 0.66, '5100461009': 1.0, '5100461010': 0.66, '5100461011': 0.66, '5100461014': 0.66, '5100461015': 1.0, '5100461016': 0.66, '5100461017': 1.0, '5100461018': 0.66, '5100461020': 0.66, '5100461021': 0.66, '5100461022': 1.0, '5100461023': 1.0, '5100461025': 0.66, '5100461029': 0.66, '5100461030': 1.0, '5100461031': 0.66, '5100461032': 0.66, '5100461033': 0.66, '5100461034': 0.66, '5100461035': 0.66, '5100461036': 0.66, '5100461037': 0.66, '5100461038': 0.66, '5100461039': 1.0, '5100461040': 0.66, '5100461042': 1.0, '5100461043': 0.66, '5100461044': 1.0, '5100461046': 0.66, '5100461047': 0.66, '5100461048': 0.66, '5100461049': 0.66, '5100461050': 0.66, '5100461051': 1.0, '5100461052': 0.66, '5100461053': 1.0, '5100461054': 0.66, '5100461055': 1.0, '5100461056': 1.0, '5100461057': 0.66, '5100461058': 0.66, '5100461061': 1.0, '5100461062': 0.66, '5100461063': 0.66, '5100461064': 1.0, '5100461065': 1.0, '5100461066': 1.0, '5100461067': 0.66, '5100461068': 0.66, '5100461069': 1.0, '5100462001': 0.66, '5100462002': 0.66, '5100462003': 0.33, '5100462005': 0.66, '5100462009': 0.66, '5100462010': 1.0, '5100462011': 1.0, '5100462012': 0.66, '5100462014': 1.0, '5100462015': 0.66, '5100462016': 0.66, '5100462017': 0.66, '5100462018': 0.66, '5100462019': 0.66, '5100462021': 1.0, '5100462022': 0.66, '5100462023': 0.66, '5100462024': 0.66, '5100462025': 0.66, '5100462026': 1.0, '5100462027': 0.66, '5100462028': 1.0, '5100462029': 1.0, '5100462031': 0.66, '5100462032': 0.66, '5100462033': 0.66, '5100462035': 1.0, '5100462037': 1.0, '5100462038': 0.66, '5100462039': 0.66, '5100462040': 0.66, '5100462041': 1.0, '5100462042': 0.66, '5100462043': 0.66, '5100462044': 0.66, '5100462045': 0.66, '5100462046': 0.66, '5100462047': 1.0, '5100462048': 0.66, '5100462050': 0.66, '5100462051': 0.66, '5100462052': 0.66, '5100462053': 1.0, '5100462054': 0.66, '5100462055': 1.0, '5100462057': 0.66, '5100462058': 1.0, '5100462059': 0.66, '5100462061': 0.66, '5100462062': 0.66, '5100462063': 1.0, '5100462064': 1.0, '5100462066': 0.66, '5100462067': 0.66, '5100462068': 0.66, '5100462069': 1.0, '5100462070': 1.0, '5100462071': 0.66, '5100462072': 1.0, '5100462074': 0.66, '5100462075': 1.0, '5100462077': 1.0, '5100462078': 0.66, '5100462079': 0.66, '5100462080': 0.66, '5100462081': 0.66, '5100462082': 0.66, '5100471001': 0.66, '5100471002': 1.0, '5100471003': 1.0, '5100471011': 0.66, '5100471012': 0.66, '5100471013': 0.66, '5100471015': 0.66, '5100471016': 1.0, '5100471018': 0.66, '5100471019': 1.0, '5100471020': 0.66, '5100471021': 0.66, '5100471023': 0.66, '5100471026': 1.0, '5100471027': 0.66, '5100471028': 1.0, '5100471029': 0.66, '5100471030': 1.0, '5100471031': 0.66, '5100471034': 0.66, '5100471037': 1.0, '5100471038': 1.0, '5100471039': 1.0, '5100471041': 1.0, '5100471042': 0.66, '5100471044': 0.66, '5100471045': 0.66, '5100471047': 1.0, '5100471049': 0.66, '5100471050': 1.0, '5100471051': 0.66, '5100471052': 0.66, '5100471054': 0.66, '5100471056': 0.66, '5100471057': 1.0, '5100471058': 0.66, '5100471059': 0.66, '5100471060': 0.66, '5100471062': 1.0, '5100471063': 1.0, '5100471065': 0.66, '5100471068': 0.66, '5100471069': 1.0, '5100471070': 0.66, '5100471072': 0.66, '5100471074': 0.66, '5100471075': 0.66, '5100471080': 0.66, '5100471081': 0.66, '5100472001': 0.33, '5100472002': 0.66, '5100472003': 0.66, '5100472004': 1.0, '5100472005': 0.66, '5100472007': 1.0, '5100472009': 1.0, '5100472010': 1.0, '5100472011': 0.66, '5100472012': 0.66, '5100472014': 0.66, '5100472019': 0.66, '5100472020': 1.0, '5100472021': 1.0, '5100472027': 1.0, '5100472030': 0.66, '5100472031': 0.66, '5100472032': 1.0, '5100472035': 0.66, '5100472039': 0.66, '5100472040': 0.66, '5100472041': 1.0, '5100472042': 0.66, '5100472044': 0.66, '5100472045': 1.0, '5100472047': 0.66, '5100472050': 0.66, '5100472052': 1.0, '5100472053': 0.66, '5100472054': 0.66, '5100472058': 0.33, '5100472060': 0.66, '5100472063': 0.66, '5100472064': 0.66, '5221290110': 1.0, '5221290111': 1.0, '5221290112': 1.0, '5221290114': 1.0, '5221290115': 0.66, '5221290116': 0.66, '5221290118': 1.0, '5221290119': 1.0, '5221290121': 1.0, '5221290122': 1.0, '5221290123': 0.66, '5221290124': 1.0, '5221290126': 1.0, '5221290127': 1.0, '5221290129': 1.0, '522129013': 1.0, '5221290131': 0.66, '5221290132': 1.0, '5221290134': 1.0, '5221290135': 1.0, '5221290137': 1.0, '5221290138': 1.0, '5221290140': 1.0, '5221290141': 1.0, '5221290142': 0.66, '5221290144': 1.0, '5221290145': 1.0, '5221290147': 1.0, '5221290149': 1.0, '5221290150': 1.0, '5221290151': 1.0, '5221290155': 1.0, '5221290158': 1.0, '522129016': 1.0, '5221290161': 0.66, '5221290162': 0.66, '5221290163': 0.66, '5221290164': 0.66, '5221290165': 1.0, '5221290166': 1.0, '5221290167': 1.0, '5221290169': 1.0, '522129017': 1.0, '5221290171': 0.66, '5221290172': 1.0, '5221290173': 1.0, '5221290174': 1.0, '5221290175': 1.0, '5221290177': 1.0, '5221290178': 1.0, '5221290179': 0.66, '522129018': 0.66, '5221290180': 1.0, '5221290184': 0.66, '522129021': 0.66, '5221290210': 1.0, '5221290212': 1.0, '5221290213': 1.0, '5221290214': 1.0, '5221290215': 1.0, '5221290216': 1.0, '5221290217': 1.0, '522129022': 1.0, '5221290220': 1.0, '5221290221': 1.0, '5221290222': 1.0, '5221290223': 1.0, '5221290226': 1.0, '5221290227': 0.66, '5221290228': 0.66, '5221290230': 0.66, '5221290231': 1.0, '5221290235': 0.66, '5221290237': 0.66, '5221290238': 1.0, '5221290239': 1.0, '522129024': 0.66, '5221290240': 1.0, '5221290242': 1.0, '5221290247': 1.0, '5221290249': 1.0, '522129025': 1.0, '5221290250': 0.66, '5221290251': 1.0, '5221290252': 1.0, '5221290253': 1.0, '5221290254': 1.0, '5221290255': 1.0, '5221290256': 1.0, '5221290257': 0.66, '5221290258': 1.0, '5221290259': 1.0, '522129026': 1.0, '5221290263': 1.0, '5221290264': 1.0, '5221290266': 1.0, '5221290268': 1.0, '5221290269': 0.66, '522129027': 1.0, '5221290270': 1.0, '5221290271': 0.66, '5221290272': 0.66, '5221290273': 1.0, '5221290274': 1.0, '5221290275': 0.66, '5221290279': 1.0, '5221290280': 0.33, '5221290282': 1.0, '5221290284': 1.0, '5564630110': 0.66, '5564630112': 0.66, '5564630115': 0.66, '5564630117': 1.0, '556463012': 1.0, '5564630121': 1.0, '5564630122': 0.66, '5564630123': 1.0, '5564630126': 0.0, '5564630127': 1.0, '5564630128': 1.0, '5564630129': 1.0, '556463013': 1.0, '5564630130': 0.66, '5564630132': 0.33, '5564630133': 0.66, '5564630134': 0.66, '5564630135': 1.0, '5564630137': 0.33, '5564630138': 0.33, '5564630139': 0.66, '556463014': 0.33, '5564630140': 0.66, '5564630141': 0.33, '5564630142': 0.66, '5564630143': 0.66, '5564630145': 1.0, '5564630147': 0.66, '5564630148': 1.0, '5564630149': 0.66, '5564630150': 0.66, '5564630152': 0.66, '5564630153': 1.0, '5564630154': 0.33, '5564630156': 0.33, '5564630157': 1.0, '5564630158': 1.0, '556463016': 1.0, '5564630160': 0.66, '5564630161': 0.66, '5564630162': 1.0, '5564630163': 1.0, '5564630165': 0.66, '5564630166': 0.66, '5564630167': 1.0, '5564630168': 0.33, '556463018': 1.0, '556463019': 0.66, '5564630211': 0.33, '5564630212': 0.66, '5564630213': 1.0, '5564630215': 0.66, '5564630216': 1.0, '5564630217': 1.0, '5564630218': 0.66, '5564630219': 0.66, '556463022': 0.33, '5564630221': 1.0, '5564630222': 1.0, '5564630226': 0.33, '5564630228': 1.0, '5564630229': 1.0, '5564630230': 1.0, '5564630232': 0.66, '5564630233': 0.66, '5564630234': 1.0, '5564630235': 0.66, '5564630236': 1.0, '5564630237': 1.0, '5564630238': 0.33, '556463024': 1.0, '5564630240': 0.66, '5564630241': 1.0, '5564630247': 1.0, '5564630249': 1.0, '556463025': 0.33, '5564630252': 0.66, '5564630253': 1.0, '5564630254': 1.0, '5564630256': 0.66, '5564630257': 0.33, '5564630258': 1.0, '556463026': 0.66, '5564630261': 1.0, '5564630262': 1.0, '5564630264': 0.66, '5564630265': 1.0, '5564630269': 0.66, '556463027': 1.0, '5564630273': 0.66, '5564630275': 0.66, '5564630276': 1.0, '556463028': 0.66, '5564630281': 1.0, '556463029': 0.66, '567496011': 1.0, '5674960111': 0.66, '5674960114': 1.0, '5674960115': 0.66, '5674960116': 1.0, '5674960117': 0.66, '5674960118': 0.66, '5674960121': 1.0, '5674960123': 1.0, '5674960124': 0.66, '5674960125': 1.0, '5674960126': 1.0, '567496013': 0.66, '5674960131': 0.66, '5674960132': 1.0, '5674960134': 1.0, '5674960136': 0.66, '5674960138': 0.66, '567496014': 1.0, '5674960142': 0.66, '5674960144': 1.0, '5674960145': 1.0, '5674960146': 1.0, '5674960148': 1.0, '5674960151': 1.0, '5674960153': 1.0, '5674960154': 1.0, '5674960155': 0.33, '5674960156': 0.66, '5674960157': 0.66, '5674960158': 0.66, '5674960160': 1.0, '5674960161': 0.66, '5674960166': 1.0, '567496017': 0.66, '5674960170': 1.0, '567496018': 0.66, '567496019': 1.0, '567496021': 0.33, '5674960211': 0.66, '5674960215': 1.0, '5674960216': 1.0, '5674960219': 1.0, '567496022': 0.33, '5674960220': 1.0, '5674960221': 1.0, '5674960222': 0.33, '5674960224': 1.0, '5674960225': 0.0, '5674960227': 1.0, '5674960228': 1.0, '5674960229': 0.66, '5674960230': 1.0, '5674960234': 0.66, '5674960235': 0.66, '567496024': 0.66, '5674960242': 0.66, '5674960246': 1.0, '5674960249': 0.66, '5674960251': 1.0, '5674960252': 0.66, '5674960255': 0.66, '5674960257': 0.66, '567496026': 1.0, '5674960261': 0.66, '5674960264': 1.0, '5674960268': 1.0, '5674960272': 1.0, '5674960273': 0.66, '5674960274': 1.0, '5674960275': 1.0, '5674960276': 1.0, '5674960277': 1.0, '5674960278': 1.0, '5674960279': 1.0, '567496028': 0.66, '5674960281': 1.0, '5674960282': 1.0, '5674960283': 0.0, '567496029': 1.0, '5912920111': 0.66, '5912920112': 1.0, '5912920113': 1.0, '5912920114': 0.66, '5912920119': 1.0, '5912920121': 1.0, '5912920123': 1.0, '5912920124': 0.66, '5912920125': 0.66, '5912920126': 1.0, '5912920127': 1.0, '5912920128': 0.33, '5912920129': 0.66, '5912920131': 1.0, '5912920133': 0.66, '5912920135': 1.0, '5912920137': 1.0, '5912920140': 1.0, '5912920142': 1.0, '5912920143': 0.66, '5912920145': 0.66, '5912920146': 0.66, '5912920147': 1.0, '5912920148': 1.0, '5912920149': 0.66, '591292015': 1.0, '5912920151': 1.0, '5912920152': 1.0, '5912920154': 1.0, '5912920156': 1.0, '5912920158': 1.0, '5912920159': 1.0, '5912920160': 1.0, '5912920163': 0.66, '5912920167': 0.66, '5912920168': 1.0, '5912920169': 0.66, '5912920170': 1.0, '5912920171': 1.0, '5912920172': 1.0, '591292019': 1.0, '591292021': 1.0, '5912920211': 1.0, '5912920212': 1.0, '5912920213': 1.0, '5912920216': 1.0, '5912920217': 0.66, '5912920220': 0.66, '5912920222': 1.0, '5912920223': 0.66, '5912920225': 1.0, '5912920227': 1.0, '5912920228': 0.66, '5912920230': 1.0, '5912920231': 1.0, '5912920233': 1.0, '5912920234': 0.66, '5912920235': 1.0, '5912920236': 1.0, '5912920239': 0.66, '591292024': 1.0, '5912920240': 1.0, '5912920241': 1.0, '5912920242': 0.66, '5912920243': 0.66, '5912920244': 0.66, '5912920245': 1.0, '5912920249': 1.0, '5912920250': 1.0, '5912920256': 1.0, '5912920260': 1.0, '5912920263': 1.0, '5912920265': 1.0, '5912920266': 0.66, '5912920267': 1.0, '5912920268': 1.0, '5912920273': 1.0, '5912920274': 1.0, '5912920275': 1.0, '5912920276': 1.0, '5912920277': 1.0, '5912920279': 1.0, '5912920280': 1.0, '769862011': 1.0, '7698620112': 1.0, '7698620113': 1.0, '7698620115': 1.0, '7698620116': 1.0, '7698620118': 0.66, '7698620120': 1.0, '7698620122': 1.0, '7698620123': 1.0, '7698620126': 1.0, '7698620129': 1.0, '7698620130': 0.66, '7698620131': 0.66, '7698620132': 1.0, '7698620133': 1.0, '7698620134': 1.0, '7698620136': 0.66, '7698620138': 1.0, '7698620139': 1.0, '769862014': 1.0, '7698620141': 1.0, '7698620144': 1.0, '7698620145': 0.66, '7698620149': 1.0, '769862015': 0.66, '7698620150': 1.0, '7698620151': 1.0, '7698620152': 1.0, '7698620153': 1.0, '7698620156': 0.66, '7698620158': 1.0, '769862016': 0.66, '7698620160': 1.0, '7698620161': 1.0, '7698620163': 1.0, '7698620165': 1.0, '7698620166': 0.66, '7698620167': 1.0, '7698620169': 1.0, '769862017': 0.33, '7698620170': 0.66, '7698620171': 1.0, '769862018': 1.0, '769862019': 1.0, '769862021': 1.0, '7698620211': 1.0, '7698620212': 1.0, '7698620217': 1.0, '7698620218': 1.0, '769862022': 1.0, '7698620221': 1.0, '7698620222': 1.0, '7698620224': 1.0, '7698620225': 0.66, '7698620227': 0.66, '7698620229': 0.66, '7698620230': 1.0, '7698620231': 1.0, '7698620233': 0.33, '7698620236': 0.66, '7698620238': 1.0, '7698620239': 1.0, '7698620240': 1.0, '7698620241': 0.66, '7698620244': 1.0, '7698620245': 1.0, '7698620248': 0.66, '7698620250': 1.0, '7698620252': 0.33, '7698620253': 0.66, '7698620255': 0.66, '7698620256': 1.0, '7698620257': 1.0, '7698620258': 1.0, '7698620260': 0.66, '7698620261': 1.0, '7698620262': 0.66, '7698620264': 0.66, '7698620265': 1.0, '7698620267': 1.0, '7698620268': 1.0, '769862027': 1.0, '7698620270': 1.0, '7698620272': 1.0, '7698620274': 1.0, '7698620275': 1.0, '7698620278': 0.66, '769862028': 1.0, '7698620281': 1.0, '7698620283': 1.0, '7994020110': 1.0, '79940201100': 0.66, '79940201110': 1.0, '79940201140': 1.0, '79940201150': 1.0, '79940201160': 1.0, '79940201180': 1.0, '79940201210': 1.0, '79940201230': 1.0, '79940201250': 1.0, '79940201270': 0.66, '7994020130': 0.66, '79940201300': 0.33, '79940201320': 1.0, '79940201330': 1.0, '79940201340': 1.0, '79940201350': 1.0, '79940201360': 1.0, '79940201370': 0.66, '79940201380': 1.0, '79940201390': 0.33, '7994020140': 0.66, '79940201410': 1.0, '79940201420': 1.0, '79940201430': 1.0, '79940201470': 1.0, '79940201490': 1.0, '79940201510': 0.66, '79940201560': 0.66, '79940201570': 1.0, '79940201580': 0.66, '7994020160': 1.0, '79940201620': 1.0, '79940201650': 0.66, '79940201660': 0.33, '79940201690': 1.0, '79940201700': 0.66, '79940201710': 1.0, '79940201720': 1.0, '79940201730': 0.66, '79940201740': 1.0, '79940201750': 0.66, '79940201760': 1.0, '79940201770': 1.0, '79940201780': 1.0, '79940201790': 0.33, '79940201810': 1.0, '79940201820': 1.0, '79940201850': 0.66, '79940201860': 1.0, '79940201880': 1.0, '79940201930': 0.66, '79940201950': 1.0, '79940202100': 1.0, '79940202120': 1.0, '79940202130': 0.66, '79940202140': 0.66, '79940202160': 1.0, '79940202170': 0.66, '79940202180': 0.66, '79940202190': 0.66, '79940202200': 1.0, '79940202210': 0.66, '79940202220': 0.66, '79940202230': 1.0, '79940202270': 0.33, '79940202280': 0.33, '7994020230': 0.33, '79940202300': 0.66, '79940202310': 0.33, '79940202320': 1.0, '79940202340': 0.66, '79940202350': 0.66, '79940202370': 1.0, '79940202390': 0.66, '79940202400': 0.66, '79940202410': 0.66, '79940202450': 0.66, '79940202470': 0.66, '79940202480': 0.66, '79940202490': 0.33, '7994020250': 1.0, '79940202510': 0.66, '79940202520': 1.0, '79940202540': 1.0, '79940202560': 1.0, '79940202570': 1.0, '79940202580': 0.66, '79940202620': 1.0, '79940202690': 1.0, '7994020270': 1.0, '79940202700': 1.0, '79940202710': 0.66, '79940202750': 0.66, '79940202760': 1.0, '79940202790': 1.0, '7994020280': 0.66, '79940202800': 0.33, '79940202820': 0.66, '79940202840': 0.33, '79940202850': 0.33, '79940202860': 0.33, '79940202870': 0.66, '79940202890': 1.0, '7994020290': 1.0, '8263820112': 1.0, '8263820113': 0.66, '8263820120': 0.66, '8263820123': 0.66, '8263820124': 0.66, '8263820126': 1.0, '8263820132': 1.0, '8263820135': 0.66, '8263820136': 1.0, '8263820138': 0.66, '8263820139': 0.66, '8263820140': 0.66, '8263820141': 0.66, '8263820144': 1.0, '8263820145': 0.66, '8263820146': 0.66, '8263820147': 1.0, '8263820148': 1.0, '826382015': 0.66, '8263820150': 1.0, '8263820151': 1.0, '8263820152': 0.66, '8263820155': 0.66, '8263820156': 0.66, '8263820159': 1.0, '826382016': 1.0, '8263820160': 1.0, '8263820162': 1.0, '8263820165': 1.0, '8263820169': 0.66, '8263820170': 1.0, '826382018': 1.0, '826382021': 0.66, '8263820210': 0.66, '8263820211': 1.0, '8263820212': 1.0, '8263820213': 0.66, '8263820214': 1.0, '8263820221': 1.0, '8263820223': 0.66, '8263820224': 0.66, '8263820227': 0.66, '8263820228': 0.66, '826382023': 1.0, '8263820231': 1.0, '8263820233': 1.0, '8263820234': 1.0, '8263820235': 1.0, '8263820237': 1.0, '8263820239': 1.0, '826382024': 0.33, '8263820240': 1.0, '8263820242': 0.66, '8263820243': 1.0, '8263820245': 0.66, '8263820246': 1.0, '8263820247': 0.66, '8263820251': 1.0, '8263820253': 0.66, '8263820254': 1.0, '8263820255': 0.66, '8263820256': 0.66, '8263820257': 0.66, '8263820259': 1.0, '826382026': 1.0, '8263820260': 0.66, '8263820264': 1.0, '8263820265': 0.66, '8263820266': 0.66, '8263820268': 1.0, '8263820269': 0.66, '826382027': 0.66, '8263820272': 1.0, '8263820273': 1.0, '8263820275': 0.66, '8263820277': 0.66, '8263820278': 0.66, '8263820279': 1.0, '826382028': 0.66, '826412010': 1.0, '8264120110': 0.66, '8264120111': 0.66, '8264120112': 0.66, '8264120113': 1.0, '8264120116': 0.33, '8264120117': 1.0, '8264120119': 1.0, '8264120120': 0.33, '8264120121': 0.66, '8264120122': 0.66, '8264120123': 0.33, '8264120124': 0.66, '8264120125': 0.66, '8264120126': 0.66, '8264120127': 0.33, '826412013': 0.33, '8264120131': 0.66, '8264120132': 0.66, '8264120136': 0.66, '8264120139': 1.0, '8264120141': 0.66, '8264120144': 1.0, '8264120145': 1.0, '8264120146': 1.0, '8264120149': 0.66, '8264120150': 0.33, '8264120156': 0.33, '8264120157': 0.66, '8264120159': 0.66, '8264120165': 1.0, '8264120166': 1.0, '8264120169': 0.33, '826412017': 0.66, '826412018': 0.66, '826412019': 0.66, '8264120210': 0.66, '8264120211': 0.33, '8264120213': 1.0, '8264120215': 1.0, '8264120216': 1.0, '8264120218': 1.0, '8264120219': 1.0, '8264120220': 0.66, '8264120221': 1.0, '8264120223': 0.66, '8264120224': 1.0, '8264120227': 1.0, '8264120228': 1.0, '8264120229': 0.66, '826412023': 1.0, '8264120231': 0.33, '8264120232': 0.66, '8264120233': 1.0, '8264120234': 0.66, '8264120239': 0.33, '826412024': 1.0, '8264120240': 0.0, '8264120241': 0.66, '8264120242': 0.66, '8264120243': 0.33, '8264120245': 0.66, '8264120247': 1.0, '8264120248': 0.66, '8264120249': 0.33, '826412025': 0.66, '8264120254': 0.33, '8264120256': 0.33, '8264120257': 1.0, '8264120258': 0.66, '8264120261': 0.33, '8264120262': 0.33, '8264120263': 0.33, '8264120265': 0.33, '8264120266': 0.33, '8264120268': 1.0, '8264120269': 0.33, '826412027': 0.66, '8264120274': 1.0, '8264120275': 1.0, '8264120279': 0.33, '8264120280': 0.66, '8264120282': 0.33, '8264120284': 0.33, '88265401100': 1.0, '88265401130': 1.0, '88265401140': 1.0, '88265401150': 1.0, '88265401160': 1.0, '88265401170': 0.66, '88265401190': 1.0, '8826540120': 1.0, '88265401200': 0.66, '88265401240': 1.0, '88265401260': 1.0, '88265401270': 1.0, '88265401280': 1.0, '88265401300': 1.0, '88265401320': 1.0, '88265401350': 1.0, '88265401360': 1.0, '88265401380': 1.0, '88265401390': 1.0, '88265401400': 1.0, '88265401410': 1.0, '88265401420': 0.66, '88265401430': 1.0, '88265401450': 1.0, '88265401470': 0.66, '88265401480': 1.0, '88265401490': 1.0, '8826540150': 1.0, '88265401520': 1.0, '88265401550': 1.0, '88265401630': 0.66, '88265401640': 0.66, '88265401660': 1.0, '88265401690': 1.0, '8826540170': 1.0, '88265401730': 1.0, '88265401740': 1.0, '88265401750': 0.33, '8826540180': 1.0, '88265402120': 1.0, '88265402150': 1.0, '88265402160': 0.66, '88265402170': 1.0, '88265402180': 0.66, '88265402190': 1.0, '88265402200': 1.0, '88265402230': 0.66, '88265402240': 0.66, '88265402270': 0.66, '8826540230': 1.0, '88265402300': 1.0, '88265402310': 1.0, '88265402320': 0.66, '88265402330': 1.0, '88265402340': 0.66, '88265402350': 1.0, '88265402370': 1.0, '88265402380': 1.0, '8826540240': 1.0, '88265402400': 0.66, '88265402420': 1.0, '88265402440': 0.66, '88265402450': 1.0, '88265402480': 0.66, '88265402490': 1.0, '88265402500': 1.0, '88265402520': 1.0, '88265402540': 0.66, '88265402570': 0.66, '88265402580': 1.0, '88265402590': 1.0, '8826540260': 0.66, '88265402600': 0.66, '88265402630': 1.0, '88265402660': 1.0, '88265402690': 1.0, '8826540270': 1.0, '88265402700': 1.0, '88265402770': 1.0, '88265402780': 1.0, '88265402790': 0.66, '8826540280': 0.66, '88265402800': 1.0, '88265402810': 1.0, '88265402820': 1.0, '88265402840': 1.0, '88265402850': 1.0, '88265402880': 0.66, '88265402890': 1.0, '8826540290': 1.0, '88265402900': 1.0, '907001100': 1.0, '9070011010': 0.66, '9070011020': 1.0, '9070011060': 1.0, '9070011090': 0.66, '907001110': 1.0, '9070011110': 1.0, '907001120': 0.66, '907001150': 1.0, '907001160': 0.66, '907001170': 1.0, '907001180': 1.0, '907001210': 1.0, '907001220': 1.0, '907001240': 1.0, '907001270': 0.66, '907001280': 1.0, '907001310': 1.0, '907001340': 1.0, '907001350': 1.0, '907001360': 1.0, '907001370': 1.0, '907001400': 1.0, '907001430': 0.66, '907001450': 1.0, '907001480': 0.33, '907001490': 1.0, '90700150': 1.0, '907001500': 1.0, '907001520': 1.0, '907001550': 1.0, '907001560': 0.66, '907001570': 1.0, '907001580': 1.0, '90700160': 1.0, '907001600': 1.0, '907001620': 1.0, '907001650': 0.66, '907001670': 1.0, '907001680': 1.0, '90700170': 1.0, '907001730': 1.0, '907001740': 0.66, '907001780': 1.0, '907001790': 1.0, '90700180': 1.0, '907001820': 1.0, '907001840': 1.0, '907001850': 1.0, '907001860': 1.0, '90700190': 1.0, '907001910': 0.66, '907001940': 1.0, '907001950': 0.33, '907001970': 1.0, '9289010111': 0.66, '9289010112': 0.66, '9289010113': 0.66, '9289010114': 0.33, '9289010115': 1.0, '9289010117': 1.0, '9289010118': 1.0, '9289010119': 1.0, '9289010120': 0.66, '9289010121': 0.66, '9289010127': 0.66, '928901013': 1.0, '9289010131': 0.66, '9289010132': 0.66, '9289010133': 1.0, '9289010134': 1.0, '9289010138': 0.66, '9289010139': 0.66, '928901014': 0.33, '9289010143': 0.66, '9289010144': 0.66, '9289010145': 0.33, '9289010147': 0.66, '9289010149': 1.0, '9289010150': 1.0, '9289010151': 1.0, '9289010152': 0.33, '9289010153': 0.66, '9289010154': 0.66, '9289010155': 1.0, '9289010157': 1.0, '9289010158': 1.0, '928901016': 0.66, '9289010160': 1.0, '9289010161': 0.66, '9289010163': 1.0, '9289010166': 0.66, '9289010167': 1.0, '928901018': 1.0, '9289010210': 1.0, '9289010211': 0.66, '9289010216': 1.0, '9289010221': 1.0, '9289010222': 1.0, '9289010223': 1.0, '9289010227': 1.0, '9289010229': 1.0, '928901023': 1.0, '9289010230': 1.0, '9289010231': 0.66, '9289010232': 1.0, '9289010233': 1.0, '9289010235': 1.0, '9289010242': 1.0, '9289010243': 1.0, '9289010244': 1.0, '9289010245': 1.0, '9289010248': 1.0, '9289010249': 1.0, '928901025': 1.0, '9289010250': 0.66, '9289010251': 1.0, '9289010253': 1.0, '9289010254': 0.66, '9289010257': 1.0, '9289010259': 1.0, '928901026': 1.0, '9289010261': 1.0, '9289010262': 1.0, '9289010263': 0.66, '9289010265': 1.0, '9289010266': 1.0, '9289010267': 1.0, '9289010268': 1.0, '9289010269': 1.0, '9289010270': 1.0, '9289010271': 0.66, '9289010273': 1.0, '9289010274': 1.0, '9289010275': 1.0, '9289010276': 0.33, '9289010278': 1.0, '928901028': 1.0, '928901029': 1.0, '940328011': 1.0, '9403280110': 1.0, '9403280112': 1.0, '9403280114': 1.0, '9403280115': 0.66, '9403280116': 1.0, '9403280117': 1.0, '940328012': 1.0, '9403280126': 1.0, '9403280129': 1.0, '9403280132': 1.0, '9403280134': 0.66, '9403280136': 1.0, '9403280138': 0.66, '940328014': 1.0, '9403280140': 0.66, '9403280143': 0.66, '9403280145': 0.66, '9403280146': 0.66, '9403280147': 1.0, '9403280149': 1.0, '9403280150': 1.0, '9403280151': 0.66, '9403280152': 0.66, '9403280155': 1.0, '9403280156': 1.0, '9403280157': 0.66, '9403280159': 1.0, '940328016': 1.0, '9403280164': 1.0, '9403280165': 0.66, '9403280167': 1.0, '940328017': 1.0, '940328018': 1.0, '9403280212': 1.0, '9403280213': 0.66, '9403280217': 0.66, '9403280218': 0.66, '9403280219': 0.66, '940328022': 1.0, '9403280227': 0.66, '9403280229': 1.0, '9403280234': 1.0, '9403280235': 0.66, '9403280236': 0.66, '9403280238': 0.66, '9403280241': 1.0, '9403280243': 1.0, '9403280245': 1.0, '9403280246': 1.0, '9403280247': 0.66, '9403280249': 1.0, '9403280250': 0.66, '9403280251': 0.66, '9403280254': 1.0, '9403280255': 1.0, '9403280256': 1.0, '9403280259': 1.0, '9403280260': 1.0, '9403280262': 1.0, '9403280265': 1.0, '9403280266': 1.0, '9403280271': 0.33, '9403280272': 1.0, '9403280273': 0.66, '9403280277': 1.0, '9403280279': 1.0, '9877360111': 1.0, '9877360113': 0.66, '9877360114': 1.0, '9877360115': 1.0, '9877360116': 0.66, '9877360117': 0.66, '9877360120': 0.33, '9877360121': 0.66, '9877360124': 1.0, '9877360125': 1.0, '9877360126': 1.0, '9877360127': 0.66, '9877360128': 1.0, '9877360130': 0.66, '9877360131': 1.0, '9877360132': 0.66, '9877360133': 0.0, '9877360134': 1.0, '9877360135': 0.66, '9877360138': 0.66, '987736014': 1.0, '9877360140': 1.0, '9877360141': 1.0, '9877360143': 1.0, '9877360147': 1.0, '9877360149': 1.0, '987736015': 0.66, '9877360151': 1.0, '9877360152': 1.0, '9877360154': 0.66, '9877360156': 1.0, '9877360157': 0.33, '9877360158': 1.0, '9877360159': 1.0, '987736016': 1.0, '9877360163': 0.66, '9877360164': 1.0, '9877360165': 1.0, '9877360166': 1.0, '9877360168': 1.0, '9877360169': 0.33}\n"
     ]
    }
   ],
   "source": [
    "ENGAGE_WILD_DATASET, BIN_CLASSIFICATION, N_CLASSES, DATASET_NAME, BASE_DATASET_DIR, ext = define_dataset(False, False)\n",
    "video2label, labels_list = get_video2label()\n",
    "print(labels_list)\n",
    "print(video2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4148ee32-ce39-42a8-884f-8cd928341cfe",
   "metadata": {},
   "source": [
    "### Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ad8b6a1-1bea-4877-8d49-366dc2ef9afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.std\n",
    "stat_name = \"std\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da853fe-7bb1-4c33-874c-5faf66445ac5",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76330efa-245a-441d-b22c-85893e35400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "582d6de4-8e16-4dc6-ac70-5974eb7a9a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e643a223-3d62-46b3-9c8f-bb5747081335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 34/5482: 0.6202116016052536%\n",
      "0.33 214/5482: 3.903684786574243%\n",
      "0.66 2649/5482: 48.32178037212696%\n",
      "1.0 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0.0 4/1723: 0.2321532211259431%\n",
      "0.33 81/1723: 4.7011027278003485%\n",
      "0.66 861/1723: 49.97098084735926%\n",
      "1.0 777/1723: 45.095763203714455%\n",
      "val:\n",
      "0.0 23/1720: 1.3372093023255813%\n",
      "0.33 160/1720: 9.30232558139535%\n",
      "0.66 912/1720: 53.02325581395349%\n",
      "1.0 625/1720: 36.33720930232558%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bb43e7-735a-4ca4-a51c-b9f9891b7ef2",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b67c7983-88a5-49be-a87b-6fa3377a15f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_4_std_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "504955f5-9996-49dc-b3b7-808f3408a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19c61f1c-5c55-406a-af00-28ef620d8492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2048) (5482,)\n",
      "(1723, 128, 2048) (1723,)\n",
      "(1720, 128, 2048) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11157087-e300-400a-aa88-9622fd7320ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 09:22:57.873860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c96fc6b9-4d8e-487f-b7bc-0f2e330665fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 09:23:04.989567: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9b0003e950 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-05 09:23:04.989590: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-08-05 09:23:04.994404: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 09:23:05.027287: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-08-05 09:23:05.078870: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 5s 71ms/step - loss: 0.0664 - mae: 0.1934 - val_loss: 0.0591 - val_mae: 0.2072\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0376 - mae: 0.1689 - val_loss: 0.0504 - val_mae: 0.1872\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0345 - mae: 0.1596 - val_loss: 0.0501 - val_mae: 0.1863\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0338 - mae: 0.1575 - val_loss: 0.0521 - val_mae: 0.1888\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0334 - mae: 0.1550 - val_loss: 0.0483 - val_mae: 0.1812\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0326 - mae: 0.1533 - val_loss: 0.0469 - val_mae: 0.1788\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0322 - mae: 0.1518 - val_loss: 0.0473 - val_mae: 0.1784\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0321 - mae: 0.1519 - val_loss: 0.0499 - val_mae: 0.1864\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 23ms/step - loss: 0.0317 - mae: 0.1505 - val_loss: 0.0489 - val_mae: 0.1833\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0312 - mae: 0.1490 - val_loss: 0.0477 - val_mae: 0.1794\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0310 - mae: 0.1489 - val_loss: 0.0493 - val_mae: 0.1845\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0309 - mae: 0.1488 - val_loss: 0.0475 - val_mae: 0.1810\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0305 - mae: 0.1474 - val_loss: 0.0488 - val_mae: 0.1831\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0302 - mae: 0.1462 - val_loss: 0.0489 - val_mae: 0.1830\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.0301 - mae: 0.1463 - val_loss: 0.0483 - val_mae: 0.1807\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0297 - mae: 0.1453 - val_loss: 0.0485 - val_mae: 0.1820\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0296 - mae: 0.1447 - val_loss: 0.0491 - val_mae: 0.1835\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.0291 - mae: 0.1432 - val_loss: 0.0486 - val_mae: 0.1813\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0292 - mae: 0.1437 - val_loss: 0.0487 - val_mae: 0.1825\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 23ms/step - loss: 0.0286 - mae: 0.1421 - val_loss: 0.0497 - val_mae: 0.1812\n",
      "0.04690246284008026\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dcaa50ad-0434-46dc-ab55-bf0dfee3be84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bce918e6-c10e-4677-a950-93c33c3347fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_std_single_attention_traditional Accuracy:  0.5606500290191526 MSE:  0.04404884499239516 UAR:  0.3336954841019881 Recall:  N/A Precision:  N/A F1:  0.3425016395849529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5606500290191526,\n",
       " 0.04404884499239516,\n",
       " 0.3336954841019881,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.3425016395849529)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ecca83b8-8f08-4a88-a594-490d9b0dd3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c98a6059-6b17-43ed-a66d-ffdc07cdf604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43ba1748-df40-476a-9660-f49e3c67d5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_std_single_attention_traditional_best Accuracy:  0.5449796865931514 MSE:  0.03844683204704938 UAR:  0.28950466145588094 Recall:  N/A Precision:  N/A F1:  0.2780953955832553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5449796865931514,\n",
       " 0.03844683204704938,\n",
       " 0.28950466145588094,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.2780953955832553)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778137aa-dac7-4192-bf29-e098ab07b1bf",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "975d3bff-1e8b-4be4-ba07-addc45c76ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_4_std_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bed21078-a9a2-44e0-bf7d-685acd7fd479",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9887ecfa-0d32-4a6b-a160-3978822cf2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2048) (5482,)\n",
      "(1723, 128, 2048) (1723,)\n",
      "(1720, 128, 2048) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55a790b5-b498-4ac0-9a77-b6b34d888319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "551eeb9a-52f8-4953-adbd-527d72bdb0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 90ms/step - loss: 0.0818 - mae: 0.2007 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "0.11642508953809738\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4c37262-873f-42c4-92a2-bea944f71863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26b89a7a-22be-47ea-9710-c15a2d748839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_std_self_attention_traditional Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "451ec4bb-300c-44c6-9f12-6d3ce7aaefd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3c18e9d-b8c6-48d5-b3d0-b9107db2ea7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba221ac0-7746-4174-afdc-202467b06b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_std_self_attention_traditional_best Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb0017f-e211-4230-b3a2-1a83066852b9",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d2c1d4ec-89d6-47f0-a60e-e65ad15ce196",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2e7fc27-842e-45d2-a3c9-0e77e9db60b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "86b9a485-1d51-46fa-8fe3-faf74c849d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 34/5482: 0.6202116016052536%\n",
      "0.33 214/5482: 3.903684786574243%\n",
      "0.66 2649/5482: 48.32178037212696%\n",
      "1.0 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0.0 4/1723: 0.2321532211259431%\n",
      "0.33 81/1723: 4.7011027278003485%\n",
      "0.66 861/1723: 49.97098084735926%\n",
      "1.0 777/1723: 45.095763203714455%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "360a94f2-44cb-449c-babe-878dfb8b68a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482,) (5482,)\n",
      "(1723,) (1723,)\n",
      "(7205,) (7205,)\n",
      "[0.   0.33 0.66 1.  ] [  38  295 3510 3362]\n",
      "7205\n",
      "5474\n",
      "1731\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0bc582e1-1fc7-4f99-b16a-dccd0205c053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 28/5474: 0.5115089514066496%\n",
      "0.33 224/5474: 4.092071611253197%\n",
      "0.66 2667/5474: 48.72122762148338%\n",
      "1.0 2555/5474: 46.67519181585678%\n",
      "test:\n",
      "0.0 10/1731: 0.5777007510109763%\n",
      "0.33 71/1731: 4.101675332177932%\n",
      "0.66 843/1731: 48.7001733102253%\n",
      "1.0 807/1731: 46.62045060658579%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d01d180-bad8-49da-9c7d-4e262c1ee96e",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3914e4a9-6404-461f-8085-231cf5fa45f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_4_std_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "98541198-359f-441c-932c-351919ad73b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "32200826-30c0-4b15-8bf9-56533944dd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 2048) (5474,)\n",
      "(1731, 128, 2048) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8e495731-27f9-4ba4-8cf1-6c06fffbfa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fc5fb741-c6b3-400f-bbd2-a6598bae6e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 3s 60ms/step - loss: 0.0524 - mae: 0.1871 - val_loss: 0.0376 - val_mae: 0.1724\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0364 - mae: 0.1673 - val_loss: 0.0351 - val_mae: 0.1613\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0346 - mae: 0.1617 - val_loss: 0.0341 - val_mae: 0.1600\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0338 - mae: 0.1590 - val_loss: 0.0341 - val_mae: 0.1600\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0332 - mae: 0.1570 - val_loss: 0.0340 - val_mae: 0.1598\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0338 - mae: 0.1573 - val_loss: 0.0360 - val_mae: 0.1634\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0329 - mae: 0.1552 - val_loss: 0.0342 - val_mae: 0.1591\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0324 - mae: 0.1546 - val_loss: 0.0343 - val_mae: 0.1555\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0320 - mae: 0.1530 - val_loss: 0.0337 - val_mae: 0.1560\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0319 - mae: 0.1525 - val_loss: 0.0348 - val_mae: 0.1603\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0315 - mae: 0.1520 - val_loss: 0.0342 - val_mae: 0.1577\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0313 - mae: 0.1510 - val_loss: 0.0335 - val_mae: 0.1553\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0313 - mae: 0.1509 - val_loss: 0.0335 - val_mae: 0.1550\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0307 - mae: 0.1491 - val_loss: 0.0360 - val_mae: 0.1606\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0305 - mae: 0.1485 - val_loss: 0.0339 - val_mae: 0.1573\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0300 - mae: 0.1475 - val_loss: 0.0341 - val_mae: 0.1549\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0301 - mae: 0.1475 - val_loss: 0.0343 - val_mae: 0.1551\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0298 - mae: 0.1465 - val_loss: 0.0345 - val_mae: 0.1586\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0297 - mae: 0.1464 - val_loss: 0.0341 - val_mae: 0.1559\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0287 - mae: 0.1434 - val_loss: 0.0342 - val_mae: 0.1568\n",
      "0.03349917009472847\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c134a35b-c3aa-46fe-a911-069ee53a65b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ad2d657-f91c-4596-91fb-a440bde5c288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_std_single_attention_balanced Accuracy:  0.5517042172154824 MSE:  0.034207547604454616 UAR:  0.3185099808036505 Recall:  N/A Precision:  N/A F1:  0.3051872322134036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5517042172154824,\n",
       " 0.034207547604454616,\n",
       " 0.3185099808036505,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.3051872322134036)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d1cebfec-2752-4dac-902a-5698f5b0c4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f2294c49-3b91-4e2c-ae35-81ed03d6c76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e0f02e3e-9203-4891-a03c-c26da8d7c0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_std_single_attention_balanced_best Accuracy:  0.5788561525129983 MSE:  0.03347769755234969 UAR:  0.3194045051019359 Recall:  N/A Precision:  N/A F1:  0.30678216509304873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5788561525129983,\n",
       " 0.03347769755234969,\n",
       " 0.3194045051019359,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.30678216509304873)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7232da-33c5-4d79-90de-5b157d18d003",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ff67d5e8-cea7-4429-a95c-e6b352bec222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_4_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3d126b32-84de-4d85-afce-cdbeab41ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "00ad024f-7168-4a54-929c-93c91f469615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 2048) (5474,)\n",
      "(1731, 128, 2048) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4f29deec-76ea-4478-8ab5-5e5a7fabbfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "182d4b67-f989-4521-9874-43499eed2232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 99ms/step - loss: 0.0799 - mae: 0.1991 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "0.08048681914806366\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2953b01c-4298-4c74-af76-0b04cb9f4631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3a73c7a8-d504-452e-93e9-2fd8fd963cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_std_self_attention_balanced Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1add895c-3e52-468a-8572-3cb40419506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a4271022-0cfb-4850-9dbb-bad351d8171f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4a92ac4e-8b6a-4018-b458-a9f2fcfee5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_std_self_attention_balanced_best Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1767e57-221e-48c6-986b-8ab4509df630",
   "metadata": {},
   "source": [
    "### Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c4b46127-b3fa-49ab-b42d-031579d7c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.max\n",
    "stat_name = \"max\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6647e8ae-3621-4d9d-937a-d7a53f466572",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6efd9a3f-f6c5-49cb-b2fb-144dcd385039",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9c657a9b-c048-4a3e-91bc-39897279746b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3945d479-c205-432c-9f3f-f04d7cd45f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 34/5482: 0.6202116016052536%\n",
      "0.33 214/5482: 3.903684786574243%\n",
      "0.66 2649/5482: 48.32178037212696%\n",
      "1.0 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0.0 4/1723: 0.2321532211259431%\n",
      "0.33 81/1723: 4.7011027278003485%\n",
      "0.66 861/1723: 49.97098084735926%\n",
      "1.0 777/1723: 45.095763203714455%\n",
      "val:\n",
      "0.0 23/1720: 1.3372093023255813%\n",
      "0.33 160/1720: 9.30232558139535%\n",
      "0.66 912/1720: 53.02325581395349%\n",
      "1.0 625/1720: 36.33720930232558%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0ead24-626d-41ef-909d-38bb4dd47132",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3f53204c-9b5f-46a5-aa04-9ea7ce296823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_4_max_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9752da19-ebfe-4ccb-aeb9-ccd4e213d188",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7007cd80-0f19-43c4-ac1d-e0dd2a6c581d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2048) (5482,)\n",
      "(1723, 128, 2048) (1723,)\n",
      "(1720, 128, 2048) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8f260588-385b-4682-995a-1928c0bdd547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "694d0c58-1dfc-45a0-ab98-0c8190d53a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 3s 51ms/step - loss: 0.0802 - mae: 0.1985 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "0.11642508953809738\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e5508a8a-101d-41c7-8e65-1a2c8b687945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e768c8b8-81c3-43c4-8719-db6b1d677d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_max_single_attention_traditional Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "31c5fbfc-7192-4da6-9fe1-a731a26fd3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "16574d31-1c7b-44f3-a19d-06b9cdd1575d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1cec2610-fe64-462e-b669-24eb060f4070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_max_single_attention_traditional_best Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed456665-3cf7-4ff0-8446-0b96e3d0ac75",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "aa3eb477-9322-429d-9898-150d89cadd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_4_max_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "23718147-4857-46d9-b374-18f446def2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1731134f-d19f-4827-acb4-73b527e11556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2048) (5482,)\n",
      "(1723, 128, 2048) (1723,)\n",
      "(1720, 128, 2048) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d028fd65-6a90-441b-ac0b-1de1cd01198a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_2 (Attention)     (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention_2[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention_2[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4ba7b11f-17e1-4a4a-af78-0e327b499007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 99ms/step - loss: 0.0797 - mae: 0.1976 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "0.11642508953809738\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "15323eb0-bc5a-4176-8105-4a76006eb54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ec6abd6d-141f-423b-823b-0e09dc8d9a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_max_self_attention_traditional Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "993b9cab-0c9b-4a2a-abea-1d0409d012ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "86c33a37-4aa5-49a9-9509-156ef5e9527b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "eb1560e8-c22f-4473-abfc-4eb8b00c34e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_max_self_attention_traditional_best Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6f53ed-6ee8-4d86-9cd3-2530ab05361f",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d556955c-a2d5-4c72-83f5-85cbde07b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9f107a3c-87e2-46de-ae4a-7e4d9b4d7110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9bea78f2-99c0-44d4-a78a-a441364da676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 34/5482: 0.6202116016052536%\n",
      "0.33 214/5482: 3.903684786574243%\n",
      "0.66 2649/5482: 48.32178037212696%\n",
      "1.0 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0.0 4/1723: 0.2321532211259431%\n",
      "0.33 81/1723: 4.7011027278003485%\n",
      "0.66 861/1723: 49.97098084735926%\n",
      "1.0 777/1723: 45.095763203714455%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "474a92aa-84ab-4526-bd37-d4936cd6ed93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482,) (5482,)\n",
      "(1723,) (1723,)\n",
      "(7205,) (7205,)\n",
      "[0.   0.33 0.66 1.  ] [  38  295 3510 3362]\n",
      "7205\n",
      "5474\n",
      "1731\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a5ec2a1a-6e6b-4473-b55a-69deb351df51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 28/5474: 0.5115089514066496%\n",
      "0.33 224/5474: 4.092071611253197%\n",
      "0.66 2667/5474: 48.72122762148338%\n",
      "1.0 2555/5474: 46.67519181585678%\n",
      "test:\n",
      "0.0 10/1731: 0.5777007510109763%\n",
      "0.33 71/1731: 4.101675332177932%\n",
      "0.66 843/1731: 48.7001733102253%\n",
      "1.0 807/1731: 46.62045060658579%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba832aa-6147-4aec-9e3d-6694807a3b37",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "46d4c233-c681-4a0c-94dd-9dfa29b14ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_4_max_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e53fe675-5059-4c10-93be-d878857aff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6498859b-1bc6-415a-900a-62cb25f929f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 2048) (5474,)\n",
      "(1731, 128, 2048) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cb0ac887-9b2a-4ed5-a370-7859e624c319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ce2fa771-1ca9-465d-a92d-b4e2c4dcd7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 3s 52ms/step - loss: 0.0802 - mae: 0.1997 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "0.08048681914806366\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8a4ff304-fd49-4fc7-890d-8472c4c4d020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dd24c398-28cc-448e-b43d-40fb5e3acad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_max_single_attention_balanced Accuracy:  0.4662045060658579 MSE:  0.08048682837604716 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682837604716,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4eab11eb-9466-4fdf-bee2-721eef622a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7502c8ae-d5de-405d-a7f8-6c42cd3cd000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8fb14d36-8839-4e6e-b160-5c91327fe0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_max_single_attention_balanced_best Accuracy:  0.4662045060658579 MSE:  0.08048682837604716 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682837604716,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff6d7c9-d3cc-47d1-a3cb-cc6a915ef896",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ecf51f24-f8c1-4b2d-9735-12293fb7b973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_4_max_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1119b1ea-c50d-469e-a07b-d4d3278bfd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8e4caf8a-3c09-44f1-bb6b-164ae1268f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 2048) (5474,)\n",
      "(1731, 128, 2048) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fb59c881-e8d0-4aea-976b-886eb4b81631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_3 (Attention)     (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention_3[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention_3[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9e5c4310-3ebb-4217-99ee-0f58ada156b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 92ms/step - loss: 0.0805 - mae: 0.1997 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "0.08048681914806366\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "07a180bc-8384-4f21-98cc-f49c7998b3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b5ad1454-999c-4f74-b24a-e4cd75429144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_max_self_attention_balanced Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d43d5a58-91a7-4358-bec6-6ebbb4406b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7b8d76c0-a338-4568-b439-1e249f108dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "04dfad1a-6e9b-4392-af76-3d86e5cd0d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_max_self_attention_balanced_best Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2240a29-8a37-4f7a-ab4e-2115bc4907f2",
   "metadata": {},
   "source": [
    "### STAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "25412d66-9139-4d27-987d-9ba48cbcf418",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = compute_descriptor\n",
    "stat_name = \"STAT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9692d5dd-fcae-4221-892f-9cd69ff315b7",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e216e306-f6c8-47db-b0af-f49d960d7dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bc7db292-e44c-44c2-922c-80e7b540635b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "824bbfec-7454-42d3-94ae-3b13733b41eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 34/5482: 0.6202116016052536%\n",
      "0.33 214/5482: 3.903684786574243%\n",
      "0.66 2649/5482: 48.32178037212696%\n",
      "1.0 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0.0 4/1723: 0.2321532211259431%\n",
      "0.33 81/1723: 4.7011027278003485%\n",
      "0.66 861/1723: 49.97098084735926%\n",
      "1.0 777/1723: 45.095763203714455%\n",
      "val:\n",
      "0.0 23/1720: 1.3372093023255813%\n",
      "0.33 160/1720: 9.30232558139535%\n",
      "0.66 912/1720: 53.02325581395349%\n",
      "1.0 625/1720: 36.33720930232558%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e83a416-aec1-42e9-939d-f06670fbdc3a",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "61fa11d0-0bfa-4dc2-9ebf-e34c80ecf77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_4_STAT_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b63c10e8-6978-4079-af42-a85c7e191ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "82222b96-253c-4e60-97e5-c0b0800f7b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 3072) (5482,)\n",
      "(1723, 128, 3072) (1723,)\n",
      "(1720, 128, 3072) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "021b8ce9-254e-4853-91d3-f531b53561a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1573376   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1576962 (6.02 MB)\n",
      "Trainable params: 1576962 (6.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3ab2936f-d624-46e2-90b5-a64c1ae4299a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 4s 72ms/step - loss: 0.0809 - mae: 0.1998 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 2s 41ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 2s 41ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "0.11642508953809738\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c0ed037c-dfe2-411c-b5b0-e42fcfa69de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "217769b7-94de-4a9a-9f9f-f5a3ac0edebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_STAT_single_attention_traditional Accuracy:  0.4509576320371445 MSE:  0.08119122675942898 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119122675942898, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3ab20aa4-d6a6-47eb-bb2e-b9cca2829e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "da25c659-a80a-4061-9d2e-11b1c6fd4bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1c2faf2c-a982-454b-808a-361556e7a8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_STAT_single_attention_traditional_best Accuracy:  0.4509576320371445 MSE:  0.08119122483188343 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119122483188343, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c6e970-a77a-4954-b626-9cc49d3a7bfe",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cc6df6c1-4f2d-4b2e-af74-c265f27d13e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_4_STAT_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e5dd607f-bb3e-4564-872d-c63cdb3a4c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "29088a3d-57e7-4532-94f4-6afadb4e5c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 3072) (5482,)\n",
      "(1723, 128, 3072) (1723,)\n",
      "(1720, 128, 3072) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7a6efdd1-fa95-47f9-b2c8-abd13afcf72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_4 (Attention)     (None, None, 3072)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['attention_4[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['attention_4[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 1)                    3073      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18880514 (72.02 MB)\n",
      "Trainable params: 18880514 (72.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e8086e92-1448-45b1-a14c-9798137e6f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 8s 155ms/step - loss: 0.0805 - mae: 0.1990 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 5s 119ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 5s 127ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "0.11642508953809738\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "78466251-b9fe-437e-9bff-a283a720587c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5439b150-384c-4343-bf5f-f1ed89ac94b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_STAT_self_attention_traditional Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "060f1a14-8ee6-406a-9dce-d1d5cc717f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7c553f7b-06b8-4860-913c-99240d4e21c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1d082099-f25e-4fe8-9f6e-7b97309d0615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_STAT_self_attention_traditional_best Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c550bf79-ced5-4986-ab3e-03485b9ee19f",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7d7dce7e-f9d8-4ee0-847b-eb31c283bda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5b17a098-5a21-47df-a19f-a65e8677b53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "82fbce9e-d0a9-4002-9e53-70bc439eec60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 34/5482: 0.6202116016052536%\n",
      "0.33 214/5482: 3.903684786574243%\n",
      "0.66 2649/5482: 48.32178037212696%\n",
      "1.0 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0.0 4/1723: 0.2321532211259431%\n",
      "0.33 81/1723: 4.7011027278003485%\n",
      "0.66 861/1723: 49.97098084735926%\n",
      "1.0 777/1723: 45.095763203714455%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d29ac931-d76e-4710-9081-69621bed5fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 2048) (5482,)\n",
      "(1723, 2048) (1723,)\n",
      "(7205, 2048) (7205,)\n",
      "[0.   0.33 0.66 1.  ] [  38  295 3510 3362]\n",
      "7205\n",
      "5474\n",
      "1731\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e5b6a6cc-9850-4a05-b77e-75052082ccd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 28/5474: 0.5115089514066496%\n",
      "0.33 224/5474: 4.092071611253197%\n",
      "0.66 2667/5474: 48.72122762148338%\n",
      "1.0 2555/5474: 46.67519181585678%\n",
      "test:\n",
      "0.0 10/1731: 0.5777007510109763%\n",
      "0.33 71/1731: 4.101675332177932%\n",
      "0.66 843/1731: 48.7001733102253%\n",
      "1.0 807/1731: 46.62045060658579%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a726ccc-c77a-41f6-bb81-8324c051f1c6",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "faac624b-fb2e-4113-8d39-cc63f9f67128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_4_STAT_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "70276e6d-be26-473e-913f-5c9226cbae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3e5bac24-527d-40d1-8c2d-20c7d4649a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 3072) (5474,)\n",
      "(1731, 128, 3072) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "02ad3d17-6ccf-43af-887a-e665444355e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1573376   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1576962 (6.02 MB)\n",
      "Trainable params: 1576962 (6.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e6c36e4e-d825-4930-8e04-065b89185a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 4s 73ms/step - loss: 0.0799 - mae: 0.1992 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 2s 41ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 2s 41ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "0.08048560470342636\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "79047471-ddf7-4041-bf92-67d56f9c5b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "261987ab-3779-4234-a84f-08eb31365fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_STAT_single_attention_balanced Accuracy:  0.4662045060658579 MSE:  0.08048561652532543 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048561652532543,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "bd894a63-5d54-4be5-847f-bc994b64148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "24cde9a3-7a6f-4a54-8b43-7ce0e66b29e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0d0aaf8c-65f6-4417-a0ed-2805072355b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_STAT_single_attention_balanced_best Accuracy:  0.4662045060658579 MSE:  0.08048561652532543 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048561652532543,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885e7b1b-082f-4a96-bf1a-a9b8d0e7d151",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "27245816-c981-41d1-a716-e8fd99e82a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_4_STAT_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e1d82684-03f1-4d98-9839-0abc532e7137",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "cb44ae5f-7506-4389-ac76-7feea48d3158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 3072) (5474,)\n",
      "(1731, 128, 3072) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "dceb1757-5e8f-4210-9ff3-68b69ff0bda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_5 (Attention)     (None, None, 3072)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['attention_5[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['attention_5[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 1)                    3073      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18880514 (72.02 MB)\n",
      "Trainable params: 18880514 (72.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6e863780-f148-4646-90b8-c87b97f24024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 8s 155ms/step - loss: 0.0802 - mae: 0.1996 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "0.08048681914806366\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "334b84ff-2583-41ef-8215-ef0cd8421483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8caa6189-6d01-4060-a840-50b2f4034dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_STAT_self_attention_balanced Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f8d1af6b-43e1-48b3-89dd-0fec69c648f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7a5e0aed-c3f7-427a-9e79-941f05e58449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5eebbdc1-d1ab-4f04-8d4f-4fc6dea3808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_STAT_self_attention_balanced_best Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32f0ac6-da64-4d69-b9aa-8e7075574dcd",
   "metadata": {},
   "source": [
    "# DAiSEE dataset (2 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "756348cb-d50e-48b4-b265-fd48f251b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_DIR = DATA_DIR + 'features_DAiSEE/'\n",
    "WEIGHTS_DIR = DATA_DIR + 'weights_DAiSEE/'\n",
    "TABLE_NAME = '02_DAiSEE_2_classes.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd04ac4c-137d-4545-928f-d4b44afe080b",
   "metadata": {},
   "source": [
    "## enet_b0_8_best_afew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "20d33da2-8d94-4865-bd82-769dd7d316b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_key = 'enet_b0_8_best_afew.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "05b5f242-0359-4b6c-b40c-9c96044c332b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['engaged', 'distracted']\n",
      "{'1100011002': 0, '1100011003': 0, '1100011004': 0, '1100011005': 0, '1100011006': 0, '1100011007': 0, '1100011008': 0, '1100011009': 0, '1100011010': 0, '1100011011': 0, '1100011012': 0, '1100011013': 0, '1100011014': 0, '1100011015': 0, '1100011016': 0, '1100011017': 0, '1100011018': 0, '1100011019': 0, '1100011020': 0, '1100011021': 0, '1100011022': 0, '1100011023': 0, '1100011025': 0, '1100011026': 0, '1100011027': 0, '1100011028': 0, '1100011029': 0, '1100011031': 0, '1100011032': 0, '1100011034': 0, '1100011035': 0, '1100011037': 0, '1100011038': 0, '1100011040': 0, '1100011046': 0, '1100011047': 0, '1100011048': 0, '1100011049': 0, '1100011050': 0, '1100011051': 0, '1100011052': 0, '1100011053': 0, '1100011054': 0, '1100011055': 0, '1100011056': 0, '1100011057': 0, '1100011058': 0, '1100011059': 0, '1100011060': 0, '1100011062': 0, '1100011063': 0, '1100011064': 0, '1100011066': 0, '1100011067': 0, '1100011068': 0, '1100011069': 0, '1100011070': 0, '1100011071': 0, '1100011072': 0, '1100011073': 0, '1100011075': 0, '1100011076': 0, '1100011078': 0, '1100011079': 0, '1100011080': 0, '1100011081': 0, '1100011082': 0, '1100011083': 0, '1100012001': 0, '1100012003': 0, '1100012007': 0, '1100012008': 0, '1100012009': 0, '1100012010': 0, '1100012011': 0, '1100012013': 0, '1100012014': 0, '1100012015': 0, '1100012016': 0, '1100012017': 0, '1100012018': 0, '1100012021': 0, '1100012022': 0, '1100012023': 0, '1100012025': 0, '1100012026': 0, '1100012027': 0, '1100012028': 0, '1100012030': 0, '1100012031': 0, '1100012032': 0, '1100012033': 0, '1100012036': 0, '1100012037': 0, '1100012038': 0, '1100012041': 0, '1100012042': 0, '1100012045': 0, '1100012046': 0, '1100012047': 0, '1100012049': 0, '1100012050': 0, '1100012051': 0, '1100012052': 0, '1100012057': 0, '1100012059': 0, '1100012060': 0, '1100012061': 0, '1100012062': 0, '1100012063': 0, '1100012064': 0, '1100012065': 0, '1100012066': 0, '1100012069': 0, '1100021001': 0, '1100021003': 1, '1100021015': 0, '1100021038': 0, '1100021039': 0, '1100021040': 0, '1100021045': 0, '1100021050': 0, '1100021055': 1, '1100022001': 0, '1100022002': 0, '1100022003': 0, '1100022004': 0, '1100022005': 1, '1100022008': 0, '1100022009': 0, '1100022014': 0, '1100022019': 0, '1100022020': 0, '1100022021': 0, '1100022022': 0, '1100022026': 0, '1100022027': 0, '1100022028': 0, '1100022029': 0, '1100022031': 0, '1100022035': 0, '1100022038': 0, '1100022039': 0, '1100022045': 0, '1100022046': 0, '1100022047': 0, '1100022048': 0, '1100022049': 0, '1100022051': 0, '1100022052': 0, '1100022053': 0, '1100022054': 0, '1100022055': 0, '1100022056': 0, '1100022057': 0, '1100041006': 0, '1100041015': 0, '1100041016': 0, '1100041017': 0, '1100041018': 0, '1100041021': 0, '1100041022': 0, '1100041023': 0, '1100041024': 0, '1100041029': 0, '1100041034': 0, '1100041044': 0, '1100041051': 0, '1100041052': 0, '1100042009': 0, '1100042010': 0, '1100042011': 0, '1100042017': 0, '1100042018': 0, '1100042019': 0, '1100042020': 0, '1100042023': 1, '1100042024': 0, '1100042025': 0, '1100042026': 1, '1100042029': 0, '1100042030': 0, '1100042031': 0, '1100042034': 0, '1100042040': 0, '1100042041': 0, '1100042058': 0, '1100042059': 0, '1100042060': 0, '1100051002': 0, '1100051004': 0, '1100051006': 0, '1100051007': 1, '1100051008': 0, '1100051009': 0, '1100051011': 0, '1100051012': 0, '1100051013': 0, '1100051014': 0, '1100051016': 1, '1100051017': 0, '1100051019': 0, '1100051020': 0, '1100051021': 0, '1100051022': 0, '1100051023': 0, '1100051024': 0, '1100051025': 0, '1100051026': 0, '1100051028': 0, '1100051029': 0, '1100051030': 1, '1100051031': 1, '1100051032': 0, '1100051033': 0, '1100051034': 0, '1100051035': 0, '1100051036': 0, '1100051037': 0, '1100051039': 0, '1100051041': 0, '1100051042': 0, '1100051044': 0, '1100051045': 0, '1100051046': 0, '1100051048': 0, '1100051049': 0, '1100051050': 0, '1100051051': 0, '1100051052': 0, '1100051053': 1, '1100051054': 0, '1100051055': 0, '1100051056': 0, '1100051057': 0, '1100051059': 0, '1100051061': 0, '1100051062': 0, '1100051064': 0, '1100051065': 0, '1100051066': 0, '1100051067': 0, '1100051068': 0, '1100051071': 0, '1100051076': 0, '1100051078': 0, '1100051079': 0, '1100052001': 0, '1100052002': 0, '1100052006': 0, '1100052007': 0, '1100052008': 0, '1100052009': 0, '1100052014': 1, '1100052023': 0, '1100052024': 0, '1100052026': 0, '1100052027': 0, '1100052028': 0, '1100052030': 0, '1100052031': 0, '1100052032': 0, '1100052033': 0, '1100052035': 0, '1100052036': 0, '1100052037': 0, '1100052038': 0, '1100052039': 0, '1100052040': 0, '1100052041': 0, '1100052047': 0, '1100052048': 0, '1100052049': 0, '1100052051': 0, '1100052055': 0, '1100052057': 0, '1100052060': 0, '1100052061': 0, '1100052062': 0, '1100052065': 0, '1100052068': 0, '1100052070': 0, '1100061009': 0, '1100061010': 0, '1100061011': 0, '1100061012': 0, '1100061013': 0, '1100061015': 0, '1100061016': 0, '1100061018': 0, '1100061019': 0, '1100061022': 0, '1100061023': 0, '1100061025': 0, '1100061027': 0, '1100061028': 0, '1100061030': 0, '1100061031': 0, '1100061032': 0, '1100061033': 0, '1100061034': 0, '1100061035': 0, '1100061036': 0, '1100061038': 0, '1100061039': 0, '1100061040': 0, '1100061042': 0, '1100061043': 0, '1100061044': 0, '1100061046': 0, '1100061047': 0, '1100061048': 0, '1100061049': 0, '1100061050': 0, '1100061051': 0, '1100061053': 0, '1100061057': 0, '1100061058': 0, '1100061061': 0, '1100061063': 0, '1100061064': 0, '1100061067': 0, '1100061068': 0, '1100061069': 0, '1100061073': 0, '1100061074': 0, '1100061077': 0, '1100061078': 0, '1100062004': 0, '1100062005': 0, '1100062007': 0, '1100062008': 1, '1100062009': 0, '1100062016': 0, '1100062017': 0, '1100062024': 0, '1100062028': 0, '1100062029': 0, '1100062036': 0, '1100062037': 0, '1100062044': 0, '1100062045': 1, '1100062046': 0, '1100062049': 1, '1100062051': 0, '1100062053': 0, '1100062054': 0, '1100062059': 0, '1100062060': 0, '1100062061': 0, '1100062062': 0, '1100062063': 0, '1100062064': 0, '1100062065': 0, '1100062066': 0, '1100062067': 0, '1100062068': 0, '1100062069': 0, '1100062070': 0, '1100062071': 0, '1100062072': 0, '1100071005': 0, '1100071006': 0, '1100071007': 0, '1100071008': 0, '1100071009': 0, '1100071010': 0, '1100071011': 0, '1100071012': 0, '1100071013': 0, '1100071014': 0, '1100071015': 0, '1100071016': 0, '1100071017': 0, '1100071018': 0, '1100071019': 0, '1100071020': 0, '1100071021': 0, '1100071022': 0, '1100071023': 0, '1100071024': 0, '1100071026': 0, '1100071027': 0, '1100071028': 0, '1100071029': 0, '1100071030': 0, '1100071031': 0, '1100071032': 0, '1100071033': 0, '1100071034': 0, '1100071035': 0, '1100071036': 0, '1100071037': 0, '1100071040': 0, '1100071041': 0, '1100071042': 0, '1100071043': 0, '1100071044': 0, '1100071045': 0, '1100071046': 0, '1100071047': 0, '1100071049': 0, '1100071050': 0, '1100071052': 0, '1100071054': 0, '1100071055': 0, '1100071056': 0, '1100071057': 0, '1100071058': 0, '1100071059': 0, '1100071060': 0, '1100071061': 0, '1100071062': 0, '1100071063': 0, '1100071064': 0, '1100071065': 0, '1100071066': 0, '1100071067': 0, '1100071069': 0, '1100071070': 0, '1100071071': 0, '1100071072': 0, '1100071073': 0, '1100071074': 0, '1100071075': 0, '1100071076': 0, '1100071077': 0, '1100071078': 0, '1100071079': 0, '1100071080': 0, '1100071081': 0, '1100072001': 0, '1100072002': 0, '1100072003': 0, '1100072004': 0, '1100072006': 0, '1100072007': 0, '1100072008': 0, '1100072009': 0, '1100072010': 0, '1100072011': 0, '1100072012': 0, '1100072013': 0, '1100072014': 0, '1100072015': 0, '1100072016': 0, '1100072021': 0, '1100072022': 0, '1100072023': 0, '1100072024': 0, '1100072027': 0, '1100072028': 0, '1100072029': 0, '1100072030': 0, '1100072031': 0, '1100072032': 0, '1100072033': 0, '1100072034': 0, '1100072036': 0, '1100072037': 0, '1100072038': 0, '1100072039': 0, '1100072040': 0, '1100072042': 0, '1100072043': 0, '1100072045': 0, '1100072047': 0, '1100072048': 0, '1100072049': 0, '1100072050': 0, '1100072051': 0, '1100072052': 0, '1100072053': 0, '1100072054': 0, '1100072056': 0, '1100072057': 0, '1100072058': 0, '1100072059': 0, '1100072060': 0, '1100072061': 0, '1100072062': 0, '1100072063': 0, '1100072065': 0, '1100072066': 0, '1100072067': 0, '1100072068': 0, '1100072069': 0, '1100072070': 0, '1100072071': 0, '1100072072': 0, '1100072073': 0, '1100072074': 0, '1100072075': 0, '1100072076': 0, '1100072077': 0, '1100072078': 0, '1100072079': 0, '1100072080': 0, '1100072081': 0, '1100072082': 0, '1100072083': 0, '1100072084': 0, '1100072085': 0, '1100081044': 0, '1100081045': 0, '1100081046': 0, '1100081047': 0, '1100081048': 0, '1100082002': 0, '1100082003': 0, '1100082018': 0, '1100082027': 0, '1100102003': 0, '1100111001': 0, '1100111002': 0, '1100111003': 0, '1100111008': 0, '1100111009': 0, '1100111010': 0, '1100111011': 0, '1100111012': 0, '1100111013': 0, '1100111014': 0, '1100111016': 0, '1100111017': 0, '1100111018': 0, '1100111019': 0, '1100111021': 0, '1100111023': 0, '1100111025': 0, '1100111026': 0, '1100111027': 0, '1100111029': 0, '1100111030': 0, '1100111032': 0, '1100112001': 0, '1100112002': 1, '1100112003': 0, '1100112004': 0, '1100112006': 1, '1100112007': 0, '1100112008': 0, '1100112009': 0, '1100112010': 0, '1100112011': 0, '1100112012': 0, '1100112013': 0, '1100112014': 0, '1100112015': 0, '1100112016': 0, '1100112017': 0, '1100112018': 0, '1100112021': 0, '1100112022': 0, '1100112024': 0, '1100112025': 0, '1100112026': 0, '1100112029': 0, '1100112030': 0, '1100112033': 0, '1100112035': 0, '1100112036': 0, '1100112037': 0, '1100112038': 0, '1100112039': 0, '1100112040': 0, '1100112041': 0, '1100112042': 0, '1100112043': 0, '1100112044': 0, '1100112045': 0, '1100112047': 0, '1100112048': 0, '1100112051': 0, '1100112052': 0, '1100112053': 0, '1100112056': 0, '1100112057': 0, '1100112058': 0, '1100112059': 0, '1100112060': 0, '1100112061': 0, '1100112062': 0, '1100112063': 0, '1100112064': 0, '1100112065': 0, '1100112066': 0, '1100112068': 0, '1100121002': 0, '1100121003': 0, '1100121004': 0, '1100121005': 0, '1100121006': 0, '1100121007': 0, '1100121008': 0, '1100121009': 0, '1100121010': 0, '1100121011': 0, '1100121012': 0, '1100121015': 0, '1100121016': 0, '1100121017': 0, '1100121018': 0, '1100121019': 0, '1100121020': 0, '1100121024': 0, '1100121025': 0, '1100121028': 0, '1100121031': 0, '1100121032': 0, '1100121033': 0, '1100121034': 0, '1100121035': 0, '1100121036': 0, '1100121038': 0, '1100121040': 0, '1100121041': 0, '1100121042': 0, '1100121044': 0, '1100121045': 0, '1100121047': 0, '1100121049': 0, '1100121050': 0, '1100121052': 0, '1100121053': 0, '1100121054': 0, '1100121056': 0, '1100121057': 0, '1100121059': 0, '1100121060': 0, '1100121061': 0, '1100121064': 0, '1100122001': 0, '1100122002': 0, '1100122003': 0, '1100122005': 0, '1100122006': 0, '1100122007': 0, '1100122008': 0, '1100122009': 0, '1100122010': 0, '1100122011': 0, '1100122012': 0, '1100122013': 0, '1100122014': 0, '1100122015': 0, '1100122017': 0, '1100122018': 0, '1100122019': 0, '1100122020': 0, '1100122021': 0, '1100122023': 0, '1100122024': 0, '1100122025': 0, '1100122026': 0, '1100122031': 0, '1100122032': 0, '1100122033': 0, '1100122034': 0, '1100122035': 0, '1100122036': 0, '1100122037': 0, '1100122038': 0, '1100122039': 0, '1100122040': 0, '1100122041': 0, '1100122045': 0, '1100122047': 0, '1100122048': 0, '1100122050': 0, '1100122051': 0, '1100122052': 0, '1100122053': 0, '1100122054': 0, '1100122056': 1, '1100131006': 0, '1100131007': 0, '1100131009': 0, '1100131010': 0, '1100131011': 0, '1100131012': 0, '1100131017': 1, '1100131019': 0, '1100141001': 0, '1100141002': 0, '1100141003': 0, '1100141004': 0, '1100141005': 0, '1100141006': 0, '1100141007': 0, '1100141008': 0, '1100141009': 0, '1100141010': 0, '1100141011': 0, '1100141012': 0, '1100141013': 1, '1100141014': 0, '1100141015': 0, '1100141016': 0, '1100141017': 0, '1100141019': 0, '1100141020': 0, '1100141021': 0, '1100141023': 0, '1100141027': 1, '1100141028': 0, '1100141029': 0, '1100141030': 0, '1100141031': 0, '1100141032': 0, '1100141033': 0, '1100141034': 0, '1100141035': 0, '1100141036': 0, '1100141039': 0, '1100141040': 0, '1100141042': 0, '1100141044': 0, '1100141045': 0, '1100141046': 0, '1100141049': 0, '1100141050': 0, '1100141052': 0, '1100141053': 0, '1100141054': 0, '1100141055': 0, '1100141056': 0, '1100141057': 0, '1100142002': 0, '1100142003': 0, '1100142004': 0, '1100142007': 0, '1100142008': 0, '1100142009': 0, '1100142010': 0, '1100142011': 0, '1100142013': 0, '1100142014': 0, '1100142015': 0, '1100142017': 0, '1100142018': 0, '1100142019': 0, '1100142021': 0, '1100142022': 0, '1100142023': 0, '1100142024': 0, '1100142027': 0, '1100142028': 0, '1100142029': 0, '1100142030': 0, '1100142031': 0, '1100142032': 0, '1100142033': 1, '1100142034': 0, '1100142035': 0, '1100142038': 0, '1100142041': 0, '1100142043': 0, '1100142044': 0, '1100142045': 0, '1100142046': 0, '1100142048': 0, '1100142049': 0, '1100142050': 0, '1100142051': 0, '1100142052': 0, '1100142053': 0, '1100142056': 0, '1100142057': 0, '1100142058': 0, '1100142059': 0, '1100142060': 0, '1100151003': 0, '1100151004': 0, '1100151008': 0, '1100151009': 0, '1100151010': 0, '1100151011': 1, '1100151012': 0, '1100151013': 0, '1100151014': 0, '1100151015': 0, '1100151016': 0, '1100151017': 0, '1100151018': 0, '1100151019': 0, '1100151020': 0, '1100151021': 0, '1100151022': 0, '1100151023': 0, '1100151024': 0, '1100151028': 0, '1100151030': 0, '1100151032': 0, '1100151033': 0, '1100151035': 0, '1100151037': 0, '1100151038': 0, '1100151039': 0, '1100151040': 0, '1100151042': 0, '1100151043': 0, '1100151044': 0, '1100151047': 0, '1100151049': 0, '1100151050': 0, '1100151051': 0, '1100151052': 0, '1100151054': 0, '1100151055': 0, '1100151056': 0, '1100151057': 1, '1100151058': 0, '1100151062': 0, '1100152001': 0, '1100152004': 0, '1100152005': 0, '1100152006': 0, '1100152008': 0, '1100152009': 0, '1100152010': 1, '1100152013': 0, '1100152014': 0, '1100152015': 0, '1100152017': 1, '1100152019': 0, '1100152020': 0, '1100152022': 0, '1100152024': 0, '1100152025': 0, '1100152026': 0, '1100152027': 0, '1100152031': 1, '1100152032': 0, '1100152039': 0, '1100152040': 0, '1100152041': 0, '1100152042': 0, '1100152043': 0, '1100152048': 0, '1100152049': 0, '1100152050': 0, '1100152051': 0, '1100152055': 1, '1100152056': 0, '1100152061': 0, '1100152062': 0, '1100152067': 0, '1100152069': 0, '1100152070': 1, '1100161002': 0, '1100161004': 0, '1100161011': 0, '1100161012': 0, '1100161013': 0, '1100161014': 0, '1100161015': 0, '1100161016': 0, '1100161020': 0, '1100161021': 0, '1100161022': 0, '1100161023': 0, '1100161028': 0, '1100161029': 0, '1100161032': 0, '1100161035': 0, '1100161036': 0, '1100161038': 0, '1100161039': 0, '1100161041': 0, '1100161043': 0, '1100161044': 0, '1100161045': 0, '1100161046': 0, '1100161048': 0, '1100161050': 0, '1100161053': 1, '1100162005': 1, '1100162007': 0, '1100162011': 0, '1100162016': 1, '1100171001': 0, '1100171002': 0, '1100171004': 1, '1100171005': 0, '1100171007': 0, '1100171008': 1, '1100171009': 0, '1100171010': 0, '1100171011': 0, '1100171012': 0, '1100171013': 0, '1100171015': 0, '1100171016': 0, '1100171017': 0, '1100171019': 0, '1100171021': 0, '1100171022': 0, '1100171023': 0, '1100171031': 0, '1100171035': 0, '1100171036': 0, '1100171038': 0, '1100171039': 0, '1100171040': 0, '1100171041': 0, '1100171043': 0, '1100171045': 0, '1100171049': 0, '1100171055': 0, '1100171056': 0, '1100171057': 0, '1100171059': 1, '1100171061': 0, '1100171063': 0, '1100171064': 0, '1100171065': 0, '1100171067': 0, '1100171069': 0, '1100171070': 0, '1100171071': 0, '1100171072': 0, '1100171073': 0, '1100171074': 0, '1100171075': 0, '1100171076': 0, '1100171077': 0, '1100171078': 0, '1100171080': 0, '1100171083': 0, '1100172003': 0, '1100172004': 0, '1100172007': 0, '1100172012': 1, '1100172013': 0, '1100172014': 0, '1100172015': 0, '1100172016': 0, '1100172017': 1, '1100172018': 0, '1100172020': 0, '1100172021': 0, '1100172022': 0, '1100172026': 0, '1100172028': 0, '1100172030': 0, '1100172032': 0, '1100172033': 1, '1100172034': 1, '1100172035': 0, '1100172037': 0, '1100172039': 0, '1100172042': 0, '1100172043': 1, '1100172047': 0, '1100172050': 0, '1100172058': 1, '1100172063': 0, '1100172066': 0, '1100411010': 0, '1100411011': 0, '1100411012': 0, '1100411013': 0, '1100411015': 0, '1100411016': 0, '1100411018': 0, '1100411020': 0, '1100411023': 0, '1100411036': 0, '1100411041': 0, '1100411045': 0, '1100411047': 0, '1100411048': 0, '1100411049': 0, '1100411050': 0, '1100411051': 0, '1100411053': 0, '1100411054': 0, '1100411055': 0, '1100411057': 0, '1100412001': 0, '1100412003': 0, '1100412010': 0, '1100412018': 1, '1100412033': 1, '1100412038': 0, '1100412039': 1, '1100412040': 0, '1110031003': 0, '1110031007': 0, '1110031010': 1, '1110031011': 0, '1110031012': 0, '1110031014': 0, '1110031019': 0, '1110031020': 0, '1110031021': 0, '1110031025': 1, '1110031027': 1, '1110031031': 0, '1110031033': 1, '1110031037': 0, '1110031038': 1, '1110031039': 0, '1110031040': 0, '1110031042': 0, '1110031048': 0, '1110031049': 0, '1110031050': 0, '1110031056': 1, '1110031061': 0, '1110031062': 0, '1110031063': 1, '1110031064': 0, '1110031065': 0, '1110032002': 0, '1110032004': 0, '1110032006': 0, '1110032008': 0, '1110032010': 0, '1110032014': 1, '1110032015': 0, '1110032018': 0, '1110032019': 0, '1110032020': 0, '1110032021': 0, '1110032022': 0, '1110032023': 0, '1110032024': 0, '1110032025': 0, '1110032027': 1, '1110032029': 0, '1110032031': 0, '1110032032': 0, '1110032033': 0, '1110032034': 0, '1110032036': 0, '1110032037': 0, '1110032042': 0, '1110032043': 1, '1110032045': 0, '1110032047': 0, '1110032048': 0, '1110032049': 0, '1110032050': 0, '1110032051': 0, '1110032052': 0, '1110032053': 0, '1110032055': 0, '1110032056': 0, '1110032058': 0, '1110032059': 0, '1110032060': 0, '1110032061': 0, '1110032062': 0, '1110032063': 0, '1813740111': 0, '1813740112': 0, '1813740115': 0, '1813740116': 0, '1813740118': 0, '1813740119': 0, '1813740122': 0, '1813740123': 0, '1813740124': 0, '1813740126': 0, '1813740127': 0, '1813740128': 0, '1813740131': 0, '1813740133': 0, '1813740135': 0, '1813740137': 0, '1813740138': 1, '1813740143': 0, '1813740144': 0, '1813740149': 0, '181374015': 0, '1813740150': 0, '1813740153': 0, '1813740155': 0, '1813740157': 0, '1813740159': 0, '181374016': 0, '1813740162': 0, '1813740164': 0, '1813740165': 0, '1813740167': 0, '1813740168': 0, '1813740169': 0, '181374017': 0, '1813740171': 0, '1813740172': 0, '1813740173': 0, '1813740174': 0, '1813740176': 0, '1813740178': 0, '1813740179': 0, '1813740180': 0, '1813740181': 0, '1813740182': 0, '1813740183': 0, '1813740184': 1, '1813740185': 1, '181374019': 0, '1813740210': 0, '1813740211': 0, '1813740212': 0, '1813740213': 0, '1813740214': 0, '1813740218': 0, '1813740219': 0, '1813740220': 0, '1813740221': 0, '1813740224': 0, '1813740225': 0, '1813740226': 0, '1813740227': 0, '1813740229': 0, '181374023': 0, '1813740231': 0, '1813740232': 0, '1813740233': 0, '1813740234': 0, '1813740235': 0, '1813740236': 0, '1813740237': 0, '1813740238': 0, '181374024': 0, '1813740240': 0, '1813740241': 0, '1813740242': 0, '1813740243': 0, '1813740245': 0, '1813740249': 0, '181374025': 0, '1813740250': 0, '1813740251': 0, '1813740252': 0, '1813740253': 0, '1813740255': 0, '1813740256': 0, '1813740257': 0, '1813740258': 0, '1813740259': 0, '181374026': 0, '1813740260': 0, '1813740261': 0, '1813740262': 0, '1813740263': 0, '1813740264': 0, '1813740265': 0, '1813740266': 0, '1813740267': 0, '1813740268': 0, '1813740269': 0, '181374027': 0, '1813740270': 0, '1813740271': 0, '1813740272': 0, '1813740273': 0, '1813740274': 0, '1813740275': 0, '1813740276': 0, '1813740277': 0, '1813740278': 0, '1813740279': 0, '181374028': 0, '181374029': 0, '2000481035': 0, '2000481036': 0, '2000481037': 0, '2000481038': 0, '2000481039': 0, '2000481040': 0, '2000481041': 0, '2000481043': 0, '2000481048': 0, '2000482008': 0, '2000482009': 0, '2000482012': 0, '2000482018': 0, '2000482021': 0, '2000482034': 0, '2000482037': 0, '2000482038': 0, '2000482039': 0, '2000482041': 0, '2000482042': 0, '2000482043': 0, '2000482044': 0, '2000482049': 0, '2000482050': 0, '2000482052': 0, '2000482059': 0, '2000482065': 0, '2000482066': 0, '2000482067': 0, '2000482068': 0, '2000482070': 0, '2000491062': 0, '2000491064': 0, '2000491065': 0, '2000491066': 0, '2000491067': 0, '2000491068': 0, '2000491070': 0, '2000491072': 0, '2000491074': 0, '2000491075': 0, '2000491076': 0, '2000491077': 1, '2000491078': 0, '2000491079': 0, '2000501001': 0, '2000501002': 0, '2000501003': 0, '2000501004': 0, '2000501006': 1, '2000501009': 0, '2000501010': 0, '2000501011': 0, '2000501012': 0, '2000501014': 0, '2000501015': 0, '2000501016': 0, '2000501018': 0, '2000501019': 0, '2000501020': 0, '2000501021': 0, '2000501023': 0, '2000501027': 0, '2000501028': 0, '2000501030': 1, '2000501031': 0, '2000501032': 0, '2000501033': 0, '2000501035': 0, '2000501036': 0, '2000501037': 0, '2000501038': 0, '2000501039': 0, '2000501040': 0, '2000501041': 0, '2000501042': 0, '2000501043': 0, '2000501044': 0, '2000501045': 0, '2000501046': 0, '2000501049': 0, '2000501050': 0, '2000501051': 0, '2000501052': 0, '2000501053': 0, '2000501054': 0, '2000501056': 0, '2000501057': 0, '2000501060': 0, '2000501061': 0, '2000501062': 0, '2000501063': 0, '2000501065': 0, '2000501066': 0, '2000501067': 0, '2000501071': 0, '2000501074': 0, '2000501075': 0, '2000501076': 0, '2000501078': 0, '2000502002': 0, '2000502005': 0, '2000502006': 0, '2000502007': 0, '2000502009': 0, '2000502010': 0, '2000502012': 0, '2000502013': 0, '2000502014': 0, '2000502015': 0, '2000502019': 0, '2000502020': 0, '2000502023': 0, '2000502025': 0, '2000502033': 0, '2000502036': 0, '2000502037': 0, '2000502039': 0, '2000502040': 0, '2000502041': 0, '2000502043': 0, '2000502044': 0, '2000502045': 0, '2000502047': 0, '2000502048': 0, '2000502049': 0, '2000502050': 0, '2000502051': 0, '2000502053': 1, '2000502054': 0, '2000502055': 0, '2000502056': 0, '2000502057': 0, '2000502058': 0, '2000502059': 0, '2000502061': 0, '2000502062': 0, '2000502063': 0, '2000502065': 1, '2000502066': 0, '2000502067': 0, '2000502069': 0, '2000502070': 0, '2000502072': 0, '2000502073': 0, '2000502075': 0, '2000502076': 0, '2000502077': 0, '2000502078': 0, '2000502081': 1, '2000502084': 0, '2000502087': 0, '2000502088': 0, '2000502090': 0, '2000541001': 0, '2000541002': 0, '2000541003': 0, '2000541006': 0, '2000541007': 0, '2000541010': 0, '2000541011': 0, '2000541014': 0, '2000541015': 0, '2000541016': 0, '2000541018': 0, '2000541019': 0, '2000541020': 0, '2000541021': 0, '2000541022': 0, '2000541023': 0, '2000541024': 0, '2000541025': 0, '2000541027': 0, '2000541028': 0, '2000541029': 0, '2000541030': 0, '2000541031': 0, '2000541032': 0, '2000541034': 0, '2000541035': 0, '2000541038': 0, '2000541039': 0, '2000541040': 0, '2000541041': 0, '2000541043': 0, '2000541044': 0, '2000541045': 0, '2000541046': 0, '2000541049': 0, '2000541050': 0, '2000541051': 0, '2000541052': 0, '2000541053': 0, '2000541054': 0, '2000541055': 0, '2000541056': 0, '2000541057': 0, '2000541059': 0, '2000541062': 0, '2000541064': 0, '2000541066': 0, '2000541067': 0, '2000541068': 0, '2000541069': 0, '2000541070': 0, '2000541071': 0, '2000541072': 0, '2000541073': 0, '2000541074': 0, '2000541075': 0, '2000541076': 0, '2000541077': 0, '2000541079': 0, '2000541080': 0, '2000541081': 0, '2000542001': 0, '2000542002': 0, '2000542007': 0, '2000542008': 0, '2000542009': 0, '2000542010': 0, '2000542013': 0, '2000542015': 0, '2000542016': 0, '2000542021': 0, '2000542022': 0, '2000542025': 0, '2000542026': 0, '2000542027': 0, '2000542029': 0, '2000542030': 0, '2000542032': 0, '2000542033': 0, '2000542034': 0, '2000542035': 0, '2000542036': 0, '2000542042': 0, '2000542049': 0, '2000542050': 0, '2000542051': 0, '2000542052': 0, '2000542054': 0, '2000542056': 0, '2026140111': 0, '2026140113': 0, '2026140116': 0, '2026140117': 0, '2026140118': 0, '2026140119': 0, '2026140120': 0, '2026140122': 0, '2026140124': 0, '2026140125': 0, '2026140126': 0, '2026140128': 0, '2026140129': 0, '2026140130': 0, '2026140131': 0, '2026140133': 0, '2026140134': 0, '2026140135': 0, '2026140138': 0, '2026140141': 0, '2026140145': 0, '2026140147': 0, '2026140149': 0, '202614015': 0, '2026140151': 0, '2026140154': 0, '2026140158': 0, '2026140159': 0, '202614016': 0, '2026140160': 0, '2026140161': 0, '2026140165': 0, '2026140169': 0, '202614017': 0, '2026140170': 0, '2026140172': 0, '202614018': 0, '202614019': 0, '202614020': 0, '202614021': 0, '2026140210': 0, '2026140212': 0, '2026140213': 0, '2026140220': 0, '2026140221': 0, '2026140223': 0, '2026140224': 0, '2026140225': 0, '202614023': 0, '2026140230': 0, '2026140233': 0, '2026140236': 0, '2026140237': 0, '2026140239': 0, '2026140241': 0, '2026140243': 0, '2026140246': 0, '2026140247': 0, '2026140249': 0, '202614025': 0, '2026140250': 0, '2026140253': 0, '2026140254': 0, '2026140255': 0, '2026140257': 1, '2026140259': 0, '2026140260': 0, '2026140263': 0, '2026140264': 1, '2026140272': 0, '2026140273': 1, '2026140275': 0, '2026140276': 0, '2026140277': 0, '2026140279': 0, '2026140281': 0, '202614029': 0, '205601011': 0, '2056010112': 0, '2056010113': 0, '2056010114': 0, '2056010116': 0, '2056010118': 0, '2056010119': 0, '205601012': 0, '2056010120': 0, '2056010122': 0, '2056010123': 0, '2056010124': 0, '2056010126': 0, '2056010130': 0, '2056010133': 0, '2056010134': 1, '2056010136': 0, '2056010137': 0, '2056010139': 0, '2056010141': 0, '2056010142': 0, '2056010148': 0, '2056010149': 0, '2056010153': 0, '2056010155': 0, '2056010156': 0, '2056010157': 0, '205601016': 0, '2056010160': 0, '2056010162': 0, '2056010164': 0, '2056010165': 0, '2056010167': 0, '205601017': 0, '205601018': 0, '2056010210': 0, '2056010212': 0, '2056010213': 0, '2056010214': 0, '2056010215': 0, '2056010218': 0, '2056010219': 0, '2056010222': 0, '2056010224': 1, '2056010225': 0, '2056010226': 0, '2056010228': 0, '2056010229': 0, '2056010230': 0, '2056010232': 0, '2056010233': 0, '2056010234': 0, '2056010235': 0, '2056010236': 0, '2056010238': 0, '2056010239': 0, '205601024': 0, '2056010240': 0, '2056010241': 0, '2056010242': 0, '2056010244': 0, '2056010245': 0, '2056010247': 0, '2056010249': 0, '205601025': 0, '2056010250': 0, '2056010252': 0, '2056010253': 0, '2056010254': 0, '2056010255': 0, '2056010258': 0, '2056010260': 0, '2056010261': 0, '2056010262': 0, '2056010263': 0, '2056010265': 0, '2056010267': 0, '2056010269': 0, '205601027': 0, '2056010272': 0, '2056010274': 0, '2056010275': 0, '2056010276': 0, '2056010277': 0, '2056010279': 0, '205601028': 0, '2056010281': 0, '2056010283': 0, '2100511002': 0, '2100511003': 0, '2100511005': 0, '2100511008': 0, '2100511011': 0, '2100511012': 0, '2100511013': 0, '2100511015': 0, '2100511016': 0, '2100511018': 0, '2100511019': 0, '2100511024': 0, '2100511026': 0, '2100511027': 0, '2100511028': 0, '2100511031': 0, '2100511032': 0, '2100511034': 0, '2100511035': 0, '2100511036': 0, '2100511038': 0, '2100511039': 0, '2100511040': 0, '2100511044': 0, '2100511048': 0, '2100511057': 0, '2100511058': 0, '2100511059': 0, '2100511060': 0, '2100511061': 0, '2100511062': 0, '2100511063': 0, '2100511064': 0, '2100511065': 0, '2100511067': 0, '2100511069': 1, '2100511070': 0, '2100511071': 0, '2100511072': 0, '2100511073': 0, '2100511074': 0, '2100511076': 0, '2100511077': 0, '2100511078': 0, '2100511079': 0, '2100511080': 0, '2100511081': 0, '2100511082': 0, '2100512001': 0, '2100512002': 0, '2100512003': 0, '2100512006': 0, '2100512007': 0, '2100512009': 0, '2100512010': 0, '2100512011': 0, '2100512012': 0, '2100512014': 0, '2100512015': 0, '2100512016': 0, '2100512017': 0, '2100512018': 0, '2100512020': 0, '2100512021': 0, '2100512025': 0, '2100512026': 0, '2100512028': 0, '2100512029': 0, '2100512032': 0, '2100512034': 0, '2100512035': 0, '2100512036': 0, '2100512037': 0, '2100512038': 0, '2100512039': 0, '2100512041': 0, '2100512042': 0, '2100512044': 0, '2100512045': 0, '2100512051': 1, '2100512052': 0, '2100512053': 0, '2100512055': 0, '2100512057': 0, '2100512058': 0, '2100512061': 0, '2100512062': 0, '2100512063': 0, '2100512064': 1, '2100512065': 0, '2100521002': 0, '2100521005': 0, '2100521006': 0, '2100521008': 0, '2100521009': 0, '2100521010': 0, '2100521013': 0, '2100521014': 0, '2100521015': 0, '2100521016': 0, '2100521017': 0, '2100521018': 0, '2100521021': 0, '2100521022': 0, '2100521023': 0, '2100521024': 0, '2100521025': 0, '2100521026': 0, '2100521027': 0, '2100521028': 0, '2100521029': 0, '2100521030': 0, '2100521031': 0, '2100521032': 1, '2100521033': 0, '2100521034': 0, '2100521035': 0, '2100521037': 0, '2100521038': 0, '2100521039': 0, '2100521040': 0, '2100521041': 0, '2100521042': 0, '2100521043': 0, '2100521044': 0, '2100521046': 0, '2100521047': 0, '2100521048': 0, '2100521049': 0, '2100521050': 0, '2100521051': 0, '2100521052': 0, '2100521054': 0, '2100521055': 0, '2100521056': 0, '2100521057': 0, '2100521059': 0, '2100521060': 0, '2100521061': 0, '2100521062': 0, '2100521063': 0, '2100521067': 0, '2100521069': 0, '2100521070': 0, '2100521072': 0, '2100521073': 0, '2100521074': 0, '2100521075': 0, '2100521076': 0, '2100521077': 0, '2100521078': 0, '2100521079': 0, '2100522001': 0, '2100522004': 0, '2100522005': 0, '2100522006': 0, '2100522007': 0, '2100522008': 0, '2100522009': 0, '2100522010': 0, '2100522011': 0, '2100522012': 0, '2100522013': 0, '2100522018': 0, '2100522019': 0, '2100522020': 0, '2100522021': 0, '2100522023': 0, '2100522024': 0, '2100522026': 0, '2100522028': 0, '2100522031': 0, '2100522033': 0, '2100522034': 0, '2100522035': 0, '2100522036': 0, '2100522038': 0, '2100522039': 0, '2100522040': 0, '2100522041': 0, '2100522042': 0, '2100522046': 0, '2100522047': 0, '2100522048': 0, '2100522049': 0, '2100522050': 0, '2100522051': 0, '2100522052': 0, '2100522053': 0, '2100522054': 0, '2100522055': 0, '2100522056': 0, '2100522059': 0, '2100522060': 0, '2100522061': 0, '2100522062': 0, '2100522063': 0, '2100522064': 0, '2100522067': 0, '2100522068': 0, '2100522070': 0, '2100531001': 0, '2100531002': 0, '2100531003': 0, '2100531004': 0, '2100531006': 0, '2100531007': 0, '2100531008': 0, '2100531009': 0, '2100531010': 0, '2100531012': 0, '2100531013': 0, '2100531014': 0, '2100531015': 0, '2100531016': 0, '2100531017': 0, '2100531018': 0, '2100531019': 0, '2100531021': 0, '2100531022': 0, '2100531023': 0, '2100531024': 0, '2100531025': 0, '2100531026': 0, '2100531027': 0, '2100531028': 0, '2100531030': 0, '2100531031': 0, '2100531033': 0, '2100531034': 0, '2100531035': 0, '2100531036': 0, '2100531037': 0, '2100531040': 0, '2100531041': 0, '2100531042': 0, '2100531043': 0, '2100531044': 0, '2100531045': 0, '2100531047': 0, '2100531048': 0, '2100531049': 0, '2100531050': 0, '2100531051': 0, '2100531052': 0, '2100531053': 0, '2100531054': 1, '2100531055': 0, '2100531056': 0, '2100531057': 0, '2100531058': 0, '2100531059': 0, '2100531060': 0, '2100531061': 0, '2100531063': 0, '2100531064': 0, '2100531065': 0, '2100531066': 0, '2100531067': 0, '2100531068': 0, '2100531070': 0, '2100531071': 0, '2100531072': 0, '2100531073': 0, '2100531074': 0, '2100531076': 0, '2100531077': 0, '2100531078': 0, '2100531079': 0, '2100531080': 0, '2100531081': 0, '2100531082': 0, '2100531084': 0, '2100532002': 0, '2100532003': 0, '2100532004': 0, '2100532005': 0, '2100532007': 0, '2100532008': 0, '2100532010': 0, '2100532012': 0, '2100532013': 0, '2100532015': 0, '2100532016': 1, '2100532017': 0, '2100532019': 0, '2100532020': 0, '2100532022': 1, '2100532023': 0, '2100532024': 0, '2100532025': 0, '2100532026': 0, '2100532027': 0, '2100532028': 0, '2100532029': 0, '2100532030': 0, '2100532031': 0, '2100532032': 0, '2100532033': 0, '2100532034': 0, '2100532037': 0, '2100532042': 0, '2100532043': 0, '2100532044': 0, '2100532045': 0, '2100532046': 0, '2100532047': 0, '2100532048': 0, '2100532050': 0, '2100532052': 0, '2100532053': 0, '2100532054': 0, '2100532055': 0, '2100532056': 0, '2100532057': 0, '2100532058': 0, '2100532059': 0, '2100532060': 0, '2100532061': 0, '2100532062': 0, '2100532063': 0, '2100532064': 0, '2100532066': 0, '2100532067': 0, '2100532068': 0, '2100532070': 0, '2100532071': 0, '2100532072': 0, '2100551002': 0, '2100551005': 1, '2100551006': 0, '2100551007': 0, '2100551010': 1, '2100551011': 0, '2100551013': 0, '2100551014': 0, '2100551015': 0, '2100551016': 0, '2100551017': 0, '2100551018': 0, '2100551019': 0, '2100551020': 0, '2100551021': 0, '2100551022': 0, '2100551023': 0, '2100551024': 0, '2100551025': 0, '2100551027': 0, '2100551028': 0, '2100551029': 0, '2100551032': 1, '2100551033': 0, '2100551034': 0, '2100551035': 1, '2100551036': 0, '2100551037': 0, '2100551039': 0, '2100551041': 0, '2100551042': 1, '2100551043': 0, '2100551044': 0, '2100551045': 0, '2100551046': 0, '2100551049': 0, '2100551050': 0, '2100551051': 0, '2100551052': 0, '2100551053': 0, '2100551054': 0, '2100551055': 0, '2100551056': 0, '2100551057': 0, '2100551059': 0, '2100551060': 0, '2100551061': 0, '2100551062': 0, '2100551063': 0, '2100551064': 0, '2100551065': 0, '2100551066': 0, '2100551067': 0, '2100551068': 0, '2100551069': 0, '2100551071': 0, '2100551072': 0, '2100551073': 0, '2100551074': 0, '2100551075': 0, '2100551076': 0, '2100551077': 0, '2100551079': 0, '2100551080': 0, '2100551081': 0, '2100552002': 0, '2100552003': 0, '2100552004': 0, '2100552005': 0, '2100552006': 0, '2100552007': 0, '2100552008': 0, '2100552009': 0, '2100552010': 0, '2100552011': 0, '2100552012': 0, '2100552013': 0, '2100552014': 0, '2100552015': 0, '2100552016': 0, '2100552017': 0, '2100552018': 0, '2100552019': 0, '2100552021': 0, '2100552022': 0, '2100552023': 0, '2100552024': 0, '2100552025': 0, '2100552027': 0, '2100552028': 0, '2100552029': 0, '2100552030': 0, '2100552031': 0, '2100552032': 0, '2100552033': 0, '2100552034': 0, '2100552035': 0, '2100552037': 0, '2100552038': 0, '2100552039': 0, '2100552041': 0, '2100552042': 0, '2100552043': 0, '2100552044': 0, '2100552045': 0, '2100552047': 0, '2100552048': 1, '2100552051': 0, '2100552052': 0, '2100552053': 0, '2100552055': 0, '2100552057': 0, '2100552059': 0, '2100552060': 0, '2100552061': 0, '2100552062': 0, '2100552063': 1, '2100552065': 0, '2100552066': 0, '2100552068': 0, '2100552072': 0, '2100561006': 0, '2100561010': 0, '2100561011': 0, '2100561013': 0, '2100561014': 0, '2100561015': 0, '2100561016': 0, '2100561018': 0, '2100561019': 0, '2100561020': 0, '2100561021': 0, '2100561022': 0, '2100561023': 0, '2100561024': 0, '2100561027': 0, '2100561029': 0, '2100561032': 0, '2100561038': 0, '2100561043': 0, '2100561044': 0, '2100561046': 0, '2100561051': 0, '2100561052': 0, '2100561053': 0, '2100561054': 0, '2100561056': 0, '2100561057': 0, '2100561058': 0, '2100561059': 0, '2100561062': 0, '2100561063': 0, '2100561064': 0, '2100561065': 0, '2100561070': 0, '2100561071': 0, '2100561074': 0, '2100561079': 0, '2100562001': 0, '2100562002': 0, '2100562003': 0, '2100562004': 0, '2100562005': 0, '2100562007': 0, '2100562008': 0, '2100562009': 0, '2100562010': 0, '2100562011': 0, '2100562012': 0, '2100562013': 0, '2100562014': 0, '2100562015': 0, '2100562017': 0, '2100562018': 0, '2100562019': 1, '2100562020': 0, '2100562024': 1, '2100562026': 0, '2100562027': 0, '2100562029': 0, '2100562030': 0, '2100562032': 0, '2100562033': 0, '2100562034': 0, '2100562035': 0, '2100562037': 0, '2100562038': 0, '2100562039': 0, '2100562040': 0, '2100562042': 0, '2100562043': 0, '2100562044': 0, '2100562046': 0, '2100562047': 0, '2100562048': 0, '2100562049': 0, '2100562050': 0, '2100562051': 0, '2100562053': 0, '2100562054': 0, '2100562055': 0, '2100562056': 0, '2100562058': 0, '2100562059': 0, '2100562060': 0, '2100562061': 0, '2100571001': 0, '2100571002': 1, '2100571004': 0, '2100571007': 1, '2100571008': 0, '2100571009': 0, '2100571011': 0, '2100571012': 0, '2100571013': 0, '2100571015': 0, '2100571017': 0, '2100571018': 0, '2100571019': 0, '2100571020': 0, '2100571021': 1, '2100571022': 0, '2100571023': 1, '2100571024': 0, '2100571025': 0, '2100571027': 0, '2100571029': 0, '2100571030': 0, '2100571031': 0, '2100571033': 0, '2100571034': 0, '2100571036': 0, '2100571038': 1, '2100571039': 0, '2100571040': 0, '2100571041': 0, '2100571042': 0, '2100571044': 1, '2100571045': 0, '2100571046': 0, '2100571047': 0, '2100571048': 0, '2100571049': 1, '2100571050': 0, '2100571051': 0, '2100571052': 0, '2100571053': 0, '2100571055': 0, '2100571056': 0, '2100571057': 0, '2100571058': 0, '2100571061': 0, '2100571062': 1, '2100571063': 0, '2100571064': 0, '2100571065': 0, '2100571066': 0, '2100571067': 0, '2100571068': 0, '2100571069': 0, '2100571070': 0, '2100571072': 0, '2100571073': 0, '2100571074': 0, '2100571075': 0, '2100571077': 0, '2100571078': 0, '2100571079': 0, '2100571081': 0, '2100571082': 0, '2100572001': 0, '2100572002': 0, '2100572004': 0, '2100572006': 0, '2100572009': 0, '2100572010': 0, '2100572011': 0, '2100572012': 0, '2100572013': 0, '2100572015': 0, '2100572017': 0, '2100572018': 0, '2100572019': 0, '2100572020': 0, '2100572021': 1, '2100572023': 0, '2100572024': 0, '2100572025': 0, '2100572026': 0, '2100572027': 0, '2100572028': 0, '2100572029': 0, '2100572030': 0, '2100572032': 0, '2100572033': 0, '2100572034': 0, '2100572036': 0, '2100572038': 0, '2100572039': 0, '2100572040': 0, '2100572041': 0, '2100572042': 0, '2100572043': 0, '2100572044': 0, '2100572045': 0, '2100572046': 0, '2100572047': 0, '2100572048': 0, '2100572050': 0, '2100572051': 0, '2100572054': 0, '2100572055': 0, '2100572056': 0, '2100572057': 1, '2100572058': 0, '2100572059': 0, '2100572060': 0, '2100572061': 0, '2100572062': 0, '2100572063': 0, '2100572064': 0, '2100572067': 0, '2100572068': 0, '2100572069': 0, '2100581001': 1, '2100581002': 0, '2100581003': 0, '2100581004': 0, '2100581005': 0, '2100581006': 0, '2100581007': 0, '2100581009': 0, '2100581010': 0, '2100581011': 0, '2100581012': 0, '2100581013': 0, '2100581014': 0, '2100581015': 0, '2100581018': 0, '2100581019': 0, '2100581021': 1, '2100581022': 0, '2100581024': 0, '2100581025': 0, '2100581026': 0, '2100581027': 0, '2100581028': 0, '2100581029': 0, '2100581030': 0, '2100581034': 0, '2100581035': 0, '2100581036': 0, '2100581037': 0, '2100581038': 0, '2100581039': 0, '2100581040': 0, '2100581041': 0, '2100581042': 0, '2100581044': 0, '2100581045': 0, '2100581051': 0, '2100581054': 0, '2100581056': 0, '2100581057': 0, '2100581058': 0, '2100581059': 0, '2100581061': 0, '2100581062': 0, '2100581064': 0, '2100581066': 0, '2100581067': 0, '2100581068': 0, '2100581069': 0, '2100581070': 0, '2100581071': 0, '2100581072': 0, '2100581073': 0, '2100581074': 0, '2100581075': 0, '2100581076': 0, '2100581077': 0, '2100582001': 0, '2100582002': 0, '2100582003': 0, '2100582004': 0, '2100582005': 0, '2100582006': 0, '2100582008': 0, '2100582009': 0, '2100582012': 0, '2100582013': 0, '2100582015': 0, '2100582017': 0, '2100582019': 0, '2100582020': 0, '2100582021': 0, '2100582023': 0, '2100582024': 0, '2100582025': 0, '2100582026': 0, '2100582027': 1, '2100582028': 0, '2100582038': 0, '2100582043': 0, '2100582044': 0, '2100582045': 0, '2100582046': 0, '2100582048': 0, '2100582050': 0, '2100582051': 0, '2100582052': 1, '2100582053': 0, '2100582054': 0, '2100582055': 1, '2100582056': 1, '2100582057': 1, '2100582058': 1, '2100582060': 1, '2100582061': 1, '2100582062': 1, '2100582064': 0, '2100582067': 0, '2100582069': 0, '2100591002': 0, '2100591003': 0, '2100591004': 0, '2100591005': 0, '2100591006': 0, '2100591007': 0, '2100591008': 0, '2100591010': 0, '2100591013': 0, '2100591015': 0, '2100591016': 0, '2100591017': 0, '2100591019': 0, '2100591020': 0, '2100591021': 0, '2100591022': 0, '2100591023': 0, '2100591025': 0, '2100591026': 0, '2100591027': 0, '2100591028': 0, '2100591030': 0, '2100591034': 0, '2100591035': 0, '2100591036': 0, '2100591037': 0, '2100591038': 0, '2100591039': 0, '2100591040': 0, '2100591041': 0, '2100591042': 0, '2100591043': 0, '2100591044': 0, '2100591045': 0, '2100591046': 1, '2100591047': 0, '2100591048': 0, '2100591049': 0, '2100591050': 0, '2100591053': 0, '2100591054': 0, '2100591055': 0, '2100591056': 0, '2100591057': 0, '2100591059': 0, '2100591060': 0, '2100591061': 0, '2100591062': 0, '2100591064': 0, '2100591065': 0, '2100591066': 0, '2100591067': 0, '2100591068': 0, '2100591069': 0, '2100591070': 0, '2100591072': 0, '2100591073': 0, '2100591074': 0, '2100591075': 0, '2100591076': 0, '2100591077': 0, '2100591078': 0, '2100591080': 0, '2100591081': 0, '2100591082': 0, '2100592002': 0, '2100592003': 0, '2100592004': 0, '2100592005': 0, '2100592007': 0, '2100592009': 0, '2100592010': 0, '2100592011': 0, '2100592012': 0, '2100592013': 0, '2100592014': 0, '2100592015': 0, '2100592016': 0, '2100592017': 0, '2100592018': 0, '2100592019': 0, '2100592020': 0, '2100592021': 0, '2100592022': 0, '2100592023': 0, '2100592024': 0, '2100592025': 0, '2100592026': 0, '2100592027': 0, '2100592028': 0, '2100592029': 0, '2100592030': 0, '2100592032': 0, '2100592033': 0, '2100592034': 0, '2100592035': 0, '2100592036': 0, '2100592038': 0, '2100592040': 0, '2100592041': 0, '2100592042': 0, '2100592043': 0, '2100592044': 0, '2100592046': 0, '2100592047': 0, '2100592048': 0, '2100592049': 0, '2100592052': 0, '2100592053': 0, '2100592054': 0, '2100592056': 0, '2100592057': 0, '2100592058': 0, '2100592059': 0, '2100592060': 0, '2100592064': 0, '2100592065': 0, '2100592066': 0, '2100592067': 0, '2100592068': 0, '2100592069': 0, '2100592070': 0, '2100592071': 0, '2100592072': 0, '2100601001': 0, '2100601002': 0, '2100601004': 0, '2100601005': 0, '2100601006': 0, '2100601007': 0, '2100601008': 0, '2100601009': 0, '2100601010': 0, '2100601011': 0, '2100601012': 1, '2100601013': 0, '2100601014': 0, '2100601015': 0, '2100601016': 0, '2100601017': 0, '2100601018': 1, '2100601020': 0, '2100601021': 0, '2100601023': 0, '2100601024': 0, '2100601025': 0, '2100601027': 0, '2100601028': 0, '2100601029': 0, '2100601030': 0, '2100601031': 0, '2100601032': 0, '2100601033': 0, '2100601035': 0, '2100601036': 0, '2100601037': 0, '2100601038': 0, '2100601039': 0, '2100601040': 0, '2100601041': 0, '2100601042': 0, '2100601043': 0, '2100601044': 0, '2100601045': 0, '2100601046': 0, '2100601049': 0, '2100601050': 0, '2100601052': 0, '2100601053': 0, '2100601054': 0, '2100601055': 0, '2100601056': 0, '2100601057': 0, '2100601059': 0, '2100601062': 0, '2100601063': 0, '2100601064': 0, '2100601065': 0, '2100601066': 0, '2100601067': 0, '2100601068': 0, '2100601069': 0, '2100601071': 0, '2100601073': 0, '2100601074': 0, '2100601075': 0, '2100601077': 0, '2100601078': 0, '2100602001': 0, '2100602002': 0, '2100602003': 0, '2100602004': 0, '2100602005': 0, '2100602006': 0, '2100602008': 0, '2100602009': 0, '2100602010': 0, '2100602011': 0, '2100602012': 0, '2100602014': 0, '2100602015': 0, '2100602017': 0, '2100602018': 0, '2100602019': 0, '2100602020': 0, '2100602022': 0, '2100602023': 0, '2100602024': 0, '2100602025': 0, '2100602026': 0, '2100602027': 0, '2100602028': 0, '2100602029': 0, '2100602030': 0, '2100602032': 0, '2100602033': 0, '2100602034': 0, '2100602035': 0, '2100602036': 0, '2100602038': 0, '2100602040': 0, '2100602041': 1, '2100602042': 0, '2100602043': 0, '2100602044': 0, '2100602046': 0, '2100602047': 0, '2100602049': 0, '2100602050': 0, '2100602051': 0, '2100602052': 0, '2100602053': 0, '2100602054': 0, '2100602056': 0, '2100602058': 0, '2100602059': 0, '2100602060': 0, '2100602061': 0, '2100602062': 0, '2100602063': 0, '2100602065': 0, '2100602067': 0, '2100602068': 0, '2100602069': 0, '2100602072': 0, '2100611002': 0, '2100611003': 0, '2100611004': 0, '2100611005': 0, '2100611006': 0, '2100611010': 0, '2100611011': 0, '2100611012': 0, '2100611013': 0, '2100611014': 0, '2100611015': 0, '2100611016': 0, '2100611017': 0, '2100611018': 0, '2100611019': 0, '2100611021': 0, '2100611023': 0, '2100611024': 0, '2100611025': 0, '2100611026': 0, '2100611027': 1, '2100611028': 0, '2100611029': 0, '2100611031': 0, '2100611032': 0, '2100611034': 0, '2100611035': 0, '2100611036': 0, '2100611037': 0, '2100611038': 0, '2100611039': 0, '2100611040': 0, '2100611041': 0, '2100611042': 0, '2100611043': 0, '2100611044': 0, '2100611045': 0, '2100611046': 0, '2100611047': 0, '2100611048': 0, '2100611049': 0, '2100611050': 0, '2100611051': 0, '2100611052': 0, '2100611055': 0, '2100611056': 0, '2100611057': 0, '2100611058': 0, '2100611059': 0, '2100611060': 0, '2100611061': 0, '2100611062': 0, '2100611063': 0, '2100611064': 0, '2100611066': 0, '2100611067': 0, '2100611068': 0, '2100611069': 0, '2100611070': 0, '2100611071': 0, '2100611075': 0, '2100611076': 0, '2100611077': 0, '2100611078': 0, '2100611079': 0, '2100611081': 0, '2100611083': 0, '2100612001': 0, '2100612002': 0, '2100612003': 0, '2100612005': 0, '2100612006': 0, '2100612007': 0, '2100612008': 0, '2100612009': 1, '2100612010': 0, '2100612011': 0, '2100612012': 0, '2100612014': 0, '2100612015': 0, '2100612020': 0, '2100612022': 0, '2100612024': 0, '2100612025': 0, '2100612026': 0, '2100612027': 0, '2100612028': 0, '2100612029': 0, '2100612030': 0, '2100612031': 0, '2100612033': 0, '2100612034': 0, '2100612035': 0, '2100612037': 0, '2100612038': 0, '2100612040': 0, '2100612041': 0, '2100612042': 0, '2100612043': 0, '2100612044': 0, '2100612045': 0, '2100612046': 0, '2100612047': 0, '2100612048': 0, '2100612051': 0, '2100612053': 0, '2100612056': 0, '2100612057': 0, '2100612058': 0, '2100612059': 0, '2100612060': 0, '2100612061': 0, '2100612062': 0, '2100612063': 0, '2100612064': 0, '2100612065': 0, '2100612066': 0, '2100612067': 0, '2100612068': 0, '2100612069': 0, '2100612070': 0, '2100612071': 0, '2100612072': 0, '2260510110': 0, '2260510113': 0, '2260510114': 0, '2260510115': 0, '2260510116': 0, '2260510118': 0, '2260510122': 0, '2260510124': 0, '2260510125': 0, '2260510126': 0, '2260510127': 0, '2260510129': 0, '226051013': 0, '2260510131': 0, '2260510134': 0, '2260510136': 0, '2260510138': 0, '2260510139': 0, '226051014': 0, '2260510140': 0, '2260510141': 0, '2260510142': 0, '2260510143': 0, '2260510146': 0, '2260510147': 0, '2260510148': 0, '2260510151': 0, '2260510152': 0, '2260510155': 1, '2260510156': 0, '2260510158': 0, '2260510159': 0, '226051016': 0, '2260510160': 0, '2260510162': 0, '2260510163': 1, '2260510167': 0, '2260510168': 0, '226051017': 0, '2260510172': 0, '2260510174': 0, '2260510176': 0, '2260510177': 1, '2260510180': 0, '2260510182': 0, '2260510183': 0, '2260510185': 0, '226051019': 0, '226051021': 0, '2260510212': 0, '2260510213': 0, '2260510214': 0, '2260510217': 0, '226051022': 0, '2260510220': 0, '2260510221': 0, '2260510222': 0, '2260510223': 0, '2260510227': 0, '2260510228': 0, '2260510229': 0, '226051023': 0, '2260510230': 0, '2260510231': 0, '2260510232': 0, '2260510233': 0, '2260510237': 0, '2260510238': 0, '2260510240': 0, '2260510241': 0, '2260510242': 0, '2260510243': 0, '2260510244': 0, '2260510247': 0, '2260510248': 0, '226051025': 0, '2260510250': 0, '2260510252': 0, '2260510253': 0, '2260510254': 0, '2260510257': 0, '2260510258': 0, '2260510259': 0, '226051026': 0, '2260510260': 0, '2260510262': 0, '2260510266': 0, '2260510267': 0, '226051027': 0, '2260510270': 0, '2260510271': 0, '2260510272': 0, '2260510276': 0, '2260510277': 0, '2260510278': 0, '240846010': 0, '240846011': 0, '2408460110': 0, '2408460111': 0, '2408460118': 1, '240846012': 0, '2408460120': 0, '2408460123': 0, '2408460125': 0, '2408460126': 0, '2408460127': 0, '2408460129': 0, '240846013': 0, '2408460130': 0, '2408460131': 0, '2408460132': 0, '2408460133': 0, '2408460134': 0, '2408460135': 0, '2408460137': 1, '2408460139': 0, '2408460143': 0, '2408460145': 0, '2408460146': 0, '2408460148': 0, '2408460149': 0, '240846015': 0, '2408460150': 0, '2408460151': 0, '2408460152': 0, '2408460154': 0, '2408460155': 0, '2408460156': 0, '2408460158': 0, '2408460159': 0, '240846016': 0, '2408460163': 0, '2408460166': 0, '240846017': 0, '240846018': 0, '240846019': 0, '2408460211': 0, '2408460212': 0, '2408460213': 0, '2408460215': 0, '2408460217': 0, '2408460219': 0, '240846022': 0, '2408460220': 0, '2408460221': 0, '2408460222': 0, '2408460223': 0, '2408460225': 0, '2408460226': 0, '2408460227': 0, '2408460229': 0, '240846023': 0, '2408460234': 0, '2408460236': 0, '2408460237': 0, '2408460238': 0, '240846024': 0, '2408460240': 0, '2408460242': 0, '2408460243': 0, '2408460244': 0, '2408460246': 0, '2408460247': 0, '2408460249': 0, '2408460252': 0, '2408460254': 0, '2408460255': 0, '2408460257': 0, '2408460260': 0, '2408460261': 0, '2408460265': 0, '2408460266': 0, '2408460268': 0, '2408460269': 0, '240846027': 0, '2408460271': 0, '2408460272': 0, '2408460274': 0, '2408460276': 0, '2408460277': 0, '2408460278': 0, '240846028': 0, '2408460280': 0, '240846029': 0, '24851011': 0, '248510111': 0, '248510112': 0, '248510114': 0, '248510116': 0, '248510117': 0, '248510118': 0, '248510119': 0, '248510120': 0, '248510125': 0, '248510127': 0, '248510128': 0, '248510129': 0, '24851013': 0, '248510131': 0, '248510136': 0, '248510137': 0, '24851014': 0, '248510142': 0, '248510147': 0, '248510148': 0, '24851015': 0, '248510150': 0, '248510151': 0, '248510153': 0, '248510155': 0, '248510156': 0, '248510157': 0, '248510160': 0, '248510161': 0, '248510163': 0, '248510164': 0, '248510167': 0, '248510170': 0, '24851018': 0, '24851019': 0, '248510211': 0, '248510212': 0, '248510213': 0, '248510214': 0, '248510215': 0, '248510216': 0, '24851022': 0, '248510220': 0, '248510223': 0, '248510225': 0, '248510227': 0, '248510229': 0, '248510230': 0, '248510232': 0, '248510233': 0, '248510235': 0, '248510236': 0, '24851024': 0, '248510241': 0, '248510242': 0, '248510245': 0, '248510246': 0, '248510248': 0, '248510249': 0, '248510250': 0, '248510251': 0, '248510253': 0, '248510255': 0, '248510256': 0, '248510259': 0, '24851026': 0, '248510260': 0, '248510262': 0, '248510264': 0, '248510265': 0, '248510267': 0, '248510268': 0, '24851027': 0, '248510271': 0, '248510272': 0, '248510273': 0, '248510276': 0, '248510278': 0, '24851028': 0, '2904280110': 0, '29042801110': 0, '29042801170': 0, '29042801180': 0, '2904280120': 0, '29042801220': 0, '29042801230': 0, '29042801250': 0, '29042801260': 0, '29042801290': 0, '29042801300': 0, '29042801320': 0, '29042801340': 0, '29042801350': 0, '29042801370': 1, '29042801390': 0, '2904280140': 0, '29042801440': 0, '29042801450': 0, '29042801470': 0, '29042801480': 0, '2904280150': 0, '29042801500': 0, '29042801550': 0, '29042801570': 0, '29042801580': 0, '2904280160': 0, '29042801600': 0, '29042801630': 0, '29042801640': 0, '29042801650': 0, '29042801680': 0, '29042801690': 0, '2904280170': 0, '29042801710': 0, '29042801740': 0, '29042801750': 0, '29042801770': 0, '29042801780': 0, '29042801790': 0, '2904280180': 0, '2904280190': 0, '29042802110': 0, '29042802140': 0, '29042802150': 0, '29042802180': 0, '29042802200': 0, '29042802220': 0, '29042802240': 0, '29042802260': 0, '29042802280': 0, '2904280230': 0, '29042802310': 0, '29042802320': 0, '29042802340': 0, '29042802350': 0, '29042802380': 0, '29042802390': 0, '29042802410': 0, '29042802420': 0, '29042802430': 0, '29042802440': 0, '29042802450': 0, '29042802460': 0, '29042802470': 0, '29042802480': 0, '2904280250': 0, '29042802500': 0, '29042802510': 0, '29042802520': 0, '29042802530': 0, '29042802560': 0, '29042802570': 0, '2904280260': 1, '29042802600': 0, '29042802640': 0, '29042802660': 0, '29042802670': 0, '29042802680': 0, '29042802690': 0, '2904280270': 0, '29042802700': 0, '29042802720': 0, '29042802740': 0, '29042802750': 0, '29042802760': 0, '29042802770': 0, '29042802790': 0, '2904280280': 0, '29042802800': 0, '29042802830': 0, '29042802860': 0, '2904280290': 0, '303830110': 0, '303830113': 1, '303830115': 0, '303830117': 0, '303830118': 0, '303830121': 0, '303830122': 0, '303830123': 0, '303830126': 1, '303830127': 0, '303830128': 0, '30383013': 0, '303830131': 0, '303830132': 0, '303830133': 0, '303830138': 0, '303830139': 1, '30383014': 0, '303830141': 0, '303830143': 0, '303830144': 0, '303830146': 0, '303830147': 0, '303830148': 0, '303830149': 1, '30383015': 0, '303830151': 0, '303830155': 1, '303830156': 0, '303830157': 0, '303830158': 0, '303830159': 0, '30383016': 0, '303830160': 0, '303830161': 0, '303830162': 0, '303830166': 0, '303830167': 0, '303830169': 0, '303830171': 0, '303830174': 0, '303830175': 0, '303830178': 0, '303830182': 0, '303830183': 0, '303830184': 0, '303830210': 0, '303830211': 0, '303830212': 0, '303830216': 0, '303830217': 0, '303830218': 0, '30383022': 0, '303830220': 0, '303830221': 0, '303830223': 0, '303830224': 0, '303830225': 0, '303830227': 0, '303830229': 0, '30383023': 1, '303830234': 0, '303830236': 0, '303830239': 0, '303830240': 0, '303830241': 0, '303830242': 0, '303830245': 0, '303830246': 0, '303830247': 0, '303830249': 0, '30383025': 0, '303830250': 0, '303830255': 0, '303830258': 0, '303830259': 0, '303830263': 0, '303830269': 0, '303830270': 0, '303830273': 0, '303830274': 0, '303830278': 0, '30383028': 0, '3100621001': 0, '3100621002': 0, '3100621003': 0, '3100621004': 0, '3100621005': 0, '3100621007': 0, '3100621009': 0, '3100621010': 0, '3100621011': 0, '3100621012': 0, '3100621013': 0, '3100621014': 0, '3100621016': 0, '3100621018': 0, '3100621019': 0, '3100621020': 0, '3100621022': 0, '3100621023': 0, '3100621024': 0, '3100621025': 0, '3100621026': 0, '3100621027': 0, '3100621028': 0, '3100621030': 0, '3100621031': 0, '3100621032': 0, '3100621033': 0, '3100621034': 0, '3100621035': 0, '3100621037': 1, '3100621039': 0, '3100621040': 0, '3100621041': 0, '3100621042': 0, '3100621043': 0, '3100621045': 0, '3100621046': 0, '3100621047': 0, '3100621048': 0, '3100621049': 0, '3100621051': 0, '3100621052': 0, '3100621053': 0, '3100621055': 0, '3100621057': 0, '3100621058': 0, '3100621059': 0, '3100621061': 0, '3100621062': 0, '3100621063': 0, '3100621064': 0, '3100622001': 0, '3100622002': 0, '3100622003': 0, '3100622006': 0, '3100622007': 0, '3100622008': 0, '3100622009': 0, '3100622011': 0, '3100622013': 0, '3100622015': 0, '3100622019': 0, '3100622020': 0, '3100622021': 0, '3100622023': 0, '3100622024': 0, '3100622026': 0, '3100622027': 0, '3100622033': 0, '3100622034': 0, '3100622036': 0, '3100622037': 0, '3100622038': 0, '3100622040': 0, '3100622041': 0, '3100622042': 0, '3100622043': 0, '3100622044': 0, '3100622045': 0, '3100622047': 0, '3100622048': 0, '3100622049': 0, '3100622051': 0, '3100622053': 0, '3100622054': 0, '3100622057': 0, '3100631001': 0, '3100631002': 0, '3100631003': 0, '3100631004': 0, '3100631005': 0, '3100631006': 0, '3100631008': 0, '3100631009': 0, '3100631010': 0, '3100631011': 0, '3100631013': 0, '3100631014': 0, '3100631015': 0, '3100631016': 0, '3100631018': 0, '3100631019': 0, '3100631022': 0, '3100631023': 0, '3100631025': 0, '3100631026': 0, '3100631027': 0, '3100631029': 0, '3100631032': 0, '3100631035': 0, '3100631037': 0, '3100631042': 0, '3100631043': 0, '3100631044': 0, '3100631045': 0, '3100631046': 0, '3100631047': 0, '3100631048': 0, '3100631049': 0, '3100631051': 0, '3100631052': 0, '3100631053': 0, '3100631054': 0, '3100631055': 0, '3100631056': 0, '3100631057': 0, '3100631058': 0, '3100631059': 0, '3100631062': 0, '3100632001': 0, '3100632002': 0, '3100632003': 0, '3100632004': 0, '3100632007': 0, '3100632008': 0, '3100632011': 0, '3100632012': 0, '3100632015': 0, '3100632016': 0, '3100632017': 0, '3100632018': 0, '3100632019': 0, '3100632021': 0, '3100632023': 0, '3100632024': 0, '3100632025': 0, '3100632026': 0, '3100632027': 0, '3100632030': 0, '3100632031': 0, '3100632039': 0, '3100632041': 0, '3100632042': 0, '3100632043': 0, '3100632044': 0, '3100632045': 0, '3100641002': 0, '3100641003': 1, '3100641004': 1, '3100641006': 1, '3100641007': 0, '3100641008': 0, '3100641023': 1, '3100642002': 0, '3100642003': 0, '3100642005': 0, '3100642006': 0, '3100642007': 1, '3100642008': 0, '3100642009': 0, '3100642011': 0, '3100642012': 0, '3100642013': 0, '3100642015': 0, '3100642017': 1, '3100642019': 0, '3100642020': 0, '3100642021': 0, '3100642022': 0, '3100642024': 0, '3100642025': 0, '3100642026': 0, '3100642027': 0, '3100642028': 0, '3100642030': 0, '3100642031': 0, '3100642032': 0, '3100642033': 0, '3100642034': 0, '3100642035': 0, '3100642036': 1, '3100642037': 0, '3100642038': 0, '3100642040': 0, '3100642045': 0, '3100642047': 0, '3100642052': 0, '3100642054': 0, '3100642055': 1, '3100642056': 0, '3100642057': 0, '3100642058': 0, '3100642060': 0, '3100642061': 0, '3100642063': 0, '3100642064': 0, '3100642066': 0, '3100642069': 0, '3100642070': 0, '3100661002': 0, '3100661007': 0, '3100661009': 0, '3100661015': 0, '3100661016': 0, '3100661022': 0, '3100661023': 0, '3100661024': 0, '3100661025': 0, '3100661027': 0, '3100661028': 0, '3100661029': 0, '3100661031': 0, '3100661032': 0, '3100661033': 0, '3100661036': 0, '3100661037': 0, '3100661038': 0, '3100661040': 0, '3100661043': 0, '3100661044': 0, '3100661046': 0, '3100661049': 0, '3100661050': 0, '3100662014': 0, '3100662015': 0, '3100662016': 0, '3100662017': 0, '3100662020': 0, '3100662022': 0, '3100662023': 0, '3100662026': 0, '3100662029': 0, '3100662032': 0, '3100662035': 0, '3100662036': 0, '3100662037': 1, '3100662045': 0, '3100662046': 0, '3100662048': 0, '3100662049': 0, '3100662050': 0, '3100662052': 0, '3100662053': 0, '3100662055': 0, '3100681001': 0, '3100681002': 0, '3100681005': 0, '3100681006': 0, '3100681015': 1, '3100681017': 1, '3100681018': 1, '3100681042': 1, '3100681043': 0, '3100681044': 0, '3100681045': 0, '3100681046': 0, '3100682001': 0, '3100682002': 0, '3100682003': 0, '3100682007': 0, '3100682008': 0, '3100682030': 0, '3100682040': 0, '3100691005': 0, '3100691006': 0, '3100691007': 0, '3100691011': 0, '3100691012': 0, '3100691021': 0, '3100691026': 0, '3100691042': 0, '3100691045': 0, '3100691048': 0, '3100692002': 0, '3100692005': 0, '3100692006': 0, '3100692007': 0, '3100692009': 0, '3100692010': 0, '3100692011': 0, '3100692012': 0, '3100692013': 0, '3100692015': 1, '3100692016': 0, '3100692020': 0, '3100692022': 0, '3100692023': 0, '3100692024': 0, '3100692025': 0, '3100692028': 0, '3100692029': 0, '3100692032': 0, '3100692034': 0, '3100692035': 0, '3100692038': 0, '3100692039': 0, '3100692045': 0, '3100692052': 0, '3100692054': 0, '3100692055': 0, '3100692056': 0, '3100701001': 0, '3100701002': 0, '3100701004': 0, '3100701005': 0, '3100701008': 0, '3100701009': 0, '3100701010': 1, '3100701011': 0, '3100701012': 0, '3100701013': 0, '3100701014': 0, '3100701015': 0, '3100701016': 0, '3100701019': 0, '3100701021': 0, '3100701022': 0, '3100701023': 1, '3100701024': 0, '3100701029': 0, '3100701031': 0, '3100701032': 0, '3100701036': 0, '3100701043': 0, '3100701044': 0, '3100701050': 0, '3100701051': 0, '3100701056': 0, '3100701057': 0, '3100701058': 0, '3100701061': 0, '3100701063': 0, '3100701072': 0, '3100701073': 0, '3100702004': 0, '3100702005': 0, '3100702006': 0, '3100702010': 0, '3100702012': 0, '3100702013': 0, '3100702016': 0, '3100702017': 0, '3100702019': 0, '3100702020': 0, '3100702021': 0, '3100702022': 0, '3100702023': 0, '3100702024': 0, '3100702025': 0, '3100702026': 0, '3100702027': 0, '3100702028': 0, '3100702029': 0, '3100702030': 0, '3100702031': 0, '3100702033': 0, '3100702034': 0, '3100702035': 0, '3100702036': 0, '3100702037': 0, '3100702038': 1, '3100702039': 0, '3100702040': 0, '3100702041': 0, '3100702043': 0, '3100702044': 0, '3100702045': 0, '3100702046': 0, '3100702047': 0, '3100702048': 0, '3100702051': 0, '3100702052': 0, '3100702054': 0, '3100702055': 0, '3100702059': 0, '3100702060': 0, '3100702061': 0, '3100702062': 0, '3100702063': 0, '3100702064': 0, '3100702065': 0, '3100702066': 0, '3100702067': 0, '3100702068': 0, '3100711007': 0, '3100711009': 0, '3100711042': 0, '3100711043': 0, '3100711049': 0, '3100711050': 0, '3100711051': 0, '3100711052': 0, '3100712014': 0, '3100721002': 0, '3100721003': 0, '3100721004': 0, '3100721005': 0, '3100721006': 0, '3100721007': 0, '3100721008': 0, '3100721011': 0, '3100721012': 0, '3100721013': 0, '3100721014': 0, '3100721015': 0, '3100721016': 0, '3100721018': 0, '3100721019': 0, '3100721020': 0, '3100721021': 0, '3100721022': 0, '3100721023': 0, '3100721024': 0, '3100721028': 0, '3100721029': 0, '3100721030': 0, '3100721031': 1, '3100721032': 0, '3100721033': 0, '3100721034': 0, '3100721036': 0, '3100721038': 0, '3100721039': 0, '3100721040': 0, '3100721041': 0, '3100721042': 0, '3100721044': 0, '3100721045': 0, '3100721046': 0, '3100721047': 0, '3100721048': 0, '3100721049': 0, '3100721050': 0, '3100721051': 0, '3100721052': 0, '3100721053': 0, '3100721054': 0, '3100721055': 0, '3100721056': 0, '3100721057': 0, '3100721058': 0, '3100721059': 0, '3100721060': 0, '3100721062': 0, '3100721063': 0, '3100721064': 0, '3100721065': 0, '3100721066': 0, '3100721068': 0, '3100721070': 0, '3100721071': 0, '3100721072': 0, '3100722003': 0, '3100722004': 0, '3100722005': 0, '3100722006': 0, '3100722007': 0, '3100722012': 0, '3100722013': 0, '3100722014': 0, '3100722016': 0, '3100722017': 0, '3100722020': 0, '3100722021': 0, '3100722022': 0, '3100722023': 0, '3100722024': 0, '3100722025': 0, '3100722026': 0, '3100722027': 0, '3100722030': 0, '3100722031': 0, '3100722032': 0, '3100722033': 0, '3100722034': 0, '3100722036': 0, '3100722038': 0, '3100722039': 0, '3100722040': 0, '3100722042': 0, '3100722044': 0, '3100722045': 0, '3100722046': 0, '3100722047': 0, '3100722048': 0, '3100722054': 0, '3100722055': 0, '3100722057': 0, '3100722059': 0, '3100722061': 0, '3100722062': 0, '3100722063': 0, '3100722064': 0, '3100722065': 0, '3100722066': 0, '3100722067': 0, '3100722068': 0, '3100722069': 0, '3100722070': 0, '3100722072': 0, '3100722073': 0, '3100722074': 0, '3100722076': 0, '3100722077': 0, '3100722078': 0, '3100722079': 0, '3100731001': 0, '3100731006': 0, '3100731007': 0, '3100731008': 0, '3100731009': 0, '3100731011': 0, '3100731012': 0, '3100731013': 0, '3100731014': 0, '3100731025': 0, '3100731026': 0, '3100731028': 0, '3100731029': 0, '3100731030': 0, '3100731031': 0, '3100731037': 0, '3100731038': 0, '3100731050': 0, '3100731052': 0, '3100731054': 0, '3100731056': 0, '3100731057': 0, '3100731058': 0, '3100732001': 0, '3100732002': 0, '3100732003': 0, '3100732006': 0, '3100732013': 0, '3100732014': 0, '3100732015': 0, '3100732017': 0, '3100732018': 0, '3100732020': 0, '3100732021': 0, '3100732022': 0, '3100732023': 0, '3100732025': 0, '3100732027': 0, '3100732028': 0, '3100732029': 0, '3100732031': 0, '3100732036': 0, '3100732040': 0, '3100732041': 0, '3100732042': 0, '3100732067': 0, '3100741001': 0, '3100741002': 0, '3100741003': 0, '3100741004': 0, '3100741011': 0, '3100741012': 0, '3100741013': 0, '3100741014': 0, '3100741016': 0, '3100741017': 0, '3100741018': 0, '3100741019': 0, '3100741020': 0, '3100741022': 0, '3100741023': 0, '3100741024': 0, '3100741025': 0, '3100741026': 0, '3100741027': 0, '3100741028': 0, '3100741029': 0, '3100741030': 0, '3100741032': 0, '3100741034': 0, '3100741035': 0, '3100741036': 0, '3100741037': 0, '3100741038': 0, '3100741039': 0, '3100741042': 0, '3100741043': 0, '3100741044': 0, '3100741045': 0, '3100741047': 0, '3100741049': 0, '3100741053': 0, '3100741054': 0, '3100741056': 0, '3100741057': 0, '3100741058': 0, '3100741059': 0, '3100741060': 0, '3100741061': 0, '3100741063': 0, '3100741064': 0, '3100741065': 0, '3100741066': 1, '3100741068': 0, '3100741069': 0, '3100741070': 0, '3100741071': 0, '3100741072': 0, '3100741073': 0, '3100741074': 0, '3100741075': 0, '3100741076': 0, '3100741077': 0, '3100741079': 0, '3100742001': 0, '3100742003': 0, '3100742004': 0, '3100742005': 0, '3100742007': 0, '3100742010': 0, '3100742011': 0, '3100742012': 0, '3100742013': 0, '3100742014': 0, '3100742015': 0, '3100742016': 0, '3100742018': 0, '3100742020': 0, '3100742021': 0, '3100742022': 0, '3100742023': 0, '3100742024': 0, '3100742025': 0, '3100742027': 0, '3100742028': 0, '3100742033': 0, '3100742034': 0, '3100742037': 0, '3100742038': 0, '3100742041': 0, '3100742042': 0, '3100742044': 0, '3100742045': 0, '3100742046': 0, '3100742047': 0, '3100742048': 0, '3100742050': 0, '3100742051': 0, '3100742052': 0, '3100742053': 0, '3100742054': 0, '3100742055': 0, '3100742056': 0, '3100742057': 0, '3100742058': 1, '3100742059': 0, '3100742060': 0, '3100742061': 0, '3100742062': 0, '3100742063': 0, '3100742065': 0, '3100742067': 0, '3100742068': 0, '3100751003': 0, '3100751004': 0, '3100751005': 0, '3100751006': 1, '3100751007': 1, '3100751008': 1, '3100751009': 0, '3100751010': 1, '3100751011': 0, '3100751012': 1, '3100751014': 0, '3100751015': 0, '3100751016': 0, '3100751017': 0, '3100751018': 0, '3100751019': 1, '3100751020': 0, '3100751021': 0, '3100751022': 0, '3100751024': 0, '3100751026': 0, '3100751027': 0, '3100751028': 0, '3100751032': 0, '3100751033': 0, '3100751034': 0, '3100751035': 0, '3100751037': 0, '3100751039': 0, '3100751040': 0, '3100751041': 0, '3100751043': 0, '3100751044': 0, '3100751045': 0, '3100751048': 0, '3100751050': 0, '3100751055': 0, '3100751056': 1, '3100751057': 1, '3100751058': 0, '3100751059': 0, '3100751063': 0, '3100751064': 0, '3100751065': 0, '3100751068': 0, '3100751069': 0, '3100751070': 0, '3100751072': 0, '3100751073': 0, '3100751074': 0, '3100751075': 0, '3100751076': 0, '3100751077': 0, '3100751078': 0, '3100751079': 0, '3100752001': 0, '3100752002': 0, '3100752003': 0, '3100752004': 0, '3100752005': 0, '3100752007': 0, '3100752008': 0, '3100752009': 0, '3100752010': 0, '3100752012': 0, '3100752014': 1, '3100752015': 0, '3100752016': 0, '3100752017': 0, '3100752018': 0, '3100752019': 0, '3100752020': 0, '3100752021': 1, '3100752022': 0, '3100752023': 0, '3100752026': 0, '3100752027': 0, '3100752029': 0, '3100752030': 1, '3100752032': 0, '3100752034': 0, '3100752035': 0, '3100752036': 0, '3100752037': 1, '3100752038': 0, '3100752039': 0, '3100752040': 0, '3100752041': 0, '3100752042': 0, '3100752043': 0, '3100752044': 0, '3100752045': 0, '3100752046': 0, '3100752047': 0, '3100752048': 1, '3100752049': 0, '3100752050': 0, '3100752051': 1, '3100752052': 0, '3100752054': 0, '3100752055': 1, '3100752056': 0, '3100752057': 0, '3100752058': 0, '3100752059': 0, '3100752060': 0, '3100752061': 0, '3100752063': 0, '3100752068': 0, '3100761003': 1, '3100761004': 0, '3100761005': 1, '3100761007': 0, '3100761008': 1, '3100761013': 0, '3100761014': 0, '3100761015': 0, '3100761016': 0, '3100761017': 0, '3100761019': 0, '3100761020': 0, '3100761021': 0, '3100761023': 0, '3100761027': 0, '3100761028': 0, '3100761029': 0, '3100761030': 0, '3100761031': 0, '3100761034': 0, '3100761042': 0, '3100761046': 0, '3100761047': 0, '3100761048': 0, '3100761049': 0, '3100761050': 0, '3100761051': 0, '3100761056': 0, '3100761062': 0, '3100761063': 0, '3100762003': 0, '3100762004': 1, '3100762005': 0, '3100762007': 0, '3100762012': 0, '3100762013': 0, '3100762016': 0, '3100762027': 1, '3100762029': 0, '3100762030': 1, '3100762052': 0, '3100762053': 0, '3100762055': 1, '3100771001': 1, '3100771002': 0, '3100771003': 0, '3100771005': 0, '3100771007': 1, '3100771008': 0, '3100771009': 0, '3100771012': 0, '3100771014': 0, '3100771016': 0, '3100771018': 0, '3100771019': 0, '3100771020': 0, '3100771021': 0, '3100771022': 0, '3100771024': 0, '3100771027': 0, '3100771028': 0, '3100771029': 0, '3100771030': 0, '3100771031': 0, '3100771032': 0, '3100771033': 0, '3100771034': 0, '3100771036': 0, '3100771037': 0, '3100771039': 0, '3100771040': 0, '3100771041': 0, '3100771042': 0, '3100771043': 0, '3100771046': 0, '3100771047': 0, '3100771048': 0, '3100771049': 0, '3100771050': 0, '3100771052': 0, '3100771054': 0, '3100771055': 0, '3100771056': 0, '3100771057': 0, '3100771058': 0, '3100771059': 0, '3100771062': 0, '3100771063': 0, '3100771064': 0, '3100771065': 0, '3100771066': 0, '3100771067': 0, '3100771068': 0, '3100771069': 0, '3100771071': 0, '3100771072': 0, '3100771073': 0, '3100771075': 0, '3100771076': 0, '3100771077': 0, '3100771078': 0, '3100771080': 0, '3100771081': 0, '3100772002': 0, '3100772004': 0, '3100772005': 0, '3100772006': 0, '3100772007': 0, '3100772008': 0, '3100772009': 0, '3100772010': 0, '3100772011': 0, '3100772013': 0, '3100772014': 0, '3100772015': 0, '3100772018': 0, '3100772019': 0, '3100772020': 0, '3100772021': 0, '3100772022': 0, '3100772023': 0, '3100772024': 0, '3100772025': 0, '3100772026': 0, '3100772027': 0, '3100772028': 0, '3100772029': 0, '3100772031': 0, '3100772032': 0, '3100772033': 0, '3100772034': 0, '3100772035': 0, '3100772036': 0, '3100772037': 0, '3100772039': 0, '3100772040': 0, '3100772041': 0, '3100772042': 0, '3100772043': 0, '3100772045': 0, '3100772046': 0, '3100772048': 0, '3100772050': 0, '3100772051': 1, '3100772052': 0, '3100772053': 0, '3100772054': 0, '3100772055': 0, '3100772056': 0, '3100772058': 0, '3100772059': 0, '3100772063': 0, '3100772065': 0, '3100772066': 0, '3100772067': 0, '3100772068': 0, '3100772069': 0, '3100781001': 0, '3100781002': 1, '3100781004': 0, '3100781006': 0, '3100781007': 1, '3100781008': 0, '3100781009': 0, '3100781010': 0, '3100781011': 0, '3100781013': 0, '3100781015': 0, '3100781016': 0, '3100781017': 0, '3100781019': 0, '3100781020': 0, '3100781021': 0, '3100781023': 0, '3100781024': 0, '3100781027': 0, '3100781029': 0, '3100781030': 0, '3100781031': 0, '3100781032': 0, '3100781033': 0, '3100781034': 1, '3100781036': 0, '3100781038': 0, '3100781040': 0, '3100781041': 0, '3100781043': 0, '3100781044': 0, '3100781046': 0, '3100781047': 0, '3100781048': 0, '3100781051': 0, '3100781052': 0, '3100781053': 0, '3100781054': 0, '3100781055': 0, '3100781056': 0, '3100781057': 0, '3100781058': 0, '3100781059': 0, '3100781061': 0, '3100781062': 0, '3100781064': 0, '3100781065': 0, '3100781066': 0, '3100781068': 0, '3100781069': 0, '3100781070': 0, '3100781071': 0, '3100781073': 0, '3100781074': 0, '3100781075': 0, '3100781076': 0, '3100781078': 0, '3100781079': 0, '3100781080': 0, '3100781081': 0, '3100782001': 0, '3100782003': 0, '3100782004': 0, '3100782005': 0, '3100782006': 0, '3100782008': 0, '3100782010': 0, '3100782011': 0, '3100782012': 0, '3100782013': 0, '3100782014': 0, '3100782015': 0, '3100782016': 0, '3100782017': 0, '3100782018': 0, '3100782019': 0, '3100782021': 0, '3100782022': 0, '3100782023': 0, '3100782024': 0, '3100782025': 0, '3100782026': 0, '3100782027': 0, '3100782028': 0, '3100782031': 0, '3100782032': 0, '3100782033': 0, '3100782035': 0, '3100782036': 0, '3100782037': 0, '3100782038': 0, '3100782039': 0, '3100782042': 0, '3100782043': 0, '3100782045': 0, '3100782046': 0, '3100782047': 0, '3100782049': 0, '3100782050': 0, '3100782053': 0, '3100782054': 0, '3100782055': 0, '3100782057': 0, '3100782058': 0, '3100782059': 0, '3100782061': 0, '3100782062': 0, '3100782063': 0, '3100782064': 0, '3100782065': 0, '3100782066': 0, '3100782067': 1, '3100782068': 0, '3100782069': 0, '3100782071': 0, '3100782072': 0, '3100791004': 0, '3100791006': 0, '3100791007': 0, '3100791008': 0, '3100791016': 0, '3100791018': 0, '3100791020': 0, '3100791021': 0, '3100791026': 0, '3100791028': 0, '3100791031': 0, '3100791033': 0, '3100791034': 0, '3100791035': 0, '3100791042': 0, '3100791044': 0, '3100791045': 0, '3100791046': 0, '3100791047': 0, '3100791049': 0, '3100791050': 0, '3100791052': 0, '3100791054': 0, '3100791056': 0, '3100791058': 1, '3100791059': 0, '3100791060': 0, '3100791061': 0, '3100791062': 0, '3100791063': 0, '3100791064': 0, '3100791065': 0, '3100791066': 0, '3100791067': 0, '3100791069': 0, '3100791070': 0, '3100791071': 0, '3100791072': 0, '3100791073': 0, '3100792002': 0, '3100792003': 0, '3100792004': 0, '3100792005': 0, '3100792006': 0, '3100792007': 0, '3100792008': 0, '3100792009': 0, '3100792010': 0, '3100792011': 0, '3100792013': 0, '3100792014': 0, '3100792015': 0, '3100792016': 0, '3100792019': 0, '3100792020': 0, '3100792021': 0, '3100792022': 0, '3100792023': 0, '3100792024': 0, '3100792025': 0, '3100792027': 0, '3100792028': 0, '3100792030': 0, '3100792031': 0, '3100792032': 0, '3100792033': 0, '3100792035': 0, '3100792036': 0, '3100792037': 0, '3100792038': 0, '3100792039': 0, '3100792040': 0, '3100792041': 0, '3100792042': 0, '3100792043': 0, '3100792044': 0, '3100792045': 1, '3100792046': 0, '3100792048': 0, '3100792050': 0, '3100792051': 0, '3100792052': 0, '3100792053': 0, '3100792057': 0, '3100792058': 0, '3100792060': 0, '3100792069': 0, '3100801006': 0, '3100802001': 0, '3100802028': 0, '3100811002': 0, '3100811018': 0, '3100811027': 0, '3100811034': 0, '3100811035': 0, '3100811036': 0, '3100811037': 0, '3100811038': 0, '3100811039': 0, '3100811040': 0, '3100811041': 0, '3100811042': 0, '3100811043': 0, '3100811045': 0, '3100811046': 0, '3100811047': 0, '3100811050': 0, '3100811051': 0, '3100811053': 0, '3100811054': 0, '3100811055': 0, '3100811056': 0, '3100811059': 0, '3100811060': 0, '3100811061': 0, '3100811063': 0, '3100811068': 0, '3100811075': 0, '3100812003': 0, '3100812004': 0, '3100812005': 0, '3100812006': 0, '3100812007': 0, '3100812008': 0, '3100812013': 0, '3100812014': 0, '3100812016': 0, '3100812017': 0, '3100812018': 0, '3100812019': 0, '3100812020': 0, '3100812021': 0, '3100812026': 0, '3100812027': 0, '3100812028': 1, '3100812040': 0, '3100821004': 0, '3100821015': 0, '3100821016': 0, '3100821019': 0, '3100821020': 0, '3100821021': 0, '3100821022': 1, '3100821030': 0, '3100821031': 0, '3100821032': 1, '3100821033': 1, '3100821034': 0, '3100821035': 0, '3100821036': 0, '3100821037': 0, '3100821038': 1, '3100821039': 0, '3100821040': 0, '3100821041': 0, '3100821042': 0, '3100821045': 0, '3100821046': 0, '3100821047': 0, '3100821048': 1, '3100821049': 0, '3100821051': 0, '3100821052': 1, '3100821054': 0, '3100821055': 0, '3100821057': 1, '3100821067': 0, '3100821068': 0, '3100821069': 1, '3100821075': 1, '3100822001': 0, '3100822011': 1, '3100822012': 0, '3100822014': 0, '3100822030': 0, '3100822031': 1, '3100822044': 0, '3100822050': 0, '3100822051': 0, '3100822057': 0, '3100822058': 0, '3100822059': 0, '3100822064': 0, '3100822065': 1, '3100822066': 1, '3100822067': 0, '3100822068': 0, '3100822069': 0, '3100822070': 0, '3100822075': 0, '3100822080': 0, '3100831003': 0, '3100831004': 0, '3100831006': 0, '3100831007': 0, '3100831008': 0, '3100831010': 0, '3100831011': 0, '3100831013': 0, '3100831014': 0, '3100831015': 0, '3100831016': 0, '3100831018': 0, '3100831019': 0, '3100831020': 0, '3100831022': 0, '3100831024': 0, '3100831026': 0, '3100831027': 0, '3100831028': 0, '3100831029': 0, '3100831032': 0, '3100831033': 0, '3100831035': 0, '3100831036': 0, '3100831037': 0, '3100831044': 0, '3100831045': 0, '3100831046': 0, '3100831047': 0, '3344630110': 0, '33446301100': 0, '33446301101': 0, '33446301103': 0, '33446301104': 0, '33446301107': 0, '3344630112': 0, '3344630113': 0, '3344630115': 0, '3344630116': 0, '3344630117': 0, '3344630119': 0, '334463012': 0, '3344630120': 0, '3344630121': 1, '3344630127': 0, '3344630130': 0, '3344630131': 1, '3344630132': 0, '3344630133': 0, '3344630136': 0, '3344630139': 0, '334463014': 0, '3344630140': 0, '3344630141': 0, '3344630142': 0, '3344630143': 0, '3344630146': 0, '3344630147': 0, '3344630148': 0, '3344630149': 0, '3344630150': 0, '3344630151': 0, '3344630153': 0, '3344630156': 0, '3344630161': 0, '3344630162': 1, '3344630163': 0, '3344630164': 0, '3344630166': 0, '3344630170': 0, '3344630171': 0, '3344630172': 0, '3344630173': 0, '3344630176': 0, '3344630179': 0, '3344630180': 0, '3344630181': 0, '3344630182': 0, '3344630184': 0, '3344630185': 0, '3344630186': 0, '3344630188': 0, '3344630189': 0, '334463019': 0, '3344630190': 0, '3344630196': 0, '3344630197': 0, '3344630198': 0, '3344630199': 0, '334463021': 0, '3344630210': 0, '3344630211': 1, '3344630213': 0, '3344630215': 0, '3344630216': 0, '3344630219': 0, '334463022': 0, '3344630220': 0, '3344630221': 0, '3344630224': 0, '3344630225': 0, '3344630226': 0, '3344630231': 0, '3344630232': 0, '3344630233': 0, '3344630236': 0, '3344630238': 0, '3344630240': 0, '3344630241': 0, '3344630242': 0, '3344630243': 0, '3344630245': 0, '3344630247': 0, '3344630248': 0, '334463025': 0, '3344630251': 0, '3344630252': 0, '3344630255': 0, '3344630257': 0, '334463026': 0, '3344630260': 0, '3344630262': 0, '3344630264': 0, '3344630265': 0, '3344630266': 0, '3344630267': 0, '334463027': 0, '3344630270': 0, '3344630271': 0, '3344630273': 0, '3344630276': 0, '3344630278': 0, '334463028': 0, '3344630280': 0, '3344630281': 0, '3344630282': 1, '334463029': 0, '33702101100': 0, '33702101110': 0, '33702101130': 0, '33702101140': 0, '33702101150': 0, '33702101180': 0, '33702101200': 0, '33702101210': 0, '33702101250': 0, '33702101260': 0, '33702101270': 0, '33702101280': 0, '33702101290': 0, '33702101300': 0, '33702101340': 0, '33702101350': 0, '33702101360': 0, '33702101370': 0, '33702101410': 0, '33702101430': 0, '33702101450': 0, '33702101460': 0, '33702101470': 0, '33702101480': 0, '33702101490': 0, '3370210150': 0, '33702101500': 0, '33702101530': 0, '33702101540': 0, '33702101550': 0, '33702101580': 0, '33702101590': 0, '33702101600': 0, '33702101620': 0, '33702101630': 0, '33702101640': 0, '33702101650': 0, '33702101660': 0, '33702101700': 0, '33702101710': 0, '33702101730': 0, '33702101740': 0, '33702101750': 0, '33702101760': 0, '3370210180': 0, '33702102100': 0, '33702102110': 0, '33702102130': 0, '33702102140': 0, '33702102160': 0, '33702102170': 0, '33702102180': 0, '33702102190': 0, '33702102200': 0, '33702102220': 0, '33702102230': 0, '33702102240': 0, '33702102250': 0, '33702102280': 0, '3370210230': 0, '33702102300': 0, '33702102310': 0, '33702102330': 0, '33702102350': 0, '33702102390': 0, '3370210240': 0, '33702102400': 0, '33702102420': 0, '33702102430': 0, '33702102470': 0, '33702102500': 0, '33702102530': 0, '33702102540': 0, '33702102550': 0, '33702102570': 0, '33702102580': 0, '33702102590': 0, '3370210260': 0, '33702102600': 0, '33702102640': 0, '33702102670': 0, '33702102690': 0, '33702102710': 0, '33702102740': 0, '3370210280': 0, '33702102820': 0, '33702102840': 0, '33702102850': 0, '33702102870': 0, '33702102880': 0, '342227010': 0, '342227011': 0, '3422270111': 1, '3422270112': 0, '3422270115': 0, '3422270116': 0, '3422270117': 0, '3422270118': 0, '3422270121': 0, '3422270122': 0, '3422270123': 0, '3422270126': 0, '3422270127': 0, '3422270128': 0, '3422270129': 1, '342227013': 0, '3422270130': 0, '3422270131': 0, '3422270133': 0, '3422270134': 0, '3422270135': 0, '3422270138': 0, '3422270139': 0, '3422270140': 0, '3422270141': 0, '3422270142': 0, '3422270143': 0, '3422270144': 0, '3422270149': 0, '3422270151': 0, '3422270152': 0, '3422270153': 0, '3422270154': 0, '3422270155': 0, '3422270157': 0, '3422270158': 0, '3422270160': 0, '3422270165': 0, '3422270166': 0, '3422270167': 1, '3422270168': 0, '3422270169': 0, '3422270171': 0, '3422270172': 0, '342227020': 0, '342227021': 0, '3422270210': 0, '3422270211': 0, '3422270212': 0, '3422270213': 0, '3422270215': 0, '3422270216': 0, '3422270217': 0, '3422270219': 0, '3422270220': 0, '3422270221': 0, '3422270222': 0, '3422270223': 0, '3422270224': 0, '3422270225': 0, '3422270227': 0, '342227023': 0, '3422270230': 0, '3422270238': 0, '3422270239': 0, '342227024': 0, '3422270240': 0, '3422270241': 0, '3422270242': 0, '3422270244': 0, '3422270245': 0, '3422270246': 0, '3422270247': 0, '3422270249': 0, '342227025': 0, '3422270250': 0, '3422270251': 0, '3422270252': 0, '3422270253': 0, '3422270254': 0, '3422270255': 0, '3422270256': 0, '3422270257': 0, '3422270261': 0, '3422270262': 0, '3422270263': 0, '3422270264': 0, '3422270267': 0, '3422270268': 0, '3422270269': 0, '342227027': 0, '3422270274': 0, '3422270278': 0, '3422270279': 0, '3422270280': 0, '3422270281': 0, '342227029': 0, '350361011': 0, '3503610110': 0, '3503610111': 0, '3503610112': 0, '3503610113': 0, '3503610114': 0, '3503610115': 0, '3503610116': 0, '3503610117': 0, '3503610118': 0, '3503610119': 0, '350361012': 0, '3503610120': 0, '3503610121': 0, '3503610122': 0, '3503610123': 0, '3503610124': 0, '3503610125': 0, '3503610126': 0, '3503610127': 0, '3503610128': 0, '3503610129': 0, '350361013': 0, '3503610130': 0, '3503610131': 0, '3503610132': 0, '3503610133': 0, '3503610134': 0, '3503610135': 0, '3503610136': 0, '3503610137': 0, '3503610138': 0, '3503610139': 0, '350361014': 0, '3503610140': 0, '3503610141': 0, '3503610142': 0, '3503610143': 0, '3503610144': 0, '3503610145': 0, '3503610146': 0, '3503610147': 0, '3503610148': 0, '3503610149': 0, '350361015': 0, '3503610150': 0, '3503610151': 0, '3503610152': 0, '3503610154': 0, '3503610156': 0, '3503610157': 0, '3503610158': 1, '350361016': 0, '3503610163': 0, '3503610168': 1, '350361017': 0, '350361019': 0, '350361021': 0, '3503610210': 0, '3503610212': 0, '3503610213': 0, '3503610214': 0, '3503610217': 0, '350361022': 0, '3503610223': 0, '3503610224': 0, '3503610225': 0, '3503610226': 0, '3503610227': 0, '3503610228': 0, '350361023': 0, '3503610230': 0, '3503610231': 0, '3503610233': 0, '3503610234': 0, '3503610235': 0, '3503610236': 0, '3503610237': 0, '3503610238': 0, '350361024': 0, '3503610240': 0, '3503610241': 0, '3503610242': 0, '3503610245': 0, '3503610246': 0, '3503610248': 0, '3503610250': 0, '3503610251': 0, '3503610252': 0, '3503610253': 0, '3503610254': 0, '3503610255': 0, '3503610256': 0, '3503610257': 0, '350361026': 0, '3503610260': 0, '3503610261': 0, '3503610264': 0, '3503610265': 0, '3503610266': 0, '3503610267': 0, '3503610268': 0, '3503610269': 0, '3503610270': 0, '3503610272': 0, '3503610273': 0, '3503610275': 0, '3503610276': 0, '3503610277': 0, '3503610278': 0, '3503610279': 0, '350361028': 1, '350361029': 0, '4000181002': 0, '4000181004': 1, '4000181005': 0, '4000181006': 0, '4000181007': 0, '4000181008': 0, '4000181010': 0, '4000181011': 0, '4000181012': 0, '4000181013': 0, '4000181014': 0, '4000181015': 1, '4000181016': 0, '4000181017': 0, '4000181019': 0, '4000181020': 0, '4000181022': 0, '4000181023': 0, '4000181024': 0, '4000181026': 0, '4000181027': 0, '4000181028': 0, '4000181029': 0, '4000181030': 0, '4000181031': 0, '4000181032': 0, '4000181033': 0, '4000181035': 0, '4000181036': 0, '4000181037': 0, '4000181039': 0, '4000181041': 0, '4000181042': 0, '4000181043': 0, '4000181044': 0, '4000181045': 0, '4000181046': 0, '4000181047': 0, '4000181048': 0, '4000181049': 0, '4000181053': 0, '4000181054': 0, '4000181055': 0, '4000181056': 0, '4000181057': 0, '4000181060': 0, '4000181061': 0, '4000181062': 0, '4000181063': 0, '4000181064': 0, '4000181065': 0, '4000181066': 0, '4000181067': 0, '4000181068': 0, '4000181069': 0, '4000181070': 0, '4000181072': 0, '4000181073': 0, '4000181074': 0, '4000181075': 0, '4000181076': 0, '4000181077': 0, '4000181078': 0, '4000181079': 0, '4000181080': 0, '4000182003': 0, '4000182004': 0, '4000182005': 0, '4000182006': 0, '4000182007': 0, '4000182008': 0, '4000182009': 0, '4000182010': 0, '4000182011': 0, '4000182013': 0, '4000182014': 0, '4000182015': 0, '4000182016': 0, '4000182017': 0, '4000182018': 0, '4000182020': 0, '4000182022': 0, '4000182024': 0, '4000182025': 0, '4000182026': 0, '4000182027': 0, '4000182028': 0, '4000182029': 0, '4000182030': 0, '4000182031': 0, '4000182032': 0, '4000182033': 0, '4000182035': 1, '4000182036': 0, '4000182037': 0, '4000182038': 0, '4000182039': 0, '4000182040': 0, '4000182041': 0, '4000182042': 0, '4000182044': 0, '4000182046': 0, '4000182047': 0, '4000182049': 0, '4000182050': 0, '4000182051': 0, '4000182053': 0, '4000182054': 0, '4000182055': 0, '4000182058': 0, '4000182059': 0, '4000182060': 0, '4000182062': 0, '4000182063': 0, '4000182064': 0, '4000182067': 0, '4000182068': 0, '4000182069': 0, '4000221001': 0, '4000221002': 0, '4000221006': 0, '4000221008': 0, '4000221009': 0, '4000221010': 0, '4000221011': 0, '4000221013': 0, '4000221014': 0, '4000221015': 0, '4000221016': 0, '4000221017': 0, '4000221018': 0, '4000221024': 0, '4000221033': 0, '4000221034': 0, '4000221035': 0, '4000221036': 0, '4000221040': 1, '4000221041': 0, '4000221042': 0, '4000221054': 0, '4000221055': 0, '4000221061': 0, '4000221062': 0, '4000221064': 0, '4000221065': 0, '4000221066': 0, '4000221067': 0, '4000221071': 0, '4000221072': 0, '4000222001': 0, '4000222003': 0, '4000222004': 0, '4000222007': 0, '4000222012': 0, '4000222013': 0, '4000222014': 0, '4000222015': 0, '4000222017': 0, '4000222031': 1, '4000222032': 1, '4000222035': 0, '4000222036': 1, '4000222038': 0, '4000222039': 0, '4000222040': 0, '4000222041': 1, '4000222042': 0, '4000222044': 0, '4000222045': 0, '4000222046': 0, '4000222051': 0, '4000222052': 0, '4000222054': 0, '4000222056': 0, '4000222057': 0, '4000222068': 0, '4000222069': 0, '4000222070': 0, '4000231001': 0, '4000231008': 0, '4000231010': 0, '4000231011': 0, '4000231012': 0, '4000231013': 0, '4000231014': 0, '4000231021': 0, '4000231032': 0, '4000231033': 0, '4000231034': 0, '4000231037': 0, '4000231038': 0, '4000231047': 0, '4000231049': 0, '4000231052': 0, '4000231060': 0, '4000231061': 0, '4000231063': 0, '4000231065': 0, '4000231070': 0, '4000231071': 0, '4000231073': 0, '4000231074': 0, '4000231081': 0, '4000232001': 0, '4000232004': 0, '4000232005': 0, '4000232006': 0, '4000232007': 0, '4000232010': 0, '4000232016': 0, '4000232017': 0, '4000232018': 0, '4000232022': 0, '4000232024': 0, '4000232027': 0, '4000232034': 0, '4000232035': 0, '4000232036': 0, '4000232037': 0, '4000232038': 0, '4000232042': 0, '4000232044': 0, '4000232045': 0, '4000232048': 0, '4000232051': 0, '4000232054': 0, '4000232059': 0, '4000232062': 0, '4000232065': 0, '4000232068': 0, '4000232071': 1, '4000232072': 0, '4000301002': 0, '4000301003': 0, '4000301005': 1, '4000301006': 1, '4000301007': 0, '4000301008': 0, '4000301010': 1, '4000301011': 1, '4000301012': 0, '4000301013': 0, '4000301014': 0, '4000301015': 0, '4000301016': 0, '4000301018': 0, '4000301019': 0, '4000301020': 0, '4000301021': 1, '4000301022': 0, '4000301023': 0, '4000301025': 0, '4000301026': 0, '4000301027': 0, '4000301028': 1, '4000301030': 1, '4000301031': 0, '4000301032': 0, '4000301034': 0, '4000301038': 0, '4000301039': 0, '4000301040': 0, '4000301041': 0, '4000301042': 1, '4000301043': 0, '4000301044': 0, '4000301045': 0, '4000301047': 0, '4000301049': 1, '4000301052': 0, '4000301053': 0, '4000301054': 0, '4000301055': 1, '4000301056': 0, '4000301057': 0, '4000301058': 0, '4000301059': 0, '4000301060': 1, '4000301061': 0, '4000301062': 0, '4000301063': 0, '4000301064': 0, '4000301065': 1, '4000301066': 1, '4000301067': 1, '4000301068': 0, '4000301069': 0, '4000301070': 1, '4000301071': 0, '4000301072': 0, '4000301073': 0, '4000301074': 0, '4000301076': 0, '4000301079': 0, '4000331001': 0, '4000331002': 0, '4000331003': 0, '4000331004': 0, '4000331005': 0, '4000331006': 0, '4000331007': 0, '4000331008': 0, '4000331011': 0, '4000331012': 0, '4000331013': 0, '4000331015': 0, '4000331017': 0, '4000331019': 0, '4000331020': 0, '4000331021': 0, '4000331022': 0, '4000331023': 0, '4000331025': 0, '4000331027': 0, '4000331029': 0, '4000331030': 0, '4000331031': 0, '4000331032': 0, '4000331033': 0, '4000331035': 0, '4000331036': 0, '4000331037': 0, '4000331038': 0, '4000331039': 0, '4000331040': 0, '4000331041': 0, '4000331042': 0, '4000331043': 0, '4000331044': 0, '4000331045': 0, '4000331046': 0, '4000331051': 0, '4000331052': 0, '4000331053': 0, '4000331054': 0, '4000331055': 0, '4000331056': 0, '4000331057': 0, '4000331058': 0, '4000331060': 0, '4000331062': 0, '4000331063': 0, '4000331064': 0, '4000331067': 0, '4000331068': 0, '4000331069': 0, '4000332001': 0, '4000332002': 0, '4000332007': 0, '4000332008': 0, '4000332009': 0, '4000332010': 0, '4000332012': 0, '4000332013': 0, '4000332014': 0, '4000332015': 0, '4000332017': 0, '4000332019': 0, '4000332020': 0, '4000332021': 0, '4000332022': 0, '4000332023': 0, '4000332025': 0, '4000332027': 0, '4000332030': 0, '4000332031': 0, '4000332032': 0, '4000332034': 0, '4000332035': 0, '4000332036': 0, '4000332037': 0, '4000332038': 0, '4000332039': 0, '4000332041': 0, '4000332044': 0, '4000332045': 0, '4000332046': 0, '4000332048': 0, '4000332050': 0, '4000332051': 0, '4000332052': 0, '4000332057': 0, '4000332059': 0, '4000332060': 0, '4000332061': 0, '4000332062': 0, '4000332063': 0, '4000332064': 0, '4000332066': 0, '4000332067': 0, '4000332068': 0, '4000332071': 0, '4000332072': 0, '4000332073': 0, '4000332074': 0, '4000332075': 0, '4000332077': 0, '4000332078': 0, '4000332079': 0, '4000332080': 0, '4000332081': 0, '4000332082': 1, '401835011': 0, '4018350112': 0, '4018350115': 0, '4018350116': 0, '4018350118': 0, '4018350119': 0, '4018350120': 0, '4018350121': 0, '4018350122': 0, '4018350126': 0, '4018350127': 0, '401835013': 0, '4018350130': 0, '4018350132': 0, '4018350134': 0, '4018350136': 0, '4018350137': 0, '4018350138': 0, '4018350139': 0, '4018350140': 0, '4018350141': 0, '4018350143': 0, '4018350144': 0, '4018350145': 0, '4018350146': 0, '4018350147': 0, '4018350149': 0, '401835015': 1, '4018350150': 0, '4018350152': 0, '4018350156': 0, '4018350157': 0, '4018350159': 0, '4018350160': 0, '4018350161': 0, '4018350162': 0, '4018350163': 0, '4018350166': 0, '4018350167': 0, '401835017': 0, '401835018': 0, '401835021': 0, '4018350213': 0, '4018350215': 0, '4018350217': 0, '4018350219': 0, '4018350220': 0, '4018350221': 0, '4018350222': 0, '4018350223': 0, '4018350224': 0, '4018350225': 0, '4018350226': 0, '4018350227': 0, '4018350231': 0, '4018350232': 0, '4018350233': 0, '4018350234': 0, '4018350236': 0, '4018350239': 0, '401835024': 0, '4018350240': 0, '4018350241': 0, '4018350244': 0, '4018350247': 0, '4018350251': 0, '4018350254': 0, '4018350256': 0, '4018350257': 0, '4018350258': 0, '4018350259': 0, '4018350260': 0, '4018350261': 0, '4018350263': 0, '4018350268': 0, '4018350269': 0, '4018350274': 0, '4018350276': 0, '4018350277': 0, '4018350279': 0, '401835028': 0, '4018350281': 0, '4018350282': 1, '4100191001': 0, '4100191002': 0, '4100191003': 0, '4100191004': 0, '4100191006': 0, '4100191007': 0, '4100191008': 1, '4100191010': 0, '4100191012': 0, '4100191014': 0, '4100191016': 0, '4100191017': 0, '4100191018': 0, '4100191020': 0, '4100191021': 0, '4100191023': 0, '4100191024': 0, '4100191025': 0, '4100191026': 0, '4100191030': 0, '4100191031': 0, '4100191032': 0, '4100191033': 1, '4100191034': 0, '4100191035': 0, '4100191038': 0, '4100191039': 0, '4100191041': 1, '4100191042': 0, '4100191043': 0, '4100191045': 0, '4100191046': 0, '4100191052': 0, '4100191053': 0, '4100192001': 0, '4100192002': 0, '4100192003': 0, '4100192004': 0, '4100192005': 0, '4100192006': 0, '4100192007': 0, '4100192010': 1, '4100192011': 1, '4100192012': 0, '4100192013': 0, '4100192014': 0, '4100192015': 1, '4100192016': 1, '4100192019': 0, '4100192020': 0, '4100192022': 0, '4100192023': 0, '4100192024': 0, '4100192025': 0, '4100192026': 1, '4100192027': 0, '4100192028': 0, '4100192029': 1, '4100192031': 1, '4100192032': 0, '4100192033': 0, '4100192034': 0, '4100192036': 0, '4100192037': 0, '4100192038': 0, '4100192039': 0, '4100192040': 0, '4100192043': 0, '4100192044': 0, '4100192045': 0, '4100192046': 0, '4100192047': 0, '4100192048': 0, '4100192049': 1, '4100192050': 0, '4100192051': 0, '4100192052': 0, '4100192053': 1, '4100192054': 0, '4100192055': 0, '4100192056': 0, '4100192057': 0, '4100192058': 0, '4100192060': 1, '4100192061': 0, '4100192062': 0, '4100192063': 0, '4100192066': 0, '4100192068': 0, '4100201001': 0, '4100201003': 0, '4100201004': 0, '4100201005': 0, '4100201006': 0, '4100201007': 0, '4100201008': 0, '4100201009': 0, '4100201010': 0, '4100201011': 0, '4100201013': 0, '4100201014': 0, '4100201016': 0, '4100201017': 0, '4100201018': 0, '4100201020': 0, '4100201021': 0, '4100201022': 0, '4100201023': 0, '4100201024': 0, '4100201025': 0, '4100201026': 0, '4100201027': 0, '4100201030': 1, '4100201031': 0, '4100201032': 1, '4100201033': 0, '4100201034': 0, '4100201035': 0, '4100201039': 1, '4100201040': 0, '4100201041': 0, '4100201042': 0, '4100201043': 1, '4100201044': 0, '4100201045': 0, '4100201046': 0, '4100201048': 0, '4100201049': 0, '4100201051': 0, '4100201052': 0, '4100201053': 0, '4100201054': 0, '4100201055': 0, '4100201056': 0, '4100201058': 0, '4100201059': 0, '4100201060': 0, '4100201061': 1, '4100201062': 0, '4100201063': 0, '4100201064': 0, '4100201068': 0, '4100201069': 0, '4100201071': 0, '4100201072': 0, '4100201073': 0, '4100201074': 0, '4100201075': 0, '4100201076': 0, '4100201078': 0, '4100201079': 0, '4100201081': 0, '4100201082': 0, '4100202001': 0, '4100202004': 0, '4100202005': 0, '4100202006': 0, '4100202007': 0, '4100202008': 0, '4100202009': 0, '4100202010': 0, '4100202011': 0, '4100202012': 0, '4100202013': 0, '4100202014': 1, '4100202015': 0, '4100202016': 0, '4100202017': 0, '4100202018': 0, '4100202019': 0, '4100202021': 0, '4100202022': 0, '4100202023': 0, '4100202024': 0, '4100202025': 0, '4100202032': 0, '4100202037': 0, '4100202039': 0, '4100202040': 0, '4100202041': 0, '4100202042': 0, '4100202043': 0, '4100202045': 0, '4100202046': 1, '4100202048': 0, '4100202052': 0, '4100202053': 0, '4100202054': 0, '4100202055': 0, '4100202056': 0, '4100202063': 0, '4100202065': 1, '4100202067': 0, '4100202068': 0, '4100241001': 0, '4100241002': 0, '4100241003': 0, '4100241004': 0, '4100241006': 0, '4100241007': 0, '4100241008': 0, '4100241009': 0, '4100241011': 0, '4100241013': 0, '4100241016': 0, '4100241017': 0, '4100241018': 0, '4100241020': 0, '4100241029': 1, '4100241030': 0, '4100241031': 0, '4100241042': 0, '4100241045': 0, '4100241046': 0, '4100241049': 0, '4100241051': 0, '4100241052': 0, '4100241053': 0, '4100241054': 0, '4100241055': 1, '4100241056': 0, '4100241059': 1, '4100241060': 0, '4100241061': 0, '4100241062': 0, '4100241063': 0, '4100241064': 0, '4100241068': 1, '4100241069': 0, '4100241075': 0, '4100242001': 0, '4100242002': 0, '4100242003': 1, '4100242004': 0, '4100242005': 0, '4100242006': 0, '4100242008': 0, '4100242011': 0, '4100242020': 0, '4100242021': 0, '4100242029': 0, '4100242031': 0, '4100242032': 1, '4100242033': 1, '4100242034': 0, '4100242035': 1, '4100242036': 0, '4100242037': 0, '4100242038': 0, '4100242040': 0, '4100242045': 0, '4100242048': 0, '4100242050': 0, '4100242053': 0, '4100242054': 0, '4100242057': 1, '4100242059': 0, '4100242060': 0, '4100242063': 1, '4100242065': 0, '4100242066': 0, '4100242067': 0, '4100251003': 0, '4100251004': 0, '4100251005': 0, '4100251006': 1, '4100251010': 0, '4100251011': 0, '4100251012': 0, '4100251013': 0, '4100251014': 0, '4100251015': 0, '4100251016': 1, '4100251017': 0, '4100251018': 0, '4100251019': 0, '4100251020': 1, '4100251021': 1, '4100251022': 0, '4100251024': 1, '4100251026': 0, '4100251027': 1, '4100251028': 1, '4100251029': 1, '4100251030': 0, '4100251031': 0, '4100251032': 1, '4100251033': 1, '4100251034': 0, '4100251035': 0, '4100251036': 1, '4100251038': 1, '4100251039': 0, '4100251040': 0, '4100251041': 1, '4100251042': 0, '4100251044': 0, '4100251046': 1, '4100251047': 0, '4100251048': 0, '4100251049': 1, '4100251051': 0, '4100251052': 0, '4100251053': 0, '4100251054': 0, '4100251056': 0, '4100251057': 1, '4100251059': 0, '4100251060': 0, '4100251061': 1, '4100251062': 0, '4100251063': 0, '4100251064': 0, '4100251065': 0, '4100251068': 1, '4100251069': 0, '4100251070': 0, '4100252001': 0, '4100252003': 0, '4100252004': 0, '4100252005': 0, '4100252007': 0, '4100252010': 0, '4100252011': 0, '4100252012': 0, '4100252013': 0, '4100252014': 0, '4100252015': 0, '4100252016': 0, '4100252019': 0, '4100252021': 0, '4100252022': 0, '4100252023': 0, '4100252024': 0, '4100252027': 0, '4100252031': 0, '4100252032': 0, '4100252033': 0, '4100252034': 0, '4100252035': 0, '4100252036': 1, '4100252037': 0, '4100252038': 0, '4100252039': 0, '4100252040': 0, '4100252041': 1, '4100252043': 0, '4100252044': 1, '4100252045': 0, '4100252048': 0, '4100252049': 0, '4100252050': 0, '4100252051': 0, '4100252053': 0, '4100252054': 0, '4100252055': 0, '4100252056': 0, '4100252057': 0, '4100252058': 0, '4100252060': 0, '4100252061': 1, '4100252062': 0, '4100252063': 0, '4100252066': 0, '4100252069': 0, '4100252070': 0, '4100252071': 0, '4100252072': 0, '4100252073': 0, '4100252074': 0, '4100252075': 0, '4100252076': 0, '4100252078': 0, '4100252081': 0, '4100261001': 0, '4100261002': 0, '4100261003': 0, '4100261004': 0, '4100261005': 1, '4100261006': 1, '4100261007': 0, '4100261010': 0, '4100261012': 0, '4100261013': 0, '4100261015': 0, '4100261016': 0, '4100261020': 0, '4100261023': 0, '4100261025': 0, '4100261027': 1, '4100261028': 0, '4100261029': 0, '4100261030': 1, '4100261031': 0, '4100261032': 0, '4100261033': 0, '4100261034': 1, '4100261035': 0, '4100261036': 0, '4100261038': 0, '4100261041': 1, '4100261044': 0, '4100261045': 0, '4100261046': 0, '4100261047': 0, '4100261048': 0, '4100261049': 0, '4100261050': 1, '4100261055': 0, '4100261056': 1, '4100261057': 0, '4100261058': 1, '4100261060': 0, '4100261061': 0, '4100262001': 0, '4100262003': 0, '4100262004': 1, '4100262006': 1, '4100262007': 0, '4100262008': 0, '4100262009': 0, '4100262010': 0, '4100262014': 0, '4100262015': 0, '4100262016': 0, '4100262017': 0, '4100262018': 0, '4100262019': 0, '4100262020': 0, '4100262022': 0, '4100262023': 0, '4100262024': 0, '4100262025': 0, '4100262027': 0, '4100262034': 1, '4100262035': 0, '4100262037': 0, '4100262038': 0, '4100262040': 0, '4100262041': 0, '4100262042': 0, '4100262043': 0, '4100262044': 0, '4100262045': 0, '4100262046': 0, '4100262047': 0, '4100262052': 0, '4100262053': 0, '4100262056': 1, '4100262057': 0, '4100262060': 0, '4100262063': 0, '4100262064': 0, '4100262065': 0, '4100262066': 0, '4100262067': 0, '4100262068': 0, '4100262069': 0, '4100262070': 0, '4100271007': 0, '4100271008': 0, '4100271009': 0, '4100271010': 0, '4100271011': 0, '4100271012': 0, '4100271026': 0, '4100271028': 0, '4100271029': 0, '4100271030': 0, '4100271032': 0, '4100271033': 0, '4100271034': 0, '4100271038': 1, '4100271039': 0, '4100271041': 1, '4100271042': 0, '4100271043': 0, '4100271056': 1, '4100272024': 0, '4100272029': 0, '4100272033': 0, '4100272034': 0, '4100272036': 0, '4100272037': 0, '4100272043': 0, '4100272051': 0, '4100272052': 0, '4100272056': 0, '4100281001': 0, '4100281002': 0, '4100281015': 0, '4100281016': 0, '4100281019': 0, '4100281022': 0, '4100281023': 0, '4100281027': 0, '4100281029': 0, '4100281030': 0, '4100281032': 1, '4100281033': 0, '4100281034': 0, '4100281035': 0, '4100281036': 0, '4100281037': 0, '4100281041': 0, '4100281042': 0, '4100281045': 0, '4100281046': 1, '4100281048': 0, '4100281049': 0, '4100281050': 0, '4100281052': 0, '4100281053': 1, '4100281054': 0, '4100281057': 0, '4100281058': 0, '4100281059': 0, '4100281060': 0, '4100281061': 0, '4100281062': 0, '4100281063': 0, '4100281066': 0, '4100281067': 1, '4100281068': 0, '4100281070': 1, '4100281072': 0, '4100281075': 0, '4100281076': 1, '4100281078': 0, '4100281079': 0, '4100281080': 0, '4100281081': 0, '4100282001': 0, '4100282002': 0, '4100282003': 0, '4100282004': 0, '4100282005': 0, '4100282007': 0, '4100282008': 0, '4100282009': 1, '4100282012': 0, '4100282013': 0, '4100282014': 0, '4100282015': 0, '4100282017': 0, '4100282018': 0, '4100282019': 0, '4100282020': 0, '4100282021': 0, '4100282022': 0, '4100282023': 0, '4100282024': 0, '4100282033': 0, '4100282043': 0, '4100282048': 0, '4100282053': 0, '4100282057': 0, '4100282058': 0, '4100282066': 1, '4100282067': 0, '4100282068': 0, '4100282070': 0, '4100291002': 0, '4100291003': 0, '4100291004': 0, '4100291005': 0, '4100291006': 1, '4100291007': 1, '4100291008': 0, '4100291009': 0, '4100291010': 1, '4100291011': 0, '4100291012': 0, '4100291014': 0, '4100291015': 0, '4100291016': 0, '4100291017': 0, '4100291018': 0, '4100291019': 1, '4100291021': 0, '4100291022': 0, '4100291025': 0, '4100291026': 1, '4100291027': 1, '4100291028': 0, '4100291032': 1, '4100291033': 0, '4100291034': 0, '4100291036': 1, '4100291037': 0, '4100291039': 0, '4100291040': 0, '4100291041': 1, '4100291043': 0, '4100291046': 0, '4100291047': 0, '4100291048': 0, '4100291049': 0, '4100291050': 0, '4100291051': 0, '4100291055': 0, '4100291056': 0, '4100291059': 0, '4100291060': 0, '4100291061': 0, '4100291062': 0, '4100291063': 0, '4100291064': 0, '4100291065': 0, '4100291070': 1, '4100291073': 1, '4100291074': 0, '4100291076': 0, '4100291077': 0, '4100291078': 1, '4100291079': 0, '4100291080': 0, '4100291081': 1, '4100291082': 1, '4100291083': 0, '4100291084': 1, '4100292001': 0, '4100292003': 0, '4100292005': 0, '4100292008': 0, '4100292010': 0, '4100292016': 0, '4100292019': 0, '4100292020': 0, '4100292021': 0, '4100292022': 0, '4100292023': 0, '4100292024': 0, '4100292025': 0, '4100292026': 0, '4100292027': 0, '4100292028': 0, '4100292035': 0, '4100292036': 0, '4100292037': 0, '4100292040': 0, '4100292041': 0, '4100292042': 0, '4100292043': 0, '4100292044': 0, '4100292045': 0, '4100292046': 0, '4100292048': 1, '4100292049': 0, '4100292050': 0, '4100292052': 0, '4100292053': 0, '4100292056': 0, '4100292057': 0, '4100292059': 0, '4100292060': 0, '4100292061': 0, '4100292062': 0, '4100292063': 0, '4100292064': 0, '4100292065': 0, '4100292066': 0, '4100292067': 0, '4100292068': 0, '4100292069': 0, '4100292070': 0, '4100292071': 0, '4100292072': 0, '4100292073': 0, '4100292074': 0, '4100292075': 0, '4100292077': 0, '4100292078': 0, '4100292079': 0, '4100292081': 0, '4100292083': 0, '4100292084': 0, '4100292085': 0, '4100292087': 0, '4100292088': 0, '4100302002': 0, '4100302013': 1, '4100302014': 0, '4100302016': 1, '4100302017': 0, '4100302018': 1, '4100302019': 0, '4100302020': 0, '4100302024': 0, '4100302028': 0, '4100302030': 1, '4100302040': 1, '4100302041': 0, '4100302042': 1, '4100302043': 1, '4100302044': 1, '4100302045': 1, '4100302046': 0, '4100302047': 0, '4100302048': 1, '4100302049': 0, '4100302050': 0, '4100302051': 0, '4100302052': 0, '4100302053': 0, '4100302054': 0, '4100302055': 1, '4100302058': 1, '4100302061': 0, '4100302063': 0, '4100302064': 1, '4100302066': 1, '4100302067': 0, '4100302068': 0, '4100302069': 0, '4100321001': 1, '4100321002': 0, '4100321003': 0, '4100321004': 0, '4100321005': 0, '4100321006': 0, '4100321008': 0, '4100321009': 1, '4100321010': 0, '4100321011': 0, '4100321012': 0, '4100321014': 0, '4100321015': 0, '4100321016': 0, '4100321019': 1, '4100321020': 0, '4100321021': 0, '4100321022': 0, '4100321023': 0, '4100321024': 0, '4100321026': 0, '4100321027': 0, '4100321028': 0, '4100321029': 0, '4100321030': 0, '4100321032': 0, '4100321033': 0, '4100321034': 0, '4100321037': 0, '4100321038': 0, '4100321039': 0, '4100321041': 0, '4100321042': 1, '4100321043': 1, '4100321044': 1, '4100321045': 0, '4100321046': 0, '4100321049': 0, '4100321051': 0, '4100321052': 0, '4100321053': 0, '4100322001': 0, '4100322007': 0, '4100322025': 0, '4100322031': 0, '4100322032': 1, '4100322033': 0, '4100322034': 0, '4100322035': 0, '4100322037': 0, '4100322038': 0, '4100322039': 0, '4100322040': 0, '4100322041': 0, '4100322042': 0, '4100322044': 0, '4100322045': 0, '4100322048': 0, '4100322051': 0, '4100322052': 0, '4100322053': 0, '4100322055': 0, '4100322056': 0, '4100322057': 0, '4100322058': 0, '4100322059': 0, '4100322060': 0, '4100322061': 0, '4110211001': 1, '4110211004': 1, '4110211005': 1, '4110211006': 0, '4110211007': 0, '4110211008': 0, '4110211009': 0, '4110211011': 0, '4110211013': 1, '4110211014': 1, '4110211015': 1, '4110211016': 0, '4110211018': 0, '4110211019': 0, '4110211020': 0, '4110211021': 1, '4110211022': 1, '4110211023': 1, '4110211024': 0, '4110211025': 1, '4110211026': 0, '4110211027': 1, '4110211028': 1, '4110211030': 0, '4110211032': 0, '4110211033': 0, '4110211034': 0, '4110211035': 0, '4110211036': 1, '4110211037': 0, '4110211038': 1, '4110211039': 1, '4110211040': 1, '4110211041': 0, '4110211043': 0, '4110211044': 0, '4110211045': 1, '4110211046': 0, '4110211047': 0, '4110211048': 0, '4110211049': 0, '4110211050': 0, '4110211051': 0, '4110211052': 0, '4110211053': 1, '4110211054': 0, '4110211055': 1, '4110211056': 0, '4110211057': 0, '4110211058': 0, '4110211060': 0, '4110211061': 1, '4110211062': 0, '4110211063': 0, '4110211064': 0, '4110211065': 0, '4110211067': 0, '4110211068': 0, '4110211072': 0, '4110211073': 0, '4110211075': 1, '4110211076': 0, '4110211078': 1, '4110211079': 0, '4110211080': 0, '4110212003': 0, '4110212004': 0, '4110212007': 0, '4110212008': 0, '4110212009': 0, '4110212010': 0, '4110212011': 0, '4110212013': 0, '4110212014': 0, '4110212015': 0, '4110212016': 0, '4110212017': 0, '4110212018': 0, '4110212019': 0, '4110212021': 0, '4110212023': 0, '4110212024': 0, '4110212026': 0, '4110212027': 0, '4110212029': 0, '4110212030': 0, '4110212033': 0, '4110212034': 1, '4110212035': 0, '4110212036': 1, '4110212038': 0, '4110212039': 0, '4110212041': 0, '4110212042': 0, '4110212044': 0, '4110212045': 0, '4110212046': 0, '4110212047': 0, '4110212049': 1, '4110212050': 0, '4110212051': 1, '4110212052': 0, '4110212053': 0, '4110212054': 0, '4110212055': 0, '4110212056': 0, '4110212059': 0, '4110212061': 0, '4110212062': 1, '4110212063': 0, '4110212064': 0, '4110212069': 0, '4110311001': 0, '4110311003': 0, '4110311004': 0, '4110311005': 0, '4110311006': 1, '4110311012': 0, '4110311015': 0, '4110311017': 0, '4110311018': 0, '4110311019': 0, '4110311020': 0, '4110311021': 0, '4110311023': 1, '4110311030': 0, '4110311031': 0, '4110311032': 0, '4110311033': 0, '4110311034': 0, '4110311036': 0, '4110311037': 0, '4110311038': 0, '4110311042': 0, '4110311043': 0, '4110311044': 0, '4110311045': 1, '4110311046': 0, '4110311048': 1, '4110311049': 0, '4110311050': 0, '4110311053': 0, '4110311054': 1, '4110311057': 0, '4110311061': 0, '4110311062': 1, '4110311064': 0, '4110311065': 0, '4110311067': 0, '4110311068': 0, '4110311072': 0, '4110312006': 0, '4110312007': 0, '4110312008': 0, '4110312009': 1, '4110312013': 0, '4110312023': 0, '4110312024': 0, '4110312025': 0, '4110312027': 0, '4110312030': 0, '4110312031': 0, '4110312048': 0, '4110312049': 0, '4110312078': 0, '414081010': 0, '414081011': 0, '4140810110': 0, '4140810114': 0, '4140810117': 0, '4140810122': 0, '4140810124': 0, '4140810125': 0, '4140810126': 0, '4140810127': 0, '4140810128': 0, '4140810129': 0, '414081013': 0, '4140810132': 0, '4140810133': 0, '4140810135': 0, '4140810136': 0, '4140810138': 0, '4140810139': 0, '4140810140': 0, '4140810142': 0, '4140810143': 0, '4140810144': 0, '4140810145': 0, '4140810146': 0, '4140810148': 0, '414081015': 0, '4140810150': 0, '4140810151': 0, '4140810152': 0, '4140810153': 1, '4140810154': 0, '4140810158': 0, '4140810159': 0, '414081016': 0, '4140810162': 1, '4140810163': 0, '4140810164': 0, '4140810165': 0, '414081017': 0, '4140810171': 0, '4140810173': 0, '4140810175': 0, '4140810176': 0, '4140810179': 0, '414081018': 0, '4140810180': 0, '4140810181': 0, '4140810182': 0, '4140810183': 0, '4140810184': 0, '4140810185': 0, '414081019': 0, '414081021': 0, '4140810210': 1, '4140810211': 0, '4140810212': 0, '4140810215': 0, '4140810217': 1, '4140810219': 1, '4140810220': 0, '4140810221': 0, '4140810222': 0, '4140810223': 0, '4140810224': 0, '4140810225': 0, '4140810226': 0, '4140810228': 0, '4140810229': 0, '414081023': 0, '4140810230': 0, '4140810233': 0, '4140810234': 0, '4140810237': 0, '4140810239': 0, '4140810240': 0, '4140810242': 0, '4140810244': 0, '4140810246': 0, '4140810247': 0, '4140810249': 0, '414081025': 0, '4140810250': 0, '4140810251': 0, '4140810252': 0, '4140810253': 0, '4140810254': 0, '4140810255': 0, '4140810256': 0, '4140810257': 0, '4140810258': 0, '4140810259': 0, '414081026': 0, '4140810264': 0, '4140810265': 0, '4140810266': 0, '4140810268': 0, '4140810269': 0, '414081027': 0, '4140810270': 0, '4140810271': 0, '4140810272': 1, '4140810273': 0, '4140810274': 0, '4140810276': 0, '4140810277': 0, '4140810278': 0, '4140810279': 0, '414081028': 0, '4140810280': 0, '414081029': 0, '459999011': 0, '4599990110': 0, '4599990112': 0, '4599990113': 0, '4599990114': 0, '4599990116': 0, '4599990117': 0, '4599990118': 0, '4599990119': 0, '459999012': 0, '4599990120': 0, '4599990125': 0, '4599990126': 0, '4599990128': 0, '4599990129': 0, '459999013': 0, '4599990130': 0, '4599990131': 0, '4599990132': 1, '4599990133': 0, '4599990134': 0, '4599990136': 0, '4599990137': 0, '4599990139': 0, '4599990141': 0, '4599990144': 0, '4599990146': 0, '4599990148': 0, '4599990149': 0, '4599990153': 0, '4599990154': 0, '4599990155': 0, '459999016': 0, '4599990163': 0, '4599990165': 0, '4599990166': 0, '4599990168': 0, '459999017': 0, '4599990171': 0, '459999021': 0, '4599990211': 0, '4599990212': 0, '4599990214': 0, '4599990216': 0, '4599990218': 0, '459999022': 0, '4599990221': 0, '4599990222': 0, '4599990223': 0, '4599990224': 0, '4599990226': 0, '4599990231': 0, '4599990233': 0, '4599990234': 0, '4599990235': 1, '4599990238': 0, '459999024': 0, '4599990240': 0, '4599990241': 0, '4599990243': 0, '4599990244': 0, '4599990245': 0, '4599990246': 0, '4599990247': 0, '4599990248': 0, '4599990249': 0, '459999025': 0, '4599990253': 0, '4599990254': 0, '4599990255': 0, '4599990256': 0, '4599990263': 0, '4599990264': 0, '4599990269': 0, '4599990270': 0, '4599990272': 0, '4599990273': 0, '4599990274': 0, '4599990275': 0, '4599990276': 0, '459999028': 0, '4599990283': 0, '5000391001': 0, '5000391002': 0, '5000391004': 0, '5000391005': 0, '5000391007': 0, '5000391008': 0, '5000391010': 0, '5000391012': 0, '5000391013': 0, '5000391014': 0, '5000391015': 0, '5000391016': 0, '5000391017': 1, '5000391019': 0, '5000391020': 0, '5000391022': 0, '5000391023': 0, '5000391024': 0, '5000391026': 0, '5000391028': 0, '5000391029': 0, '5000391030': 0, '5000391031': 0, '5000391032': 0, '5000391034': 0, '5000391035': 0, '5000391036': 0, '5000391037': 0, '5000391038': 0, '5000391040': 0, '5000391045': 1, '5000391046': 0, '5000391047': 0, '5000391049': 0, '5000391050': 0, '5000391054': 0, '5000391055': 1, '5000391056': 1, '5000391059': 0, '5000391060': 1, '5000391061': 0, '5000391062': 0, '5000391063': 0, '5000391064': 0, '5000391065': 0, '5000391066': 0, '5000391067': 0, '5000391068': 0, '5000391069': 0, '5000391070': 0, '5000391071': 0, '5000391072': 0, '5000391073': 0, '5000391074': 0, '5000391076': 0, '5000391078': 0, '5000391079': 0, '5000391080': 0, '5000391081': 0, '5000392001': 0, '5000392002': 0, '5000392003': 0, '5000392006': 0, '5000392007': 0, '5000392010': 0, '5000392011': 0, '5000392015': 0, '5000392016': 0, '5000392017': 0, '5000392018': 0, '5000392019': 0, '5000392020': 0, '5000392021': 0, '5000392022': 0, '5000392025': 0, '5000392026': 0, '5000392027': 0, '5000392029': 0, '5000392033': 1, '5000392035': 0, '5000392036': 0, '5000392038': 0, '5000392039': 0, '5000392040': 0, '5000392041': 0, '5000392042': 0, '5000392044': 0, '5000392047': 0, '5000392048': 0, '5000392049': 0, '5000392050': 0, '5000392051': 0, '5000392052': 1, '5000392053': 0, '5000392054': 0, '5000392055': 0, '5000392056': 0, '5000392058': 0, '5000392060': 1, '5000392062': 0, '5000392063': 0, '5000392064': 0, '5000392065': 0, '5000392066': 0, '5000392067': 0, '5000392070': 0, '5000392071': 0, '5000392072': 0, '5000431019': 0, '5000431020': 0, '5000431021': 0, '5000431022': 0, '5000431023': 0, '5000431025': 0, '5000431026': 0, '5000431049': 0, '5000431050': 0, '5000432001': 0, '5000432003': 0, '5000432006': 0, '5000432059': 0, '5000441001': 0, '5000441002': 0, '5000441003': 0, '5000441005': 0, '5000441006': 0, '5000441007': 0, '5000441008': 0, '5000441009': 0, '5000441010': 0, '5000441012': 0, '5000441013': 0, '5000441014': 0, '5000441015': 0, '5000441016': 0, '5000441017': 0, '5000441018': 0, '5000441021': 0, '5000441022': 0, '5000441023': 0, '5000441024': 1, '5000441027': 0, '5000441030': 0, '5000441031': 0, '5000441032': 0, '5000441033': 0, '5000441034': 0, '5000441035': 0, '5000441037': 0, '5000441038': 0, '5000441039': 0, '5000441040': 0, '5000441041': 0, '5000441042': 0, '5000441043': 0, '5000441044': 0, '5000441045': 0, '5000441046': 0, '5000441047': 0, '5000441048': 0, '5000441050': 0, '5000441051': 0, '5000441052': 0, '5000441053': 0, '5000441054': 0, '5000441055': 0, '5000441058': 1, '5000441059': 0, '5000441061': 0, '5000441062': 0, '5000441064': 0, '5000441065': 0, '5000441066': 0, '5000441067': 1, '5000441068': 0, '5000441069': 0, '5000441070': 0, '5000441071': 0, '5000441072': 0, '5000442001': 0, '5000442002': 0, '5000442003': 0, '5000442004': 0, '5000442005': 0, '5000442007': 0, '5000442008': 0, '5000442009': 0, '5000442010': 0, '5000442014': 0, '5000442015': 0, '5000442016': 0, '5000442019': 0, '5000442021': 0, '5000442022': 0, '5000442024': 0, '5000442025': 0, '5000442026': 0, '5000442027': 0, '5000442028': 0, '5000442029': 0, '5000442033': 0, '5000442034': 0, '5000442035': 0, '5000442036': 0, '5000442037': 0, '5000442038': 0, '5000442039': 0, '5000442040': 0, '5000442042': 0, '5000442043': 0, '5000442045': 0, '5000442047': 0, '5000442048': 0, '5000442050': 0, '5000442051': 0, '5000442052': 0, '5000442053': 0, '5000442054': 0, '5000442055': 0, '5000442056': 0, '5000442057': 0, '5000442058': 0, '5000442059': 0, '5000442060': 0, '5000442062': 0, '5000442063': 0, '5000442064': 0, '5000442065': 0, '5000442066': 0, '5000442067': 0, '5000442068': 0, '5000442069': 0, '5000442070': 0, '5000442072': 0, '5000442073': 0, '5000442074': 0, '5000442075': 0, '5000442076': 0, '5000442077': 0, '5000442078': 0, '5000671001': 0, '5000671002': 0, '5000671003': 0, '5000671004': 0, '5000671005': 0, '5000671006': 0, '5000671008': 0, '5000671009': 0, '5000671010': 0, '5000671011': 0, '5000671012': 0, '5000671013': 0, '5000671014': 0, '5000671015': 0, '5000671016': 0, '5000671017': 0, '5000671018': 0, '5000671019': 0, '5000671020': 0, '5000671022': 0, '5000671023': 0, '5000671024': 0, '5000671026': 0, '5000671027': 0, '5000671028': 0, '5000671029': 0, '5000671030': 0, '5000671031': 0, '5000671032': 0, '5000671033': 0, '5000671034': 0, '5000671035': 0, '5000671036': 0, '5000671037': 0, '5000671038': 0, '5000671039': 0, '5000671040': 0, '5000671041': 1, '5000671042': 1, '5000671043': 0, '5000671046': 0, '5000671047': 0, '5000671048': 1, '5000671049': 1, '5000671050': 0, '5000671051': 0, '5000671053': 0, '5000671055': 0, '5000671056': 0, '5000671057': 0, '5000671058': 1, '5000671059': 0, '5000671060': 0, '5000671061': 1, '5000671062': 0, '5000671063': 0, '5000671064': 0, '5000671065': 0, '5000671066': 0, '5000671067': 0, '5000671069': 1, '5000671070': 1, '5000671071': 0, '5000672002': 0, '5000672004': 0, '5000672005': 0, '5000672006': 0, '5000672007': 0, '5000672008': 0, '5000672010': 0, '5000672011': 0, '5000672012': 0, '5000672013': 0, '5000672014': 0, '5000672016': 0, '5000672017': 0, '5000672019': 0, '5000672020': 0, '5000672021': 0, '5000672022': 0, '5000672023': 0, '5000672024': 0, '5000672025': 0, '5000672026': 0, '5000672027': 0, '5000672030': 0, '5000672031': 0, '5000672033': 0, '5000672034': 0, '5000672035': 0, '5000672036': 0, '5000672038': 0, '5000672042': 0, '5000672043': 0, '5000672044': 0, '5000672045': 0, '5000672046': 0, '5000672047': 0, '5000672048': 0, '5000672049': 0, '5000672050': 0, '5000672051': 0, '5000672052': 0, '5000672053': 0, '5000672054': 0, '5000672055': 0, '5000672056': 0, '5000672057': 0, '5000672058': 0, '5000672059': 0, '5000672060': 0, '5000672062': 0, '5000672064': 0, '5000672065': 0, '5000672066': 0, '5000672067': 0, '5000672068': 0, '5000672070': 0, '5000672071': 0, '5000672072': 0, '5000672074': 0, '5000672075': 0, '5000672076': 0, '5000672077': 0, '5000672081': 0, '5000672082': 0, '5000951001': 0, '5000951002': 0, '5000951003': 0, '5000951004': 0, '5000951005': 0, '5000951006': 0, '5000951007': 0, '5000951008': 0, '5000951009': 0, '5000951010': 0, '5000951011': 0, '5000951012': 0, '5000951013': 0, '5000951015': 0, '5000951016': 0, '5000951017': 0, '5000951018': 0, '5000951019': 1, '5000951021': 0, '5000951023': 1, '5000951024': 1, '5000951025': 0, '5000951027': 1, '5000951028': 0, '5000951033': 0, '5000951034': 0, '5000951035': 0, '5000951037': 0, '5000951039': 0, '5000951040': 0, '5000951042': 0, '5000951043': 0, '5000951044': 0, '5000951045': 0, '5000951047': 0, '5000951049': 0, '5000951051': 0, '5000951052': 0, '5000951053': 0, '5000951054': 0, '5000951055': 0, '5000951056': 0, '5000951057': 0, '5000951058': 0, '5000951060': 0, '5000951061': 0, '5000951062': 0, '5000951063': 0, '5000951065': 0, '5000951066': 0, '5000951067': 0, '5000952002': 0, '5000952003': 0, '5000952004': 0, '5000952005': 0, '5000952007': 0, '5000952008': 0, '5000952011': 0, '5000952013': 0, '5000952014': 0, '5000952015': 0, '5000952016': 0, '5000952017': 0, '5000952018': 0, '5000952020': 0, '5000952021': 0, '5000952022': 0, '5000952023': 0, '5000952024': 0, '5000952025': 0, '5000952026': 0, '5000952027': 0, '5000952028': 0, '5000952029': 0, '5000952031': 0, '5000952032': 0, '5000952033': 0, '5000952034': 1, '5000952035': 0, '5000952036': 0, '5000952038': 0, '5000952040': 0, '5000952041': 0, '5000952042': 0, '5000952044': 0, '5000952045': 0, '5000952046': 0, '5000952048': 0, '5000952050': 0, '5000952052': 0, '5000952053': 0, '5000952054': 0, '5000952055': 0, '5000952060': 0, '5000952061': 0, '5000952062': 1, '5000952063': 0, '5000952064': 0, '5000952065': 0, '5000952066': 0, '5000952068': 0, '5000952069': 0, '5000952070': 0, '5000952071': 0, '5000952072': 0, '5000952073': 0, '5000952075': 0, '5000952076': 0, '5000952077': 0, '5000952078': 0, '5000952080': 0, '5000952083': 1, '5100091001': 0, '5100091003': 0, '5100091004': 0, '5100091005': 0, '5100091006': 0, '5100091007': 0, '5100091008': 0, '5100091009': 0, '5100091010': 0, '5100091012': 0, '5100091017': 0, '5100091019': 0, '5100091020': 0, '5100091025': 0, '5100091026': 0, '5100091027': 0, '5100091028': 0, '5100091032': 0, '5100091033': 0, '5100091034': 0, '5100091035': 0, '5100091036': 0, '5100091038': 0, '5100091039': 0, '5100091042': 0, '5100091046': 0, '5100091049': 1, '5100091050': 0, '5100091051': 0, '5100091053': 0, '5100091055': 0, '5100091056': 0, '5100091057': 0, '5100091058': 0, '5100091059': 0, '5100091062': 0, '5100091064': 0, '5100091065': 0, '5100091066': 0, '5100091067': 0, '5100091068': 0, '5100091069': 0, '5100092002': 0, '5100092003': 0, '5100092005': 0, '5100092006': 0, '5100092008': 0, '5100092010': 0, '5100092011': 0, '5100092013': 0, '5100092017': 0, '5100092019': 0, '5100092021': 0, '5100092022': 0, '5100092023': 0, '5100092026': 0, '5100092027': 0, '5100092032': 0, '5100092033': 0, '5100092034': 0, '5100092035': 0, '5100092037': 0, '5100092038': 0, '5100092039': 0, '5100092040': 0, '5100092041': 0, '5100092042': 0, '5100092043': 0, '5100092044': 0, '5100092045': 0, '5100092053': 0, '5100092056': 0, '5100092057': 0, '5100092060': 0, '5100092061': 0, '5100092062': 0, '5100092063': 0, '5100092064': 0, '5100092065': 0, '5100092067': 0, '5100092068': 0, '5100092069': 0, '5100092071': 0, '5100092072': 0, '5100341002': 0, '5100341003': 0, '5100341004': 0, '5100341005': 0, '5100341006': 0, '5100341008': 0, '5100341009': 0, '5100341010': 0, '5100341012': 0, '5100341013': 0, '5100341014': 0, '5100341015': 0, '5100341016': 0, '5100341017': 0, '5100341019': 0, '5100341020': 0, '5100341021': 0, '5100341022': 0, '5100341023': 0, '5100341024': 0, '5100341025': 0, '5100341026': 0, '5100341027': 0, '5100341028': 0, '5100341030': 0, '5100341031': 0, '5100341032': 0, '5100341033': 0, '5100341034': 0, '5100341035': 0, '5100341037': 0, '5100341038': 0, '5100341039': 0, '5100341042': 0, '5100341043': 1, '5100341046': 0, '5100341048': 0, '5100341050': 0, '5100341052': 0, '5100341054': 0, '5100341055': 0, '5100341056': 0, '5100341057': 0, '5100341058': 0, '5100341061': 0, '5100341062': 0, '5100341065': 0, '5100341067': 0, '5100341068': 0, '5100341070': 0, '5100341071': 0, '5100341072': 0, '5100341074': 1, '5100341075': 0, '5100341076': 0, '5100341077': 0, '5100341078': 0, '5100341079': 0, '5100342002': 0, '5100342003': 0, '5100342007': 0, '5100342008': 0, '5100342009': 0, '5100342012': 0, '5100342016': 0, '5100342017': 0, '5100342018': 0, '5100342020': 0, '5100342022': 1, '5100342023': 1, '5100342024': 1, '5100342025': 0, '5100342028': 1, '5100342030': 0, '5100342031': 0, '5100342034': 0, '5100342036': 1, '5100342042': 0, '5100342043': 0, '5100342045': 0, '5100342048': 1, '5100351001': 1, '5100351002': 1, '5100351004': 0, '5100351005': 0, '5100351007': 0, '5100351009': 0, '5100351010': 0, '5100351012': 0, '5100351013': 1, '5100351015': 0, '5100351016': 0, '5100351019': 0, '5100351020': 0, '5100351021': 0, '5100351022': 1, '5100351023': 0, '5100351024': 0, '5100351025': 0, '5100351026': 0, '5100351032': 0, '5100351034': 0, '5100351035': 0, '5100351036': 0, '5100351038': 0, '5100351039': 0, '5100351040': 0, '5100351042': 1, '5100351043': 0, '5100351044': 0, '5100351045': 0, '5100351046': 0, '5100351049': 0, '5100351051': 0, '5100351054': 0, '5100351058': 0, '5100352001': 0, '5100352002': 0, '5100352003': 0, '5100352004': 0, '5100352005': 0, '5100352006': 0, '5100352007': 0, '5100352008': 0, '5100352009': 0, '5100352011': 0, '5100352012': 0, '5100352013': 0, '5100352014': 0, '5100352015': 0, '5100352016': 0, '5100352017': 0, '5100352018': 0, '5100352020': 0, '5100352021': 0, '5100352022': 1, '5100352026': 0, '5100352027': 0, '5100352028': 0, '5100352030': 0, '5100352031': 0, '5100352032': 0, '5100352033': 0, '5100352034': 0, '5100352035': 0, '5100352037': 0, '5100352038': 0, '5100352039': 0, '5100352041': 0, '5100352042': 0, '5100352043': 1, '5100352044': 0, '5100352045': 0, '5100352046': 0, '5100352049': 0, '5100352050': 0, '5100352051': 0, '5100352052': 0, '5100352054': 1, '5100352055': 0, '5100352056': 0, '5100352057': 0, '5100352060': 0, '5100352061': 0, '5100352063': 0, '5100361009': 0, '5100361056': 0, '5100362028': 0, '5100362029': 0, '5100362030': 0, '5100362052': 0, '5100371022': 0, '5100371023': 0, '5100371024': 0, '5100371026': 0, '5100371027': 0, '5100371042': 0, '5100371055': 0, '5100371056': 0, '5100371067': 0, '5100371079': 0, '5100372001': 0, '5100372002': 0, '5100372003': 0, '5100372005': 0, '5100372006': 0, '5100372007': 0, '5100372009': 0, '5100372011': 0, '5100372015': 0, '5100372016': 0, '5100372017': 0, '5100372018': 0, '5100372019': 0, '5100372020': 0, '5100372021': 0, '5100372022': 0, '5100372023': 0, '5100372026': 0, '5100372027': 0, '5100372028': 0, '5100372069': 0, '5100381002': 0, '5100381003': 0, '5100381004': 0, '5100381005': 0, '5100381006': 0, '5100381007': 0, '5100381008': 0, '5100381009': 0, '5100381010': 0, '5100381011': 0, '5100381012': 0, '5100381015': 0, '5100381016': 0, '5100381017': 0, '5100381018': 0, '5100381019': 0, '5100381020': 0, '5100381021': 0, '5100381022': 0, '5100381023': 0, '5100381024': 0, '5100381026': 0, '5100381027': 0, '5100381028': 0, '5100381029': 0, '5100381031': 0, '5100381032': 0, '5100381034': 0, '5100381035': 0, '5100381037': 0, '5100381038': 0, '5100381039': 0, '5100381040': 0, '5100381041': 0, '5100381042': 0, '5100381043': 0, '5100381044': 0, '5100381045': 0, '5100381046': 0, '5100381047': 0, '5100381048': 0, '5100381049': 0, '5100381050': 0, '5100381051': 0, '5100381052': 0, '5100381053': 0, '5100381054': 0, '5100381055': 0, '5100381056': 0, '5100381058': 0, '5100381059': 0, '5100381060': 0, '5100381061': 0, '5100381063': 0, '5100381065': 0, '5100381066': 0, '5100381067': 0, '5100381069': 0, '5100382001': 0, '5100382003': 0, '5100382007': 0, '5100382008': 0, '5100382010': 0, '5100382011': 0, '5100382012': 0, '5100382013': 0, '5100382014': 0, '5100382015': 0, '5100382016': 0, '5100382018': 0, '5100382019': 0, '5100382020': 0, '5100382021': 0, '5100382022': 0, '5100382023': 0, '5100382025': 0, '5100382026': 0, '5100382027': 0, '5100382028': 0, '5100382029': 0, '5100382030': 0, '5100382031': 0, '5100382032': 0, '5100382033': 0, '5100382034': 0, '5100382035': 0, '5100382036': 0, '5100382037': 0, '5100382038': 0, '5100382039': 0, '5100382040': 0, '5100382042': 0, '5100382045': 0, '5100382046': 0, '5100382048': 0, '5100382050': 0, '5100382051': 0, '5100382052': 0, '5100382053': 0, '5100382054': 0, '5100382055': 0, '5100382056': 0, '5100382057': 0, '5100382058': 0, '5100382059': 0, '5100382060': 0, '5100382061': 0, '5100382062': 0, '5100382063': 0, '5100382064': 0, '5100382065': 0, '5100382066': 0, '5100382067': 0, '5100382068': 0, '5100382069': 0, '5100382070': 0, '5100382071': 0, '5100382072': 0, '5100382073': 0, '5100382075': 0, '5100382076': 0, '5100382077': 0, '5100382078': 0, '5100382079': 0, '5100401001': 0, '5100401003': 0, '5100401005': 0, '5100401006': 0, '5100401007': 0, '5100401008': 0, '5100401010': 0, '5100401011': 0, '5100401012': 0, '5100401014': 0, '5100401015': 0, '5100401016': 0, '5100401018': 0, '5100401021': 0, '5100401022': 0, '5100401023': 1, '5100401025': 0, '5100401026': 0, '5100401028': 0, '5100401029': 0, '5100401030': 0, '5100401031': 0, '5100401032': 0, '5100401033': 0, '5100401034': 1, '5100401035': 0, '5100401036': 0, '5100401038': 0, '5100401039': 0, '5100401040': 0, '5100401042': 0, '5100401043': 1, '5100401044': 0, '5100401045': 0, '5100401046': 0, '5100401047': 0, '5100401048': 0, '5100401049': 0, '5100401050': 0, '5100401051': 0, '5100401053': 0, '5100401054': 0, '5100401055': 0, '5100401056': 0, '5100401057': 0, '5100401059': 0, '5100401060': 0, '5100401061': 0, '5100401062': 0, '5100401063': 0, '5100401064': 0, '5100401065': 1, '5100401066': 0, '5100401067': 0, '5100401069': 0, '5100401070': 0, '5100401071': 0, '5100401072': 0, '5100401073': 0, '5100401074': 0, '5100401075': 0, '5100401076': 0, '5100401077': 0, '5100401078': 0, '5100402001': 1, '5100402002': 0, '5100402004': 0, '5100402005': 0, '5100402007': 0, '5100402008': 0, '5100402009': 0, '5100402011': 0, '5100402012': 0, '5100402015': 0, '5100402016': 0, '5100402017': 0, '5100402019': 0, '5100402020': 0, '5100402023': 0, '5100402024': 0, '5100402028': 0, '5100402029': 0, '5100402031': 0, '5100402032': 0, '5100402033': 0, '5100402034': 0, '5100402035': 0, '5100402036': 0, '5100402037': 0, '5100402038': 0, '5100402039': 0, '5100402040': 0, '5100402046': 0, '5100402047': 0, '5100402048': 0, '5100402049': 0, '5100402050': 0, '5100402051': 0, '5100402052': 0, '5100402053': 0, '5100402054': 0, '5100402055': 0, '5100402057': 0, '5100402058': 0, '5100402059': 0, '5100402062': 1, '5100402063': 1, '5100402065': 0, '5100402066': 0, '5100402067': 0, '5100402068': 0, '5100402069': 0, '5100421001': 0, '5100421002': 0, '5100421003': 0, '5100421005': 0, '5100421007': 0, '5100421009': 0, '5100421011': 0, '5100421012': 0, '5100421013': 0, '5100421015': 0, '5100421016': 0, '5100421017': 0, '5100421018': 0, '5100421019': 0, '5100421020': 0, '5100421021': 0, '5100421024': 0, '5100421025': 0, '5100421026': 0, '5100421027': 0, '5100421029': 0, '5100421032': 0, '5100421033': 0, '5100421034': 0, '5100421038': 0, '5100421039': 0, '5100421040': 0, '5100421041': 0, '5100421043': 0, '5100421045': 0, '5100421047': 0, '5100421048': 0, '5100421049': 0, '5100421050': 0, '5100421051': 0, '5100421052': 0, '5100421053': 0, '5100421054': 0, '5100421056': 0, '5100421057': 0, '5100421058': 0, '5100421059': 0, '5100421060': 0, '5100421061': 0, '5100421062': 0, '5100421063': 0, '5100421064': 0, '5100421065': 0, '5100421067': 0, '5100421068': 0, '5100421069': 0, '5100421070': 0, '5100421071': 0, '5100421072': 0, '5100421073': 0, '5100421074': 0, '5100421076': 0, '5100421078': 0, '5100421079': 0, '5100421080': 0, '5100421081': 0, '5100422002': 0, '5100422003': 0, '5100422004': 0, '5100422005': 0, '5100422006': 0, '5100422007': 0, '5100422008': 0, '5100422009': 0, '5100422011': 0, '5100422012': 0, '5100422013': 0, '5100422014': 0, '5100422016': 0, '5100422017': 0, '5100422018': 0, '5100422019': 0, '5100422022': 0, '5100422023': 0, '5100422024': 0, '5100422025': 0, '5100422026': 0, '5100422027': 0, '5100422028': 0, '5100422029': 0, '5100422030': 0, '5100422033': 0, '5100422034': 0, '5100422035': 0, '5100422036': 0, '5100422037': 0, '5100422038': 0, '5100422039': 0, '5100422041': 0, '5100422042': 0, '5100422044': 0, '5100422045': 0, '5100422046': 0, '5100422047': 0, '5100422049': 0, '5100422050': 0, '5100422051': 0, '5100422052': 0, '5100422055': 0, '5100422056': 0, '5100422057': 0, '5100422058': 0, '5100422059': 0, '5100422060': 0, '5100422061': 0, '5100422062': 0, '5100422063': 0, '5100422065': 0, '5100422066': 0, '5100422067': 0, '5100422068': 0, '5100422069': 0, '5100422071': 0, '5100422072': 0, '5100422073': 0, '5100422074': 0, '5100422075': 0, '5100422077': 0, '5100422078': 0, '5100422079': 0, '5100422080': 0, '5100422081': 0, '5100422084': 0, '5100422085': 0, '5100451001': 0, '5100451003': 0, '5100451004': 0, '5100451006': 0, '5100451007': 0, '5100451012': 0, '5100451013': 0, '5100451015': 0, '5100451016': 0, '5100451017': 0, '5100451018': 0, '5100451019': 0, '5100451020': 0, '5100451024': 0, '5100451026': 0, '5100451027': 0, '5100451033': 0, '5100451034': 0, '5100451035': 0, '5100451036': 0, '5100451038': 0, '5100451041': 0, '5100451043': 0, '5100451044': 0, '5100451045': 0, '5100451049': 0, '5100451050': 0, '5100451051': 0, '5100451052': 0, '5100451055': 0, '5100451056': 0, '5100451059': 0, '5100451060': 0, '5100451061': 0, '5100451064': 0, '5100451065': 0, '5100451066': 0, '5100451067': 0, '5100451070': 0, '5100451071': 0, '5100452002': 0, '5100452004': 0, '5100452005': 0, '5100452006': 0, '5100452007': 0, '5100452008': 0, '5100452009': 0, '5100452010': 0, '5100452011': 0, '5100452012': 0, '5100452013': 0, '5100452014': 0, '5100452016': 1, '5100452017': 0, '5100452018': 0, '5100452021': 0, '5100452023': 0, '5100452025': 0, '5100452027': 0, '5100452028': 0, '5100452030': 0, '5100452031': 0, '5100452032': 0, '5100452033': 0, '5100452034': 0, '5100452035': 0, '5100452036': 0, '5100452037': 0, '5100452038': 0, '5100452039': 0, '5100452040': 0, '5100452047': 0, '5100452049': 0, '5100452050': 0, '5100452053': 0, '5100452054': 0, '5100452055': 0, '5100452059': 0, '5100452060': 0, '5100452061': 0, '5100452065': 0, '5100452066': 0, '5100452067': 0, '5100452076': 0, '5100452078': 0, '5100452079': 0, '5100452080': 0, '5100452081': 0, '5100461004': 0, '5100461005': 0, '5100461006': 0, '5100461007': 1, '5100461008': 0, '5100461009': 0, '5100461010': 0, '5100461011': 0, '5100461014': 0, '5100461015': 0, '5100461016': 0, '5100461017': 0, '5100461018': 0, '5100461020': 0, '5100461021': 0, '5100461022': 0, '5100461023': 0, '5100461025': 0, '5100461029': 0, '5100461030': 0, '5100461031': 0, '5100461032': 0, '5100461033': 0, '5100461034': 0, '5100461035': 0, '5100461036': 0, '5100461037': 0, '5100461038': 0, '5100461039': 0, '5100461040': 0, '5100461042': 0, '5100461043': 0, '5100461044': 0, '5100461046': 0, '5100461047': 0, '5100461048': 0, '5100461049': 0, '5100461050': 0, '5100461051': 0, '5100461052': 0, '5100461053': 0, '5100461054': 0, '5100461055': 0, '5100461056': 0, '5100461057': 0, '5100461058': 0, '5100461061': 0, '5100461062': 0, '5100461063': 0, '5100461064': 0, '5100461065': 0, '5100461066': 0, '5100461067': 0, '5100461068': 0, '5100461069': 0, '5100462001': 0, '5100462002': 0, '5100462003': 1, '5100462005': 0, '5100462009': 0, '5100462010': 0, '5100462011': 0, '5100462012': 0, '5100462014': 0, '5100462015': 0, '5100462016': 0, '5100462017': 0, '5100462018': 0, '5100462019': 0, '5100462021': 0, '5100462022': 0, '5100462023': 0, '5100462024': 0, '5100462025': 0, '5100462026': 0, '5100462027': 0, '5100462028': 0, '5100462029': 0, '5100462031': 0, '5100462032': 0, '5100462033': 0, '5100462035': 0, '5100462037': 0, '5100462038': 0, '5100462039': 0, '5100462040': 0, '5100462041': 0, '5100462042': 0, '5100462043': 0, '5100462044': 0, '5100462045': 0, '5100462046': 0, '5100462047': 0, '5100462048': 0, '5100462050': 0, '5100462051': 0, '5100462052': 0, '5100462053': 0, '5100462054': 0, '5100462055': 0, '5100462057': 0, '5100462058': 0, '5100462059': 0, '5100462061': 0, '5100462062': 0, '5100462063': 0, '5100462064': 0, '5100462066': 0, '5100462067': 0, '5100462068': 0, '5100462069': 0, '5100462070': 0, '5100462071': 0, '5100462072': 0, '5100462074': 0, '5100462075': 0, '5100462077': 0, '5100462078': 0, '5100462079': 0, '5100462080': 0, '5100462081': 0, '5100462082': 0, '5100471001': 0, '5100471002': 0, '5100471003': 0, '5100471011': 0, '5100471012': 0, '5100471013': 0, '5100471015': 0, '5100471016': 0, '5100471018': 0, '5100471019': 0, '5100471020': 0, '5100471021': 0, '5100471023': 0, '5100471026': 0, '5100471027': 0, '5100471028': 0, '5100471029': 0, '5100471030': 0, '5100471031': 0, '5100471034': 0, '5100471037': 0, '5100471038': 0, '5100471039': 0, '5100471041': 0, '5100471042': 0, '5100471044': 0, '5100471045': 0, '5100471047': 0, '5100471049': 0, '5100471050': 0, '5100471051': 0, '5100471052': 0, '5100471054': 0, '5100471056': 0, '5100471057': 0, '5100471058': 0, '5100471059': 0, '5100471060': 0, '5100471062': 0, '5100471063': 0, '5100471065': 0, '5100471068': 0, '5100471069': 0, '5100471070': 0, '5100471072': 0, '5100471074': 0, '5100471075': 0, '5100471080': 0, '5100471081': 0, '5100472001': 1, '5100472002': 0, '5100472003': 0, '5100472004': 0, '5100472005': 0, '5100472007': 0, '5100472009': 0, '5100472010': 0, '5100472011': 0, '5100472012': 0, '5100472014': 0, '5100472019': 0, '5100472020': 0, '5100472021': 0, '5100472027': 0, '5100472030': 0, '5100472031': 0, '5100472032': 0, '5100472035': 0, '5100472039': 0, '5100472040': 0, '5100472041': 0, '5100472042': 0, '5100472044': 0, '5100472045': 0, '5100472047': 0, '5100472050': 0, '5100472052': 0, '5100472053': 0, '5100472054': 0, '5100472058': 1, '5100472060': 0, '5100472063': 0, '5100472064': 0, '5221290110': 0, '5221290111': 0, '5221290112': 0, '5221290114': 0, '5221290115': 0, '5221290116': 0, '5221290118': 0, '5221290119': 0, '5221290121': 0, '5221290122': 0, '5221290123': 0, '5221290124': 0, '5221290126': 0, '5221290127': 0, '5221290129': 0, '522129013': 0, '5221290131': 0, '5221290132': 0, '5221290134': 0, '5221290135': 0, '5221290137': 0, '5221290138': 0, '5221290140': 0, '5221290141': 0, '5221290142': 0, '5221290144': 0, '5221290145': 0, '5221290147': 0, '5221290149': 0, '5221290150': 0, '5221290151': 0, '5221290155': 0, '5221290158': 0, '522129016': 0, '5221290161': 0, '5221290162': 0, '5221290163': 0, '5221290164': 0, '5221290165': 0, '5221290166': 0, '5221290167': 0, '5221290169': 0, '522129017': 0, '5221290171': 0, '5221290172': 0, '5221290173': 0, '5221290174': 0, '5221290175': 0, '5221290177': 0, '5221290178': 0, '5221290179': 0, '522129018': 0, '5221290180': 0, '5221290184': 0, '522129021': 0, '5221290210': 0, '5221290212': 0, '5221290213': 0, '5221290214': 0, '5221290215': 0, '5221290216': 0, '5221290217': 0, '522129022': 0, '5221290220': 0, '5221290221': 0, '5221290222': 0, '5221290223': 0, '5221290226': 0, '5221290227': 0, '5221290228': 0, '5221290230': 0, '5221290231': 0, '5221290235': 0, '5221290237': 0, '5221290238': 0, '5221290239': 0, '522129024': 0, '5221290240': 0, '5221290242': 0, '5221290247': 0, '5221290249': 0, '522129025': 0, '5221290250': 0, '5221290251': 0, '5221290252': 0, '5221290253': 0, '5221290254': 0, '5221290255': 0, '5221290256': 0, '5221290257': 0, '5221290258': 0, '5221290259': 0, '522129026': 0, '5221290263': 0, '5221290264': 0, '5221290266': 0, '5221290268': 0, '5221290269': 0, '522129027': 0, '5221290270': 0, '5221290271': 0, '5221290272': 0, '5221290273': 0, '5221290274': 0, '5221290275': 0, '5221290279': 0, '5221290280': 1, '5221290282': 0, '5221290284': 0, '5564630110': 0, '5564630112': 0, '5564630115': 0, '5564630117': 0, '556463012': 0, '5564630121': 0, '5564630122': 0, '5564630123': 0, '5564630126': 1, '5564630127': 0, '5564630128': 0, '5564630129': 0, '556463013': 0, '5564630130': 0, '5564630132': 1, '5564630133': 0, '5564630134': 0, '5564630135': 0, '5564630137': 1, '5564630138': 1, '5564630139': 0, '556463014': 1, '5564630140': 0, '5564630141': 1, '5564630142': 0, '5564630143': 0, '5564630145': 0, '5564630147': 0, '5564630148': 0, '5564630149': 0, '5564630150': 0, '5564630152': 0, '5564630153': 0, '5564630154': 1, '5564630156': 1, '5564630157': 0, '5564630158': 0, '556463016': 0, '5564630160': 0, '5564630161': 0, '5564630162': 0, '5564630163': 0, '5564630165': 0, '5564630166': 0, '5564630167': 0, '5564630168': 1, '556463018': 0, '556463019': 0, '5564630211': 1, '5564630212': 0, '5564630213': 0, '5564630215': 0, '5564630216': 0, '5564630217': 0, '5564630218': 0, '5564630219': 0, '556463022': 1, '5564630221': 0, '5564630222': 0, '5564630226': 1, '5564630228': 0, '5564630229': 0, '5564630230': 0, '5564630232': 0, '5564630233': 0, '5564630234': 0, '5564630235': 0, '5564630236': 0, '5564630237': 0, '5564630238': 1, '556463024': 0, '5564630240': 0, '5564630241': 0, '5564630247': 0, '5564630249': 0, '556463025': 1, '5564630252': 0, '5564630253': 0, '5564630254': 0, '5564630256': 0, '5564630257': 1, '5564630258': 0, '556463026': 0, '5564630261': 0, '5564630262': 0, '5564630264': 0, '5564630265': 0, '5564630269': 0, '556463027': 0, '5564630273': 0, '5564630275': 0, '5564630276': 0, '556463028': 0, '5564630281': 0, '556463029': 0, '567496011': 0, '5674960111': 0, '5674960114': 0, '5674960115': 0, '5674960116': 0, '5674960117': 0, '5674960118': 0, '5674960121': 0, '5674960123': 0, '5674960124': 0, '5674960125': 0, '5674960126': 0, '567496013': 0, '5674960131': 0, '5674960132': 0, '5674960134': 0, '5674960136': 0, '5674960138': 0, '567496014': 0, '5674960142': 0, '5674960144': 0, '5674960145': 0, '5674960146': 0, '5674960148': 0, '5674960151': 0, '5674960153': 0, '5674960154': 0, '5674960155': 1, '5674960156': 0, '5674960157': 0, '5674960158': 0, '5674960160': 0, '5674960161': 0, '5674960166': 0, '567496017': 0, '5674960170': 0, '567496018': 0, '567496019': 0, '567496021': 1, '5674960211': 0, '5674960215': 0, '5674960216': 0, '5674960219': 0, '567496022': 1, '5674960220': 0, '5674960221': 0, '5674960222': 1, '5674960224': 0, '5674960225': 1, '5674960227': 0, '5674960228': 0, '5674960229': 0, '5674960230': 0, '5674960234': 0, '5674960235': 0, '567496024': 0, '5674960242': 0, '5674960246': 0, '5674960249': 0, '5674960251': 0, '5674960252': 0, '5674960255': 0, '5674960257': 0, '567496026': 0, '5674960261': 0, '5674960264': 0, '5674960268': 0, '5674960272': 0, '5674960273': 0, '5674960274': 0, '5674960275': 0, '5674960276': 0, '5674960277': 0, '5674960278': 0, '5674960279': 0, '567496028': 0, '5674960281': 0, '5674960282': 0, '5674960283': 1, '567496029': 0, '5912920111': 0, '5912920112': 0, '5912920113': 0, '5912920114': 0, '5912920119': 0, '5912920121': 0, '5912920123': 0, '5912920124': 0, '5912920125': 0, '5912920126': 0, '5912920127': 0, '5912920128': 1, '5912920129': 0, '5912920131': 0, '5912920133': 0, '5912920135': 0, '5912920137': 0, '5912920140': 0, '5912920142': 0, '5912920143': 0, '5912920145': 0, '5912920146': 0, '5912920147': 0, '5912920148': 0, '5912920149': 0, '591292015': 0, '5912920151': 0, '5912920152': 0, '5912920154': 0, '5912920156': 0, '5912920158': 0, '5912920159': 0, '5912920160': 0, '5912920163': 0, '5912920167': 0, '5912920168': 0, '5912920169': 0, '5912920170': 0, '5912920171': 0, '5912920172': 0, '591292019': 0, '591292021': 0, '5912920211': 0, '5912920212': 0, '5912920213': 0, '5912920216': 0, '5912920217': 0, '5912920220': 0, '5912920222': 0, '5912920223': 0, '5912920225': 0, '5912920227': 0, '5912920228': 0, '5912920230': 0, '5912920231': 0, '5912920233': 0, '5912920234': 0, '5912920235': 0, '5912920236': 0, '5912920239': 0, '591292024': 0, '5912920240': 0, '5912920241': 0, '5912920242': 0, '5912920243': 0, '5912920244': 0, '5912920245': 0, '5912920249': 0, '5912920250': 0, '5912920256': 0, '5912920260': 0, '5912920263': 0, '5912920265': 0, '5912920266': 0, '5912920267': 0, '5912920268': 0, '5912920273': 0, '5912920274': 0, '5912920275': 0, '5912920276': 0, '5912920277': 0, '5912920279': 0, '5912920280': 0, '769862011': 0, '7698620112': 0, '7698620113': 0, '7698620115': 0, '7698620116': 0, '7698620118': 0, '7698620120': 0, '7698620122': 0, '7698620123': 0, '7698620126': 0, '7698620129': 0, '7698620130': 0, '7698620131': 0, '7698620132': 0, '7698620133': 0, '7698620134': 0, '7698620136': 0, '7698620138': 0, '7698620139': 0, '769862014': 0, '7698620141': 0, '7698620144': 0, '7698620145': 0, '7698620149': 0, '769862015': 0, '7698620150': 0, '7698620151': 0, '7698620152': 0, '7698620153': 0, '7698620156': 0, '7698620158': 0, '769862016': 0, '7698620160': 0, '7698620161': 0, '7698620163': 0, '7698620165': 0, '7698620166': 0, '7698620167': 0, '7698620169': 0, '769862017': 1, '7698620170': 0, '7698620171': 0, '769862018': 0, '769862019': 0, '769862021': 0, '7698620211': 0, '7698620212': 0, '7698620217': 0, '7698620218': 0, '769862022': 0, '7698620221': 0, '7698620222': 0, '7698620224': 0, '7698620225': 0, '7698620227': 0, '7698620229': 0, '7698620230': 0, '7698620231': 0, '7698620233': 1, '7698620236': 0, '7698620238': 0, '7698620239': 0, '7698620240': 0, '7698620241': 0, '7698620244': 0, '7698620245': 0, '7698620248': 0, '7698620250': 0, '7698620252': 1, '7698620253': 0, '7698620255': 0, '7698620256': 0, '7698620257': 0, '7698620258': 0, '7698620260': 0, '7698620261': 0, '7698620262': 0, '7698620264': 0, '7698620265': 0, '7698620267': 0, '7698620268': 0, '769862027': 0, '7698620270': 0, '7698620272': 0, '7698620274': 0, '7698620275': 0, '7698620278': 0, '769862028': 0, '7698620281': 0, '7698620283': 0, '7994020110': 0, '79940201100': 0, '79940201110': 0, '79940201140': 0, '79940201150': 0, '79940201160': 0, '79940201180': 0, '79940201210': 0, '79940201230': 0, '79940201250': 0, '79940201270': 0, '7994020130': 0, '79940201300': 1, '79940201320': 0, '79940201330': 0, '79940201340': 0, '79940201350': 0, '79940201360': 0, '79940201370': 0, '79940201380': 0, '79940201390': 1, '7994020140': 0, '79940201410': 0, '79940201420': 0, '79940201430': 0, '79940201470': 0, '79940201490': 0, '79940201510': 0, '79940201560': 0, '79940201570': 0, '79940201580': 0, '7994020160': 0, '79940201620': 0, '79940201650': 0, '79940201660': 1, '79940201690': 0, '79940201700': 0, '79940201710': 0, '79940201720': 0, '79940201730': 0, '79940201740': 0, '79940201750': 0, '79940201760': 0, '79940201770': 0, '79940201780': 0, '79940201790': 1, '79940201810': 0, '79940201820': 0, '79940201850': 0, '79940201860': 0, '79940201880': 0, '79940201930': 0, '79940201950': 0, '79940202100': 0, '79940202120': 0, '79940202130': 0, '79940202140': 0, '79940202160': 0, '79940202170': 0, '79940202180': 0, '79940202190': 0, '79940202200': 0, '79940202210': 0, '79940202220': 0, '79940202230': 0, '79940202270': 1, '79940202280': 1, '7994020230': 1, '79940202300': 0, '79940202310': 1, '79940202320': 0, '79940202340': 0, '79940202350': 0, '79940202370': 0, '79940202390': 0, '79940202400': 0, '79940202410': 0, '79940202450': 0, '79940202470': 0, '79940202480': 0, '79940202490': 1, '7994020250': 0, '79940202510': 0, '79940202520': 0, '79940202540': 0, '79940202560': 0, '79940202570': 0, '79940202580': 0, '79940202620': 0, '79940202690': 0, '7994020270': 0, '79940202700': 0, '79940202710': 0, '79940202750': 0, '79940202760': 0, '79940202790': 0, '7994020280': 0, '79940202800': 1, '79940202820': 0, '79940202840': 1, '79940202850': 1, '79940202860': 1, '79940202870': 0, '79940202890': 0, '7994020290': 0, '8263820112': 0, '8263820113': 0, '8263820120': 0, '8263820123': 0, '8263820124': 0, '8263820126': 0, '8263820132': 0, '8263820135': 0, '8263820136': 0, '8263820138': 0, '8263820139': 0, '8263820140': 0, '8263820141': 0, '8263820144': 0, '8263820145': 0, '8263820146': 0, '8263820147': 0, '8263820148': 0, '826382015': 0, '8263820150': 0, '8263820151': 0, '8263820152': 0, '8263820155': 0, '8263820156': 0, '8263820159': 0, '826382016': 0, '8263820160': 0, '8263820162': 0, '8263820165': 0, '8263820169': 0, '8263820170': 0, '826382018': 0, '826382021': 0, '8263820210': 0, '8263820211': 0, '8263820212': 0, '8263820213': 0, '8263820214': 0, '8263820221': 0, '8263820223': 0, '8263820224': 0, '8263820227': 0, '8263820228': 0, '826382023': 0, '8263820231': 0, '8263820233': 0, '8263820234': 0, '8263820235': 0, '8263820237': 0, '8263820239': 0, '826382024': 1, '8263820240': 0, '8263820242': 0, '8263820243': 0, '8263820245': 0, '8263820246': 0, '8263820247': 0, '8263820251': 0, '8263820253': 0, '8263820254': 0, '8263820255': 0, '8263820256': 0, '8263820257': 0, '8263820259': 0, '826382026': 0, '8263820260': 0, '8263820264': 0, '8263820265': 0, '8263820266': 0, '8263820268': 0, '8263820269': 0, '826382027': 0, '8263820272': 0, '8263820273': 0, '8263820275': 0, '8263820277': 0, '8263820278': 0, '8263820279': 0, '826382028': 0, '826412010': 0, '8264120110': 0, '8264120111': 0, '8264120112': 0, '8264120113': 0, '8264120116': 1, '8264120117': 0, '8264120119': 0, '8264120120': 1, '8264120121': 0, '8264120122': 0, '8264120123': 1, '8264120124': 0, '8264120125': 0, '8264120126': 0, '8264120127': 1, '826412013': 1, '8264120131': 0, '8264120132': 0, '8264120136': 0, '8264120139': 0, '8264120141': 0, '8264120144': 0, '8264120145': 0, '8264120146': 0, '8264120149': 0, '8264120150': 1, '8264120156': 1, '8264120157': 0, '8264120159': 0, '8264120165': 0, '8264120166': 0, '8264120169': 1, '826412017': 0, '826412018': 0, '826412019': 0, '8264120210': 0, '8264120211': 1, '8264120213': 0, '8264120215': 0, '8264120216': 0, '8264120218': 0, '8264120219': 0, '8264120220': 0, '8264120221': 0, '8264120223': 0, '8264120224': 0, '8264120227': 0, '8264120228': 0, '8264120229': 0, '826412023': 0, '8264120231': 1, '8264120232': 0, '8264120233': 0, '8264120234': 0, '8264120239': 1, '826412024': 0, '8264120240': 1, '8264120241': 0, '8264120242': 0, '8264120243': 1, '8264120245': 0, '8264120247': 0, '8264120248': 0, '8264120249': 1, '826412025': 0, '8264120254': 1, '8264120256': 1, '8264120257': 0, '8264120258': 0, '8264120261': 1, '8264120262': 1, '8264120263': 1, '8264120265': 1, '8264120266': 1, '8264120268': 0, '8264120269': 1, '826412027': 0, '8264120274': 0, '8264120275': 0, '8264120279': 1, '8264120280': 0, '8264120282': 1, '8264120284': 1, '88265401100': 0, '88265401130': 0, '88265401140': 0, '88265401150': 0, '88265401160': 0, '88265401170': 0, '88265401190': 0, '8826540120': 0, '88265401200': 0, '88265401240': 0, '88265401260': 0, '88265401270': 0, '88265401280': 0, '88265401300': 0, '88265401320': 0, '88265401350': 0, '88265401360': 0, '88265401380': 0, '88265401390': 0, '88265401400': 0, '88265401410': 0, '88265401420': 0, '88265401430': 0, '88265401450': 0, '88265401470': 0, '88265401480': 0, '88265401490': 0, '8826540150': 0, '88265401520': 0, '88265401550': 0, '88265401630': 0, '88265401640': 0, '88265401660': 0, '88265401690': 0, '8826540170': 0, '88265401730': 0, '88265401740': 0, '88265401750': 1, '8826540180': 0, '88265402120': 0, '88265402150': 0, '88265402160': 0, '88265402170': 0, '88265402180': 0, '88265402190': 0, '88265402200': 0, '88265402230': 0, '88265402240': 0, '88265402270': 0, '8826540230': 0, '88265402300': 0, '88265402310': 0, '88265402320': 0, '88265402330': 0, '88265402340': 0, '88265402350': 0, '88265402370': 0, '88265402380': 0, '8826540240': 0, '88265402400': 0, '88265402420': 0, '88265402440': 0, '88265402450': 0, '88265402480': 0, '88265402490': 0, '88265402500': 0, '88265402520': 0, '88265402540': 0, '88265402570': 0, '88265402580': 0, '88265402590': 0, '8826540260': 0, '88265402600': 0, '88265402630': 0, '88265402660': 0, '88265402690': 0, '8826540270': 0, '88265402700': 0, '88265402770': 0, '88265402780': 0, '88265402790': 0, '8826540280': 0, '88265402800': 0, '88265402810': 0, '88265402820': 0, '88265402840': 0, '88265402850': 0, '88265402880': 0, '88265402890': 0, '8826540290': 0, '88265402900': 0, '907001100': 0, '9070011010': 0, '9070011020': 0, '9070011060': 0, '9070011090': 0, '907001110': 0, '9070011110': 0, '907001120': 0, '907001150': 0, '907001160': 0, '907001170': 0, '907001180': 0, '907001210': 0, '907001220': 0, '907001240': 0, '907001270': 0, '907001280': 0, '907001310': 0, '907001340': 0, '907001350': 0, '907001360': 0, '907001370': 0, '907001400': 0, '907001430': 0, '907001450': 0, '907001480': 1, '907001490': 0, '90700150': 0, '907001500': 0, '907001520': 0, '907001550': 0, '907001560': 0, '907001570': 0, '907001580': 0, '90700160': 0, '907001600': 0, '907001620': 0, '907001650': 0, '907001670': 0, '907001680': 0, '90700170': 0, '907001730': 0, '907001740': 0, '907001780': 0, '907001790': 0, '90700180': 0, '907001820': 0, '907001840': 0, '907001850': 0, '907001860': 0, '90700190': 0, '907001910': 0, '907001940': 0, '907001950': 1, '907001970': 0, '9289010111': 0, '9289010112': 0, '9289010113': 0, '9289010114': 1, '9289010115': 0, '9289010117': 0, '9289010118': 0, '9289010119': 0, '9289010120': 0, '9289010121': 0, '9289010127': 0, '928901013': 0, '9289010131': 0, '9289010132': 0, '9289010133': 0, '9289010134': 0, '9289010138': 0, '9289010139': 0, '928901014': 1, '9289010143': 0, '9289010144': 0, '9289010145': 1, '9289010147': 0, '9289010149': 0, '9289010150': 0, '9289010151': 0, '9289010152': 1, '9289010153': 0, '9289010154': 0, '9289010155': 0, '9289010157': 0, '9289010158': 0, '928901016': 0, '9289010160': 0, '9289010161': 0, '9289010163': 0, '9289010166': 0, '9289010167': 0, '928901018': 0, '9289010210': 0, '9289010211': 0, '9289010216': 0, '9289010221': 0, '9289010222': 0, '9289010223': 0, '9289010227': 0, '9289010229': 0, '928901023': 0, '9289010230': 0, '9289010231': 0, '9289010232': 0, '9289010233': 0, '9289010235': 0, '9289010242': 0, '9289010243': 0, '9289010244': 0, '9289010245': 0, '9289010248': 0, '9289010249': 0, '928901025': 0, '9289010250': 0, '9289010251': 0, '9289010253': 0, '9289010254': 0, '9289010257': 0, '9289010259': 0, '928901026': 0, '9289010261': 0, '9289010262': 0, '9289010263': 0, '9289010265': 0, '9289010266': 0, '9289010267': 0, '9289010268': 0, '9289010269': 0, '9289010270': 0, '9289010271': 0, '9289010273': 0, '9289010274': 0, '9289010275': 0, '9289010276': 1, '9289010278': 0, '928901028': 0, '928901029': 0, '940328011': 0, '9403280110': 0, '9403280112': 0, '9403280114': 0, '9403280115': 0, '9403280116': 0, '9403280117': 0, '940328012': 0, '9403280126': 0, '9403280129': 0, '9403280132': 0, '9403280134': 0, '9403280136': 0, '9403280138': 0, '940328014': 0, '9403280140': 0, '9403280143': 0, '9403280145': 0, '9403280146': 0, '9403280147': 0, '9403280149': 0, '9403280150': 0, '9403280151': 0, '9403280152': 0, '9403280155': 0, '9403280156': 0, '9403280157': 0, '9403280159': 0, '940328016': 0, '9403280164': 0, '9403280165': 0, '9403280167': 0, '940328017': 0, '940328018': 0, '9403280212': 0, '9403280213': 0, '9403280217': 0, '9403280218': 0, '9403280219': 0, '940328022': 0, '9403280227': 0, '9403280229': 0, '9403280234': 0, '9403280235': 0, '9403280236': 0, '9403280238': 0, '9403280241': 0, '9403280243': 0, '9403280245': 0, '9403280246': 0, '9403280247': 0, '9403280249': 0, '9403280250': 0, '9403280251': 0, '9403280254': 0, '9403280255': 0, '9403280256': 0, '9403280259': 0, '9403280260': 0, '9403280262': 0, '9403280265': 0, '9403280266': 0, '9403280271': 1, '9403280272': 0, '9403280273': 0, '9403280277': 0, '9403280279': 0, '9877360111': 0, '9877360113': 0, '9877360114': 0, '9877360115': 0, '9877360116': 0, '9877360117': 0, '9877360120': 1, '9877360121': 0, '9877360124': 0, '9877360125': 0, '9877360126': 0, '9877360127': 0, '9877360128': 0, '9877360130': 0, '9877360131': 0, '9877360132': 0, '9877360133': 1, '9877360134': 0, '9877360135': 0, '9877360138': 0, '987736014': 0, '9877360140': 0, '9877360141': 0, '9877360143': 0, '9877360147': 0, '9877360149': 0, '987736015': 0, '9877360151': 0, '9877360152': 0, '9877360154': 0, '9877360156': 0, '9877360157': 1, '9877360158': 0, '9877360159': 0, '987736016': 0, '9877360163': 0, '9877360164': 0, '9877360165': 0, '9877360166': 0, '9877360168': 0, '9877360169': 1}\n"
     ]
    }
   ],
   "source": [
    "ENGAGE_WILD_DATASET, BIN_CLASSIFICATION, N_CLASSES, DATASET_NAME, BASE_DATASET_DIR, ext = define_dataset(False, True)\n",
    "video2label, labels_list = get_video2label()\n",
    "print(labels_list)\n",
    "print(video2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2541821e-e6ec-400f-954c-f01eeb373001",
   "metadata": {},
   "source": [
    "### Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "edff7cbe-da8d-4a85-a469-82d59bf8867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.std\n",
    "stat_name = \"std\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c864c9ce-7841-4dfe-8905-1c604c5978f3",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "6f8fa8b1-be1b-403a-8b7d-fb91113e6052",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ba7a8a78-8b27-44c6-91a8-3179d9feff9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d67b23ce-9a74-45ab-988e-9e1d7ac077e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "test:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n",
      "val:\n",
      "0 1537/1720: 89.36046511627907%\n",
      "1 183/1720: 10.63953488372093%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9df74c-95bb-4f52-aee9-c6070241db66",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "46f1fad7-e908-436d-834c-465f7ba9cde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e01f7066-7ddc-4d30-a777-e8d939dc81e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ba540def-94f3-4282-8fa7-2b801357662b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "628ebe73-b2bb-40ff-a607-6919212d1f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d98f4f3f-ffa9-4c47-971b-28c0548918a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 68ms/step - loss: 0.2087 - acc: 0.9409 - auc: 0.5783 - binary_accuracy: 0.9409 - recall: 0.0040 - precision: 0.0128 - val_loss: 0.3481 - val_acc: 0.8936 - val_auc: 0.6314 - val_binary_accuracy: 0.8936 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1639 - acc: 0.9548 - auc: 0.7567 - binary_accuracy: 0.9548 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.3484 - val_acc: 0.8936 - val_auc: 0.6606 - val_binary_accuracy: 0.8936 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1580 - acc: 0.9548 - auc: 0.7838 - binary_accuracy: 0.9548 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.3312 - val_acc: 0.8936 - val_auc: 0.6682 - val_binary_accuracy: 0.8936 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1531 - acc: 0.9548 - auc: 0.8004 - binary_accuracy: 0.9548 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.3556 - val_acc: 0.8936 - val_auc: 0.6688 - val_binary_accuracy: 0.8936 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1492 - acc: 0.9548 - auc: 0.8187 - binary_accuracy: 0.9548 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.3323 - val_acc: 0.8936 - val_auc: 0.6810 - val_binary_accuracy: 0.8936 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1477 - acc: 0.9546 - auc: 0.8216 - binary_accuracy: 0.9546 - recall: 0.0081 - precision: 0.4000 - val_loss: 0.3669 - val_acc: 0.8936 - val_auc: 0.6759 - val_binary_accuracy: 0.8936 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1454 - acc: 0.9553 - auc: 0.8315 - binary_accuracy: 0.9553 - recall: 0.0161 - precision: 0.8000 - val_loss: 0.3538 - val_acc: 0.8930 - val_auc: 0.6769 - val_binary_accuracy: 0.8930 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1504 - acc: 0.9542 - auc: 0.8161 - binary_accuracy: 0.9542 - recall: 0.0282 - precision: 0.4118 - val_loss: 0.3672 - val_acc: 0.8936 - val_auc: 0.6738 - val_binary_accuracy: 0.8936 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1397 - acc: 0.9549 - auc: 0.8524 - binary_accuracy: 0.9549 - recall: 0.0040 - precision: 1.0000 - val_loss: 0.3464 - val_acc: 0.8936 - val_auc: 0.6791 - val_binary_accuracy: 0.8936 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1388 - acc: 0.9551 - auc: 0.8534 - binary_accuracy: 0.9551 - recall: 0.0121 - precision: 0.7500 - val_loss: 0.3717 - val_acc: 0.8936 - val_auc: 0.6674 - val_binary_accuracy: 0.8936 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.1362 - acc: 0.9548 - auc: 0.8610 - binary_accuracy: 0.9548 - recall: 0.0081 - precision: 0.5000 - val_loss: 0.3797 - val_acc: 0.8936 - val_auc: 0.6686 - val_binary_accuracy: 0.8936 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.1359 - acc: 0.9553 - auc: 0.8643 - binary_accuracy: 0.9553 - recall: 0.0161 - precision: 0.8000 - val_loss: 0.3580 - val_acc: 0.8936 - val_auc: 0.6709 - val_binary_accuracy: 0.8936 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.1341 - acc: 0.9557 - auc: 0.8701 - binary_accuracy: 0.9557 - recall: 0.0323 - precision: 0.7273 - val_loss: 0.3704 - val_acc: 0.8930 - val_auc: 0.6742 - val_binary_accuracy: 0.8930 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.1320 - acc: 0.9548 - auc: 0.8787 - binary_accuracy: 0.9548 - recall: 0.0242 - precision: 0.5000 - val_loss: 0.3595 - val_acc: 0.8936 - val_auc: 0.6675 - val_binary_accuracy: 0.8936 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1307 - acc: 0.9564 - auc: 0.8778 - binary_accuracy: 0.9564 - recall: 0.0444 - precision: 0.8462 - val_loss: 0.3558 - val_acc: 0.8930 - val_auc: 0.6742 - val_binary_accuracy: 0.8930 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1267 - acc: 0.9559 - auc: 0.8925 - binary_accuracy: 0.9559 - recall: 0.0484 - precision: 0.6667 - val_loss: 0.3612 - val_acc: 0.8936 - val_auc: 0.6698 - val_binary_accuracy: 0.8936 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1272 - acc: 0.9560 - auc: 0.8901 - binary_accuracy: 0.9560 - recall: 0.0444 - precision: 0.7333 - val_loss: 0.3808 - val_acc: 0.8930 - val_auc: 0.6610 - val_binary_accuracy: 0.8930 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1238 - acc: 0.9575 - auc: 0.8952 - binary_accuracy: 0.9575 - recall: 0.0806 - precision: 0.8000 - val_loss: 0.3763 - val_acc: 0.8930 - val_auc: 0.6572 - val_binary_accuracy: 0.8930 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1217 - acc: 0.9560 - auc: 0.9041 - binary_accuracy: 0.9560 - recall: 0.0605 - precision: 0.6522 - val_loss: 0.3517 - val_acc: 0.8907 - val_auc: 0.6600 - val_binary_accuracy: 0.8907 - val_recall: 0.0273 - val_precision: 0.3333\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.1240 - acc: 0.9586 - auc: 0.8930 - binary_accuracy: 0.9586 - recall: 0.1129 - precision: 0.8000 - val_loss: 0.3959 - val_acc: 0.8930 - val_auc: 0.6460 - val_binary_accuracy: 0.8930 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "0.33123600482940674\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8892bcd3-66f0-4fca-884f-bc7594dacbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e55f1bcd-dfa3-4c83-a4be-8c663a0a06dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional Accuracy:  0.8961114335461404 MSE:  0.10388856645385955 UAR:  0.6497737556561086 Recall:  0.3764705882352941 Precision:  0.20253164556962025 F1:  0.2633744855967078\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional Accuracy:  0.938479396401625 MSE:  0.061520603598374926 UAR:  0.5605149752208576 Recall:  0.1411764705882353 Precision:  0.26666666666666666 F1:  0.1846153846153846\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional Accuracy:  0.9454439930354034 MSE:  0.054556006964596636 UAR:  0.5251382604323781 Recall:  0.058823529411764705 Precision:  0.2631578947368421 F1:  0.09615384615384615\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional Accuracy:  0.9500870574579222 MSE:  0.04991294254207777 UAR:  0.5164260576025282 Recall:  0.03529411764705882 Precision:  0.42857142857142855 F1:  0.06521739130434782\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5058823529411764 Recall:  0.011764705882352941 Precision:  1.0 F1:  0.023255813953488372\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6497737556561086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "eb2c40a8-8ab7-4e44-a09f-f72d4a25a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "33dfe327-5d8c-432e-b4ef-62d479bacb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "bd2e5b90-1b18-489e-883e-56ca79521b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.8786999419616948 MSE:  0.12130005803830528 UAR:  0.6740788623141565 Recall:  0.4470588235294118 Precision:  0.19 F1:  0.26666666666666666\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.9338363319791062 MSE:  0.0661636680208938 UAR:  0.619421101774043 Recall:  0.27058823529411763 Precision:  0.30666666666666664 F1:  0.2875\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.9489262913522926 MSE:  0.05107370864770749 UAR:  0.5771636859872155 Recall:  0.16470588235294117 Precision:  0.45161290322580644 F1:  0.2413793103448276\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5173418085182792 Recall:  0.03529411764705882 Precision:  0.75 F1:  0.06741573033707865\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6740788623141565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4366fef2-77f3-45d4-bda9-a4d01716346e",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "32c83339-8eb2-454e-ab13-0963effd34a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "cb3e3d7d-41c9-4d01-96f9-20ce9170072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ad731708-9dd8-4587-bc1b-98e2dc417d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b2f5463b-fad4-4592-a086-6326e0870a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_6 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_6[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_6[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "fc8cb043-e313-4dd3-bb40-3d8349eed399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 127ms/step - loss: 0.3520 - acc: 0.9435 - auc: 0.5372 - binary_accuracy: 0.9435 - recall_1: 0.0121 - precision_1: 0.0441 - val_loss: 0.3655 - val_acc: 0.8936 - val_auc: 0.6054 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1676 - acc: 0.9544 - auc: 0.7332 - binary_accuracy: 0.9544 - recall_1: 0.0081 - precision_1: 0.3333 - val_loss: 0.4156 - val_acc: 0.8936 - val_auc: 0.6291 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1589 - acc: 0.9533 - auc: 0.7800 - binary_accuracy: 0.9533 - recall_1: 0.0081 - precision_1: 0.1667 - val_loss: 0.3692 - val_acc: 0.8907 - val_auc: 0.6405 - val_binary_accuracy: 0.8907 - val_recall_1: 0.0328 - val_precision_1: 0.3529\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1570 - acc: 0.9538 - auc: 0.7916 - binary_accuracy: 0.9538 - recall_1: 0.0282 - precision_1: 0.3684 - val_loss: 0.4193 - val_acc: 0.8930 - val_auc: 0.6368 - val_binary_accuracy: 0.8930 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1648 - acc: 0.9526 - auc: 0.7644 - binary_accuracy: 0.9526 - recall_1: 0.0403 - precision_1: 0.3125 - val_loss: 0.3956 - val_acc: 0.8936 - val_auc: 0.6295 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1544 - acc: 0.9557 - auc: 0.8021 - binary_accuracy: 0.9557 - recall_1: 0.0524 - precision_1: 0.6190 - val_loss: 0.3884 - val_acc: 0.8942 - val_auc: 0.6372 - val_binary_accuracy: 0.8942 - val_recall_1: 0.0164 - val_precision_1: 0.6000\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1498 - acc: 0.9564 - auc: 0.8126 - binary_accuracy: 0.9564 - recall_1: 0.0726 - precision_1: 0.6667 - val_loss: 0.4350 - val_acc: 0.8936 - val_auc: 0.6258 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1505 - acc: 0.9562 - auc: 0.7941 - binary_accuracy: 0.9562 - recall_1: 0.0927 - precision_1: 0.6053 - val_loss: 0.4107 - val_acc: 0.8936 - val_auc: 0.6443 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1529 - acc: 0.9529 - auc: 0.8132 - binary_accuracy: 0.9529 - recall_1: 0.0565 - precision_1: 0.3684 - val_loss: 0.3560 - val_acc: 0.8901 - val_auc: 0.6600 - val_binary_accuracy: 0.8901 - val_recall_1: 0.0328 - val_precision_1: 0.3333\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1611 - acc: 0.9544 - auc: 0.7951 - binary_accuracy: 0.9544 - recall_1: 0.0766 - precision_1: 0.4750 - val_loss: 0.3404 - val_acc: 0.8919 - val_auc: 0.6709 - val_binary_accuracy: 0.8919 - val_recall_1: 0.0164 - val_precision_1: 0.3333\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1480 - acc: 0.9551 - auc: 0.8080 - binary_accuracy: 0.9551 - recall_1: 0.0645 - precision_1: 0.5333 - val_loss: 0.3748 - val_acc: 0.8791 - val_auc: 0.6659 - val_binary_accuracy: 0.8791 - val_recall_1: 0.0546 - val_precision_1: 0.2222\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1393 - acc: 0.9577 - auc: 0.8477 - binary_accuracy: 0.9577 - recall_1: 0.1169 - precision_1: 0.6905 - val_loss: 0.4060 - val_acc: 0.8843 - val_auc: 0.6437 - val_binary_accuracy: 0.8843 - val_recall_1: 0.0328 - val_precision_1: 0.2143\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1391 - acc: 0.9584 - auc: 0.8543 - binary_accuracy: 0.9584 - recall_1: 0.1694 - precision_1: 0.6562 - val_loss: 0.4013 - val_acc: 0.8913 - val_auc: 0.6270 - val_binary_accuracy: 0.8913 - val_recall_1: 0.0055 - val_precision_1: 0.1667\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1430 - acc: 0.9564 - auc: 0.8307 - binary_accuracy: 0.9564 - recall_1: 0.1250 - precision_1: 0.5849 - val_loss: 0.4422 - val_acc: 0.8936 - val_auc: 0.6349 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0164 - val_precision_1: 0.5000\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1403 - acc: 0.9593 - auc: 0.8408 - binary_accuracy: 0.9593 - recall_1: 0.1532 - precision_1: 0.7451 - val_loss: 0.3936 - val_acc: 0.8860 - val_auc: 0.6520 - val_binary_accuracy: 0.8860 - val_recall_1: 0.0273 - val_precision_1: 0.2174\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1331 - acc: 0.9599 - auc: 0.8623 - binary_accuracy: 0.9599 - recall_1: 0.1815 - precision_1: 0.7258 - val_loss: 0.4326 - val_acc: 0.8890 - val_auc: 0.6155 - val_binary_accuracy: 0.8890 - val_recall_1: 0.0109 - val_precision_1: 0.1667\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1567 - acc: 0.9579 - auc: 0.8211 - binary_accuracy: 0.9579 - recall_1: 0.1855 - precision_1: 0.6133 - val_loss: 0.6409 - val_acc: 0.8901 - val_auc: 0.5315 - val_binary_accuracy: 0.8901 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1939 - acc: 0.9513 - auc: 0.7187 - binary_accuracy: 0.9513 - recall_1: 0.0927 - precision_1: 0.3538 - val_loss: 0.4528 - val_acc: 0.8924 - val_auc: 0.6278 - val_binary_accuracy: 0.8924 - val_recall_1: 0.0109 - val_precision_1: 0.3333\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1382 - acc: 0.9582 - auc: 0.8531 - binary_accuracy: 0.9582 - recall_1: 0.1532 - precision_1: 0.6667 - val_loss: 0.4255 - val_acc: 0.8831 - val_auc: 0.6076 - val_binary_accuracy: 0.8831 - val_recall_1: 0.0328 - val_precision_1: 0.2000\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1471 - acc: 0.9573 - auc: 0.8318 - binary_accuracy: 0.9573 - recall_1: 0.1653 - precision_1: 0.6029 - val_loss: 0.3628 - val_acc: 0.8831 - val_auc: 0.6370 - val_binary_accuracy: 0.8831 - val_recall_1: 0.0273 - val_precision_1: 0.1786\n",
      "0.340364933013916\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f4a97098-009d-4bd1-95a9-f717c54407a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f2948234-3243-41aa-aa2d-abf82f6b1368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.8415554265815438 MSE:  0.1584445734184562 UAR:  0.6043489190548015 Recall:  0.3411764705882353 Precision:  0.11788617886178862 F1:  0.17522658610271902\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.930354033662217 MSE:  0.06964596633778293 UAR:  0.5450872656755009 Recall:  0.11764705882352941 Precision:  0.18181818181818182 F1:  0.14285714285714285\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9437028438769588 MSE:  0.05629715612304121 UAR:  0.5409538174244057 Recall:  0.09411764705882353 Precision:  0.2857142857142857 F1:  0.1415929203539823\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.947185142193848 MSE:  0.05281485780615206 UAR:  0.526054011348129 Recall:  0.058823529411764705 Precision:  0.3125 F1:  0.09900990099009901\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5281907634848811 Recall:  0.058823529411764705 Precision:  0.5555555555555556 F1:  0.10638297872340426\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5229189111542053 Recall:  0.047058823529411764 Precision:  0.6666666666666666 F1:  0.08791208791208792\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9529889727219966 MSE:  0.047011027278003485 UAR:  0.5235294117647059 Recall:  0.047058823529411764 Precision:  1.0 F1:  0.0898876404494382\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5176470588235295 Recall:  0.03529411764705882 Precision:  1.0 F1:  0.06818181818181818\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5117647058823529 Recall:  0.023529411764705882 Precision:  1.0 F1:  0.04597701149425288\n",
      "0.1 0.6043489190548015\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "33cb7345-dcf8-423c-8dcb-d6c977457dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "63a24600-cf63-4a68-8a53-d15c7f2d1de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "cb2dbc3b-e8b8-4033-a12d-3a128606b6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.8340104468949506 MSE:  0.16598955310504934 UAR:  0.6282661782661783 Recall:  0.4 Precision:  0.12639405204460966 F1:  0.192090395480226\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9297736506094022 MSE:  0.0702263493905978 UAR:  0.5949759390935861 Recall:  0.2235294117647059 Precision:  0.25675675675675674 F1:  0.2389937106918239\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9477655252466628 MSE:  0.0522344747533372 UAR:  0.5653989801048624 Recall:  0.1411764705882353 Precision:  0.41379310344827586 F1:  0.21052631578947367\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5566867772750126 Recall:  0.11764705882352941 Precision:  0.5882352941176471 F1:  0.19607843137254902\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9529889727219966 MSE:  0.047011027278003485 UAR:  0.5402607196724843 Recall:  0.08235294117647059 Precision:  0.7 F1:  0.14736842105263157\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5288012640953818 Recall:  0.058823529411764705 Precision:  0.7142857142857143 F1:  0.10869565217391305\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9500870574579222 MSE:  0.04991294254207777 UAR:  0.5052718523306758 Recall:  0.011764705882352941 Precision:  0.3333333333333333 F1:  0.022727272727272728\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5058823529411764 Recall:  0.011764705882352941 Precision:  1.0 F1:  0.023255813953488372\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6282661782661783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e8a9bb-3862-41cf-8874-b1d836f1ed46",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "98bc46ed-ccd4-4e43-bbe8-ff63bc3ca5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "03f736dc-4ff5-4a26-acb5-4c250e6c3c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "8e05c0f4-9c24-43a7-bca6-3931ff63e61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "val:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "ce4cd71e-18dc-4102-84ab-de8e4e5b9d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482,) (5482,)\n",
      "(1723,) (1723,)\n",
      "(7205,) (7205,)\n",
      "[0 1] [6872  333]\n",
      "7205\n",
      "5475\n",
      "1730\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9d6a000a-98eb-4664-962f-0d840cd146c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5222/5475: 95.37899543378995%\n",
      "1 253/5475: 4.621004566210046%\n",
      "val:\n",
      "0 1650/1730: 95.3757225433526%\n",
      "1 80/1730: 4.624277456647399%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1246107a-1a3b-48b1-b43a-1182e7388351",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ae4302db-ad1a-44bb-ab32-91147ea5ba3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5c1ade1e-b384-45ef-b9ba-a814f37845ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "1613455f-09ae-455c-89a2-31c678953ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 2560) (5475,)\n",
      "(1730, 128, 2560) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b9675b01-331c-4fac-a5d3-fcbbab3f83b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "46f45f4a-2ea6-447e-a088-a9c84f47ad23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 4s 66ms/step - loss: 0.2223 - acc: 0.9315 - auc: 0.5639 - binary_accuracy: 0.9315 - recall_2: 0.0158 - precision_2: 0.0308 - val_loss: 0.1833 - val_acc: 0.9532 - val_auc: 0.6921 - val_binary_accuracy: 0.9532 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.1685 - acc: 0.9543 - auc: 0.7300 - binary_accuracy: 0.9543 - recall_2: 0.0119 - precision_2: 1.0000 - val_loss: 0.1702 - val_acc: 0.9532 - val_auc: 0.7677 - val_binary_accuracy: 0.9532 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1614 - acc: 0.9543 - auc: 0.7606 - binary_accuracy: 0.9543 - recall_2: 0.0158 - precision_2: 0.8000 - val_loss: 0.1628 - val_acc: 0.9532 - val_auc: 0.7720 - val_binary_accuracy: 0.9532 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1582 - acc: 0.9543 - auc: 0.7729 - binary_accuracy: 0.9543 - recall_2: 0.0158 - precision_2: 0.8000 - val_loss: 0.1614 - val_acc: 0.9532 - val_auc: 0.7854 - val_binary_accuracy: 0.9532 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1518 - acc: 0.9543 - auc: 0.8100 - binary_accuracy: 0.9543 - recall_2: 0.0198 - precision_2: 0.7143 - val_loss: 0.1582 - val_acc: 0.9520 - val_auc: 0.7937 - val_binary_accuracy: 0.9520 - val_recall_2: 0.0125 - val_precision_2: 0.2000\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1495 - acc: 0.9547 - auc: 0.8202 - binary_accuracy: 0.9547 - recall_2: 0.0277 - precision_2: 0.7778 - val_loss: 0.1579 - val_acc: 0.9538 - val_auc: 0.7911 - val_binary_accuracy: 0.9538 - val_recall_2: 0.0125 - val_precision_2: 0.5000\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1468 - acc: 0.9545 - auc: 0.8287 - binary_accuracy: 0.9545 - recall_2: 0.0395 - precision_2: 0.6250 - val_loss: 0.1598 - val_acc: 0.9532 - val_auc: 0.7904 - val_binary_accuracy: 0.9532 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1439 - acc: 0.9549 - auc: 0.8409 - binary_accuracy: 0.9549 - recall_2: 0.0395 - precision_2: 0.7143 - val_loss: 0.1574 - val_acc: 0.9532 - val_auc: 0.7931 - val_binary_accuracy: 0.9532 - val_recall_2: 0.0125 - val_precision_2: 0.3333\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1429 - acc: 0.9547 - auc: 0.8404 - binary_accuracy: 0.9547 - recall_2: 0.0514 - precision_2: 0.6190 - val_loss: 0.1635 - val_acc: 0.9532 - val_auc: 0.7861 - val_binary_accuracy: 0.9532 - val_recall_2: 0.0125 - val_precision_2: 0.3333\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1415 - acc: 0.9536 - auc: 0.8505 - binary_accuracy: 0.9536 - recall_2: 0.0395 - precision_2: 0.4762 - val_loss: 0.1572 - val_acc: 0.9532 - val_auc: 0.7919 - val_binary_accuracy: 0.9532 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1378 - acc: 0.9558 - auc: 0.8638 - binary_accuracy: 0.9558 - recall_2: 0.0474 - precision_2: 0.9231 - val_loss: 0.1593 - val_acc: 0.9538 - val_auc: 0.7831 - val_binary_accuracy: 0.9538 - val_recall_2: 0.0250 - val_precision_2: 0.5000\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1349 - acc: 0.9560 - auc: 0.8689 - binary_accuracy: 0.9560 - recall_2: 0.0949 - precision_2: 0.6667 - val_loss: 0.1610 - val_acc: 0.9532 - val_auc: 0.7826 - val_binary_accuracy: 0.9532 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1315 - acc: 0.9576 - auc: 0.8774 - binary_accuracy: 0.9576 - recall_2: 0.1107 - precision_2: 0.8000 - val_loss: 0.1621 - val_acc: 0.9532 - val_auc: 0.7698 - val_binary_accuracy: 0.9532 - val_recall_2: 0.0250 - val_precision_2: 0.4000\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.1362 - acc: 0.9578 - auc: 0.8631 - binary_accuracy: 0.9578 - recall_2: 0.1225 - precision_2: 0.7750 - val_loss: 0.1650 - val_acc: 0.9514 - val_auc: 0.7638 - val_binary_accuracy: 0.9514 - val_recall_2: 0.0250 - val_precision_2: 0.2500\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1338 - acc: 0.9571 - auc: 0.8721 - binary_accuracy: 0.9571 - recall_2: 0.1186 - precision_2: 0.7143 - val_loss: 0.1600 - val_acc: 0.9526 - val_auc: 0.7821 - val_binary_accuracy: 0.9526 - val_recall_2: 0.0375 - val_precision_2: 0.3750\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.1247 - acc: 0.9593 - auc: 0.8970 - binary_accuracy: 0.9593 - recall_2: 0.1502 - precision_2: 0.8261 - val_loss: 0.1680 - val_acc: 0.9520 - val_auc: 0.7697 - val_binary_accuracy: 0.9520 - val_recall_2: 0.0125 - val_precision_2: 0.2000\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1252 - acc: 0.9582 - auc: 0.8928 - binary_accuracy: 0.9582 - recall_2: 0.1344 - precision_2: 0.7727 - val_loss: 0.1678 - val_acc: 0.9509 - val_auc: 0.7762 - val_binary_accuracy: 0.9509 - val_recall_2: 0.1125 - val_precision_2: 0.3913\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1210 - acc: 0.9602 - auc: 0.9026 - binary_accuracy: 0.9602 - recall_2: 0.1897 - precision_2: 0.7869 - val_loss: 0.1663 - val_acc: 0.9520 - val_auc: 0.7785 - val_binary_accuracy: 0.9520 - val_recall_2: 0.0625 - val_precision_2: 0.3846\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1257 - acc: 0.9604 - auc: 0.8900 - binary_accuracy: 0.9604 - recall_2: 0.1897 - precision_2: 0.8000 - val_loss: 0.1793 - val_acc: 0.9532 - val_auc: 0.7569 - val_binary_accuracy: 0.9532 - val_recall_2: 0.0125 - val_precision_2: 0.3333\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1199 - acc: 0.9582 - auc: 0.9105 - binary_accuracy: 0.9582 - recall_2: 0.1581 - precision_2: 0.7143 - val_loss: 0.1727 - val_acc: 0.9509 - val_auc: 0.7526 - val_binary_accuracy: 0.9509 - val_recall_2: 0.0375 - val_precision_2: 0.2727\n",
      "0.1572372168302536\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e3f8ad29-ba7a-4529-b3c9-fd964a9faebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "0f13c5df-c620-47c3-ad61-dd4fc5aebc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced Accuracy:  0.9086705202312139 MSE:  0.09132947976878612 UAR:  0.7023484848484849 Recall:  0.475 Precision:  0.24675324675324675 F1:  0.3247863247863248\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced Accuracy:  0.9421965317919075 MSE:  0.057803468208092484 UAR:  0.6128787878787878 Recall:  0.25 Precision:  0.3333333333333333 F1:  0.28571428571428575\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced Accuracy:  0.9508670520231214 MSE:  0.049132947976878616 UAR:  0.5698484848484848 Recall:  0.15 Precision:  0.41379310344827586 F1:  0.22018348623853212\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced Accuracy:  0.9497109826589596 MSE:  0.050289017341040465 UAR:  0.5335606060606061 Recall:  0.075 Precision:  0.3157894736842105 F1:  0.1212121212121212\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced Accuracy:  0.9508670520231214 MSE:  0.049132947976878616 UAR:  0.5163257575757576 Recall:  0.0375 Precision:  0.2727272727272727 F1:  0.06593406593406594\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5115909090909091 Recall:  0.025 Precision:  0.4 F1:  0.04705882352941177\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.7023484848484849\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "788c2071-97d6-4c38-b8c4-94bd359d44cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "99a860e3-3a9b-4460-93ab-3499ea74b032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "004ce109-65ab-4eb0-a642-59838a03084e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.8971098265895954 MSE:  0.10289017341040463 UAR:  0.7081818181818182 Recall:  0.5 Precision:  0.2247191011235955 F1:  0.31007751937984496\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.9416184971098266 MSE:  0.05838150289017341 UAR:  0.624469696969697 Recall:  0.275 Precision:  0.3384615384615385 F1:  0.30344827586206896\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.9502890173410404 MSE:  0.04971098265895954 UAR:  0.5873863636363637 Recall:  0.1875 Precision:  0.4166666666666667 F1:  0.2586206896551724\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.9514450867052023 MSE:  0.048554913294797684 UAR:  0.5344696969696969 Recall:  0.075 Precision:  0.375 F1:  0.12499999999999999\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.7081818181818182\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8353e0d-9e9e-4dbb-b5e9-cf87382fb327",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "20b9c376-486e-427e-9660-7dd838cb42d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a25b6aec-9448-4d0d-9fd9-39bf2e6711e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ee797bfc-b3ad-4e9b-bc12-aa269ad4d83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 2560) (5475,)\n",
      "(1730, 128, 2560) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b171ce19-4ced-4166-bc16-c6d01a658e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_7 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_7[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_7[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "1d824048-840c-468f-8164-7a222209ce2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 125ms/step - loss: 0.3764 - acc: 0.9412 - auc: 0.5374 - binary_accuracy: 0.9412 - recall_3: 0.0277 - precision_3: 0.0843 - val_loss: 0.1875 - val_acc: 0.9526 - val_auc: 0.6787 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0125 - val_precision_3: 0.2500\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1737 - acc: 0.9540 - auc: 0.7014 - binary_accuracy: 0.9540 - recall_3: 0.0514 - precision_3: 0.5200 - val_loss: 0.1701 - val_acc: 0.9526 - val_auc: 0.7431 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0250 - val_precision_3: 0.3333\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1627 - acc: 0.9536 - auc: 0.7562 - binary_accuracy: 0.9536 - recall_3: 0.0435 - precision_3: 0.4783 - val_loss: 0.1690 - val_acc: 0.9526 - val_auc: 0.7421 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1558 - acc: 0.9563 - auc: 0.7868 - binary_accuracy: 0.9563 - recall_3: 0.0751 - precision_3: 0.7917 - val_loss: 0.1788 - val_acc: 0.9532 - val_auc: 0.7731 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1543 - acc: 0.9558 - auc: 0.7960 - binary_accuracy: 0.9558 - recall_3: 0.0870 - precision_3: 0.6667 - val_loss: 0.1673 - val_acc: 0.9468 - val_auc: 0.7855 - val_binary_accuracy: 0.9468 - val_recall_3: 0.0375 - val_precision_3: 0.1667\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1532 - acc: 0.9542 - auc: 0.8100 - binary_accuracy: 0.9542 - recall_3: 0.0672 - precision_3: 0.5312 - val_loss: 0.1618 - val_acc: 0.9509 - val_auc: 0.7852 - val_binary_accuracy: 0.9509 - val_recall_3: 0.0500 - val_precision_3: 0.3077\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1613 - acc: 0.9542 - auc: 0.7767 - binary_accuracy: 0.9542 - recall_3: 0.0830 - precision_3: 0.5250 - val_loss: 0.1652 - val_acc: 0.9538 - val_auc: 0.7618 - val_binary_accuracy: 0.9538 - val_recall_3: 0.0125 - val_precision_3: 0.5000\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1583 - acc: 0.9538 - auc: 0.7944 - binary_accuracy: 0.9538 - recall_3: 0.0711 - precision_3: 0.5000 - val_loss: 0.1699 - val_acc: 0.9538 - val_auc: 0.7600 - val_binary_accuracy: 0.9538 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1508 - acc: 0.9556 - auc: 0.8224 - binary_accuracy: 0.9556 - recall_3: 0.0909 - precision_3: 0.6389 - val_loss: 0.1673 - val_acc: 0.9468 - val_auc: 0.7807 - val_binary_accuracy: 0.9468 - val_recall_3: 0.0375 - val_precision_3: 0.1667\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1453 - acc: 0.9567 - auc: 0.8235 - binary_accuracy: 0.9567 - recall_3: 0.1186 - precision_3: 0.6818 - val_loss: 0.1636 - val_acc: 0.9462 - val_auc: 0.7945 - val_binary_accuracy: 0.9462 - val_recall_3: 0.0750 - val_precision_3: 0.2400\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1429 - acc: 0.9558 - auc: 0.8417 - binary_accuracy: 0.9558 - recall_3: 0.1502 - precision_3: 0.5846 - val_loss: 0.1630 - val_acc: 0.9526 - val_auc: 0.7949 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0750 - val_precision_3: 0.4286\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1419 - acc: 0.9563 - auc: 0.8401 - binary_accuracy: 0.9563 - recall_3: 0.1225 - precision_3: 0.6458 - val_loss: 0.1636 - val_acc: 0.9480 - val_auc: 0.7922 - val_binary_accuracy: 0.9480 - val_recall_3: 0.0750 - val_precision_3: 0.2727\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1377 - acc: 0.9574 - auc: 0.8583 - binary_accuracy: 0.9574 - recall_3: 0.1502 - precision_3: 0.6786 - val_loss: 0.1665 - val_acc: 0.9532 - val_auc: 0.7744 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0625 - val_precision_3: 0.4545\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1382 - acc: 0.9569 - auc: 0.8516 - binary_accuracy: 0.9569 - recall_3: 0.1423 - precision_3: 0.6545 - val_loss: 0.1775 - val_acc: 0.9445 - val_auc: 0.7679 - val_binary_accuracy: 0.9445 - val_recall_3: 0.1625 - val_precision_3: 0.3095\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1597 - acc: 0.9536 - auc: 0.7827 - binary_accuracy: 0.9536 - recall_3: 0.1265 - precision_3: 0.4923 - val_loss: 0.1692 - val_acc: 0.9543 - val_auc: 0.7693 - val_binary_accuracy: 0.9543 - val_recall_3: 0.0625 - val_precision_3: 0.5556\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1370 - acc: 0.9582 - auc: 0.8615 - binary_accuracy: 0.9582 - recall_3: 0.1581 - precision_3: 0.7143 - val_loss: 0.1664 - val_acc: 0.9503 - val_auc: 0.7886 - val_binary_accuracy: 0.9503 - val_recall_3: 0.1250 - val_precision_3: 0.3846\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1338 - acc: 0.9591 - auc: 0.8699 - binary_accuracy: 0.9591 - recall_3: 0.1897 - precision_3: 0.7164 - val_loss: 0.1720 - val_acc: 0.9538 - val_auc: 0.7680 - val_binary_accuracy: 0.9538 - val_recall_3: 0.0625 - val_precision_3: 0.5000\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1501 - acc: 0.9553 - auc: 0.8296 - binary_accuracy: 0.9553 - recall_3: 0.1462 - precision_3: 0.5606 - val_loss: 0.1714 - val_acc: 0.9532 - val_auc: 0.7667 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1465 - acc: 0.9556 - auc: 0.8340 - binary_accuracy: 0.9556 - recall_3: 0.0949 - precision_3: 0.6316 - val_loss: 0.1637 - val_acc: 0.9468 - val_auc: 0.7976 - val_binary_accuracy: 0.9468 - val_recall_3: 0.0500 - val_precision_3: 0.2000\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1520 - acc: 0.9527 - auc: 0.8244 - binary_accuracy: 0.9527 - recall_3: 0.1542 - precision_3: 0.4643 - val_loss: 0.1976 - val_acc: 0.9532 - val_auc: 0.6923 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0125 - val_precision_3: 0.3333\n",
      "0.16184794902801514\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "51499141-4437-4375-bf6a-ce67b52b74d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "0b725b94-d65b-4c2d-82a7-fad243039945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9445086705202312 MSE:  0.055491329479768786 UAR:  0.5903030303030303 Recall:  0.2 Precision:  0.3333333333333333 F1:  0.25\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9520231213872833 MSE:  0.04797687861271676 UAR:  0.5526136363636364 Recall:  0.1125 Precision:  0.42857142857142855 F1:  0.1782178217821782\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5297348484848485 Recall:  0.0625 Precision:  0.5 F1:  0.1111111111111111\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.954335260115607 MSE:  0.04566473988439306 UAR:  0.5181439393939394 Recall:  0.0375 Precision:  0.6 F1:  0.07058823529411765\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.4993939393939394 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.5903030303030303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "d3b508f9-12df-4445-ba6a-9729f52adcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "0de2a6cc-d0be-405b-8e5b-276dc40aa0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "75c06925-5ff8-4be2-a613-64661ddca460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.8549132947976879 MSE:  0.14508670520231215 UAR:  0.6979545454545455 Recall:  0.525 Precision:  0.16470588235294117 F1:  0.2507462686567164\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9260115606936417 MSE:  0.07398843930635839 UAR:  0.6460227272727272 Recall:  0.3375 Precision:  0.2647058823529412 F1:  0.29670329670329665\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.946242774566474 MSE:  0.05375722543352601 UAR:  0.5852651515151515 Recall:  0.1875 Precision:  0.3488372093023256 F1:  0.2439024390243903\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.954335260115607 MSE:  0.04566473988439306 UAR:  0.5716666666666667 Recall:  0.15 Precision:  0.5217391304347826 F1:  0.23300970873786406\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.5350757575757575 Recall:  0.075 Precision:  0.42857142857142855 F1:  0.1276595744680851\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5118939393939393 Recall:  0.025 Precision:  0.5 F1:  0.047619047619047616\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6979545454545455\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7866b29-8f21-439f-8fa8-d8e7edfaabfe",
   "metadata": {},
   "source": [
    "### Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "2983785c-5682-40d0-a52a-066758538c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.max\n",
    "stat_name = \"max\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b55b62b-e7e6-4d86-b026-9d1e74c2e574",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "65834db3-359e-4839-aaf8-bf3a7c82b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "531060b2-3cbd-45cc-9a1f-ea9a4bf931dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ec2d41af-5bac-44d7-be33-47ff2f0edd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "test:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n",
      "val:\n",
      "0 1537/1720: 89.36046511627907%\n",
      "1 183/1720: 10.63953488372093%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3d5d3c-7521-44a0-9d98-9003bb605e71",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "79886878-0d1c-4e17-baaf-0b8061aa6e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a1b7bff3-a102-4a55-87fd-03cf97f1ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "1ebb3ff7-4c99-433f-a417-7d3de777a153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "fac9c1d6-ca15-4655-8945-665ba0421433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "3fae2548-9707-4f4b-b382-e9455e4183d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 4s 67ms/step - loss: 0.1984 - acc: 0.9528 - auc: 0.6336 - binary_accuracy: 0.9528 - recall_4: 0.0081 - precision_4: 0.1333 - val_loss: 0.3389 - val_acc: 0.8936 - val_auc: 0.6639 - val_binary_accuracy: 0.8936 - val_recall_4: 0.0000e+00 - val_precision_4: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.1617 - acc: 0.9548 - auc: 0.7635 - binary_accuracy: 0.9548 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00 - val_loss: 0.3587 - val_acc: 0.8936 - val_auc: 0.6692 - val_binary_accuracy: 0.8936 - val_recall_4: 0.0000e+00 - val_precision_4: 0.0000e+00\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1549 - acc: 0.9548 - auc: 0.8004 - binary_accuracy: 0.9548 - recall_4: 0.0040 - precision_4: 0.5000 - val_loss: 0.3423 - val_acc: 0.8936 - val_auc: 0.6735 - val_binary_accuracy: 0.8936 - val_recall_4: 0.0000e+00 - val_precision_4: 0.0000e+00\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1495 - acc: 0.9548 - auc: 0.8180 - binary_accuracy: 0.9548 - recall_4: 0.0040 - precision_4: 0.5000 - val_loss: 0.3749 - val_acc: 0.8936 - val_auc: 0.6729 - val_binary_accuracy: 0.8936 - val_recall_4: 0.0000e+00 - val_precision_4: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1478 - acc: 0.9549 - auc: 0.8227 - binary_accuracy: 0.9549 - recall_4: 0.0202 - precision_4: 0.5556 - val_loss: 0.3421 - val_acc: 0.8936 - val_auc: 0.6738 - val_binary_accuracy: 0.8936 - val_recall_4: 0.0000e+00 - val_precision_4: 0.0000e+00\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1460 - acc: 0.9540 - auc: 0.8302 - binary_accuracy: 0.9540 - recall_4: 0.0040 - precision_4: 0.1667 - val_loss: 0.3367 - val_acc: 0.8936 - val_auc: 0.6659 - val_binary_accuracy: 0.8936 - val_recall_4: 0.0000e+00 - val_precision_4: 0.0000e+00\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1426 - acc: 0.9544 - auc: 0.8442 - binary_accuracy: 0.9544 - recall_4: 0.0161 - precision_4: 0.4000 - val_loss: 0.3514 - val_acc: 0.8936 - val_auc: 0.6665 - val_binary_accuracy: 0.8936 - val_recall_4: 0.0000e+00 - val_precision_4: 0.0000e+00\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1392 - acc: 0.9548 - auc: 0.8576 - binary_accuracy: 0.9548 - recall_4: 0.0121 - precision_4: 0.5000 - val_loss: 0.3776 - val_acc: 0.8936 - val_auc: 0.6507 - val_binary_accuracy: 0.8936 - val_recall_4: 0.0000e+00 - val_precision_4: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1360 - acc: 0.9549 - auc: 0.8664 - binary_accuracy: 0.9549 - recall_4: 0.0323 - precision_4: 0.5333 - val_loss: 0.3587 - val_acc: 0.8936 - val_auc: 0.6512 - val_binary_accuracy: 0.8936 - val_recall_4: 0.0000e+00 - val_precision_4: 0.0000e+00\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1312 - acc: 0.9560 - auc: 0.8833 - binary_accuracy: 0.9560 - recall_4: 0.0524 - precision_4: 0.6842 - val_loss: 0.3703 - val_acc: 0.8930 - val_auc: 0.6625 - val_binary_accuracy: 0.8930 - val_recall_4: 0.0000e+00 - val_precision_4: 0.0000e+00\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1319 - acc: 0.9570 - auc: 0.8759 - binary_accuracy: 0.9570 - recall_4: 0.0645 - precision_4: 0.8000 - val_loss: 0.4396 - val_acc: 0.8936 - val_auc: 0.6259 - val_binary_accuracy: 0.8936 - val_recall_4: 0.0000e+00 - val_precision_4: 0.0000e+00\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1303 - acc: 0.9564 - auc: 0.8795 - binary_accuracy: 0.9564 - recall_4: 0.0645 - precision_4: 0.6957 - val_loss: 0.3456 - val_acc: 0.8930 - val_auc: 0.6565 - val_binary_accuracy: 0.8930 - val_recall_4: 0.0000e+00 - val_precision_4: 0.0000e+00\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1264 - acc: 0.9575 - auc: 0.8956 - binary_accuracy: 0.9575 - recall_4: 0.0887 - precision_4: 0.7586 - val_loss: 0.3937 - val_acc: 0.8930 - val_auc: 0.6468 - val_binary_accuracy: 0.8930 - val_recall_4: 0.0055 - val_precision_4: 0.3333\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1238 - acc: 0.9599 - auc: 0.8944 - binary_accuracy: 0.9599 - recall_4: 0.1290 - precision_4: 0.8889 - val_loss: 0.3577 - val_acc: 0.8913 - val_auc: 0.6423 - val_binary_accuracy: 0.8913 - val_recall_4: 0.0109 - val_precision_4: 0.2500\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1245 - acc: 0.9591 - auc: 0.8921 - binary_accuracy: 0.9591 - recall_4: 0.1573 - precision_4: 0.7222 - val_loss: 0.4345 - val_acc: 0.8936 - val_auc: 0.6178 - val_binary_accuracy: 0.8936 - val_recall_4: 0.0000e+00 - val_precision_4: 0.0000e+00\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1194 - acc: 0.9597 - auc: 0.9086 - binary_accuracy: 0.9597 - recall_4: 0.1492 - precision_4: 0.7872 - val_loss: 0.3959 - val_acc: 0.8890 - val_auc: 0.6474 - val_binary_accuracy: 0.8890 - val_recall_4: 0.0383 - val_precision_4: 0.3182\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1175 - acc: 0.9595 - auc: 0.9108 - binary_accuracy: 0.9595 - recall_4: 0.1694 - precision_4: 0.7241 - val_loss: 0.3857 - val_acc: 0.8837 - val_auc: 0.6344 - val_binary_accuracy: 0.8837 - val_recall_4: 0.0492 - val_precision_4: 0.2571\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1140 - acc: 0.9601 - auc: 0.9197 - binary_accuracy: 0.9601 - recall_4: 0.1815 - precision_4: 0.7377 - val_loss: 0.4299 - val_acc: 0.8843 - val_auc: 0.6163 - val_binary_accuracy: 0.8843 - val_recall_4: 0.0492 - val_precision_4: 0.2647\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1141 - acc: 0.9626 - auc: 0.9124 - binary_accuracy: 0.9626 - recall_4: 0.2298 - precision_4: 0.8028 - val_loss: 0.4757 - val_acc: 0.8890 - val_auc: 0.5989 - val_binary_accuracy: 0.8890 - val_recall_4: 0.0492 - val_precision_4: 0.3462\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1091 - acc: 0.9637 - auc: 0.9272 - binary_accuracy: 0.9637 - recall_4: 0.2702 - precision_4: 0.7882 - val_loss: 0.4581 - val_acc: 0.8884 - val_auc: 0.6040 - val_binary_accuracy: 0.8884 - val_recall_4: 0.0437 - val_precision_4: 0.3200\n",
      "0.33673444390296936\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "fc32abe2-5153-43c3-ac0b-736edc80b659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f8caa38f-d110-46ea-bee5-7c375798af21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional Accuracy:  0.9071387115496228 MSE:  0.09286128845037725 UAR:  0.5551856640091934 Recall:  0.16470588235294117 Precision:  0.13592233009708737 F1:  0.14893617021276592\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional Accuracy:  0.942542077771329 MSE:  0.057457922228670924 UAR:  0.5347662141779789 Recall:  0.08235294117647059 Precision:  0.25 F1:  0.12389380530973451\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional Accuracy:  0.9454439930354034 MSE:  0.054556006964596636 UAR:  0.5139840551605258 Recall:  0.03529411764705882 Precision:  0.2 F1:  0.060000000000000005\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional Accuracy:  0.9495066744051074 MSE:  0.05049332559489263 UAR:  0.5161208072972779 Recall:  0.03529411764705882 Precision:  0.375 F1:  0.06451612903225806\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5114594555771026 Recall:  0.023529411764705882 Precision:  0.6666666666666666 F1:  0.045454545454545456\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5117647058823529 Recall:  0.023529411764705882 Precision:  1.0 F1:  0.04597701149425288\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5117647058823529 Recall:  0.023529411764705882 Precision:  1.0 F1:  0.04597701149425288\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.5551856640091934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "29d3a27b-d129-4f8a-88e2-98cd4ac0ea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "74819b80-96c7-46bd-b6e4-c9d339370857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "1bc233b9-c762-49a0-8ee2-2f032d77c622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.8340104468949506 MSE:  0.16598955310504934 UAR:  0.6896143072613661 Recall:  0.5294117647058824 Precision:  0.15463917525773196 F1:  0.23936170212765956\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.9315147997678468 MSE:  0.06848520023215322 UAR:  0.5624290741937801 Recall:  0.15294117647058825 Precision:  0.22033898305084745 F1:  0.18055555555555555\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.9489262913522926 MSE:  0.05107370864770749 UAR:  0.5437010701716585 Recall:  0.09411764705882353 Precision:  0.42105263157894735 F1:  0.15384615384615383\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5058823529411764 Recall:  0.011764705882352941 Precision:  1.0 F1:  0.023255813953488372\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6896143072613661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba9ad43-ba42-4e19-9e21-0a14023ed8e1",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "82018aba-88f3-4ec9-88eb-85e9e189e5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "d7ade335-e218-4721-944b-a7bb646af8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "4579b3c3-84a9-4452-9ef0-7f52ea8089e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "c01dd763-f28c-482c-94ca-175feb50d826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_8 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_8[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_8[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_17 (Dense)            (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "b05c800b-65a1-4010-94e6-4be74a4d1e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 126ms/step - loss: 0.5691 - acc: 0.9159 - auc: 0.5587 - binary_accuracy: 0.9159 - recall_5: 0.0726 - precision_5: 0.0723 - val_loss: 0.5374 - val_acc: 0.8750 - val_auc: 0.5344 - val_binary_accuracy: 0.8750 - val_recall_5: 0.0546 - val_precision_5: 0.1923\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1979 - acc: 0.9497 - auc: 0.6736 - binary_accuracy: 0.9497 - recall_5: 0.0403 - precision_5: 0.2083 - val_loss: 0.3844 - val_acc: 0.8942 - val_auc: 0.6325 - val_binary_accuracy: 0.8942 - val_recall_5: 0.0219 - val_precision_5: 0.5714\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1687 - acc: 0.9533 - auc: 0.7470 - binary_accuracy: 0.9533 - recall_5: 0.0323 - precision_5: 0.3333 - val_loss: 0.3648 - val_acc: 0.8930 - val_auc: 0.6631 - val_binary_accuracy: 0.8930 - val_recall_5: 0.0219 - val_precision_5: 0.4444\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1785 - acc: 0.9533 - auc: 0.7320 - binary_accuracy: 0.9533 - recall_5: 0.0484 - precision_5: 0.3750 - val_loss: 0.4902 - val_acc: 0.8058 - val_auc: 0.5912 - val_binary_accuracy: 0.8058 - val_recall_5: 0.1694 - val_precision_5: 0.1455\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1727 - acc: 0.9509 - auc: 0.7646 - binary_accuracy: 0.9509 - recall_5: 0.0605 - precision_5: 0.2941 - val_loss: 0.3563 - val_acc: 0.8942 - val_auc: 0.6607 - val_binary_accuracy: 0.8942 - val_recall_5: 0.0164 - val_precision_5: 0.6000\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1537 - acc: 0.9546 - auc: 0.7995 - binary_accuracy: 0.9546 - recall_5: 0.0242 - precision_5: 0.4615 - val_loss: 0.3511 - val_acc: 0.8942 - val_auc: 0.6606 - val_binary_accuracy: 0.8942 - val_recall_5: 0.0109 - val_precision_5: 0.6667\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1484 - acc: 0.9560 - auc: 0.8196 - binary_accuracy: 0.9560 - recall_5: 0.0645 - precision_5: 0.6400 - val_loss: 0.3663 - val_acc: 0.8884 - val_auc: 0.6499 - val_binary_accuracy: 0.8884 - val_recall_5: 0.0273 - val_precision_5: 0.2632\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1470 - acc: 0.9557 - auc: 0.8249 - binary_accuracy: 0.9557 - recall_5: 0.0766 - precision_5: 0.5758 - val_loss: 0.3630 - val_acc: 0.8773 - val_auc: 0.6623 - val_binary_accuracy: 0.8773 - val_recall_5: 0.0710 - val_precision_5: 0.2407\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1439 - acc: 0.9562 - auc: 0.8352 - binary_accuracy: 0.9562 - recall_5: 0.0726 - precision_5: 0.6429 - val_loss: 0.3681 - val_acc: 0.8831 - val_auc: 0.6573 - val_binary_accuracy: 0.8831 - val_recall_5: 0.0437 - val_precision_5: 0.2353\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1544 - acc: 0.9548 - auc: 0.8159 - binary_accuracy: 0.9548 - recall_5: 0.0806 - precision_5: 0.5000 - val_loss: 0.4519 - val_acc: 0.8930 - val_auc: 0.6418 - val_binary_accuracy: 0.8930 - val_recall_5: 0.0109 - val_precision_5: 0.4000\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1508 - acc: 0.9546 - auc: 0.8208 - binary_accuracy: 0.9546 - recall_5: 0.0847 - precision_5: 0.4884 - val_loss: 0.3506 - val_acc: 0.8924 - val_auc: 0.6572 - val_binary_accuracy: 0.8924 - val_recall_5: 0.0055 - val_precision_5: 0.2500\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1395 - acc: 0.9573 - auc: 0.8394 - binary_accuracy: 0.9573 - recall_5: 0.1089 - precision_5: 0.6750 - val_loss: 0.3738 - val_acc: 0.8866 - val_auc: 0.6567 - val_binary_accuracy: 0.8866 - val_recall_5: 0.0328 - val_precision_5: 0.2500\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1383 - acc: 0.9586 - auc: 0.8490 - binary_accuracy: 0.9586 - recall_5: 0.1331 - precision_5: 0.7333 - val_loss: 0.3879 - val_acc: 0.8913 - val_auc: 0.6567 - val_binary_accuracy: 0.8913 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1405 - acc: 0.9571 - auc: 0.8556 - binary_accuracy: 0.9571 - recall_5: 0.1452 - precision_5: 0.6102 - val_loss: 0.3917 - val_acc: 0.8919 - val_auc: 0.6639 - val_binary_accuracy: 0.8919 - val_recall_5: 0.0109 - val_precision_5: 0.2857\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1368 - acc: 0.9584 - auc: 0.8585 - binary_accuracy: 0.9584 - recall_5: 0.1452 - precision_5: 0.6923 - val_loss: 0.3565 - val_acc: 0.8802 - val_auc: 0.6663 - val_binary_accuracy: 0.8802 - val_recall_5: 0.0874 - val_precision_5: 0.2909\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1371 - acc: 0.9579 - auc: 0.8570 - binary_accuracy: 0.9579 - recall_5: 0.1573 - precision_5: 0.6393 - val_loss: 0.3968 - val_acc: 0.8919 - val_auc: 0.6537 - val_binary_accuracy: 0.8919 - val_recall_5: 0.0055 - val_precision_5: 0.2000\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1337 - acc: 0.9580 - auc: 0.8650 - binary_accuracy: 0.9580 - recall_5: 0.1452 - precision_5: 0.6667 - val_loss: 0.4354 - val_acc: 0.8919 - val_auc: 0.6355 - val_binary_accuracy: 0.8919 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1434 - acc: 0.9564 - auc: 0.8281 - binary_accuracy: 0.9564 - recall_5: 0.1653 - precision_5: 0.5616 - val_loss: 0.3538 - val_acc: 0.8826 - val_auc: 0.6531 - val_binary_accuracy: 0.8826 - val_recall_5: 0.0929 - val_precision_5: 0.3208\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1359 - acc: 0.9579 - auc: 0.8657 - binary_accuracy: 0.9579 - recall_5: 0.1290 - precision_5: 0.6809 - val_loss: 0.3660 - val_acc: 0.8727 - val_auc: 0.6506 - val_binary_accuracy: 0.8727 - val_recall_5: 0.1311 - val_precision_5: 0.2857\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1311 - acc: 0.9580 - auc: 0.8699 - binary_accuracy: 0.9580 - recall_5: 0.1653 - precision_5: 0.6406 - val_loss: 0.3721 - val_acc: 0.8855 - val_auc: 0.6492 - val_binary_accuracy: 0.8855 - val_recall_5: 0.0929 - val_precision_5: 0.3542\n",
      "0.3506045639514923\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f7d43635-e72b-4293-947b-de24457b6182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "4f042da2-08d2-41b7-ab64-1cc4eee5e0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_traditional Accuracy:  0.8067324434126524 MSE:  0.19326755658734765 UAR:  0.5971881060116354 Recall:  0.36470588235294116 Precision:  0.1 F1:  0.15696202531645567\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_traditional Accuracy:  0.8874056877539176 MSE:  0.11259431224608242 UAR:  0.5615384615384615 Recall:  0.2 Precision:  0.11888111888111888 F1:  0.14912280701754385\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_traditional Accuracy:  0.9239698200812536 MSE:  0.07603017991874637 UAR:  0.5528837175896 Recall:  0.1411764705882353 Precision:  0.17142857142857143 F1:  0.15483870967741936\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_traditional Accuracy:  0.9408009286128846 MSE:  0.0591990713871155 UAR:  0.5561588738059327 Recall:  0.12941176470588237 Precision:  0.28205128205128205 F1:  0.1774193548387097\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_traditional Accuracy:  0.9483459082994776 MSE:  0.05165409170052235 UAR:  0.5433958198664082 Recall:  0.09411764705882353 Precision:  0.4 F1:  0.1523809523809524\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_traditional Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5390397184514831 Recall:  0.08235294117647059 Precision:  0.5 F1:  0.1414141414141414\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_traditional Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5337678661208073 Recall:  0.07058823529411765 Precision:  0.5454545454545454 F1:  0.125\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_traditional Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5167313079077785 Recall:  0.03529411764705882 Precision:  0.5 F1:  0.06593406593406594\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_traditional Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5111542052718523 Recall:  0.023529411764705882 Precision:  0.5 F1:  0.0449438202247191\n",
      "0.1 0.5971881060116354\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "15b5905c-bf80-4e3d-be03-3e60b46d3e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "0c3fe09b-70ea-4fb7-ade5-ef7fe1c59eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "fdd9b636-e619-4f54-bb4e-95d5f702f3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_traditional_best Accuracy:  0.8717353453279164 MSE:  0.1282646546720836 UAR:  0.5923364217481865 Recall:  0.2823529411764706 Precision:  0.13043478260869565 F1:  0.17843866171003714\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_traditional_best Accuracy:  0.9373186302959954 MSE:  0.06268136970400465 UAR:  0.5766357825181354 Recall:  0.17647058823529413 Precision:  0.2830188679245283 F1:  0.2173913043478261\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_traditional_best Accuracy:  0.9437028438769588 MSE:  0.05629715612304121 UAR:  0.5688393306040365 Recall:  0.15294117647058825 Precision:  0.34210526315789475 F1:  0.21138211382113825\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_traditional_best Accuracy:  0.9500870574579222 MSE:  0.04991294254207777 UAR:  0.5498886734180852 Recall:  0.10588235294117647 Precision:  0.47368421052631576 F1:  0.17307692307692304\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_traditional_best Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5396502190619837 Recall:  0.08235294117647059 Precision:  0.5833333333333334 F1:  0.14432989690721648\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_traditional_best Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5343783667313079 Recall:  0.07058823529411765 Precision:  0.6666666666666666 F1:  0.12765957446808512\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_traditional_best Accuracy:  0.9529889727219966 MSE:  0.047011027278003485 UAR:  0.529106514400632 Recall:  0.058823529411764705 Precision:  0.8333333333333334 F1:  0.10989010989010989\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_traditional_best Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5173418085182792 Recall:  0.03529411764705882 Precision:  0.75 F1:  0.06741573033707865\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_traditional_best Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5058823529411764 Recall:  0.011764705882352941 Precision:  1.0 F1:  0.023255813953488372\n",
      "0.1 0.5923364217481865\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120f975c-83b5-4802-9098-1409adfbd952",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "1ea34a4d-6878-4be5-ab43-5fcd551c00ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "6c71abb4-932b-4fda-863d-df1707662a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "2b8e35da-7180-461e-bcd8-a90d94ae4de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "val:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "afe29569-fb09-458d-8791-63087d7546d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482,) (5482,)\n",
      "(1723,) (1723,)\n",
      "(7205,) (7205,)\n",
      "[0 1] [6872  333]\n",
      "7205\n",
      "5475\n",
      "1730\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "4f129a22-99e7-4800-9e0c-a43e33385637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5222/5475: 95.37899543378995%\n",
      "1 253/5475: 4.621004566210046%\n",
      "val:\n",
      "0 1650/1730: 95.3757225433526%\n",
      "1 80/1730: 4.624277456647399%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d5903e-50e0-49c9-bf38-4d7ad378eb5d",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "43156cbc-b43d-4fe3-9a1f-f9a909ddce07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c446ba65-0e2e-43a6-a2cf-7796842e28eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "5a42abcf-42f8-4feb-9ee2-893d94a19d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 2560) (5475,)\n",
      "(1730, 128, 2560) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "9836fddc-6736-414a-9048-55056adb6a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_18 (Dense)            (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "5dcad58b-c5fd-4103-a476-21f2d7d40375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 4s 67ms/step - loss: 0.2116 - acc: 0.9344 - auc: 0.6204 - binary_accuracy: 0.9344 - recall_6: 0.0514 - precision_6: 0.0985 - val_loss: 0.1730 - val_acc: 0.9538 - val_auc: 0.7392 - val_binary_accuracy: 0.9538 - val_recall_6: 0.0000e+00 - val_precision_6: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1649 - acc: 0.9531 - auc: 0.7579 - binary_accuracy: 0.9531 - recall_6: 0.0040 - precision_6: 0.1667 - val_loss: 0.1642 - val_acc: 0.9532 - val_auc: 0.7711 - val_binary_accuracy: 0.9532 - val_recall_6: 0.0000e+00 - val_precision_6: 0.0000e+00\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1572 - acc: 0.9543 - auc: 0.7928 - binary_accuracy: 0.9543 - recall_6: 0.0277 - precision_6: 0.6364 - val_loss: 0.1614 - val_acc: 0.9532 - val_auc: 0.7868 - val_binary_accuracy: 0.9532 - val_recall_6: 0.0000e+00 - val_precision_6: 0.0000e+00\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1533 - acc: 0.9551 - auc: 0.8138 - binary_accuracy: 0.9551 - recall_6: 0.0316 - precision_6: 0.8889 - val_loss: 0.1603 - val_acc: 0.9532 - val_auc: 0.7917 - val_binary_accuracy: 0.9532 - val_recall_6: 0.0000e+00 - val_precision_6: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1538 - acc: 0.9545 - auc: 0.8101 - binary_accuracy: 0.9545 - recall_6: 0.0356 - precision_6: 0.6429 - val_loss: 0.1608 - val_acc: 0.9509 - val_auc: 0.7776 - val_binary_accuracy: 0.9509 - val_recall_6: 0.0125 - val_precision_6: 0.1429\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1474 - acc: 0.9545 - auc: 0.8348 - binary_accuracy: 0.9545 - recall_6: 0.0198 - precision_6: 0.8333 - val_loss: 0.1595 - val_acc: 0.9526 - val_auc: 0.7893 - val_binary_accuracy: 0.9526 - val_recall_6: 0.0125 - val_precision_6: 0.2500\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1441 - acc: 0.9540 - auc: 0.8488 - binary_accuracy: 0.9540 - recall_6: 0.0514 - precision_6: 0.5200 - val_loss: 0.1626 - val_acc: 0.9532 - val_auc: 0.7830 - val_binary_accuracy: 0.9532 - val_recall_6: 0.0000e+00 - val_precision_6: 0.0000e+00\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1383 - acc: 0.9540 - auc: 0.8662 - binary_accuracy: 0.9540 - recall_6: 0.0316 - precision_6: 0.5333 - val_loss: 0.1623 - val_acc: 0.9497 - val_auc: 0.7863 - val_binary_accuracy: 0.9497 - val_recall_6: 0.0125 - val_precision_6: 0.1111\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1395 - acc: 0.9538 - auc: 0.8625 - binary_accuracy: 0.9538 - recall_6: 0.0593 - precision_6: 0.5000 - val_loss: 0.1612 - val_acc: 0.9526 - val_auc: 0.7788 - val_binary_accuracy: 0.9526 - val_recall_6: 0.0000e+00 - val_precision_6: 0.0000e+00\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1340 - acc: 0.9553 - auc: 0.8766 - binary_accuracy: 0.9553 - recall_6: 0.0435 - precision_6: 0.7857 - val_loss: 0.1705 - val_acc: 0.9514 - val_auc: 0.7705 - val_binary_accuracy: 0.9514 - val_recall_6: 0.0250 - val_precision_6: 0.2500\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1324 - acc: 0.9556 - auc: 0.8842 - binary_accuracy: 0.9556 - recall_6: 0.0672 - precision_6: 0.7083 - val_loss: 0.1670 - val_acc: 0.9514 - val_auc: 0.7740 - val_binary_accuracy: 0.9514 - val_recall_6: 0.0250 - val_precision_6: 0.2500\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1277 - acc: 0.9573 - auc: 0.8959 - binary_accuracy: 0.9573 - recall_6: 0.1028 - precision_6: 0.7879 - val_loss: 0.1700 - val_acc: 0.9503 - val_auc: 0.7731 - val_binary_accuracy: 0.9503 - val_recall_6: 0.0625 - val_precision_6: 0.3125\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1280 - acc: 0.9567 - auc: 0.8958 - binary_accuracy: 0.9567 - recall_6: 0.0949 - precision_6: 0.7500 - val_loss: 0.1750 - val_acc: 0.9538 - val_auc: 0.7788 - val_binary_accuracy: 0.9538 - val_recall_6: 0.0125 - val_precision_6: 0.5000\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1245 - acc: 0.9576 - auc: 0.9013 - binary_accuracy: 0.9576 - recall_6: 0.1225 - precision_6: 0.7561 - val_loss: 0.1784 - val_acc: 0.9543 - val_auc: 0.7438 - val_binary_accuracy: 0.9543 - val_recall_6: 0.0500 - val_precision_6: 0.5714\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1236 - acc: 0.9584 - auc: 0.9073 - binary_accuracy: 0.9584 - recall_6: 0.1265 - precision_6: 0.8205 - val_loss: 0.1683 - val_acc: 0.9491 - val_auc: 0.7705 - val_binary_accuracy: 0.9491 - val_recall_6: 0.0375 - val_precision_6: 0.2143\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1170 - acc: 0.9591 - auc: 0.9193 - binary_accuracy: 0.9591 - recall_6: 0.1542 - precision_6: 0.7959 - val_loss: 0.1783 - val_acc: 0.9514 - val_auc: 0.7615 - val_binary_accuracy: 0.9514 - val_recall_6: 0.0375 - val_precision_6: 0.3000\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1170 - acc: 0.9589 - auc: 0.9148 - binary_accuracy: 0.9589 - recall_6: 0.1581 - precision_6: 0.7692 - val_loss: 0.1727 - val_acc: 0.9526 - val_auc: 0.7655 - val_binary_accuracy: 0.9526 - val_recall_6: 0.0375 - val_precision_6: 0.3750\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1131 - acc: 0.9598 - auc: 0.9238 - binary_accuracy: 0.9598 - recall_6: 0.1818 - precision_6: 0.7797 - val_loss: 0.1844 - val_acc: 0.9514 - val_auc: 0.7507 - val_binary_accuracy: 0.9514 - val_recall_6: 0.0500 - val_precision_6: 0.3333\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1105 - acc: 0.9609 - auc: 0.9303 - binary_accuracy: 0.9609 - recall_6: 0.2095 - precision_6: 0.7910 - val_loss: 0.1904 - val_acc: 0.9532 - val_auc: 0.7439 - val_binary_accuracy: 0.9532 - val_recall_6: 0.0375 - val_precision_6: 0.4286\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.1123 - acc: 0.9616 - auc: 0.9235 - binary_accuracy: 0.9616 - recall_6: 0.2174 - precision_6: 0.8209 - val_loss: 0.1855 - val_acc: 0.9486 - val_auc: 0.7620 - val_binary_accuracy: 0.9486 - val_recall_6: 0.1625 - val_precision_6: 0.3714\n",
      "0.1594851166009903\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "779f495e-6ede-4948-bd20-28ae54aa4ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "7906020c-fc2f-4706-8dda-5d3e41ee5b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced Accuracy:  0.8745664739884393 MSE:  0.1254335260115607 UAR:  0.7082575757575758 Recall:  0.525 Precision:  0.19004524886877827 F1:  0.27906976744186046\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced Accuracy:  0.9161849710982659 MSE:  0.0838150289017341 UAR:  0.6706060606060606 Recall:  0.4 Precision:  0.24806201550387597 F1:  0.3062200956937799\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced Accuracy:  0.9358381502890173 MSE:  0.06416184971098265 UAR:  0.621439393939394 Recall:  0.275 Precision:  0.29333333333333333 F1:  0.2838709677419355\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced Accuracy:  0.9416184971098266 MSE:  0.05838150289017341 UAR:  0.5947348484848485 Recall:  0.2125 Precision:  0.3090909090909091 F1:  0.2518518518518518\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced Accuracy:  0.9479768786127167 MSE:  0.05202312138728324 UAR:  0.5683333333333334 Recall:  0.15 Precision:  0.35294117647058826 F1:  0.21052631578947367\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced Accuracy:  0.9514450867052023 MSE:  0.048554913294797684 UAR:  0.552310606060606 Recall:  0.1125 Precision:  0.4090909090909091 F1:  0.17647058823529413\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.5172348484848485 Recall:  0.0375 Precision:  0.375 F1:  0.06818181818181818\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.5053409090909091 Recall:  0.0125 Precision:  0.25 F1:  0.023809523809523808\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.4993939393939394 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.7082575757575758\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "8662c7c4-9a8f-4e80-b4b6-fffb7e1820d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "95c1fbf3-7f9c-4bee-a540-9f898d66a730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "523f2702-19a9-4a0c-8236-f4c78f40ed78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.9 MSE:  0.1 UAR:  0.7096969696969697 Recall:  0.5 Precision:  0.23121387283236994 F1:  0.31620553359683795\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.9433526011560693 MSE:  0.056647398843930635 UAR:  0.6313257575757576 Recall:  0.2875 Precision:  0.359375 F1:  0.3194444444444444\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.9473988439306359 MSE:  0.05260115606936416 UAR:  0.5382954545454546 Recall:  0.0875 Precision:  0.28 F1:  0.13333333333333333\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.9497109826589596 MSE:  0.050289017341040465 UAR:  0.5038257575757575 Recall:  0.0125 Precision:  0.1111111111111111 F1:  0.022471910112359553\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.5053409090909091 Recall:  0.0125 Precision:  0.25 F1:  0.023809523809523808\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.7096969696969697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b230f7-763d-4508-ab91-a09f6a48cb0f",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "153d37a5-ec14-4b04-a7a0-36d173b0bfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "8b2c9fc1-f636-469d-aabe-ed0517a0b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "d67419c6-00f6-4ba3-a9bf-5850ff32c1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 2560) (5475,)\n",
      "(1730, 128, 2560) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "998e36f5-e9ee-491a-b84f-001018dff430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_9 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_9[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_9[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_19 (Dense)            (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "2e748acc-7811-4ec4-b869-1c79ed9e03c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 126ms/step - loss: 0.5038 - acc: 0.9419 - auc: 0.5467 - binary_accuracy: 0.9419 - recall_7: 0.0435 - precision_7: 0.1264 - val_loss: 0.1838 - val_acc: 0.9520 - val_auc: 0.7074 - val_binary_accuracy: 0.9520 - val_recall_7: 0.0250 - val_precision_7: 0.2857\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1727 - acc: 0.9542 - auc: 0.7127 - binary_accuracy: 0.9542 - recall_7: 0.0593 - precision_7: 0.5357 - val_loss: 0.1684 - val_acc: 0.9526 - val_auc: 0.7593 - val_binary_accuracy: 0.9526 - val_recall_7: 0.0125 - val_precision_7: 0.2500\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1666 - acc: 0.9543 - auc: 0.7581 - binary_accuracy: 0.9543 - recall_7: 0.0514 - precision_7: 0.5652 - val_loss: 0.1904 - val_acc: 0.9532 - val_auc: 0.7580 - val_binary_accuracy: 0.9532 - val_recall_7: 0.0625 - val_precision_7: 0.4545\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1638 - acc: 0.9545 - auc: 0.7495 - binary_accuracy: 0.9545 - recall_7: 0.0474 - precision_7: 0.6000 - val_loss: 0.1759 - val_acc: 0.9514 - val_auc: 0.7574 - val_binary_accuracy: 0.9514 - val_recall_7: 0.0125 - val_precision_7: 0.1667\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1591 - acc: 0.9549 - auc: 0.7910 - binary_accuracy: 0.9549 - recall_7: 0.0949 - precision_7: 0.5714 - val_loss: 0.1658 - val_acc: 0.9520 - val_auc: 0.7850 - val_binary_accuracy: 0.9520 - val_recall_7: 0.0625 - val_precision_7: 0.3846\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1526 - acc: 0.9540 - auc: 0.8172 - binary_accuracy: 0.9540 - recall_7: 0.0593 - precision_7: 0.5172 - val_loss: 0.1631 - val_acc: 0.9549 - val_auc: 0.7805 - val_binary_accuracy: 0.9549 - val_recall_7: 0.1125 - val_precision_7: 0.5625\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1539 - acc: 0.9549 - auc: 0.8147 - binary_accuracy: 0.9549 - recall_7: 0.0909 - precision_7: 0.5750 - val_loss: 0.1723 - val_acc: 0.9503 - val_auc: 0.7655 - val_binary_accuracy: 0.9503 - val_recall_7: 0.0250 - val_precision_7: 0.2000\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1536 - acc: 0.9556 - auc: 0.8082 - binary_accuracy: 0.9556 - recall_7: 0.1028 - precision_7: 0.6190 - val_loss: 0.2028 - val_acc: 0.9532 - val_auc: 0.7492 - val_binary_accuracy: 0.9532 - val_recall_7: 0.0000e+00 - val_precision_7: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1495 - acc: 0.9560 - auc: 0.8257 - binary_accuracy: 0.9560 - recall_7: 0.1107 - precision_7: 0.6364 - val_loss: 0.1775 - val_acc: 0.9497 - val_auc: 0.7662 - val_binary_accuracy: 0.9497 - val_recall_7: 0.0875 - val_precision_7: 0.3333\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1488 - acc: 0.9571 - auc: 0.8260 - binary_accuracy: 0.9571 - recall_7: 0.1383 - precision_7: 0.6731 - val_loss: 0.1694 - val_acc: 0.9538 - val_auc: 0.7632 - val_binary_accuracy: 0.9538 - val_recall_7: 0.0375 - val_precision_7: 0.5000\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1491 - acc: 0.9562 - auc: 0.8282 - binary_accuracy: 0.9562 - recall_7: 0.0909 - precision_7: 0.6970 - val_loss: 0.1828 - val_acc: 0.9462 - val_auc: 0.7557 - val_binary_accuracy: 0.9462 - val_recall_7: 0.0750 - val_precision_7: 0.2400\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1516 - acc: 0.9558 - auc: 0.8219 - binary_accuracy: 0.9558 - recall_7: 0.1225 - precision_7: 0.6078 - val_loss: 0.1717 - val_acc: 0.9532 - val_auc: 0.7645 - val_binary_accuracy: 0.9532 - val_recall_7: 0.0625 - val_precision_7: 0.4545\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1440 - acc: 0.9549 - auc: 0.8469 - binary_accuracy: 0.9549 - recall_7: 0.1107 - precision_7: 0.5600 - val_loss: 0.1687 - val_acc: 0.9520 - val_auc: 0.7692 - val_binary_accuracy: 0.9520 - val_recall_7: 0.0625 - val_precision_7: 0.3846\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1360 - acc: 0.9573 - auc: 0.8595 - binary_accuracy: 0.9573 - recall_7: 0.1304 - precision_7: 0.7021 - val_loss: 0.1814 - val_acc: 0.9451 - val_auc: 0.7602 - val_binary_accuracy: 0.9451 - val_recall_7: 0.1375 - val_precision_7: 0.2973\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1429 - acc: 0.9551 - auc: 0.8576 - binary_accuracy: 0.9551 - recall_7: 0.1462 - precision_7: 0.5522 - val_loss: 0.1740 - val_acc: 0.9514 - val_auc: 0.7485 - val_binary_accuracy: 0.9514 - val_recall_7: 0.0625 - val_precision_7: 0.3571\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1379 - acc: 0.9574 - auc: 0.8575 - binary_accuracy: 0.9574 - recall_7: 0.1621 - precision_7: 0.6613 - val_loss: 0.1767 - val_acc: 0.9520 - val_auc: 0.7405 - val_binary_accuracy: 0.9520 - val_recall_7: 0.0375 - val_precision_7: 0.3333\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1342 - acc: 0.9573 - auc: 0.8736 - binary_accuracy: 0.9573 - recall_7: 0.1700 - precision_7: 0.6418 - val_loss: 0.1840 - val_acc: 0.9514 - val_auc: 0.7521 - val_binary_accuracy: 0.9514 - val_recall_7: 0.0625 - val_precision_7: 0.3571\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1420 - acc: 0.9542 - auc: 0.8562 - binary_accuracy: 0.9542 - recall_7: 0.1146 - precision_7: 0.5179 - val_loss: 0.1722 - val_acc: 0.9491 - val_auc: 0.7642 - val_binary_accuracy: 0.9491 - val_recall_7: 0.0375 - val_precision_7: 0.2143\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1279 - acc: 0.9585 - auc: 0.8886 - binary_accuracy: 0.9585 - recall_7: 0.1660 - precision_7: 0.7241 - val_loss: 0.1966 - val_acc: 0.9410 - val_auc: 0.7322 - val_binary_accuracy: 0.9410 - val_recall_7: 0.1125 - val_precision_7: 0.2250\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1308 - acc: 0.9595 - auc: 0.8740 - binary_accuracy: 0.9595 - recall_7: 0.1976 - precision_7: 0.7246 - val_loss: 0.1823 - val_acc: 0.9503 - val_auc: 0.7385 - val_binary_accuracy: 0.9503 - val_recall_7: 0.1250 - val_precision_7: 0.3846\n",
      "0.16311943531036377\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "eb7d2284-de37-4db1-a807-c399f5adb446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "0351fa13-108f-4050-b9af-2a7551c3d72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_balanced Accuracy:  0.8317919075144509 MSE:  0.16820809248554913 UAR:  0.6798863636363637 Recall:  0.5125 Precision:  0.13993174061433447 F1:  0.21983914209115282\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_balanced Accuracy:  0.9109826589595376 MSE:  0.08901734104046242 UAR:  0.6559848484848485 Recall:  0.375 Precision:  0.22388059701492538 F1:  0.28037383177570097\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_balanced Accuracy:  0.9317919075144508 MSE:  0.06820809248554913 UAR:  0.6133712121212122 Recall:  0.2625 Precision:  0.2625 F1:  0.2625\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_balanced Accuracy:  0.9450867052023122 MSE:  0.05491329479768786 UAR:  0.584659090909091 Recall:  0.1875 Precision:  0.3333333333333333 F1:  0.24000000000000005\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_balanced Accuracy:  0.9497109826589596 MSE:  0.050289017341040465 UAR:  0.5632954545454546 Recall:  0.1375 Precision:  0.3793103448275862 F1:  0.20183486238532108\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_balanced Accuracy:  0.9520231213872833 MSE:  0.04797687861271676 UAR:  0.5526136363636364 Recall:  0.1125 Precision:  0.42857142857142855 F1:  0.1782178217821782\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_balanced Accuracy:  0.954335260115607 MSE:  0.04566473988439306 UAR:  0.5359848484848485 Recall:  0.075 Precision:  0.5454545454545454 F1:  0.13186813186813187\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_balanced Accuracy:  0.954335260115607 MSE:  0.04566473988439306 UAR:  0.5181439393939394 Recall:  0.0375 Precision:  0.6 F1:  0.07058823529411765\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5059469696969697 Recall:  0.0125 Precision:  0.5 F1:  0.02439024390243903\n",
      "0.1 0.6798863636363637\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "3103fb16-3fa3-4c69-b068-911ee70915a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "d149d487-f927-4c70-a3e7-73ffa3edc178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "090d43b6-5df7-4353-91b1-8f98900287df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_balanced_best Accuracy:  0.8745664739884393 MSE:  0.1254335260115607 UAR:  0.6904166666666667 Recall:  0.4875 Precision:  0.1813953488372093 F1:  0.26440677966101694\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_balanced_best Accuracy:  0.9323699421965318 MSE:  0.0676300578034682 UAR:  0.6374621212121212 Recall:  0.3125 Precision:  0.28735632183908044 F1:  0.2994011976047904\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_balanced_best Accuracy:  0.9468208092485549 MSE:  0.05317919075144509 UAR:  0.5915151515151515 Recall:  0.2 Precision:  0.36363636363636365 F1:  0.25806451612903225\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_balanced_best Accuracy:  0.9491329479768786 MSE:  0.05086705202312139 UAR:  0.568939393939394 Recall:  0.15 Precision:  0.375 F1:  0.21428571428571425\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_balanced_best Accuracy:  0.954335260115607 MSE:  0.04566473988439306 UAR:  0.5538257575757576 Recall:  0.1125 Precision:  0.5294117647058824 F1:  0.18556701030927836\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5234848484848484 Recall:  0.05 Precision:  0.4444444444444444 F1:  0.08988764044943821\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6904166666666667\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fe2590-8c2d-4eb4-a3bf-5bf1e89cbef1",
   "metadata": {},
   "source": [
    "### STAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "606721d2-adda-45f6-8905-a51f1d7432af",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = compute_descriptor\n",
    "stat_name = \"STAT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ae1e95-f4f9-42e5-8740-82b8abec98b5",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "866d8971-44b4-401b-bec4-e21143b34031",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "7272b984-9de5-44e6-b991-b59bd31543f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "4102c946-bab9-458d-8b1f-74b696116c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "test:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n",
      "val:\n",
      "0 1537/1720: 89.36046511627907%\n",
      "1 183/1720: 10.63953488372093%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fa8172-1d1d-4472-9f99-d96a3cfe8463",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "d0195ee5-9144-4c6f-8fa7-9d787c258f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "611c63c0-e608-43da-bae3-34a9ffc71f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "1d2f5524-ce19-4929-b4cf-36c6c7f40be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 3840) (5482,)\n",
      "(1723, 128, 3840) (1723,)\n",
      "(1720, 128, 3840) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "9e842d3f-7c74-46ca-af83-2aa3a9f5caff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1966592   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_20 (Dense)            (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1970946 (7.52 MB)\n",
      "Trainable params: 1970946 (7.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "4828e17b-8970-4905-bea4-65f69bb89b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 97ms/step - loss: 0.2071 - acc: 0.9464 - auc: 0.6059 - binary_accuracy: 0.9464 - recall_8: 0.0040 - precision_8: 0.0208 - val_loss: 0.3544 - val_acc: 0.8936 - val_auc: 0.6199 - val_binary_accuracy: 0.8936 - val_recall_8: 0.0000e+00 - val_precision_8: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.1626 - acc: 0.9548 - auc: 0.7616 - binary_accuracy: 0.9548 - recall_8: 0.0000e+00 - precision_8: 0.0000e+00 - val_loss: 0.3673 - val_acc: 0.8936 - val_auc: 0.6570 - val_binary_accuracy: 0.8936 - val_recall_8: 0.0000e+00 - val_precision_8: 0.0000e+00\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.1553 - acc: 0.9548 - auc: 0.7932 - binary_accuracy: 0.9548 - recall_8: 0.0000e+00 - precision_8: 0.0000e+00 - val_loss: 0.3347 - val_acc: 0.8936 - val_auc: 0.6722 - val_binary_accuracy: 0.8936 - val_recall_8: 0.0000e+00 - val_precision_8: 0.0000e+00\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.1524 - acc: 0.9551 - auc: 0.8061 - binary_accuracy: 0.9551 - recall_8: 0.0081 - precision_8: 1.0000 - val_loss: 0.4018 - val_acc: 0.8936 - val_auc: 0.6563 - val_binary_accuracy: 0.8936 - val_recall_8: 0.0000e+00 - val_precision_8: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.1541 - acc: 0.9553 - auc: 0.7944 - binary_accuracy: 0.9553 - recall_8: 0.0121 - precision_8: 1.0000 - val_loss: 0.3457 - val_acc: 0.8936 - val_auc: 0.6686 - val_binary_accuracy: 0.8936 - val_recall_8: 0.0000e+00 - val_precision_8: 0.0000e+00\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.1460 - acc: 0.9559 - auc: 0.8300 - binary_accuracy: 0.9559 - recall_8: 0.0323 - precision_8: 0.8000 - val_loss: 0.3363 - val_acc: 0.8936 - val_auc: 0.6694 - val_binary_accuracy: 0.8936 - val_recall_8: 0.0000e+00 - val_precision_8: 0.0000e+00\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.1477 - acc: 0.9562 - auc: 0.8228 - binary_accuracy: 0.9562 - recall_8: 0.0444 - precision_8: 0.7857 - val_loss: 0.3527 - val_acc: 0.8936 - val_auc: 0.6615 - val_binary_accuracy: 0.8936 - val_recall_8: 0.0000e+00 - val_precision_8: 0.0000e+00\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.1429 - acc: 0.9557 - auc: 0.8435 - binary_accuracy: 0.9557 - recall_8: 0.0484 - precision_8: 0.6316 - val_loss: 0.3782 - val_acc: 0.8936 - val_auc: 0.6576 - val_binary_accuracy: 0.8936 - val_recall_8: 0.0000e+00 - val_precision_8: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.1404 - acc: 0.9570 - auc: 0.8450 - binary_accuracy: 0.9570 - recall_8: 0.0645 - precision_8: 0.8000 - val_loss: 0.3603 - val_acc: 0.8936 - val_auc: 0.6575 - val_binary_accuracy: 0.8936 - val_recall_8: 0.0000e+00 - val_precision_8: 0.0000e+00\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.1394 - acc: 0.9566 - auc: 0.8525 - binary_accuracy: 0.9566 - recall_8: 0.0645 - precision_8: 0.7273 - val_loss: 0.3694 - val_acc: 0.8936 - val_auc: 0.6595 - val_binary_accuracy: 0.8936 - val_recall_8: 0.0000e+00 - val_precision_8: 0.0000e+00\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.1352 - acc: 0.9566 - auc: 0.8652 - binary_accuracy: 0.9566 - recall_8: 0.0685 - precision_8: 0.7083 - val_loss: 0.3558 - val_acc: 0.8901 - val_auc: 0.6556 - val_binary_accuracy: 0.8901 - val_recall_8: 0.0055 - val_precision_8: 0.1250\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.1338 - acc: 0.9591 - auc: 0.8642 - binary_accuracy: 0.9591 - recall_8: 0.1048 - precision_8: 0.9286 - val_loss: 0.4039 - val_acc: 0.8895 - val_auc: 0.6429 - val_binary_accuracy: 0.8895 - val_recall_8: 0.0055 - val_precision_8: 0.1111\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.1317 - acc: 0.9580 - auc: 0.8748 - binary_accuracy: 0.9580 - recall_8: 0.0887 - precision_8: 0.8462 - val_loss: 0.3615 - val_acc: 0.8860 - val_auc: 0.6556 - val_binary_accuracy: 0.8860 - val_recall_8: 0.0164 - val_precision_8: 0.1579\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.1303 - acc: 0.9590 - auc: 0.8786 - binary_accuracy: 0.9590 - recall_8: 0.1250 - precision_8: 0.7949 - val_loss: 0.3752 - val_acc: 0.8895 - val_auc: 0.6569 - val_binary_accuracy: 0.8895 - val_recall_8: 0.0109 - val_precision_8: 0.1818\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.1286 - acc: 0.9588 - auc: 0.8822 - binary_accuracy: 0.9588 - recall_8: 0.1210 - precision_8: 0.7895 - val_loss: 0.4060 - val_acc: 0.8913 - val_auc: 0.6445 - val_binary_accuracy: 0.8913 - val_recall_8: 0.0000e+00 - val_precision_8: 0.0000e+00\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.1244 - acc: 0.9590 - auc: 0.8948 - binary_accuracy: 0.9590 - recall_8: 0.1129 - precision_8: 0.8485 - val_loss: 0.3958 - val_acc: 0.8860 - val_auc: 0.6483 - val_binary_accuracy: 0.8860 - val_recall_8: 0.0383 - val_precision_8: 0.2593\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.1253 - acc: 0.9613 - auc: 0.8906 - binary_accuracy: 0.9613 - recall_8: 0.1935 - precision_8: 0.8000 - val_loss: 0.4022 - val_acc: 0.8884 - val_auc: 0.6366 - val_binary_accuracy: 0.8884 - val_recall_8: 0.0273 - val_precision_8: 0.2632\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.1218 - acc: 0.9604 - auc: 0.8993 - binary_accuracy: 0.9604 - recall_8: 0.1573 - precision_8: 0.8298 - val_loss: 0.3744 - val_acc: 0.8843 - val_auc: 0.6432 - val_binary_accuracy: 0.8843 - val_recall_8: 0.0601 - val_precision_8: 0.2895\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.1276 - acc: 0.9582 - auc: 0.8870 - binary_accuracy: 0.9582 - recall_8: 0.1532 - precision_8: 0.6667 - val_loss: 0.3693 - val_acc: 0.8872 - val_auc: 0.6405 - val_binary_accuracy: 0.8872 - val_recall_8: 0.0546 - val_precision_8: 0.3226\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.1196 - acc: 0.9593 - auc: 0.9001 - binary_accuracy: 0.9593 - recall_8: 0.1895 - precision_8: 0.6812 - val_loss: 0.3787 - val_acc: 0.8866 - val_auc: 0.6310 - val_binary_accuracy: 0.8866 - val_recall_8: 0.0601 - val_precision_8: 0.3235\n",
      "0.3347465395927429\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "7bd7e01c-1923-4113-83ea-b87b1c305cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "870f0baf-b107-4345-8687-115b31d4fd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.7945443993035404 MSE:  0.20545560069645966 UAR:  0.6130862601450837 Recall:  0.4117647058823529 Precision:  0.10324483775811209 F1:  0.1650943396226415\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.8705745792222868 MSE:  0.1294254207777133 UAR:  0.5861488185017597 Recall:  0.27058823529411763 Precision:  0.125 F1:  0.17100371747211895\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.9042367962855484 MSE:  0.09576320371445154 UAR:  0.5703907203907204 Recall:  0.2 Precision:  0.14912280701754385 F1:  0.17085427135678394\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.9355774811375508 MSE:  0.06442251886244922 UAR:  0.5422574157868275 Recall:  0.10588235294117647 Precision:  0.20454545454545456 F1:  0.13953488372093026\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.9495066744051074 MSE:  0.05049332559489263 UAR:  0.5161208072972779 Recall:  0.03529411764705882 Precision:  0.375 F1:  0.06451612903225806\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.9500870574579222 MSE:  0.04991294254207777 UAR:  0.510848954966602 Recall:  0.023529411764705882 Precision:  0.4 F1:  0.044444444444444446\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5117647058823529 Recall:  0.023529411764705882 Precision:  1.0 F1:  0.04597701149425288\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6130862601450837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "bcefdaba-c7e3-4f10-96e5-ca33f75be3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "aa43c3b5-67b2-4e41-8370-3bb4ceb5d2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "6590356a-4db8-429e-af83-29282ce945d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.9053975623911782 MSE:  0.09460243760882182 UAR:  0.6546577605401135 Recall:  0.3764705882352941 Precision:  0.22535211267605634 F1:  0.28193832599118945\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.9460243760882182 MSE:  0.053975623911781775 UAR:  0.5923687423687424 Recall:  0.2 Precision:  0.40476190476190477 F1:  0.26771653543307083\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5566867772750126 Recall:  0.11764705882352941 Precision:  0.5882352941176471 F1:  0.19607843137254902\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5232241614594556 Recall:  0.047058823529411764 Precision:  0.8 F1:  0.08888888888888889\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6546577605401135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3d4c60-0b84-4b84-bcd1-0b12c0a22ce2",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "00b90ba7-7429-460a-9f33-234b03a1e818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "a320d603-e45a-4416-a919-d4692f6f69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "d223a5f5-ae7b-4690-8791-bd2a93a9d4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 3840) (5482,)\n",
      "(1723, 128, 3840) (1723,)\n",
      "(1720, 128, 3840) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "2fbe1990-165a-4312-8775-d795736c34b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " attention_10 (Attention)    (None, None, 3840)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['attention_10[0][0]']        \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['attention_10[0][0]',        \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_21 (Dense)            (None, 1)                    3841      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29498882 (112.53 MB)\n",
      "Trainable params: 29498882 (112.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "6fae7bdf-7048-4117-90fb-26a1e97bfae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 12s 227ms/step - loss: 0.6625 - acc: 0.9239 - auc: 0.5221 - binary_accuracy: 0.9239 - recall_9: 0.0605 - precision_9: 0.0754 - val_loss: 0.3818 - val_acc: 0.8924 - val_auc: 0.5921 - val_binary_accuracy: 0.8924 - val_recall_9: 0.0055 - val_precision_9: 0.2500\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 8s 176ms/step - loss: 0.1709 - acc: 0.9531 - auc: 0.7334 - binary_accuracy: 0.9531 - recall_9: 0.0444 - precision_9: 0.3548 - val_loss: 0.3445 - val_acc: 0.8936 - val_auc: 0.6673 - val_binary_accuracy: 0.8936 - val_recall_9: 0.0055 - val_precision_9: 0.5000\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 7s 173ms/step - loss: 0.1627 - acc: 0.9538 - auc: 0.7598 - binary_accuracy: 0.9538 - recall_9: 0.0161 - precision_9: 0.3077 - val_loss: 0.4119 - val_acc: 0.8936 - val_auc: 0.6508 - val_binary_accuracy: 0.8936 - val_recall_9: 0.0055 - val_precision_9: 0.5000\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 7s 174ms/step - loss: 0.1583 - acc: 0.9560 - auc: 0.7837 - binary_accuracy: 0.9560 - recall_9: 0.0806 - precision_9: 0.6061 - val_loss: 0.3989 - val_acc: 0.8936 - val_auc: 0.6569 - val_binary_accuracy: 0.8936 - val_recall_9: 0.0000e+00 - val_precision_9: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 7s 172ms/step - loss: 0.1551 - acc: 0.9564 - auc: 0.7872 - binary_accuracy: 0.9564 - recall_9: 0.0766 - precision_9: 0.6552 - val_loss: 0.3531 - val_acc: 0.8913 - val_auc: 0.6437 - val_binary_accuracy: 0.8913 - val_recall_9: 0.0055 - val_precision_9: 0.1667\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 7s 172ms/step - loss: 0.1520 - acc: 0.9555 - auc: 0.8086 - binary_accuracy: 0.9555 - recall_9: 0.0685 - precision_9: 0.5667 - val_loss: 0.3659 - val_acc: 0.8901 - val_auc: 0.6606 - val_binary_accuracy: 0.8901 - val_recall_9: 0.0055 - val_precision_9: 0.1250\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 7s 172ms/step - loss: 0.1470 - acc: 0.9553 - auc: 0.8229 - binary_accuracy: 0.9553 - recall_9: 0.0766 - precision_9: 0.5429 - val_loss: 0.3663 - val_acc: 0.8762 - val_auc: 0.6668 - val_binary_accuracy: 0.8762 - val_recall_9: 0.0492 - val_precision_9: 0.1875\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 8s 176ms/step - loss: 0.1436 - acc: 0.9560 - auc: 0.8349 - binary_accuracy: 0.9560 - recall_9: 0.0887 - precision_9: 0.5946 - val_loss: 0.3765 - val_acc: 0.8517 - val_auc: 0.6596 - val_binary_accuracy: 0.8517 - val_recall_9: 0.0874 - val_precision_9: 0.1538\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 7s 174ms/step - loss: 0.1496 - acc: 0.9542 - auc: 0.8219 - binary_accuracy: 0.9542 - recall_9: 0.0968 - precision_9: 0.4706 - val_loss: 0.3678 - val_acc: 0.8907 - val_auc: 0.6511 - val_binary_accuracy: 0.8907 - val_recall_9: 0.0000e+00 - val_precision_9: 0.0000e+00\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 7s 173ms/step - loss: 0.1451 - acc: 0.9571 - auc: 0.8360 - binary_accuracy: 0.9571 - recall_9: 0.1129 - precision_9: 0.6512 - val_loss: 0.3824 - val_acc: 0.8924 - val_auc: 0.6512 - val_binary_accuracy: 0.8924 - val_recall_9: 0.0000e+00 - val_precision_9: 0.0000e+00\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 7s 173ms/step - loss: 0.1405 - acc: 0.9584 - auc: 0.8425 - binary_accuracy: 0.9584 - recall_9: 0.1210 - precision_9: 0.7500 - val_loss: 0.3634 - val_acc: 0.8866 - val_auc: 0.6496 - val_binary_accuracy: 0.8866 - val_recall_9: 0.0273 - val_precision_9: 0.2273\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 7s 173ms/step - loss: 0.1372 - acc: 0.9575 - auc: 0.8492 - binary_accuracy: 0.9575 - recall_9: 0.1411 - precision_9: 0.6364 - val_loss: 0.3884 - val_acc: 0.8610 - val_auc: 0.6451 - val_binary_accuracy: 0.8610 - val_recall_9: 0.0601 - val_precision_9: 0.1410\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 7s 173ms/step - loss: 0.1354 - acc: 0.9584 - auc: 0.8607 - binary_accuracy: 0.9584 - recall_9: 0.1532 - precision_9: 0.6786 - val_loss: 0.3643 - val_acc: 0.8843 - val_auc: 0.6561 - val_binary_accuracy: 0.8843 - val_recall_9: 0.0546 - val_precision_9: 0.2778\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 7s 172ms/step - loss: 0.1386 - acc: 0.9571 - auc: 0.8493 - binary_accuracy: 0.9571 - recall_9: 0.1774 - precision_9: 0.5867 - val_loss: 0.3853 - val_acc: 0.8866 - val_auc: 0.6313 - val_binary_accuracy: 0.8866 - val_recall_9: 0.0109 - val_precision_9: 0.1250\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 7s 175ms/step - loss: 0.1385 - acc: 0.9579 - auc: 0.8548 - binary_accuracy: 0.9579 - recall_9: 0.1452 - precision_9: 0.6545 - val_loss: 0.4048 - val_acc: 0.8872 - val_auc: 0.6427 - val_binary_accuracy: 0.8872 - val_recall_9: 0.0437 - val_precision_9: 0.2963\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 8s 176ms/step - loss: 0.1308 - acc: 0.9595 - auc: 0.8715 - binary_accuracy: 0.9595 - recall_9: 0.1895 - precision_9: 0.6912 - val_loss: 0.4299 - val_acc: 0.8901 - val_auc: 0.6314 - val_binary_accuracy: 0.8901 - val_recall_9: 0.0000e+00 - val_precision_9: 0.0000e+00\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 7s 173ms/step - loss: 0.1303 - acc: 0.9595 - auc: 0.8700 - binary_accuracy: 0.9595 - recall_9: 0.2016 - precision_9: 0.6757 - val_loss: 0.4230 - val_acc: 0.8605 - val_auc: 0.6275 - val_binary_accuracy: 0.8605 - val_recall_9: 0.0437 - val_precision_9: 0.1096\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 7s 173ms/step - loss: 0.1341 - acc: 0.9584 - auc: 0.8641 - binary_accuracy: 0.9584 - recall_9: 0.1774 - precision_9: 0.6471 - val_loss: 0.4396 - val_acc: 0.8901 - val_auc: 0.6139 - val_binary_accuracy: 0.8901 - val_recall_9: 0.0055 - val_precision_9: 0.1250\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 7s 172ms/step - loss: 0.1438 - acc: 0.9579 - auc: 0.8543 - binary_accuracy: 0.9579 - recall_9: 0.1492 - precision_9: 0.6491 - val_loss: 0.3994 - val_acc: 0.8831 - val_auc: 0.6390 - val_binary_accuracy: 0.8831 - val_recall_9: 0.0437 - val_precision_9: 0.2353\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 7s 172ms/step - loss: 0.1306 - acc: 0.9590 - auc: 0.8678 - binary_accuracy: 0.9590 - recall_9: 0.1694 - precision_9: 0.6885 - val_loss: 0.4960 - val_acc: 0.8924 - val_auc: 0.5996 - val_binary_accuracy: 0.8924 - val_recall_9: 0.0000e+00 - val_precision_9: 0.0000e+00\n",
      "0.34453827142715454\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "04989d04-164a-44c9-944a-374ae75a48db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "56515389-caf3-42a4-a69b-1dc128940617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_traditional Accuracy:  0.9338363319791062 MSE:  0.0661636680208938 UAR:  0.5357645622351505 Recall:  0.09411764705882353 Precision:  0.17777777777777778 F1:  0.12307692307692307\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_traditional Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5390397184514831 Recall:  0.08235294117647059 Precision:  0.5 F1:  0.1414141414141414\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5284960137901314 Recall:  0.058823529411764705 Precision:  0.625 F1:  0.10752688172043011\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5229189111542053 Recall:  0.047058823529411764 Precision:  0.6666666666666666 F1:  0.08791208791208792\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5117647058823529 Recall:  0.023529411764705882 Precision:  1.0 F1:  0.04597701149425288\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5117647058823529 Recall:  0.023529411764705882 Precision:  1.0 F1:  0.04597701149425288\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5117647058823529 Recall:  0.023529411764705882 Precision:  1.0 F1:  0.04597701149425288\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_traditional Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5058823529411764 Recall:  0.011764705882352941 Precision:  1.0 F1:  0.023255813953488372\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_traditional Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5058823529411764 Recall:  0.011764705882352941 Precision:  1.0 F1:  0.023255813953488372\n",
      "0.2 0.5390397184514831\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "8569ec7b-0123-4ee6-b38d-b4e76212e6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "ae6c08b6-c2e6-4d40-91aa-70fb0e639cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "bdabd6dc-28f8-41dd-905d-b593757b9937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_traditional_best Accuracy:  0.9048171793383634 MSE:  0.09518282066163668 UAR:  0.6208898944193062 Recall:  0.3058823529411765 Precision:  0.1984732824427481 F1:  0.24074074074074073\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_traditional_best Accuracy:  0.9442832269297736 MSE:  0.05571677307022635 UAR:  0.5914529914529915 Recall:  0.2 Precision:  0.37777777777777777 F1:  0.26153846153846155\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_traditional_best Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5672304819363643 Recall:  0.1411764705882353 Precision:  0.5217391304347826 F1:  0.22222222222222218\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_traditional_best Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5337678661208073 Recall:  0.07058823529411765 Precision:  0.5454545454545454 F1:  0.125\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_traditional_best Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5114594555771026 Recall:  0.023529411764705882 Precision:  0.6666666666666666 F1:  0.045454545454545456\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5055771026359261 Recall:  0.011764705882352941 Precision:  0.5 F1:  0.02298850574712644\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6208898944193062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587057ee-aebd-4e00-94af-8a455d9b9374",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "48a450d7-736f-4135-a0d2-f5f52e50215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "4e9e70ff-0b79-4cbd-af8a-ca148c7c7be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "01de8a23-691f-49eb-9e47-234346cdcf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "val:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "40bb2724-b80c-4d6f-997f-af9d734f9fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 2560) (5482,)\n",
      "(1723, 2560) (1723,)\n",
      "(7205, 2560) (7205,)\n",
      "[0 1] [6872  333]\n",
      "7205\n",
      "5475\n",
      "1730\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "deb4424d-a1df-4968-ad08-d7a10bac937a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5222/5475: 95.37899543378995%\n",
      "1 253/5475: 4.621004566210046%\n",
      "val:\n",
      "0 1650/1730: 95.3757225433526%\n",
      "1 80/1730: 4.624277456647399%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c6abca-3d82-4b7d-ab9c-ded7e320958b",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "a4e302bc-b7f2-43a6-b951-5a95f77aef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "85ef2fa6-73a8-4bf5-9a89-467f057876fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "a1d536cd-294b-4203-b699-bd6b59a3dace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 3840) (5475,)\n",
      "(1730, 128, 3840) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "c3906cf2-8473-4218-8e24-2e1741471cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1966592   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_22 (Dense)            (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1970946 (7.52 MB)\n",
      "Trainable params: 1970946 (7.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "3bece67b-995c-439e-b5a3-af1deaf4cfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 95ms/step - loss: 0.2116 - acc: 0.9357 - auc: 0.6157 - binary_accuracy: 0.9357 - recall_10: 0.0435 - precision_10: 0.0909 - val_loss: 0.1770 - val_acc: 0.9538 - val_auc: 0.7389 - val_binary_accuracy: 0.9538 - val_recall_10: 0.0000e+00 - val_precision_10: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.1681 - acc: 0.9538 - auc: 0.7434 - binary_accuracy: 0.9538 - recall_10: 0.0119 - precision_10: 0.5000 - val_loss: 0.1664 - val_acc: 0.9532 - val_auc: 0.7714 - val_binary_accuracy: 0.9532 - val_recall_10: 0.0000e+00 - val_precision_10: 0.0000e+00\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.1588 - acc: 0.9545 - auc: 0.7815 - binary_accuracy: 0.9545 - recall_10: 0.0198 - precision_10: 0.8333 - val_loss: 0.1620 - val_acc: 0.9532 - val_auc: 0.7787 - val_binary_accuracy: 0.9532 - val_recall_10: 0.0125 - val_precision_10: 0.3333\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.1538 - acc: 0.9553 - auc: 0.8079 - binary_accuracy: 0.9553 - recall_10: 0.0435 - precision_10: 0.7857 - val_loss: 0.1598 - val_acc: 0.9526 - val_auc: 0.7870 - val_binary_accuracy: 0.9526 - val_recall_10: 0.0125 - val_precision_10: 0.2500\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.1528 - acc: 0.9540 - auc: 0.8150 - binary_accuracy: 0.9540 - recall_10: 0.0356 - precision_10: 0.5294 - val_loss: 0.1664 - val_acc: 0.9532 - val_auc: 0.7905 - val_binary_accuracy: 0.9532 - val_recall_10: 0.0625 - val_precision_10: 0.4545\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.1493 - acc: 0.9565 - auc: 0.8216 - binary_accuracy: 0.9565 - recall_10: 0.0949 - precision_10: 0.7273 - val_loss: 0.1582 - val_acc: 0.9532 - val_auc: 0.7921 - val_binary_accuracy: 0.9532 - val_recall_10: 0.0000e+00 - val_precision_10: 0.0000e+00\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.1458 - acc: 0.9560 - auc: 0.8389 - binary_accuracy: 0.9560 - recall_10: 0.0553 - precision_10: 0.8750 - val_loss: 0.1580 - val_acc: 0.9543 - val_auc: 0.7764 - val_binary_accuracy: 0.9543 - val_recall_10: 0.0375 - val_precision_10: 0.6000\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.1412 - acc: 0.9562 - auc: 0.8510 - binary_accuracy: 0.9562 - recall_10: 0.0830 - precision_10: 0.7241 - val_loss: 0.1598 - val_acc: 0.9514 - val_auc: 0.7867 - val_binary_accuracy: 0.9514 - val_recall_10: 0.0375 - val_precision_10: 0.3000\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.1392 - acc: 0.9558 - auc: 0.8634 - binary_accuracy: 0.9558 - recall_10: 0.0711 - precision_10: 0.7200 - val_loss: 0.1615 - val_acc: 0.9526 - val_auc: 0.7821 - val_binary_accuracy: 0.9526 - val_recall_10: 0.0000e+00 - val_precision_10: 0.0000e+00\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.1383 - acc: 0.9578 - auc: 0.8572 - binary_accuracy: 0.9578 - recall_10: 0.1146 - precision_10: 0.8056 - val_loss: 0.1602 - val_acc: 0.9532 - val_auc: 0.7814 - val_binary_accuracy: 0.9532 - val_recall_10: 0.0250 - val_precision_10: 0.4000\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.1388 - acc: 0.9560 - auc: 0.8531 - binary_accuracy: 0.9560 - recall_10: 0.0949 - precision_10: 0.6667 - val_loss: 0.1633 - val_acc: 0.9509 - val_auc: 0.7772 - val_binary_accuracy: 0.9509 - val_recall_10: 0.0500 - val_precision_10: 0.3077\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.1339 - acc: 0.9584 - auc: 0.8690 - binary_accuracy: 0.9584 - recall_10: 0.1383 - precision_10: 0.7778 - val_loss: 0.1609 - val_acc: 0.9549 - val_auc: 0.7714 - val_binary_accuracy: 0.9549 - val_recall_10: 0.0750 - val_precision_10: 0.6000\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.1346 - acc: 0.9573 - auc: 0.8653 - binary_accuracy: 0.9573 - recall_10: 0.0988 - precision_10: 0.8065 - val_loss: 0.1663 - val_acc: 0.9526 - val_auc: 0.7656 - val_binary_accuracy: 0.9526 - val_recall_10: 0.1000 - val_precision_10: 0.4444\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.1274 - acc: 0.9591 - auc: 0.8942 - binary_accuracy: 0.9591 - recall_10: 0.1621 - precision_10: 0.7736 - val_loss: 0.1647 - val_acc: 0.9520 - val_auc: 0.7698 - val_binary_accuracy: 0.9520 - val_recall_10: 0.0125 - val_precision_10: 0.2000\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.1255 - acc: 0.9598 - auc: 0.8960 - binary_accuracy: 0.9598 - recall_10: 0.1660 - precision_10: 0.8235 - val_loss: 0.1679 - val_acc: 0.9509 - val_auc: 0.7724 - val_binary_accuracy: 0.9509 - val_recall_10: 0.1125 - val_precision_10: 0.3913\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.1287 - acc: 0.9580 - auc: 0.8849 - binary_accuracy: 0.9580 - recall_10: 0.1660 - precision_10: 0.6885 - val_loss: 0.1689 - val_acc: 0.9543 - val_auc: 0.7613 - val_binary_accuracy: 0.9543 - val_recall_10: 0.0875 - val_precision_10: 0.5385\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.1218 - acc: 0.9582 - auc: 0.9077 - binary_accuracy: 0.9582 - recall_10: 0.1542 - precision_10: 0.7222 - val_loss: 0.1687 - val_acc: 0.9509 - val_auc: 0.7583 - val_binary_accuracy: 0.9509 - val_recall_10: 0.0750 - val_precision_10: 0.3529\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.1170 - acc: 0.9607 - auc: 0.9123 - binary_accuracy: 0.9607 - recall_10: 0.2016 - precision_10: 0.7969 - val_loss: 0.1728 - val_acc: 0.9532 - val_auc: 0.7550 - val_binary_accuracy: 0.9532 - val_recall_10: 0.1000 - val_precision_10: 0.4706\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.1168 - acc: 0.9616 - auc: 0.9101 - binary_accuracy: 0.9616 - recall_10: 0.2292 - precision_10: 0.7945 - val_loss: 0.1702 - val_acc: 0.9532 - val_auc: 0.7597 - val_binary_accuracy: 0.9532 - val_recall_10: 0.1125 - val_precision_10: 0.4737\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.1115 - acc: 0.9620 - auc: 0.9256 - binary_accuracy: 0.9620 - recall_10: 0.2372 - precision_10: 0.8000 - val_loss: 0.1743 - val_acc: 0.9520 - val_auc: 0.7529 - val_binary_accuracy: 0.9520 - val_recall_10: 0.1500 - val_precision_10: 0.4444\n",
      "0.15800650417804718\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "6f43f7ea-902b-4dc8-9ad6-4fe00993bc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "879fe81f-1afa-4bb0-b520-097f108760d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.8456647398843931 MSE:  0.15433526011560694 UAR:  0.7168939393939393 Recall:  0.575 Precision:  0.16487455197132617 F1:  0.2562674094707521\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.9208092485549133 MSE:  0.07919075144508671 UAR:  0.6908712121212122 Recall:  0.4375 Precision:  0.2755905511811024 F1:  0.3381642512077295\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.9404624277456647 MSE:  0.05953757225433526 UAR:  0.6535984848484848 Recall:  0.3375 Precision:  0.35064935064935066 F1:  0.34394904458598724\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.9479768786127167 MSE:  0.05202312138728324 UAR:  0.5980681818181818 Recall:  0.2125 Precision:  0.38636363636363635 F1:  0.27419354838709675\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.5767045454545455 Recall:  0.1625 Precision:  0.4642857142857143 F1:  0.24074074074074078\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5472727272727272 Recall:  0.1 Precision:  0.47058823529411764 F1:  0.16494845360824742\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.9520231213872833 MSE:  0.04797687861271676 UAR:  0.5050378787878788 Recall:  0.0125 Precision:  0.2 F1:  0.023529411764705885\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.7168939393939393\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "f58869af-30d2-4d86-8783-0448b45eb3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "f2abf6b6-a5c9-4b7a-8b80-23d6a793e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "bf5937ed-2f6c-4d9f-bd8f-f50feaff28f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.8780346820809248 MSE:  0.12196531791907514 UAR:  0.7219696969696969 Recall:  0.55 Precision:  0.2009132420091324 F1:  0.294314381270903\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.9387283236994219 MSE:  0.06127167630057803 UAR:  0.6407954545454546 Recall:  0.3125 Precision:  0.32894736842105265 F1:  0.32051282051282054\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.6010984848484848 Recall:  0.2125 Precision:  0.5 F1:  0.2982456140350877\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.9560693641618497 MSE:  0.04393063583815029 UAR:  0.5666287878787879 Recall:  0.1375 Precision:  0.6111111111111112 F1:  0.22448979591836737\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.954335260115607 MSE:  0.04566473988439306 UAR:  0.5181439393939394 Recall:  0.0375 Precision:  0.6 F1:  0.07058823529411765\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.7219696969696969\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d261a3-d1d5-4ebe-ab09-e82b08cf676f",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "fe349490-f157-4331-b7ea-bdc4da8484dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "5e0d98da-2eeb-4aad-86e4-202c08022fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "9c7ed33e-1fbb-4f36-b941-4ff6f4f36b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 3840) (5475,)\n",
      "(1730, 128, 3840) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "b69063b0-2eee-481d-8e1b-50626ef048a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " attention_11 (Attention)    (None, None, 3840)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['attention_11[0][0]']        \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['attention_11[0][0]',        \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_23 (Dense)            (None, 1)                    3841      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29498882 (112.53 MB)\n",
      "Trainable params: 29498882 (112.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "c1bf92cf-1a59-423b-a958-7ae3880562af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 11s 222ms/step - loss: 0.6550 - acc: 0.9253 - auc: 0.5266 - binary_accuracy: 0.9253 - recall_11: 0.0751 - precision_11: 0.0979 - val_loss: 0.2056 - val_acc: 0.9445 - val_auc: 0.7181 - val_binary_accuracy: 0.9445 - val_recall_11: 0.1125 - val_precision_11: 0.2647\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 7s 173ms/step - loss: 0.1759 - acc: 0.9514 - auc: 0.7221 - binary_accuracy: 0.9514 - recall_11: 0.0395 - precision_11: 0.3030 - val_loss: 0.1680 - val_acc: 0.9538 - val_auc: 0.7627 - val_binary_accuracy: 0.9538 - val_recall_11: 0.0125 - val_precision_11: 0.5000\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 7s 172ms/step - loss: 0.1580 - acc: 0.9549 - auc: 0.7791 - binary_accuracy: 0.9549 - recall_11: 0.0553 - precision_11: 0.6364 - val_loss: 0.1674 - val_acc: 0.9503 - val_auc: 0.7787 - val_binary_accuracy: 0.9503 - val_recall_11: 0.0625 - val_precision_11: 0.3125\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 7s 174ms/step - loss: 0.1634 - acc: 0.9553 - auc: 0.7661 - binary_accuracy: 0.9553 - recall_11: 0.0870 - precision_11: 0.6111 - val_loss: 0.2064 - val_acc: 0.9532 - val_auc: 0.7405 - val_binary_accuracy: 0.9532 - val_recall_11: 0.0000e+00 - val_precision_11: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 7s 172ms/step - loss: 0.1684 - acc: 0.9538 - auc: 0.7605 - binary_accuracy: 0.9538 - recall_11: 0.0830 - precision_11: 0.5000 - val_loss: 0.1708 - val_acc: 0.9532 - val_auc: 0.7862 - val_binary_accuracy: 0.9532 - val_recall_11: 0.0125 - val_precision_11: 0.3333\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 7s 172ms/step - loss: 0.1623 - acc: 0.9538 - auc: 0.7922 - binary_accuracy: 0.9538 - recall_11: 0.0632 - precision_11: 0.5000 - val_loss: 0.1705 - val_acc: 0.9532 - val_auc: 0.7755 - val_binary_accuracy: 0.9532 - val_recall_11: 0.0125 - val_precision_11: 0.3333\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 7s 173ms/step - loss: 0.1512 - acc: 0.9554 - auc: 0.8108 - binary_accuracy: 0.9554 - recall_11: 0.1028 - precision_11: 0.6047 - val_loss: 0.1635 - val_acc: 0.9503 - val_auc: 0.7792 - val_binary_accuracy: 0.9503 - val_recall_11: 0.0500 - val_precision_11: 0.2857\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 7s 173ms/step - loss: 0.1475 - acc: 0.9558 - auc: 0.8172 - binary_accuracy: 0.9558 - recall_11: 0.0949 - precision_11: 0.6486 - val_loss: 0.1641 - val_acc: 0.9543 - val_auc: 0.7821 - val_binary_accuracy: 0.9543 - val_recall_11: 0.0625 - val_precision_11: 0.5556\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 7s 172ms/step - loss: 0.1443 - acc: 0.9553 - auc: 0.8353 - binary_accuracy: 0.9553 - recall_11: 0.1067 - precision_11: 0.5870 - val_loss: 0.1692 - val_acc: 0.9497 - val_auc: 0.7771 - val_binary_accuracy: 0.9497 - val_recall_11: 0.0750 - val_precision_11: 0.3158\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 7s 172ms/step - loss: 0.1436 - acc: 0.9558 - auc: 0.8419 - binary_accuracy: 0.9558 - recall_11: 0.1462 - precision_11: 0.5873 - val_loss: 0.1645 - val_acc: 0.9532 - val_auc: 0.7732 - val_binary_accuracy: 0.9532 - val_recall_11: 0.0125 - val_precision_11: 0.3333\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 7s 173ms/step - loss: 0.1435 - acc: 0.9558 - auc: 0.8356 - binary_accuracy: 0.9558 - recall_11: 0.1186 - precision_11: 0.6122 - val_loss: 0.2076 - val_acc: 0.9497 - val_auc: 0.7629 - val_binary_accuracy: 0.9497 - val_recall_11: 0.0125 - val_precision_11: 0.1111\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 7s 172ms/step - loss: 0.1553 - acc: 0.9558 - auc: 0.8013 - binary_accuracy: 0.9558 - recall_11: 0.1304 - precision_11: 0.6000 - val_loss: 0.1684 - val_acc: 0.9480 - val_auc: 0.7780 - val_binary_accuracy: 0.9480 - val_recall_11: 0.0500 - val_precision_11: 0.2222\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 7s 173ms/step - loss: 0.1451 - acc: 0.9551 - auc: 0.8347 - binary_accuracy: 0.9551 - recall_11: 0.1265 - precision_11: 0.5614 - val_loss: 0.1735 - val_acc: 0.9491 - val_auc: 0.7643 - val_binary_accuracy: 0.9491 - val_recall_11: 0.0875 - val_precision_11: 0.3182\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 8s 177ms/step - loss: 0.1373 - acc: 0.9573 - auc: 0.8540 - binary_accuracy: 0.9573 - recall_11: 0.1621 - precision_11: 0.6508 - val_loss: 0.1687 - val_acc: 0.9480 - val_auc: 0.7886 - val_binary_accuracy: 0.9480 - val_recall_11: 0.0500 - val_precision_11: 0.2222\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 8s 176ms/step - loss: 0.1411 - acc: 0.9576 - auc: 0.8373 - binary_accuracy: 0.9576 - recall_11: 0.1581 - precision_11: 0.6780 - val_loss: 0.1703 - val_acc: 0.9543 - val_auc: 0.7665 - val_binary_accuracy: 0.9543 - val_recall_11: 0.0875 - val_precision_11: 0.5385\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 7s 173ms/step - loss: 0.1359 - acc: 0.9595 - auc: 0.8582 - binary_accuracy: 0.9595 - recall_11: 0.1976 - precision_11: 0.7246 - val_loss: 0.1698 - val_acc: 0.9538 - val_auc: 0.7634 - val_binary_accuracy: 0.9538 - val_recall_11: 0.0250 - val_precision_11: 0.5000\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 7s 173ms/step - loss: 0.1300 - acc: 0.9593 - auc: 0.8721 - binary_accuracy: 0.9593 - recall_11: 0.1976 - precision_11: 0.7143 - val_loss: 0.1738 - val_acc: 0.9538 - val_auc: 0.7515 - val_binary_accuracy: 0.9538 - val_recall_11: 0.0500 - val_precision_11: 0.5000\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 7s 172ms/step - loss: 0.1301 - acc: 0.9595 - auc: 0.8733 - binary_accuracy: 0.9595 - recall_11: 0.2095 - precision_11: 0.7067 - val_loss: 0.1818 - val_acc: 0.9509 - val_auc: 0.7317 - val_binary_accuracy: 0.9509 - val_recall_11: 0.0750 - val_precision_11: 0.3529\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 7s 174ms/step - loss: 0.1331 - acc: 0.9585 - auc: 0.8672 - binary_accuracy: 0.9585 - recall_11: 0.1897 - precision_11: 0.6857 - val_loss: 0.1871 - val_acc: 0.9468 - val_auc: 0.7566 - val_binary_accuracy: 0.9468 - val_recall_11: 0.1375 - val_precision_11: 0.3235\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 7s 171ms/step - loss: 0.1393 - acc: 0.9582 - auc: 0.8495 - binary_accuracy: 0.9582 - recall_11: 0.2016 - precision_11: 0.6538 - val_loss: 0.1701 - val_acc: 0.9538 - val_auc: 0.7514 - val_binary_accuracy: 0.9538 - val_recall_11: 0.0500 - val_precision_11: 0.5000\n",
      "0.16352415084838867\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "07dad635-1e23-41c0-a999-52cb59cb883d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "10ee1aa0-7178-4336-811d-4d1120c8ec03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_balanced Accuracy:  0.8890173410404625 MSE:  0.11098265895953757 UAR:  0.6742045454545454 Recall:  0.4375 Precision:  0.19230769230769232 F1:  0.26717557251908397\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_balanced Accuracy:  0.9329479768786128 MSE:  0.06705202312138728 UAR:  0.5842424242424242 Recall:  0.2 Precision:  0.23529411764705882 F1:  0.2162162162162162\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_balanced Accuracy:  0.9473988439306359 MSE:  0.05260115606936416 UAR:  0.568030303030303 Recall:  0.15 Precision:  0.34285714285714286 F1:  0.20869565217391303\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_balanced Accuracy:  0.9514450867052023 MSE:  0.048554913294797684 UAR:  0.5285227272727273 Recall:  0.0625 Precision:  0.35714285714285715 F1:  0.10638297872340426\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_balanced Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.5231818181818182 Recall:  0.05 Precision:  0.4 F1:  0.0888888888888889\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5118939393939393 Recall:  0.025 Precision:  0.5 F1:  0.047619047619047616\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5059469696969697 Recall:  0.0125 Precision:  0.5 F1:  0.02439024390243903\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5059469696969697 Recall:  0.0125 Precision:  0.5 F1:  0.02439024390243903\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6742045454545454\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "d796a8dc-4415-4b06-948e-7b3938fa9d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "4083b302-21ed-4d71-86a3-3d82ce105e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "04bd6529-c9d0-4318-8e31-7e42e177ca43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_balanced_best Accuracy:  0.869364161849711 MSE:  0.130635838150289 UAR:  0.687689393939394 Recall:  0.4875 Precision:  0.17410714285714285 F1:  0.2565789473684211\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_balanced_best Accuracy:  0.9300578034682081 MSE:  0.06994219653179191 UAR:  0.6481439393939394 Recall:  0.3375 Precision:  0.28421052631578947 F1:  0.30857142857142855\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_balanced_best Accuracy:  0.946242774566474 MSE:  0.05375722543352601 UAR:  0.5793181818181818 Recall:  0.175 Precision:  0.34146341463414637 F1:  0.23140495867768593\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_balanced_best Accuracy:  0.9502890173410404 MSE:  0.04971098265895954 UAR:  0.5517045454545455 Recall:  0.1125 Precision:  0.375 F1:  0.1730769230769231\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_balanced_best Accuracy:  0.9491329479768786 MSE:  0.05086705202312139 UAR:  0.5154166666666666 Recall:  0.0375 Precision:  0.21428571428571427 F1:  0.06382978723404255\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5118939393939393 Recall:  0.025 Precision:  0.5 F1:  0.047619047619047616\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5059469696969697 Recall:  0.0125 Precision:  0.5 F1:  0.02439024390243903\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.687689393939394\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3062cf9-e8cb-4ed8-8bfd-5f5456720532",
   "metadata": {},
   "source": [
    "## MobileNet_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "1421a469-4d92-4e5d-93b7-fb50af3a38b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_key = 'mobilenet_7.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "dfbd48af-0c81-42c0-be75-abb8240bb409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['engaged', 'distracted']\n",
      "{'1100011002': 0, '1100011003': 0, '1100011004': 0, '1100011005': 0, '1100011006': 0, '1100011007': 0, '1100011008': 0, '1100011009': 0, '1100011010': 0, '1100011011': 0, '1100011012': 0, '1100011013': 0, '1100011014': 0, '1100011015': 0, '1100011016': 0, '1100011017': 0, '1100011018': 0, '1100011019': 0, '1100011020': 0, '1100011021': 0, '1100011022': 0, '1100011023': 0, '1100011025': 0, '1100011026': 0, '1100011027': 0, '1100011028': 0, '1100011029': 0, '1100011031': 0, '1100011032': 0, '1100011034': 0, '1100011035': 0, '1100011037': 0, '1100011038': 0, '1100011040': 0, '1100011046': 0, '1100011047': 0, '1100011048': 0, '1100011049': 0, '1100011050': 0, '1100011051': 0, '1100011052': 0, '1100011053': 0, '1100011054': 0, '1100011055': 0, '1100011056': 0, '1100011057': 0, '1100011058': 0, '1100011059': 0, '1100011060': 0, '1100011062': 0, '1100011063': 0, '1100011064': 0, '1100011066': 0, '1100011067': 0, '1100011068': 0, '1100011069': 0, '1100011070': 0, '1100011071': 0, '1100011072': 0, '1100011073': 0, '1100011075': 0, '1100011076': 0, '1100011078': 0, '1100011079': 0, '1100011080': 0, '1100011081': 0, '1100011082': 0, '1100011083': 0, '1100012001': 0, '1100012003': 0, '1100012007': 0, '1100012008': 0, '1100012009': 0, '1100012010': 0, '1100012011': 0, '1100012013': 0, '1100012014': 0, '1100012015': 0, '1100012016': 0, '1100012017': 0, '1100012018': 0, '1100012021': 0, '1100012022': 0, '1100012023': 0, '1100012025': 0, '1100012026': 0, '1100012027': 0, '1100012028': 0, '1100012030': 0, '1100012031': 0, '1100012032': 0, '1100012033': 0, '1100012036': 0, '1100012037': 0, '1100012038': 0, '1100012041': 0, '1100012042': 0, '1100012045': 0, '1100012046': 0, '1100012047': 0, '1100012049': 0, '1100012050': 0, '1100012051': 0, '1100012052': 0, '1100012057': 0, '1100012059': 0, '1100012060': 0, '1100012061': 0, '1100012062': 0, '1100012063': 0, '1100012064': 0, '1100012065': 0, '1100012066': 0, '1100012069': 0, '1100021001': 0, '1100021003': 1, '1100021015': 0, '1100021038': 0, '1100021039': 0, '1100021040': 0, '1100021045': 0, '1100021050': 0, '1100021055': 1, '1100022001': 0, '1100022002': 0, '1100022003': 0, '1100022004': 0, '1100022005': 1, '1100022008': 0, '1100022009': 0, '1100022014': 0, '1100022019': 0, '1100022020': 0, '1100022021': 0, '1100022022': 0, '1100022026': 0, '1100022027': 0, '1100022028': 0, '1100022029': 0, '1100022031': 0, '1100022035': 0, '1100022038': 0, '1100022039': 0, '1100022045': 0, '1100022046': 0, '1100022047': 0, '1100022048': 0, '1100022049': 0, '1100022051': 0, '1100022052': 0, '1100022053': 0, '1100022054': 0, '1100022055': 0, '1100022056': 0, '1100022057': 0, '1100041006': 0, '1100041015': 0, '1100041016': 0, '1100041017': 0, '1100041018': 0, '1100041021': 0, '1100041022': 0, '1100041023': 0, '1100041024': 0, '1100041029': 0, '1100041034': 0, '1100041044': 0, '1100041051': 0, '1100041052': 0, '1100042009': 0, '1100042010': 0, '1100042011': 0, '1100042017': 0, '1100042018': 0, '1100042019': 0, '1100042020': 0, '1100042023': 1, '1100042024': 0, '1100042025': 0, '1100042026': 1, '1100042029': 0, '1100042030': 0, '1100042031': 0, '1100042034': 0, '1100042040': 0, '1100042041': 0, '1100042058': 0, '1100042059': 0, '1100042060': 0, '1100051002': 0, '1100051004': 0, '1100051006': 0, '1100051007': 1, '1100051008': 0, '1100051009': 0, '1100051011': 0, '1100051012': 0, '1100051013': 0, '1100051014': 0, '1100051016': 1, '1100051017': 0, '1100051019': 0, '1100051020': 0, '1100051021': 0, '1100051022': 0, '1100051023': 0, '1100051024': 0, '1100051025': 0, '1100051026': 0, '1100051028': 0, '1100051029': 0, '1100051030': 1, '1100051031': 1, '1100051032': 0, '1100051033': 0, '1100051034': 0, '1100051035': 0, '1100051036': 0, '1100051037': 0, '1100051039': 0, '1100051041': 0, '1100051042': 0, '1100051044': 0, '1100051045': 0, '1100051046': 0, '1100051048': 0, '1100051049': 0, '1100051050': 0, '1100051051': 0, '1100051052': 0, '1100051053': 1, '1100051054': 0, '1100051055': 0, '1100051056': 0, '1100051057': 0, '1100051059': 0, '1100051061': 0, '1100051062': 0, '1100051064': 0, '1100051065': 0, '1100051066': 0, '1100051067': 0, '1100051068': 0, '1100051071': 0, '1100051076': 0, '1100051078': 0, '1100051079': 0, '1100052001': 0, '1100052002': 0, '1100052006': 0, '1100052007': 0, '1100052008': 0, '1100052009': 0, '1100052014': 1, '1100052023': 0, '1100052024': 0, '1100052026': 0, '1100052027': 0, '1100052028': 0, '1100052030': 0, '1100052031': 0, '1100052032': 0, '1100052033': 0, '1100052035': 0, '1100052036': 0, '1100052037': 0, '1100052038': 0, '1100052039': 0, '1100052040': 0, '1100052041': 0, '1100052047': 0, '1100052048': 0, '1100052049': 0, '1100052051': 0, '1100052055': 0, '1100052057': 0, '1100052060': 0, '1100052061': 0, '1100052062': 0, '1100052065': 0, '1100052068': 0, '1100052070': 0, '1100061009': 0, '1100061010': 0, '1100061011': 0, '1100061012': 0, '1100061013': 0, '1100061015': 0, '1100061016': 0, '1100061018': 0, '1100061019': 0, '1100061022': 0, '1100061023': 0, '1100061025': 0, '1100061027': 0, '1100061028': 0, '1100061030': 0, '1100061031': 0, '1100061032': 0, '1100061033': 0, '1100061034': 0, '1100061035': 0, '1100061036': 0, '1100061038': 0, '1100061039': 0, '1100061040': 0, '1100061042': 0, '1100061043': 0, '1100061044': 0, '1100061046': 0, '1100061047': 0, '1100061048': 0, '1100061049': 0, '1100061050': 0, '1100061051': 0, '1100061053': 0, '1100061057': 0, '1100061058': 0, '1100061061': 0, '1100061063': 0, '1100061064': 0, '1100061067': 0, '1100061068': 0, '1100061069': 0, '1100061073': 0, '1100061074': 0, '1100061077': 0, '1100061078': 0, '1100062004': 0, '1100062005': 0, '1100062007': 0, '1100062008': 1, '1100062009': 0, '1100062016': 0, '1100062017': 0, '1100062024': 0, '1100062028': 0, '1100062029': 0, '1100062036': 0, '1100062037': 0, '1100062044': 0, '1100062045': 1, '1100062046': 0, '1100062049': 1, '1100062051': 0, '1100062053': 0, '1100062054': 0, '1100062059': 0, '1100062060': 0, '1100062061': 0, '1100062062': 0, '1100062063': 0, '1100062064': 0, '1100062065': 0, '1100062066': 0, '1100062067': 0, '1100062068': 0, '1100062069': 0, '1100062070': 0, '1100062071': 0, '1100062072': 0, '1100071005': 0, '1100071006': 0, '1100071007': 0, '1100071008': 0, '1100071009': 0, '1100071010': 0, '1100071011': 0, '1100071012': 0, '1100071013': 0, '1100071014': 0, '1100071015': 0, '1100071016': 0, '1100071017': 0, '1100071018': 0, '1100071019': 0, '1100071020': 0, '1100071021': 0, '1100071022': 0, '1100071023': 0, '1100071024': 0, '1100071026': 0, '1100071027': 0, '1100071028': 0, '1100071029': 0, '1100071030': 0, '1100071031': 0, '1100071032': 0, '1100071033': 0, '1100071034': 0, '1100071035': 0, '1100071036': 0, '1100071037': 0, '1100071040': 0, '1100071041': 0, '1100071042': 0, '1100071043': 0, '1100071044': 0, '1100071045': 0, '1100071046': 0, '1100071047': 0, '1100071049': 0, '1100071050': 0, '1100071052': 0, '1100071054': 0, '1100071055': 0, '1100071056': 0, '1100071057': 0, '1100071058': 0, '1100071059': 0, '1100071060': 0, '1100071061': 0, '1100071062': 0, '1100071063': 0, '1100071064': 0, '1100071065': 0, '1100071066': 0, '1100071067': 0, '1100071069': 0, '1100071070': 0, '1100071071': 0, '1100071072': 0, '1100071073': 0, '1100071074': 0, '1100071075': 0, '1100071076': 0, '1100071077': 0, '1100071078': 0, '1100071079': 0, '1100071080': 0, '1100071081': 0, '1100072001': 0, '1100072002': 0, '1100072003': 0, '1100072004': 0, '1100072006': 0, '1100072007': 0, '1100072008': 0, '1100072009': 0, '1100072010': 0, '1100072011': 0, '1100072012': 0, '1100072013': 0, '1100072014': 0, '1100072015': 0, '1100072016': 0, '1100072021': 0, '1100072022': 0, '1100072023': 0, '1100072024': 0, '1100072027': 0, '1100072028': 0, '1100072029': 0, '1100072030': 0, '1100072031': 0, '1100072032': 0, '1100072033': 0, '1100072034': 0, '1100072036': 0, '1100072037': 0, '1100072038': 0, '1100072039': 0, '1100072040': 0, '1100072042': 0, '1100072043': 0, '1100072045': 0, '1100072047': 0, '1100072048': 0, '1100072049': 0, '1100072050': 0, '1100072051': 0, '1100072052': 0, '1100072053': 0, '1100072054': 0, '1100072056': 0, '1100072057': 0, '1100072058': 0, '1100072059': 0, '1100072060': 0, '1100072061': 0, '1100072062': 0, '1100072063': 0, '1100072065': 0, '1100072066': 0, '1100072067': 0, '1100072068': 0, '1100072069': 0, '1100072070': 0, '1100072071': 0, '1100072072': 0, '1100072073': 0, '1100072074': 0, '1100072075': 0, '1100072076': 0, '1100072077': 0, '1100072078': 0, '1100072079': 0, '1100072080': 0, '1100072081': 0, '1100072082': 0, '1100072083': 0, '1100072084': 0, '1100072085': 0, '1100081044': 0, '1100081045': 0, '1100081046': 0, '1100081047': 0, '1100081048': 0, '1100082002': 0, '1100082003': 0, '1100082018': 0, '1100082027': 0, '1100102003': 0, '1100111001': 0, '1100111002': 0, '1100111003': 0, '1100111008': 0, '1100111009': 0, '1100111010': 0, '1100111011': 0, '1100111012': 0, '1100111013': 0, '1100111014': 0, '1100111016': 0, '1100111017': 0, '1100111018': 0, '1100111019': 0, '1100111021': 0, '1100111023': 0, '1100111025': 0, '1100111026': 0, '1100111027': 0, '1100111029': 0, '1100111030': 0, '1100111032': 0, '1100112001': 0, '1100112002': 1, '1100112003': 0, '1100112004': 0, '1100112006': 1, '1100112007': 0, '1100112008': 0, '1100112009': 0, '1100112010': 0, '1100112011': 0, '1100112012': 0, '1100112013': 0, '1100112014': 0, '1100112015': 0, '1100112016': 0, '1100112017': 0, '1100112018': 0, '1100112021': 0, '1100112022': 0, '1100112024': 0, '1100112025': 0, '1100112026': 0, '1100112029': 0, '1100112030': 0, '1100112033': 0, '1100112035': 0, '1100112036': 0, '1100112037': 0, '1100112038': 0, '1100112039': 0, '1100112040': 0, '1100112041': 0, '1100112042': 0, '1100112043': 0, '1100112044': 0, '1100112045': 0, '1100112047': 0, '1100112048': 0, '1100112051': 0, '1100112052': 0, '1100112053': 0, '1100112056': 0, '1100112057': 0, '1100112058': 0, '1100112059': 0, '1100112060': 0, '1100112061': 0, '1100112062': 0, '1100112063': 0, '1100112064': 0, '1100112065': 0, '1100112066': 0, '1100112068': 0, '1100121002': 0, '1100121003': 0, '1100121004': 0, '1100121005': 0, '1100121006': 0, '1100121007': 0, '1100121008': 0, '1100121009': 0, '1100121010': 0, '1100121011': 0, '1100121012': 0, '1100121015': 0, '1100121016': 0, '1100121017': 0, '1100121018': 0, '1100121019': 0, '1100121020': 0, '1100121024': 0, '1100121025': 0, '1100121028': 0, '1100121031': 0, '1100121032': 0, '1100121033': 0, '1100121034': 0, '1100121035': 0, '1100121036': 0, '1100121038': 0, '1100121040': 0, '1100121041': 0, '1100121042': 0, '1100121044': 0, '1100121045': 0, '1100121047': 0, '1100121049': 0, '1100121050': 0, '1100121052': 0, '1100121053': 0, '1100121054': 0, '1100121056': 0, '1100121057': 0, '1100121059': 0, '1100121060': 0, '1100121061': 0, '1100121064': 0, '1100122001': 0, '1100122002': 0, '1100122003': 0, '1100122005': 0, '1100122006': 0, '1100122007': 0, '1100122008': 0, '1100122009': 0, '1100122010': 0, '1100122011': 0, '1100122012': 0, '1100122013': 0, '1100122014': 0, '1100122015': 0, '1100122017': 0, '1100122018': 0, '1100122019': 0, '1100122020': 0, '1100122021': 0, '1100122023': 0, '1100122024': 0, '1100122025': 0, '1100122026': 0, '1100122031': 0, '1100122032': 0, '1100122033': 0, '1100122034': 0, '1100122035': 0, '1100122036': 0, '1100122037': 0, '1100122038': 0, '1100122039': 0, '1100122040': 0, '1100122041': 0, '1100122045': 0, '1100122047': 0, '1100122048': 0, '1100122050': 0, '1100122051': 0, '1100122052': 0, '1100122053': 0, '1100122054': 0, '1100122056': 1, '1100131006': 0, '1100131007': 0, '1100131009': 0, '1100131010': 0, '1100131011': 0, '1100131012': 0, '1100131017': 1, '1100131019': 0, '1100141001': 0, '1100141002': 0, '1100141003': 0, '1100141004': 0, '1100141005': 0, '1100141006': 0, '1100141007': 0, '1100141008': 0, '1100141009': 0, '1100141010': 0, '1100141011': 0, '1100141012': 0, '1100141013': 1, '1100141014': 0, '1100141015': 0, '1100141016': 0, '1100141017': 0, '1100141019': 0, '1100141020': 0, '1100141021': 0, '1100141023': 0, '1100141027': 1, '1100141028': 0, '1100141029': 0, '1100141030': 0, '1100141031': 0, '1100141032': 0, '1100141033': 0, '1100141034': 0, '1100141035': 0, '1100141036': 0, '1100141039': 0, '1100141040': 0, '1100141042': 0, '1100141044': 0, '1100141045': 0, '1100141046': 0, '1100141049': 0, '1100141050': 0, '1100141052': 0, '1100141053': 0, '1100141054': 0, '1100141055': 0, '1100141056': 0, '1100141057': 0, '1100142002': 0, '1100142003': 0, '1100142004': 0, '1100142007': 0, '1100142008': 0, '1100142009': 0, '1100142010': 0, '1100142011': 0, '1100142013': 0, '1100142014': 0, '1100142015': 0, '1100142017': 0, '1100142018': 0, '1100142019': 0, '1100142021': 0, '1100142022': 0, '1100142023': 0, '1100142024': 0, '1100142027': 0, '1100142028': 0, '1100142029': 0, '1100142030': 0, '1100142031': 0, '1100142032': 0, '1100142033': 1, '1100142034': 0, '1100142035': 0, '1100142038': 0, '1100142041': 0, '1100142043': 0, '1100142044': 0, '1100142045': 0, '1100142046': 0, '1100142048': 0, '1100142049': 0, '1100142050': 0, '1100142051': 0, '1100142052': 0, '1100142053': 0, '1100142056': 0, '1100142057': 0, '1100142058': 0, '1100142059': 0, '1100142060': 0, '1100151003': 0, '1100151004': 0, '1100151008': 0, '1100151009': 0, '1100151010': 0, '1100151011': 1, '1100151012': 0, '1100151013': 0, '1100151014': 0, '1100151015': 0, '1100151016': 0, '1100151017': 0, '1100151018': 0, '1100151019': 0, '1100151020': 0, '1100151021': 0, '1100151022': 0, '1100151023': 0, '1100151024': 0, '1100151028': 0, '1100151030': 0, '1100151032': 0, '1100151033': 0, '1100151035': 0, '1100151037': 0, '1100151038': 0, '1100151039': 0, '1100151040': 0, '1100151042': 0, '1100151043': 0, '1100151044': 0, '1100151047': 0, '1100151049': 0, '1100151050': 0, '1100151051': 0, '1100151052': 0, '1100151054': 0, '1100151055': 0, '1100151056': 0, '1100151057': 1, '1100151058': 0, '1100151062': 0, '1100152001': 0, '1100152004': 0, '1100152005': 0, '1100152006': 0, '1100152008': 0, '1100152009': 0, '1100152010': 1, '1100152013': 0, '1100152014': 0, '1100152015': 0, '1100152017': 1, '1100152019': 0, '1100152020': 0, '1100152022': 0, '1100152024': 0, '1100152025': 0, '1100152026': 0, '1100152027': 0, '1100152031': 1, '1100152032': 0, '1100152039': 0, '1100152040': 0, '1100152041': 0, '1100152042': 0, '1100152043': 0, '1100152048': 0, '1100152049': 0, '1100152050': 0, '1100152051': 0, '1100152055': 1, '1100152056': 0, '1100152061': 0, '1100152062': 0, '1100152067': 0, '1100152069': 0, '1100152070': 1, '1100161002': 0, '1100161004': 0, '1100161011': 0, '1100161012': 0, '1100161013': 0, '1100161014': 0, '1100161015': 0, '1100161016': 0, '1100161020': 0, '1100161021': 0, '1100161022': 0, '1100161023': 0, '1100161028': 0, '1100161029': 0, '1100161032': 0, '1100161035': 0, '1100161036': 0, '1100161038': 0, '1100161039': 0, '1100161041': 0, '1100161043': 0, '1100161044': 0, '1100161045': 0, '1100161046': 0, '1100161048': 0, '1100161050': 0, '1100161053': 1, '1100162005': 1, '1100162007': 0, '1100162011': 0, '1100162016': 1, '1100171001': 0, '1100171002': 0, '1100171004': 1, '1100171005': 0, '1100171007': 0, '1100171008': 1, '1100171009': 0, '1100171010': 0, '1100171011': 0, '1100171012': 0, '1100171013': 0, '1100171015': 0, '1100171016': 0, '1100171017': 0, '1100171019': 0, '1100171021': 0, '1100171022': 0, '1100171023': 0, '1100171031': 0, '1100171035': 0, '1100171036': 0, '1100171038': 0, '1100171039': 0, '1100171040': 0, '1100171041': 0, '1100171043': 0, '1100171045': 0, '1100171049': 0, '1100171055': 0, '1100171056': 0, '1100171057': 0, '1100171059': 1, '1100171061': 0, '1100171063': 0, '1100171064': 0, '1100171065': 0, '1100171067': 0, '1100171069': 0, '1100171070': 0, '1100171071': 0, '1100171072': 0, '1100171073': 0, '1100171074': 0, '1100171075': 0, '1100171076': 0, '1100171077': 0, '1100171078': 0, '1100171080': 0, '1100171083': 0, '1100172003': 0, '1100172004': 0, '1100172007': 0, '1100172012': 1, '1100172013': 0, '1100172014': 0, '1100172015': 0, '1100172016': 0, '1100172017': 1, '1100172018': 0, '1100172020': 0, '1100172021': 0, '1100172022': 0, '1100172026': 0, '1100172028': 0, '1100172030': 0, '1100172032': 0, '1100172033': 1, '1100172034': 1, '1100172035': 0, '1100172037': 0, '1100172039': 0, '1100172042': 0, '1100172043': 1, '1100172047': 0, '1100172050': 0, '1100172058': 1, '1100172063': 0, '1100172066': 0, '1100411010': 0, '1100411011': 0, '1100411012': 0, '1100411013': 0, '1100411015': 0, '1100411016': 0, '1100411018': 0, '1100411020': 0, '1100411023': 0, '1100411036': 0, '1100411041': 0, '1100411045': 0, '1100411047': 0, '1100411048': 0, '1100411049': 0, '1100411050': 0, '1100411051': 0, '1100411053': 0, '1100411054': 0, '1100411055': 0, '1100411057': 0, '1100412001': 0, '1100412003': 0, '1100412010': 0, '1100412018': 1, '1100412033': 1, '1100412038': 0, '1100412039': 1, '1100412040': 0, '1110031003': 0, '1110031007': 0, '1110031010': 1, '1110031011': 0, '1110031012': 0, '1110031014': 0, '1110031019': 0, '1110031020': 0, '1110031021': 0, '1110031025': 1, '1110031027': 1, '1110031031': 0, '1110031033': 1, '1110031037': 0, '1110031038': 1, '1110031039': 0, '1110031040': 0, '1110031042': 0, '1110031048': 0, '1110031049': 0, '1110031050': 0, '1110031056': 1, '1110031061': 0, '1110031062': 0, '1110031063': 1, '1110031064': 0, '1110031065': 0, '1110032002': 0, '1110032004': 0, '1110032006': 0, '1110032008': 0, '1110032010': 0, '1110032014': 1, '1110032015': 0, '1110032018': 0, '1110032019': 0, '1110032020': 0, '1110032021': 0, '1110032022': 0, '1110032023': 0, '1110032024': 0, '1110032025': 0, '1110032027': 1, '1110032029': 0, '1110032031': 0, '1110032032': 0, '1110032033': 0, '1110032034': 0, '1110032036': 0, '1110032037': 0, '1110032042': 0, '1110032043': 1, '1110032045': 0, '1110032047': 0, '1110032048': 0, '1110032049': 0, '1110032050': 0, '1110032051': 0, '1110032052': 0, '1110032053': 0, '1110032055': 0, '1110032056': 0, '1110032058': 0, '1110032059': 0, '1110032060': 0, '1110032061': 0, '1110032062': 0, '1110032063': 0, '1813740111': 0, '1813740112': 0, '1813740115': 0, '1813740116': 0, '1813740118': 0, '1813740119': 0, '1813740122': 0, '1813740123': 0, '1813740124': 0, '1813740126': 0, '1813740127': 0, '1813740128': 0, '1813740131': 0, '1813740133': 0, '1813740135': 0, '1813740137': 0, '1813740138': 1, '1813740143': 0, '1813740144': 0, '1813740149': 0, '181374015': 0, '1813740150': 0, '1813740153': 0, '1813740155': 0, '1813740157': 0, '1813740159': 0, '181374016': 0, '1813740162': 0, '1813740164': 0, '1813740165': 0, '1813740167': 0, '1813740168': 0, '1813740169': 0, '181374017': 0, '1813740171': 0, '1813740172': 0, '1813740173': 0, '1813740174': 0, '1813740176': 0, '1813740178': 0, '1813740179': 0, '1813740180': 0, '1813740181': 0, '1813740182': 0, '1813740183': 0, '1813740184': 1, '1813740185': 1, '181374019': 0, '1813740210': 0, '1813740211': 0, '1813740212': 0, '1813740213': 0, '1813740214': 0, '1813740218': 0, '1813740219': 0, '1813740220': 0, '1813740221': 0, '1813740224': 0, '1813740225': 0, '1813740226': 0, '1813740227': 0, '1813740229': 0, '181374023': 0, '1813740231': 0, '1813740232': 0, '1813740233': 0, '1813740234': 0, '1813740235': 0, '1813740236': 0, '1813740237': 0, '1813740238': 0, '181374024': 0, '1813740240': 0, '1813740241': 0, '1813740242': 0, '1813740243': 0, '1813740245': 0, '1813740249': 0, '181374025': 0, '1813740250': 0, '1813740251': 0, '1813740252': 0, '1813740253': 0, '1813740255': 0, '1813740256': 0, '1813740257': 0, '1813740258': 0, '1813740259': 0, '181374026': 0, '1813740260': 0, '1813740261': 0, '1813740262': 0, '1813740263': 0, '1813740264': 0, '1813740265': 0, '1813740266': 0, '1813740267': 0, '1813740268': 0, '1813740269': 0, '181374027': 0, '1813740270': 0, '1813740271': 0, '1813740272': 0, '1813740273': 0, '1813740274': 0, '1813740275': 0, '1813740276': 0, '1813740277': 0, '1813740278': 0, '1813740279': 0, '181374028': 0, '181374029': 0, '2000481035': 0, '2000481036': 0, '2000481037': 0, '2000481038': 0, '2000481039': 0, '2000481040': 0, '2000481041': 0, '2000481043': 0, '2000481048': 0, '2000482008': 0, '2000482009': 0, '2000482012': 0, '2000482018': 0, '2000482021': 0, '2000482034': 0, '2000482037': 0, '2000482038': 0, '2000482039': 0, '2000482041': 0, '2000482042': 0, '2000482043': 0, '2000482044': 0, '2000482049': 0, '2000482050': 0, '2000482052': 0, '2000482059': 0, '2000482065': 0, '2000482066': 0, '2000482067': 0, '2000482068': 0, '2000482070': 0, '2000491062': 0, '2000491064': 0, '2000491065': 0, '2000491066': 0, '2000491067': 0, '2000491068': 0, '2000491070': 0, '2000491072': 0, '2000491074': 0, '2000491075': 0, '2000491076': 0, '2000491077': 1, '2000491078': 0, '2000491079': 0, '2000501001': 0, '2000501002': 0, '2000501003': 0, '2000501004': 0, '2000501006': 1, '2000501009': 0, '2000501010': 0, '2000501011': 0, '2000501012': 0, '2000501014': 0, '2000501015': 0, '2000501016': 0, '2000501018': 0, '2000501019': 0, '2000501020': 0, '2000501021': 0, '2000501023': 0, '2000501027': 0, '2000501028': 0, '2000501030': 1, '2000501031': 0, '2000501032': 0, '2000501033': 0, '2000501035': 0, '2000501036': 0, '2000501037': 0, '2000501038': 0, '2000501039': 0, '2000501040': 0, '2000501041': 0, '2000501042': 0, '2000501043': 0, '2000501044': 0, '2000501045': 0, '2000501046': 0, '2000501049': 0, '2000501050': 0, '2000501051': 0, '2000501052': 0, '2000501053': 0, '2000501054': 0, '2000501056': 0, '2000501057': 0, '2000501060': 0, '2000501061': 0, '2000501062': 0, '2000501063': 0, '2000501065': 0, '2000501066': 0, '2000501067': 0, '2000501071': 0, '2000501074': 0, '2000501075': 0, '2000501076': 0, '2000501078': 0, '2000502002': 0, '2000502005': 0, '2000502006': 0, '2000502007': 0, '2000502009': 0, '2000502010': 0, '2000502012': 0, '2000502013': 0, '2000502014': 0, '2000502015': 0, '2000502019': 0, '2000502020': 0, '2000502023': 0, '2000502025': 0, '2000502033': 0, '2000502036': 0, '2000502037': 0, '2000502039': 0, '2000502040': 0, '2000502041': 0, '2000502043': 0, '2000502044': 0, '2000502045': 0, '2000502047': 0, '2000502048': 0, '2000502049': 0, '2000502050': 0, '2000502051': 0, '2000502053': 1, '2000502054': 0, '2000502055': 0, '2000502056': 0, '2000502057': 0, '2000502058': 0, '2000502059': 0, '2000502061': 0, '2000502062': 0, '2000502063': 0, '2000502065': 1, '2000502066': 0, '2000502067': 0, '2000502069': 0, '2000502070': 0, '2000502072': 0, '2000502073': 0, '2000502075': 0, '2000502076': 0, '2000502077': 0, '2000502078': 0, '2000502081': 1, '2000502084': 0, '2000502087': 0, '2000502088': 0, '2000502090': 0, '2000541001': 0, '2000541002': 0, '2000541003': 0, '2000541006': 0, '2000541007': 0, '2000541010': 0, '2000541011': 0, '2000541014': 0, '2000541015': 0, '2000541016': 0, '2000541018': 0, '2000541019': 0, '2000541020': 0, '2000541021': 0, '2000541022': 0, '2000541023': 0, '2000541024': 0, '2000541025': 0, '2000541027': 0, '2000541028': 0, '2000541029': 0, '2000541030': 0, '2000541031': 0, '2000541032': 0, '2000541034': 0, '2000541035': 0, '2000541038': 0, '2000541039': 0, '2000541040': 0, '2000541041': 0, '2000541043': 0, '2000541044': 0, '2000541045': 0, '2000541046': 0, '2000541049': 0, '2000541050': 0, '2000541051': 0, '2000541052': 0, '2000541053': 0, '2000541054': 0, '2000541055': 0, '2000541056': 0, '2000541057': 0, '2000541059': 0, '2000541062': 0, '2000541064': 0, '2000541066': 0, '2000541067': 0, '2000541068': 0, '2000541069': 0, '2000541070': 0, '2000541071': 0, '2000541072': 0, '2000541073': 0, '2000541074': 0, '2000541075': 0, '2000541076': 0, '2000541077': 0, '2000541079': 0, '2000541080': 0, '2000541081': 0, '2000542001': 0, '2000542002': 0, '2000542007': 0, '2000542008': 0, '2000542009': 0, '2000542010': 0, '2000542013': 0, '2000542015': 0, '2000542016': 0, '2000542021': 0, '2000542022': 0, '2000542025': 0, '2000542026': 0, '2000542027': 0, '2000542029': 0, '2000542030': 0, '2000542032': 0, '2000542033': 0, '2000542034': 0, '2000542035': 0, '2000542036': 0, '2000542042': 0, '2000542049': 0, '2000542050': 0, '2000542051': 0, '2000542052': 0, '2000542054': 0, '2000542056': 0, '2026140111': 0, '2026140113': 0, '2026140116': 0, '2026140117': 0, '2026140118': 0, '2026140119': 0, '2026140120': 0, '2026140122': 0, '2026140124': 0, '2026140125': 0, '2026140126': 0, '2026140128': 0, '2026140129': 0, '2026140130': 0, '2026140131': 0, '2026140133': 0, '2026140134': 0, '2026140135': 0, '2026140138': 0, '2026140141': 0, '2026140145': 0, '2026140147': 0, '2026140149': 0, '202614015': 0, '2026140151': 0, '2026140154': 0, '2026140158': 0, '2026140159': 0, '202614016': 0, '2026140160': 0, '2026140161': 0, '2026140165': 0, '2026140169': 0, '202614017': 0, '2026140170': 0, '2026140172': 0, '202614018': 0, '202614019': 0, '202614020': 0, '202614021': 0, '2026140210': 0, '2026140212': 0, '2026140213': 0, '2026140220': 0, '2026140221': 0, '2026140223': 0, '2026140224': 0, '2026140225': 0, '202614023': 0, '2026140230': 0, '2026140233': 0, '2026140236': 0, '2026140237': 0, '2026140239': 0, '2026140241': 0, '2026140243': 0, '2026140246': 0, '2026140247': 0, '2026140249': 0, '202614025': 0, '2026140250': 0, '2026140253': 0, '2026140254': 0, '2026140255': 0, '2026140257': 1, '2026140259': 0, '2026140260': 0, '2026140263': 0, '2026140264': 1, '2026140272': 0, '2026140273': 1, '2026140275': 0, '2026140276': 0, '2026140277': 0, '2026140279': 0, '2026140281': 0, '202614029': 0, '205601011': 0, '2056010112': 0, '2056010113': 0, '2056010114': 0, '2056010116': 0, '2056010118': 0, '2056010119': 0, '205601012': 0, '2056010120': 0, '2056010122': 0, '2056010123': 0, '2056010124': 0, '2056010126': 0, '2056010130': 0, '2056010133': 0, '2056010134': 1, '2056010136': 0, '2056010137': 0, '2056010139': 0, '2056010141': 0, '2056010142': 0, '2056010148': 0, '2056010149': 0, '2056010153': 0, '2056010155': 0, '2056010156': 0, '2056010157': 0, '205601016': 0, '2056010160': 0, '2056010162': 0, '2056010164': 0, '2056010165': 0, '2056010167': 0, '205601017': 0, '205601018': 0, '2056010210': 0, '2056010212': 0, '2056010213': 0, '2056010214': 0, '2056010215': 0, '2056010218': 0, '2056010219': 0, '2056010222': 0, '2056010224': 1, '2056010225': 0, '2056010226': 0, '2056010228': 0, '2056010229': 0, '2056010230': 0, '2056010232': 0, '2056010233': 0, '2056010234': 0, '2056010235': 0, '2056010236': 0, '2056010238': 0, '2056010239': 0, '205601024': 0, '2056010240': 0, '2056010241': 0, '2056010242': 0, '2056010244': 0, '2056010245': 0, '2056010247': 0, '2056010249': 0, '205601025': 0, '2056010250': 0, '2056010252': 0, '2056010253': 0, '2056010254': 0, '2056010255': 0, '2056010258': 0, '2056010260': 0, '2056010261': 0, '2056010262': 0, '2056010263': 0, '2056010265': 0, '2056010267': 0, '2056010269': 0, '205601027': 0, '2056010272': 0, '2056010274': 0, '2056010275': 0, '2056010276': 0, '2056010277': 0, '2056010279': 0, '205601028': 0, '2056010281': 0, '2056010283': 0, '2100511002': 0, '2100511003': 0, '2100511005': 0, '2100511008': 0, '2100511011': 0, '2100511012': 0, '2100511013': 0, '2100511015': 0, '2100511016': 0, '2100511018': 0, '2100511019': 0, '2100511024': 0, '2100511026': 0, '2100511027': 0, '2100511028': 0, '2100511031': 0, '2100511032': 0, '2100511034': 0, '2100511035': 0, '2100511036': 0, '2100511038': 0, '2100511039': 0, '2100511040': 0, '2100511044': 0, '2100511048': 0, '2100511057': 0, '2100511058': 0, '2100511059': 0, '2100511060': 0, '2100511061': 0, '2100511062': 0, '2100511063': 0, '2100511064': 0, '2100511065': 0, '2100511067': 0, '2100511069': 1, '2100511070': 0, '2100511071': 0, '2100511072': 0, '2100511073': 0, '2100511074': 0, '2100511076': 0, '2100511077': 0, '2100511078': 0, '2100511079': 0, '2100511080': 0, '2100511081': 0, '2100511082': 0, '2100512001': 0, '2100512002': 0, '2100512003': 0, '2100512006': 0, '2100512007': 0, '2100512009': 0, '2100512010': 0, '2100512011': 0, '2100512012': 0, '2100512014': 0, '2100512015': 0, '2100512016': 0, '2100512017': 0, '2100512018': 0, '2100512020': 0, '2100512021': 0, '2100512025': 0, '2100512026': 0, '2100512028': 0, '2100512029': 0, '2100512032': 0, '2100512034': 0, '2100512035': 0, '2100512036': 0, '2100512037': 0, '2100512038': 0, '2100512039': 0, '2100512041': 0, '2100512042': 0, '2100512044': 0, '2100512045': 0, '2100512051': 1, '2100512052': 0, '2100512053': 0, '2100512055': 0, '2100512057': 0, '2100512058': 0, '2100512061': 0, '2100512062': 0, '2100512063': 0, '2100512064': 1, '2100512065': 0, '2100521002': 0, '2100521005': 0, '2100521006': 0, '2100521008': 0, '2100521009': 0, '2100521010': 0, '2100521013': 0, '2100521014': 0, '2100521015': 0, '2100521016': 0, '2100521017': 0, '2100521018': 0, '2100521021': 0, '2100521022': 0, '2100521023': 0, '2100521024': 0, '2100521025': 0, '2100521026': 0, '2100521027': 0, '2100521028': 0, '2100521029': 0, '2100521030': 0, '2100521031': 0, '2100521032': 1, '2100521033': 0, '2100521034': 0, '2100521035': 0, '2100521037': 0, '2100521038': 0, '2100521039': 0, '2100521040': 0, '2100521041': 0, '2100521042': 0, '2100521043': 0, '2100521044': 0, '2100521046': 0, '2100521047': 0, '2100521048': 0, '2100521049': 0, '2100521050': 0, '2100521051': 0, '2100521052': 0, '2100521054': 0, '2100521055': 0, '2100521056': 0, '2100521057': 0, '2100521059': 0, '2100521060': 0, '2100521061': 0, '2100521062': 0, '2100521063': 0, '2100521067': 0, '2100521069': 0, '2100521070': 0, '2100521072': 0, '2100521073': 0, '2100521074': 0, '2100521075': 0, '2100521076': 0, '2100521077': 0, '2100521078': 0, '2100521079': 0, '2100522001': 0, '2100522004': 0, '2100522005': 0, '2100522006': 0, '2100522007': 0, '2100522008': 0, '2100522009': 0, '2100522010': 0, '2100522011': 0, '2100522012': 0, '2100522013': 0, '2100522018': 0, '2100522019': 0, '2100522020': 0, '2100522021': 0, '2100522023': 0, '2100522024': 0, '2100522026': 0, '2100522028': 0, '2100522031': 0, '2100522033': 0, '2100522034': 0, '2100522035': 0, '2100522036': 0, '2100522038': 0, '2100522039': 0, '2100522040': 0, '2100522041': 0, '2100522042': 0, '2100522046': 0, '2100522047': 0, '2100522048': 0, '2100522049': 0, '2100522050': 0, '2100522051': 0, '2100522052': 0, '2100522053': 0, '2100522054': 0, '2100522055': 0, '2100522056': 0, '2100522059': 0, '2100522060': 0, '2100522061': 0, '2100522062': 0, '2100522063': 0, '2100522064': 0, '2100522067': 0, '2100522068': 0, '2100522070': 0, '2100531001': 0, '2100531002': 0, '2100531003': 0, '2100531004': 0, '2100531006': 0, '2100531007': 0, '2100531008': 0, '2100531009': 0, '2100531010': 0, '2100531012': 0, '2100531013': 0, '2100531014': 0, '2100531015': 0, '2100531016': 0, '2100531017': 0, '2100531018': 0, '2100531019': 0, '2100531021': 0, '2100531022': 0, '2100531023': 0, '2100531024': 0, '2100531025': 0, '2100531026': 0, '2100531027': 0, '2100531028': 0, '2100531030': 0, '2100531031': 0, '2100531033': 0, '2100531034': 0, '2100531035': 0, '2100531036': 0, '2100531037': 0, '2100531040': 0, '2100531041': 0, '2100531042': 0, '2100531043': 0, '2100531044': 0, '2100531045': 0, '2100531047': 0, '2100531048': 0, '2100531049': 0, '2100531050': 0, '2100531051': 0, '2100531052': 0, '2100531053': 0, '2100531054': 1, '2100531055': 0, '2100531056': 0, '2100531057': 0, '2100531058': 0, '2100531059': 0, '2100531060': 0, '2100531061': 0, '2100531063': 0, '2100531064': 0, '2100531065': 0, '2100531066': 0, '2100531067': 0, '2100531068': 0, '2100531070': 0, '2100531071': 0, '2100531072': 0, '2100531073': 0, '2100531074': 0, '2100531076': 0, '2100531077': 0, '2100531078': 0, '2100531079': 0, '2100531080': 0, '2100531081': 0, '2100531082': 0, '2100531084': 0, '2100532002': 0, '2100532003': 0, '2100532004': 0, '2100532005': 0, '2100532007': 0, '2100532008': 0, '2100532010': 0, '2100532012': 0, '2100532013': 0, '2100532015': 0, '2100532016': 1, '2100532017': 0, '2100532019': 0, '2100532020': 0, '2100532022': 1, '2100532023': 0, '2100532024': 0, '2100532025': 0, '2100532026': 0, '2100532027': 0, '2100532028': 0, '2100532029': 0, '2100532030': 0, '2100532031': 0, '2100532032': 0, '2100532033': 0, '2100532034': 0, '2100532037': 0, '2100532042': 0, '2100532043': 0, '2100532044': 0, '2100532045': 0, '2100532046': 0, '2100532047': 0, '2100532048': 0, '2100532050': 0, '2100532052': 0, '2100532053': 0, '2100532054': 0, '2100532055': 0, '2100532056': 0, '2100532057': 0, '2100532058': 0, '2100532059': 0, '2100532060': 0, '2100532061': 0, '2100532062': 0, '2100532063': 0, '2100532064': 0, '2100532066': 0, '2100532067': 0, '2100532068': 0, '2100532070': 0, '2100532071': 0, '2100532072': 0, '2100551002': 0, '2100551005': 1, '2100551006': 0, '2100551007': 0, '2100551010': 1, '2100551011': 0, '2100551013': 0, '2100551014': 0, '2100551015': 0, '2100551016': 0, '2100551017': 0, '2100551018': 0, '2100551019': 0, '2100551020': 0, '2100551021': 0, '2100551022': 0, '2100551023': 0, '2100551024': 0, '2100551025': 0, '2100551027': 0, '2100551028': 0, '2100551029': 0, '2100551032': 1, '2100551033': 0, '2100551034': 0, '2100551035': 1, '2100551036': 0, '2100551037': 0, '2100551039': 0, '2100551041': 0, '2100551042': 1, '2100551043': 0, '2100551044': 0, '2100551045': 0, '2100551046': 0, '2100551049': 0, '2100551050': 0, '2100551051': 0, '2100551052': 0, '2100551053': 0, '2100551054': 0, '2100551055': 0, '2100551056': 0, '2100551057': 0, '2100551059': 0, '2100551060': 0, '2100551061': 0, '2100551062': 0, '2100551063': 0, '2100551064': 0, '2100551065': 0, '2100551066': 0, '2100551067': 0, '2100551068': 0, '2100551069': 0, '2100551071': 0, '2100551072': 0, '2100551073': 0, '2100551074': 0, '2100551075': 0, '2100551076': 0, '2100551077': 0, '2100551079': 0, '2100551080': 0, '2100551081': 0, '2100552002': 0, '2100552003': 0, '2100552004': 0, '2100552005': 0, '2100552006': 0, '2100552007': 0, '2100552008': 0, '2100552009': 0, '2100552010': 0, '2100552011': 0, '2100552012': 0, '2100552013': 0, '2100552014': 0, '2100552015': 0, '2100552016': 0, '2100552017': 0, '2100552018': 0, '2100552019': 0, '2100552021': 0, '2100552022': 0, '2100552023': 0, '2100552024': 0, '2100552025': 0, '2100552027': 0, '2100552028': 0, '2100552029': 0, '2100552030': 0, '2100552031': 0, '2100552032': 0, '2100552033': 0, '2100552034': 0, '2100552035': 0, '2100552037': 0, '2100552038': 0, '2100552039': 0, '2100552041': 0, '2100552042': 0, '2100552043': 0, '2100552044': 0, '2100552045': 0, '2100552047': 0, '2100552048': 1, '2100552051': 0, '2100552052': 0, '2100552053': 0, '2100552055': 0, '2100552057': 0, '2100552059': 0, '2100552060': 0, '2100552061': 0, '2100552062': 0, '2100552063': 1, '2100552065': 0, '2100552066': 0, '2100552068': 0, '2100552072': 0, '2100561006': 0, '2100561010': 0, '2100561011': 0, '2100561013': 0, '2100561014': 0, '2100561015': 0, '2100561016': 0, '2100561018': 0, '2100561019': 0, '2100561020': 0, '2100561021': 0, '2100561022': 0, '2100561023': 0, '2100561024': 0, '2100561027': 0, '2100561029': 0, '2100561032': 0, '2100561038': 0, '2100561043': 0, '2100561044': 0, '2100561046': 0, '2100561051': 0, '2100561052': 0, '2100561053': 0, '2100561054': 0, '2100561056': 0, '2100561057': 0, '2100561058': 0, '2100561059': 0, '2100561062': 0, '2100561063': 0, '2100561064': 0, '2100561065': 0, '2100561070': 0, '2100561071': 0, '2100561074': 0, '2100561079': 0, '2100562001': 0, '2100562002': 0, '2100562003': 0, '2100562004': 0, '2100562005': 0, '2100562007': 0, '2100562008': 0, '2100562009': 0, '2100562010': 0, '2100562011': 0, '2100562012': 0, '2100562013': 0, '2100562014': 0, '2100562015': 0, '2100562017': 0, '2100562018': 0, '2100562019': 1, '2100562020': 0, '2100562024': 1, '2100562026': 0, '2100562027': 0, '2100562029': 0, '2100562030': 0, '2100562032': 0, '2100562033': 0, '2100562034': 0, '2100562035': 0, '2100562037': 0, '2100562038': 0, '2100562039': 0, '2100562040': 0, '2100562042': 0, '2100562043': 0, '2100562044': 0, '2100562046': 0, '2100562047': 0, '2100562048': 0, '2100562049': 0, '2100562050': 0, '2100562051': 0, '2100562053': 0, '2100562054': 0, '2100562055': 0, '2100562056': 0, '2100562058': 0, '2100562059': 0, '2100562060': 0, '2100562061': 0, '2100571001': 0, '2100571002': 1, '2100571004': 0, '2100571007': 1, '2100571008': 0, '2100571009': 0, '2100571011': 0, '2100571012': 0, '2100571013': 0, '2100571015': 0, '2100571017': 0, '2100571018': 0, '2100571019': 0, '2100571020': 0, '2100571021': 1, '2100571022': 0, '2100571023': 1, '2100571024': 0, '2100571025': 0, '2100571027': 0, '2100571029': 0, '2100571030': 0, '2100571031': 0, '2100571033': 0, '2100571034': 0, '2100571036': 0, '2100571038': 1, '2100571039': 0, '2100571040': 0, '2100571041': 0, '2100571042': 0, '2100571044': 1, '2100571045': 0, '2100571046': 0, '2100571047': 0, '2100571048': 0, '2100571049': 1, '2100571050': 0, '2100571051': 0, '2100571052': 0, '2100571053': 0, '2100571055': 0, '2100571056': 0, '2100571057': 0, '2100571058': 0, '2100571061': 0, '2100571062': 1, '2100571063': 0, '2100571064': 0, '2100571065': 0, '2100571066': 0, '2100571067': 0, '2100571068': 0, '2100571069': 0, '2100571070': 0, '2100571072': 0, '2100571073': 0, '2100571074': 0, '2100571075': 0, '2100571077': 0, '2100571078': 0, '2100571079': 0, '2100571081': 0, '2100571082': 0, '2100572001': 0, '2100572002': 0, '2100572004': 0, '2100572006': 0, '2100572009': 0, '2100572010': 0, '2100572011': 0, '2100572012': 0, '2100572013': 0, '2100572015': 0, '2100572017': 0, '2100572018': 0, '2100572019': 0, '2100572020': 0, '2100572021': 1, '2100572023': 0, '2100572024': 0, '2100572025': 0, '2100572026': 0, '2100572027': 0, '2100572028': 0, '2100572029': 0, '2100572030': 0, '2100572032': 0, '2100572033': 0, '2100572034': 0, '2100572036': 0, '2100572038': 0, '2100572039': 0, '2100572040': 0, '2100572041': 0, '2100572042': 0, '2100572043': 0, '2100572044': 0, '2100572045': 0, '2100572046': 0, '2100572047': 0, '2100572048': 0, '2100572050': 0, '2100572051': 0, '2100572054': 0, '2100572055': 0, '2100572056': 0, '2100572057': 1, '2100572058': 0, '2100572059': 0, '2100572060': 0, '2100572061': 0, '2100572062': 0, '2100572063': 0, '2100572064': 0, '2100572067': 0, '2100572068': 0, '2100572069': 0, '2100581001': 1, '2100581002': 0, '2100581003': 0, '2100581004': 0, '2100581005': 0, '2100581006': 0, '2100581007': 0, '2100581009': 0, '2100581010': 0, '2100581011': 0, '2100581012': 0, '2100581013': 0, '2100581014': 0, '2100581015': 0, '2100581018': 0, '2100581019': 0, '2100581021': 1, '2100581022': 0, '2100581024': 0, '2100581025': 0, '2100581026': 0, '2100581027': 0, '2100581028': 0, '2100581029': 0, '2100581030': 0, '2100581034': 0, '2100581035': 0, '2100581036': 0, '2100581037': 0, '2100581038': 0, '2100581039': 0, '2100581040': 0, '2100581041': 0, '2100581042': 0, '2100581044': 0, '2100581045': 0, '2100581051': 0, '2100581054': 0, '2100581056': 0, '2100581057': 0, '2100581058': 0, '2100581059': 0, '2100581061': 0, '2100581062': 0, '2100581064': 0, '2100581066': 0, '2100581067': 0, '2100581068': 0, '2100581069': 0, '2100581070': 0, '2100581071': 0, '2100581072': 0, '2100581073': 0, '2100581074': 0, '2100581075': 0, '2100581076': 0, '2100581077': 0, '2100582001': 0, '2100582002': 0, '2100582003': 0, '2100582004': 0, '2100582005': 0, '2100582006': 0, '2100582008': 0, '2100582009': 0, '2100582012': 0, '2100582013': 0, '2100582015': 0, '2100582017': 0, '2100582019': 0, '2100582020': 0, '2100582021': 0, '2100582023': 0, '2100582024': 0, '2100582025': 0, '2100582026': 0, '2100582027': 1, '2100582028': 0, '2100582038': 0, '2100582043': 0, '2100582044': 0, '2100582045': 0, '2100582046': 0, '2100582048': 0, '2100582050': 0, '2100582051': 0, '2100582052': 1, '2100582053': 0, '2100582054': 0, '2100582055': 1, '2100582056': 1, '2100582057': 1, '2100582058': 1, '2100582060': 1, '2100582061': 1, '2100582062': 1, '2100582064': 0, '2100582067': 0, '2100582069': 0, '2100591002': 0, '2100591003': 0, '2100591004': 0, '2100591005': 0, '2100591006': 0, '2100591007': 0, '2100591008': 0, '2100591010': 0, '2100591013': 0, '2100591015': 0, '2100591016': 0, '2100591017': 0, '2100591019': 0, '2100591020': 0, '2100591021': 0, '2100591022': 0, '2100591023': 0, '2100591025': 0, '2100591026': 0, '2100591027': 0, '2100591028': 0, '2100591030': 0, '2100591034': 0, '2100591035': 0, '2100591036': 0, '2100591037': 0, '2100591038': 0, '2100591039': 0, '2100591040': 0, '2100591041': 0, '2100591042': 0, '2100591043': 0, '2100591044': 0, '2100591045': 0, '2100591046': 1, '2100591047': 0, '2100591048': 0, '2100591049': 0, '2100591050': 0, '2100591053': 0, '2100591054': 0, '2100591055': 0, '2100591056': 0, '2100591057': 0, '2100591059': 0, '2100591060': 0, '2100591061': 0, '2100591062': 0, '2100591064': 0, '2100591065': 0, '2100591066': 0, '2100591067': 0, '2100591068': 0, '2100591069': 0, '2100591070': 0, '2100591072': 0, '2100591073': 0, '2100591074': 0, '2100591075': 0, '2100591076': 0, '2100591077': 0, '2100591078': 0, '2100591080': 0, '2100591081': 0, '2100591082': 0, '2100592002': 0, '2100592003': 0, '2100592004': 0, '2100592005': 0, '2100592007': 0, '2100592009': 0, '2100592010': 0, '2100592011': 0, '2100592012': 0, '2100592013': 0, '2100592014': 0, '2100592015': 0, '2100592016': 0, '2100592017': 0, '2100592018': 0, '2100592019': 0, '2100592020': 0, '2100592021': 0, '2100592022': 0, '2100592023': 0, '2100592024': 0, '2100592025': 0, '2100592026': 0, '2100592027': 0, '2100592028': 0, '2100592029': 0, '2100592030': 0, '2100592032': 0, '2100592033': 0, '2100592034': 0, '2100592035': 0, '2100592036': 0, '2100592038': 0, '2100592040': 0, '2100592041': 0, '2100592042': 0, '2100592043': 0, '2100592044': 0, '2100592046': 0, '2100592047': 0, '2100592048': 0, '2100592049': 0, '2100592052': 0, '2100592053': 0, '2100592054': 0, '2100592056': 0, '2100592057': 0, '2100592058': 0, '2100592059': 0, '2100592060': 0, '2100592064': 0, '2100592065': 0, '2100592066': 0, '2100592067': 0, '2100592068': 0, '2100592069': 0, '2100592070': 0, '2100592071': 0, '2100592072': 0, '2100601001': 0, '2100601002': 0, '2100601004': 0, '2100601005': 0, '2100601006': 0, '2100601007': 0, '2100601008': 0, '2100601009': 0, '2100601010': 0, '2100601011': 0, '2100601012': 1, '2100601013': 0, '2100601014': 0, '2100601015': 0, '2100601016': 0, '2100601017': 0, '2100601018': 1, '2100601020': 0, '2100601021': 0, '2100601023': 0, '2100601024': 0, '2100601025': 0, '2100601027': 0, '2100601028': 0, '2100601029': 0, '2100601030': 0, '2100601031': 0, '2100601032': 0, '2100601033': 0, '2100601035': 0, '2100601036': 0, '2100601037': 0, '2100601038': 0, '2100601039': 0, '2100601040': 0, '2100601041': 0, '2100601042': 0, '2100601043': 0, '2100601044': 0, '2100601045': 0, '2100601046': 0, '2100601049': 0, '2100601050': 0, '2100601052': 0, '2100601053': 0, '2100601054': 0, '2100601055': 0, '2100601056': 0, '2100601057': 0, '2100601059': 0, '2100601062': 0, '2100601063': 0, '2100601064': 0, '2100601065': 0, '2100601066': 0, '2100601067': 0, '2100601068': 0, '2100601069': 0, '2100601071': 0, '2100601073': 0, '2100601074': 0, '2100601075': 0, '2100601077': 0, '2100601078': 0, '2100602001': 0, '2100602002': 0, '2100602003': 0, '2100602004': 0, '2100602005': 0, '2100602006': 0, '2100602008': 0, '2100602009': 0, '2100602010': 0, '2100602011': 0, '2100602012': 0, '2100602014': 0, '2100602015': 0, '2100602017': 0, '2100602018': 0, '2100602019': 0, '2100602020': 0, '2100602022': 0, '2100602023': 0, '2100602024': 0, '2100602025': 0, '2100602026': 0, '2100602027': 0, '2100602028': 0, '2100602029': 0, '2100602030': 0, '2100602032': 0, '2100602033': 0, '2100602034': 0, '2100602035': 0, '2100602036': 0, '2100602038': 0, '2100602040': 0, '2100602041': 1, '2100602042': 0, '2100602043': 0, '2100602044': 0, '2100602046': 0, '2100602047': 0, '2100602049': 0, '2100602050': 0, '2100602051': 0, '2100602052': 0, '2100602053': 0, '2100602054': 0, '2100602056': 0, '2100602058': 0, '2100602059': 0, '2100602060': 0, '2100602061': 0, '2100602062': 0, '2100602063': 0, '2100602065': 0, '2100602067': 0, '2100602068': 0, '2100602069': 0, '2100602072': 0, '2100611002': 0, '2100611003': 0, '2100611004': 0, '2100611005': 0, '2100611006': 0, '2100611010': 0, '2100611011': 0, '2100611012': 0, '2100611013': 0, '2100611014': 0, '2100611015': 0, '2100611016': 0, '2100611017': 0, '2100611018': 0, '2100611019': 0, '2100611021': 0, '2100611023': 0, '2100611024': 0, '2100611025': 0, '2100611026': 0, '2100611027': 1, '2100611028': 0, '2100611029': 0, '2100611031': 0, '2100611032': 0, '2100611034': 0, '2100611035': 0, '2100611036': 0, '2100611037': 0, '2100611038': 0, '2100611039': 0, '2100611040': 0, '2100611041': 0, '2100611042': 0, '2100611043': 0, '2100611044': 0, '2100611045': 0, '2100611046': 0, '2100611047': 0, '2100611048': 0, '2100611049': 0, '2100611050': 0, '2100611051': 0, '2100611052': 0, '2100611055': 0, '2100611056': 0, '2100611057': 0, '2100611058': 0, '2100611059': 0, '2100611060': 0, '2100611061': 0, '2100611062': 0, '2100611063': 0, '2100611064': 0, '2100611066': 0, '2100611067': 0, '2100611068': 0, '2100611069': 0, '2100611070': 0, '2100611071': 0, '2100611075': 0, '2100611076': 0, '2100611077': 0, '2100611078': 0, '2100611079': 0, '2100611081': 0, '2100611083': 0, '2100612001': 0, '2100612002': 0, '2100612003': 0, '2100612005': 0, '2100612006': 0, '2100612007': 0, '2100612008': 0, '2100612009': 1, '2100612010': 0, '2100612011': 0, '2100612012': 0, '2100612014': 0, '2100612015': 0, '2100612020': 0, '2100612022': 0, '2100612024': 0, '2100612025': 0, '2100612026': 0, '2100612027': 0, '2100612028': 0, '2100612029': 0, '2100612030': 0, '2100612031': 0, '2100612033': 0, '2100612034': 0, '2100612035': 0, '2100612037': 0, '2100612038': 0, '2100612040': 0, '2100612041': 0, '2100612042': 0, '2100612043': 0, '2100612044': 0, '2100612045': 0, '2100612046': 0, '2100612047': 0, '2100612048': 0, '2100612051': 0, '2100612053': 0, '2100612056': 0, '2100612057': 0, '2100612058': 0, '2100612059': 0, '2100612060': 0, '2100612061': 0, '2100612062': 0, '2100612063': 0, '2100612064': 0, '2100612065': 0, '2100612066': 0, '2100612067': 0, '2100612068': 0, '2100612069': 0, '2100612070': 0, '2100612071': 0, '2100612072': 0, '2260510110': 0, '2260510113': 0, '2260510114': 0, '2260510115': 0, '2260510116': 0, '2260510118': 0, '2260510122': 0, '2260510124': 0, '2260510125': 0, '2260510126': 0, '2260510127': 0, '2260510129': 0, '226051013': 0, '2260510131': 0, '2260510134': 0, '2260510136': 0, '2260510138': 0, '2260510139': 0, '226051014': 0, '2260510140': 0, '2260510141': 0, '2260510142': 0, '2260510143': 0, '2260510146': 0, '2260510147': 0, '2260510148': 0, '2260510151': 0, '2260510152': 0, '2260510155': 1, '2260510156': 0, '2260510158': 0, '2260510159': 0, '226051016': 0, '2260510160': 0, '2260510162': 0, '2260510163': 1, '2260510167': 0, '2260510168': 0, '226051017': 0, '2260510172': 0, '2260510174': 0, '2260510176': 0, '2260510177': 1, '2260510180': 0, '2260510182': 0, '2260510183': 0, '2260510185': 0, '226051019': 0, '226051021': 0, '2260510212': 0, '2260510213': 0, '2260510214': 0, '2260510217': 0, '226051022': 0, '2260510220': 0, '2260510221': 0, '2260510222': 0, '2260510223': 0, '2260510227': 0, '2260510228': 0, '2260510229': 0, '226051023': 0, '2260510230': 0, '2260510231': 0, '2260510232': 0, '2260510233': 0, '2260510237': 0, '2260510238': 0, '2260510240': 0, '2260510241': 0, '2260510242': 0, '2260510243': 0, '2260510244': 0, '2260510247': 0, '2260510248': 0, '226051025': 0, '2260510250': 0, '2260510252': 0, '2260510253': 0, '2260510254': 0, '2260510257': 0, '2260510258': 0, '2260510259': 0, '226051026': 0, '2260510260': 0, '2260510262': 0, '2260510266': 0, '2260510267': 0, '226051027': 0, '2260510270': 0, '2260510271': 0, '2260510272': 0, '2260510276': 0, '2260510277': 0, '2260510278': 0, '240846010': 0, '240846011': 0, '2408460110': 0, '2408460111': 0, '2408460118': 1, '240846012': 0, '2408460120': 0, '2408460123': 0, '2408460125': 0, '2408460126': 0, '2408460127': 0, '2408460129': 0, '240846013': 0, '2408460130': 0, '2408460131': 0, '2408460132': 0, '2408460133': 0, '2408460134': 0, '2408460135': 0, '2408460137': 1, '2408460139': 0, '2408460143': 0, '2408460145': 0, '2408460146': 0, '2408460148': 0, '2408460149': 0, '240846015': 0, '2408460150': 0, '2408460151': 0, '2408460152': 0, '2408460154': 0, '2408460155': 0, '2408460156': 0, '2408460158': 0, '2408460159': 0, '240846016': 0, '2408460163': 0, '2408460166': 0, '240846017': 0, '240846018': 0, '240846019': 0, '2408460211': 0, '2408460212': 0, '2408460213': 0, '2408460215': 0, '2408460217': 0, '2408460219': 0, '240846022': 0, '2408460220': 0, '2408460221': 0, '2408460222': 0, '2408460223': 0, '2408460225': 0, '2408460226': 0, '2408460227': 0, '2408460229': 0, '240846023': 0, '2408460234': 0, '2408460236': 0, '2408460237': 0, '2408460238': 0, '240846024': 0, '2408460240': 0, '2408460242': 0, '2408460243': 0, '2408460244': 0, '2408460246': 0, '2408460247': 0, '2408460249': 0, '2408460252': 0, '2408460254': 0, '2408460255': 0, '2408460257': 0, '2408460260': 0, '2408460261': 0, '2408460265': 0, '2408460266': 0, '2408460268': 0, '2408460269': 0, '240846027': 0, '2408460271': 0, '2408460272': 0, '2408460274': 0, '2408460276': 0, '2408460277': 0, '2408460278': 0, '240846028': 0, '2408460280': 0, '240846029': 0, '24851011': 0, '248510111': 0, '248510112': 0, '248510114': 0, '248510116': 0, '248510117': 0, '248510118': 0, '248510119': 0, '248510120': 0, '248510125': 0, '248510127': 0, '248510128': 0, '248510129': 0, '24851013': 0, '248510131': 0, '248510136': 0, '248510137': 0, '24851014': 0, '248510142': 0, '248510147': 0, '248510148': 0, '24851015': 0, '248510150': 0, '248510151': 0, '248510153': 0, '248510155': 0, '248510156': 0, '248510157': 0, '248510160': 0, '248510161': 0, '248510163': 0, '248510164': 0, '248510167': 0, '248510170': 0, '24851018': 0, '24851019': 0, '248510211': 0, '248510212': 0, '248510213': 0, '248510214': 0, '248510215': 0, '248510216': 0, '24851022': 0, '248510220': 0, '248510223': 0, '248510225': 0, '248510227': 0, '248510229': 0, '248510230': 0, '248510232': 0, '248510233': 0, '248510235': 0, '248510236': 0, '24851024': 0, '248510241': 0, '248510242': 0, '248510245': 0, '248510246': 0, '248510248': 0, '248510249': 0, '248510250': 0, '248510251': 0, '248510253': 0, '248510255': 0, '248510256': 0, '248510259': 0, '24851026': 0, '248510260': 0, '248510262': 0, '248510264': 0, '248510265': 0, '248510267': 0, '248510268': 0, '24851027': 0, '248510271': 0, '248510272': 0, '248510273': 0, '248510276': 0, '248510278': 0, '24851028': 0, '2904280110': 0, '29042801110': 0, '29042801170': 0, '29042801180': 0, '2904280120': 0, '29042801220': 0, '29042801230': 0, '29042801250': 0, '29042801260': 0, '29042801290': 0, '29042801300': 0, '29042801320': 0, '29042801340': 0, '29042801350': 0, '29042801370': 1, '29042801390': 0, '2904280140': 0, '29042801440': 0, '29042801450': 0, '29042801470': 0, '29042801480': 0, '2904280150': 0, '29042801500': 0, '29042801550': 0, '29042801570': 0, '29042801580': 0, '2904280160': 0, '29042801600': 0, '29042801630': 0, '29042801640': 0, '29042801650': 0, '29042801680': 0, '29042801690': 0, '2904280170': 0, '29042801710': 0, '29042801740': 0, '29042801750': 0, '29042801770': 0, '29042801780': 0, '29042801790': 0, '2904280180': 0, '2904280190': 0, '29042802110': 0, '29042802140': 0, '29042802150': 0, '29042802180': 0, '29042802200': 0, '29042802220': 0, '29042802240': 0, '29042802260': 0, '29042802280': 0, '2904280230': 0, '29042802310': 0, '29042802320': 0, '29042802340': 0, '29042802350': 0, '29042802380': 0, '29042802390': 0, '29042802410': 0, '29042802420': 0, '29042802430': 0, '29042802440': 0, '29042802450': 0, '29042802460': 0, '29042802470': 0, '29042802480': 0, '2904280250': 0, '29042802500': 0, '29042802510': 0, '29042802520': 0, '29042802530': 0, '29042802560': 0, '29042802570': 0, '2904280260': 1, '29042802600': 0, '29042802640': 0, '29042802660': 0, '29042802670': 0, '29042802680': 0, '29042802690': 0, '2904280270': 0, '29042802700': 0, '29042802720': 0, '29042802740': 0, '29042802750': 0, '29042802760': 0, '29042802770': 0, '29042802790': 0, '2904280280': 0, '29042802800': 0, '29042802830': 0, '29042802860': 0, '2904280290': 0, '303830110': 0, '303830113': 1, '303830115': 0, '303830117': 0, '303830118': 0, '303830121': 0, '303830122': 0, '303830123': 0, '303830126': 1, '303830127': 0, '303830128': 0, '30383013': 0, '303830131': 0, '303830132': 0, '303830133': 0, '303830138': 0, '303830139': 1, '30383014': 0, '303830141': 0, '303830143': 0, '303830144': 0, '303830146': 0, '303830147': 0, '303830148': 0, '303830149': 1, '30383015': 0, '303830151': 0, '303830155': 1, '303830156': 0, '303830157': 0, '303830158': 0, '303830159': 0, '30383016': 0, '303830160': 0, '303830161': 0, '303830162': 0, '303830166': 0, '303830167': 0, '303830169': 0, '303830171': 0, '303830174': 0, '303830175': 0, '303830178': 0, '303830182': 0, '303830183': 0, '303830184': 0, '303830210': 0, '303830211': 0, '303830212': 0, '303830216': 0, '303830217': 0, '303830218': 0, '30383022': 0, '303830220': 0, '303830221': 0, '303830223': 0, '303830224': 0, '303830225': 0, '303830227': 0, '303830229': 0, '30383023': 1, '303830234': 0, '303830236': 0, '303830239': 0, '303830240': 0, '303830241': 0, '303830242': 0, '303830245': 0, '303830246': 0, '303830247': 0, '303830249': 0, '30383025': 0, '303830250': 0, '303830255': 0, '303830258': 0, '303830259': 0, '303830263': 0, '303830269': 0, '303830270': 0, '303830273': 0, '303830274': 0, '303830278': 0, '30383028': 0, '3100621001': 0, '3100621002': 0, '3100621003': 0, '3100621004': 0, '3100621005': 0, '3100621007': 0, '3100621009': 0, '3100621010': 0, '3100621011': 0, '3100621012': 0, '3100621013': 0, '3100621014': 0, '3100621016': 0, '3100621018': 0, '3100621019': 0, '3100621020': 0, '3100621022': 0, '3100621023': 0, '3100621024': 0, '3100621025': 0, '3100621026': 0, '3100621027': 0, '3100621028': 0, '3100621030': 0, '3100621031': 0, '3100621032': 0, '3100621033': 0, '3100621034': 0, '3100621035': 0, '3100621037': 1, '3100621039': 0, '3100621040': 0, '3100621041': 0, '3100621042': 0, '3100621043': 0, '3100621045': 0, '3100621046': 0, '3100621047': 0, '3100621048': 0, '3100621049': 0, '3100621051': 0, '3100621052': 0, '3100621053': 0, '3100621055': 0, '3100621057': 0, '3100621058': 0, '3100621059': 0, '3100621061': 0, '3100621062': 0, '3100621063': 0, '3100621064': 0, '3100622001': 0, '3100622002': 0, '3100622003': 0, '3100622006': 0, '3100622007': 0, '3100622008': 0, '3100622009': 0, '3100622011': 0, '3100622013': 0, '3100622015': 0, '3100622019': 0, '3100622020': 0, '3100622021': 0, '3100622023': 0, '3100622024': 0, '3100622026': 0, '3100622027': 0, '3100622033': 0, '3100622034': 0, '3100622036': 0, '3100622037': 0, '3100622038': 0, '3100622040': 0, '3100622041': 0, '3100622042': 0, '3100622043': 0, '3100622044': 0, '3100622045': 0, '3100622047': 0, '3100622048': 0, '3100622049': 0, '3100622051': 0, '3100622053': 0, '3100622054': 0, '3100622057': 0, '3100631001': 0, '3100631002': 0, '3100631003': 0, '3100631004': 0, '3100631005': 0, '3100631006': 0, '3100631008': 0, '3100631009': 0, '3100631010': 0, '3100631011': 0, '3100631013': 0, '3100631014': 0, '3100631015': 0, '3100631016': 0, '3100631018': 0, '3100631019': 0, '3100631022': 0, '3100631023': 0, '3100631025': 0, '3100631026': 0, '3100631027': 0, '3100631029': 0, '3100631032': 0, '3100631035': 0, '3100631037': 0, '3100631042': 0, '3100631043': 0, '3100631044': 0, '3100631045': 0, '3100631046': 0, '3100631047': 0, '3100631048': 0, '3100631049': 0, '3100631051': 0, '3100631052': 0, '3100631053': 0, '3100631054': 0, '3100631055': 0, '3100631056': 0, '3100631057': 0, '3100631058': 0, '3100631059': 0, '3100631062': 0, '3100632001': 0, '3100632002': 0, '3100632003': 0, '3100632004': 0, '3100632007': 0, '3100632008': 0, '3100632011': 0, '3100632012': 0, '3100632015': 0, '3100632016': 0, '3100632017': 0, '3100632018': 0, '3100632019': 0, '3100632021': 0, '3100632023': 0, '3100632024': 0, '3100632025': 0, '3100632026': 0, '3100632027': 0, '3100632030': 0, '3100632031': 0, '3100632039': 0, '3100632041': 0, '3100632042': 0, '3100632043': 0, '3100632044': 0, '3100632045': 0, '3100641002': 0, '3100641003': 1, '3100641004': 1, '3100641006': 1, '3100641007': 0, '3100641008': 0, '3100641023': 1, '3100642002': 0, '3100642003': 0, '3100642005': 0, '3100642006': 0, '3100642007': 1, '3100642008': 0, '3100642009': 0, '3100642011': 0, '3100642012': 0, '3100642013': 0, '3100642015': 0, '3100642017': 1, '3100642019': 0, '3100642020': 0, '3100642021': 0, '3100642022': 0, '3100642024': 0, '3100642025': 0, '3100642026': 0, '3100642027': 0, '3100642028': 0, '3100642030': 0, '3100642031': 0, '3100642032': 0, '3100642033': 0, '3100642034': 0, '3100642035': 0, '3100642036': 1, '3100642037': 0, '3100642038': 0, '3100642040': 0, '3100642045': 0, '3100642047': 0, '3100642052': 0, '3100642054': 0, '3100642055': 1, '3100642056': 0, '3100642057': 0, '3100642058': 0, '3100642060': 0, '3100642061': 0, '3100642063': 0, '3100642064': 0, '3100642066': 0, '3100642069': 0, '3100642070': 0, '3100661002': 0, '3100661007': 0, '3100661009': 0, '3100661015': 0, '3100661016': 0, '3100661022': 0, '3100661023': 0, '3100661024': 0, '3100661025': 0, '3100661027': 0, '3100661028': 0, '3100661029': 0, '3100661031': 0, '3100661032': 0, '3100661033': 0, '3100661036': 0, '3100661037': 0, '3100661038': 0, '3100661040': 0, '3100661043': 0, '3100661044': 0, '3100661046': 0, '3100661049': 0, '3100661050': 0, '3100662014': 0, '3100662015': 0, '3100662016': 0, '3100662017': 0, '3100662020': 0, '3100662022': 0, '3100662023': 0, '3100662026': 0, '3100662029': 0, '3100662032': 0, '3100662035': 0, '3100662036': 0, '3100662037': 1, '3100662045': 0, '3100662046': 0, '3100662048': 0, '3100662049': 0, '3100662050': 0, '3100662052': 0, '3100662053': 0, '3100662055': 0, '3100681001': 0, '3100681002': 0, '3100681005': 0, '3100681006': 0, '3100681015': 1, '3100681017': 1, '3100681018': 1, '3100681042': 1, '3100681043': 0, '3100681044': 0, '3100681045': 0, '3100681046': 0, '3100682001': 0, '3100682002': 0, '3100682003': 0, '3100682007': 0, '3100682008': 0, '3100682030': 0, '3100682040': 0, '3100691005': 0, '3100691006': 0, '3100691007': 0, '3100691011': 0, '3100691012': 0, '3100691021': 0, '3100691026': 0, '3100691042': 0, '3100691045': 0, '3100691048': 0, '3100692002': 0, '3100692005': 0, '3100692006': 0, '3100692007': 0, '3100692009': 0, '3100692010': 0, '3100692011': 0, '3100692012': 0, '3100692013': 0, '3100692015': 1, '3100692016': 0, '3100692020': 0, '3100692022': 0, '3100692023': 0, '3100692024': 0, '3100692025': 0, '3100692028': 0, '3100692029': 0, '3100692032': 0, '3100692034': 0, '3100692035': 0, '3100692038': 0, '3100692039': 0, '3100692045': 0, '3100692052': 0, '3100692054': 0, '3100692055': 0, '3100692056': 0, '3100701001': 0, '3100701002': 0, '3100701004': 0, '3100701005': 0, '3100701008': 0, '3100701009': 0, '3100701010': 1, '3100701011': 0, '3100701012': 0, '3100701013': 0, '3100701014': 0, '3100701015': 0, '3100701016': 0, '3100701019': 0, '3100701021': 0, '3100701022': 0, '3100701023': 1, '3100701024': 0, '3100701029': 0, '3100701031': 0, '3100701032': 0, '3100701036': 0, '3100701043': 0, '3100701044': 0, '3100701050': 0, '3100701051': 0, '3100701056': 0, '3100701057': 0, '3100701058': 0, '3100701061': 0, '3100701063': 0, '3100701072': 0, '3100701073': 0, '3100702004': 0, '3100702005': 0, '3100702006': 0, '3100702010': 0, '3100702012': 0, '3100702013': 0, '3100702016': 0, '3100702017': 0, '3100702019': 0, '3100702020': 0, '3100702021': 0, '3100702022': 0, '3100702023': 0, '3100702024': 0, '3100702025': 0, '3100702026': 0, '3100702027': 0, '3100702028': 0, '3100702029': 0, '3100702030': 0, '3100702031': 0, '3100702033': 0, '3100702034': 0, '3100702035': 0, '3100702036': 0, '3100702037': 0, '3100702038': 1, '3100702039': 0, '3100702040': 0, '3100702041': 0, '3100702043': 0, '3100702044': 0, '3100702045': 0, '3100702046': 0, '3100702047': 0, '3100702048': 0, '3100702051': 0, '3100702052': 0, '3100702054': 0, '3100702055': 0, '3100702059': 0, '3100702060': 0, '3100702061': 0, '3100702062': 0, '3100702063': 0, '3100702064': 0, '3100702065': 0, '3100702066': 0, '3100702067': 0, '3100702068': 0, '3100711007': 0, '3100711009': 0, '3100711042': 0, '3100711043': 0, '3100711049': 0, '3100711050': 0, '3100711051': 0, '3100711052': 0, '3100712014': 0, '3100721002': 0, '3100721003': 0, '3100721004': 0, '3100721005': 0, '3100721006': 0, '3100721007': 0, '3100721008': 0, '3100721011': 0, '3100721012': 0, '3100721013': 0, '3100721014': 0, '3100721015': 0, '3100721016': 0, '3100721018': 0, '3100721019': 0, '3100721020': 0, '3100721021': 0, '3100721022': 0, '3100721023': 0, '3100721024': 0, '3100721028': 0, '3100721029': 0, '3100721030': 0, '3100721031': 1, '3100721032': 0, '3100721033': 0, '3100721034': 0, '3100721036': 0, '3100721038': 0, '3100721039': 0, '3100721040': 0, '3100721041': 0, '3100721042': 0, '3100721044': 0, '3100721045': 0, '3100721046': 0, '3100721047': 0, '3100721048': 0, '3100721049': 0, '3100721050': 0, '3100721051': 0, '3100721052': 0, '3100721053': 0, '3100721054': 0, '3100721055': 0, '3100721056': 0, '3100721057': 0, '3100721058': 0, '3100721059': 0, '3100721060': 0, '3100721062': 0, '3100721063': 0, '3100721064': 0, '3100721065': 0, '3100721066': 0, '3100721068': 0, '3100721070': 0, '3100721071': 0, '3100721072': 0, '3100722003': 0, '3100722004': 0, '3100722005': 0, '3100722006': 0, '3100722007': 0, '3100722012': 0, '3100722013': 0, '3100722014': 0, '3100722016': 0, '3100722017': 0, '3100722020': 0, '3100722021': 0, '3100722022': 0, '3100722023': 0, '3100722024': 0, '3100722025': 0, '3100722026': 0, '3100722027': 0, '3100722030': 0, '3100722031': 0, '3100722032': 0, '3100722033': 0, '3100722034': 0, '3100722036': 0, '3100722038': 0, '3100722039': 0, '3100722040': 0, '3100722042': 0, '3100722044': 0, '3100722045': 0, '3100722046': 0, '3100722047': 0, '3100722048': 0, '3100722054': 0, '3100722055': 0, '3100722057': 0, '3100722059': 0, '3100722061': 0, '3100722062': 0, '3100722063': 0, '3100722064': 0, '3100722065': 0, '3100722066': 0, '3100722067': 0, '3100722068': 0, '3100722069': 0, '3100722070': 0, '3100722072': 0, '3100722073': 0, '3100722074': 0, '3100722076': 0, '3100722077': 0, '3100722078': 0, '3100722079': 0, '3100731001': 0, '3100731006': 0, '3100731007': 0, '3100731008': 0, '3100731009': 0, '3100731011': 0, '3100731012': 0, '3100731013': 0, '3100731014': 0, '3100731025': 0, '3100731026': 0, '3100731028': 0, '3100731029': 0, '3100731030': 0, '3100731031': 0, '3100731037': 0, '3100731038': 0, '3100731050': 0, '3100731052': 0, '3100731054': 0, '3100731056': 0, '3100731057': 0, '3100731058': 0, '3100732001': 0, '3100732002': 0, '3100732003': 0, '3100732006': 0, '3100732013': 0, '3100732014': 0, '3100732015': 0, '3100732017': 0, '3100732018': 0, '3100732020': 0, '3100732021': 0, '3100732022': 0, '3100732023': 0, '3100732025': 0, '3100732027': 0, '3100732028': 0, '3100732029': 0, '3100732031': 0, '3100732036': 0, '3100732040': 0, '3100732041': 0, '3100732042': 0, '3100732067': 0, '3100741001': 0, '3100741002': 0, '3100741003': 0, '3100741004': 0, '3100741011': 0, '3100741012': 0, '3100741013': 0, '3100741014': 0, '3100741016': 0, '3100741017': 0, '3100741018': 0, '3100741019': 0, '3100741020': 0, '3100741022': 0, '3100741023': 0, '3100741024': 0, '3100741025': 0, '3100741026': 0, '3100741027': 0, '3100741028': 0, '3100741029': 0, '3100741030': 0, '3100741032': 0, '3100741034': 0, '3100741035': 0, '3100741036': 0, '3100741037': 0, '3100741038': 0, '3100741039': 0, '3100741042': 0, '3100741043': 0, '3100741044': 0, '3100741045': 0, '3100741047': 0, '3100741049': 0, '3100741053': 0, '3100741054': 0, '3100741056': 0, '3100741057': 0, '3100741058': 0, '3100741059': 0, '3100741060': 0, '3100741061': 0, '3100741063': 0, '3100741064': 0, '3100741065': 0, '3100741066': 1, '3100741068': 0, '3100741069': 0, '3100741070': 0, '3100741071': 0, '3100741072': 0, '3100741073': 0, '3100741074': 0, '3100741075': 0, '3100741076': 0, '3100741077': 0, '3100741079': 0, '3100742001': 0, '3100742003': 0, '3100742004': 0, '3100742005': 0, '3100742007': 0, '3100742010': 0, '3100742011': 0, '3100742012': 0, '3100742013': 0, '3100742014': 0, '3100742015': 0, '3100742016': 0, '3100742018': 0, '3100742020': 0, '3100742021': 0, '3100742022': 0, '3100742023': 0, '3100742024': 0, '3100742025': 0, '3100742027': 0, '3100742028': 0, '3100742033': 0, '3100742034': 0, '3100742037': 0, '3100742038': 0, '3100742041': 0, '3100742042': 0, '3100742044': 0, '3100742045': 0, '3100742046': 0, '3100742047': 0, '3100742048': 0, '3100742050': 0, '3100742051': 0, '3100742052': 0, '3100742053': 0, '3100742054': 0, '3100742055': 0, '3100742056': 0, '3100742057': 0, '3100742058': 1, '3100742059': 0, '3100742060': 0, '3100742061': 0, '3100742062': 0, '3100742063': 0, '3100742065': 0, '3100742067': 0, '3100742068': 0, '3100751003': 0, '3100751004': 0, '3100751005': 0, '3100751006': 1, '3100751007': 1, '3100751008': 1, '3100751009': 0, '3100751010': 1, '3100751011': 0, '3100751012': 1, '3100751014': 0, '3100751015': 0, '3100751016': 0, '3100751017': 0, '3100751018': 0, '3100751019': 1, '3100751020': 0, '3100751021': 0, '3100751022': 0, '3100751024': 0, '3100751026': 0, '3100751027': 0, '3100751028': 0, '3100751032': 0, '3100751033': 0, '3100751034': 0, '3100751035': 0, '3100751037': 0, '3100751039': 0, '3100751040': 0, '3100751041': 0, '3100751043': 0, '3100751044': 0, '3100751045': 0, '3100751048': 0, '3100751050': 0, '3100751055': 0, '3100751056': 1, '3100751057': 1, '3100751058': 0, '3100751059': 0, '3100751063': 0, '3100751064': 0, '3100751065': 0, '3100751068': 0, '3100751069': 0, '3100751070': 0, '3100751072': 0, '3100751073': 0, '3100751074': 0, '3100751075': 0, '3100751076': 0, '3100751077': 0, '3100751078': 0, '3100751079': 0, '3100752001': 0, '3100752002': 0, '3100752003': 0, '3100752004': 0, '3100752005': 0, '3100752007': 0, '3100752008': 0, '3100752009': 0, '3100752010': 0, '3100752012': 0, '3100752014': 1, '3100752015': 0, '3100752016': 0, '3100752017': 0, '3100752018': 0, '3100752019': 0, '3100752020': 0, '3100752021': 1, '3100752022': 0, '3100752023': 0, '3100752026': 0, '3100752027': 0, '3100752029': 0, '3100752030': 1, '3100752032': 0, '3100752034': 0, '3100752035': 0, '3100752036': 0, '3100752037': 1, '3100752038': 0, '3100752039': 0, '3100752040': 0, '3100752041': 0, '3100752042': 0, '3100752043': 0, '3100752044': 0, '3100752045': 0, '3100752046': 0, '3100752047': 0, '3100752048': 1, '3100752049': 0, '3100752050': 0, '3100752051': 1, '3100752052': 0, '3100752054': 0, '3100752055': 1, '3100752056': 0, '3100752057': 0, '3100752058': 0, '3100752059': 0, '3100752060': 0, '3100752061': 0, '3100752063': 0, '3100752068': 0, '3100761003': 1, '3100761004': 0, '3100761005': 1, '3100761007': 0, '3100761008': 1, '3100761013': 0, '3100761014': 0, '3100761015': 0, '3100761016': 0, '3100761017': 0, '3100761019': 0, '3100761020': 0, '3100761021': 0, '3100761023': 0, '3100761027': 0, '3100761028': 0, '3100761029': 0, '3100761030': 0, '3100761031': 0, '3100761034': 0, '3100761042': 0, '3100761046': 0, '3100761047': 0, '3100761048': 0, '3100761049': 0, '3100761050': 0, '3100761051': 0, '3100761056': 0, '3100761062': 0, '3100761063': 0, '3100762003': 0, '3100762004': 1, '3100762005': 0, '3100762007': 0, '3100762012': 0, '3100762013': 0, '3100762016': 0, '3100762027': 1, '3100762029': 0, '3100762030': 1, '3100762052': 0, '3100762053': 0, '3100762055': 1, '3100771001': 1, '3100771002': 0, '3100771003': 0, '3100771005': 0, '3100771007': 1, '3100771008': 0, '3100771009': 0, '3100771012': 0, '3100771014': 0, '3100771016': 0, '3100771018': 0, '3100771019': 0, '3100771020': 0, '3100771021': 0, '3100771022': 0, '3100771024': 0, '3100771027': 0, '3100771028': 0, '3100771029': 0, '3100771030': 0, '3100771031': 0, '3100771032': 0, '3100771033': 0, '3100771034': 0, '3100771036': 0, '3100771037': 0, '3100771039': 0, '3100771040': 0, '3100771041': 0, '3100771042': 0, '3100771043': 0, '3100771046': 0, '3100771047': 0, '3100771048': 0, '3100771049': 0, '3100771050': 0, '3100771052': 0, '3100771054': 0, '3100771055': 0, '3100771056': 0, '3100771057': 0, '3100771058': 0, '3100771059': 0, '3100771062': 0, '3100771063': 0, '3100771064': 0, '3100771065': 0, '3100771066': 0, '3100771067': 0, '3100771068': 0, '3100771069': 0, '3100771071': 0, '3100771072': 0, '3100771073': 0, '3100771075': 0, '3100771076': 0, '3100771077': 0, '3100771078': 0, '3100771080': 0, '3100771081': 0, '3100772002': 0, '3100772004': 0, '3100772005': 0, '3100772006': 0, '3100772007': 0, '3100772008': 0, '3100772009': 0, '3100772010': 0, '3100772011': 0, '3100772013': 0, '3100772014': 0, '3100772015': 0, '3100772018': 0, '3100772019': 0, '3100772020': 0, '3100772021': 0, '3100772022': 0, '3100772023': 0, '3100772024': 0, '3100772025': 0, '3100772026': 0, '3100772027': 0, '3100772028': 0, '3100772029': 0, '3100772031': 0, '3100772032': 0, '3100772033': 0, '3100772034': 0, '3100772035': 0, '3100772036': 0, '3100772037': 0, '3100772039': 0, '3100772040': 0, '3100772041': 0, '3100772042': 0, '3100772043': 0, '3100772045': 0, '3100772046': 0, '3100772048': 0, '3100772050': 0, '3100772051': 1, '3100772052': 0, '3100772053': 0, '3100772054': 0, '3100772055': 0, '3100772056': 0, '3100772058': 0, '3100772059': 0, '3100772063': 0, '3100772065': 0, '3100772066': 0, '3100772067': 0, '3100772068': 0, '3100772069': 0, '3100781001': 0, '3100781002': 1, '3100781004': 0, '3100781006': 0, '3100781007': 1, '3100781008': 0, '3100781009': 0, '3100781010': 0, '3100781011': 0, '3100781013': 0, '3100781015': 0, '3100781016': 0, '3100781017': 0, '3100781019': 0, '3100781020': 0, '3100781021': 0, '3100781023': 0, '3100781024': 0, '3100781027': 0, '3100781029': 0, '3100781030': 0, '3100781031': 0, '3100781032': 0, '3100781033': 0, '3100781034': 1, '3100781036': 0, '3100781038': 0, '3100781040': 0, '3100781041': 0, '3100781043': 0, '3100781044': 0, '3100781046': 0, '3100781047': 0, '3100781048': 0, '3100781051': 0, '3100781052': 0, '3100781053': 0, '3100781054': 0, '3100781055': 0, '3100781056': 0, '3100781057': 0, '3100781058': 0, '3100781059': 0, '3100781061': 0, '3100781062': 0, '3100781064': 0, '3100781065': 0, '3100781066': 0, '3100781068': 0, '3100781069': 0, '3100781070': 0, '3100781071': 0, '3100781073': 0, '3100781074': 0, '3100781075': 0, '3100781076': 0, '3100781078': 0, '3100781079': 0, '3100781080': 0, '3100781081': 0, '3100782001': 0, '3100782003': 0, '3100782004': 0, '3100782005': 0, '3100782006': 0, '3100782008': 0, '3100782010': 0, '3100782011': 0, '3100782012': 0, '3100782013': 0, '3100782014': 0, '3100782015': 0, '3100782016': 0, '3100782017': 0, '3100782018': 0, '3100782019': 0, '3100782021': 0, '3100782022': 0, '3100782023': 0, '3100782024': 0, '3100782025': 0, '3100782026': 0, '3100782027': 0, '3100782028': 0, '3100782031': 0, '3100782032': 0, '3100782033': 0, '3100782035': 0, '3100782036': 0, '3100782037': 0, '3100782038': 0, '3100782039': 0, '3100782042': 0, '3100782043': 0, '3100782045': 0, '3100782046': 0, '3100782047': 0, '3100782049': 0, '3100782050': 0, '3100782053': 0, '3100782054': 0, '3100782055': 0, '3100782057': 0, '3100782058': 0, '3100782059': 0, '3100782061': 0, '3100782062': 0, '3100782063': 0, '3100782064': 0, '3100782065': 0, '3100782066': 0, '3100782067': 1, '3100782068': 0, '3100782069': 0, '3100782071': 0, '3100782072': 0, '3100791004': 0, '3100791006': 0, '3100791007': 0, '3100791008': 0, '3100791016': 0, '3100791018': 0, '3100791020': 0, '3100791021': 0, '3100791026': 0, '3100791028': 0, '3100791031': 0, '3100791033': 0, '3100791034': 0, '3100791035': 0, '3100791042': 0, '3100791044': 0, '3100791045': 0, '3100791046': 0, '3100791047': 0, '3100791049': 0, '3100791050': 0, '3100791052': 0, '3100791054': 0, '3100791056': 0, '3100791058': 1, '3100791059': 0, '3100791060': 0, '3100791061': 0, '3100791062': 0, '3100791063': 0, '3100791064': 0, '3100791065': 0, '3100791066': 0, '3100791067': 0, '3100791069': 0, '3100791070': 0, '3100791071': 0, '3100791072': 0, '3100791073': 0, '3100792002': 0, '3100792003': 0, '3100792004': 0, '3100792005': 0, '3100792006': 0, '3100792007': 0, '3100792008': 0, '3100792009': 0, '3100792010': 0, '3100792011': 0, '3100792013': 0, '3100792014': 0, '3100792015': 0, '3100792016': 0, '3100792019': 0, '3100792020': 0, '3100792021': 0, '3100792022': 0, '3100792023': 0, '3100792024': 0, '3100792025': 0, '3100792027': 0, '3100792028': 0, '3100792030': 0, '3100792031': 0, '3100792032': 0, '3100792033': 0, '3100792035': 0, '3100792036': 0, '3100792037': 0, '3100792038': 0, '3100792039': 0, '3100792040': 0, '3100792041': 0, '3100792042': 0, '3100792043': 0, '3100792044': 0, '3100792045': 1, '3100792046': 0, '3100792048': 0, '3100792050': 0, '3100792051': 0, '3100792052': 0, '3100792053': 0, '3100792057': 0, '3100792058': 0, '3100792060': 0, '3100792069': 0, '3100801006': 0, '3100802001': 0, '3100802028': 0, '3100811002': 0, '3100811018': 0, '3100811027': 0, '3100811034': 0, '3100811035': 0, '3100811036': 0, '3100811037': 0, '3100811038': 0, '3100811039': 0, '3100811040': 0, '3100811041': 0, '3100811042': 0, '3100811043': 0, '3100811045': 0, '3100811046': 0, '3100811047': 0, '3100811050': 0, '3100811051': 0, '3100811053': 0, '3100811054': 0, '3100811055': 0, '3100811056': 0, '3100811059': 0, '3100811060': 0, '3100811061': 0, '3100811063': 0, '3100811068': 0, '3100811075': 0, '3100812003': 0, '3100812004': 0, '3100812005': 0, '3100812006': 0, '3100812007': 0, '3100812008': 0, '3100812013': 0, '3100812014': 0, '3100812016': 0, '3100812017': 0, '3100812018': 0, '3100812019': 0, '3100812020': 0, '3100812021': 0, '3100812026': 0, '3100812027': 0, '3100812028': 1, '3100812040': 0, '3100821004': 0, '3100821015': 0, '3100821016': 0, '3100821019': 0, '3100821020': 0, '3100821021': 0, '3100821022': 1, '3100821030': 0, '3100821031': 0, '3100821032': 1, '3100821033': 1, '3100821034': 0, '3100821035': 0, '3100821036': 0, '3100821037': 0, '3100821038': 1, '3100821039': 0, '3100821040': 0, '3100821041': 0, '3100821042': 0, '3100821045': 0, '3100821046': 0, '3100821047': 0, '3100821048': 1, '3100821049': 0, '3100821051': 0, '3100821052': 1, '3100821054': 0, '3100821055': 0, '3100821057': 1, '3100821067': 0, '3100821068': 0, '3100821069': 1, '3100821075': 1, '3100822001': 0, '3100822011': 1, '3100822012': 0, '3100822014': 0, '3100822030': 0, '3100822031': 1, '3100822044': 0, '3100822050': 0, '3100822051': 0, '3100822057': 0, '3100822058': 0, '3100822059': 0, '3100822064': 0, '3100822065': 1, '3100822066': 1, '3100822067': 0, '3100822068': 0, '3100822069': 0, '3100822070': 0, '3100822075': 0, '3100822080': 0, '3100831003': 0, '3100831004': 0, '3100831006': 0, '3100831007': 0, '3100831008': 0, '3100831010': 0, '3100831011': 0, '3100831013': 0, '3100831014': 0, '3100831015': 0, '3100831016': 0, '3100831018': 0, '3100831019': 0, '3100831020': 0, '3100831022': 0, '3100831024': 0, '3100831026': 0, '3100831027': 0, '3100831028': 0, '3100831029': 0, '3100831032': 0, '3100831033': 0, '3100831035': 0, '3100831036': 0, '3100831037': 0, '3100831044': 0, '3100831045': 0, '3100831046': 0, '3100831047': 0, '3344630110': 0, '33446301100': 0, '33446301101': 0, '33446301103': 0, '33446301104': 0, '33446301107': 0, '3344630112': 0, '3344630113': 0, '3344630115': 0, '3344630116': 0, '3344630117': 0, '3344630119': 0, '334463012': 0, '3344630120': 0, '3344630121': 1, '3344630127': 0, '3344630130': 0, '3344630131': 1, '3344630132': 0, '3344630133': 0, '3344630136': 0, '3344630139': 0, '334463014': 0, '3344630140': 0, '3344630141': 0, '3344630142': 0, '3344630143': 0, '3344630146': 0, '3344630147': 0, '3344630148': 0, '3344630149': 0, '3344630150': 0, '3344630151': 0, '3344630153': 0, '3344630156': 0, '3344630161': 0, '3344630162': 1, '3344630163': 0, '3344630164': 0, '3344630166': 0, '3344630170': 0, '3344630171': 0, '3344630172': 0, '3344630173': 0, '3344630176': 0, '3344630179': 0, '3344630180': 0, '3344630181': 0, '3344630182': 0, '3344630184': 0, '3344630185': 0, '3344630186': 0, '3344630188': 0, '3344630189': 0, '334463019': 0, '3344630190': 0, '3344630196': 0, '3344630197': 0, '3344630198': 0, '3344630199': 0, '334463021': 0, '3344630210': 0, '3344630211': 1, '3344630213': 0, '3344630215': 0, '3344630216': 0, '3344630219': 0, '334463022': 0, '3344630220': 0, '3344630221': 0, '3344630224': 0, '3344630225': 0, '3344630226': 0, '3344630231': 0, '3344630232': 0, '3344630233': 0, '3344630236': 0, '3344630238': 0, '3344630240': 0, '3344630241': 0, '3344630242': 0, '3344630243': 0, '3344630245': 0, '3344630247': 0, '3344630248': 0, '334463025': 0, '3344630251': 0, '3344630252': 0, '3344630255': 0, '3344630257': 0, '334463026': 0, '3344630260': 0, '3344630262': 0, '3344630264': 0, '3344630265': 0, '3344630266': 0, '3344630267': 0, '334463027': 0, '3344630270': 0, '3344630271': 0, '3344630273': 0, '3344630276': 0, '3344630278': 0, '334463028': 0, '3344630280': 0, '3344630281': 0, '3344630282': 1, '334463029': 0, '33702101100': 0, '33702101110': 0, '33702101130': 0, '33702101140': 0, '33702101150': 0, '33702101180': 0, '33702101200': 0, '33702101210': 0, '33702101250': 0, '33702101260': 0, '33702101270': 0, '33702101280': 0, '33702101290': 0, '33702101300': 0, '33702101340': 0, '33702101350': 0, '33702101360': 0, '33702101370': 0, '33702101410': 0, '33702101430': 0, '33702101450': 0, '33702101460': 0, '33702101470': 0, '33702101480': 0, '33702101490': 0, '3370210150': 0, '33702101500': 0, '33702101530': 0, '33702101540': 0, '33702101550': 0, '33702101580': 0, '33702101590': 0, '33702101600': 0, '33702101620': 0, '33702101630': 0, '33702101640': 0, '33702101650': 0, '33702101660': 0, '33702101700': 0, '33702101710': 0, '33702101730': 0, '33702101740': 0, '33702101750': 0, '33702101760': 0, '3370210180': 0, '33702102100': 0, '33702102110': 0, '33702102130': 0, '33702102140': 0, '33702102160': 0, '33702102170': 0, '33702102180': 0, '33702102190': 0, '33702102200': 0, '33702102220': 0, '33702102230': 0, '33702102240': 0, '33702102250': 0, '33702102280': 0, '3370210230': 0, '33702102300': 0, '33702102310': 0, '33702102330': 0, '33702102350': 0, '33702102390': 0, '3370210240': 0, '33702102400': 0, '33702102420': 0, '33702102430': 0, '33702102470': 0, '33702102500': 0, '33702102530': 0, '33702102540': 0, '33702102550': 0, '33702102570': 0, '33702102580': 0, '33702102590': 0, '3370210260': 0, '33702102600': 0, '33702102640': 0, '33702102670': 0, '33702102690': 0, '33702102710': 0, '33702102740': 0, '3370210280': 0, '33702102820': 0, '33702102840': 0, '33702102850': 0, '33702102870': 0, '33702102880': 0, '342227010': 0, '342227011': 0, '3422270111': 1, '3422270112': 0, '3422270115': 0, '3422270116': 0, '3422270117': 0, '3422270118': 0, '3422270121': 0, '3422270122': 0, '3422270123': 0, '3422270126': 0, '3422270127': 0, '3422270128': 0, '3422270129': 1, '342227013': 0, '3422270130': 0, '3422270131': 0, '3422270133': 0, '3422270134': 0, '3422270135': 0, '3422270138': 0, '3422270139': 0, '3422270140': 0, '3422270141': 0, '3422270142': 0, '3422270143': 0, '3422270144': 0, '3422270149': 0, '3422270151': 0, '3422270152': 0, '3422270153': 0, '3422270154': 0, '3422270155': 0, '3422270157': 0, '3422270158': 0, '3422270160': 0, '3422270165': 0, '3422270166': 0, '3422270167': 1, '3422270168': 0, '3422270169': 0, '3422270171': 0, '3422270172': 0, '342227020': 0, '342227021': 0, '3422270210': 0, '3422270211': 0, '3422270212': 0, '3422270213': 0, '3422270215': 0, '3422270216': 0, '3422270217': 0, '3422270219': 0, '3422270220': 0, '3422270221': 0, '3422270222': 0, '3422270223': 0, '3422270224': 0, '3422270225': 0, '3422270227': 0, '342227023': 0, '3422270230': 0, '3422270238': 0, '3422270239': 0, '342227024': 0, '3422270240': 0, '3422270241': 0, '3422270242': 0, '3422270244': 0, '3422270245': 0, '3422270246': 0, '3422270247': 0, '3422270249': 0, '342227025': 0, '3422270250': 0, '3422270251': 0, '3422270252': 0, '3422270253': 0, '3422270254': 0, '3422270255': 0, '3422270256': 0, '3422270257': 0, '3422270261': 0, '3422270262': 0, '3422270263': 0, '3422270264': 0, '3422270267': 0, '3422270268': 0, '3422270269': 0, '342227027': 0, '3422270274': 0, '3422270278': 0, '3422270279': 0, '3422270280': 0, '3422270281': 0, '342227029': 0, '350361011': 0, '3503610110': 0, '3503610111': 0, '3503610112': 0, '3503610113': 0, '3503610114': 0, '3503610115': 0, '3503610116': 0, '3503610117': 0, '3503610118': 0, '3503610119': 0, '350361012': 0, '3503610120': 0, '3503610121': 0, '3503610122': 0, '3503610123': 0, '3503610124': 0, '3503610125': 0, '3503610126': 0, '3503610127': 0, '3503610128': 0, '3503610129': 0, '350361013': 0, '3503610130': 0, '3503610131': 0, '3503610132': 0, '3503610133': 0, '3503610134': 0, '3503610135': 0, '3503610136': 0, '3503610137': 0, '3503610138': 0, '3503610139': 0, '350361014': 0, '3503610140': 0, '3503610141': 0, '3503610142': 0, '3503610143': 0, '3503610144': 0, '3503610145': 0, '3503610146': 0, '3503610147': 0, '3503610148': 0, '3503610149': 0, '350361015': 0, '3503610150': 0, '3503610151': 0, '3503610152': 0, '3503610154': 0, '3503610156': 0, '3503610157': 0, '3503610158': 1, '350361016': 0, '3503610163': 0, '3503610168': 1, '350361017': 0, '350361019': 0, '350361021': 0, '3503610210': 0, '3503610212': 0, '3503610213': 0, '3503610214': 0, '3503610217': 0, '350361022': 0, '3503610223': 0, '3503610224': 0, '3503610225': 0, '3503610226': 0, '3503610227': 0, '3503610228': 0, '350361023': 0, '3503610230': 0, '3503610231': 0, '3503610233': 0, '3503610234': 0, '3503610235': 0, '3503610236': 0, '3503610237': 0, '3503610238': 0, '350361024': 0, '3503610240': 0, '3503610241': 0, '3503610242': 0, '3503610245': 0, '3503610246': 0, '3503610248': 0, '3503610250': 0, '3503610251': 0, '3503610252': 0, '3503610253': 0, '3503610254': 0, '3503610255': 0, '3503610256': 0, '3503610257': 0, '350361026': 0, '3503610260': 0, '3503610261': 0, '3503610264': 0, '3503610265': 0, '3503610266': 0, '3503610267': 0, '3503610268': 0, '3503610269': 0, '3503610270': 0, '3503610272': 0, '3503610273': 0, '3503610275': 0, '3503610276': 0, '3503610277': 0, '3503610278': 0, '3503610279': 0, '350361028': 1, '350361029': 0, '4000181002': 0, '4000181004': 1, '4000181005': 0, '4000181006': 0, '4000181007': 0, '4000181008': 0, '4000181010': 0, '4000181011': 0, '4000181012': 0, '4000181013': 0, '4000181014': 0, '4000181015': 1, '4000181016': 0, '4000181017': 0, '4000181019': 0, '4000181020': 0, '4000181022': 0, '4000181023': 0, '4000181024': 0, '4000181026': 0, '4000181027': 0, '4000181028': 0, '4000181029': 0, '4000181030': 0, '4000181031': 0, '4000181032': 0, '4000181033': 0, '4000181035': 0, '4000181036': 0, '4000181037': 0, '4000181039': 0, '4000181041': 0, '4000181042': 0, '4000181043': 0, '4000181044': 0, '4000181045': 0, '4000181046': 0, '4000181047': 0, '4000181048': 0, '4000181049': 0, '4000181053': 0, '4000181054': 0, '4000181055': 0, '4000181056': 0, '4000181057': 0, '4000181060': 0, '4000181061': 0, '4000181062': 0, '4000181063': 0, '4000181064': 0, '4000181065': 0, '4000181066': 0, '4000181067': 0, '4000181068': 0, '4000181069': 0, '4000181070': 0, '4000181072': 0, '4000181073': 0, '4000181074': 0, '4000181075': 0, '4000181076': 0, '4000181077': 0, '4000181078': 0, '4000181079': 0, '4000181080': 0, '4000182003': 0, '4000182004': 0, '4000182005': 0, '4000182006': 0, '4000182007': 0, '4000182008': 0, '4000182009': 0, '4000182010': 0, '4000182011': 0, '4000182013': 0, '4000182014': 0, '4000182015': 0, '4000182016': 0, '4000182017': 0, '4000182018': 0, '4000182020': 0, '4000182022': 0, '4000182024': 0, '4000182025': 0, '4000182026': 0, '4000182027': 0, '4000182028': 0, '4000182029': 0, '4000182030': 0, '4000182031': 0, '4000182032': 0, '4000182033': 0, '4000182035': 1, '4000182036': 0, '4000182037': 0, '4000182038': 0, '4000182039': 0, '4000182040': 0, '4000182041': 0, '4000182042': 0, '4000182044': 0, '4000182046': 0, '4000182047': 0, '4000182049': 0, '4000182050': 0, '4000182051': 0, '4000182053': 0, '4000182054': 0, '4000182055': 0, '4000182058': 0, '4000182059': 0, '4000182060': 0, '4000182062': 0, '4000182063': 0, '4000182064': 0, '4000182067': 0, '4000182068': 0, '4000182069': 0, '4000221001': 0, '4000221002': 0, '4000221006': 0, '4000221008': 0, '4000221009': 0, '4000221010': 0, '4000221011': 0, '4000221013': 0, '4000221014': 0, '4000221015': 0, '4000221016': 0, '4000221017': 0, '4000221018': 0, '4000221024': 0, '4000221033': 0, '4000221034': 0, '4000221035': 0, '4000221036': 0, '4000221040': 1, '4000221041': 0, '4000221042': 0, '4000221054': 0, '4000221055': 0, '4000221061': 0, '4000221062': 0, '4000221064': 0, '4000221065': 0, '4000221066': 0, '4000221067': 0, '4000221071': 0, '4000221072': 0, '4000222001': 0, '4000222003': 0, '4000222004': 0, '4000222007': 0, '4000222012': 0, '4000222013': 0, '4000222014': 0, '4000222015': 0, '4000222017': 0, '4000222031': 1, '4000222032': 1, '4000222035': 0, '4000222036': 1, '4000222038': 0, '4000222039': 0, '4000222040': 0, '4000222041': 1, '4000222042': 0, '4000222044': 0, '4000222045': 0, '4000222046': 0, '4000222051': 0, '4000222052': 0, '4000222054': 0, '4000222056': 0, '4000222057': 0, '4000222068': 0, '4000222069': 0, '4000222070': 0, '4000231001': 0, '4000231008': 0, '4000231010': 0, '4000231011': 0, '4000231012': 0, '4000231013': 0, '4000231014': 0, '4000231021': 0, '4000231032': 0, '4000231033': 0, '4000231034': 0, '4000231037': 0, '4000231038': 0, '4000231047': 0, '4000231049': 0, '4000231052': 0, '4000231060': 0, '4000231061': 0, '4000231063': 0, '4000231065': 0, '4000231070': 0, '4000231071': 0, '4000231073': 0, '4000231074': 0, '4000231081': 0, '4000232001': 0, '4000232004': 0, '4000232005': 0, '4000232006': 0, '4000232007': 0, '4000232010': 0, '4000232016': 0, '4000232017': 0, '4000232018': 0, '4000232022': 0, '4000232024': 0, '4000232027': 0, '4000232034': 0, '4000232035': 0, '4000232036': 0, '4000232037': 0, '4000232038': 0, '4000232042': 0, '4000232044': 0, '4000232045': 0, '4000232048': 0, '4000232051': 0, '4000232054': 0, '4000232059': 0, '4000232062': 0, '4000232065': 0, '4000232068': 0, '4000232071': 1, '4000232072': 0, '4000301002': 0, '4000301003': 0, '4000301005': 1, '4000301006': 1, '4000301007': 0, '4000301008': 0, '4000301010': 1, '4000301011': 1, '4000301012': 0, '4000301013': 0, '4000301014': 0, '4000301015': 0, '4000301016': 0, '4000301018': 0, '4000301019': 0, '4000301020': 0, '4000301021': 1, '4000301022': 0, '4000301023': 0, '4000301025': 0, '4000301026': 0, '4000301027': 0, '4000301028': 1, '4000301030': 1, '4000301031': 0, '4000301032': 0, '4000301034': 0, '4000301038': 0, '4000301039': 0, '4000301040': 0, '4000301041': 0, '4000301042': 1, '4000301043': 0, '4000301044': 0, '4000301045': 0, '4000301047': 0, '4000301049': 1, '4000301052': 0, '4000301053': 0, '4000301054': 0, '4000301055': 1, '4000301056': 0, '4000301057': 0, '4000301058': 0, '4000301059': 0, '4000301060': 1, '4000301061': 0, '4000301062': 0, '4000301063': 0, '4000301064': 0, '4000301065': 1, '4000301066': 1, '4000301067': 1, '4000301068': 0, '4000301069': 0, '4000301070': 1, '4000301071': 0, '4000301072': 0, '4000301073': 0, '4000301074': 0, '4000301076': 0, '4000301079': 0, '4000331001': 0, '4000331002': 0, '4000331003': 0, '4000331004': 0, '4000331005': 0, '4000331006': 0, '4000331007': 0, '4000331008': 0, '4000331011': 0, '4000331012': 0, '4000331013': 0, '4000331015': 0, '4000331017': 0, '4000331019': 0, '4000331020': 0, '4000331021': 0, '4000331022': 0, '4000331023': 0, '4000331025': 0, '4000331027': 0, '4000331029': 0, '4000331030': 0, '4000331031': 0, '4000331032': 0, '4000331033': 0, '4000331035': 0, '4000331036': 0, '4000331037': 0, '4000331038': 0, '4000331039': 0, '4000331040': 0, '4000331041': 0, '4000331042': 0, '4000331043': 0, '4000331044': 0, '4000331045': 0, '4000331046': 0, '4000331051': 0, '4000331052': 0, '4000331053': 0, '4000331054': 0, '4000331055': 0, '4000331056': 0, '4000331057': 0, '4000331058': 0, '4000331060': 0, '4000331062': 0, '4000331063': 0, '4000331064': 0, '4000331067': 0, '4000331068': 0, '4000331069': 0, '4000332001': 0, '4000332002': 0, '4000332007': 0, '4000332008': 0, '4000332009': 0, '4000332010': 0, '4000332012': 0, '4000332013': 0, '4000332014': 0, '4000332015': 0, '4000332017': 0, '4000332019': 0, '4000332020': 0, '4000332021': 0, '4000332022': 0, '4000332023': 0, '4000332025': 0, '4000332027': 0, '4000332030': 0, '4000332031': 0, '4000332032': 0, '4000332034': 0, '4000332035': 0, '4000332036': 0, '4000332037': 0, '4000332038': 0, '4000332039': 0, '4000332041': 0, '4000332044': 0, '4000332045': 0, '4000332046': 0, '4000332048': 0, '4000332050': 0, '4000332051': 0, '4000332052': 0, '4000332057': 0, '4000332059': 0, '4000332060': 0, '4000332061': 0, '4000332062': 0, '4000332063': 0, '4000332064': 0, '4000332066': 0, '4000332067': 0, '4000332068': 0, '4000332071': 0, '4000332072': 0, '4000332073': 0, '4000332074': 0, '4000332075': 0, '4000332077': 0, '4000332078': 0, '4000332079': 0, '4000332080': 0, '4000332081': 0, '4000332082': 1, '401835011': 0, '4018350112': 0, '4018350115': 0, '4018350116': 0, '4018350118': 0, '4018350119': 0, '4018350120': 0, '4018350121': 0, '4018350122': 0, '4018350126': 0, '4018350127': 0, '401835013': 0, '4018350130': 0, '4018350132': 0, '4018350134': 0, '4018350136': 0, '4018350137': 0, '4018350138': 0, '4018350139': 0, '4018350140': 0, '4018350141': 0, '4018350143': 0, '4018350144': 0, '4018350145': 0, '4018350146': 0, '4018350147': 0, '4018350149': 0, '401835015': 1, '4018350150': 0, '4018350152': 0, '4018350156': 0, '4018350157': 0, '4018350159': 0, '4018350160': 0, '4018350161': 0, '4018350162': 0, '4018350163': 0, '4018350166': 0, '4018350167': 0, '401835017': 0, '401835018': 0, '401835021': 0, '4018350213': 0, '4018350215': 0, '4018350217': 0, '4018350219': 0, '4018350220': 0, '4018350221': 0, '4018350222': 0, '4018350223': 0, '4018350224': 0, '4018350225': 0, '4018350226': 0, '4018350227': 0, '4018350231': 0, '4018350232': 0, '4018350233': 0, '4018350234': 0, '4018350236': 0, '4018350239': 0, '401835024': 0, '4018350240': 0, '4018350241': 0, '4018350244': 0, '4018350247': 0, '4018350251': 0, '4018350254': 0, '4018350256': 0, '4018350257': 0, '4018350258': 0, '4018350259': 0, '4018350260': 0, '4018350261': 0, '4018350263': 0, '4018350268': 0, '4018350269': 0, '4018350274': 0, '4018350276': 0, '4018350277': 0, '4018350279': 0, '401835028': 0, '4018350281': 0, '4018350282': 1, '4100191001': 0, '4100191002': 0, '4100191003': 0, '4100191004': 0, '4100191006': 0, '4100191007': 0, '4100191008': 1, '4100191010': 0, '4100191012': 0, '4100191014': 0, '4100191016': 0, '4100191017': 0, '4100191018': 0, '4100191020': 0, '4100191021': 0, '4100191023': 0, '4100191024': 0, '4100191025': 0, '4100191026': 0, '4100191030': 0, '4100191031': 0, '4100191032': 0, '4100191033': 1, '4100191034': 0, '4100191035': 0, '4100191038': 0, '4100191039': 0, '4100191041': 1, '4100191042': 0, '4100191043': 0, '4100191045': 0, '4100191046': 0, '4100191052': 0, '4100191053': 0, '4100192001': 0, '4100192002': 0, '4100192003': 0, '4100192004': 0, '4100192005': 0, '4100192006': 0, '4100192007': 0, '4100192010': 1, '4100192011': 1, '4100192012': 0, '4100192013': 0, '4100192014': 0, '4100192015': 1, '4100192016': 1, '4100192019': 0, '4100192020': 0, '4100192022': 0, '4100192023': 0, '4100192024': 0, '4100192025': 0, '4100192026': 1, '4100192027': 0, '4100192028': 0, '4100192029': 1, '4100192031': 1, '4100192032': 0, '4100192033': 0, '4100192034': 0, '4100192036': 0, '4100192037': 0, '4100192038': 0, '4100192039': 0, '4100192040': 0, '4100192043': 0, '4100192044': 0, '4100192045': 0, '4100192046': 0, '4100192047': 0, '4100192048': 0, '4100192049': 1, '4100192050': 0, '4100192051': 0, '4100192052': 0, '4100192053': 1, '4100192054': 0, '4100192055': 0, '4100192056': 0, '4100192057': 0, '4100192058': 0, '4100192060': 1, '4100192061': 0, '4100192062': 0, '4100192063': 0, '4100192066': 0, '4100192068': 0, '4100201001': 0, '4100201003': 0, '4100201004': 0, '4100201005': 0, '4100201006': 0, '4100201007': 0, '4100201008': 0, '4100201009': 0, '4100201010': 0, '4100201011': 0, '4100201013': 0, '4100201014': 0, '4100201016': 0, '4100201017': 0, '4100201018': 0, '4100201020': 0, '4100201021': 0, '4100201022': 0, '4100201023': 0, '4100201024': 0, '4100201025': 0, '4100201026': 0, '4100201027': 0, '4100201030': 1, '4100201031': 0, '4100201032': 1, '4100201033': 0, '4100201034': 0, '4100201035': 0, '4100201039': 1, '4100201040': 0, '4100201041': 0, '4100201042': 0, '4100201043': 1, '4100201044': 0, '4100201045': 0, '4100201046': 0, '4100201048': 0, '4100201049': 0, '4100201051': 0, '4100201052': 0, '4100201053': 0, '4100201054': 0, '4100201055': 0, '4100201056': 0, '4100201058': 0, '4100201059': 0, '4100201060': 0, '4100201061': 1, '4100201062': 0, '4100201063': 0, '4100201064': 0, '4100201068': 0, '4100201069': 0, '4100201071': 0, '4100201072': 0, '4100201073': 0, '4100201074': 0, '4100201075': 0, '4100201076': 0, '4100201078': 0, '4100201079': 0, '4100201081': 0, '4100201082': 0, '4100202001': 0, '4100202004': 0, '4100202005': 0, '4100202006': 0, '4100202007': 0, '4100202008': 0, '4100202009': 0, '4100202010': 0, '4100202011': 0, '4100202012': 0, '4100202013': 0, '4100202014': 1, '4100202015': 0, '4100202016': 0, '4100202017': 0, '4100202018': 0, '4100202019': 0, '4100202021': 0, '4100202022': 0, '4100202023': 0, '4100202024': 0, '4100202025': 0, '4100202032': 0, '4100202037': 0, '4100202039': 0, '4100202040': 0, '4100202041': 0, '4100202042': 0, '4100202043': 0, '4100202045': 0, '4100202046': 1, '4100202048': 0, '4100202052': 0, '4100202053': 0, '4100202054': 0, '4100202055': 0, '4100202056': 0, '4100202063': 0, '4100202065': 1, '4100202067': 0, '4100202068': 0, '4100241001': 0, '4100241002': 0, '4100241003': 0, '4100241004': 0, '4100241006': 0, '4100241007': 0, '4100241008': 0, '4100241009': 0, '4100241011': 0, '4100241013': 0, '4100241016': 0, '4100241017': 0, '4100241018': 0, '4100241020': 0, '4100241029': 1, '4100241030': 0, '4100241031': 0, '4100241042': 0, '4100241045': 0, '4100241046': 0, '4100241049': 0, '4100241051': 0, '4100241052': 0, '4100241053': 0, '4100241054': 0, '4100241055': 1, '4100241056': 0, '4100241059': 1, '4100241060': 0, '4100241061': 0, '4100241062': 0, '4100241063': 0, '4100241064': 0, '4100241068': 1, '4100241069': 0, '4100241075': 0, '4100242001': 0, '4100242002': 0, '4100242003': 1, '4100242004': 0, '4100242005': 0, '4100242006': 0, '4100242008': 0, '4100242011': 0, '4100242020': 0, '4100242021': 0, '4100242029': 0, '4100242031': 0, '4100242032': 1, '4100242033': 1, '4100242034': 0, '4100242035': 1, '4100242036': 0, '4100242037': 0, '4100242038': 0, '4100242040': 0, '4100242045': 0, '4100242048': 0, '4100242050': 0, '4100242053': 0, '4100242054': 0, '4100242057': 1, '4100242059': 0, '4100242060': 0, '4100242063': 1, '4100242065': 0, '4100242066': 0, '4100242067': 0, '4100251003': 0, '4100251004': 0, '4100251005': 0, '4100251006': 1, '4100251010': 0, '4100251011': 0, '4100251012': 0, '4100251013': 0, '4100251014': 0, '4100251015': 0, '4100251016': 1, '4100251017': 0, '4100251018': 0, '4100251019': 0, '4100251020': 1, '4100251021': 1, '4100251022': 0, '4100251024': 1, '4100251026': 0, '4100251027': 1, '4100251028': 1, '4100251029': 1, '4100251030': 0, '4100251031': 0, '4100251032': 1, '4100251033': 1, '4100251034': 0, '4100251035': 0, '4100251036': 1, '4100251038': 1, '4100251039': 0, '4100251040': 0, '4100251041': 1, '4100251042': 0, '4100251044': 0, '4100251046': 1, '4100251047': 0, '4100251048': 0, '4100251049': 1, '4100251051': 0, '4100251052': 0, '4100251053': 0, '4100251054': 0, '4100251056': 0, '4100251057': 1, '4100251059': 0, '4100251060': 0, '4100251061': 1, '4100251062': 0, '4100251063': 0, '4100251064': 0, '4100251065': 0, '4100251068': 1, '4100251069': 0, '4100251070': 0, '4100252001': 0, '4100252003': 0, '4100252004': 0, '4100252005': 0, '4100252007': 0, '4100252010': 0, '4100252011': 0, '4100252012': 0, '4100252013': 0, '4100252014': 0, '4100252015': 0, '4100252016': 0, '4100252019': 0, '4100252021': 0, '4100252022': 0, '4100252023': 0, '4100252024': 0, '4100252027': 0, '4100252031': 0, '4100252032': 0, '4100252033': 0, '4100252034': 0, '4100252035': 0, '4100252036': 1, '4100252037': 0, '4100252038': 0, '4100252039': 0, '4100252040': 0, '4100252041': 1, '4100252043': 0, '4100252044': 1, '4100252045': 0, '4100252048': 0, '4100252049': 0, '4100252050': 0, '4100252051': 0, '4100252053': 0, '4100252054': 0, '4100252055': 0, '4100252056': 0, '4100252057': 0, '4100252058': 0, '4100252060': 0, '4100252061': 1, '4100252062': 0, '4100252063': 0, '4100252066': 0, '4100252069': 0, '4100252070': 0, '4100252071': 0, '4100252072': 0, '4100252073': 0, '4100252074': 0, '4100252075': 0, '4100252076': 0, '4100252078': 0, '4100252081': 0, '4100261001': 0, '4100261002': 0, '4100261003': 0, '4100261004': 0, '4100261005': 1, '4100261006': 1, '4100261007': 0, '4100261010': 0, '4100261012': 0, '4100261013': 0, '4100261015': 0, '4100261016': 0, '4100261020': 0, '4100261023': 0, '4100261025': 0, '4100261027': 1, '4100261028': 0, '4100261029': 0, '4100261030': 1, '4100261031': 0, '4100261032': 0, '4100261033': 0, '4100261034': 1, '4100261035': 0, '4100261036': 0, '4100261038': 0, '4100261041': 1, '4100261044': 0, '4100261045': 0, '4100261046': 0, '4100261047': 0, '4100261048': 0, '4100261049': 0, '4100261050': 1, '4100261055': 0, '4100261056': 1, '4100261057': 0, '4100261058': 1, '4100261060': 0, '4100261061': 0, '4100262001': 0, '4100262003': 0, '4100262004': 1, '4100262006': 1, '4100262007': 0, '4100262008': 0, '4100262009': 0, '4100262010': 0, '4100262014': 0, '4100262015': 0, '4100262016': 0, '4100262017': 0, '4100262018': 0, '4100262019': 0, '4100262020': 0, '4100262022': 0, '4100262023': 0, '4100262024': 0, '4100262025': 0, '4100262027': 0, '4100262034': 1, '4100262035': 0, '4100262037': 0, '4100262038': 0, '4100262040': 0, '4100262041': 0, '4100262042': 0, '4100262043': 0, '4100262044': 0, '4100262045': 0, '4100262046': 0, '4100262047': 0, '4100262052': 0, '4100262053': 0, '4100262056': 1, '4100262057': 0, '4100262060': 0, '4100262063': 0, '4100262064': 0, '4100262065': 0, '4100262066': 0, '4100262067': 0, '4100262068': 0, '4100262069': 0, '4100262070': 0, '4100271007': 0, '4100271008': 0, '4100271009': 0, '4100271010': 0, '4100271011': 0, '4100271012': 0, '4100271026': 0, '4100271028': 0, '4100271029': 0, '4100271030': 0, '4100271032': 0, '4100271033': 0, '4100271034': 0, '4100271038': 1, '4100271039': 0, '4100271041': 1, '4100271042': 0, '4100271043': 0, '4100271056': 1, '4100272024': 0, '4100272029': 0, '4100272033': 0, '4100272034': 0, '4100272036': 0, '4100272037': 0, '4100272043': 0, '4100272051': 0, '4100272052': 0, '4100272056': 0, '4100281001': 0, '4100281002': 0, '4100281015': 0, '4100281016': 0, '4100281019': 0, '4100281022': 0, '4100281023': 0, '4100281027': 0, '4100281029': 0, '4100281030': 0, '4100281032': 1, '4100281033': 0, '4100281034': 0, '4100281035': 0, '4100281036': 0, '4100281037': 0, '4100281041': 0, '4100281042': 0, '4100281045': 0, '4100281046': 1, '4100281048': 0, '4100281049': 0, '4100281050': 0, '4100281052': 0, '4100281053': 1, '4100281054': 0, '4100281057': 0, '4100281058': 0, '4100281059': 0, '4100281060': 0, '4100281061': 0, '4100281062': 0, '4100281063': 0, '4100281066': 0, '4100281067': 1, '4100281068': 0, '4100281070': 1, '4100281072': 0, '4100281075': 0, '4100281076': 1, '4100281078': 0, '4100281079': 0, '4100281080': 0, '4100281081': 0, '4100282001': 0, '4100282002': 0, '4100282003': 0, '4100282004': 0, '4100282005': 0, '4100282007': 0, '4100282008': 0, '4100282009': 1, '4100282012': 0, '4100282013': 0, '4100282014': 0, '4100282015': 0, '4100282017': 0, '4100282018': 0, '4100282019': 0, '4100282020': 0, '4100282021': 0, '4100282022': 0, '4100282023': 0, '4100282024': 0, '4100282033': 0, '4100282043': 0, '4100282048': 0, '4100282053': 0, '4100282057': 0, '4100282058': 0, '4100282066': 1, '4100282067': 0, '4100282068': 0, '4100282070': 0, '4100291002': 0, '4100291003': 0, '4100291004': 0, '4100291005': 0, '4100291006': 1, '4100291007': 1, '4100291008': 0, '4100291009': 0, '4100291010': 1, '4100291011': 0, '4100291012': 0, '4100291014': 0, '4100291015': 0, '4100291016': 0, '4100291017': 0, '4100291018': 0, '4100291019': 1, '4100291021': 0, '4100291022': 0, '4100291025': 0, '4100291026': 1, '4100291027': 1, '4100291028': 0, '4100291032': 1, '4100291033': 0, '4100291034': 0, '4100291036': 1, '4100291037': 0, '4100291039': 0, '4100291040': 0, '4100291041': 1, '4100291043': 0, '4100291046': 0, '4100291047': 0, '4100291048': 0, '4100291049': 0, '4100291050': 0, '4100291051': 0, '4100291055': 0, '4100291056': 0, '4100291059': 0, '4100291060': 0, '4100291061': 0, '4100291062': 0, '4100291063': 0, '4100291064': 0, '4100291065': 0, '4100291070': 1, '4100291073': 1, '4100291074': 0, '4100291076': 0, '4100291077': 0, '4100291078': 1, '4100291079': 0, '4100291080': 0, '4100291081': 1, '4100291082': 1, '4100291083': 0, '4100291084': 1, '4100292001': 0, '4100292003': 0, '4100292005': 0, '4100292008': 0, '4100292010': 0, '4100292016': 0, '4100292019': 0, '4100292020': 0, '4100292021': 0, '4100292022': 0, '4100292023': 0, '4100292024': 0, '4100292025': 0, '4100292026': 0, '4100292027': 0, '4100292028': 0, '4100292035': 0, '4100292036': 0, '4100292037': 0, '4100292040': 0, '4100292041': 0, '4100292042': 0, '4100292043': 0, '4100292044': 0, '4100292045': 0, '4100292046': 0, '4100292048': 1, '4100292049': 0, '4100292050': 0, '4100292052': 0, '4100292053': 0, '4100292056': 0, '4100292057': 0, '4100292059': 0, '4100292060': 0, '4100292061': 0, '4100292062': 0, '4100292063': 0, '4100292064': 0, '4100292065': 0, '4100292066': 0, '4100292067': 0, '4100292068': 0, '4100292069': 0, '4100292070': 0, '4100292071': 0, '4100292072': 0, '4100292073': 0, '4100292074': 0, '4100292075': 0, '4100292077': 0, '4100292078': 0, '4100292079': 0, '4100292081': 0, '4100292083': 0, '4100292084': 0, '4100292085': 0, '4100292087': 0, '4100292088': 0, '4100302002': 0, '4100302013': 1, '4100302014': 0, '4100302016': 1, '4100302017': 0, '4100302018': 1, '4100302019': 0, '4100302020': 0, '4100302024': 0, '4100302028': 0, '4100302030': 1, '4100302040': 1, '4100302041': 0, '4100302042': 1, '4100302043': 1, '4100302044': 1, '4100302045': 1, '4100302046': 0, '4100302047': 0, '4100302048': 1, '4100302049': 0, '4100302050': 0, '4100302051': 0, '4100302052': 0, '4100302053': 0, '4100302054': 0, '4100302055': 1, '4100302058': 1, '4100302061': 0, '4100302063': 0, '4100302064': 1, '4100302066': 1, '4100302067': 0, '4100302068': 0, '4100302069': 0, '4100321001': 1, '4100321002': 0, '4100321003': 0, '4100321004': 0, '4100321005': 0, '4100321006': 0, '4100321008': 0, '4100321009': 1, '4100321010': 0, '4100321011': 0, '4100321012': 0, '4100321014': 0, '4100321015': 0, '4100321016': 0, '4100321019': 1, '4100321020': 0, '4100321021': 0, '4100321022': 0, '4100321023': 0, '4100321024': 0, '4100321026': 0, '4100321027': 0, '4100321028': 0, '4100321029': 0, '4100321030': 0, '4100321032': 0, '4100321033': 0, '4100321034': 0, '4100321037': 0, '4100321038': 0, '4100321039': 0, '4100321041': 0, '4100321042': 1, '4100321043': 1, '4100321044': 1, '4100321045': 0, '4100321046': 0, '4100321049': 0, '4100321051': 0, '4100321052': 0, '4100321053': 0, '4100322001': 0, '4100322007': 0, '4100322025': 0, '4100322031': 0, '4100322032': 1, '4100322033': 0, '4100322034': 0, '4100322035': 0, '4100322037': 0, '4100322038': 0, '4100322039': 0, '4100322040': 0, '4100322041': 0, '4100322042': 0, '4100322044': 0, '4100322045': 0, '4100322048': 0, '4100322051': 0, '4100322052': 0, '4100322053': 0, '4100322055': 0, '4100322056': 0, '4100322057': 0, '4100322058': 0, '4100322059': 0, '4100322060': 0, '4100322061': 0, '4110211001': 1, '4110211004': 1, '4110211005': 1, '4110211006': 0, '4110211007': 0, '4110211008': 0, '4110211009': 0, '4110211011': 0, '4110211013': 1, '4110211014': 1, '4110211015': 1, '4110211016': 0, '4110211018': 0, '4110211019': 0, '4110211020': 0, '4110211021': 1, '4110211022': 1, '4110211023': 1, '4110211024': 0, '4110211025': 1, '4110211026': 0, '4110211027': 1, '4110211028': 1, '4110211030': 0, '4110211032': 0, '4110211033': 0, '4110211034': 0, '4110211035': 0, '4110211036': 1, '4110211037': 0, '4110211038': 1, '4110211039': 1, '4110211040': 1, '4110211041': 0, '4110211043': 0, '4110211044': 0, '4110211045': 1, '4110211046': 0, '4110211047': 0, '4110211048': 0, '4110211049': 0, '4110211050': 0, '4110211051': 0, '4110211052': 0, '4110211053': 1, '4110211054': 0, '4110211055': 1, '4110211056': 0, '4110211057': 0, '4110211058': 0, '4110211060': 0, '4110211061': 1, '4110211062': 0, '4110211063': 0, '4110211064': 0, '4110211065': 0, '4110211067': 0, '4110211068': 0, '4110211072': 0, '4110211073': 0, '4110211075': 1, '4110211076': 0, '4110211078': 1, '4110211079': 0, '4110211080': 0, '4110212003': 0, '4110212004': 0, '4110212007': 0, '4110212008': 0, '4110212009': 0, '4110212010': 0, '4110212011': 0, '4110212013': 0, '4110212014': 0, '4110212015': 0, '4110212016': 0, '4110212017': 0, '4110212018': 0, '4110212019': 0, '4110212021': 0, '4110212023': 0, '4110212024': 0, '4110212026': 0, '4110212027': 0, '4110212029': 0, '4110212030': 0, '4110212033': 0, '4110212034': 1, '4110212035': 0, '4110212036': 1, '4110212038': 0, '4110212039': 0, '4110212041': 0, '4110212042': 0, '4110212044': 0, '4110212045': 0, '4110212046': 0, '4110212047': 0, '4110212049': 1, '4110212050': 0, '4110212051': 1, '4110212052': 0, '4110212053': 0, '4110212054': 0, '4110212055': 0, '4110212056': 0, '4110212059': 0, '4110212061': 0, '4110212062': 1, '4110212063': 0, '4110212064': 0, '4110212069': 0, '4110311001': 0, '4110311003': 0, '4110311004': 0, '4110311005': 0, '4110311006': 1, '4110311012': 0, '4110311015': 0, '4110311017': 0, '4110311018': 0, '4110311019': 0, '4110311020': 0, '4110311021': 0, '4110311023': 1, '4110311030': 0, '4110311031': 0, '4110311032': 0, '4110311033': 0, '4110311034': 0, '4110311036': 0, '4110311037': 0, '4110311038': 0, '4110311042': 0, '4110311043': 0, '4110311044': 0, '4110311045': 1, '4110311046': 0, '4110311048': 1, '4110311049': 0, '4110311050': 0, '4110311053': 0, '4110311054': 1, '4110311057': 0, '4110311061': 0, '4110311062': 1, '4110311064': 0, '4110311065': 0, '4110311067': 0, '4110311068': 0, '4110311072': 0, '4110312006': 0, '4110312007': 0, '4110312008': 0, '4110312009': 1, '4110312013': 0, '4110312023': 0, '4110312024': 0, '4110312025': 0, '4110312027': 0, '4110312030': 0, '4110312031': 0, '4110312048': 0, '4110312049': 0, '4110312078': 0, '414081010': 0, '414081011': 0, '4140810110': 0, '4140810114': 0, '4140810117': 0, '4140810122': 0, '4140810124': 0, '4140810125': 0, '4140810126': 0, '4140810127': 0, '4140810128': 0, '4140810129': 0, '414081013': 0, '4140810132': 0, '4140810133': 0, '4140810135': 0, '4140810136': 0, '4140810138': 0, '4140810139': 0, '4140810140': 0, '4140810142': 0, '4140810143': 0, '4140810144': 0, '4140810145': 0, '4140810146': 0, '4140810148': 0, '414081015': 0, '4140810150': 0, '4140810151': 0, '4140810152': 0, '4140810153': 1, '4140810154': 0, '4140810158': 0, '4140810159': 0, '414081016': 0, '4140810162': 1, '4140810163': 0, '4140810164': 0, '4140810165': 0, '414081017': 0, '4140810171': 0, '4140810173': 0, '4140810175': 0, '4140810176': 0, '4140810179': 0, '414081018': 0, '4140810180': 0, '4140810181': 0, '4140810182': 0, '4140810183': 0, '4140810184': 0, '4140810185': 0, '414081019': 0, '414081021': 0, '4140810210': 1, '4140810211': 0, '4140810212': 0, '4140810215': 0, '4140810217': 1, '4140810219': 1, '4140810220': 0, '4140810221': 0, '4140810222': 0, '4140810223': 0, '4140810224': 0, '4140810225': 0, '4140810226': 0, '4140810228': 0, '4140810229': 0, '414081023': 0, '4140810230': 0, '4140810233': 0, '4140810234': 0, '4140810237': 0, '4140810239': 0, '4140810240': 0, '4140810242': 0, '4140810244': 0, '4140810246': 0, '4140810247': 0, '4140810249': 0, '414081025': 0, '4140810250': 0, '4140810251': 0, '4140810252': 0, '4140810253': 0, '4140810254': 0, '4140810255': 0, '4140810256': 0, '4140810257': 0, '4140810258': 0, '4140810259': 0, '414081026': 0, '4140810264': 0, '4140810265': 0, '4140810266': 0, '4140810268': 0, '4140810269': 0, '414081027': 0, '4140810270': 0, '4140810271': 0, '4140810272': 1, '4140810273': 0, '4140810274': 0, '4140810276': 0, '4140810277': 0, '4140810278': 0, '4140810279': 0, '414081028': 0, '4140810280': 0, '414081029': 0, '459999011': 0, '4599990110': 0, '4599990112': 0, '4599990113': 0, '4599990114': 0, '4599990116': 0, '4599990117': 0, '4599990118': 0, '4599990119': 0, '459999012': 0, '4599990120': 0, '4599990125': 0, '4599990126': 0, '4599990128': 0, '4599990129': 0, '459999013': 0, '4599990130': 0, '4599990131': 0, '4599990132': 1, '4599990133': 0, '4599990134': 0, '4599990136': 0, '4599990137': 0, '4599990139': 0, '4599990141': 0, '4599990144': 0, '4599990146': 0, '4599990148': 0, '4599990149': 0, '4599990153': 0, '4599990154': 0, '4599990155': 0, '459999016': 0, '4599990163': 0, '4599990165': 0, '4599990166': 0, '4599990168': 0, '459999017': 0, '4599990171': 0, '459999021': 0, '4599990211': 0, '4599990212': 0, '4599990214': 0, '4599990216': 0, '4599990218': 0, '459999022': 0, '4599990221': 0, '4599990222': 0, '4599990223': 0, '4599990224': 0, '4599990226': 0, '4599990231': 0, '4599990233': 0, '4599990234': 0, '4599990235': 1, '4599990238': 0, '459999024': 0, '4599990240': 0, '4599990241': 0, '4599990243': 0, '4599990244': 0, '4599990245': 0, '4599990246': 0, '4599990247': 0, '4599990248': 0, '4599990249': 0, '459999025': 0, '4599990253': 0, '4599990254': 0, '4599990255': 0, '4599990256': 0, '4599990263': 0, '4599990264': 0, '4599990269': 0, '4599990270': 0, '4599990272': 0, '4599990273': 0, '4599990274': 0, '4599990275': 0, '4599990276': 0, '459999028': 0, '4599990283': 0, '5000391001': 0, '5000391002': 0, '5000391004': 0, '5000391005': 0, '5000391007': 0, '5000391008': 0, '5000391010': 0, '5000391012': 0, '5000391013': 0, '5000391014': 0, '5000391015': 0, '5000391016': 0, '5000391017': 1, '5000391019': 0, '5000391020': 0, '5000391022': 0, '5000391023': 0, '5000391024': 0, '5000391026': 0, '5000391028': 0, '5000391029': 0, '5000391030': 0, '5000391031': 0, '5000391032': 0, '5000391034': 0, '5000391035': 0, '5000391036': 0, '5000391037': 0, '5000391038': 0, '5000391040': 0, '5000391045': 1, '5000391046': 0, '5000391047': 0, '5000391049': 0, '5000391050': 0, '5000391054': 0, '5000391055': 1, '5000391056': 1, '5000391059': 0, '5000391060': 1, '5000391061': 0, '5000391062': 0, '5000391063': 0, '5000391064': 0, '5000391065': 0, '5000391066': 0, '5000391067': 0, '5000391068': 0, '5000391069': 0, '5000391070': 0, '5000391071': 0, '5000391072': 0, '5000391073': 0, '5000391074': 0, '5000391076': 0, '5000391078': 0, '5000391079': 0, '5000391080': 0, '5000391081': 0, '5000392001': 0, '5000392002': 0, '5000392003': 0, '5000392006': 0, '5000392007': 0, '5000392010': 0, '5000392011': 0, '5000392015': 0, '5000392016': 0, '5000392017': 0, '5000392018': 0, '5000392019': 0, '5000392020': 0, '5000392021': 0, '5000392022': 0, '5000392025': 0, '5000392026': 0, '5000392027': 0, '5000392029': 0, '5000392033': 1, '5000392035': 0, '5000392036': 0, '5000392038': 0, '5000392039': 0, '5000392040': 0, '5000392041': 0, '5000392042': 0, '5000392044': 0, '5000392047': 0, '5000392048': 0, '5000392049': 0, '5000392050': 0, '5000392051': 0, '5000392052': 1, '5000392053': 0, '5000392054': 0, '5000392055': 0, '5000392056': 0, '5000392058': 0, '5000392060': 1, '5000392062': 0, '5000392063': 0, '5000392064': 0, '5000392065': 0, '5000392066': 0, '5000392067': 0, '5000392070': 0, '5000392071': 0, '5000392072': 0, '5000431019': 0, '5000431020': 0, '5000431021': 0, '5000431022': 0, '5000431023': 0, '5000431025': 0, '5000431026': 0, '5000431049': 0, '5000431050': 0, '5000432001': 0, '5000432003': 0, '5000432006': 0, '5000432059': 0, '5000441001': 0, '5000441002': 0, '5000441003': 0, '5000441005': 0, '5000441006': 0, '5000441007': 0, '5000441008': 0, '5000441009': 0, '5000441010': 0, '5000441012': 0, '5000441013': 0, '5000441014': 0, '5000441015': 0, '5000441016': 0, '5000441017': 0, '5000441018': 0, '5000441021': 0, '5000441022': 0, '5000441023': 0, '5000441024': 1, '5000441027': 0, '5000441030': 0, '5000441031': 0, '5000441032': 0, '5000441033': 0, '5000441034': 0, '5000441035': 0, '5000441037': 0, '5000441038': 0, '5000441039': 0, '5000441040': 0, '5000441041': 0, '5000441042': 0, '5000441043': 0, '5000441044': 0, '5000441045': 0, '5000441046': 0, '5000441047': 0, '5000441048': 0, '5000441050': 0, '5000441051': 0, '5000441052': 0, '5000441053': 0, '5000441054': 0, '5000441055': 0, '5000441058': 1, '5000441059': 0, '5000441061': 0, '5000441062': 0, '5000441064': 0, '5000441065': 0, '5000441066': 0, '5000441067': 1, '5000441068': 0, '5000441069': 0, '5000441070': 0, '5000441071': 0, '5000441072': 0, '5000442001': 0, '5000442002': 0, '5000442003': 0, '5000442004': 0, '5000442005': 0, '5000442007': 0, '5000442008': 0, '5000442009': 0, '5000442010': 0, '5000442014': 0, '5000442015': 0, '5000442016': 0, '5000442019': 0, '5000442021': 0, '5000442022': 0, '5000442024': 0, '5000442025': 0, '5000442026': 0, '5000442027': 0, '5000442028': 0, '5000442029': 0, '5000442033': 0, '5000442034': 0, '5000442035': 0, '5000442036': 0, '5000442037': 0, '5000442038': 0, '5000442039': 0, '5000442040': 0, '5000442042': 0, '5000442043': 0, '5000442045': 0, '5000442047': 0, '5000442048': 0, '5000442050': 0, '5000442051': 0, '5000442052': 0, '5000442053': 0, '5000442054': 0, '5000442055': 0, '5000442056': 0, '5000442057': 0, '5000442058': 0, '5000442059': 0, '5000442060': 0, '5000442062': 0, '5000442063': 0, '5000442064': 0, '5000442065': 0, '5000442066': 0, '5000442067': 0, '5000442068': 0, '5000442069': 0, '5000442070': 0, '5000442072': 0, '5000442073': 0, '5000442074': 0, '5000442075': 0, '5000442076': 0, '5000442077': 0, '5000442078': 0, '5000671001': 0, '5000671002': 0, '5000671003': 0, '5000671004': 0, '5000671005': 0, '5000671006': 0, '5000671008': 0, '5000671009': 0, '5000671010': 0, '5000671011': 0, '5000671012': 0, '5000671013': 0, '5000671014': 0, '5000671015': 0, '5000671016': 0, '5000671017': 0, '5000671018': 0, '5000671019': 0, '5000671020': 0, '5000671022': 0, '5000671023': 0, '5000671024': 0, '5000671026': 0, '5000671027': 0, '5000671028': 0, '5000671029': 0, '5000671030': 0, '5000671031': 0, '5000671032': 0, '5000671033': 0, '5000671034': 0, '5000671035': 0, '5000671036': 0, '5000671037': 0, '5000671038': 0, '5000671039': 0, '5000671040': 0, '5000671041': 1, '5000671042': 1, '5000671043': 0, '5000671046': 0, '5000671047': 0, '5000671048': 1, '5000671049': 1, '5000671050': 0, '5000671051': 0, '5000671053': 0, '5000671055': 0, '5000671056': 0, '5000671057': 0, '5000671058': 1, '5000671059': 0, '5000671060': 0, '5000671061': 1, '5000671062': 0, '5000671063': 0, '5000671064': 0, '5000671065': 0, '5000671066': 0, '5000671067': 0, '5000671069': 1, '5000671070': 1, '5000671071': 0, '5000672002': 0, '5000672004': 0, '5000672005': 0, '5000672006': 0, '5000672007': 0, '5000672008': 0, '5000672010': 0, '5000672011': 0, '5000672012': 0, '5000672013': 0, '5000672014': 0, '5000672016': 0, '5000672017': 0, '5000672019': 0, '5000672020': 0, '5000672021': 0, '5000672022': 0, '5000672023': 0, '5000672024': 0, '5000672025': 0, '5000672026': 0, '5000672027': 0, '5000672030': 0, '5000672031': 0, '5000672033': 0, '5000672034': 0, '5000672035': 0, '5000672036': 0, '5000672038': 0, '5000672042': 0, '5000672043': 0, '5000672044': 0, '5000672045': 0, '5000672046': 0, '5000672047': 0, '5000672048': 0, '5000672049': 0, '5000672050': 0, '5000672051': 0, '5000672052': 0, '5000672053': 0, '5000672054': 0, '5000672055': 0, '5000672056': 0, '5000672057': 0, '5000672058': 0, '5000672059': 0, '5000672060': 0, '5000672062': 0, '5000672064': 0, '5000672065': 0, '5000672066': 0, '5000672067': 0, '5000672068': 0, '5000672070': 0, '5000672071': 0, '5000672072': 0, '5000672074': 0, '5000672075': 0, '5000672076': 0, '5000672077': 0, '5000672081': 0, '5000672082': 0, '5000951001': 0, '5000951002': 0, '5000951003': 0, '5000951004': 0, '5000951005': 0, '5000951006': 0, '5000951007': 0, '5000951008': 0, '5000951009': 0, '5000951010': 0, '5000951011': 0, '5000951012': 0, '5000951013': 0, '5000951015': 0, '5000951016': 0, '5000951017': 0, '5000951018': 0, '5000951019': 1, '5000951021': 0, '5000951023': 1, '5000951024': 1, '5000951025': 0, '5000951027': 1, '5000951028': 0, '5000951033': 0, '5000951034': 0, '5000951035': 0, '5000951037': 0, '5000951039': 0, '5000951040': 0, '5000951042': 0, '5000951043': 0, '5000951044': 0, '5000951045': 0, '5000951047': 0, '5000951049': 0, '5000951051': 0, '5000951052': 0, '5000951053': 0, '5000951054': 0, '5000951055': 0, '5000951056': 0, '5000951057': 0, '5000951058': 0, '5000951060': 0, '5000951061': 0, '5000951062': 0, '5000951063': 0, '5000951065': 0, '5000951066': 0, '5000951067': 0, '5000952002': 0, '5000952003': 0, '5000952004': 0, '5000952005': 0, '5000952007': 0, '5000952008': 0, '5000952011': 0, '5000952013': 0, '5000952014': 0, '5000952015': 0, '5000952016': 0, '5000952017': 0, '5000952018': 0, '5000952020': 0, '5000952021': 0, '5000952022': 0, '5000952023': 0, '5000952024': 0, '5000952025': 0, '5000952026': 0, '5000952027': 0, '5000952028': 0, '5000952029': 0, '5000952031': 0, '5000952032': 0, '5000952033': 0, '5000952034': 1, '5000952035': 0, '5000952036': 0, '5000952038': 0, '5000952040': 0, '5000952041': 0, '5000952042': 0, '5000952044': 0, '5000952045': 0, '5000952046': 0, '5000952048': 0, '5000952050': 0, '5000952052': 0, '5000952053': 0, '5000952054': 0, '5000952055': 0, '5000952060': 0, '5000952061': 0, '5000952062': 1, '5000952063': 0, '5000952064': 0, '5000952065': 0, '5000952066': 0, '5000952068': 0, '5000952069': 0, '5000952070': 0, '5000952071': 0, '5000952072': 0, '5000952073': 0, '5000952075': 0, '5000952076': 0, '5000952077': 0, '5000952078': 0, '5000952080': 0, '5000952083': 1, '5100091001': 0, '5100091003': 0, '5100091004': 0, '5100091005': 0, '5100091006': 0, '5100091007': 0, '5100091008': 0, '5100091009': 0, '5100091010': 0, '5100091012': 0, '5100091017': 0, '5100091019': 0, '5100091020': 0, '5100091025': 0, '5100091026': 0, '5100091027': 0, '5100091028': 0, '5100091032': 0, '5100091033': 0, '5100091034': 0, '5100091035': 0, '5100091036': 0, '5100091038': 0, '5100091039': 0, '5100091042': 0, '5100091046': 0, '5100091049': 1, '5100091050': 0, '5100091051': 0, '5100091053': 0, '5100091055': 0, '5100091056': 0, '5100091057': 0, '5100091058': 0, '5100091059': 0, '5100091062': 0, '5100091064': 0, '5100091065': 0, '5100091066': 0, '5100091067': 0, '5100091068': 0, '5100091069': 0, '5100092002': 0, '5100092003': 0, '5100092005': 0, '5100092006': 0, '5100092008': 0, '5100092010': 0, '5100092011': 0, '5100092013': 0, '5100092017': 0, '5100092019': 0, '5100092021': 0, '5100092022': 0, '5100092023': 0, '5100092026': 0, '5100092027': 0, '5100092032': 0, '5100092033': 0, '5100092034': 0, '5100092035': 0, '5100092037': 0, '5100092038': 0, '5100092039': 0, '5100092040': 0, '5100092041': 0, '5100092042': 0, '5100092043': 0, '5100092044': 0, '5100092045': 0, '5100092053': 0, '5100092056': 0, '5100092057': 0, '5100092060': 0, '5100092061': 0, '5100092062': 0, '5100092063': 0, '5100092064': 0, '5100092065': 0, '5100092067': 0, '5100092068': 0, '5100092069': 0, '5100092071': 0, '5100092072': 0, '5100341002': 0, '5100341003': 0, '5100341004': 0, '5100341005': 0, '5100341006': 0, '5100341008': 0, '5100341009': 0, '5100341010': 0, '5100341012': 0, '5100341013': 0, '5100341014': 0, '5100341015': 0, '5100341016': 0, '5100341017': 0, '5100341019': 0, '5100341020': 0, '5100341021': 0, '5100341022': 0, '5100341023': 0, '5100341024': 0, '5100341025': 0, '5100341026': 0, '5100341027': 0, '5100341028': 0, '5100341030': 0, '5100341031': 0, '5100341032': 0, '5100341033': 0, '5100341034': 0, '5100341035': 0, '5100341037': 0, '5100341038': 0, '5100341039': 0, '5100341042': 0, '5100341043': 1, '5100341046': 0, '5100341048': 0, '5100341050': 0, '5100341052': 0, '5100341054': 0, '5100341055': 0, '5100341056': 0, '5100341057': 0, '5100341058': 0, '5100341061': 0, '5100341062': 0, '5100341065': 0, '5100341067': 0, '5100341068': 0, '5100341070': 0, '5100341071': 0, '5100341072': 0, '5100341074': 1, '5100341075': 0, '5100341076': 0, '5100341077': 0, '5100341078': 0, '5100341079': 0, '5100342002': 0, '5100342003': 0, '5100342007': 0, '5100342008': 0, '5100342009': 0, '5100342012': 0, '5100342016': 0, '5100342017': 0, '5100342018': 0, '5100342020': 0, '5100342022': 1, '5100342023': 1, '5100342024': 1, '5100342025': 0, '5100342028': 1, '5100342030': 0, '5100342031': 0, '5100342034': 0, '5100342036': 1, '5100342042': 0, '5100342043': 0, '5100342045': 0, '5100342048': 1, '5100351001': 1, '5100351002': 1, '5100351004': 0, '5100351005': 0, '5100351007': 0, '5100351009': 0, '5100351010': 0, '5100351012': 0, '5100351013': 1, '5100351015': 0, '5100351016': 0, '5100351019': 0, '5100351020': 0, '5100351021': 0, '5100351022': 1, '5100351023': 0, '5100351024': 0, '5100351025': 0, '5100351026': 0, '5100351032': 0, '5100351034': 0, '5100351035': 0, '5100351036': 0, '5100351038': 0, '5100351039': 0, '5100351040': 0, '5100351042': 1, '5100351043': 0, '5100351044': 0, '5100351045': 0, '5100351046': 0, '5100351049': 0, '5100351051': 0, '5100351054': 0, '5100351058': 0, '5100352001': 0, '5100352002': 0, '5100352003': 0, '5100352004': 0, '5100352005': 0, '5100352006': 0, '5100352007': 0, '5100352008': 0, '5100352009': 0, '5100352011': 0, '5100352012': 0, '5100352013': 0, '5100352014': 0, '5100352015': 0, '5100352016': 0, '5100352017': 0, '5100352018': 0, '5100352020': 0, '5100352021': 0, '5100352022': 1, '5100352026': 0, '5100352027': 0, '5100352028': 0, '5100352030': 0, '5100352031': 0, '5100352032': 0, '5100352033': 0, '5100352034': 0, '5100352035': 0, '5100352037': 0, '5100352038': 0, '5100352039': 0, '5100352041': 0, '5100352042': 0, '5100352043': 1, '5100352044': 0, '5100352045': 0, '5100352046': 0, '5100352049': 0, '5100352050': 0, '5100352051': 0, '5100352052': 0, '5100352054': 1, '5100352055': 0, '5100352056': 0, '5100352057': 0, '5100352060': 0, '5100352061': 0, '5100352063': 0, '5100361009': 0, '5100361056': 0, '5100362028': 0, '5100362029': 0, '5100362030': 0, '5100362052': 0, '5100371022': 0, '5100371023': 0, '5100371024': 0, '5100371026': 0, '5100371027': 0, '5100371042': 0, '5100371055': 0, '5100371056': 0, '5100371067': 0, '5100371079': 0, '5100372001': 0, '5100372002': 0, '5100372003': 0, '5100372005': 0, '5100372006': 0, '5100372007': 0, '5100372009': 0, '5100372011': 0, '5100372015': 0, '5100372016': 0, '5100372017': 0, '5100372018': 0, '5100372019': 0, '5100372020': 0, '5100372021': 0, '5100372022': 0, '5100372023': 0, '5100372026': 0, '5100372027': 0, '5100372028': 0, '5100372069': 0, '5100381002': 0, '5100381003': 0, '5100381004': 0, '5100381005': 0, '5100381006': 0, '5100381007': 0, '5100381008': 0, '5100381009': 0, '5100381010': 0, '5100381011': 0, '5100381012': 0, '5100381015': 0, '5100381016': 0, '5100381017': 0, '5100381018': 0, '5100381019': 0, '5100381020': 0, '5100381021': 0, '5100381022': 0, '5100381023': 0, '5100381024': 0, '5100381026': 0, '5100381027': 0, '5100381028': 0, '5100381029': 0, '5100381031': 0, '5100381032': 0, '5100381034': 0, '5100381035': 0, '5100381037': 0, '5100381038': 0, '5100381039': 0, '5100381040': 0, '5100381041': 0, '5100381042': 0, '5100381043': 0, '5100381044': 0, '5100381045': 0, '5100381046': 0, '5100381047': 0, '5100381048': 0, '5100381049': 0, '5100381050': 0, '5100381051': 0, '5100381052': 0, '5100381053': 0, '5100381054': 0, '5100381055': 0, '5100381056': 0, '5100381058': 0, '5100381059': 0, '5100381060': 0, '5100381061': 0, '5100381063': 0, '5100381065': 0, '5100381066': 0, '5100381067': 0, '5100381069': 0, '5100382001': 0, '5100382003': 0, '5100382007': 0, '5100382008': 0, '5100382010': 0, '5100382011': 0, '5100382012': 0, '5100382013': 0, '5100382014': 0, '5100382015': 0, '5100382016': 0, '5100382018': 0, '5100382019': 0, '5100382020': 0, '5100382021': 0, '5100382022': 0, '5100382023': 0, '5100382025': 0, '5100382026': 0, '5100382027': 0, '5100382028': 0, '5100382029': 0, '5100382030': 0, '5100382031': 0, '5100382032': 0, '5100382033': 0, '5100382034': 0, '5100382035': 0, '5100382036': 0, '5100382037': 0, '5100382038': 0, '5100382039': 0, '5100382040': 0, '5100382042': 0, '5100382045': 0, '5100382046': 0, '5100382048': 0, '5100382050': 0, '5100382051': 0, '5100382052': 0, '5100382053': 0, '5100382054': 0, '5100382055': 0, '5100382056': 0, '5100382057': 0, '5100382058': 0, '5100382059': 0, '5100382060': 0, '5100382061': 0, '5100382062': 0, '5100382063': 0, '5100382064': 0, '5100382065': 0, '5100382066': 0, '5100382067': 0, '5100382068': 0, '5100382069': 0, '5100382070': 0, '5100382071': 0, '5100382072': 0, '5100382073': 0, '5100382075': 0, '5100382076': 0, '5100382077': 0, '5100382078': 0, '5100382079': 0, '5100401001': 0, '5100401003': 0, '5100401005': 0, '5100401006': 0, '5100401007': 0, '5100401008': 0, '5100401010': 0, '5100401011': 0, '5100401012': 0, '5100401014': 0, '5100401015': 0, '5100401016': 0, '5100401018': 0, '5100401021': 0, '5100401022': 0, '5100401023': 1, '5100401025': 0, '5100401026': 0, '5100401028': 0, '5100401029': 0, '5100401030': 0, '5100401031': 0, '5100401032': 0, '5100401033': 0, '5100401034': 1, '5100401035': 0, '5100401036': 0, '5100401038': 0, '5100401039': 0, '5100401040': 0, '5100401042': 0, '5100401043': 1, '5100401044': 0, '5100401045': 0, '5100401046': 0, '5100401047': 0, '5100401048': 0, '5100401049': 0, '5100401050': 0, '5100401051': 0, '5100401053': 0, '5100401054': 0, '5100401055': 0, '5100401056': 0, '5100401057': 0, '5100401059': 0, '5100401060': 0, '5100401061': 0, '5100401062': 0, '5100401063': 0, '5100401064': 0, '5100401065': 1, '5100401066': 0, '5100401067': 0, '5100401069': 0, '5100401070': 0, '5100401071': 0, '5100401072': 0, '5100401073': 0, '5100401074': 0, '5100401075': 0, '5100401076': 0, '5100401077': 0, '5100401078': 0, '5100402001': 1, '5100402002': 0, '5100402004': 0, '5100402005': 0, '5100402007': 0, '5100402008': 0, '5100402009': 0, '5100402011': 0, '5100402012': 0, '5100402015': 0, '5100402016': 0, '5100402017': 0, '5100402019': 0, '5100402020': 0, '5100402023': 0, '5100402024': 0, '5100402028': 0, '5100402029': 0, '5100402031': 0, '5100402032': 0, '5100402033': 0, '5100402034': 0, '5100402035': 0, '5100402036': 0, '5100402037': 0, '5100402038': 0, '5100402039': 0, '5100402040': 0, '5100402046': 0, '5100402047': 0, '5100402048': 0, '5100402049': 0, '5100402050': 0, '5100402051': 0, '5100402052': 0, '5100402053': 0, '5100402054': 0, '5100402055': 0, '5100402057': 0, '5100402058': 0, '5100402059': 0, '5100402062': 1, '5100402063': 1, '5100402065': 0, '5100402066': 0, '5100402067': 0, '5100402068': 0, '5100402069': 0, '5100421001': 0, '5100421002': 0, '5100421003': 0, '5100421005': 0, '5100421007': 0, '5100421009': 0, '5100421011': 0, '5100421012': 0, '5100421013': 0, '5100421015': 0, '5100421016': 0, '5100421017': 0, '5100421018': 0, '5100421019': 0, '5100421020': 0, '5100421021': 0, '5100421024': 0, '5100421025': 0, '5100421026': 0, '5100421027': 0, '5100421029': 0, '5100421032': 0, '5100421033': 0, '5100421034': 0, '5100421038': 0, '5100421039': 0, '5100421040': 0, '5100421041': 0, '5100421043': 0, '5100421045': 0, '5100421047': 0, '5100421048': 0, '5100421049': 0, '5100421050': 0, '5100421051': 0, '5100421052': 0, '5100421053': 0, '5100421054': 0, '5100421056': 0, '5100421057': 0, '5100421058': 0, '5100421059': 0, '5100421060': 0, '5100421061': 0, '5100421062': 0, '5100421063': 0, '5100421064': 0, '5100421065': 0, '5100421067': 0, '5100421068': 0, '5100421069': 0, '5100421070': 0, '5100421071': 0, '5100421072': 0, '5100421073': 0, '5100421074': 0, '5100421076': 0, '5100421078': 0, '5100421079': 0, '5100421080': 0, '5100421081': 0, '5100422002': 0, '5100422003': 0, '5100422004': 0, '5100422005': 0, '5100422006': 0, '5100422007': 0, '5100422008': 0, '5100422009': 0, '5100422011': 0, '5100422012': 0, '5100422013': 0, '5100422014': 0, '5100422016': 0, '5100422017': 0, '5100422018': 0, '5100422019': 0, '5100422022': 0, '5100422023': 0, '5100422024': 0, '5100422025': 0, '5100422026': 0, '5100422027': 0, '5100422028': 0, '5100422029': 0, '5100422030': 0, '5100422033': 0, '5100422034': 0, '5100422035': 0, '5100422036': 0, '5100422037': 0, '5100422038': 0, '5100422039': 0, '5100422041': 0, '5100422042': 0, '5100422044': 0, '5100422045': 0, '5100422046': 0, '5100422047': 0, '5100422049': 0, '5100422050': 0, '5100422051': 0, '5100422052': 0, '5100422055': 0, '5100422056': 0, '5100422057': 0, '5100422058': 0, '5100422059': 0, '5100422060': 0, '5100422061': 0, '5100422062': 0, '5100422063': 0, '5100422065': 0, '5100422066': 0, '5100422067': 0, '5100422068': 0, '5100422069': 0, '5100422071': 0, '5100422072': 0, '5100422073': 0, '5100422074': 0, '5100422075': 0, '5100422077': 0, '5100422078': 0, '5100422079': 0, '5100422080': 0, '5100422081': 0, '5100422084': 0, '5100422085': 0, '5100451001': 0, '5100451003': 0, '5100451004': 0, '5100451006': 0, '5100451007': 0, '5100451012': 0, '5100451013': 0, '5100451015': 0, '5100451016': 0, '5100451017': 0, '5100451018': 0, '5100451019': 0, '5100451020': 0, '5100451024': 0, '5100451026': 0, '5100451027': 0, '5100451033': 0, '5100451034': 0, '5100451035': 0, '5100451036': 0, '5100451038': 0, '5100451041': 0, '5100451043': 0, '5100451044': 0, '5100451045': 0, '5100451049': 0, '5100451050': 0, '5100451051': 0, '5100451052': 0, '5100451055': 0, '5100451056': 0, '5100451059': 0, '5100451060': 0, '5100451061': 0, '5100451064': 0, '5100451065': 0, '5100451066': 0, '5100451067': 0, '5100451070': 0, '5100451071': 0, '5100452002': 0, '5100452004': 0, '5100452005': 0, '5100452006': 0, '5100452007': 0, '5100452008': 0, '5100452009': 0, '5100452010': 0, '5100452011': 0, '5100452012': 0, '5100452013': 0, '5100452014': 0, '5100452016': 1, '5100452017': 0, '5100452018': 0, '5100452021': 0, '5100452023': 0, '5100452025': 0, '5100452027': 0, '5100452028': 0, '5100452030': 0, '5100452031': 0, '5100452032': 0, '5100452033': 0, '5100452034': 0, '5100452035': 0, '5100452036': 0, '5100452037': 0, '5100452038': 0, '5100452039': 0, '5100452040': 0, '5100452047': 0, '5100452049': 0, '5100452050': 0, '5100452053': 0, '5100452054': 0, '5100452055': 0, '5100452059': 0, '5100452060': 0, '5100452061': 0, '5100452065': 0, '5100452066': 0, '5100452067': 0, '5100452076': 0, '5100452078': 0, '5100452079': 0, '5100452080': 0, '5100452081': 0, '5100461004': 0, '5100461005': 0, '5100461006': 0, '5100461007': 1, '5100461008': 0, '5100461009': 0, '5100461010': 0, '5100461011': 0, '5100461014': 0, '5100461015': 0, '5100461016': 0, '5100461017': 0, '5100461018': 0, '5100461020': 0, '5100461021': 0, '5100461022': 0, '5100461023': 0, '5100461025': 0, '5100461029': 0, '5100461030': 0, '5100461031': 0, '5100461032': 0, '5100461033': 0, '5100461034': 0, '5100461035': 0, '5100461036': 0, '5100461037': 0, '5100461038': 0, '5100461039': 0, '5100461040': 0, '5100461042': 0, '5100461043': 0, '5100461044': 0, '5100461046': 0, '5100461047': 0, '5100461048': 0, '5100461049': 0, '5100461050': 0, '5100461051': 0, '5100461052': 0, '5100461053': 0, '5100461054': 0, '5100461055': 0, '5100461056': 0, '5100461057': 0, '5100461058': 0, '5100461061': 0, '5100461062': 0, '5100461063': 0, '5100461064': 0, '5100461065': 0, '5100461066': 0, '5100461067': 0, '5100461068': 0, '5100461069': 0, '5100462001': 0, '5100462002': 0, '5100462003': 1, '5100462005': 0, '5100462009': 0, '5100462010': 0, '5100462011': 0, '5100462012': 0, '5100462014': 0, '5100462015': 0, '5100462016': 0, '5100462017': 0, '5100462018': 0, '5100462019': 0, '5100462021': 0, '5100462022': 0, '5100462023': 0, '5100462024': 0, '5100462025': 0, '5100462026': 0, '5100462027': 0, '5100462028': 0, '5100462029': 0, '5100462031': 0, '5100462032': 0, '5100462033': 0, '5100462035': 0, '5100462037': 0, '5100462038': 0, '5100462039': 0, '5100462040': 0, '5100462041': 0, '5100462042': 0, '5100462043': 0, '5100462044': 0, '5100462045': 0, '5100462046': 0, '5100462047': 0, '5100462048': 0, '5100462050': 0, '5100462051': 0, '5100462052': 0, '5100462053': 0, '5100462054': 0, '5100462055': 0, '5100462057': 0, '5100462058': 0, '5100462059': 0, '5100462061': 0, '5100462062': 0, '5100462063': 0, '5100462064': 0, '5100462066': 0, '5100462067': 0, '5100462068': 0, '5100462069': 0, '5100462070': 0, '5100462071': 0, '5100462072': 0, '5100462074': 0, '5100462075': 0, '5100462077': 0, '5100462078': 0, '5100462079': 0, '5100462080': 0, '5100462081': 0, '5100462082': 0, '5100471001': 0, '5100471002': 0, '5100471003': 0, '5100471011': 0, '5100471012': 0, '5100471013': 0, '5100471015': 0, '5100471016': 0, '5100471018': 0, '5100471019': 0, '5100471020': 0, '5100471021': 0, '5100471023': 0, '5100471026': 0, '5100471027': 0, '5100471028': 0, '5100471029': 0, '5100471030': 0, '5100471031': 0, '5100471034': 0, '5100471037': 0, '5100471038': 0, '5100471039': 0, '5100471041': 0, '5100471042': 0, '5100471044': 0, '5100471045': 0, '5100471047': 0, '5100471049': 0, '5100471050': 0, '5100471051': 0, '5100471052': 0, '5100471054': 0, '5100471056': 0, '5100471057': 0, '5100471058': 0, '5100471059': 0, '5100471060': 0, '5100471062': 0, '5100471063': 0, '5100471065': 0, '5100471068': 0, '5100471069': 0, '5100471070': 0, '5100471072': 0, '5100471074': 0, '5100471075': 0, '5100471080': 0, '5100471081': 0, '5100472001': 1, '5100472002': 0, '5100472003': 0, '5100472004': 0, '5100472005': 0, '5100472007': 0, '5100472009': 0, '5100472010': 0, '5100472011': 0, '5100472012': 0, '5100472014': 0, '5100472019': 0, '5100472020': 0, '5100472021': 0, '5100472027': 0, '5100472030': 0, '5100472031': 0, '5100472032': 0, '5100472035': 0, '5100472039': 0, '5100472040': 0, '5100472041': 0, '5100472042': 0, '5100472044': 0, '5100472045': 0, '5100472047': 0, '5100472050': 0, '5100472052': 0, '5100472053': 0, '5100472054': 0, '5100472058': 1, '5100472060': 0, '5100472063': 0, '5100472064': 0, '5221290110': 0, '5221290111': 0, '5221290112': 0, '5221290114': 0, '5221290115': 0, '5221290116': 0, '5221290118': 0, '5221290119': 0, '5221290121': 0, '5221290122': 0, '5221290123': 0, '5221290124': 0, '5221290126': 0, '5221290127': 0, '5221290129': 0, '522129013': 0, '5221290131': 0, '5221290132': 0, '5221290134': 0, '5221290135': 0, '5221290137': 0, '5221290138': 0, '5221290140': 0, '5221290141': 0, '5221290142': 0, '5221290144': 0, '5221290145': 0, '5221290147': 0, '5221290149': 0, '5221290150': 0, '5221290151': 0, '5221290155': 0, '5221290158': 0, '522129016': 0, '5221290161': 0, '5221290162': 0, '5221290163': 0, '5221290164': 0, '5221290165': 0, '5221290166': 0, '5221290167': 0, '5221290169': 0, '522129017': 0, '5221290171': 0, '5221290172': 0, '5221290173': 0, '5221290174': 0, '5221290175': 0, '5221290177': 0, '5221290178': 0, '5221290179': 0, '522129018': 0, '5221290180': 0, '5221290184': 0, '522129021': 0, '5221290210': 0, '5221290212': 0, '5221290213': 0, '5221290214': 0, '5221290215': 0, '5221290216': 0, '5221290217': 0, '522129022': 0, '5221290220': 0, '5221290221': 0, '5221290222': 0, '5221290223': 0, '5221290226': 0, '5221290227': 0, '5221290228': 0, '5221290230': 0, '5221290231': 0, '5221290235': 0, '5221290237': 0, '5221290238': 0, '5221290239': 0, '522129024': 0, '5221290240': 0, '5221290242': 0, '5221290247': 0, '5221290249': 0, '522129025': 0, '5221290250': 0, '5221290251': 0, '5221290252': 0, '5221290253': 0, '5221290254': 0, '5221290255': 0, '5221290256': 0, '5221290257': 0, '5221290258': 0, '5221290259': 0, '522129026': 0, '5221290263': 0, '5221290264': 0, '5221290266': 0, '5221290268': 0, '5221290269': 0, '522129027': 0, '5221290270': 0, '5221290271': 0, '5221290272': 0, '5221290273': 0, '5221290274': 0, '5221290275': 0, '5221290279': 0, '5221290280': 1, '5221290282': 0, '5221290284': 0, '5564630110': 0, '5564630112': 0, '5564630115': 0, '5564630117': 0, '556463012': 0, '5564630121': 0, '5564630122': 0, '5564630123': 0, '5564630126': 1, '5564630127': 0, '5564630128': 0, '5564630129': 0, '556463013': 0, '5564630130': 0, '5564630132': 1, '5564630133': 0, '5564630134': 0, '5564630135': 0, '5564630137': 1, '5564630138': 1, '5564630139': 0, '556463014': 1, '5564630140': 0, '5564630141': 1, '5564630142': 0, '5564630143': 0, '5564630145': 0, '5564630147': 0, '5564630148': 0, '5564630149': 0, '5564630150': 0, '5564630152': 0, '5564630153': 0, '5564630154': 1, '5564630156': 1, '5564630157': 0, '5564630158': 0, '556463016': 0, '5564630160': 0, '5564630161': 0, '5564630162': 0, '5564630163': 0, '5564630165': 0, '5564630166': 0, '5564630167': 0, '5564630168': 1, '556463018': 0, '556463019': 0, '5564630211': 1, '5564630212': 0, '5564630213': 0, '5564630215': 0, '5564630216': 0, '5564630217': 0, '5564630218': 0, '5564630219': 0, '556463022': 1, '5564630221': 0, '5564630222': 0, '5564630226': 1, '5564630228': 0, '5564630229': 0, '5564630230': 0, '5564630232': 0, '5564630233': 0, '5564630234': 0, '5564630235': 0, '5564630236': 0, '5564630237': 0, '5564630238': 1, '556463024': 0, '5564630240': 0, '5564630241': 0, '5564630247': 0, '5564630249': 0, '556463025': 1, '5564630252': 0, '5564630253': 0, '5564630254': 0, '5564630256': 0, '5564630257': 1, '5564630258': 0, '556463026': 0, '5564630261': 0, '5564630262': 0, '5564630264': 0, '5564630265': 0, '5564630269': 0, '556463027': 0, '5564630273': 0, '5564630275': 0, '5564630276': 0, '556463028': 0, '5564630281': 0, '556463029': 0, '567496011': 0, '5674960111': 0, '5674960114': 0, '5674960115': 0, '5674960116': 0, '5674960117': 0, '5674960118': 0, '5674960121': 0, '5674960123': 0, '5674960124': 0, '5674960125': 0, '5674960126': 0, '567496013': 0, '5674960131': 0, '5674960132': 0, '5674960134': 0, '5674960136': 0, '5674960138': 0, '567496014': 0, '5674960142': 0, '5674960144': 0, '5674960145': 0, '5674960146': 0, '5674960148': 0, '5674960151': 0, '5674960153': 0, '5674960154': 0, '5674960155': 1, '5674960156': 0, '5674960157': 0, '5674960158': 0, '5674960160': 0, '5674960161': 0, '5674960166': 0, '567496017': 0, '5674960170': 0, '567496018': 0, '567496019': 0, '567496021': 1, '5674960211': 0, '5674960215': 0, '5674960216': 0, '5674960219': 0, '567496022': 1, '5674960220': 0, '5674960221': 0, '5674960222': 1, '5674960224': 0, '5674960225': 1, '5674960227': 0, '5674960228': 0, '5674960229': 0, '5674960230': 0, '5674960234': 0, '5674960235': 0, '567496024': 0, '5674960242': 0, '5674960246': 0, '5674960249': 0, '5674960251': 0, '5674960252': 0, '5674960255': 0, '5674960257': 0, '567496026': 0, '5674960261': 0, '5674960264': 0, '5674960268': 0, '5674960272': 0, '5674960273': 0, '5674960274': 0, '5674960275': 0, '5674960276': 0, '5674960277': 0, '5674960278': 0, '5674960279': 0, '567496028': 0, '5674960281': 0, '5674960282': 0, '5674960283': 1, '567496029': 0, '5912920111': 0, '5912920112': 0, '5912920113': 0, '5912920114': 0, '5912920119': 0, '5912920121': 0, '5912920123': 0, '5912920124': 0, '5912920125': 0, '5912920126': 0, '5912920127': 0, '5912920128': 1, '5912920129': 0, '5912920131': 0, '5912920133': 0, '5912920135': 0, '5912920137': 0, '5912920140': 0, '5912920142': 0, '5912920143': 0, '5912920145': 0, '5912920146': 0, '5912920147': 0, '5912920148': 0, '5912920149': 0, '591292015': 0, '5912920151': 0, '5912920152': 0, '5912920154': 0, '5912920156': 0, '5912920158': 0, '5912920159': 0, '5912920160': 0, '5912920163': 0, '5912920167': 0, '5912920168': 0, '5912920169': 0, '5912920170': 0, '5912920171': 0, '5912920172': 0, '591292019': 0, '591292021': 0, '5912920211': 0, '5912920212': 0, '5912920213': 0, '5912920216': 0, '5912920217': 0, '5912920220': 0, '5912920222': 0, '5912920223': 0, '5912920225': 0, '5912920227': 0, '5912920228': 0, '5912920230': 0, '5912920231': 0, '5912920233': 0, '5912920234': 0, '5912920235': 0, '5912920236': 0, '5912920239': 0, '591292024': 0, '5912920240': 0, '5912920241': 0, '5912920242': 0, '5912920243': 0, '5912920244': 0, '5912920245': 0, '5912920249': 0, '5912920250': 0, '5912920256': 0, '5912920260': 0, '5912920263': 0, '5912920265': 0, '5912920266': 0, '5912920267': 0, '5912920268': 0, '5912920273': 0, '5912920274': 0, '5912920275': 0, '5912920276': 0, '5912920277': 0, '5912920279': 0, '5912920280': 0, '769862011': 0, '7698620112': 0, '7698620113': 0, '7698620115': 0, '7698620116': 0, '7698620118': 0, '7698620120': 0, '7698620122': 0, '7698620123': 0, '7698620126': 0, '7698620129': 0, '7698620130': 0, '7698620131': 0, '7698620132': 0, '7698620133': 0, '7698620134': 0, '7698620136': 0, '7698620138': 0, '7698620139': 0, '769862014': 0, '7698620141': 0, '7698620144': 0, '7698620145': 0, '7698620149': 0, '769862015': 0, '7698620150': 0, '7698620151': 0, '7698620152': 0, '7698620153': 0, '7698620156': 0, '7698620158': 0, '769862016': 0, '7698620160': 0, '7698620161': 0, '7698620163': 0, '7698620165': 0, '7698620166': 0, '7698620167': 0, '7698620169': 0, '769862017': 1, '7698620170': 0, '7698620171': 0, '769862018': 0, '769862019': 0, '769862021': 0, '7698620211': 0, '7698620212': 0, '7698620217': 0, '7698620218': 0, '769862022': 0, '7698620221': 0, '7698620222': 0, '7698620224': 0, '7698620225': 0, '7698620227': 0, '7698620229': 0, '7698620230': 0, '7698620231': 0, '7698620233': 1, '7698620236': 0, '7698620238': 0, '7698620239': 0, '7698620240': 0, '7698620241': 0, '7698620244': 0, '7698620245': 0, '7698620248': 0, '7698620250': 0, '7698620252': 1, '7698620253': 0, '7698620255': 0, '7698620256': 0, '7698620257': 0, '7698620258': 0, '7698620260': 0, '7698620261': 0, '7698620262': 0, '7698620264': 0, '7698620265': 0, '7698620267': 0, '7698620268': 0, '769862027': 0, '7698620270': 0, '7698620272': 0, '7698620274': 0, '7698620275': 0, '7698620278': 0, '769862028': 0, '7698620281': 0, '7698620283': 0, '7994020110': 0, '79940201100': 0, '79940201110': 0, '79940201140': 0, '79940201150': 0, '79940201160': 0, '79940201180': 0, '79940201210': 0, '79940201230': 0, '79940201250': 0, '79940201270': 0, '7994020130': 0, '79940201300': 1, '79940201320': 0, '79940201330': 0, '79940201340': 0, '79940201350': 0, '79940201360': 0, '79940201370': 0, '79940201380': 0, '79940201390': 1, '7994020140': 0, '79940201410': 0, '79940201420': 0, '79940201430': 0, '79940201470': 0, '79940201490': 0, '79940201510': 0, '79940201560': 0, '79940201570': 0, '79940201580': 0, '7994020160': 0, '79940201620': 0, '79940201650': 0, '79940201660': 1, '79940201690': 0, '79940201700': 0, '79940201710': 0, '79940201720': 0, '79940201730': 0, '79940201740': 0, '79940201750': 0, '79940201760': 0, '79940201770': 0, '79940201780': 0, '79940201790': 1, '79940201810': 0, '79940201820': 0, '79940201850': 0, '79940201860': 0, '79940201880': 0, '79940201930': 0, '79940201950': 0, '79940202100': 0, '79940202120': 0, '79940202130': 0, '79940202140': 0, '79940202160': 0, '79940202170': 0, '79940202180': 0, '79940202190': 0, '79940202200': 0, '79940202210': 0, '79940202220': 0, '79940202230': 0, '79940202270': 1, '79940202280': 1, '7994020230': 1, '79940202300': 0, '79940202310': 1, '79940202320': 0, '79940202340': 0, '79940202350': 0, '79940202370': 0, '79940202390': 0, '79940202400': 0, '79940202410': 0, '79940202450': 0, '79940202470': 0, '79940202480': 0, '79940202490': 1, '7994020250': 0, '79940202510': 0, '79940202520': 0, '79940202540': 0, '79940202560': 0, '79940202570': 0, '79940202580': 0, '79940202620': 0, '79940202690': 0, '7994020270': 0, '79940202700': 0, '79940202710': 0, '79940202750': 0, '79940202760': 0, '79940202790': 0, '7994020280': 0, '79940202800': 1, '79940202820': 0, '79940202840': 1, '79940202850': 1, '79940202860': 1, '79940202870': 0, '79940202890': 0, '7994020290': 0, '8263820112': 0, '8263820113': 0, '8263820120': 0, '8263820123': 0, '8263820124': 0, '8263820126': 0, '8263820132': 0, '8263820135': 0, '8263820136': 0, '8263820138': 0, '8263820139': 0, '8263820140': 0, '8263820141': 0, '8263820144': 0, '8263820145': 0, '8263820146': 0, '8263820147': 0, '8263820148': 0, '826382015': 0, '8263820150': 0, '8263820151': 0, '8263820152': 0, '8263820155': 0, '8263820156': 0, '8263820159': 0, '826382016': 0, '8263820160': 0, '8263820162': 0, '8263820165': 0, '8263820169': 0, '8263820170': 0, '826382018': 0, '826382021': 0, '8263820210': 0, '8263820211': 0, '8263820212': 0, '8263820213': 0, '8263820214': 0, '8263820221': 0, '8263820223': 0, '8263820224': 0, '8263820227': 0, '8263820228': 0, '826382023': 0, '8263820231': 0, '8263820233': 0, '8263820234': 0, '8263820235': 0, '8263820237': 0, '8263820239': 0, '826382024': 1, '8263820240': 0, '8263820242': 0, '8263820243': 0, '8263820245': 0, '8263820246': 0, '8263820247': 0, '8263820251': 0, '8263820253': 0, '8263820254': 0, '8263820255': 0, '8263820256': 0, '8263820257': 0, '8263820259': 0, '826382026': 0, '8263820260': 0, '8263820264': 0, '8263820265': 0, '8263820266': 0, '8263820268': 0, '8263820269': 0, '826382027': 0, '8263820272': 0, '8263820273': 0, '8263820275': 0, '8263820277': 0, '8263820278': 0, '8263820279': 0, '826382028': 0, '826412010': 0, '8264120110': 0, '8264120111': 0, '8264120112': 0, '8264120113': 0, '8264120116': 1, '8264120117': 0, '8264120119': 0, '8264120120': 1, '8264120121': 0, '8264120122': 0, '8264120123': 1, '8264120124': 0, '8264120125': 0, '8264120126': 0, '8264120127': 1, '826412013': 1, '8264120131': 0, '8264120132': 0, '8264120136': 0, '8264120139': 0, '8264120141': 0, '8264120144': 0, '8264120145': 0, '8264120146': 0, '8264120149': 0, '8264120150': 1, '8264120156': 1, '8264120157': 0, '8264120159': 0, '8264120165': 0, '8264120166': 0, '8264120169': 1, '826412017': 0, '826412018': 0, '826412019': 0, '8264120210': 0, '8264120211': 1, '8264120213': 0, '8264120215': 0, '8264120216': 0, '8264120218': 0, '8264120219': 0, '8264120220': 0, '8264120221': 0, '8264120223': 0, '8264120224': 0, '8264120227': 0, '8264120228': 0, '8264120229': 0, '826412023': 0, '8264120231': 1, '8264120232': 0, '8264120233': 0, '8264120234': 0, '8264120239': 1, '826412024': 0, '8264120240': 1, '8264120241': 0, '8264120242': 0, '8264120243': 1, '8264120245': 0, '8264120247': 0, '8264120248': 0, '8264120249': 1, '826412025': 0, '8264120254': 1, '8264120256': 1, '8264120257': 0, '8264120258': 0, '8264120261': 1, '8264120262': 1, '8264120263': 1, '8264120265': 1, '8264120266': 1, '8264120268': 0, '8264120269': 1, '826412027': 0, '8264120274': 0, '8264120275': 0, '8264120279': 1, '8264120280': 0, '8264120282': 1, '8264120284': 1, '88265401100': 0, '88265401130': 0, '88265401140': 0, '88265401150': 0, '88265401160': 0, '88265401170': 0, '88265401190': 0, '8826540120': 0, '88265401200': 0, '88265401240': 0, '88265401260': 0, '88265401270': 0, '88265401280': 0, '88265401300': 0, '88265401320': 0, '88265401350': 0, '88265401360': 0, '88265401380': 0, '88265401390': 0, '88265401400': 0, '88265401410': 0, '88265401420': 0, '88265401430': 0, '88265401450': 0, '88265401470': 0, '88265401480': 0, '88265401490': 0, '8826540150': 0, '88265401520': 0, '88265401550': 0, '88265401630': 0, '88265401640': 0, '88265401660': 0, '88265401690': 0, '8826540170': 0, '88265401730': 0, '88265401740': 0, '88265401750': 1, '8826540180': 0, '88265402120': 0, '88265402150': 0, '88265402160': 0, '88265402170': 0, '88265402180': 0, '88265402190': 0, '88265402200': 0, '88265402230': 0, '88265402240': 0, '88265402270': 0, '8826540230': 0, '88265402300': 0, '88265402310': 0, '88265402320': 0, '88265402330': 0, '88265402340': 0, '88265402350': 0, '88265402370': 0, '88265402380': 0, '8826540240': 0, '88265402400': 0, '88265402420': 0, '88265402440': 0, '88265402450': 0, '88265402480': 0, '88265402490': 0, '88265402500': 0, '88265402520': 0, '88265402540': 0, '88265402570': 0, '88265402580': 0, '88265402590': 0, '8826540260': 0, '88265402600': 0, '88265402630': 0, '88265402660': 0, '88265402690': 0, '8826540270': 0, '88265402700': 0, '88265402770': 0, '88265402780': 0, '88265402790': 0, '8826540280': 0, '88265402800': 0, '88265402810': 0, '88265402820': 0, '88265402840': 0, '88265402850': 0, '88265402880': 0, '88265402890': 0, '8826540290': 0, '88265402900': 0, '907001100': 0, '9070011010': 0, '9070011020': 0, '9070011060': 0, '9070011090': 0, '907001110': 0, '9070011110': 0, '907001120': 0, '907001150': 0, '907001160': 0, '907001170': 0, '907001180': 0, '907001210': 0, '907001220': 0, '907001240': 0, '907001270': 0, '907001280': 0, '907001310': 0, '907001340': 0, '907001350': 0, '907001360': 0, '907001370': 0, '907001400': 0, '907001430': 0, '907001450': 0, '907001480': 1, '907001490': 0, '90700150': 0, '907001500': 0, '907001520': 0, '907001550': 0, '907001560': 0, '907001570': 0, '907001580': 0, '90700160': 0, '907001600': 0, '907001620': 0, '907001650': 0, '907001670': 0, '907001680': 0, '90700170': 0, '907001730': 0, '907001740': 0, '907001780': 0, '907001790': 0, '90700180': 0, '907001820': 0, '907001840': 0, '907001850': 0, '907001860': 0, '90700190': 0, '907001910': 0, '907001940': 0, '907001950': 1, '907001970': 0, '9289010111': 0, '9289010112': 0, '9289010113': 0, '9289010114': 1, '9289010115': 0, '9289010117': 0, '9289010118': 0, '9289010119': 0, '9289010120': 0, '9289010121': 0, '9289010127': 0, '928901013': 0, '9289010131': 0, '9289010132': 0, '9289010133': 0, '9289010134': 0, '9289010138': 0, '9289010139': 0, '928901014': 1, '9289010143': 0, '9289010144': 0, '9289010145': 1, '9289010147': 0, '9289010149': 0, '9289010150': 0, '9289010151': 0, '9289010152': 1, '9289010153': 0, '9289010154': 0, '9289010155': 0, '9289010157': 0, '9289010158': 0, '928901016': 0, '9289010160': 0, '9289010161': 0, '9289010163': 0, '9289010166': 0, '9289010167': 0, '928901018': 0, '9289010210': 0, '9289010211': 0, '9289010216': 0, '9289010221': 0, '9289010222': 0, '9289010223': 0, '9289010227': 0, '9289010229': 0, '928901023': 0, '9289010230': 0, '9289010231': 0, '9289010232': 0, '9289010233': 0, '9289010235': 0, '9289010242': 0, '9289010243': 0, '9289010244': 0, '9289010245': 0, '9289010248': 0, '9289010249': 0, '928901025': 0, '9289010250': 0, '9289010251': 0, '9289010253': 0, '9289010254': 0, '9289010257': 0, '9289010259': 0, '928901026': 0, '9289010261': 0, '9289010262': 0, '9289010263': 0, '9289010265': 0, '9289010266': 0, '9289010267': 0, '9289010268': 0, '9289010269': 0, '9289010270': 0, '9289010271': 0, '9289010273': 0, '9289010274': 0, '9289010275': 0, '9289010276': 1, '9289010278': 0, '928901028': 0, '928901029': 0, '940328011': 0, '9403280110': 0, '9403280112': 0, '9403280114': 0, '9403280115': 0, '9403280116': 0, '9403280117': 0, '940328012': 0, '9403280126': 0, '9403280129': 0, '9403280132': 0, '9403280134': 0, '9403280136': 0, '9403280138': 0, '940328014': 0, '9403280140': 0, '9403280143': 0, '9403280145': 0, '9403280146': 0, '9403280147': 0, '9403280149': 0, '9403280150': 0, '9403280151': 0, '9403280152': 0, '9403280155': 0, '9403280156': 0, '9403280157': 0, '9403280159': 0, '940328016': 0, '9403280164': 0, '9403280165': 0, '9403280167': 0, '940328017': 0, '940328018': 0, '9403280212': 0, '9403280213': 0, '9403280217': 0, '9403280218': 0, '9403280219': 0, '940328022': 0, '9403280227': 0, '9403280229': 0, '9403280234': 0, '9403280235': 0, '9403280236': 0, '9403280238': 0, '9403280241': 0, '9403280243': 0, '9403280245': 0, '9403280246': 0, '9403280247': 0, '9403280249': 0, '9403280250': 0, '9403280251': 0, '9403280254': 0, '9403280255': 0, '9403280256': 0, '9403280259': 0, '9403280260': 0, '9403280262': 0, '9403280265': 0, '9403280266': 0, '9403280271': 1, '9403280272': 0, '9403280273': 0, '9403280277': 0, '9403280279': 0, '9877360111': 0, '9877360113': 0, '9877360114': 0, '9877360115': 0, '9877360116': 0, '9877360117': 0, '9877360120': 1, '9877360121': 0, '9877360124': 0, '9877360125': 0, '9877360126': 0, '9877360127': 0, '9877360128': 0, '9877360130': 0, '9877360131': 0, '9877360132': 0, '9877360133': 1, '9877360134': 0, '9877360135': 0, '9877360138': 0, '987736014': 0, '9877360140': 0, '9877360141': 0, '9877360143': 0, '9877360147': 0, '9877360149': 0, '987736015': 0, '9877360151': 0, '9877360152': 0, '9877360154': 0, '9877360156': 0, '9877360157': 1, '9877360158': 0, '9877360159': 0, '987736016': 0, '9877360163': 0, '9877360164': 0, '9877360165': 0, '9877360166': 0, '9877360168': 0, '9877360169': 1}\n"
     ]
    }
   ],
   "source": [
    "ENGAGE_WILD_DATASET, BIN_CLASSIFICATION, N_CLASSES, DATASET_NAME, BASE_DATASET_DIR, ext = define_dataset(False, True)\n",
    "video2label, labels_list = get_video2label()\n",
    "print(labels_list)\n",
    "print(video2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6942055-a58e-47a3-8da1-2e3171e90779",
   "metadata": {},
   "source": [
    "### Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "bd8652a2-f32b-40c3-b4a7-632e43b859d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.std\n",
    "stat_name = \"std\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e46e8c8-b8d6-490c-85c6-03914939dda7",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "28edfa26-4ea6-4198-b4b8-cbde733db24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "48f14080-3894-48ac-976e-e45215c0107f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "2cb19360-ae21-4dfd-8d94-484fcdc99324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "test:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n",
      "val:\n",
      "0 1537/1720: 89.36046511627907%\n",
      "1 183/1720: 10.63953488372093%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3fd215-2e9d-40e1-8f2e-4160fe4f23b2",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "27babfba-7323-4eb0-bfe4-da038e549f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "a77ec8e7-38d5-484b-9cfe-275a966a54da",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "4f2357dd-884a-42d1-b6aa-b57828d8fc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2048) (5482,)\n",
      "(1723, 128, 2048) (1723,)\n",
      "(1720, 128, 2048) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "9e28c005-4792-4ccb-b5f2-061e07d49e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_24 (Dense)            (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "3951c125-b3d0-45e4-9f24-41e54ca16153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 4s 55ms/step - loss: 0.2167 - acc: 0.9548 - auc: 0.5371 - binary_accuracy: 0.9548 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00 - val_loss: 0.3532 - val_acc: 0.8936 - val_auc: 0.5805 - val_binary_accuracy: 0.8936 - val_recall_12: 0.0000e+00 - val_precision_12: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1690 - acc: 0.9548 - auc: 0.7114 - binary_accuracy: 0.9548 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00 - val_loss: 0.3347 - val_acc: 0.8936 - val_auc: 0.6479 - val_binary_accuracy: 0.8936 - val_recall_12: 0.0000e+00 - val_precision_12: 0.0000e+00\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1592 - acc: 0.9548 - auc: 0.7697 - binary_accuracy: 0.9548 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00 - val_loss: 0.3497 - val_acc: 0.8936 - val_auc: 0.6575 - val_binary_accuracy: 0.8936 - val_recall_12: 0.0000e+00 - val_precision_12: 0.0000e+00\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1551 - acc: 0.9548 - auc: 0.7828 - binary_accuracy: 0.9548 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00 - val_loss: 0.3544 - val_acc: 0.8936 - val_auc: 0.6624 - val_binary_accuracy: 0.8936 - val_recall_12: 0.0000e+00 - val_precision_12: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1506 - acc: 0.9548 - auc: 0.8062 - binary_accuracy: 0.9548 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00 - val_loss: 0.3539 - val_acc: 0.8936 - val_auc: 0.6719 - val_binary_accuracy: 0.8936 - val_recall_12: 0.0000e+00 - val_precision_12: 0.0000e+00\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1497 - acc: 0.9548 - auc: 0.8132 - binary_accuracy: 0.9548 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00 - val_loss: 0.3661 - val_acc: 0.8936 - val_auc: 0.6779 - val_binary_accuracy: 0.8936 - val_recall_12: 0.0000e+00 - val_precision_12: 0.0000e+00\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1463 - acc: 0.9548 - auc: 0.8240 - binary_accuracy: 0.9548 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00 - val_loss: 0.3919 - val_acc: 0.8936 - val_auc: 0.6767 - val_binary_accuracy: 0.8936 - val_recall_12: 0.0000e+00 - val_precision_12: 0.0000e+00\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1471 - acc: 0.9548 - auc: 0.8262 - binary_accuracy: 0.9548 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00 - val_loss: 0.3437 - val_acc: 0.8936 - val_auc: 0.6848 - val_binary_accuracy: 0.8936 - val_recall_12: 0.0000e+00 - val_precision_12: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.1411 - acc: 0.9548 - auc: 0.8501 - binary_accuracy: 0.9548 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00 - val_loss: 0.3597 - val_acc: 0.8936 - val_auc: 0.6833 - val_binary_accuracy: 0.8936 - val_recall_12: 0.0000e+00 - val_precision_12: 0.0000e+00\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1386 - acc: 0.9548 - auc: 0.8557 - binary_accuracy: 0.9548 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00 - val_loss: 0.3448 - val_acc: 0.8936 - val_auc: 0.6876 - val_binary_accuracy: 0.8936 - val_recall_12: 0.0000e+00 - val_precision_12: 0.0000e+00\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1371 - acc: 0.9548 - auc: 0.8576 - binary_accuracy: 0.9548 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00 - val_loss: 0.3360 - val_acc: 0.8936 - val_auc: 0.6893 - val_binary_accuracy: 0.8936 - val_recall_12: 0.0000e+00 - val_precision_12: 0.0000e+00\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1357 - acc: 0.9549 - auc: 0.8653 - binary_accuracy: 0.9549 - recall_12: 0.0040 - precision_12: 1.0000 - val_loss: 0.3704 - val_acc: 0.8936 - val_auc: 0.6848 - val_binary_accuracy: 0.8936 - val_recall_12: 0.0000e+00 - val_precision_12: 0.0000e+00\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1341 - acc: 0.9548 - auc: 0.8704 - binary_accuracy: 0.9548 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00 - val_loss: 0.3613 - val_acc: 0.8936 - val_auc: 0.6814 - val_binary_accuracy: 0.8936 - val_recall_12: 0.0000e+00 - val_precision_12: 0.0000e+00\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.1312 - acc: 0.9549 - auc: 0.8810 - binary_accuracy: 0.9549 - recall_12: 0.0040 - precision_12: 1.0000 - val_loss: 0.3629 - val_acc: 0.8936 - val_auc: 0.6822 - val_binary_accuracy: 0.8936 - val_recall_12: 0.0000e+00 - val_precision_12: 0.0000e+00\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1292 - acc: 0.9549 - auc: 0.8855 - binary_accuracy: 0.9549 - recall_12: 0.0040 - precision_12: 1.0000 - val_loss: 0.4365 - val_acc: 0.8936 - val_auc: 0.6699 - val_binary_accuracy: 0.8936 - val_recall_12: 0.0000e+00 - val_precision_12: 0.0000e+00\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1341 - acc: 0.9557 - auc: 0.8681 - binary_accuracy: 0.9557 - recall_12: 0.0202 - precision_12: 1.0000 - val_loss: 0.4156 - val_acc: 0.8936 - val_auc: 0.6632 - val_binary_accuracy: 0.8936 - val_recall_12: 0.0000e+00 - val_precision_12: 0.0000e+00\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1275 - acc: 0.9553 - auc: 0.8860 - binary_accuracy: 0.9553 - recall_12: 0.0121 - precision_12: 1.0000 - val_loss: 0.4111 - val_acc: 0.8936 - val_auc: 0.6691 - val_binary_accuracy: 0.8936 - val_recall_12: 0.0000e+00 - val_precision_12: 0.0000e+00\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.1240 - acc: 0.9557 - auc: 0.8966 - binary_accuracy: 0.9557 - recall_12: 0.0202 - precision_12: 1.0000 - val_loss: 0.4061 - val_acc: 0.8936 - val_auc: 0.6646 - val_binary_accuracy: 0.8936 - val_recall_12: 0.0000e+00 - val_precision_12: 0.0000e+00\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1245 - acc: 0.9571 - auc: 0.8960 - binary_accuracy: 0.9571 - recall_12: 0.0524 - precision_12: 1.0000 - val_loss: 0.3755 - val_acc: 0.8936 - val_auc: 0.6657 - val_binary_accuracy: 0.8936 - val_recall_12: 0.0000e+00 - val_precision_12: 0.0000e+00\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1216 - acc: 0.9579 - auc: 0.9026 - binary_accuracy: 0.9579 - recall_12: 0.0847 - precision_12: 0.8400 - val_loss: 0.4055 - val_acc: 0.8936 - val_auc: 0.6625 - val_binary_accuracy: 0.8936 - val_recall_12: 0.0000e+00 - val_precision_12: 0.0000e+00\n",
      "0.334656298160553\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "ab9ac8fc-9e88-4ec2-b146-2a97586fe1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "f8e0dde9-b6ea-4fe5-8925-63b4c8aa24cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional Accuracy:  0.7492745211839814 MSE:  0.2507254788160186 UAR:  0.594853838971486 Recall:  0.4235294117647059 Precision:  0.08591885441527446 F1:  0.14285714285714285\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional Accuracy:  0.8757980266976204 MSE:  0.12420197330237957 UAR:  0.57774186597716 Recall:  0.24705882352941178 Precision:  0.12280701754385964 F1:  0.1640625\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional Accuracy:  0.926871735345328 MSE:  0.07312826465467208 UAR:  0.5599870717517776 Recall:  0.15294117647058825 Precision:  0.19402985074626866 F1:  0.17105263157894737\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional Accuracy:  0.9483459082994776 MSE:  0.05165409170052235 UAR:  0.5378187172304819 Recall:  0.08235294117647059 Precision:  0.3888888888888889 F1:  0.13592233009708737\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5170365582130289 Recall:  0.03529411764705882 Precision:  0.6 F1:  0.06666666666666667\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.594853838971486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "a516bd5c-c6b2-4c6d-9e47-a36648daf2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "e4286b65-67cf-4d03-8f4e-7063a4f24b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "3b8a9ba8-b77e-49ab-8bd2-9d18309d6484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.8432965757399884 MSE:  0.1567034242600116 UAR:  0.6666127989657402 Recall:  0.47058823529411764 Precision:  0.1509433962264151 F1:  0.2285714285714286\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.9500870574579222 MSE:  0.04991294254207777 UAR:  0.5777741865977161 Recall:  0.16470588235294117 Precision:  0.4827586206896552 F1:  0.24561403508771928\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5170365582130289 Recall:  0.03529411764705882 Precision:  0.6 F1:  0.06666666666666667\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.9495066744051074 MSE:  0.05049332559489263 UAR:  0.4993894993894994 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6666127989657402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aea6a2-8cc8-4433-a119-e2bda753d876",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "cdf66633-5e29-4748-a890-48bb2dfa8487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_2_std_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "89367bae-f250-429b-b4a7-cf68818995b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "687e3a23-ce8d-44ee-a6b9-c31efb9e06e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2048) (5482,)\n",
      "(1723, 128, 2048) (1723,)\n",
      "(1720, 128, 2048) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "862aab12-3bf4-4b75-95b2-ea7a0f06a218",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_25\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_12 (Attention)    (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention_12[0][0]']        \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention_12[0][0]',        \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_25 (Dense)            (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "dbde505f-b311-4ea0-b1f8-008db1cd32d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 95ms/step - loss: 0.3712 - acc: 0.9365 - auc: 0.5789 - binary_accuracy: 0.9365 - recall_13: 0.0323 - precision_13: 0.0690 - val_loss: 0.4060 - val_acc: 0.8936 - val_auc: 0.5761 - val_binary_accuracy: 0.8936 - val_recall_13: 0.0000e+00 - val_precision_13: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1655 - acc: 0.9548 - auc: 0.7363 - binary_accuracy: 0.9548 - recall_13: 0.0081 - precision_13: 0.5000 - val_loss: 0.3365 - val_acc: 0.8831 - val_auc: 0.6547 - val_binary_accuracy: 0.8831 - val_recall_13: 0.0219 - val_precision_13: 0.1538\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.1707 - acc: 0.9535 - auc: 0.7258 - binary_accuracy: 0.9535 - recall_13: 0.0524 - precision_13: 0.3939 - val_loss: 0.3455 - val_acc: 0.8919 - val_auc: 0.6341 - val_binary_accuracy: 0.8919 - val_recall_13: 0.0109 - val_precision_13: 0.2857\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1556 - acc: 0.9540 - auc: 0.7928 - binary_accuracy: 0.9540 - recall_13: 0.0403 - precision_13: 0.4167 - val_loss: 0.3689 - val_acc: 0.8878 - val_auc: 0.6354 - val_binary_accuracy: 0.8878 - val_recall_13: 0.0055 - val_precision_13: 0.0833\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 3s 64ms/step - loss: 0.1465 - acc: 0.9575 - auc: 0.8217 - binary_accuracy: 0.9575 - recall_13: 0.1008 - precision_13: 0.7143 - val_loss: 0.3571 - val_acc: 0.8901 - val_auc: 0.6484 - val_binary_accuracy: 0.8901 - val_recall_13: 0.0000e+00 - val_precision_13: 0.0000e+00\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.1463 - acc: 0.9553 - auc: 0.8228 - binary_accuracy: 0.9553 - recall_13: 0.0847 - precision_13: 0.5385 - val_loss: 0.3418 - val_acc: 0.8820 - val_auc: 0.6575 - val_binary_accuracy: 0.8820 - val_recall_13: 0.0219 - val_precision_13: 0.1429\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1465 - acc: 0.9568 - auc: 0.8237 - binary_accuracy: 0.9568 - recall_13: 0.1250 - precision_13: 0.6078 - val_loss: 0.3574 - val_acc: 0.8913 - val_auc: 0.6557 - val_binary_accuracy: 0.8913 - val_recall_13: 0.0055 - val_precision_13: 0.1667\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 3s 64ms/step - loss: 0.1406 - acc: 0.9579 - auc: 0.8374 - binary_accuracy: 0.9579 - recall_13: 0.1371 - precision_13: 0.6667 - val_loss: 0.3398 - val_acc: 0.8843 - val_auc: 0.6689 - val_binary_accuracy: 0.8843 - val_recall_13: 0.0437 - val_precision_13: 0.2500\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1357 - acc: 0.9570 - auc: 0.8528 - binary_accuracy: 0.9570 - recall_13: 0.1290 - precision_13: 0.6154 - val_loss: 0.3466 - val_acc: 0.8855 - val_auc: 0.6667 - val_binary_accuracy: 0.8855 - val_recall_13: 0.0219 - val_precision_13: 0.1818\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1299 - acc: 0.9586 - auc: 0.8724 - binary_accuracy: 0.9586 - recall_13: 0.1935 - precision_13: 0.6400 - val_loss: 0.4094 - val_acc: 0.8913 - val_auc: 0.6398 - val_binary_accuracy: 0.8913 - val_recall_13: 0.0055 - val_precision_13: 0.1667\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1333 - acc: 0.9580 - auc: 0.8643 - binary_accuracy: 0.9580 - recall_13: 0.1653 - precision_13: 0.6406 - val_loss: 0.3678 - val_acc: 0.8890 - val_auc: 0.6455 - val_binary_accuracy: 0.8890 - val_recall_13: 0.0546 - val_precision_13: 0.3571\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.1424 - acc: 0.9580 - auc: 0.8375 - binary_accuracy: 0.9580 - recall_13: 0.1976 - precision_13: 0.6125 - val_loss: 0.3556 - val_acc: 0.8808 - val_auc: 0.6568 - val_binary_accuracy: 0.8808 - val_recall_13: 0.0273 - val_precision_13: 0.1562\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.1332 - acc: 0.9591 - auc: 0.8620 - binary_accuracy: 0.9591 - recall_13: 0.1734 - precision_13: 0.6935 - val_loss: 0.4526 - val_acc: 0.8919 - val_auc: 0.6684 - val_binary_accuracy: 0.8919 - val_recall_13: 0.0055 - val_precision_13: 0.2000\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1249 - acc: 0.9602 - auc: 0.8903 - binary_accuracy: 0.9602 - recall_13: 0.1815 - precision_13: 0.7500 - val_loss: 0.4314 - val_acc: 0.8919 - val_auc: 0.6343 - val_binary_accuracy: 0.8919 - val_recall_13: 0.0055 - val_precision_13: 0.2000\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1317 - acc: 0.9597 - auc: 0.8748 - binary_accuracy: 0.9597 - recall_13: 0.1976 - precision_13: 0.6901 - val_loss: 0.3935 - val_acc: 0.8890 - val_auc: 0.6330 - val_binary_accuracy: 0.8890 - val_recall_13: 0.0219 - val_precision_13: 0.2500\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.1289 - acc: 0.9582 - auc: 0.8834 - binary_accuracy: 0.9582 - recall_13: 0.1935 - precision_13: 0.6234 - val_loss: 0.4733 - val_acc: 0.8901 - val_auc: 0.6418 - val_binary_accuracy: 0.8901 - val_recall_13: 0.0109 - val_precision_13: 0.2000\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.1250 - acc: 0.9595 - auc: 0.8903 - binary_accuracy: 0.9595 - recall_13: 0.2056 - precision_13: 0.6711 - val_loss: 0.4231 - val_acc: 0.8895 - val_auc: 0.6211 - val_binary_accuracy: 0.8895 - val_recall_13: 0.0109 - val_precision_13: 0.1818\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1184 - acc: 0.9622 - auc: 0.8961 - binary_accuracy: 0.9622 - recall_13: 0.2581 - precision_13: 0.7356 - val_loss: 0.4730 - val_acc: 0.8919 - val_auc: 0.6039 - val_binary_accuracy: 0.8919 - val_recall_13: 0.0055 - val_precision_13: 0.2000\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1145 - acc: 0.9635 - auc: 0.9078 - binary_accuracy: 0.9635 - recall_13: 0.2903 - precision_13: 0.7500 - val_loss: 0.4382 - val_acc: 0.8866 - val_auc: 0.6280 - val_binary_accuracy: 0.8866 - val_recall_13: 0.0328 - val_precision_13: 0.2500\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1357 - acc: 0.9571 - auc: 0.8739 - binary_accuracy: 0.9571 - recall_13: 0.2258 - precision_13: 0.5657 - val_loss: 0.4795 - val_acc: 0.8924 - val_auc: 0.6226 - val_binary_accuracy: 0.8924 - val_recall_13: 0.0219 - val_precision_13: 0.4000\n",
      "0.33647653460502625\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "644b9281-cd4f-4cf0-996c-6b82f2b7decf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "dbc05e9a-a885-49de-a68a-f66ec8c92138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_traditional Accuracy:  0.820661636680209 MSE:  0.17933836331979106 UAR:  0.5320117790706026 Recall:  0.21176470588235294 Precision:  0.06923076923076923 F1:  0.10434782608695653\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9239698200812536 MSE:  0.07603017991874637 UAR:  0.5528837175896 Recall:  0.1411764705882353 Precision:  0.17142857142857143 F1:  0.15483870967741936\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9402205455600696 MSE:  0.05977945443993035 UAR:  0.5335452129569777 Recall:  0.08235294117647059 Precision:  0.21875 F1:  0.11965811965811965\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9483459082994776 MSE:  0.05165409170052235 UAR:  0.5322416145945558 Recall:  0.07058823529411765 Precision:  0.375 F1:  0.11881188118811882\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9495066744051074 MSE:  0.05049332559489263 UAR:  0.5216979099332041 Recall:  0.047058823529411764 Precision:  0.4 F1:  0.08421052631578947\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_traditional Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.522613660848955 Recall:  0.047058823529411764 Precision:  0.5714285714285714 F1:  0.08695652173913043\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5229189111542053 Recall:  0.047058823529411764 Precision:  0.6666666666666666 F1:  0.08791208791208792\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5117647058823529 Recall:  0.023529411764705882 Precision:  1.0 F1:  0.04597701149425288\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_traditional Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5058823529411764 Recall:  0.011764705882352941 Precision:  1.0 F1:  0.023255813953488372\n",
      "0.2 0.5528837175896\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "94cdce8d-861c-41fc-a44c-853fc766f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "7ddca334-be96-4c91-8bfd-d31b2cbfaef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "240b01fc-ccf1-4e4d-9120-2f726fd03644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.575739988392339 MSE:  0.4242600116076611 UAR:  0.609548947784242 Recall:  0.6470588235294118 Precision:  0.07275132275132275 F1:  0.13079667063020212\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.840975043528729 MSE:  0.15902495647127105 UAR:  0.6598146951088127 Recall:  0.4588235294117647 Precision:  0.14606741573033707 F1:  0.2215909090909091\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9210679048171794 MSE:  0.07893209518282066 UAR:  0.6238598003303886 Recall:  0.29411764705882354 Precision:  0.24752475247524752 F1:  0.26881720430107525\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9437028438769588 MSE:  0.05629715612304121 UAR:  0.5967248437836673 Recall:  0.21176470588235294 Precision:  0.375 F1:  0.2706766917293233\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9477655252466628 MSE:  0.0522344747533372 UAR:  0.5598218774689363 Recall:  0.12941176470588237 Precision:  0.4074074074074074 F1:  0.19642857142857145\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5446168210874094 Recall:  0.09411764705882353 Precision:  0.5 F1:  0.15841584158415842\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9495066744051074 MSE:  0.05049332559489263 UAR:  0.5216979099332041 Recall:  0.047058823529411764 Precision:  0.4 F1:  0.08421052631578947\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5170365582130289 Recall:  0.03529411764705882 Precision:  0.6 F1:  0.06666666666666667\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.2 0.6598146951088127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a558c6-adc9-45bd-a59c-878d8be0c2a4",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "bdafdd4c-dc74-4eed-961a-4e3c22b438cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "50f5aa04-9da3-4083-a68a-9c0bff90f129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "b92c6d8e-6b77-4878-919b-b9b41f35e163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "val:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "6d0ee1a6-4b64-4bd5-8de6-2e2d6692c355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482,) (5482,)\n",
      "(1723,) (1723,)\n",
      "(7205,) (7205,)\n",
      "[0 1] [6872  333]\n",
      "7205\n",
      "5475\n",
      "1730\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "d95e1bfe-2c28-4e61-bd0b-2dedabedd8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5222/5475: 95.37899543378995%\n",
      "1 253/5475: 4.621004566210046%\n",
      "val:\n",
      "0 1650/1730: 95.3757225433526%\n",
      "1 80/1730: 4.624277456647399%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae739ad-154b-4d15-beee-592c58eb9ee5",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "5c1e9397-5072-4ba4-8f46-3a9dba402fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "c4b21013-d106-4288-88a0-cf6602d2a4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "3380b43e-bef0-417f-9905-dd0634e361c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 2048) (5475,)\n",
      "(1730, 128, 2048) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "445cf326-f8a8-4452-a408-80ef3c6034bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_26\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_26 (Dense)            (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "7390ff98-f3ce-4ab5-9796-2f5ad8626095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 4s 56ms/step - loss: 0.2223 - acc: 0.9443 - auc: 0.5189 - binary_accuracy: 0.9443 - recall_14: 0.0000e+00 - precision_14: 0.0000e+00 - val_loss: 0.1775 - val_acc: 0.9538 - val_auc: 0.6726 - val_binary_accuracy: 0.9538 - val_recall_14: 0.0000e+00 - val_precision_14: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1723 - acc: 0.9538 - auc: 0.7023 - binary_accuracy: 0.9538 - recall_14: 0.0000e+00 - precision_14: 0.0000e+00 - val_loss: 0.1682 - val_acc: 0.9538 - val_auc: 0.7322 - val_binary_accuracy: 0.9538 - val_recall_14: 0.0000e+00 - val_precision_14: 0.0000e+00\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1618 - acc: 0.9540 - auc: 0.7720 - binary_accuracy: 0.9540 - recall_14: 0.0040 - precision_14: 1.0000 - val_loss: 0.1675 - val_acc: 0.9538 - val_auc: 0.7538 - val_binary_accuracy: 0.9538 - val_recall_14: 0.0000e+00 - val_precision_14: 0.0000e+00\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1568 - acc: 0.9538 - auc: 0.7920 - binary_accuracy: 0.9538 - recall_14: 0.0000e+00 - precision_14: 0.0000e+00 - val_loss: 0.1603 - val_acc: 0.9538 - val_auc: 0.7721 - val_binary_accuracy: 0.9538 - val_recall_14: 0.0000e+00 - val_precision_14: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1548 - acc: 0.9556 - auc: 0.7933 - binary_accuracy: 0.9556 - recall_14: 0.0395 - precision_14: 1.0000 - val_loss: 0.1585 - val_acc: 0.9538 - val_auc: 0.7789 - val_binary_accuracy: 0.9538 - val_recall_14: 0.0125 - val_precision_14: 0.5000\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1499 - acc: 0.9549 - auc: 0.8231 - binary_accuracy: 0.9549 - recall_14: 0.0237 - precision_14: 1.0000 - val_loss: 0.1640 - val_acc: 0.9526 - val_auc: 0.7864 - val_binary_accuracy: 0.9526 - val_recall_14: 0.0625 - val_precision_14: 0.4167\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1484 - acc: 0.9569 - auc: 0.8226 - binary_accuracy: 0.9569 - recall_14: 0.0830 - precision_14: 0.8400 - val_loss: 0.1645 - val_acc: 0.9532 - val_auc: 0.7840 - val_binary_accuracy: 0.9532 - val_recall_14: 0.0500 - val_precision_14: 0.4444\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1470 - acc: 0.9558 - auc: 0.8291 - binary_accuracy: 0.9558 - recall_14: 0.0751 - precision_14: 0.7037 - val_loss: 0.1570 - val_acc: 0.9538 - val_auc: 0.7777 - val_binary_accuracy: 0.9538 - val_recall_14: 0.0125 - val_precision_14: 0.5000\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1426 - acc: 0.9558 - auc: 0.8466 - binary_accuracy: 0.9558 - recall_14: 0.0751 - precision_14: 0.7037 - val_loss: 0.1620 - val_acc: 0.9532 - val_auc: 0.7726 - val_binary_accuracy: 0.9532 - val_recall_14: 0.0000e+00 - val_precision_14: 0.0000e+00\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1418 - acc: 0.9576 - auc: 0.8467 - binary_accuracy: 0.9576 - recall_14: 0.0949 - precision_14: 0.8889 - val_loss: 0.1591 - val_acc: 0.9520 - val_auc: 0.7756 - val_binary_accuracy: 0.9520 - val_recall_14: 0.0125 - val_precision_14: 0.2000\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1354 - acc: 0.9585 - auc: 0.8700 - binary_accuracy: 0.9585 - recall_14: 0.1067 - precision_14: 0.9643 - val_loss: 0.1650 - val_acc: 0.9503 - val_auc: 0.7841 - val_binary_accuracy: 0.9503 - val_recall_14: 0.0750 - val_precision_14: 0.3333\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1353 - acc: 0.9582 - auc: 0.8662 - binary_accuracy: 0.9582 - recall_14: 0.1304 - precision_14: 0.7857 - val_loss: 0.1673 - val_acc: 0.9503 - val_auc: 0.7856 - val_binary_accuracy: 0.9503 - val_recall_14: 0.1125 - val_precision_14: 0.3750\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1336 - acc: 0.9584 - auc: 0.8729 - binary_accuracy: 0.9584 - recall_14: 0.1344 - precision_14: 0.7907 - val_loss: 0.1642 - val_acc: 0.9526 - val_auc: 0.7639 - val_binary_accuracy: 0.9526 - val_recall_14: 0.0000e+00 - val_precision_14: 0.0000e+00\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1300 - acc: 0.9587 - auc: 0.8847 - binary_accuracy: 0.9587 - recall_14: 0.1265 - precision_14: 0.8649 - val_loss: 0.1614 - val_acc: 0.9532 - val_auc: 0.7717 - val_binary_accuracy: 0.9532 - val_recall_14: 0.0750 - val_precision_14: 0.4615\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1296 - acc: 0.9600 - auc: 0.8839 - binary_accuracy: 0.9600 - recall_14: 0.1660 - precision_14: 0.8400 - val_loss: 0.1629 - val_acc: 0.9514 - val_auc: 0.7684 - val_binary_accuracy: 0.9514 - val_recall_14: 0.0875 - val_precision_14: 0.3889\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1242 - acc: 0.9595 - auc: 0.8972 - binary_accuracy: 0.9595 - recall_14: 0.1700 - precision_14: 0.7818 - val_loss: 0.1662 - val_acc: 0.9532 - val_auc: 0.7625 - val_binary_accuracy: 0.9532 - val_recall_14: 0.0250 - val_precision_14: 0.4000\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1204 - acc: 0.9602 - auc: 0.9047 - binary_accuracy: 0.9602 - recall_14: 0.1818 - precision_14: 0.8070 - val_loss: 0.1674 - val_acc: 0.9514 - val_auc: 0.7646 - val_binary_accuracy: 0.9514 - val_recall_14: 0.0375 - val_precision_14: 0.3000\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1253 - acc: 0.9580 - auc: 0.8934 - binary_accuracy: 0.9580 - recall_14: 0.1581 - precision_14: 0.7018 - val_loss: 0.1711 - val_acc: 0.9509 - val_auc: 0.7609 - val_binary_accuracy: 0.9509 - val_recall_14: 0.1250 - val_precision_14: 0.4000\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1176 - acc: 0.9613 - auc: 0.9134 - binary_accuracy: 0.9613 - recall_14: 0.2095 - precision_14: 0.8154 - val_loss: 0.1681 - val_acc: 0.9503 - val_auc: 0.7670 - val_binary_accuracy: 0.9503 - val_recall_14: 0.1250 - val_precision_14: 0.3846\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1139 - acc: 0.9629 - auc: 0.9168 - binary_accuracy: 0.9629 - recall_14: 0.2372 - precision_14: 0.8571 - val_loss: 0.1696 - val_acc: 0.9509 - val_auc: 0.7575 - val_binary_accuracy: 0.9509 - val_recall_14: 0.1000 - val_precision_14: 0.3810\n",
      "0.15699563920497894\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "0f4588b2-21aa-4938-99ac-a22d7209409c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "e57461ff-1676-4644-b986-1b7ec3ca7e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced Accuracy:  0.8560693641618498 MSE:  0.1439306358381503 UAR:  0.7045075757575757 Recall:  0.5375 Precision:  0.16862745098039217 F1:  0.2567164179104478\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced Accuracy:  0.9179190751445087 MSE:  0.08208092485549133 UAR:  0.6715151515151515 Recall:  0.4 Precision:  0.25396825396825395 F1:  0.3106796116504854\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced Accuracy:  0.9416184971098266 MSE:  0.05838150289017341 UAR:  0.6125757575757576 Recall:  0.25 Precision:  0.32786885245901637 F1:  0.28368794326241137\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced Accuracy:  0.9508670520231214 MSE:  0.049132947976878616 UAR:  0.5817424242424243 Recall:  0.175 Precision:  0.42424242424242425 F1:  0.247787610619469\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced Accuracy:  0.9514450867052023 MSE:  0.048554913294797684 UAR:  0.5463636363636364 Recall:  0.1 Precision:  0.4 F1:  0.16000000000000003\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5115909090909091 Recall:  0.025 Precision:  0.4 F1:  0.04705882352941177\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.4993939393939394 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.7045075757575757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "cc6658e5-5174-4567-b107-12f93b241005",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "7951c40b-66e7-4101-bbee-f7662fe39ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "679a5792-c59a-4cae-a86a-a6825109389e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.8791907514450867 MSE:  0.12080924855491329 UAR:  0.7225757575757576 Recall:  0.55 Precision:  0.20276497695852536 F1:  0.2962962962962963\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.9427745664739884 MSE:  0.05722543352601156 UAR:  0.636969696969697 Recall:  0.3 Precision:  0.3582089552238806 F1:  0.32653061224489793\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.9502890173410404 MSE:  0.04971098265895954 UAR:  0.5814393939393939 Recall:  0.175 Precision:  0.4117647058823529 F1:  0.2456140350877193\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.954335260115607 MSE:  0.04566473988439306 UAR:  0.5359848484848485 Recall:  0.075 Precision:  0.5454545454545454 F1:  0.13186813186813187\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5059469696969697 Recall:  0.0125 Precision:  0.5 F1:  0.02439024390243903\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.7225757575757576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67e6297-4df9-460c-a385-4d650524310b",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "986c03a2-84ba-4041-8355-afc7405f4dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_2_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "73944d34-5e99-4558-a07f-ac684ddb849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "12dcff9d-2efd-4c61-ad9b-6c5befb5af75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 2048) (5475,)\n",
      "(1730, 128, 2048) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "8f15ef1d-bf43-4c89-b3cc-6152f803870a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_27\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_13 (Attention)    (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention_13[0][0]']        \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention_13[0][0]',        \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_27 (Dense)            (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "d18df981-8b09-49eb-bb8e-576a37856a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 95ms/step - loss: 0.3851 - acc: 0.9410 - auc: 0.5399 - binary_accuracy: 0.9410 - recall_15: 0.0593 - precision_15: 0.1500 - val_loss: 0.1973 - val_acc: 0.9538 - val_auc: 0.6883 - val_binary_accuracy: 0.9538 - val_recall_15: 0.0000e+00 - val_precision_15: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1714 - acc: 0.9534 - auc: 0.7176 - binary_accuracy: 0.9534 - recall_15: 0.0277 - precision_15: 0.4375 - val_loss: 0.1686 - val_acc: 0.9549 - val_auc: 0.7377 - val_binary_accuracy: 0.9549 - val_recall_15: 0.0375 - val_precision_15: 0.7500\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1590 - acc: 0.9543 - auc: 0.7782 - binary_accuracy: 0.9543 - recall_15: 0.0632 - precision_15: 0.5517 - val_loss: 0.1681 - val_acc: 0.9520 - val_auc: 0.7399 - val_binary_accuracy: 0.9520 - val_recall_15: 0.0250 - val_precision_15: 0.2857\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1601 - acc: 0.9534 - auc: 0.7775 - binary_accuracy: 0.9534 - recall_15: 0.0672 - precision_15: 0.4722 - val_loss: 0.1939 - val_acc: 0.9538 - val_auc: 0.7289 - val_binary_accuracy: 0.9538 - val_recall_15: 0.0000e+00 - val_precision_15: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.1539 - acc: 0.9554 - auc: 0.7974 - binary_accuracy: 0.9554 - recall_15: 0.0870 - precision_15: 0.6286 - val_loss: 0.1690 - val_acc: 0.9532 - val_auc: 0.7590 - val_binary_accuracy: 0.9532 - val_recall_15: 0.0000e+00 - val_precision_15: 0.0000e+00\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1476 - acc: 0.9538 - auc: 0.8343 - binary_accuracy: 0.9538 - recall_15: 0.0830 - precision_15: 0.5000 - val_loss: 0.1688 - val_acc: 0.9520 - val_auc: 0.7677 - val_binary_accuracy: 0.9520 - val_recall_15: 0.0375 - val_precision_15: 0.3333\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1467 - acc: 0.9558 - auc: 0.8352 - binary_accuracy: 0.9558 - recall_15: 0.1304 - precision_15: 0.6000 - val_loss: 0.1796 - val_acc: 0.9538 - val_auc: 0.7326 - val_binary_accuracy: 0.9538 - val_recall_15: 0.0125 - val_precision_15: 0.5000\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1411 - acc: 0.9585 - auc: 0.8459 - binary_accuracy: 0.9585 - recall_15: 0.1462 - precision_15: 0.7708 - val_loss: 0.1679 - val_acc: 0.9526 - val_auc: 0.7468 - val_binary_accuracy: 0.9526 - val_recall_15: 0.0500 - val_precision_15: 0.4000\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1398 - acc: 0.9565 - auc: 0.8490 - binary_accuracy: 0.9565 - recall_15: 0.1304 - precision_15: 0.6471 - val_loss: 0.1842 - val_acc: 0.9538 - val_auc: 0.7378 - val_binary_accuracy: 0.9538 - val_recall_15: 0.0250 - val_precision_15: 0.5000\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1365 - acc: 0.9574 - auc: 0.8598 - binary_accuracy: 0.9574 - recall_15: 0.1779 - precision_15: 0.6429 - val_loss: 0.1706 - val_acc: 0.9543 - val_auc: 0.7354 - val_binary_accuracy: 0.9543 - val_recall_15: 0.1250 - val_precision_15: 0.5263\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.1323 - acc: 0.9582 - auc: 0.8775 - binary_accuracy: 0.9582 - recall_15: 0.1818 - precision_15: 0.6765 - val_loss: 0.1681 - val_acc: 0.9520 - val_auc: 0.7514 - val_binary_accuracy: 0.9520 - val_recall_15: 0.0375 - val_precision_15: 0.3333\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1265 - acc: 0.9609 - auc: 0.8865 - binary_accuracy: 0.9609 - recall_15: 0.2134 - precision_15: 0.7826 - val_loss: 0.1778 - val_acc: 0.9480 - val_auc: 0.7487 - val_binary_accuracy: 0.9480 - val_recall_15: 0.2000 - val_precision_15: 0.3810\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.1321 - acc: 0.9589 - auc: 0.8748 - binary_accuracy: 0.9589 - recall_15: 0.2292 - precision_15: 0.6591 - val_loss: 0.1772 - val_acc: 0.9491 - val_auc: 0.7543 - val_binary_accuracy: 0.9491 - val_recall_15: 0.1125 - val_precision_15: 0.3462\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.1257 - acc: 0.9595 - auc: 0.8881 - binary_accuracy: 0.9595 - recall_15: 0.1897 - precision_15: 0.7385 - val_loss: 0.2126 - val_acc: 0.9329 - val_auc: 0.7570 - val_binary_accuracy: 0.9329 - val_recall_15: 0.2750 - val_precision_15: 0.2750\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 3s 64ms/step - loss: 0.1304 - acc: 0.9591 - auc: 0.8772 - binary_accuracy: 0.9591 - recall_15: 0.2411 - precision_15: 0.6559 - val_loss: 0.1750 - val_acc: 0.9532 - val_auc: 0.7560 - val_binary_accuracy: 0.9532 - val_recall_15: 0.0625 - val_precision_15: 0.4545\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1230 - acc: 0.9602 - auc: 0.8967 - binary_accuracy: 0.9602 - recall_15: 0.2253 - precision_15: 0.7215 - val_loss: 0.1801 - val_acc: 0.9480 - val_auc: 0.7409 - val_binary_accuracy: 0.9480 - val_recall_15: 0.0750 - val_precision_15: 0.2727\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1224 - acc: 0.9620 - auc: 0.8936 - binary_accuracy: 0.9620 - recall_15: 0.2767 - precision_15: 0.7368 - val_loss: 0.1941 - val_acc: 0.9509 - val_auc: 0.6992 - val_binary_accuracy: 0.9509 - val_recall_15: 0.0375 - val_precision_15: 0.2727\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.1350 - acc: 0.9604 - auc: 0.8654 - binary_accuracy: 0.9604 - recall_15: 0.2451 - precision_15: 0.7045 - val_loss: 0.1975 - val_acc: 0.9520 - val_auc: 0.6904 - val_binary_accuracy: 0.9520 - val_recall_15: 0.0375 - val_precision_15: 0.3333\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.1235 - acc: 0.9598 - auc: 0.8923 - binary_accuracy: 0.9598 - recall_15: 0.2490 - precision_15: 0.6774 - val_loss: 0.1824 - val_acc: 0.9538 - val_auc: 0.7451 - val_binary_accuracy: 0.9538 - val_recall_15: 0.0500 - val_precision_15: 0.5000\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1225 - acc: 0.9609 - auc: 0.8928 - binary_accuracy: 0.9609 - recall_15: 0.2411 - precision_15: 0.7349 - val_loss: 0.1789 - val_acc: 0.9480 - val_auc: 0.7469 - val_binary_accuracy: 0.9480 - val_recall_15: 0.0750 - val_precision_15: 0.2727\n",
      "0.16794371604919434\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "bd97937b-a202-4b13-8b9a-5b96a581da6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "caf11540-0454-4c81-b562-b29affae033a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_balanced Accuracy:  0.8849710982658959 MSE:  0.11502890173410404 UAR:  0.7137121212121212 Recall:  0.525 Precision:  0.20689655172413793 F1:  0.2968197879858658\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9300578034682081 MSE:  0.06994219653179191 UAR:  0.6065151515151515 Recall:  0.25 Precision:  0.24691358024691357 F1:  0.2484472049689441\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9387283236994219 MSE:  0.06127167630057803 UAR:  0.5753787878787878 Recall:  0.175 Precision:  0.25925925925925924 F1:  0.208955223880597\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9410404624277456 MSE:  0.058959537572254334 UAR:  0.5409090909090909 Recall:  0.1 Precision:  0.21052631578947367 F1:  0.13559322033898305\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9479768786127167 MSE:  0.05202312138728324 UAR:  0.5326515151515152 Recall:  0.075 Precision:  0.2727272727272727 F1:  0.1176470588235294\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9508670520231214 MSE:  0.049132947976878616 UAR:  0.5222727272727272 Recall:  0.05 Precision:  0.3076923076923077 F1:  0.08602150537634409\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9508670520231214 MSE:  0.049132947976878616 UAR:  0.5163257575757576 Recall:  0.0375 Precision:  0.2727272727272727 F1:  0.06593406593406594\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9514450867052023 MSE:  0.048554913294797684 UAR:  0.5047348484848485 Recall:  0.0125 Precision:  0.16666666666666666 F1:  0.023255813953488372\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.7137121212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "172e3397-d2f0-451f-a676-0a4d0831a9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "f38ad336-dd9e-4a7d-9b69-2b0254a76383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "6ad68979-7b15-4332-9c12-e99f89ba748e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.8641618497109826 MSE:  0.13583815028901733 UAR:  0.6849621212121212 Recall:  0.4875 Precision:  0.16738197424892703 F1:  0.24920127795527158\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9179190751445087 MSE:  0.08208092485549133 UAR:  0.6179924242424242 Recall:  0.2875 Precision:  0.21296296296296297 F1:  0.2446808510638298\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9387283236994219 MSE:  0.06127167630057803 UAR:  0.5813257575757576 Recall:  0.1875 Precision:  0.26785714285714285 F1:  0.22058823529411767\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9514450867052023 MSE:  0.048554913294797684 UAR:  0.5582575757575757 Recall:  0.125 Precision:  0.4166666666666667 F1:  0.1923076923076923\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9514450867052023 MSE:  0.048554913294797684 UAR:  0.5225757575757576 Recall:  0.05 Precision:  0.3333333333333333 F1:  0.08695652173913045\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5175378787878788 Recall:  0.0375 Precision:  0.42857142857142855 F1:  0.06896551724137931\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.5053409090909091 Recall:  0.0125 Precision:  0.25 F1:  0.023809523809523808\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6849621212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc120f8-e400-4900-8d24-392a41bec51e",
   "metadata": {},
   "source": [
    "### Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "479780fa-bcad-40e2-b671-08bc9381a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.max\n",
    "stat_name = \"max\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9f19a8-3669-4ce2-81f1-9a108cb730b1",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "acfd728b-b786-46d9-a044-a8fe42dea55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "74125cb4-a83e-47d0-8ffb-5fe899cda949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "ba1fb5e9-0e34-4b79-90f4-635f9950d232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "test:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n",
      "val:\n",
      "0 1537/1720: 89.36046511627907%\n",
      "1 183/1720: 10.63953488372093%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6f7335-e42c-4dc9-ac48-5a12e7686ac5",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "7ef63001-6180-4216-ba33-7474bf4cd0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "01129be0-fb65-4707-b031-47c713023c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "cbb5bc31-92a1-4845-9d9c-4b078ebbd67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2048) (5482,)\n",
      "(1723, 128, 2048) (1723,)\n",
      "(1720, 128, 2048) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "2ae44fa1-0c38-41a1-bd6d-4910ee90e9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_28\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_28 (Dense)            (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "d5bab413-662c-475c-b9c9-ee30916bae99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 4s 55ms/step - loss: 0.2203 - acc: 0.9538 - auc: 0.5377 - binary_accuracy: 0.9538 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00 - val_loss: 0.3500 - val_acc: 0.8936 - val_auc: 0.6077 - val_binary_accuracy: 0.8936 - val_recall_16: 0.0000e+00 - val_precision_16: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1698 - acc: 0.9544 - auc: 0.7120 - binary_accuracy: 0.9544 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00 - val_loss: 0.3314 - val_acc: 0.8936 - val_auc: 0.6549 - val_binary_accuracy: 0.8936 - val_recall_16: 0.0000e+00 - val_precision_16: 0.0000e+00\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1608 - acc: 0.9548 - auc: 0.7555 - binary_accuracy: 0.9548 - recall_16: 0.0040 - precision_16: 0.5000 - val_loss: 0.3560 - val_acc: 0.8936 - val_auc: 0.6486 - val_binary_accuracy: 0.8936 - val_recall_16: 0.0000e+00 - val_precision_16: 0.0000e+00\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1580 - acc: 0.9542 - auc: 0.7737 - binary_accuracy: 0.9542 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00 - val_loss: 0.3329 - val_acc: 0.8936 - val_auc: 0.6714 - val_binary_accuracy: 0.8936 - val_recall_16: 0.0000e+00 - val_precision_16: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1508 - acc: 0.9553 - auc: 0.8017 - binary_accuracy: 0.9553 - recall_16: 0.0242 - precision_16: 0.6667 - val_loss: 0.3341 - val_acc: 0.8936 - val_auc: 0.6712 - val_binary_accuracy: 0.8936 - val_recall_16: 0.0000e+00 - val_precision_16: 0.0000e+00\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1477 - acc: 0.9551 - auc: 0.8184 - binary_accuracy: 0.9551 - recall_16: 0.0282 - precision_16: 0.5833 - val_loss: 0.3318 - val_acc: 0.8942 - val_auc: 0.6918 - val_binary_accuracy: 0.8942 - val_recall_16: 0.0055 - val_precision_16: 1.0000\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1444 - acc: 0.9564 - auc: 0.8287 - binary_accuracy: 0.9564 - recall_16: 0.0444 - precision_16: 0.8462 - val_loss: 0.3306 - val_acc: 0.8936 - val_auc: 0.6929 - val_binary_accuracy: 0.8936 - val_recall_16: 0.0109 - val_precision_16: 0.5000\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1461 - acc: 0.9566 - auc: 0.8204 - binary_accuracy: 0.9566 - recall_16: 0.0766 - precision_16: 0.6786 - val_loss: 0.3478 - val_acc: 0.8936 - val_auc: 0.6846 - val_binary_accuracy: 0.8936 - val_recall_16: 0.0000e+00 - val_precision_16: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1422 - acc: 0.9566 - auc: 0.8379 - binary_accuracy: 0.9566 - recall_16: 0.0726 - precision_16: 0.6923 - val_loss: 0.3292 - val_acc: 0.8913 - val_auc: 0.6878 - val_binary_accuracy: 0.8913 - val_recall_16: 0.0546 - val_precision_16: 0.4167\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.1379 - acc: 0.9571 - auc: 0.8507 - binary_accuracy: 0.9571 - recall_16: 0.0806 - precision_16: 0.7407 - val_loss: 0.3316 - val_acc: 0.8901 - val_auc: 0.6946 - val_binary_accuracy: 0.8901 - val_recall_16: 0.0546 - val_precision_16: 0.3846\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1355 - acc: 0.9577 - auc: 0.8570 - binary_accuracy: 0.9577 - recall_16: 0.0927 - precision_16: 0.7667 - val_loss: 0.3365 - val_acc: 0.8907 - val_auc: 0.6878 - val_binary_accuracy: 0.8907 - val_recall_16: 0.0437 - val_precision_16: 0.3810\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1416 - acc: 0.9590 - auc: 0.8416 - binary_accuracy: 0.9590 - recall_16: 0.1290 - precision_16: 0.7805 - val_loss: 0.3467 - val_acc: 0.8715 - val_auc: 0.6884 - val_binary_accuracy: 0.8715 - val_recall_16: 0.1093 - val_precision_16: 0.2564\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1336 - acc: 0.9599 - auc: 0.8660 - binary_accuracy: 0.9599 - recall_16: 0.1290 - precision_16: 0.8889 - val_loss: 0.3726 - val_acc: 0.8936 - val_auc: 0.6824 - val_binary_accuracy: 0.8936 - val_recall_16: 0.0055 - val_precision_16: 0.5000\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1290 - acc: 0.9593 - auc: 0.8777 - binary_accuracy: 0.9593 - recall_16: 0.1613 - precision_16: 0.7273 - val_loss: 0.3925 - val_acc: 0.8930 - val_auc: 0.6799 - val_binary_accuracy: 0.8930 - val_recall_16: 0.0055 - val_precision_16: 0.3333\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1307 - acc: 0.9593 - auc: 0.8733 - binary_accuracy: 0.9593 - recall_16: 0.1290 - precision_16: 0.8205 - val_loss: 0.3790 - val_acc: 0.8924 - val_auc: 0.6754 - val_binary_accuracy: 0.8924 - val_recall_16: 0.0055 - val_precision_16: 0.2500\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1293 - acc: 0.9591 - auc: 0.8736 - binary_accuracy: 0.9591 - recall_16: 0.1653 - precision_16: 0.7069 - val_loss: 0.4281 - val_acc: 0.8924 - val_auc: 0.6668 - val_binary_accuracy: 0.8924 - val_recall_16: 0.0055 - val_precision_16: 0.2500\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1265 - acc: 0.9590 - auc: 0.8823 - binary_accuracy: 0.9590 - recall_16: 0.1653 - precision_16: 0.6949 - val_loss: 0.3978 - val_acc: 0.8913 - val_auc: 0.6703 - val_binary_accuracy: 0.8913 - val_recall_16: 0.0109 - val_precision_16: 0.2500\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1264 - acc: 0.9615 - auc: 0.8776 - binary_accuracy: 0.9615 - recall_16: 0.1935 - precision_16: 0.8136 - val_loss: 0.4081 - val_acc: 0.8942 - val_auc: 0.6717 - val_binary_accuracy: 0.8942 - val_recall_16: 0.0055 - val_precision_16: 1.0000\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1164 - acc: 0.9624 - auc: 0.9111 - binary_accuracy: 0.9624 - recall_16: 0.2016 - precision_16: 0.8621 - val_loss: 0.3905 - val_acc: 0.8942 - val_auc: 0.6768 - val_binary_accuracy: 0.8942 - val_recall_16: 0.0055 - val_precision_16: 1.0000\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1239 - acc: 0.9606 - auc: 0.8885 - binary_accuracy: 0.9606 - recall_16: 0.1895 - precision_16: 0.7581 - val_loss: 0.3725 - val_acc: 0.8651 - val_auc: 0.6732 - val_binary_accuracy: 0.8651 - val_recall_16: 0.1038 - val_precision_16: 0.2184\n",
      "0.32920607924461365\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "cb42aa44-6441-49d8-8276-1e5d86703eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "12a7478e-5653-4861-8d31-979b648dc00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional Accuracy:  0.5455600696459664 MSE:  0.4544399303540337 UAR:  0.6215614450908569 Recall:  0.7058823529411765 Precision:  0.07334963325183375 F1:  0.132890365448505\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional Accuracy:  0.7260591990713872 MSE:  0.2739408009286129 UAR:  0.6718774689362925 Recall:  0.611764705882353 Precision:  0.10590631364562118 F1:  0.18055555555555555\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional Accuracy:  0.8154381892048752 MSE:  0.1845618107951248 UAR:  0.6631149895855779 Recall:  0.49411764705882355 Precision:  0.13249211356466878 F1:  0.208955223880597\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional Accuracy:  0.8670922809053976 MSE:  0.13290771909460244 UAR:  0.6512425483013718 Recall:  0.4117647058823529 Precision:  0.16355140186915887 F1:  0.23411371237458192\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional Accuracy:  0.9048171793383634 MSE:  0.09518282066163668 UAR:  0.6264669970552323 Recall:  0.3176470588235294 Precision:  0.20300751879699247 F1:  0.24770642201834867\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional Accuracy:  0.9210679048171794 MSE:  0.07893209518282066 UAR:  0.5792429792429793 Recall:  0.2 Precision:  0.2 F1:  0.20000000000000004\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional Accuracy:  0.9361578641903656 MSE:  0.06384213580963435 UAR:  0.5592939739998564 Recall:  0.1411764705882353 Precision:  0.24489795918367346 F1:  0.17910447761194032\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional Accuracy:  0.9495066744051074 MSE:  0.05049332559489263 UAR:  0.5328521152050564 Recall:  0.07058823529411765 Precision:  0.42857142857142855 F1:  0.1212121212121212\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5055771026359261 Recall:  0.011764705882352941 Precision:  0.5 F1:  0.02298850574712644\n",
      "0.2 0.6718774689362925\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "781ebc6c-3b0e-41cd-8de3-3928d8090501",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "71e4c604-bd93-43ab-8339-f952cddaaee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "e02c2584-601f-43f2-9a91-09c7bd183b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.5908299477655252 MSE:  0.4091700522344748 UAR:  0.6453709689003807 Recall:  0.7058823529411765 Precision:  0.08108108108108109 F1:  0.14545454545454548\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.8026697620429484 MSE:  0.19733023795705165 UAR:  0.6396681749622926 Recall:  0.4588235294117647 Precision:  0.11711711711711711 F1:  0.18660287081339713\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.9071387115496228 MSE:  0.09286128845037725 UAR:  0.6276879982762336 Recall:  0.3176470588235294 Precision:  0.20930232558139536 F1:  0.2523364485981308\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.946604759141033 MSE:  0.053395240858966915 UAR:  0.5815197874021404 Recall:  0.17647058823529413 Precision:  0.40540540540540543 F1:  0.24590163934426235\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5340731164260576 Recall:  0.07058823529411765 Precision:  0.6 F1:  0.12631578947368421\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5114594555771026 Recall:  0.023529411764705882 Precision:  0.6666666666666666 F1:  0.045454545454545456\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6453709689003807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c9a84-6da9-42a3-8f3b-c3a2aa642e33",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "29a562d8-dc8c-429a-b078-ef463107324c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_2_max_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "ca70fe56-f824-4acc-872f-5616cc56ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "89bf0066-4164-4f2c-b675-a09a67122ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2048) (5482,)\n",
      "(1723, 128, 2048) (1723,)\n",
      "(1720, 128, 2048) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "d8bf3906-19b6-449d-a343-88243a591523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_29\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_14 (Attention)    (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention_14[0][0]']        \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention_14[0][0]',        \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_29 (Dense)            (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "b8e7f2fb-2417-4484-ba7c-da2681efc278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 94ms/step - loss: 0.9046 - acc: 0.9259 - auc: 0.5388 - binary_accuracy: 0.9259 - recall_17: 0.0685 - precision_17: 0.0885 - val_loss: 0.5634 - val_acc: 0.8936 - val_auc: 0.5168 - val_binary_accuracy: 0.8936 - val_recall_17: 0.0000e+00 - val_precision_17: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 3s 64ms/step - loss: 0.1865 - acc: 0.9526 - auc: 0.6456 - binary_accuracy: 0.9526 - recall_17: 0.0121 - precision_17: 0.1667 - val_loss: 0.3380 - val_acc: 0.8919 - val_auc: 0.6463 - val_binary_accuracy: 0.8919 - val_recall_17: 0.0055 - val_precision_17: 0.2000\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1605 - acc: 0.9542 - auc: 0.7603 - binary_accuracy: 0.9542 - recall_17: 0.0363 - precision_17: 0.4286 - val_loss: 0.3453 - val_acc: 0.8895 - val_auc: 0.6549 - val_binary_accuracy: 0.8895 - val_recall_17: 0.0546 - val_precision_17: 0.3704\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1603 - acc: 0.9533 - auc: 0.7661 - binary_accuracy: 0.9533 - recall_17: 0.0524 - precision_17: 0.3824 - val_loss: 0.5028 - val_acc: 0.8936 - val_auc: 0.6117 - val_binary_accuracy: 0.8936 - val_recall_17: 0.0000e+00 - val_precision_17: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.1713 - acc: 0.9540 - auc: 0.7381 - binary_accuracy: 0.9540 - recall_17: 0.1048 - precision_17: 0.4643 - val_loss: 0.4424 - val_acc: 0.8936 - val_auc: 0.6306 - val_binary_accuracy: 0.8936 - val_recall_17: 0.0000e+00 - val_precision_17: 0.0000e+00\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.1684 - acc: 0.9535 - auc: 0.7433 - binary_accuracy: 0.9535 - recall_17: 0.0887 - precision_17: 0.4314 - val_loss: 0.3564 - val_acc: 0.8901 - val_auc: 0.6499 - val_binary_accuracy: 0.8901 - val_recall_17: 0.0000e+00 - val_precision_17: 0.0000e+00\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1477 - acc: 0.9568 - auc: 0.8092 - binary_accuracy: 0.9568 - recall_17: 0.0726 - precision_17: 0.7200 - val_loss: 0.3476 - val_acc: 0.8692 - val_auc: 0.6680 - val_binary_accuracy: 0.8692 - val_recall_17: 0.0874 - val_precision_17: 0.2162\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.1564 - acc: 0.9538 - auc: 0.7942 - binary_accuracy: 0.9538 - recall_17: 0.1290 - precision_17: 0.4638 - val_loss: 0.3739 - val_acc: 0.8890 - val_auc: 0.6600 - val_binary_accuracy: 0.8890 - val_recall_17: 0.0383 - val_precision_17: 0.3182\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1418 - acc: 0.9564 - auc: 0.8388 - binary_accuracy: 0.9564 - recall_17: 0.0806 - precision_17: 0.6452 - val_loss: 0.3487 - val_acc: 0.8762 - val_auc: 0.6707 - val_binary_accuracy: 0.8762 - val_recall_17: 0.0984 - val_precision_17: 0.2727\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1398 - acc: 0.9557 - auc: 0.8472 - binary_accuracy: 0.9557 - recall_17: 0.1048 - precision_17: 0.5532 - val_loss: 0.3676 - val_acc: 0.8901 - val_auc: 0.6539 - val_binary_accuracy: 0.8901 - val_recall_17: 0.0109 - val_precision_17: 0.2000\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.1397 - acc: 0.9584 - auc: 0.8438 - binary_accuracy: 0.9584 - recall_17: 0.1573 - precision_17: 0.6724 - val_loss: 0.4048 - val_acc: 0.8936 - val_auc: 0.6544 - val_binary_accuracy: 0.8936 - val_recall_17: 0.0055 - val_precision_17: 0.5000\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.1453 - acc: 0.9542 - auc: 0.8321 - binary_accuracy: 0.9542 - recall_17: 0.1129 - precision_17: 0.4746 - val_loss: 0.3864 - val_acc: 0.8913 - val_auc: 0.6667 - val_binary_accuracy: 0.8913 - val_recall_17: 0.0055 - val_precision_17: 0.1667\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1332 - acc: 0.9573 - auc: 0.8680 - binary_accuracy: 0.9573 - recall_17: 0.1250 - precision_17: 0.6458 - val_loss: 0.3854 - val_acc: 0.8930 - val_auc: 0.6598 - val_binary_accuracy: 0.8930 - val_recall_17: 0.0055 - val_precision_17: 0.3333\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.1450 - acc: 0.9557 - auc: 0.8261 - binary_accuracy: 0.9557 - recall_17: 0.1371 - precision_17: 0.5397 - val_loss: 0.4236 - val_acc: 0.8110 - val_auc: 0.6787 - val_binary_accuracy: 0.8110 - val_recall_17: 0.3005 - val_precision_17: 0.2183\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1439 - acc: 0.9555 - auc: 0.8357 - binary_accuracy: 0.9555 - recall_17: 0.1210 - precision_17: 0.5357 - val_loss: 0.3774 - val_acc: 0.8895 - val_auc: 0.6574 - val_binary_accuracy: 0.8895 - val_recall_17: 0.0273 - val_precision_17: 0.2941\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1353 - acc: 0.9582 - auc: 0.8550 - binary_accuracy: 0.9582 - recall_17: 0.1492 - precision_17: 0.6727 - val_loss: 0.3531 - val_acc: 0.8884 - val_auc: 0.6737 - val_binary_accuracy: 0.8884 - val_recall_17: 0.0601 - val_precision_17: 0.3548\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.1443 - acc: 0.9582 - auc: 0.8304 - binary_accuracy: 0.9582 - recall_17: 0.1855 - precision_17: 0.6301 - val_loss: 0.3839 - val_acc: 0.8884 - val_auc: 0.6687 - val_binary_accuracy: 0.8884 - val_recall_17: 0.0109 - val_precision_17: 0.1538\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1324 - acc: 0.9591 - auc: 0.8671 - binary_accuracy: 0.9591 - recall_17: 0.1734 - precision_17: 0.6935 - val_loss: 0.4082 - val_acc: 0.8930 - val_auc: 0.6539 - val_binary_accuracy: 0.8930 - val_recall_17: 0.0109 - val_precision_17: 0.4000\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1353 - acc: 0.9580 - auc: 0.8564 - binary_accuracy: 0.9580 - recall_17: 0.2056 - precision_17: 0.6071 - val_loss: 0.3661 - val_acc: 0.8860 - val_auc: 0.6536 - val_binary_accuracy: 0.8860 - val_recall_17: 0.0546 - val_precision_17: 0.3030\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1223 - acc: 0.9610 - auc: 0.8897 - binary_accuracy: 0.9610 - recall_17: 0.1935 - precision_17: 0.7742 - val_loss: 0.3991 - val_acc: 0.8576 - val_auc: 0.6524 - val_binary_accuracy: 0.8576 - val_recall_17: 0.1585 - val_precision_17: 0.2417\n",
      "0.3379881978034973\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c681b8e7-9444-4d88-b4dd-636cb677df1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377f2b20-a393-470d-a73d-d55e695e3741",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4996bfe9-03e1-41a9-8dfe-a25a48b96be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "2ee79b8a-f752-41d8-8a00-39a4ad568639",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "f6d5fffd-bf77-4082-b3cb-5218b1e68d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_traditional_best Accuracy:  0.7417295414973882 MSE:  0.2582704585026117 UAR:  0.6076168929110105 Recall:  0.4588235294117647 Precision:  0.08904109589041095 F1:  0.14913957934990438\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_traditional_best Accuracy:  0.9251305861868834 MSE:  0.07486941381311665 UAR:  0.6148423471952884 Recall:  0.27058823529411763 Precision:  0.25555555555555554 F1:  0.2628571428571429\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_traditional_best Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.6009983480571716 Recall:  0.21176470588235294 Precision:  0.5294117647058824 F1:  0.3025210084033613\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5390397184514831 Recall:  0.08235294117647059 Precision:  0.5 F1:  0.1414141414141414\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5167313079077785 Recall:  0.03529411764705882 Precision:  0.5 F1:  0.06593406593406594\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5111542052718523 Recall:  0.023529411764705882 Precision:  0.5 F1:  0.0449438202247191\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5055771026359261 Recall:  0.011764705882352941 Precision:  0.5 F1:  0.02298850574712644\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_traditional_best Accuracy:  0.9500870574579222 MSE:  0.04991294254207777 UAR:  0.4996947496947497 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.2 0.6148423471952884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b71195f-06ea-424b-b655-c372e8cfa705",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "e92053af-8454-4584-a282-a798926379be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "9c8bfb94-7941-424b-9cad-b322a4ef0f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "a3f818ee-f5fd-4cce-b1ac-52594ea071f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "val:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "8282bffa-0423-414f-b219-52b031b54e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482,) (5482,)\n",
      "(1723,) (1723,)\n",
      "(7205,) (7205,)\n",
      "[0 1] [6872  333]\n",
      "7205\n",
      "5475\n",
      "1730\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "ee79a1bf-19be-4db3-8380-cdf0639472cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5222/5475: 95.37899543378995%\n",
      "1 253/5475: 4.621004566210046%\n",
      "val:\n",
      "0 1650/1730: 95.3757225433526%\n",
      "1 80/1730: 4.624277456647399%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028ca596-44a0-4eae-899e-458cfeb34320",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "a81e09b1-e831-4c06-b788-9653e537857e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "69e16f1a-7b6f-4c17-b6e6-5780e28f37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "11101c7d-0933-4c6a-96f6-b9f67fb0ffc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 2048) (5475,)\n",
      "(1730, 128, 2048) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "a53207bb-3367-4a8e-b72c-f31b80aaffe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_30\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_30 (Dense)            (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "74b0bf7f-ce0f-4ca8-bf27-d8ec12c5b96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 4s 57ms/step - loss: 0.2681 - acc: 0.9370 - auc: 0.5105 - binary_accuracy: 0.9370 - recall_18: 0.0158 - precision_18: 0.0400 - val_loss: 0.1837 - val_acc: 0.9538 - val_auc: 0.6330 - val_binary_accuracy: 0.9538 - val_recall_18: 0.0000e+00 - val_precision_18: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1751 - acc: 0.9538 - auc: 0.6807 - binary_accuracy: 0.9538 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00 - val_loss: 0.1708 - val_acc: 0.9538 - val_auc: 0.7270 - val_binary_accuracy: 0.9538 - val_recall_18: 0.0000e+00 - val_precision_18: 0.0000e+00\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1655 - acc: 0.9538 - auc: 0.7413 - binary_accuracy: 0.9538 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00 - val_loss: 0.1730 - val_acc: 0.9538 - val_auc: 0.7468 - val_binary_accuracy: 0.9538 - val_recall_18: 0.0000e+00 - val_precision_18: 0.0000e+00\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1626 - acc: 0.9538 - auc: 0.7543 - binary_accuracy: 0.9538 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00 - val_loss: 0.1618 - val_acc: 0.9538 - val_auc: 0.7737 - val_binary_accuracy: 0.9538 - val_recall_18: 0.0000e+00 - val_precision_18: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1570 - acc: 0.9538 - auc: 0.7910 - binary_accuracy: 0.9538 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00 - val_loss: 0.1627 - val_acc: 0.9538 - val_auc: 0.7751 - val_binary_accuracy: 0.9538 - val_recall_18: 0.0000e+00 - val_precision_18: 0.0000e+00\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1512 - acc: 0.9538 - auc: 0.8109 - binary_accuracy: 0.9538 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00 - val_loss: 0.1587 - val_acc: 0.9538 - val_auc: 0.7860 - val_binary_accuracy: 0.9538 - val_recall_18: 0.0000e+00 - val_precision_18: 0.0000e+00\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1507 - acc: 0.9538 - auc: 0.8195 - binary_accuracy: 0.9538 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00 - val_loss: 0.1590 - val_acc: 0.9538 - val_auc: 0.7791 - val_binary_accuracy: 0.9538 - val_recall_18: 0.0000e+00 - val_precision_18: 0.0000e+00\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1488 - acc: 0.9538 - auc: 0.8266 - binary_accuracy: 0.9538 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00 - val_loss: 0.1572 - val_acc: 0.9538 - val_auc: 0.7842 - val_binary_accuracy: 0.9538 - val_recall_18: 0.0000e+00 - val_precision_18: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.1447 - acc: 0.9538 - auc: 0.8428 - binary_accuracy: 0.9538 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00 - val_loss: 0.1593 - val_acc: 0.9538 - val_auc: 0.7823 - val_binary_accuracy: 0.9538 - val_recall_18: 0.0000e+00 - val_precision_18: 0.0000e+00\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1436 - acc: 0.9538 - auc: 0.8416 - binary_accuracy: 0.9538 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00 - val_loss: 0.1577 - val_acc: 0.9538 - val_auc: 0.7801 - val_binary_accuracy: 0.9538 - val_recall_18: 0.0000e+00 - val_precision_18: 0.0000e+00\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1408 - acc: 0.9538 - auc: 0.8576 - binary_accuracy: 0.9538 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00 - val_loss: 0.1785 - val_acc: 0.9538 - val_auc: 0.7653 - val_binary_accuracy: 0.9538 - val_recall_18: 0.0000e+00 - val_precision_18: 0.0000e+00\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1366 - acc: 0.9538 - auc: 0.8691 - binary_accuracy: 0.9538 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00 - val_loss: 0.1633 - val_acc: 0.9538 - val_auc: 0.7728 - val_binary_accuracy: 0.9538 - val_recall_18: 0.0000e+00 - val_precision_18: 0.0000e+00\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1383 - acc: 0.9540 - auc: 0.8613 - binary_accuracy: 0.9540 - recall_18: 0.0040 - precision_18: 1.0000 - val_loss: 0.1709 - val_acc: 0.9538 - val_auc: 0.7645 - val_binary_accuracy: 0.9538 - val_recall_18: 0.0000e+00 - val_precision_18: 0.0000e+00\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.1416 - acc: 0.9543 - auc: 0.8508 - binary_accuracy: 0.9543 - recall_18: 0.0119 - precision_18: 1.0000 - val_loss: 0.2006 - val_acc: 0.9538 - val_auc: 0.7610 - val_binary_accuracy: 0.9538 - val_recall_18: 0.0000e+00 - val_precision_18: 0.0000e+00\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1342 - acc: 0.9540 - auc: 0.8799 - binary_accuracy: 0.9540 - recall_18: 0.0040 - precision_18: 1.0000 - val_loss: 0.1605 - val_acc: 0.9538 - val_auc: 0.7753 - val_binary_accuracy: 0.9538 - val_recall_18: 0.0000e+00 - val_precision_18: 0.0000e+00\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.1307 - acc: 0.9543 - auc: 0.8872 - binary_accuracy: 0.9543 - recall_18: 0.0119 - precision_18: 1.0000 - val_loss: 0.1610 - val_acc: 0.9532 - val_auc: 0.7761 - val_binary_accuracy: 0.9532 - val_recall_18: 0.0000e+00 - val_precision_18: 0.0000e+00\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1331 - acc: 0.9551 - auc: 0.8791 - binary_accuracy: 0.9551 - recall_18: 0.0277 - precision_18: 1.0000 - val_loss: 0.1670 - val_acc: 0.9532 - val_auc: 0.7797 - val_binary_accuracy: 0.9532 - val_recall_18: 0.0000e+00 - val_precision_18: 0.0000e+00\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.1364 - acc: 0.9543 - auc: 0.8661 - binary_accuracy: 0.9543 - recall_18: 0.0119 - precision_18: 1.0000 - val_loss: 0.1607 - val_acc: 0.9538 - val_auc: 0.7700 - val_binary_accuracy: 0.9538 - val_recall_18: 0.0000e+00 - val_precision_18: 0.0000e+00\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1233 - acc: 0.9551 - auc: 0.9050 - binary_accuracy: 0.9551 - recall_18: 0.0277 - precision_18: 1.0000 - val_loss: 0.1615 - val_acc: 0.9532 - val_auc: 0.7673 - val_binary_accuracy: 0.9532 - val_recall_18: 0.0000e+00 - val_precision_18: 0.0000e+00\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.1228 - acc: 0.9549 - auc: 0.9064 - binary_accuracy: 0.9549 - recall_18: 0.0277 - precision_18: 0.8750 - val_loss: 0.1630 - val_acc: 0.9538 - val_auc: 0.7705 - val_binary_accuracy: 0.9538 - val_recall_18: 0.0000e+00 - val_precision_18: 0.0000e+00\n",
      "0.15724459290504456\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "c76d17f5-7089-40a5-bf43-82ab512e012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "740aa1ba-aa51-43e1-8e40-abd20449fa30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced Accuracy:  0.8473988439306358 MSE:  0.15260115606936417 UAR:  0.7178030303030303 Recall:  0.575 Precision:  0.16666666666666666 F1:  0.25842696629213485\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced Accuracy:  0.9277456647398844 MSE:  0.07225433526011561 UAR:  0.6766666666666667 Recall:  0.4 Precision:  0.29357798165137616 F1:  0.3386243386243386\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced Accuracy:  0.945664739884393 MSE:  0.05433526011560694 UAR:  0.6206439393939394 Recall:  0.2625 Precision:  0.375 F1:  0.3088235294117648\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced Accuracy:  0.9497109826589596 MSE:  0.050289017341040465 UAR:  0.5395075757575757 Recall:  0.0875 Precision:  0.3333333333333333 F1:  0.13861386138613863\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.7178030303030303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "ea001ae4-e979-4f75-80c9-e68b69bb281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "52f492bb-b8d4-4493-bfa7-450bd7822bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "35df4f65-7535-4dd8-a465-43458fa45c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.9121387283236995 MSE:  0.08786127167630058 UAR:  0.7101136363636363 Recall:  0.4875 Precision:  0.26 F1:  0.3391304347826087\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.945664739884393 MSE:  0.05433526011560694 UAR:  0.6206439393939394 Recall:  0.2625 Precision:  0.375 F1:  0.3088235294117648\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.9514450867052023 MSE:  0.048554913294797684 UAR:  0.5582575757575757 Recall:  0.125 Precision:  0.4166666666666667 F1:  0.1923076923076923\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.7101136363636363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5505a82f-1599-4ffa-9ea2-f648f3f869e4",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "dd8a23ac-cb9b-4f73-b9b4-ba58bf45cb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_2_max_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "8d8867ee-00fe-4fa5-ab60-4b48d53a76e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "ea829990-2cff-43ee-9d79-9727a0520784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 2048) (5475,)\n",
      "(1730, 128, 2048) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "b491f70b-d22c-4e86-8f83-2cdcf71cfdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_31\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_15 (Attention)    (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention_15[0][0]']        \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention_15[0][0]',        \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_31 (Dense)            (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "a1c4ebed-d03a-46b5-ad29-0c4559729b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 94ms/step - loss: 0.6588 - acc: 0.9302 - auc: 0.5810 - binary_accuracy: 0.9302 - recall_19: 0.0791 - precision_19: 0.1183 - val_loss: 0.1834 - val_acc: 0.9503 - val_auc: 0.6953 - val_binary_accuracy: 0.9503 - val_recall_19: 0.1000 - val_precision_19: 0.3636\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1791 - acc: 0.9527 - auc: 0.6992 - binary_accuracy: 0.9527 - recall_19: 0.0474 - precision_19: 0.4000 - val_loss: 0.1724 - val_acc: 0.9538 - val_auc: 0.7251 - val_binary_accuracy: 0.9538 - val_recall_19: 0.0125 - val_precision_19: 0.5000\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1765 - acc: 0.9532 - auc: 0.7144 - binary_accuracy: 0.9532 - recall_19: 0.0949 - precision_19: 0.4706 - val_loss: 0.1718 - val_acc: 0.9509 - val_auc: 0.7603 - val_binary_accuracy: 0.9509 - val_recall_19: 0.1000 - val_precision_19: 0.3810\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 3s 64ms/step - loss: 0.1563 - acc: 0.9547 - auc: 0.7887 - binary_accuracy: 0.9547 - recall_19: 0.0988 - precision_19: 0.5556 - val_loss: 0.1782 - val_acc: 0.9532 - val_auc: 0.7437 - val_binary_accuracy: 0.9532 - val_recall_19: 0.0000e+00 - val_precision_19: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1575 - acc: 0.9532 - auc: 0.7842 - binary_accuracy: 0.9532 - recall_19: 0.0791 - precision_19: 0.4651 - val_loss: 0.1688 - val_acc: 0.9486 - val_auc: 0.7689 - val_binary_accuracy: 0.9486 - val_recall_19: 0.1000 - val_precision_19: 0.3200\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.1521 - acc: 0.9540 - auc: 0.8090 - binary_accuracy: 0.9540 - recall_19: 0.0988 - precision_19: 0.5102 - val_loss: 0.1603 - val_acc: 0.9509 - val_auc: 0.7736 - val_binary_accuracy: 0.9509 - val_recall_19: 0.0125 - val_precision_19: 0.1429\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1504 - acc: 0.9547 - auc: 0.8153 - binary_accuracy: 0.9547 - recall_19: 0.1265 - precision_19: 0.5424 - val_loss: 0.1674 - val_acc: 0.9532 - val_auc: 0.7639 - val_binary_accuracy: 0.9532 - val_recall_19: 0.0000e+00 - val_precision_19: 0.0000e+00\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1672 - acc: 0.9532 - auc: 0.7639 - binary_accuracy: 0.9532 - recall_19: 0.0870 - precision_19: 0.4681 - val_loss: 0.1740 - val_acc: 0.9526 - val_auc: 0.7549 - val_binary_accuracy: 0.9526 - val_recall_19: 0.0000e+00 - val_precision_19: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1475 - acc: 0.9562 - auc: 0.8234 - binary_accuracy: 0.9562 - recall_19: 0.0988 - precision_19: 0.6757 - val_loss: 0.1631 - val_acc: 0.9532 - val_auc: 0.7789 - val_binary_accuracy: 0.9532 - val_recall_19: 0.0125 - val_precision_19: 0.3333\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1432 - acc: 0.9558 - auc: 0.8430 - binary_accuracy: 0.9558 - recall_19: 0.1383 - precision_19: 0.5932 - val_loss: 0.1657 - val_acc: 0.9532 - val_auc: 0.7665 - val_binary_accuracy: 0.9532 - val_recall_19: 0.0125 - val_precision_19: 0.3333\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1440 - acc: 0.9563 - auc: 0.8292 - binary_accuracy: 0.9563 - recall_19: 0.1146 - precision_19: 0.6591 - val_loss: 0.1636 - val_acc: 0.9526 - val_auc: 0.7674 - val_binary_accuracy: 0.9526 - val_recall_19: 0.0625 - val_precision_19: 0.4167\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1469 - acc: 0.9549 - auc: 0.8300 - binary_accuracy: 0.9549 - recall_19: 0.1304 - precision_19: 0.5500 - val_loss: 0.1980 - val_acc: 0.9532 - val_auc: 0.7224 - val_binary_accuracy: 0.9532 - val_recall_19: 0.0000e+00 - val_precision_19: 0.0000e+00\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1408 - acc: 0.9585 - auc: 0.8429 - binary_accuracy: 0.9585 - recall_19: 0.1502 - precision_19: 0.7600 - val_loss: 0.1689 - val_acc: 0.9526 - val_auc: 0.7635 - val_binary_accuracy: 0.9526 - val_recall_19: 0.0000e+00 - val_precision_19: 0.0000e+00\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1295 - acc: 0.9589 - auc: 0.8761 - binary_accuracy: 0.9589 - recall_19: 0.1779 - precision_19: 0.7258 - val_loss: 0.1675 - val_acc: 0.9526 - val_auc: 0.7700 - val_binary_accuracy: 0.9526 - val_recall_19: 0.1000 - val_precision_19: 0.4444\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1317 - acc: 0.9587 - auc: 0.8642 - binary_accuracy: 0.9587 - recall_19: 0.2016 - precision_19: 0.6800 - val_loss: 0.1733 - val_acc: 0.9486 - val_auc: 0.7555 - val_binary_accuracy: 0.9486 - val_recall_19: 0.0750 - val_precision_19: 0.2857\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1456 - acc: 0.9560 - auc: 0.8371 - binary_accuracy: 0.9560 - recall_19: 0.2174 - precision_19: 0.5612 - val_loss: 0.1739 - val_acc: 0.9497 - val_auc: 0.7555 - val_binary_accuracy: 0.9497 - val_recall_19: 0.0250 - val_precision_19: 0.1818\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 3s 64ms/step - loss: 0.1306 - acc: 0.9569 - auc: 0.8814 - binary_accuracy: 0.9569 - recall_19: 0.1660 - precision_19: 0.6269 - val_loss: 0.1757 - val_acc: 0.9468 - val_auc: 0.7488 - val_binary_accuracy: 0.9468 - val_recall_19: 0.1125 - val_precision_19: 0.3000\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1349 - acc: 0.9580 - auc: 0.8598 - binary_accuracy: 0.9580 - recall_19: 0.1897 - precision_19: 0.6575 - val_loss: 0.2410 - val_acc: 0.9231 - val_auc: 0.7590 - val_binary_accuracy: 0.9231 - val_recall_19: 0.3750 - val_precision_19: 0.2655\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.1361 - acc: 0.9587 - auc: 0.8540 - binary_accuracy: 0.9587 - recall_19: 0.2411 - precision_19: 0.6421 - val_loss: 0.1666 - val_acc: 0.9543 - val_auc: 0.7563 - val_binary_accuracy: 0.9543 - val_recall_19: 0.0875 - val_precision_19: 0.5385\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.1275 - acc: 0.9593 - auc: 0.8836 - binary_accuracy: 0.9593 - recall_19: 0.1976 - precision_19: 0.7143 - val_loss: 0.1933 - val_acc: 0.9538 - val_auc: 0.7298 - val_binary_accuracy: 0.9538 - val_recall_19: 0.0375 - val_precision_19: 0.5000\n",
      "0.16027964651584625\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "d96b4a94-6daa-427d-8334-458193fcc2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "df45b65e-4a9d-4e3f-992e-cb8f140df47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_balanced Accuracy:  0.9439306358381503 MSE:  0.05606936416184971 UAR:  0.6137878787878788 Recall:  0.25 Precision:  0.3508771929824561 F1:  0.291970802919708\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_balanced Accuracy:  0.9491329479768786 MSE:  0.05086705202312139 UAR:  0.5629924242424242 Recall:  0.1375 Precision:  0.36666666666666664 F1:  0.2\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_balanced Accuracy:  0.9497109826589596 MSE:  0.050289017341040465 UAR:  0.5216666666666666 Recall:  0.05 Precision:  0.26666666666666666 F1:  0.08421052631578949\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_balanced Accuracy:  0.9520231213872833 MSE:  0.04797687861271676 UAR:  0.5169318181818182 Recall:  0.0375 Precision:  0.3333333333333333 F1:  0.06741573033707865\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5178409090909091 Recall:  0.0375 Precision:  0.5 F1:  0.06976744186046512\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5118939393939393 Recall:  0.025 Precision:  0.5 F1:  0.047619047619047616\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5059469696969697 Recall:  0.0125 Precision:  0.5 F1:  0.02439024390243903\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5059469696969697 Recall:  0.0125 Precision:  0.5 F1:  0.02439024390243903\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6137878787878788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "c2f1b36c-4a5c-4c3a-b2dc-45d546860979",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "17ad8230-b80c-415f-b450-2316c8fd0285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "f65e593c-ba42-4610-b277-05c291a06ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_balanced_best Accuracy:  0.9 MSE:  0.1 UAR:  0.7096969696969697 Recall:  0.5 Precision:  0.23121387283236994 F1:  0.31620553359683795\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_balanced_best Accuracy:  0.9439306358381503 MSE:  0.05606936416184971 UAR:  0.6375757575757576 Recall:  0.3 Precision:  0.36923076923076925 F1:  0.3310344827586207\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_balanced_best Accuracy:  0.9508670520231214 MSE:  0.049132947976878616 UAR:  0.5876893939393939 Recall:  0.1875 Precision:  0.42857142857142855 F1:  0.26086956521739124\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_balanced_best Accuracy:  0.9502890173410404 MSE:  0.04971098265895954 UAR:  0.5279166666666666 Recall:  0.0625 Precision:  0.3125 F1:  0.10416666666666667\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_balanced_best Accuracy:  0.9514450867052023 MSE:  0.048554913294797684 UAR:  0.5106818181818181 Recall:  0.025 Precision:  0.25 F1:  0.045454545454545456\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_self_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.7096969696969697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e31674d-2359-4d1d-ac4c-5abc62e63753",
   "metadata": {},
   "source": [
    "### STAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "38d3c4d9-4ae2-4407-b161-7426dda8bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = compute_descriptor\n",
    "stat_name = \"STAT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e6bb0f-5d09-4c1f-9911-f46880bbb703",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "85f9c8b6-6b7d-4f54-b8bb-73bd0bfa28e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "17cc4e90-c8b5-47a9-a347-f479eca60c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "4e56c78e-b56b-46c8-b032-ce0f58a9b6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "test:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n",
      "val:\n",
      "0 1537/1720: 89.36046511627907%\n",
      "1 183/1720: 10.63953488372093%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e7f34b-2623-4f8b-8dd6-04e616ee62a4",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "3c3522ea-2397-4396-a7e8-555d4ef08a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "63e0e9d2-9a82-4d63-9c3a-9ff0927586cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "eb49f48f-e263-4a2b-ac0b-b865ed9581b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 3072) (5482,)\n",
      "(1723, 128, 3072) (1723,)\n",
      "(1720, 128, 3072) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "8f6c76c1-35fc-4b6a-a15d-0646da95b4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_32\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1573376   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_32 (Dense)            (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1576962 (6.02 MB)\n",
      "Trainable params: 1576962 (6.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "7385e388-e858-4228-8e93-48fbb7660f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 78ms/step - loss: 0.2130 - acc: 0.9537 - auc: 0.5883 - binary_accuracy: 0.9537 - recall_20: 0.0081 - precision_20: 0.2000 - val_loss: 0.3418 - val_acc: 0.8936 - val_auc: 0.6117 - val_binary_accuracy: 0.8936 - val_recall_20: 0.0000e+00 - val_precision_20: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 2s 41ms/step - loss: 0.1650 - acc: 0.9548 - auc: 0.7414 - binary_accuracy: 0.9548 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00 - val_loss: 0.3509 - val_acc: 0.8936 - val_auc: 0.6489 - val_binary_accuracy: 0.8936 - val_recall_20: 0.0000e+00 - val_precision_20: 0.0000e+00\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.1568 - acc: 0.9548 - auc: 0.7823 - binary_accuracy: 0.9548 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00 - val_loss: 0.3482 - val_acc: 0.8936 - val_auc: 0.6613 - val_binary_accuracy: 0.8936 - val_recall_20: 0.0000e+00 - val_precision_20: 0.0000e+00\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.1529 - acc: 0.9551 - auc: 0.7985 - binary_accuracy: 0.9551 - recall_20: 0.0081 - precision_20: 1.0000 - val_loss: 0.3430 - val_acc: 0.8936 - val_auc: 0.6634 - val_binary_accuracy: 0.8936 - val_recall_20: 0.0000e+00 - val_precision_20: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.1532 - acc: 0.9548 - auc: 0.7960 - binary_accuracy: 0.9548 - recall_20: 0.0161 - precision_20: 0.5000 - val_loss: 0.3332 - val_acc: 0.8936 - val_auc: 0.6809 - val_binary_accuracy: 0.8936 - val_recall_20: 0.0000e+00 - val_precision_20: 0.0000e+00\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.1529 - acc: 0.9546 - auc: 0.7992 - binary_accuracy: 0.9546 - recall_20: 0.0121 - precision_20: 0.4286 - val_loss: 0.3311 - val_acc: 0.8936 - val_auc: 0.6808 - val_binary_accuracy: 0.8936 - val_recall_20: 0.0000e+00 - val_precision_20: 0.0000e+00\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 0.1484 - acc: 0.9551 - auc: 0.8125 - binary_accuracy: 0.9551 - recall_20: 0.0081 - precision_20: 1.0000 - val_loss: 0.3348 - val_acc: 0.8936 - val_auc: 0.6772 - val_binary_accuracy: 0.8936 - val_recall_20: 0.0055 - val_precision_20: 0.5000\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.1448 - acc: 0.9553 - auc: 0.8280 - binary_accuracy: 0.9553 - recall_20: 0.0363 - precision_20: 0.6000 - val_loss: 0.3309 - val_acc: 0.8930 - val_auc: 0.6874 - val_binary_accuracy: 0.8930 - val_recall_20: 0.0055 - val_precision_20: 0.3333\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.1392 - acc: 0.9566 - auc: 0.8454 - binary_accuracy: 0.9566 - recall_20: 0.0484 - precision_20: 0.8571 - val_loss: 0.3785 - val_acc: 0.8936 - val_auc: 0.6643 - val_binary_accuracy: 0.8936 - val_recall_20: 0.0000e+00 - val_precision_20: 0.0000e+00\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 0.1392 - acc: 0.9570 - auc: 0.8501 - binary_accuracy: 0.9570 - recall_20: 0.0685 - precision_20: 0.7727 - val_loss: 0.3567 - val_acc: 0.8936 - val_auc: 0.6827 - val_binary_accuracy: 0.8936 - val_recall_20: 0.0055 - val_precision_20: 0.5000\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 2s 41ms/step - loss: 0.1352 - acc: 0.9580 - auc: 0.8624 - binary_accuracy: 0.9580 - recall_20: 0.0927 - precision_20: 0.8214 - val_loss: 0.3630 - val_acc: 0.8942 - val_auc: 0.6793 - val_binary_accuracy: 0.8942 - val_recall_20: 0.0055 - val_precision_20: 1.0000\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.1351 - acc: 0.9579 - auc: 0.8620 - binary_accuracy: 0.9579 - recall_20: 0.0887 - precision_20: 0.8148 - val_loss: 0.3754 - val_acc: 0.8907 - val_auc: 0.6684 - val_binary_accuracy: 0.8907 - val_recall_20: 0.0055 - val_precision_20: 0.1429\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 0.1313 - acc: 0.9584 - auc: 0.8754 - binary_accuracy: 0.9584 - recall_20: 0.1048 - precision_20: 0.8125 - val_loss: 0.3633 - val_acc: 0.8930 - val_auc: 0.6751 - val_binary_accuracy: 0.8930 - val_recall_20: 0.0437 - val_precision_20: 0.4706\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.1299 - acc: 0.9588 - auc: 0.8755 - binary_accuracy: 0.9588 - recall_20: 0.1250 - precision_20: 0.7750 - val_loss: 0.3540 - val_acc: 0.8866 - val_auc: 0.6764 - val_binary_accuracy: 0.8866 - val_recall_20: 0.0601 - val_precision_20: 0.3235\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.1265 - acc: 0.9591 - auc: 0.8869 - binary_accuracy: 0.9591 - recall_20: 0.1411 - precision_20: 0.7609 - val_loss: 0.3892 - val_acc: 0.8913 - val_auc: 0.6592 - val_binary_accuracy: 0.8913 - val_recall_20: 0.0219 - val_precision_20: 0.3333\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.1283 - acc: 0.9604 - auc: 0.8769 - binary_accuracy: 0.9604 - recall_20: 0.1452 - precision_20: 0.8780 - val_loss: 0.3667 - val_acc: 0.8733 - val_auc: 0.6701 - val_binary_accuracy: 0.8733 - val_recall_20: 0.0820 - val_precision_20: 0.2308\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 0.1220 - acc: 0.9601 - auc: 0.8962 - binary_accuracy: 0.9601 - recall_20: 0.1815 - precision_20: 0.7377 - val_loss: 0.3798 - val_acc: 0.8901 - val_auc: 0.6601 - val_binary_accuracy: 0.8901 - val_recall_20: 0.0328 - val_precision_20: 0.3333\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.1215 - acc: 0.9593 - auc: 0.9020 - binary_accuracy: 0.9593 - recall_20: 0.1613 - precision_20: 0.7273 - val_loss: 0.4005 - val_acc: 0.8860 - val_auc: 0.6562 - val_binary_accuracy: 0.8860 - val_recall_20: 0.0437 - val_precision_20: 0.2759\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.1184 - acc: 0.9608 - auc: 0.9035 - binary_accuracy: 0.9608 - recall_20: 0.1855 - precision_20: 0.7797 - val_loss: 0.4574 - val_acc: 0.8919 - val_auc: 0.6428 - val_binary_accuracy: 0.8919 - val_recall_20: 0.0219 - val_precision_20: 0.3636\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.1180 - acc: 0.9619 - auc: 0.9038 - binary_accuracy: 0.9619 - recall_20: 0.1935 - precision_20: 0.8421 - val_loss: 0.4211 - val_acc: 0.8895 - val_auc: 0.6530 - val_binary_accuracy: 0.8895 - val_recall_20: 0.0328 - val_precision_20: 0.3158\n",
      "0.33094802498817444\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "86036572-e2ad-4ad2-bf91-6250519bd7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "0b456adb-46f0-46fe-b8d0-0367550dfe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.7301218804410912 MSE:  0.2698781195589089 UAR:  0.6349745026215614 Recall:  0.5294117647058824 Precision:  0.09574468085106383 F1:  0.16216216216216217\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.824143934997098 MSE:  0.1758560650029019 UAR:  0.5673058967176614 Recall:  0.2823529411764706 Precision:  0.09022556390977443 F1:  0.13675213675213674\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.8810214741729542 MSE:  0.11897852582704585 UAR:  0.5693349134525605 Recall:  0.2235294117647059 Precision:  0.12025316455696203 F1:  0.15637860082304528\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.9123621590249564 MSE:  0.08763784097504353 UAR:  0.5467787114845938 Recall:  0.1411764705882353 Precision:  0.13333333333333333 F1:  0.13714285714285712\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.934416715031921 MSE:  0.06558328496807893 UAR:  0.5360698125404008 Recall:  0.09411764705882353 Precision:  0.18181818181818182 F1:  0.12403100775193798\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.9460243760882182 MSE:  0.053975623911781775 UAR:  0.5254435107376284 Recall:  0.058823529411764705 Precision:  0.2777777777777778 F1:  0.0970873786407767\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5173418085182792 Recall:  0.03529411764705882 Precision:  0.75 F1:  0.06741573033707865\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5058823529411764 Recall:  0.011764705882352941 Precision:  1.0 F1:  0.023255813953488372\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6349745026215614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "8495cc34-e75a-48be-8265-b862f719e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "9600ba59-5af8-4656-a043-aa42a69ba909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "b2d8b09c-7143-418b-b4df-07300a098464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.6477074869413814 MSE:  0.3522925130586187 UAR:  0.6418228829993535 Recall:  0.6352941176470588 Precision:  0.08571428571428572 F1:  0.15104895104895105\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.8461984910040626 MSE:  0.1538015089959373 UAR:  0.6625619478560655 Recall:  0.4588235294117647 Precision:  0.1511627906976744 F1:  0.22740524781341107\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.9239698200812536 MSE:  0.07603017991874637 UAR:  0.619808949220714 Recall:  0.2823529411764706 Precision:  0.2553191489361702 F1:  0.2681564245810055\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.9500870574579222 MSE:  0.04991294254207777 UAR:  0.5833512892336422 Recall:  0.17647058823529413 Precision:  0.4838709677419355 F1:  0.25862068965517243\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5229189111542053 Recall:  0.047058823529411764 Precision:  0.6666666666666666 F1:  0.08791208791208792\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.2 0.6625619478560655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53da924b-9895-451b-8027-91846a5068c1",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "b5216311-9097-42d4-b9c0-7ec1fb9ccaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_2_STAT_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "4503b573-a60a-4932-8d94-2d1a25e38cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "a5ef8def-7073-4aa5-b24f-bab2aa64fdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 3072) (5482,)\n",
      "(1723, 128, 3072) (1723,)\n",
      "(1720, 128, 3072) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "f9b0e499-89bd-4dfd-8c91-ac8bb9504b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_33\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_16 (Attention)    (None, None, 3072)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['attention_16[0][0]']        \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['attention_16[0][0]',        \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_33 (Dense)            (None, 1)                    3073      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18880514 (72.02 MB)\n",
      "Trainable params: 18880514 (72.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "2016d392-a82b-4fe8-80b0-baf2788d5728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 8s 164ms/step - loss: 0.6305 - acc: 0.9327 - auc: 0.5362 - binary_accuracy: 0.9327 - recall_21: 0.0323 - precision_21: 0.0584 - val_loss: 0.5288 - val_acc: 0.8936 - val_auc: 0.5954 - val_binary_accuracy: 0.8936 - val_recall_21: 0.0000e+00 - val_precision_21: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.1687 - acc: 0.9537 - auc: 0.7200 - binary_accuracy: 0.9537 - recall_21: 0.0363 - precision_21: 0.3750 - val_loss: 0.3306 - val_acc: 0.8913 - val_auc: 0.6568 - val_binary_accuracy: 0.8913 - val_recall_21: 0.0055 - val_precision_21: 0.1667\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.1577 - acc: 0.9548 - auc: 0.7672 - binary_accuracy: 0.9548 - recall_21: 0.0524 - precision_21: 0.5000 - val_loss: 0.3384 - val_acc: 0.8808 - val_auc: 0.6695 - val_binary_accuracy: 0.8808 - val_recall_21: 0.0765 - val_precision_21: 0.2800\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.1517 - acc: 0.9568 - auc: 0.7984 - binary_accuracy: 0.9568 - recall_21: 0.0766 - precision_21: 0.7037 - val_loss: 0.3683 - val_acc: 0.8913 - val_auc: 0.6632 - val_binary_accuracy: 0.8913 - val_recall_21: 0.0164 - val_precision_21: 0.3000\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 5s 119ms/step - loss: 0.1486 - acc: 0.9560 - auc: 0.8121 - binary_accuracy: 0.9560 - recall_21: 0.0927 - precision_21: 0.5897 - val_loss: 0.3455 - val_acc: 0.8860 - val_auc: 0.6695 - val_binary_accuracy: 0.8860 - val_recall_21: 0.0656 - val_precision_21: 0.3243\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.1427 - acc: 0.9568 - auc: 0.8353 - binary_accuracy: 0.9568 - recall_21: 0.0847 - precision_21: 0.6774 - val_loss: 0.3502 - val_acc: 0.8837 - val_auc: 0.6756 - val_binary_accuracy: 0.8837 - val_recall_21: 0.0656 - val_precision_21: 0.2927\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.1484 - acc: 0.9551 - auc: 0.8228 - binary_accuracy: 0.9551 - recall_21: 0.1411 - precision_21: 0.5147 - val_loss: 0.3485 - val_acc: 0.8901 - val_auc: 0.6610 - val_binary_accuracy: 0.8901 - val_recall_21: 0.0437 - val_precision_21: 0.3636\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 5s 119ms/step - loss: 0.1432 - acc: 0.9566 - auc: 0.8342 - binary_accuracy: 0.9566 - recall_21: 0.1169 - precision_21: 0.6042 - val_loss: 0.3590 - val_acc: 0.8855 - val_auc: 0.6708 - val_binary_accuracy: 0.8855 - val_recall_21: 0.0820 - val_precision_21: 0.3409\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.1409 - acc: 0.9591 - auc: 0.8393 - binary_accuracy: 0.9591 - recall_21: 0.1532 - precision_21: 0.7308 - val_loss: 0.3581 - val_acc: 0.8831 - val_auc: 0.6694 - val_binary_accuracy: 0.8831 - val_recall_21: 0.0656 - val_precision_21: 0.2857\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 6s 129ms/step - loss: 0.1340 - acc: 0.9590 - auc: 0.8649 - binary_accuracy: 0.9590 - recall_21: 0.1613 - precision_21: 0.7018 - val_loss: 0.3787 - val_acc: 0.8744 - val_auc: 0.6536 - val_binary_accuracy: 0.8744 - val_recall_21: 0.0984 - val_precision_21: 0.2609\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 5s 118ms/step - loss: 0.1461 - acc: 0.9604 - auc: 0.8141 - binary_accuracy: 0.9604 - recall_21: 0.2056 - precision_21: 0.7183 - val_loss: 0.3885 - val_acc: 0.8901 - val_auc: 0.6531 - val_binary_accuracy: 0.8901 - val_recall_21: 0.0109 - val_precision_21: 0.2000\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 5s 119ms/step - loss: 0.1371 - acc: 0.9566 - auc: 0.8484 - binary_accuracy: 0.9566 - recall_21: 0.1532 - precision_21: 0.5758 - val_loss: 0.4072 - val_acc: 0.8913 - val_auc: 0.6520 - val_binary_accuracy: 0.8913 - val_recall_21: 0.0164 - val_precision_21: 0.3000\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.1413 - acc: 0.9577 - auc: 0.8473 - binary_accuracy: 0.9577 - recall_21: 0.1613 - precision_21: 0.6250 - val_loss: 0.4845 - val_acc: 0.8924 - val_auc: 0.6268 - val_binary_accuracy: 0.8924 - val_recall_21: 0.0055 - val_precision_21: 0.2500\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.1330 - acc: 0.9593 - auc: 0.8609 - binary_accuracy: 0.9593 - recall_21: 0.1774 - precision_21: 0.6984 - val_loss: 0.3934 - val_acc: 0.8860 - val_auc: 0.6477 - val_binary_accuracy: 0.8860 - val_recall_21: 0.0383 - val_precision_21: 0.2593\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 5s 119ms/step - loss: 0.1271 - acc: 0.9595 - auc: 0.8780 - binary_accuracy: 0.9595 - recall_21: 0.1694 - precision_21: 0.7241 - val_loss: 0.3834 - val_acc: 0.8663 - val_auc: 0.6550 - val_binary_accuracy: 0.8663 - val_recall_21: 0.0874 - val_precision_21: 0.2025\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 5s 119ms/step - loss: 0.1268 - acc: 0.9593 - auc: 0.8822 - binary_accuracy: 0.9593 - recall_21: 0.2339 - precision_21: 0.6374 - val_loss: 0.5112 - val_acc: 0.8919 - val_auc: 0.6343 - val_binary_accuracy: 0.8919 - val_recall_21: 0.0055 - val_precision_21: 0.2000\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 5s 118ms/step - loss: 0.1230 - acc: 0.9628 - auc: 0.8890 - binary_accuracy: 0.9628 - recall_21: 0.2379 - precision_21: 0.7973 - val_loss: 0.4250 - val_acc: 0.8820 - val_auc: 0.6536 - val_binary_accuracy: 0.8820 - val_recall_21: 0.0383 - val_precision_21: 0.2059\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 6s 130ms/step - loss: 0.1394 - acc: 0.9579 - auc: 0.8494 - binary_accuracy: 0.9579 - recall_21: 0.1976 - precision_21: 0.6049 - val_loss: 0.3862 - val_acc: 0.8913 - val_auc: 0.6317 - val_binary_accuracy: 0.8913 - val_recall_21: 0.0219 - val_precision_21: 0.3333\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.1236 - acc: 0.9610 - auc: 0.8826 - binary_accuracy: 0.9610 - recall_21: 0.2218 - precision_21: 0.7237 - val_loss: 0.4341 - val_acc: 0.8913 - val_auc: 0.6072 - val_binary_accuracy: 0.8913 - val_recall_21: 0.0109 - val_precision_21: 0.2500\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 5s 119ms/step - loss: 0.1227 - acc: 0.9617 - auc: 0.8895 - binary_accuracy: 0.9617 - recall_21: 0.2460 - precision_21: 0.7262 - val_loss: 0.4183 - val_acc: 0.8802 - val_auc: 0.6308 - val_binary_accuracy: 0.8802 - val_recall_21: 0.0492 - val_precision_21: 0.2195\n",
      "0.33059704303741455\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "bc23c547-835b-469a-a1b6-465f48804f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "2d5ea3c2-0085-46a7-8434-a2b11bdfada6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_traditional Accuracy:  0.6297156123041208 MSE:  0.3702843876958793 UAR:  0.5710119945414063 Recall:  0.5058823529411764 Precision:  0.06729264475743349 F1:  0.11878453038674033\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_traditional Accuracy:  0.7678467788740568 MSE:  0.2321532211259431 UAR:  0.5600050276520865 Recall:  0.32941176470588235 Precision:  0.07547169811320754 F1:  0.12280701754385966\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_traditional Accuracy:  0.832269297736506 MSE:  0.1677307022634939 UAR:  0.5436938878115349 Recall:  0.2235294117647059 Precision:  0.07851239669421488 F1:  0.11620795107033641\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_traditional Accuracy:  0.8618688334300638 MSE:  0.13813116656993615 UAR:  0.5202219349278173 Recall:  0.1411764705882353 Precision:  0.06779661016949153 F1:  0.0916030534351145\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_traditional Accuracy:  0.8746372605919908 MSE:  0.1253627394080093 UAR:  0.5046290310996193 Recall:  0.09411764705882353 Precision:  0.05442176870748299 F1:  0.06896551724137931\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_traditional Accuracy:  0.8827626233313988 MSE:  0.11723737666860128 UAR:  0.5033254327371974 Recall:  0.08235294117647059 Precision:  0.05343511450381679 F1:  0.06481481481481481\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_traditional Accuracy:  0.8879860708067324 MSE:  0.11201392919326755 UAR:  0.4949184802125979 Recall:  0.058823529411764705 Precision:  0.0423728813559322 F1:  0.04926108374384237\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_traditional Accuracy:  0.8995937318630296 MSE:  0.1004062681369704 UAR:  0.4898692810457516 Recall:  0.03529411764705882 Precision:  0.031914893617021274 F1:  0.03351955307262569\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_traditional Accuracy:  0.9286128845037724 MSE:  0.0713871154962275 UAR:  0.5051317963082669 Recall:  0.03529411764705882 Precision:  0.06818181818181818 F1:  0.046511627906976744\n",
      "0.1 0.5710119945414063\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "bd78ee6e-a178-4f72-a22e-b6042254333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "1bc71da2-b963-4337-a487-9b18c7d13874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "441da2bd-9008-4c18-b52a-49a4a1b382bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_traditional_best Accuracy:  0.7214161346488682 MSE:  0.2785838653511317 UAR:  0.6638583638583638 Recall:  0.6 Precision:  0.10261569416498995 F1:  0.1752577319587629\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_traditional_best Accuracy:  0.8984329657573998 MSE:  0.10156703424260012 UAR:  0.589646627881922 Recall:  0.24705882352941178 Precision:  0.1590909090909091 F1:  0.19354838709677422\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_traditional_best Accuracy:  0.9442832269297736 MSE:  0.05571677307022635 UAR:  0.5691445809092868 Recall:  0.15294117647058825 Precision:  0.35135135135135137 F1:  0.21311475409836064\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5557710263592617 Recall:  0.11764705882352941 Precision:  0.5 F1:  0.19047619047619047\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_traditional_best Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5343783667313079 Recall:  0.07058823529411765 Precision:  0.6666666666666666 F1:  0.12765957446808512\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_traditional_best Accuracy:  0.9500870574579222 MSE:  0.04991294254207777 UAR:  0.510848954966602 Recall:  0.023529411764705882 Precision:  0.4 F1:  0.044444444444444446\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_traditional_best Accuracy:  0.9495066744051074 MSE:  0.05049332559489263 UAR:  0.4993894993894994 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6638583638583638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc4b70d-cc3c-423b-a846-e465db285d5b",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "e9de4955-6355-4a80-bef8-e31b11c77bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "6b5af9c3-e0ce-465c-a15e-6b19421afb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "5e402c5f-0582-430d-9138-0c4ce0c0315b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "val:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "db9648fd-cfeb-41c1-aba3-b0c137d0dd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 2048) (5482,)\n",
      "(1723, 2048) (1723,)\n",
      "(7205, 2048) (7205,)\n",
      "[0 1] [6872  333]\n",
      "7205\n",
      "5475\n",
      "1730\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "d140b776-0b98-4727-941d-2ee6f91e7b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5222/5475: 95.37899543378995%\n",
      "1 253/5475: 4.621004566210046%\n",
      "val:\n",
      "0 1650/1730: 95.3757225433526%\n",
      "1 80/1730: 4.624277456647399%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f3954c-0870-48a9-8464-1ab9bf4e46d2",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "293d4c6c-d7ca-4262-acc4-f1fb3689ecff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "c4720e63-bb3e-4b39-b74c-2cee0f17f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "5e21f999-00c9-4faa-9974-3a1b987aae5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 3072) (5475,)\n",
      "(1730, 128, 3072) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "c6baa69e-17af-4e3c-a6df-23debf4e5e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_34\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1573376   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_34 (Dense)            (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1576962 (6.02 MB)\n",
      "Trainable params: 1576962 (6.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "939ab2bf-c42d-41c6-93ed-04f963da1259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 87ms/step - loss: 0.2170 - acc: 0.9381 - auc: 0.5603 - binary_accuracy: 0.9381 - recall_22: 0.0158 - precision_22: 0.0426 - val_loss: 0.1779 - val_acc: 0.9538 - val_auc: 0.7091 - val_binary_accuracy: 0.9538 - val_recall_22: 0.0000e+00 - val_precision_22: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.1684 - acc: 0.9540 - auc: 0.7284 - binary_accuracy: 0.9540 - recall_22: 0.0040 - precision_22: 1.0000 - val_loss: 0.1660 - val_acc: 0.9538 - val_auc: 0.7475 - val_binary_accuracy: 0.9538 - val_recall_22: 0.0000e+00 - val_precision_22: 0.0000e+00\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.1601 - acc: 0.9542 - auc: 0.7749 - binary_accuracy: 0.9542 - recall_22: 0.0237 - precision_22: 0.6000 - val_loss: 0.1612 - val_acc: 0.9538 - val_auc: 0.7620 - val_binary_accuracy: 0.9538 - val_recall_22: 0.0000e+00 - val_precision_22: 0.0000e+00\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.1543 - acc: 0.9547 - auc: 0.8076 - binary_accuracy: 0.9547 - recall_22: 0.0198 - precision_22: 1.0000 - val_loss: 0.1626 - val_acc: 0.9532 - val_auc: 0.7716 - val_binary_accuracy: 0.9532 - val_recall_22: 0.0250 - val_precision_22: 0.4000\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.1542 - acc: 0.9562 - auc: 0.8034 - binary_accuracy: 0.9562 - recall_22: 0.0553 - precision_22: 0.9333 - val_loss: 0.1613 - val_acc: 0.9532 - val_auc: 0.7732 - val_binary_accuracy: 0.9532 - val_recall_22: 0.0000e+00 - val_precision_22: 0.0000e+00\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.1511 - acc: 0.9551 - auc: 0.8124 - binary_accuracy: 0.9551 - recall_22: 0.0672 - precision_22: 0.6296 - val_loss: 0.1725 - val_acc: 0.9532 - val_auc: 0.7686 - val_binary_accuracy: 0.9532 - val_recall_22: 0.0000e+00 - val_precision_22: 0.0000e+00\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.1452 - acc: 0.9556 - auc: 0.8374 - binary_accuracy: 0.9556 - recall_22: 0.0711 - precision_22: 0.6923 - val_loss: 0.1616 - val_acc: 0.9532 - val_auc: 0.7683 - val_binary_accuracy: 0.9532 - val_recall_22: 0.0000e+00 - val_precision_22: 0.0000e+00\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.1445 - acc: 0.9569 - auc: 0.8407 - binary_accuracy: 0.9569 - recall_22: 0.0791 - precision_22: 0.8696 - val_loss: 0.1756 - val_acc: 0.9532 - val_auc: 0.7640 - val_binary_accuracy: 0.9532 - val_recall_22: 0.0000e+00 - val_precision_22: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.1422 - acc: 0.9578 - auc: 0.8463 - binary_accuracy: 0.9578 - recall_22: 0.1186 - precision_22: 0.7895 - val_loss: 0.1687 - val_acc: 0.9532 - val_auc: 0.7603 - val_binary_accuracy: 0.9532 - val_recall_22: 0.0000e+00 - val_precision_22: 0.0000e+00\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.1401 - acc: 0.9565 - auc: 0.8546 - binary_accuracy: 0.9565 - recall_22: 0.0949 - precision_22: 0.7273 - val_loss: 0.1593 - val_acc: 0.9543 - val_auc: 0.7701 - val_binary_accuracy: 0.9543 - val_recall_22: 0.0625 - val_precision_22: 0.5556\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.1356 - acc: 0.9576 - auc: 0.8655 - binary_accuracy: 0.9576 - recall_22: 0.1028 - precision_22: 0.8387 - val_loss: 0.1649 - val_acc: 0.9538 - val_auc: 0.7688 - val_binary_accuracy: 0.9538 - val_recall_22: 0.0125 - val_precision_22: 0.5000\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.1336 - acc: 0.9582 - auc: 0.8725 - binary_accuracy: 0.9582 - recall_22: 0.1344 - precision_22: 0.7727 - val_loss: 0.1616 - val_acc: 0.9543 - val_auc: 0.7605 - val_binary_accuracy: 0.9543 - val_recall_22: 0.0375 - val_precision_22: 0.6000\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.1308 - acc: 0.9585 - auc: 0.8807 - binary_accuracy: 0.9585 - recall_22: 0.1502 - precision_22: 0.7600 - val_loss: 0.1633 - val_acc: 0.9526 - val_auc: 0.7660 - val_binary_accuracy: 0.9526 - val_recall_22: 0.0250 - val_precision_22: 0.3333\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.1272 - acc: 0.9591 - auc: 0.8939 - binary_accuracy: 0.9591 - recall_22: 0.1423 - precision_22: 0.8372 - val_loss: 0.1685 - val_acc: 0.9509 - val_auc: 0.7648 - val_binary_accuracy: 0.9509 - val_recall_22: 0.0500 - val_precision_22: 0.3077\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.1236 - acc: 0.9596 - auc: 0.8978 - binary_accuracy: 0.9596 - recall_22: 0.1660 - precision_22: 0.8077 - val_loss: 0.1795 - val_acc: 0.9538 - val_auc: 0.7605 - val_binary_accuracy: 0.9538 - val_recall_22: 0.0125 - val_precision_22: 0.5000\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.1231 - acc: 0.9604 - auc: 0.8993 - binary_accuracy: 0.9604 - recall_22: 0.1739 - precision_22: 0.8462 - val_loss: 0.1669 - val_acc: 0.9514 - val_auc: 0.7711 - val_binary_accuracy: 0.9514 - val_recall_22: 0.0500 - val_precision_22: 0.3333\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.1211 - acc: 0.9604 - auc: 0.9038 - binary_accuracy: 0.9604 - recall_22: 0.1937 - precision_22: 0.7903 - val_loss: 0.1687 - val_acc: 0.9526 - val_auc: 0.7632 - val_binary_accuracy: 0.9526 - val_recall_22: 0.1125 - val_precision_22: 0.4500\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.1187 - acc: 0.9607 - auc: 0.9114 - binary_accuracy: 0.9607 - recall_22: 0.2095 - precision_22: 0.7794 - val_loss: 0.1710 - val_acc: 0.9532 - val_auc: 0.7627 - val_binary_accuracy: 0.9532 - val_recall_22: 0.0625 - val_precision_22: 0.4545\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 0.1163 - acc: 0.9616 - auc: 0.9129 - binary_accuracy: 0.9616 - recall_22: 0.2134 - precision_22: 0.8308 - val_loss: 0.1761 - val_acc: 0.9538 - val_auc: 0.7503 - val_binary_accuracy: 0.9538 - val_recall_22: 0.0250 - val_precision_22: 0.5000\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.1150 - acc: 0.9618 - auc: 0.9114 - binary_accuracy: 0.9618 - recall_22: 0.2253 - precision_22: 0.8143 - val_loss: 0.1960 - val_acc: 0.9538 - val_auc: 0.7209 - val_binary_accuracy: 0.9538 - val_recall_22: 0.0375 - val_precision_22: 0.5000\n",
      "0.15930849313735962\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "0b934a11-561a-4798-a419-bd2626e85813",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "a512ca10-069a-43db-bb07-825cad0c9b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.9439306358381503 MSE:  0.05606936416184971 UAR:  0.6197348484848485 Recall:  0.2625 Precision:  0.3559322033898305 F1:  0.302158273381295\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.9497109826589596 MSE:  0.050289017341040465 UAR:  0.575189393939394 Recall:  0.1625 Precision:  0.3939393939393939 F1:  0.23008849557522124\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.9497109826589596 MSE:  0.050289017341040465 UAR:  0.5335606060606061 Recall:  0.075 Precision:  0.3157894736842105 F1:  0.1212121212121212\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.9520231213872833 MSE:  0.04797687861271676 UAR:  0.5169318181818182 Recall:  0.0375 Precision:  0.3333333333333333 F1:  0.06741573033707865\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5115909090909091 Recall:  0.025 Precision:  0.4 F1:  0.04705882352941177\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5118939393939393 Recall:  0.025 Precision:  0.5 F1:  0.047619047619047616\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5059469696969697 Recall:  0.0125 Precision:  0.5 F1:  0.02439024390243903\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6197348484848485\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "3bad300e-beb0-4bf0-949a-917e755a3bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "eeb808f8-d460-4faf-aa12-70b7f8862ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "069e7edb-1826-41d6-9020-adde4abcb94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.8953757225433526 MSE:  0.1046242774566474 UAR:  0.7132196969696969 Recall:  0.5125 Precision:  0.22404371584699453 F1:  0.31178707224334595\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.9450867052023122 MSE:  0.05491329479768786 UAR:  0.6381818181818182 Recall:  0.3 Precision:  0.38095238095238093 F1:  0.3356643356643356\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.9514450867052023 MSE:  0.048554913294797684 UAR:  0.5879924242424243 Recall:  0.1875 Precision:  0.4411764705882353 F1:  0.2631578947368421\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5535227272727272 Recall:  0.1125 Precision:  0.5 F1:  0.18367346938775508\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5237878787878788 Recall:  0.05 Precision:  0.5 F1:  0.09090909090909091\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.7132196969696969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac13a36e-74f2-4863-ad4a-b41a197a311b",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "fd25ffbf-0fee-4e84-9598-629bfefed5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_2_STAT_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "4dc18d51-4ff8-4d28-985a-3105ff9fe788",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "1ad9db9b-cb09-4cc1-b84d-d20965787e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 3072) (5475,)\n",
      "(1730, 128, 3072) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "6ffc0b81-38cc-481a-916d-e19e6b664f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_35\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_17 (Attention)    (None, None, 3072)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['attention_17[0][0]']        \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['attention_17[0][0]',        \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_35 (Dense)            (None, 1)                    3073      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18880514 (72.02 MB)\n",
      "Trainable params: 18880514 (72.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "adeb0293-87e3-4137-89e8-534cde8a8cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 8s 163ms/step - loss: 0.5890 - acc: 0.9383 - auc: 0.5378 - binary_accuracy: 0.9383 - recall_23: 0.0435 - precision_23: 0.1028 - val_loss: 0.1908 - val_acc: 0.9445 - val_auc: 0.7407 - val_binary_accuracy: 0.9445 - val_recall_23: 0.1000 - val_precision_23: 0.2500\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.1665 - acc: 0.9529 - auc: 0.7388 - binary_accuracy: 0.9529 - recall_23: 0.0474 - precision_23: 0.4138 - val_loss: 0.1684 - val_acc: 0.9538 - val_auc: 0.7480 - val_binary_accuracy: 0.9538 - val_recall_23: 0.0625 - val_precision_23: 0.5000\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.1583 - acc: 0.9549 - auc: 0.7844 - binary_accuracy: 0.9549 - recall_23: 0.0751 - precision_23: 0.5938 - val_loss: 0.1819 - val_acc: 0.9532 - val_auc: 0.7437 - val_binary_accuracy: 0.9532 - val_recall_23: 0.0000e+00 - val_precision_23: 0.0000e+00\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 5s 119ms/step - loss: 0.1534 - acc: 0.9567 - auc: 0.7915 - binary_accuracy: 0.9567 - recall_23: 0.1186 - precision_23: 0.6818 - val_loss: 0.2071 - val_acc: 0.9538 - val_auc: 0.7408 - val_binary_accuracy: 0.9538 - val_recall_23: 0.0000e+00 - val_precision_23: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.1615 - acc: 0.9542 - auc: 0.7706 - binary_accuracy: 0.9542 - recall_23: 0.0791 - precision_23: 0.5263 - val_loss: 0.1638 - val_acc: 0.9491 - val_auc: 0.7680 - val_binary_accuracy: 0.9491 - val_recall_23: 0.0750 - val_precision_23: 0.3000\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.1426 - acc: 0.9565 - auc: 0.8457 - binary_accuracy: 0.9565 - recall_23: 0.1067 - precision_23: 0.6923 - val_loss: 0.1657 - val_acc: 0.9514 - val_auc: 0.7734 - val_binary_accuracy: 0.9514 - val_recall_23: 0.1250 - val_precision_23: 0.4167\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 5s 118ms/step - loss: 0.1408 - acc: 0.9571 - auc: 0.8460 - binary_accuracy: 0.9571 - recall_23: 0.1423 - precision_23: 0.6667 - val_loss: 0.1672 - val_acc: 0.9514 - val_auc: 0.7568 - val_binary_accuracy: 0.9514 - val_recall_23: 0.1125 - val_precision_23: 0.4091\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 5s 119ms/step - loss: 0.1450 - acc: 0.9569 - auc: 0.8343 - binary_accuracy: 0.9569 - recall_23: 0.1462 - precision_23: 0.6491 - val_loss: 0.1713 - val_acc: 0.9538 - val_auc: 0.7612 - val_binary_accuracy: 0.9538 - val_recall_23: 0.0250 - val_precision_23: 0.5000\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 5s 118ms/step - loss: 0.1402 - acc: 0.9582 - auc: 0.8517 - binary_accuracy: 0.9582 - recall_23: 0.1937 - precision_23: 0.6622 - val_loss: 0.1751 - val_acc: 0.9532 - val_auc: 0.7552 - val_binary_accuracy: 0.9532 - val_recall_23: 0.0000e+00 - val_precision_23: 0.0000e+00\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.1400 - acc: 0.9580 - auc: 0.8491 - binary_accuracy: 0.9580 - recall_23: 0.1581 - precision_23: 0.7018 - val_loss: 0.1637 - val_acc: 0.9514 - val_auc: 0.7722 - val_binary_accuracy: 0.9514 - val_recall_23: 0.0375 - val_precision_23: 0.3000\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 5s 118ms/step - loss: 0.1313 - acc: 0.9593 - auc: 0.8732 - binary_accuracy: 0.9593 - recall_23: 0.1897 - precision_23: 0.7273 - val_loss: 0.1683 - val_acc: 0.9474 - val_auc: 0.7751 - val_binary_accuracy: 0.9474 - val_recall_23: 0.1125 - val_precision_23: 0.3103\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 5s 119ms/step - loss: 0.1398 - acc: 0.9571 - auc: 0.8536 - binary_accuracy: 0.9571 - recall_23: 0.1621 - precision_23: 0.6406 - val_loss: 0.1724 - val_acc: 0.9486 - val_auc: 0.7551 - val_binary_accuracy: 0.9486 - val_recall_23: 0.1375 - val_precision_23: 0.3548\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 6s 130ms/step - loss: 0.1336 - acc: 0.9582 - auc: 0.8687 - binary_accuracy: 0.9582 - recall_23: 0.2095 - precision_23: 0.6463 - val_loss: 0.1898 - val_acc: 0.9532 - val_auc: 0.7448 - val_binary_accuracy: 0.9532 - val_recall_23: 0.0250 - val_precision_23: 0.4000\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.1323 - acc: 0.9587 - auc: 0.8692 - binary_accuracy: 0.9587 - recall_23: 0.2134 - precision_23: 0.6667 - val_loss: 0.1733 - val_acc: 0.9532 - val_auc: 0.7448 - val_binary_accuracy: 0.9532 - val_recall_23: 0.0625 - val_precision_23: 0.4545\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 5s 118ms/step - loss: 0.1368 - acc: 0.9582 - auc: 0.8530 - binary_accuracy: 0.9582 - recall_23: 0.2213 - precision_23: 0.6364 - val_loss: 0.1998 - val_acc: 0.9532 - val_auc: 0.7495 - val_binary_accuracy: 0.9532 - val_recall_23: 0.0000e+00 - val_precision_23: 0.0000e+00\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 5s 119ms/step - loss: 0.1385 - acc: 0.9578 - auc: 0.8517 - binary_accuracy: 0.9578 - recall_23: 0.1621 - precision_23: 0.6833 - val_loss: 0.1734 - val_acc: 0.9538 - val_auc: 0.7576 - val_binary_accuracy: 0.9538 - val_recall_23: 0.0500 - val_precision_23: 0.5000\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 5s 118ms/step - loss: 0.1258 - acc: 0.9611 - auc: 0.8837 - binary_accuracy: 0.9611 - recall_23: 0.2332 - precision_23: 0.7564 - val_loss: 0.1744 - val_acc: 0.9520 - val_auc: 0.7535 - val_binary_accuracy: 0.9520 - val_recall_23: 0.0750 - val_precision_23: 0.4000\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 5s 118ms/step - loss: 0.1263 - acc: 0.9618 - auc: 0.8829 - binary_accuracy: 0.9618 - recall_23: 0.2569 - precision_23: 0.7558 - val_loss: 0.1788 - val_acc: 0.9514 - val_auc: 0.7354 - val_binary_accuracy: 0.9514 - val_recall_23: 0.2000 - val_precision_23: 0.4444\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 5s 118ms/step - loss: 0.1340 - acc: 0.9576 - auc: 0.8651 - binary_accuracy: 0.9576 - recall_23: 0.1818 - precision_23: 0.6479 - val_loss: 0.1723 - val_acc: 0.9532 - val_auc: 0.7293 - val_binary_accuracy: 0.9532 - val_recall_23: 0.1250 - val_precision_23: 0.4762\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 5s 118ms/step - loss: 0.1196 - acc: 0.9626 - auc: 0.9017 - binary_accuracy: 0.9626 - recall_23: 0.2885 - precision_23: 0.7449 - val_loss: 0.1901 - val_acc: 0.9538 - val_auc: 0.7420 - val_binary_accuracy: 0.9538 - val_recall_23: 0.0125 - val_precision_23: 0.5000\n",
      "0.16371285915374756\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "b64c2673-1085-4903-be18-aa3f774f526e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "792b8edb-db65-42e0-a28c-5a60c9beb30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_balanced Accuracy:  0.9364161849710982 MSE:  0.06358381502890173 UAR:  0.6098484848484849 Recall:  0.25 Precision:  0.2857142857142857 F1:  0.26666666666666666\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_balanced Accuracy:  0.9502890173410404 MSE:  0.04971098265895954 UAR:  0.5517045454545455 Recall:  0.1125 Precision:  0.375 F1:  0.1730769230769231\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_balanced Accuracy:  0.9520231213872833 MSE:  0.04797687861271676 UAR:  0.5347727272727273 Recall:  0.075 Precision:  0.4 F1:  0.1263157894736842\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5237878787878788 Recall:  0.05 Precision:  0.5 F1:  0.09090909090909091\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5059469696969697 Recall:  0.0125 Precision:  0.5 F1:  0.02439024390243903\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5059469696969697 Recall:  0.0125 Precision:  0.5 F1:  0.02439024390243903\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5059469696969697 Recall:  0.0125 Precision:  0.5 F1:  0.02439024390243903\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6098484848484849\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "842adc74-cf76-4c2d-abf4-740ba016446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "8e6d81e3-c28a-45ee-a989-40b7b7fd993f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "37fcdcc3-a527-4038-915e-fb6d9b23319c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_balanced_best Accuracy:  0.8994219653179191 MSE:  0.10057803468208093 UAR:  0.6856060606060607 Recall:  0.45 Precision:  0.21686746987951808 F1:  0.2926829268292683\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_balanced_best Accuracy:  0.9427745664739884 MSE:  0.05722543352601156 UAR:  0.6250757575757575 Recall:  0.275 Precision:  0.3492063492063492 F1:  0.3076923076923077\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_balanced_best Accuracy:  0.9473988439306359 MSE:  0.05260115606936416 UAR:  0.568030303030303 Recall:  0.15 Precision:  0.34285714285714286 F1:  0.20869565217391303\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5654166666666667 Recall:  0.1375 Precision:  0.5 F1:  0.21568627450980396\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5356818181818181 Recall:  0.075 Precision:  0.5 F1:  0.13043478260869565\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_balanced_best Accuracy:  0.954335260115607 MSE:  0.04566473988439306 UAR:  0.524090909090909 Recall:  0.05 Precision:  0.5714285714285714 F1:  0.09195402298850575\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5059469696969697 Recall:  0.0125 Precision:  0.5 F1:  0.02439024390243903\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6856060606060607\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d19c65-0fae-4887-b25f-70dd28a60799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
