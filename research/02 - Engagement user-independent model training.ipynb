{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cbdbb52-efcf-422d-9c12-ba1596b5e5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be3a71b-e9c9-4df9-8354-88a175b3908b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 21:37:22.195689: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-11 21:37:22.233428: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-11 21:37:22.233452: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-11 21:37:22.233480: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-11 21:37:22.240628: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-11 21:37:22.912638: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.1.0+cu121\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential, load_model, model_from_json\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, classification_report, balanced_accuracy_score, matthews_corrcoef\n",
    "\n",
    "print(f\"Torch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff1af93-899e-4029-ba0f-8a44f500743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense, Activation, Concatenate, Reshape\n",
    "from tensorflow.keras.layers import Flatten, RepeatVector, Permute, TimeDistributed\n",
    "from tensorflow.keras.layers import Multiply, Lambda, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b8b96fe-a854-476f-9b38-e28e75ddaed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/media/deelvin_disk/echuraev/Workspace/HSE/engagement/'\n",
    "BATCH_SIZE = 128\n",
    "TABLE_NAME = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000c5344-e9d5-42ce-b467-56ec2a66b41f",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "690cd1a6-aa5c-4cbb-af14-60c58d349397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_features(file_name, features):\n",
    "    if os.path.isfile(file_name):\n",
    "        print(\"Error! Cannot save features because file already exists\")\n",
    "        return\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(features, f) # , protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def load_features(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def save_weights(model, file_name):\n",
    "    if os.path.isfile(file_name):\n",
    "        print(\"Error! Cannot save features because file already exists\")\n",
    "        return\n",
    "    model.save_weights(file_name)\n",
    "\n",
    "def load_weights(model, file_name):\n",
    "    model.load_weights(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "203fda8c-0c21-4591-abbb-f52f494e58e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion_matrix(all_preds, all_labels):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import pandas as pd\n",
    "    import seaborn as sn\n",
    "\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for p in all_preds:\n",
    "        preds.append(float2int[p])\n",
    "    for l in all_labels:\n",
    "        labels.append(float2int[l])\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    preds = np.array(preds)\n",
    "    data=confusion_matrix(labels, preds)\n",
    "\n",
    "    df_cm = pd.DataFrame(data, columns=labels_list)\n",
    "    df_cm.index.name = 'Actual'\n",
    "    df_cm.columns.name = 'Predicted'\n",
    "    plt.figure(figsize = (13,10))\n",
    "    sn.set(font_scale=3)#for label size\n",
    "    sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16*2.5}, fmt='g')# font size\n",
    "    plt.yticks(np.arange(len(labels_list))+0.5, labels_list, rotation=0, va=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee3b5b51-fa74-4915-bce2-4f6f01f7e0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_sequences2norm_features(features):\n",
    "    ret = []\n",
    "    for i in range(len(features)):\n",
    "        ret.append(stat_func(features[i], axis=0))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a1cab33-de58-4395-bd65-0769de182bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred2label(pred):\n",
    "    if pred < 0.25:\n",
    "        return 0.0\n",
    "    if pred < 0.5:\n",
    "        return 0.33\n",
    "    if pred < 0.75:\n",
    "        return 0.66\n",
    "    return 1.0\n",
    "\n",
    "def get_prediction(model, file2feat, with_processing=False):\n",
    "    y_pred = []\n",
    "    exp_pred = []\n",
    "    for fn, x in file2feat.items():\n",
    "        #print(x.shape)\n",
    "        if len(x)==0:\n",
    "            continue\n",
    "        if CONCATENATE_STAT:\n",
    "            mean_x=np.repeat(stat_func(x,axis=0).reshape((1,-1)),len(x),axis=0)            \n",
    "            #preds=model.predict(np.expand_dims(np.concatenate((mean_x,x-mean_x),axis=1), axis=0))[0]\n",
    "            pred=model.predict(np.expand_dims(np.concatenate((mean_x,x),axis=1), axis=0), verbose=0)\n",
    "        else:\n",
    "            pred=model.predict(np.expand_dims(x, axis=0), verbose=0)\n",
    "        #y_pred.append(np.argmax(pred))\n",
    "        #if with_processing:\n",
    "        #    y_pred.append(pred2label(pred[0]))\n",
    "        #else:\n",
    "        #    y_pred.append(float(pred[0]))\n",
    "        if ENGAGE_WILD_DATASET is True or N_CLASSES == 2:\n",
    "            y_pred.append(float(pred[0]))\n",
    "        else:\n",
    "            y_pred.append(np.argmax(pred))\n",
    "        exp_pred.append(video2label[fn])\n",
    "    return np.array(y_pred), np.array(exp_pred) \n",
    "\n",
    "def prediction2bin(preds, threshold):\n",
    "    y_pred = []\n",
    "    for y in preds:\n",
    "        if N_CLASSES == 2:\n",
    "            y = 0 if y < threshold else 1\n",
    "        y_pred.append(y)\n",
    "    return y_pred\n",
    "\n",
    "def dump_to_table(table_name, metric_name, acc, mse, uar, recall, precision, f1, num_comma=\",\"):\n",
    "    def _to_str(num, num_comma):\n",
    "        if num_comma == \",\":\n",
    "            return str(num).replace(\".\", \",\")\n",
    "        return str(num).replace(\",\", \".\")\n",
    "    \n",
    "    import pandas as pd\n",
    "    if os.path.isfile(table_name):\n",
    "        df = pd.read_excel(open(table_name,'rb'))\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['metric_name', 'accuracy', 'mse', 'uar', 'recall', 'precision', 'f1'])\n",
    "\n",
    "    idx = len(df)\n",
    "    # Remove previous recordings\n",
    "    df = df[df.metric_name != metric_name]\n",
    "    df.loc[idx] = [\n",
    "        metric_name,\n",
    "        _to_str(acc, num_comma),\n",
    "        _to_str(mse, num_comma),\n",
    "        _to_str(uar, num_comma),\n",
    "        _to_str(recall, num_comma),\n",
    "        _to_str(precision, num_comma), \n",
    "        _to_str(f1, num_comma)\n",
    "    ] \n",
    "    df.to_excel(table_name, index=False) \n",
    "    \n",
    "\n",
    "def print_results(pred, labels, table_name=None, metric_name=None, from_int=False):\n",
    "    if from_int is False:\n",
    "        float2int={0:0,0.33:1,0.66:2,1:3}\n",
    "        if N_CLASSES == 2:\n",
    "            float2int={0:1,0.33:1,0.66:0,1:0}\n",
    "        pred_int = np.array([float2int[pred2label(l)] for l in pred])\n",
    "        labels_int = np.array([float2int[l] for l in labels])\n",
    "        #labels_float = np.array([int2float[l] for l in labels])\n",
    "        #pred_float = np.array([int2float[l] for l in pred])\n",
    "        acc = (labels_int==pred_int).mean()\n",
    "        #if N_CLASSES == 2:\n",
    "        #    mse = ((labels-pred)**2).mean()\n",
    "        #else:\n",
    "        #    mse = ((labels_float-pred_float)**2).mean()\n",
    "        mse = ((labels-pred)**2).mean()\n",
    "        uar = recall_score(y_true=labels_int,y_pred=pred_int, average='macro')\n",
    "        if N_CLASSES == 2:\n",
    "            recall = recall_score(y_true=labels,y_pred=pred, average='binary',pos_label=1)\n",
    "            precision = precision_score(y_true=labels,y_pred=pred, average='binary',pos_label=1)\n",
    "            f1 = f1_score(y_true=labels,y_pred=pred, average='binary',pos_label=1)\n",
    "        else:\n",
    "            recall = 'N/A'\n",
    "            precision = 'N/A'\n",
    "            f1 = f1_score(y_true=labels_int,y_pred=pred_int, average='macro')\n",
    "    else:\n",
    "        int2float = {0:0.0, 1: 0.33, 2:0.66, 3: 1.0}\n",
    "        labels_float = np.array([int2float[l] for l in labels])\n",
    "        pred_float = np.array([int2float[l] for l in pred])\n",
    "        acc = (labels==pred).mean()\n",
    "        if N_CLASSES == 2:\n",
    "            mse = ((labels-pred)**2).mean()\n",
    "        else:\n",
    "            mse = ((labels_float-pred_float)**2).mean()\n",
    "        uar = recall_score(y_true=labels,y_pred=pred, average='macro')\n",
    "        if N_CLASSES == 2:\n",
    "            recall = recall_score(y_true=labels,y_pred=pred, average='binary',pos_label=1)\n",
    "            precision = precision_score(y_true=labels,y_pred=pred, average='binary',pos_label=1)\n",
    "            f1 = f1_score(y_true=labels,y_pred=pred, average='binary',pos_label=1)\n",
    "        else:\n",
    "            recall = 'N/A'\n",
    "            precision = 'N/A'\n",
    "            f1 = f1_score(y_true=labels,y_pred=pred, average='macro')\n",
    "    print('Metric_name: ', metric_name,\n",
    "          'Accuracy: ', acc,\n",
    "          'MSE: ', mse,\n",
    "          'UAR: ', uar,\n",
    "          'Recall: ', recall,\n",
    "          'Precision: ', precision,\n",
    "          'F1: ', f1)\n",
    "    if table_name is not None and metric_name is not None:\n",
    "        dump_to_table(table_name, metric_name, acc, mse, uar, recall, precision, f1)\n",
    "    return acc, mse, uar, recall, precision, f1\n",
    "\n",
    "def print_mse(preds, labels):\n",
    "    diff_correct,num_total=0.0,0\n",
    "    for i in range(len(preds)):\n",
    "        diff_correct+=(preds[i]-labels[i])**2\n",
    "        num_total+=1\n",
    "    print(num_total,diff_correct/num_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af2468be-d8a0-4500-97df-139a94874c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_dataset(engage_wild_dataset, bin_classification):\n",
    "    ENGAGE_WILD_DATASET = engage_wild_dataset\n",
    "    BIN_CLASSIFICATION = bin_classification\n",
    "    if BIN_CLASSIFICATION is True:\n",
    "        N_CLASSES = 2\n",
    "    else:\n",
    "        N_CLASSES = 4\n",
    "    if ENGAGE_WILD_DATASET is True:\n",
    "        ext = \"png\"\n",
    "        DATASET_NAME = 'EngageWild'\n",
    "        BASE_DATASET_DIR = '/home/HDD6TB/datasets/emotions/EmotiW/engagement/'\n",
    "        BASE_DATASET_DIR = '/media/deelvin_disk/echuraev/Workspace/HSE/datasets/EngageWild'\n",
    "    else:\n",
    "        ext = \"jpg\"\n",
    "        DATASET_NAME = 'DAiSEE'\n",
    "        BASE_DATASET_DIR = '/home/HDD6TB/datasets/emotions/DAiSEE/'\n",
    "        BASE_DATASET_DIR = '/media/deelvin_disk/echuraev/Workspace/HSE/datasets/DAiSEE'\n",
    "\n",
    "    return ENGAGE_WILD_DATASET, BIN_CLASSIFICATION, N_CLASSES, DATASET_NAME, BASE_DATASET_DIR, ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "373346b1-9103-44bc-b50d-60301a410255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video2label():\n",
    "    labels_list = ['very distracted', 'distracted', 'engaged', 'very engaged']\n",
    "    float2int={0:0,0.33:1,0.66:2,1:3}\n",
    "    if ENGAGE_WILD_DATASET is True:\n",
    "        import csv\n",
    "        video2label={}\n",
    "        with open(os.path.join(BASE_DATASET_DIR,'Engagement_Labels_Engagement.csv'), mode='r') as csvfile:\n",
    "            labels_reader = csv.reader(csvfile, delimiter='\\t')\n",
    "            for i,row in enumerate(labels_reader):\n",
    "                if i==0:\n",
    "                    continue\n",
    "                #videoname,label=row[0],float2int[float(row[1])]\n",
    "                videoname,label=row[0],float(row[1])\n",
    "                video2label[videoname]=label\n",
    "                #print(videoname,label)\n",
    "                #if (videoname not in filename2features_val) and (videoname not in filename2features_train):\n",
    "                #    print(videoname,label)\n",
    "        #check if fix is incorrect\n",
    "        video2label['subject_87_Vid_3']=video2label['subject_77_Vid_6']\n",
    "        #video2label = to_categorical(video2label)\n",
    "        #print(len(video2label))\n",
    "        #print(video2label)\n",
    "        if N_CLASSES == 2:\n",
    "            labels_list = ['engaged', 'distracted']\n",
    "            bin_labels = {0:1, 1:1, 2:0, 3:0}\n",
    "            for k in video2label.keys():\n",
    "                video2label[k] = bin_labels[float2int[video2label[k]]]\n",
    "    else:\n",
    "        import pandas as pd\n",
    "        df=pd.read_csv(os.path.join(BASE_DATASET_DIR,'Labels/AllLabels.csv'))\n",
    "        df.columns = df.columns.str.replace(' ', '')\n",
    "        df.head()\n",
    "        labels2fileAndValues=df.set_index('ClipID').to_dict()\n",
    "        video2label={os.path.splitext(video)[0]:val for video,val in labels2fileAndValues['Engagement'].items()}\n",
    "        #print(video2label)\n",
    "        if N_CLASSES == 2:\n",
    "            labels_list = ['engaged', 'distracted']\n",
    "            bin_labels = {0:1, 1:1, 2:0, 3:0}\n",
    "            for k in video2label.keys():\n",
    "                video2label[k] = bin_labels[video2label[k]]\n",
    "    return video2label, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e892933-aa4b-494f-9e10-08d3de782583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_path(metric_name):\n",
    "    return WEIGHTS_DIR + \"{}.h5\".format(metric_name)\n",
    "    \n",
    "def get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, aggregator, classificator):\n",
    "    return \"{}_{}_{}_{}_{}\".format(base_model_key, DATASET_NAME, N_CLASSES, aggregator, classificator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b40c7059-6a3d-4dc5-8d27-e89797e97e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classes(labels):\n",
    "    min_num = len(labels)\n",
    "    for i in np.unique(labels):\n",
    "        count = labels.count(i)\n",
    "        if count < min_num:\n",
    "            min_num = count\n",
    "        percent = count * 100 / len(labels)\n",
    "        print(\"{} {}/{}: {}%\".format(i, count, len(labels), percent))\n",
    "\n",
    "def get_labels(fn2feat):\n",
    "    labels = []\n",
    "    for fn in fn2feat.keys():\n",
    "        labels.append(video2label[fn])\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb41a413-6ea8-482c-9967-798a50a5b079",
   "metadata": {},
   "source": [
    "## Dataset balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b5d88ee-9f09-48dd-8889-500f8e2c1acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(filename2features):\n",
    "    x = []\n",
    "    y = []\n",
    "    ind=0\n",
    "    for fn in filename2features:\n",
    "        features=filename2features[fn]\n",
    "        total_features=None\n",
    "        if USE_ALL_FEATURES:\n",
    "            #prev=features[0].shape\n",
    "            cur_features=features[0][features[-1]==1]\n",
    "            #if filename2features_val==filename2features:\n",
    "            #    print(cur_features.shape)\n",
    "            #    cur_features=cur_features[2:]\n",
    "            #print(prev,features.shape)\n",
    "        else:\n",
    "            cur_features=features\n",
    "        \n",
    "        total_features=stat_func(cur_features)\n",
    "        if total_features is not None:\n",
    "            x.append(total_features)\n",
    "            y.append(video2label[fn])\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    print(x.shape,y.shape)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58a5385f-6003-4ad7-8cd3-b484baf9fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(7)\n",
    "\n",
    "def get_train_test_indices(x_all, y_all, SPLIT_RATIO):\n",
    "    inds_train, inds_test = [], []\n",
    "    inds = np.arange(len(y_all))\n",
    "    \n",
    "    for lbl in np.unique(y_all):\n",
    "        tmp_inds = inds[y_all == lbl]\n",
    "        random.shuffle(tmp_inds)\n",
    "        \n",
    "        ind=int(len(tmp_inds) * SPLIT_RATIO)\n",
    "        inds_train.append(tmp_inds[:ind])\n",
    "        inds_test.append(tmp_inds[ind:])\n",
    "    \n",
    "    inds_train = np.concatenate(inds_train, axis=0)\n",
    "    inds_test = np.concatenate(inds_test, axis=0)\n",
    "    return inds_train, inds_test\n",
    "\n",
    "def get_train_test():\n",
    "    inds_train, inds_test = get_train_test_indices()\n",
    "    X_train=x_all[inds_train]\n",
    "    y_train=y_all[inds_train]\n",
    "    X_test=x_all[inds_test]\n",
    "    y_test=y_all[inds_test]\n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f6b4d33-6613-4fc7-b389-6692e9a8b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_new_dataset(filename2features_train, filename2features_test, SPLIT_RATIO): # =0.767):\n",
    "    x_train, y_train = create_dataset(filename2features_train)\n",
    "    x_test, y_test = create_dataset(filename2features_test)\n",
    "\n",
    "    x_all=np.concatenate((x_train,x_test),axis=0)\n",
    "    y_all=np.concatenate((y_train,y_test),axis=0)\n",
    "    print(x_all.shape,y_all.shape)\n",
    "    \n",
    "    labels,counts=np.unique(y_all,return_counts=True)\n",
    "    print(labels,counts)\n",
    "\n",
    "    filenames_all=list(filename2features_train.keys())+list(filename2features_test.keys())\n",
    "    print(len(filenames_all))\n",
    "    \n",
    "    random.seed(7)\n",
    "    inds_train, inds_val = get_train_test_indices(x_all, y_all, SPLIT_RATIO)\n",
    "    \n",
    "    def get_filename2features_new(inds):\n",
    "        filename2features_new={}\n",
    "        for ind in inds:\n",
    "            filename=filenames_all[ind]\n",
    "            if filename in filename2features_train:\n",
    "                filename2features_new[filename]=filename2features_train[filename]\n",
    "            else:\n",
    "                filename2features_new[filename]=filename2features_test[filename]\n",
    "        print(len(filename2features_new))\n",
    "        return filename2features_new\n",
    "    filename2features_train_new=get_filename2features_new(inds_train)\n",
    "    filename2features_val_new=get_filename2features_new(inds_val)\n",
    "\n",
    "    return filename2features_train_new, filename2features_val_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e2f3045-37f6-4b28-90c9-c046f45d8142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_descriptor(cur_features, axis=0):\n",
    "    #cur_features=cur_features[1000:]\n",
    "    #cur_features=cur_features[30:-30]\n",
    "    #mean_features=features.mean(axis=0)\n",
    "    mean_features = np.mean(cur_features, axis=0)\n",
    "    std_features = np.std(cur_features, axis=0)\n",
    "    max_features = np.max(cur_features, axis=0)\n",
    "    min_features = np.min(cur_features, axis=0)\n",
    "\n",
    "    # join several features together\n",
    "    #feature = np.concatenate((mean_features, std_features, min_features, max_features), axis=None)                    \n",
    "    #feature = np.concatenate((mean_features, std_features, max_features), axis=None)\n",
    "    #feature = np.concatenate((mean_features, min_features, max_features), axis=None)\n",
    "    feature = np.concatenate((mean_features, std_features), axis=None)\n",
    "    #feature = np.concatenate((max_features, std_features), axis=None)\n",
    "\n",
    "    #feature=std_features\n",
    "    #feature=mean_features\n",
    "    #feature=np.percentile(cur_features, 100,axis=0)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a7c8f-7ae5-47c7-afb5-5440ff9610a5",
   "metadata": {},
   "source": [
    "## Attention specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48fea5d6-24c3-45f1-8648-3e5408d11c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SET_SIZE=128 #32 #20\n",
    "USE_GENERATORS = False\n",
    "USE_ALL_FEATURES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47e5377f-7c0a-413d-a054-39a6ee75e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(features_list, labels_list):\n",
    "    X_subsample,y_subsample=[],[]\n",
    "    for i in range(len(features_list)):\n",
    "        features=features_list[i]\n",
    "        label = labels_list[i]\n",
    "        total_features=None\n",
    "        if USE_ALL_FEATURES:\n",
    "            x=features[0][features[-1]==1]\n",
    "        else:\n",
    "            x=features\n",
    "        max_ind=len(x)-IMAGE_SET_SIZE\n",
    "        if max_ind<=0:\n",
    "            continue\n",
    "        stat_x=stat_func(x,axis=0)\n",
    "        num_samples=max(max_ind//(IMAGE_SET_SIZE),1)\n",
    "        for frame_ind in random.sample(range(max_ind),k=num_samples):\n",
    "            if CONCATENATE_STAT:\n",
    "                X_current=[np.concatenate((stat_x,x[frame_ind+i])) for i in range(IMAGE_SET_SIZE)]\n",
    "            else:\n",
    "                X_current=[x[frame_ind+i] for i in range(IMAGE_SET_SIZE)]\n",
    "            X_subsample.append(X_current)\n",
    "            y_subsample.append(label)\n",
    "    \n",
    " \n",
    "    X_subsample = np.array(X_subsample)\n",
    "    y_subsample=np.array(y_subsample)\n",
    "    print(X_subsample.shape,y_subsample.shape)\n",
    "    return X_subsample,y_subsample\n",
    "\n",
    "def get_samples(filename2features):\n",
    "    X_subsample,y_subsample=[],[]\n",
    "    for fn in filename2features:\n",
    "        features=filename2features[fn]\n",
    "        total_features=None\n",
    "        if USE_ALL_FEATURES:\n",
    "            x=features[0][features[-1]==1]\n",
    "        else:\n",
    "            x=features\n",
    "        max_ind=len(x)-IMAGE_SET_SIZE\n",
    "        if max_ind<=0:\n",
    "            continue\n",
    "        stat_x=stat_func(x,axis=0)\n",
    "        num_samples=max(max_ind//(IMAGE_SET_SIZE),1)\n",
    "        for frame_ind in random.sample(range(max_ind),k=num_samples):\n",
    "            if CONCATENATE_STAT:\n",
    "                X_current=[np.concatenate((stat_x,x[frame_ind+i])) for i in range(IMAGE_SET_SIZE)]\n",
    "            else:\n",
    "                X_current=[x[frame_ind+i] for i in range(IMAGE_SET_SIZE)]\n",
    "            X_subsample.append(X_current)\n",
    "            y_subsample.append(video2label[fn])\n",
    "    \n",
    " \n",
    "    X_subsample = np.array(X_subsample)\n",
    "    y_subsample=np.array(y_subsample)\n",
    "    print(X_subsample.shape,y_subsample.shape)\n",
    "    return X_subsample,y_subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1796b579-60bf-4967-b792-2c7cf1fae864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(features, labels):\n",
    "    X_subsample = []\n",
    "    Y_subsample = []\n",
    "    while True:\n",
    "        idx = random.randrange(len(labels))\n",
    "        x = features[idx]\n",
    "        img_count=len(x)\n",
    "        num_per_part = img_count // IMAGE_SET_SIZE\n",
    "\n",
    "        if img_count < IMAGE_SET_SIZE:\n",
    "            continue\n",
    "\n",
    "        mean_x=stat_func(x,axis=0)\n",
    "        for j in range(img_count):\n",
    "            if CONCATENATE_STAT:\n",
    "                #X_current=[np.concatenate((mean_x,x[frame_ind+i]-mean_x)) for i in range(IMAGE_SET_SIZE)]\n",
    "                X_current=[np.concatenate((mean_x,x[random.randint(num_per_part*j, min(num_per_part*(j+1),img_count-1))])) for j in range(IMAGE_SET_SIZE)]\n",
    "            else:\n",
    "                X_current=[x[random.randint(num_per_part*j, min(num_per_part*(j+1),img_count-1))] for j in range(IMAGE_SET_SIZE)]\n",
    "            X_subsample.append(X_current)\n",
    "            Y_subsample.append(labels[idx])\n",
    "            if len(Y_subsample) >= BATCH_SIZE:\n",
    "                X_subsample = np.array(X_subsample)\n",
    "                Y_subsample = np.array(Y_subsample)\n",
    "                yield X_subsample, Y_subsample\n",
    "                X_subsample = []\n",
    "                Y_subsample = []\n",
    "\n",
    "\n",
    "def get_num_samples(features):\n",
    "    num_samples = 0\n",
    "    for idx in range(len(features)):\n",
    "        x = features[idx]\n",
    "        img_count=len(x)\n",
    "        num_per_part = img_count // IMAGE_SET_SIZE\n",
    "\n",
    "        if img_count < IMAGE_SET_SIZE:\n",
    "            continue\n",
    "\n",
    "        num_samples += img_count\n",
    "\n",
    "    if num_samples % BATCH_SIZE > 0:\n",
    "        num_samples += BATCH_SIZE\n",
    "\n",
    "    if CONCATENATE_STAT:\n",
    "        mean_x=stat_func(x,axis=0)\n",
    "        #X_current=[np.concatenate((mean_x,x[frame_ind+i]-mean_x)) for i in range(IMAGE_SET_SIZE)]\n",
    "        vector_dim = len(np.concatenate((mean_x,x[random.randint(0, min(num_per_part,img_count-1))])))\n",
    "    else:\n",
    "        vector_dim = len(x[random.randint(0, min(num_per_part,img_count-1))])\n",
    "    return num_samples, vector_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "147937c0-db4d-439d-b58d-cd0bfaf66408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model,Model\n",
    "class SaveBestModel(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, save_best_metric='val_loss', this_max=False):\n",
    "        self.save_best_metric = save_best_metric\n",
    "        self.max = this_max\n",
    "        if this_max:\n",
    "            self.best = float('-inf')\n",
    "        else:\n",
    "            self.best = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metric_value = logs[self.save_best_metric]\n",
    "        if self.max:\n",
    "            if metric_value > self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_model_weights = self.model.get_weights()\n",
    "\n",
    "        else:\n",
    "            if metric_value < self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_model_weights = self.model.get_weights()\n",
    "\n",
    "# custom metrics for computing balance accuracy, mcc and f1\n",
    "class SaveBestModelByUAR(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, X, Y):\n",
    "        super(SaveBestModelByUAR, self).__init__()\n",
    "        self.X = X\n",
    "        self.Y = Y #.argmax(axis=-1)\n",
    "        self.best = float('-inf')\n",
    "        self.best_model_weights = None\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        predictions = self.model.predict(self.X)\n",
    "        y_pred = predictions.argmax(axis=-1)\n",
    "\n",
    "        metric_value = logs['val_uar'] = recall_score(y_true=self.Y,y_pred=y_pred, average='macro')\n",
    "        logs['val_bacc'] = balanced_accuracy_score(self.Y, y_pred)\n",
    "        logs['val_f1'] = f1_score(self.Y, y_pred, average='micro')\n",
    "        logs['val_mcc'] = matthews_corrcoef(self.Y, y_pred)\n",
    "        if metric_value > self.best:\n",
    "            self.best = metric_value\n",
    "            self.best_model_weights = self.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "040d6c89-9f1e-45fb-bef2-5d21b0766ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def uar_m(y_true, preds):\n",
    "    y_pred = K.argmax(preds, axis=-1)\n",
    "    return recall_m(y_true, y_pred) # recall_score(y_true=y_true,y_pred=y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d075de3-053a-43ba-955f-bb7e68a63135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES):\n",
    "    inputs = Input(shape=(None, FEATURE_VECTOR_DIM),name='image_set')  # (batch, samples, features)\n",
    "    e = Dense(1, activation='linear', name='e')(inputs)\n",
    "    e = Reshape([-1], name='alignment')(e)\n",
    "    alpha = Activation('softmax', name='alpha')(e)\n",
    "    \n",
    "    alpha_repeated = Permute([2, 1],name='alpha_repeated')(RepeatVector(FEATURE_VECTOR_DIM, name='repeat')(alpha))\n",
    "    \n",
    "    c = Multiply(name='c')([inputs, alpha_repeated])\n",
    "    x = Lambda(lambda xin: K.sum(xin, axis=1), output_shape=(FEATURE_VECTOR_DIM,), name='context')(c)\n",
    "    \n",
    "    #x = Dropout(0.3)(x)\n",
    "    x = Dense(units=512, activation='relu', name='hidden_FC')(x)  # (batch, units) #128 64\n",
    "    #x = tf.keras.activations.gelu(Dense(512, activation='linear')(x))\n",
    "\n",
    "    #pred=Dense(N_CLASSES,activation='softmax')(x)\n",
    "    if ENGAGE_WILD_DATASET is True or N_CLASSES == 2:\n",
    "        pred=Dense(1,activation='sigmoid')(x)\n",
    "        modelAtn=Model(inputs=inputs,outputs=pred)\n",
    "        #modelAtn.compile(optimizer=Adam(lr=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        if N_CLASSES == 2:\n",
    "            #modelAtn.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['acc', f1_m,precision_m, recall_m])\n",
    "            metrics=['acc',tf.keras.metrics.AUC(multi_label=True,name='auc'), tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.Recall(),tf.keras.metrics.Precision()]\n",
    "            modelAtn.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=metrics)\n",
    "        else:\n",
    "            modelAtn.compile(optimizer=Adam(lr=1e-4), loss='mse', metrics=['mae'])\n",
    "        save_best_model = SaveBestModel('val_loss',False)\n",
    "    else:\n",
    "        pred=Dense(N_CLASSES,activation='softmax')(x)\n",
    "        modelAtn=Model(inputs=inputs,outputs=pred)\n",
    "        #modelAtn.compile(optimizer=Adam(lr=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        #save_best_model = SaveBestModel('val_accuracy',True)\n",
    "        #METRICS = [\n",
    "        #    # keras.metrics.BinaryCrossentropy(name='cross entropy'),  # same as model's loss\n",
    "        #    # keras.metrics.MeanSquaredError(name='Brier score'),\n",
    "        #    # keras.metrics.TruePositives(name='tp'),\n",
    "        #    # keras.metrics.FalsePositives(name='fp'),\n",
    "        #    # keras.metrics.TrueNegatives(name='tn'),\n",
    "        #    # keras.metrics.FalseNegatives(name='fn'), \n",
    "        #    # keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        #    #keras.metrics.Precision(name='precision'),\n",
    "        #    #keras.metrics.Recall(name='recall'),\n",
    "        #    # keras.metrics.AUC(name='auc'),\n",
    "        #    # keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "        #    keras.metrics.F1Score(name='f1'),\n",
    "        #    'accuracy',\n",
    "        #    #f1_score_metric,\n",
    "        #]\n",
    "        modelAtn.compile(optimizer=Adam(lr=1e-4), loss='sparse_categorical_crossentropy', metrics=None)\n",
    "        save_best_model = SaveBestModel('accuracy',True)\n",
    "    modelAtn.summary()\n",
    "\n",
    "    \n",
    "    return modelAtn, save_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0261c53f-a317-428c-b48b-81fc4cd67929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES):\n",
    "    embeddings_dim=512\n",
    "    embeddings_dim=FEATURE_VECTOR_DIM\n",
    "    inputs = Input(shape=(None, FEATURE_VECTOR_DIM),name='image_set')  # (batch, samples, features)\n",
    "    if False:\n",
    "        query_seq_encoding, value_seq_encoding=inputs,inputs\n",
    "    else:\n",
    "        query_seq_encoding=Dense(embeddings_dim, activation='linear',use_bias=False, name='query')(inputs)\n",
    "        value_seq_encoding=Dense(embeddings_dim, activation='linear',use_bias=False, name='value')(inputs)\n",
    "    query_value_attention_seq = tf.keras.layers.Attention()([query_seq_encoding, value_seq_encoding])\n",
    "    \n",
    "    e = Dense(1, activation='linear', name='e')(query_value_attention_seq)\n",
    "    e = Reshape([-1], name='alignment')(e)\n",
    "    alpha = Activation('softmax', name='alpha')(e)\n",
    "    \n",
    "    alpha_repeated = Permute([2, 1],name='alpha_repeated')(RepeatVector(embeddings_dim, name='repeat')(alpha))\n",
    "    \n",
    "    c = Multiply(name='c')([query_value_attention_seq, alpha_repeated])\n",
    "    x = Lambda(lambda xin: K.sum(xin, axis=1), output_shape=(embeddings_dim,), name='context')(c)\n",
    "\n",
    "    #pred=Dense(N_CLASSES,activation='softmax')(x)\n",
    "    pred=Dense(1,activation='sigmoid')(x)\n",
    "    modelAtn=Model(inputs=inputs,outputs=pred)\n",
    "    #modelAtn.compile(optimizer=Adam(lr=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    if N_CLASSES == 2:\n",
    "        #modelAtn.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['acc', f1_m,precision_m, recall_m])\n",
    "        metrics=['acc',tf.keras.metrics.AUC(multi_label=True,name='auc'), tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.Recall(),tf.keras.metrics.Precision()]\n",
    "        modelAtn.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=metrics)\n",
    "    else:\n",
    "        modelAtn.compile(optimizer=Adam(lr=1e-4), loss='mse', metrics=['mae'])\n",
    "    modelAtn.summary()\n",
    "\n",
    "    #save_best_model = SaveBestModel('val_accuracy',True)\n",
    "    save_best_model = SaveBestModel('val_loss',False)\n",
    "    return modelAtn, save_best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd92ed1-9dd6-4c7c-a9a1-938f2b2716ec",
   "metadata": {},
   "source": [
    "# EngageWild dataset (4 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f28e1c4-93f0-4ecc-b130-0983d744aa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_DIR = DATA_DIR + 'features_EngageWild/'\n",
    "WEIGHTS_DIR = DATA_DIR + 'weights_EngageWild/'\n",
    "TABLE_NAME = '02_EngageWild_4_classes.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5112ce-2f9c-4bd8-a107-145cfcabd316",
   "metadata": {},
   "source": [
    "## enet_b0_8_best_afew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72c65ed3-b57c-4084-b551-cdb41a82e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_key = 'enet_b0_8_best_afew.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44e5336d-317a-4c08-8450-ef57609e7104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['very distracted', 'distracted', 'engaged', 'very engaged']\n",
      "{'subject_1_Vid_1': 1.0, 'subject_1_Vid_2': 1.0, 'subject_1_Vid_3': 0.66, 'subject_1_Vid_4': 1.0, 'subject_1_Vid_5': 1.0, 'subject_31_Vid_6': 1.0, 'subject_2_Vid_6': 0.33, 'subject_3_Vid_6': 1.0, 'subject_3_Vid_1': 0.33, 'subject_3_Vid_2': 0.33, 'subject_3_Vid_3': 0.66, 'subject_3_Vid_4': 0.66, 'subject_3_Vid_5': 0.33, 'subject_3_Vid_7': 1.0, 'subject_4_Vid_6': 1.0, 'subject_5_Vid_6': 1.0, 'subject_6_Vid_6': 0.33, 'subject_7_Vid_1': 0.66, 'subject_7_Vid_2': 0.66, 'subject_7_Vid_3': 0.66, 'subject_7_Vid_4': 0.66, 'subject_7_Vid_5': 0.33, 'subject_8_Vid_6': 1.0, 'subject_9_Vid_6': 0.0, 'subject_10_Vid_6': 0.66, 'subject_11_Vid_6': 1.0, 'subject_12_Vid_6': 0.0, 'subject_13_Vid_6': 0.66, 'subject_14_Vid_6': 0.66, 'subject_15_Vid_6': 0.66, 'subject_16_Vid_6': 0.33, 'subject_17_Vid_6': 0.66, 'subject_18_Vid_6': 0.33, 'subject_19_Vid_6': 1.0, 'subject_20_Vid_6': 0.66, 'subject_20_Vid_1': 0.66, 'subject_20_Vid_2': 0.66, 'subject_20_Vid_3': 0.66, 'subject_20_Vid_4': 0.33, 'subject_20_Vid_5': 0.66, 'subject_20_Vid_5_1': 0.66, 'subject_20_Vid_5_2': 1.0, 'subject_20_Vid_7': 0.0, 'subject_21_Vid_5': 0.0, 'subject_22_Vid_5': 1.0, 'subject_23_Vid_5': 0.33, 'subject_24_Vid_5': 1.0, 'subject_25_Vid_5': 0.66, 'subject_26_Vid_1': 0.66, 'subject_26_Vid_2': 0.66, 'subject_26_Vid_3': 0.33, 'subject_26_Vid_4': 0.66, 'subject_26_Vid_5': 0.33, 'subject_26_Vid_5_1': 0.66, 'subject_26_Vid_5_2': 0.66, 'subject_26_Vid_7': 0.33, 'subject_27_Vid_1': 0.66, 'subject_29_Vid_6': 0.66, 'subject_29_Vid_7': 0.33, 'subject_30_Vid_1': 0.33, 'subject_30_Vid_2': 0.66, 'subject_30_Vid_3': 0.66, 'subject_30_Vid_4': 1.0, 'subject_30_Vid_5': 0.33, 'subject_32_Vid_6': 1.0, 'subject_32_Vid_1': 0.66, 'subject_32_Vid_2': 0.66, 'subject_32_Vid_3': 0.66, 'subject_32_Vid_4': 0.66, 'subject_32_Vid_5': 0.66, 'subject_32_Vid_7': 0.33, 'subject_33_Vid_1': 0.33, 'subject_33_Vid_2': 0.66, 'subject_33_Vid_3': 0.66, 'subject_33_Vid_4': 0.66, 'subject_33_Vid_7': 0.66, 'subject_34_Vid_7': 1.0, 'subject_34_Vid_1': 0.66, 'subject_34_Vid_5': 0.66, 'subject_35_Vid_6': 0.33, 'subject_35_Vid_7': 0.66, 'subject_36_Vid_7': 0.66, 'subject_37_Vid_7': 0.66, 'subject_38_Vid_7': 0.66, 'subject_39_Vid_6': 0.66, 'subject_39_Vid_7': 0.33, 'subject_40_Vid_6': 0.66, 'subject_40_Vid_7': 0.33, 'subject_41_Vid_6': 1.0, 'subject_41_Vid_2': 0.0, 'subject_41_Vid_3': 0.66, 'subject_41_Vid_4': 0.33, 'subject_41_Vid_5': 0.33, 'subject_41_Vid_5_1': 0.66, 'subject_41_Vid_5_2': 0.33, 'subject_41_Vid_7': 0.66, 'subject_42_Vid_7': 1.0, 'subject_43_Vid_7': 0.66, 'subject_44_Vid_7': 0.33, 'subject_45_Vid_7': 0.33, 'subject_46_Vid_6': 0.66, 'subject_47_Vid_6': 1.0, 'subject_48_Vid_6': 1.0, 'subject_48_Vid_7': 0.66, 'subject_49_Vid_7': 0.66, 'subject_50_Vid_6': 0.66, 'subject_50_Vid_1': 0.66, 'subject_50_Vid_2': 0.33, 'subject_50_Vid_3': 0.33, 'subject_50_Vid_4': 0.33, 'subject_50_Vid_5': 0.33, 'subject_51_Vid_7': 1.0, 'subject_52_Vid_7': 0.0, 'subject_53_Vid_2': 0.66, 'subject_53_Vid_3': 0.66, 'subject_53_Vid_4': 0.66, 'subject_53_Vid_5': 0.66, 'subject_54_Vid_6': 0.66, 'subject_55_Vid_6': 0.66, 'subject_56_Vid_6': 0.66, 'subject_56_Vid_1': 0.66, 'subject_56_Vid_2': 0.66, 'subject_56_Vid_3': 1.0, 'subject_56_Vid_4': 0.66, 'subject_56_Vid_5': 0.66, 'subject_57_Vid_7': 1.0, 'subject_58_Vid_6': 1.0, 'subject_58_Vid_7': 0.66, 'subject_59_Vid_7': 0.66, 'subject_60_Vid_6': 1.0, 'subject_60_Vid_7': 0.66, 'subject_62_Vid_6': 1.0, 'subject_62_Vid_1': 0.66, 'subject_62_Vid_2': 1.0, 'subject_62_Vid_3': 0.33, 'subject_62_Vid_4': 1.0, 'subject_62_Vid_5': 0.66, 'subject_62_Vid_7': 0.66, 'subject_63_Vid_7': 0.33, 'subject_64_Vid_6': 1.0, 'subject_64_Vid_7': 0.33, 'subject_65_Vid_6': 1.0, 'subject_66_Vid_6': 1.0, 'subject_66_Vid_7': 0.33, 'subject_67_Vid_6': 0.66, 'subject_67_Vid_1': 1.0, 'subject_67_Vid_2': 0.66, 'subject_67_Vid_4': 0.66, 'subject_67_Vid_5': 0.66, 'subject_68_Vid_6': 0.66, 'subject_68_Vid_7': 0.33, 'subject_69_Vid_6': 1.0, 'subject_69_Vid_7': 0.66, 'subject_70_Vid_6': 0.66, 'subject_70_Vid_1': 0.66, 'subject_70_Vid_2': 0.66, 'subject_70_Vid_3': 0.66, 'subject_70_Vid_4': 0.66, 'subject_70_Vid_5': 0.33, 'subject_72_Vid_6': 0.66, 'subject_73_Vid_6': 1.0, 'subject_73_Vid_7': 1.0, 'subject_74_Vid_7': 0.0, 'subject_75_Vid_7': 0.66, 'subject_76_Vid_6': 0.66, 'subject_76_Vid_7': 1.0, 'subject_77_Vid_6': 0.66, 'subject_77_Vid_1': 0.33, 'subject_77_Vid_2': 0.33, 'subject_77_Vid_3': 0.66, 'subject_77_Vid_4': 0.66, 'subject_77_Vid_5': 0.0, 'subject_78_Vid_6': 0.66, 'subject_79_Vid_7': 0.66, 'subject_80_Vid_6': 0.66, 'subject_80_Vid_1': 0.66, 'subject_80_Vid_2': 0.66, 'subject_80_Vid_3': 0.66, 'subject_80_Vid_4': 0.66, 'subject_80_Vid_5': 0.66, 'subject_81_Vid_7': 0.33, 'subject_82_Vid_7': 1.0, 'subject_83_Vid_7': 1.0, 'subject_84_Vid_6': 0.33, 'subject_84_Vid_1': 0.33, 'subject_84_Vid_2': 0.33, 'subject_84_Vid_3': 0.0, 'subject_84_Vid_4': 0.33, 'subject_84_Vid_5': 0.33, 'subject_85_Vid_7': 1.0, 'subject_86_Vid_7': 1.0, 'subject_77_Vid_7': 0.33, 'subject_34_Vid_2': 0.66, 'subject_34_Vid_3': 1.0, 'subject_34_Vid_4': 0.66, 'subject_87_Vid_3': 0.66}\n"
     ]
    }
   ],
   "source": [
    "ENGAGE_WILD_DATASET, BIN_CLASSIFICATION, N_CLASSES, DATASET_NAME, BASE_DATASET_DIR, ext = define_dataset(True, False)\n",
    "video2label, labels_list = get_video2label()\n",
    "print(labels_list)\n",
    "print(video2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e342e6-fc90-4f16-9951-1267a4a0446d",
   "metadata": {},
   "source": [
    "### Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1b68647-64fc-4079-a891-11769c701f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.std\n",
    "stat_name = \"std\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefcfc60-4d4f-4ee0-b55b-4b815813389b",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "235e9668-1144-4463-b0fa-abed6a7f5fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f26e7aa-2222-4e92-8a34-366eb18b26c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b6fd4f5-d6ea-44fc-8cbd-9d964b8673f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab68e9b3-2a00-4c5a-a866-122f7f17022c",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "264a77be-bd26-4b8c-8071-4d8786aa3cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_std_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2398d316-4885-43d7-8fa9-54fe333b60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5d3ef1c-a851-4fac-9bd2-a9cf0c685055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2560) (5449,)\n",
      "(2284, 128, 2560) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df3167f6-1373-4937-a762-5b64004f9e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 20:57:19.794348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b194d2a-d5be-4f29-8a05-8e49c7b1a0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 20:57:28.377540: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xcab7b090 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-21 20:57:28.377561: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-21 20:57:28.382472: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-21 20:57:28.415997: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-07-21 20:57:28.468254: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 6s 102ms/step - loss: 0.0463 - mae: 0.1715 - val_loss: 0.0895 - val_mae: 0.2561\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0175 - mae: 0.1041 - val_loss: 0.0881 - val_mae: 0.2481\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0114 - mae: 0.0791 - val_loss: 0.0936 - val_mae: 0.2515\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0078 - mae: 0.0619 - val_loss: 0.0885 - val_mae: 0.2469\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0057 - mae: 0.0523 - val_loss: 0.0915 - val_mae: 0.2512\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0042 - mae: 0.0460 - val_loss: 0.1035 - val_mae: 0.2689\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0032 - mae: 0.0399 - val_loss: 0.0986 - val_mae: 0.2649\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0025 - mae: 0.0346 - val_loss: 0.0990 - val_mae: 0.2656\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0020 - mae: 0.0319 - val_loss: 0.1020 - val_mae: 0.2721\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0016 - mae: 0.0285 - val_loss: 0.1052 - val_mae: 0.2760\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0015 - mae: 0.0287 - val_loss: 0.0996 - val_mae: 0.2689\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0011 - mae: 0.0231 - val_loss: 0.1033 - val_mae: 0.2749\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 9.1736e-04 - mae: 0.0214 - val_loss: 0.1006 - val_mae: 0.2722\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 8.5897e-04 - mae: 0.0214 - val_loss: 0.1052 - val_mae: 0.2798\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 7.6170e-04 - mae: 0.0200 - val_loss: 0.1031 - val_mae: 0.2785\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 7.0384e-04 - mae: 0.0195 - val_loss: 0.1029 - val_mae: 0.2773\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 5.7950e-04 - mae: 0.0176 - val_loss: 0.1005 - val_mae: 0.2741\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 5.7016e-04 - mae: 0.0177 - val_loss: 0.1029 - val_mae: 0.2780\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 5.4686e-04 - mae: 0.0175 - val_loss: 0.1034 - val_mae: 0.2780\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 4.5498e-04 - mae: 0.0157 - val_loss: 0.1011 - val_mae: 0.2753\n",
      "0.08812975138425827\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d31fecba-0da6-4bd8-b1ad-cc5d9b065276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d96ded0-714e-49a7-8623-72450de6c4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_std_single_attention_traditional Accuracy:  0.2916666666666667 MSE:  0.10009201708232872 UAR:  0.3478070175438596 Recall:  N/A Precision:  N/A F1:  0.3157444005270092\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ffa2a78-60b7-4300-8948-01d95e9fdebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4c20336-ccff-4f57-9ad8-c91aa1fc7ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f52b0d5-b088-4f12-b5fe-6fcba71775b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_std_single_attention_traditional_best Accuracy:  0.3541666666666667 MSE:  0.08007323866137694 UAR:  0.2850877192982456 Recall:  N/A Precision:  N/A F1:  0.2765014024088434\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01f63cc-be71-4dc7-baa9-7b6fe46f3d7c",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "148310a7-8c22-4d29-b00f-b60d61441af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_std_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b435bfe4-7e66-4eb6-b925-36c17956a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bde3167e-1e05-430c-93a0-bd516a745e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2560) (5449,)\n",
      "(2284, 128, 2560) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b39372c-cde7-4611-9405-c1b720d34ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15e29ad5-e101-44fa-ae17-ea12505e55b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 152ms/step - loss: 0.2071 - mae: 0.3759 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 102ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "0.25096195936203003\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b177b6ef-6f0f-4046-a756-136271cc2d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a99d16e-b695-49e5-9473-7f3eb7c28be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_std_self_attention_traditional Accuracy:  0.3125 MSE:  0.22261249999999996 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9bccfb4-f7f8-4b57-ab0d-16d3075f19df",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee31f909-495b-412f-a4c5-17af56501651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b9a99ae-2d1f-40de-b53a-cda1cbf609e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_std_self_attention_traditional_best Accuracy:  0.3125 MSE:  0.22261249999999996 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e359871-f824-4738-9018-93f48c9f1c8e",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0733af2b-a721-4e4a-8680-f448575c6776",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c42478b-82a4-47cc-8ddc-1a116e23ee87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef9b0fff-41f4-45ac-bf78-fad80190c02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c34bda4-ccfe-4532-ab39-2c33ec84ba4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147,) (147,)\n",
      "(48,) (48,)\n",
      "(195,) (195,)\n",
      "[0.   0.33 0.66 1.  ] [ 9 45 98 43]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.767)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4b693810-e437-498b-b414-8bd348c93a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 6/147: 4.081632653061225%\n",
      "0.33 34/147: 23.12925170068027%\n",
      "0.66 75/147: 51.02040816326531%\n",
      "1.0 32/147: 21.768707482993197%\n",
      "val:\n",
      "0.0 3/48: 6.25%\n",
      "0.33 11/48: 22.916666666666668%\n",
      "0.66 23/48: 47.916666666666664%\n",
      "1.0 11/48: 22.916666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87409032-8f8c-461d-8163-dee55ca48745",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3dc1617b-24c1-411a-9c4f-723e824289d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_std_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f546513a-72ab-4329-b143-5da4681ccf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cee27540-ca68-45e2-a6fc-1169d0b14c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 2560) (5641,)\n",
      "(2092, 128, 2560) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a3d28b65-66f6-40c6-a95a-c5ef120fd802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fed6f241-7138-4c81-b8f2-4c7c406d36c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 4s 72ms/step - loss: 0.0421 - mae: 0.1615 - val_loss: 0.0632 - val_mae: 0.2078\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 2s 37ms/step - loss: 0.0124 - mae: 0.0855 - val_loss: 0.0632 - val_mae: 0.2054\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.0072 - mae: 0.0624 - val_loss: 0.0682 - val_mae: 0.2172\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0053 - mae: 0.0538 - val_loss: 0.0716 - val_mae: 0.2219\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.0035 - mae: 0.0407 - val_loss: 0.0742 - val_mae: 0.2249\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 1s 32ms/step - loss: 0.0028 - mae: 0.0368 - val_loss: 0.0769 - val_mae: 0.2310\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 2s 36ms/step - loss: 0.0024 - mae: 0.0345 - val_loss: 0.0777 - val_mae: 0.2317\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.0017 - mae: 0.0283 - val_loss: 0.0813 - val_mae: 0.2362\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0019 - mae: 0.0316 - val_loss: 0.0826 - val_mae: 0.2412\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 2s 37ms/step - loss: 0.0014 - mae: 0.0261 - val_loss: 0.0816 - val_mae: 0.2394\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 0.0823 - val_mae: 0.2387\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 0.0819 - val_mae: 0.2396\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 2s 37ms/step - loss: 8.9481e-04 - mae: 0.0217 - val_loss: 0.0853 - val_mae: 0.2443\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 8.3718e-04 - mae: 0.0211 - val_loss: 0.0826 - val_mae: 0.2399\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0010 - mae: 0.0228 - val_loss: 0.0837 - val_mae: 0.2409\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 2s 37ms/step - loss: 6.6876e-04 - mae: 0.0194 - val_loss: 0.0844 - val_mae: 0.2425\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 5.1003e-04 - mae: 0.0166 - val_loss: 0.0859 - val_mae: 0.2435\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 5.0099e-04 - mae: 0.0167 - val_loss: 0.0843 - val_mae: 0.2412\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 6.1644e-04 - mae: 0.0186 - val_loss: 0.0847 - val_mae: 0.2416\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 2s 36ms/step - loss: 5.1745e-04 - mae: 0.0172 - val_loss: 0.0859 - val_mae: 0.2427\n",
      "0.06317615509033203\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ac297fac-c4cb-467c-8eda-9ec3f9143bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "68598819-edcd-455e-94df-b041e097a713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_std_single_attention_balanced Accuracy:  0.3541666666666667 MSE:  0.0828139840055649 UAR:  0.363965744400527 Recall:  N/A Precision:  N/A F1:  0.36019736842105265\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1f7ea92d-8bdf-4a4a-b248-4c600b8f7d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "89308f93-f569-4aa6-8e95-55755649f314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "415ac85b-dd94-49c9-9e60-8c86d5e0b7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_std_single_attention_balanced_best Accuracy:  0.4583333333333333 MSE:  0.056269898658401506 UAR:  0.4183135704874835 Recall:  N/A Precision:  N/A F1:  0.4298611111111111\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b672de75-2cb6-4666-8e5c-693c75cffffd",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e0aedb55-3a27-4aad-955c-47e7d60815c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0f6fdfd7-d096-4523-b86e-dde918d077fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "697d679c-75c0-4f52-a9fa-03447b48432d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 2560) (5641,)\n",
      "(2092, 128, 2560) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "900cbe9f-58ca-437f-a9be-33b52f7b9e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "79605949-8be5-4fe5-8865-763392c89d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 7s 138ms/step - loss: 0.2181 - mae: 0.3788 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 4s 99ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 4s 89ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 4s 87ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 4s 89ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 4s 89ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 4s 100ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 4s 89ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "0.22412924468517303\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "310bd33c-00d1-4fc4-944d-bc15e38ec5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c0cc9db6-8e4b-4ca1-884e-a6973f74f031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_std_self_attention_balanced Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eceab423-e924-4920-bf11-db65fdc560d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0bccc1c7-f561-4c38-8210-c29567130ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "41680688-1dfa-4e64-92da-263bec48ff7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_std_self_attention_balanced_best Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a64f30c-7fc5-4f45-8ff6-936379d55c44",
   "metadata": {},
   "source": [
    "### Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b195292-3588-4f98-baea-a8fb3f857246",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.max\n",
    "stat_name = \"max\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289fa512-d8d3-46c0-8a7d-65b7f3c74ac3",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "baa38a93-0b4f-4247-9cdd-b96b4aab49f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "518c1c99-3d72-4ec8-a62a-f00aa39718af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4d90fa0b-124d-4c46-b8d8-231bdce2cc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dff5bd-525f-4c01-b563-26d80a0822f3",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bade9065-2988-483c-bda0-cdc6686fa006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_max_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c72c8448-9cd0-4423-8745-d6e1ba73ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bf954463-4185-4a01-9bbe-c0e5a696ccaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2560) (5449,)\n",
      "(2284, 128, 2560) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "96d95aa8-f976-4bfa-9cee-eead931c6ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4c13a604-9b92-4279-9181-be5435898db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 89ms/step - loss: 0.2061 - mae: 0.3746 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "0.25096195936203003\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5b167531-1f5c-4232-95df-0e5efad6e33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "42a15824-1e28-4190-a760-5ed4a341aecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_max_single_attention_traditional Accuracy:  0.3125 MSE:  0.22261250000000113 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d419209f-1a85-48d2-bde0-8c1693f14949",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "14b93dc5-5db7-4270-9d72-ae77dde78a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5ab4dc3c-4bfd-4560-8e6d-bf6d081b1161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_max_single_attention_traditional_best Accuracy:  0.3125 MSE:  0.22261250000000113 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a49507a-7a0b-41c1-8dd0-a62375605168",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "184b407a-36f0-475d-9aec-75735dcefb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_max_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "63edb738-71cb-4261-a282-ad59f4d8211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1a1bdbd4-e484-424e-9b58-815f85ffce27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2560) (5449,)\n",
      "(2284, 128, 2560) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "57910f69-acb8-43ab-8e22-9cc58f876229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_2 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_2[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_2[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7c22ac8e-68de-4bb7-8af6-f46ecd2a727f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 135ms/step - loss: 0.2059 - mae: 0.3744 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 102ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "0.25096195936203003\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e560fc06-2eed-4bff-bf0d-70c8bfbbdf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "40ba1c65-45b4-420e-a78a-69eee9e551cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_max_self_attention_traditional Accuracy:  0.3125 MSE:  0.22261249999999996 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b219e0d2-61ad-44cf-9f6d-d662352bd212",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d89a59c4-5e8e-489d-bdea-42bbeecf6fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3608044/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "df0ee10f-d0c8-4d2b-9677-dc7add7ceb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_max_self_attention_traditional_best Accuracy:  0.3125 MSE:  0.22261249999999996 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c4f180-1654-4e72-b69a-87c0ed2037e7",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b16e0523-5c1f-4039-8627-05f786a27090",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d95eaf87-91a1-4805-83a5-3832857b78a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c6e0aad-3173-41d3-a7d0-99ee13bdf54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30e6c463-4572-4b4b-a180-376e52b55a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147,) (147,)\n",
      "(48,) (48,)\n",
      "(195,) (195,)\n",
      "[0.   0.33 0.66 1.  ] [ 9 45 98 43]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.767)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec0867df-e582-4617-943b-7319f14e775f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 6/147: 4.081632653061225%\n",
      "0.33 34/147: 23.12925170068027%\n",
      "0.66 75/147: 51.02040816326531%\n",
      "1.0 32/147: 21.768707482993197%\n",
      "val:\n",
      "0.0 3/48: 6.25%\n",
      "0.33 11/48: 22.916666666666668%\n",
      "0.66 23/48: 47.916666666666664%\n",
      "1.0 11/48: 22.916666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d391549-ee93-4fef-b762-4f37292c35d1",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d5e9d3d-2b9c-4ee3-9d3e-32883263b899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_max_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17728ff2-1ee1-4ff4-9132-b45e3e5e9045",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f96053bc-4aed-4653-bc90-7f71cebe6377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 2560) (5641,)\n",
      "(2092, 128, 2560) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb590e04-90aa-4d0d-9097-9e9706c26fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 05:20:12.882923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f3ddea0-6cb0-4af2-8e69-3f52316cac35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 05:20:22.010341: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8a48007850 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-22 05:20:22.010361: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-22 05:20:22.015152: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-22 05:20:22.056624: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-07-22 05:20:22.109869: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 6s 94ms/step - loss: 0.2172 - mae: 0.3782 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 2s 37ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 2s 36ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 2s 37ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "0.22412924468517303\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00de1408-3c3a-45ca-90ca-1753d26a57c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3803109/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dcff4da7-30bc-441a-911f-6d662ecc2554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_max_single_attention_balanced Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c9b7b4f-92cb-4cda-a65a-c92b3539fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "601f8205-17b6-4321-a86d-ed60d1bbd235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3803109/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "67fa7c6c-cc8f-485b-ac6a-aa2e4009d7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_max_single_attention_balanced_best Accuracy:  0.22916666666666666 MSE:  0.2207645833333336 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f79cbe-5843-49de-8da0-603df23929a8",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e4bf602-9e4f-4b32-be76-78b4d3f81ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_max_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "954041ee-fb0f-463c-8ea0-cdae90d634c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0d79950-df9a-4652-8f4d-d72d54af02c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 2560) (5641,)\n",
      "(2092, 128, 2560) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e6044f64-92e4-4bfd-819a-128611a91885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5a1a2f5-ec51-4209-8cbd-eb92b1266fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 8s 152ms/step - loss: 0.2205 - mae: 0.3819 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 4s 87ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 4s 87ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 4s 87ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 4s 87ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 4s 87ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 4s 89ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 4s 89ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 4s 87ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 4s 88ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "0.22412924468517303\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42ef849c-2be6-49ba-864b-fc1375334ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3803109/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a91960d4-27c3-42b8-be87-48b1d56dd753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_max_self_attention_balanced Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf2e0022-8351-4c93-926a-37dea0e16b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "287f120b-1937-42f8-a7fd-6e8c94c4194f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3803109/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fdc73b7c-fb4f-4373-82ad-a723eb8fd3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_max_self_attention_balanced_best Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244037aa-84e4-45ab-b459-6183941eab9d",
   "metadata": {},
   "source": [
    "### STAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15084b36-0ac8-4409-9b71-fd92a289245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = compute_descriptor\n",
    "stat_name = \"STAT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44566caa-87bc-4db9-9d7f-2dfd1644116e",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e2be21e-2e28-457d-bc16-863d799257ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed6d4efe-2a52-40de-a363-480f583a8cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a121bea-44b4-4592-9e64-3f4a60f774ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072c7336-c38d-438f-bbfa-464043748347",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2377d7ff-d97d-4de1-aaf7-131d6ff19b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_STAT_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb3ec4ba-01db-46cf-88af-b4785dbc602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fc97153-9986-442c-8efc-f9998206f2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 3840) (5449,)\n",
      "(2284, 128, 3840) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "814aac4a-620f-46c7-8fcf-c2d3e5ed149b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 06:05:31.848209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1966592   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1970946 (7.52 MB)\n",
      "Trainable params: 1970946 (7.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c7b5cf2-17fb-47b9-a7f7-fa58bea5131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a8eeb31-abe3-4ab2-a944-606d57e9404d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3828290/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57e1d00b-1228-4ed3-8645-e3c19a0d0741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_STAT_single_attention_traditional Accuracy:  0.25 MSE:  0.1146485906264167 UAR:  0.22631578947368422 Recall:  N/A Precision:  N/A F1:  0.2108556832694764\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "550935d5-9075-4b50-8b72-96791c7b798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    modelAtn.set_weights(best_model_weights)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "86bcd151-ff3b-4279-8279-67f94902194d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3828290/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f91bb04f-3a62-4209-a94c-0781109d70f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_STAT_single_attention_traditional_best Accuracy:  0.3958333333333333 MSE:  0.08042476034517941 UAR:  0.3078947368421053 Recall:  N/A Precision:  N/A F1:  0.2902121374865736\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4011366-38ce-4e07-9b36-0255eab682c5",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6389cde-e688-4da3-bc21-066f39a6fdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_STAT_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31c7184e-5500-4370-966c-05348887529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8e3a040-fd1d-4270-8cbb-dc5e969c3656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 3840) (5449,)\n",
      "(2284, 128, 3840) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b38a2497-6876-4c4d-8c41-10454ce01451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 3840)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    3841      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29498882 (112.53 MB)\n",
      "Trainable params: 29498882 (112.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb722b09-b49b-4ca9-94d9-96f47383a37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28db23d7-faf1-4977-9a1d-13a17ec8da43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3828290/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f970d777-e247-4aa4-b35b-afc07b0b9b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_STAT_self_attention_traditional Accuracy:  0.3541666666666667 MSE:  0.10893076012359715 UAR:  0.38728070175438595 Recall:  N/A Precision:  N/A F1:  0.36451612903225805\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b9092ecf-4678-469e-9aa6-2c9437f0bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    modelAtn.set_weights(best_model_weights)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b62f95e-2608-4c69-bdea-e29e076ee3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3828290/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f22c2c14-f3a1-4b15-b53d-0c405f052233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_STAT_self_attention_traditional_best Accuracy:  0.4166666666666667 MSE:  0.07915359221476707 UAR:  0.4232456140350877 Recall:  N/A Precision:  N/A F1:  0.45722610722610724\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31608616-2d31-46dc-bd8b-5f1010018b85",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a9d5fb2-df83-46a8-b19f-b85f357ac3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4cac28d-b556-49ec-976a-e26ff6e191e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ce918278-f91f-4e9e-a338-a5b786f3f2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "35839ec8-7813-4003-aabc-ea51c8ff7c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147, 2560) (147,)\n",
      "(48, 2560) (48,)\n",
      "(195, 2560) (195,)\n",
      "[0.   0.33 0.66 1.  ] [ 9 45 98 43]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.767)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8b764ae8-925b-4505-bc73-dbb10e28e31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 6/147: 4.081632653061225%\n",
      "0.33 34/147: 23.12925170068027%\n",
      "0.66 75/147: 51.02040816326531%\n",
      "1.0 32/147: 21.768707482993197%\n",
      "val:\n",
      "0.0 3/48: 6.25%\n",
      "0.33 11/48: 22.916666666666668%\n",
      "0.66 23/48: 47.916666666666664%\n",
      "1.0 11/48: 22.916666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de34c445-bcf1-44e2-96a3-3ebc8f417fff",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8374547-f6f3-4bf6-8a60-2c407660ae07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_STAT_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b67bed2b-fca6-47ca-ae88-462c37108f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a287d128-d2da-4767-8d94-226a3670c1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 3840) (5641,)\n",
      "(2092, 128, 3840) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f4f8ce50-8c05-4d4d-b350-6529f2fc6962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1966592   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1970946 (7.52 MB)\n",
      "Trainable params: 1970946 (7.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ea401fc0-804b-4ebe-acee-db2550c02f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 06:09:52.493356: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7eec008940 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-22 06:09:52.493378: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-22 06:09:52.498201: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-22 06:09:52.535635: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-07-22 06:09:52.588560: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 8s 146ms/step - loss: 0.0425 - mae: 0.1595 - val_loss: 0.0671 - val_mae: 0.2109\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 2s 43ms/step - loss: 0.0109 - mae: 0.0782 - val_loss: 0.0690 - val_mae: 0.2114\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 2s 47ms/step - loss: 0.0057 - mae: 0.0518 - val_loss: 0.0778 - val_mae: 0.2242\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 2s 43ms/step - loss: 0.0043 - mae: 0.0455 - val_loss: 0.0797 - val_mae: 0.2309\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 2s 44ms/step - loss: 0.0030 - mae: 0.0362 - val_loss: 0.0795 - val_mae: 0.2317\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 2s 44ms/step - loss: 0.0021 - mae: 0.0302 - val_loss: 0.0808 - val_mae: 0.2333\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 2s 45ms/step - loss: 0.0021 - mae: 0.0313 - val_loss: 0.0903 - val_mae: 0.2447\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 2s 44ms/step - loss: 0.0016 - mae: 0.0276 - val_loss: 0.0878 - val_mae: 0.2434\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 2s 44ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 0.0846 - val_mae: 0.2406\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 2s 44ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0877 - val_mae: 0.2451\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 2s 44ms/step - loss: 8.2759e-04 - mae: 0.0200 - val_loss: 0.0854 - val_mae: 0.2419\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 2s 43ms/step - loss: 6.4077e-04 - mae: 0.0170 - val_loss: 0.0861 - val_mae: 0.2433\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 2s 44ms/step - loss: 6.2194e-04 - mae: 0.0175 - val_loss: 0.0873 - val_mae: 0.2433\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 2s 46ms/step - loss: 6.9158e-04 - mae: 0.0192 - val_loss: 0.0882 - val_mae: 0.2439\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 2s 44ms/step - loss: 4.1023e-04 - mae: 0.0142 - val_loss: 0.0875 - val_mae: 0.2426\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 2s 44ms/step - loss: 7.9377e-04 - mae: 0.0215 - val_loss: 0.0867 - val_mae: 0.2427\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 2s 46ms/step - loss: 5.1462e-04 - mae: 0.0167 - val_loss: 0.0909 - val_mae: 0.2482\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 2s 44ms/step - loss: 4.4852e-04 - mae: 0.0158 - val_loss: 0.0895 - val_mae: 0.2450\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 2s 44ms/step - loss: 2.3415e-04 - mae: 0.0107 - val_loss: 0.0895 - val_mae: 0.2454\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 2s 42ms/step - loss: 2.5423e-04 - mae: 0.0115 - val_loss: 0.0889 - val_mae: 0.2446\n",
      "0.06714434176683426\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf841647-5bb6-4bed-84ec-9804cd532ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3828290/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "416d0c59-e656-4a6e-83b4-c8fdb934a989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_STAT_single_attention_balanced Accuracy:  0.3541666666666667 MSE:  0.08639217736825654 UAR:  0.363965744400527 Recall:  N/A Precision:  N/A F1:  0.34731934731934727\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8ca50cbd-902a-4dbd-8d6e-417bc8d031aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    modelAtn.set_weights(best_model_weights)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fc0a8704-9418-4564-b119-ce8413dbda25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3828290/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fbd3fa48-55f7-43b3-ba23-3eb0748c49fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_4_STAT_single_attention_balanced_best Accuracy:  0.4791666666666667 MSE:  0.0586605660204162 UAR:  0.42918313570487476 Recall:  N/A Precision:  N/A F1:  0.4437641723356009\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ed5e65-6532-424d-b488-04cfe3fcf0e2",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "88b6d625-ef94-4e41-91f4-141a16d514ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_4_STAT_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd2b2588-4801-4cb4-bb02-c24e314f2a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6e77439e-107d-4eaf-9ea8-8c5e027da9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 3840) (5641,)\n",
      "(2092, 128, 3840) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fb25e35d-5de3-46cb-88e3-f0c80883a59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 3840)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    3841      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29498882 (112.53 MB)\n",
      "Trainable params: 29498882 (112.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2937f4eb-0235-4ea5-a09e-79a2e547f5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 13s 270ms/step - loss: 0.2176 - mae: 0.3791 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 9s 197ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 8s 172ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 8s 171ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 8s 171ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 9/20\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.2202 - mae: 0.3810"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0859e-51b7-4190-82ed-a7562d95ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e91a51-24dd-4da2-9584-c2fb381106fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c4395-5936-441a-9f11-0e63e6e055fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    modelAtn.set_weights(best_model_weights)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a25056-68cc-4b0b-a52b-bf71d4f388a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bcf3a1-a509-4f50-b856-842264fe414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3ab641-f92d-4359-b8d8-5eb13a03502c",
   "metadata": {},
   "source": [
    "## MobileNet_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dffa3b34-1dac-4749-846b-7bfeef4c0d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_key = 'mobilenet_7.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a342b79f-70a8-42ce-ae9a-fe01450f49d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['very distracted', 'distracted', 'engaged', 'very engaged']\n",
      "{'subject_1_Vid_1': 1.0, 'subject_1_Vid_2': 1.0, 'subject_1_Vid_3': 0.66, 'subject_1_Vid_4': 1.0, 'subject_1_Vid_5': 1.0, 'subject_31_Vid_6': 1.0, 'subject_2_Vid_6': 0.33, 'subject_3_Vid_6': 1.0, 'subject_3_Vid_1': 0.33, 'subject_3_Vid_2': 0.33, 'subject_3_Vid_3': 0.66, 'subject_3_Vid_4': 0.66, 'subject_3_Vid_5': 0.33, 'subject_3_Vid_7': 1.0, 'subject_4_Vid_6': 1.0, 'subject_5_Vid_6': 1.0, 'subject_6_Vid_6': 0.33, 'subject_7_Vid_1': 0.66, 'subject_7_Vid_2': 0.66, 'subject_7_Vid_3': 0.66, 'subject_7_Vid_4': 0.66, 'subject_7_Vid_5': 0.33, 'subject_8_Vid_6': 1.0, 'subject_9_Vid_6': 0.0, 'subject_10_Vid_6': 0.66, 'subject_11_Vid_6': 1.0, 'subject_12_Vid_6': 0.0, 'subject_13_Vid_6': 0.66, 'subject_14_Vid_6': 0.66, 'subject_15_Vid_6': 0.66, 'subject_16_Vid_6': 0.33, 'subject_17_Vid_6': 0.66, 'subject_18_Vid_6': 0.33, 'subject_19_Vid_6': 1.0, 'subject_20_Vid_6': 0.66, 'subject_20_Vid_1': 0.66, 'subject_20_Vid_2': 0.66, 'subject_20_Vid_3': 0.66, 'subject_20_Vid_4': 0.33, 'subject_20_Vid_5': 0.66, 'subject_20_Vid_5_1': 0.66, 'subject_20_Vid_5_2': 1.0, 'subject_20_Vid_7': 0.0, 'subject_21_Vid_5': 0.0, 'subject_22_Vid_5': 1.0, 'subject_23_Vid_5': 0.33, 'subject_24_Vid_5': 1.0, 'subject_25_Vid_5': 0.66, 'subject_26_Vid_1': 0.66, 'subject_26_Vid_2': 0.66, 'subject_26_Vid_3': 0.33, 'subject_26_Vid_4': 0.66, 'subject_26_Vid_5': 0.33, 'subject_26_Vid_5_1': 0.66, 'subject_26_Vid_5_2': 0.66, 'subject_26_Vid_7': 0.33, 'subject_27_Vid_1': 0.66, 'subject_29_Vid_6': 0.66, 'subject_29_Vid_7': 0.33, 'subject_30_Vid_1': 0.33, 'subject_30_Vid_2': 0.66, 'subject_30_Vid_3': 0.66, 'subject_30_Vid_4': 1.0, 'subject_30_Vid_5': 0.33, 'subject_32_Vid_6': 1.0, 'subject_32_Vid_1': 0.66, 'subject_32_Vid_2': 0.66, 'subject_32_Vid_3': 0.66, 'subject_32_Vid_4': 0.66, 'subject_32_Vid_5': 0.66, 'subject_32_Vid_7': 0.33, 'subject_33_Vid_1': 0.33, 'subject_33_Vid_2': 0.66, 'subject_33_Vid_3': 0.66, 'subject_33_Vid_4': 0.66, 'subject_33_Vid_7': 0.66, 'subject_34_Vid_7': 1.0, 'subject_34_Vid_1': 0.66, 'subject_34_Vid_5': 0.66, 'subject_35_Vid_6': 0.33, 'subject_35_Vid_7': 0.66, 'subject_36_Vid_7': 0.66, 'subject_37_Vid_7': 0.66, 'subject_38_Vid_7': 0.66, 'subject_39_Vid_6': 0.66, 'subject_39_Vid_7': 0.33, 'subject_40_Vid_6': 0.66, 'subject_40_Vid_7': 0.33, 'subject_41_Vid_6': 1.0, 'subject_41_Vid_2': 0.0, 'subject_41_Vid_3': 0.66, 'subject_41_Vid_4': 0.33, 'subject_41_Vid_5': 0.33, 'subject_41_Vid_5_1': 0.66, 'subject_41_Vid_5_2': 0.33, 'subject_41_Vid_7': 0.66, 'subject_42_Vid_7': 1.0, 'subject_43_Vid_7': 0.66, 'subject_44_Vid_7': 0.33, 'subject_45_Vid_7': 0.33, 'subject_46_Vid_6': 0.66, 'subject_47_Vid_6': 1.0, 'subject_48_Vid_6': 1.0, 'subject_48_Vid_7': 0.66, 'subject_49_Vid_7': 0.66, 'subject_50_Vid_6': 0.66, 'subject_50_Vid_1': 0.66, 'subject_50_Vid_2': 0.33, 'subject_50_Vid_3': 0.33, 'subject_50_Vid_4': 0.33, 'subject_50_Vid_5': 0.33, 'subject_51_Vid_7': 1.0, 'subject_52_Vid_7': 0.0, 'subject_53_Vid_2': 0.66, 'subject_53_Vid_3': 0.66, 'subject_53_Vid_4': 0.66, 'subject_53_Vid_5': 0.66, 'subject_54_Vid_6': 0.66, 'subject_55_Vid_6': 0.66, 'subject_56_Vid_6': 0.66, 'subject_56_Vid_1': 0.66, 'subject_56_Vid_2': 0.66, 'subject_56_Vid_3': 1.0, 'subject_56_Vid_4': 0.66, 'subject_56_Vid_5': 0.66, 'subject_57_Vid_7': 1.0, 'subject_58_Vid_6': 1.0, 'subject_58_Vid_7': 0.66, 'subject_59_Vid_7': 0.66, 'subject_60_Vid_6': 1.0, 'subject_60_Vid_7': 0.66, 'subject_62_Vid_6': 1.0, 'subject_62_Vid_1': 0.66, 'subject_62_Vid_2': 1.0, 'subject_62_Vid_3': 0.33, 'subject_62_Vid_4': 1.0, 'subject_62_Vid_5': 0.66, 'subject_62_Vid_7': 0.66, 'subject_63_Vid_7': 0.33, 'subject_64_Vid_6': 1.0, 'subject_64_Vid_7': 0.33, 'subject_65_Vid_6': 1.0, 'subject_66_Vid_6': 1.0, 'subject_66_Vid_7': 0.33, 'subject_67_Vid_6': 0.66, 'subject_67_Vid_1': 1.0, 'subject_67_Vid_2': 0.66, 'subject_67_Vid_4': 0.66, 'subject_67_Vid_5': 0.66, 'subject_68_Vid_6': 0.66, 'subject_68_Vid_7': 0.33, 'subject_69_Vid_6': 1.0, 'subject_69_Vid_7': 0.66, 'subject_70_Vid_6': 0.66, 'subject_70_Vid_1': 0.66, 'subject_70_Vid_2': 0.66, 'subject_70_Vid_3': 0.66, 'subject_70_Vid_4': 0.66, 'subject_70_Vid_5': 0.33, 'subject_72_Vid_6': 0.66, 'subject_73_Vid_6': 1.0, 'subject_73_Vid_7': 1.0, 'subject_74_Vid_7': 0.0, 'subject_75_Vid_7': 0.66, 'subject_76_Vid_6': 0.66, 'subject_76_Vid_7': 1.0, 'subject_77_Vid_6': 0.66, 'subject_77_Vid_1': 0.33, 'subject_77_Vid_2': 0.33, 'subject_77_Vid_3': 0.66, 'subject_77_Vid_4': 0.66, 'subject_77_Vid_5': 0.0, 'subject_78_Vid_6': 0.66, 'subject_79_Vid_7': 0.66, 'subject_80_Vid_6': 0.66, 'subject_80_Vid_1': 0.66, 'subject_80_Vid_2': 0.66, 'subject_80_Vid_3': 0.66, 'subject_80_Vid_4': 0.66, 'subject_80_Vid_5': 0.66, 'subject_81_Vid_7': 0.33, 'subject_82_Vid_7': 1.0, 'subject_83_Vid_7': 1.0, 'subject_84_Vid_6': 0.33, 'subject_84_Vid_1': 0.33, 'subject_84_Vid_2': 0.33, 'subject_84_Vid_3': 0.0, 'subject_84_Vid_4': 0.33, 'subject_84_Vid_5': 0.33, 'subject_85_Vid_7': 1.0, 'subject_86_Vid_7': 1.0, 'subject_77_Vid_7': 0.33, 'subject_34_Vid_2': 0.66, 'subject_34_Vid_3': 1.0, 'subject_34_Vid_4': 0.66, 'subject_87_Vid_3': 0.66}\n"
     ]
    }
   ],
   "source": [
    "ENGAGE_WILD_DATASET, BIN_CLASSIFICATION, N_CLASSES, DATASET_NAME, BASE_DATASET_DIR, ext = define_dataset(True, False)\n",
    "video2label, labels_list = get_video2label()\n",
    "print(labels_list)\n",
    "print(video2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0814fe-ae1d-4655-8ad0-4c8f67c8611b",
   "metadata": {},
   "source": [
    "### Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "793e8d4a-5902-4266-b4a7-fa5fa5ed943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.std\n",
    "stat_name = \"std\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e991975-458a-4db2-a6a1-27138473f962",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0d598a6-14af-456e-8113-9a0d424f9ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "903ab869-7bbe-46e4-8a2f-1131ebccbb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "177e27ac-e0c2-4a6d-b0a2-9ee0fcaf360c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd728eb-895e-4d66-9699-40bffdfc5004",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "568affbd-ba0b-4bc1-80db-e88f0b819918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_std_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88d68cf7-f021-40c5-a048-d814c48e3596",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84fddbce-c1fc-445b-a04e-5cb297bf6f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2048) (5449,)\n",
      "(2284, 128, 2048) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4c31cc1-3752-460b-af40-1a6dfb95ec39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 15:58:54.594011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f142cab8-8855-44e4-9e38-42b7db03c7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 15:59:01.869079: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x13b0e8840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-23 15:59:01.869100: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-23 15:59:01.873846: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-23 15:59:01.905719: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-07-23 15:59:01.957648: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 5s 87ms/step - loss: 0.0493 - mae: 0.1724 - val_loss: 0.0992 - val_mae: 0.2626\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.0181 - mae: 0.1056 - val_loss: 0.0975 - val_mae: 0.2508\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.0098 - mae: 0.0745 - val_loss: 0.1053 - val_mae: 0.2578\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.0065 - mae: 0.0600 - val_loss: 0.1108 - val_mae: 0.2641\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.0044 - mae: 0.0480 - val_loss: 0.1173 - val_mae: 0.2652\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.0033 - mae: 0.0416 - val_loss: 0.1229 - val_mae: 0.2696\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.0024 - mae: 0.0352 - val_loss: 0.1229 - val_mae: 0.2677\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.0017 - mae: 0.0292 - val_loss: 0.1255 - val_mae: 0.2696\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 0.1253 - val_mae: 0.2709\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0012 - mae: 0.0238 - val_loss: 0.1314 - val_mae: 0.2749\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0011 - mae: 0.0232 - val_loss: 0.1291 - val_mae: 0.2751\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.0010 - mae: 0.0236 - val_loss: 0.1304 - val_mae: 0.2794\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 7.1315e-04 - mae: 0.0190 - val_loss: 0.1313 - val_mae: 0.2794\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 6.2009e-04 - mae: 0.0179 - val_loss: 0.1324 - val_mae: 0.2800\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 6.2929e-04 - mae: 0.0184 - val_loss: 0.1335 - val_mae: 0.2815\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 5.3124e-04 - mae: 0.0169 - val_loss: 0.1324 - val_mae: 0.2822\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 6.9970e-04 - mae: 0.0203 - val_loss: 0.1311 - val_mae: 0.2837\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 5.3418e-04 - mae: 0.0174 - val_loss: 0.1333 - val_mae: 0.2825\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 4.2130e-04 - mae: 0.0151 - val_loss: 0.1340 - val_mae: 0.2839\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 4.3590e-04 - mae: 0.0157 - val_loss: 0.1341 - val_mae: 0.2839\n",
      "0.09747046232223511\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66491423-128d-404f-8afc-77ee5b1bba6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a98c0707-dc80-4b03-b1e5-085e709c9b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_std_single_attention_traditional Accuracy:  0.4375 MSE:  0.11541946616558597 UAR:  0.356578947368421 Recall:  N/A Precision:  N/A F1:  0.3360759953501889\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f5a049b-f05c-4985-81a7-a2985f47e456",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e6a1fc7-e01f-48d5-b25c-a26eca5234f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89df3fc3-4d35-401b-9df1-f6bb880b8cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_std_single_attention_traditional_best Accuracy:  0.4166666666666667 MSE:  0.08423179411250159 UAR:  0.30087719298245613 Recall:  N/A Precision:  N/A F1:  0.2812820512820513\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20ddc05-09bd-47f5-8c1b-0ccc5b1dd818",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d44ef88-2e76-4abb-a87d-f9cff7c3c9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_std_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b27a3e80-0d83-45cb-862c-99c6b49bd797",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "baa585b2-512b-476c-8282-0479edc7c460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2048) (5449,)\n",
      "(2284, 128, 2048) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "403375d7-e066-4934-98c4-664785e9154c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2962b8ea-2de2-42da-a6d4-72c57379b974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 129ms/step - loss: 0.2048 - mae: 0.3731 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 3s 64ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "0.25096195936203003\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cabfec47-4487-4eef-9311-2b89dc1e378d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a3efe377-8f70-480b-94c1-9bc29de327d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_std_self_attention_traditional Accuracy:  0.3125 MSE:  0.22261249999999996 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5972dae2-5972-40fa-ba89-c9d96f4a7225",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "60425a81-f048-47f6-851e-1bc81d08f2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5264123-53e1-483a-b3bf-41d80e561bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_std_self_attention_traditional_best Accuracy:  0.3125 MSE:  0.22261249999999996 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e43bd5-010f-4def-9dac-0dd741cd6b47",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6aaea95a-618c-4fef-858f-2085095f0e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dfe3218a-8431-4c9e-9102-cb787c84af84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "503da23f-116f-4346-b0b7-c896c0825e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "405a075d-f875-401e-97d9-02f6ae499b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147,) (147,)\n",
      "(48,) (48,)\n",
      "(195,) (195,)\n",
      "[0.   0.33 0.66 1.  ] [ 9 45 98 43]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.767)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32f2a819-7f5e-4bfa-831f-507606beb945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 6/147: 4.081632653061225%\n",
      "0.33 34/147: 23.12925170068027%\n",
      "0.66 75/147: 51.02040816326531%\n",
      "1.0 32/147: 21.768707482993197%\n",
      "val:\n",
      "0.0 3/48: 6.25%\n",
      "0.33 11/48: 22.916666666666668%\n",
      "0.66 23/48: 47.916666666666664%\n",
      "1.0 11/48: 22.916666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d42ad2-fab9-4aff-b72f-c60ea8f158f0",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a41b3fd3-4cf6-4a78-ac31-2367da3c5d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_std_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f60a2150-e989-42f0-b67f-ac629044fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f89cb8d7-f346-456e-ae86-ebadbeb0e458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 2048) (5641,)\n",
      "(2092, 128, 2048) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c6f0c4f3-2b0d-42c3-8413-b21a6309c877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ebcfbfe0-58c0-437f-bb2b-7a6f2eb8874d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 3s 60ms/step - loss: 0.0497 - mae: 0.1738 - val_loss: 0.0687 - val_mae: 0.2079\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0171 - mae: 0.1051 - val_loss: 0.0673 - val_mae: 0.2081\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0086 - mae: 0.0705 - val_loss: 0.0686 - val_mae: 0.2080\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0052 - mae: 0.0536 - val_loss: 0.0678 - val_mae: 0.2071\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0037 - mae: 0.0443 - val_loss: 0.0726 - val_mae: 0.2110\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0030 - mae: 0.0398 - val_loss: 0.0736 - val_mae: 0.2154\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0026 - mae: 0.0379 - val_loss: 0.0758 - val_mae: 0.2195\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0020 - mae: 0.0317 - val_loss: 0.0764 - val_mae: 0.2181\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 0.0796 - val_mae: 0.2196\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0012 - mae: 0.0241 - val_loss: 0.0789 - val_mae: 0.2189\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0011 - mae: 0.0243 - val_loss: 0.0814 - val_mae: 0.2249\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0012 - mae: 0.0250 - val_loss: 0.0798 - val_mae: 0.2200\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 8.0569e-04 - mae: 0.0202 - val_loss: 0.0804 - val_mae: 0.2198\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 8.3052e-04 - mae: 0.0214 - val_loss: 0.0794 - val_mae: 0.2144\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 9.5357e-04 - mae: 0.0235 - val_loss: 0.0794 - val_mae: 0.2191\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 6.8454e-04 - mae: 0.0196 - val_loss: 0.0828 - val_mae: 0.2276\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 7.9620e-04 - mae: 0.0216 - val_loss: 0.0799 - val_mae: 0.2182\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 7.0113e-04 - mae: 0.0205 - val_loss: 0.0810 - val_mae: 0.2185\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 7.0571e-04 - mae: 0.0205 - val_loss: 0.0814 - val_mae: 0.2199\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 4.6846e-04 - mae: 0.0164 - val_loss: 0.0795 - val_mae: 0.2178\n",
      "0.06734990328550339\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f637f2b7-8e79-4c00-8442-b2a8d166cea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e3148656-8ffe-4e55-bf23-a4e1777d348f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_std_single_attention_balanced Accuracy:  0.4583333333333333 MSE:  0.06568898942859348 UAR:  0.3814229249011858 Recall:  N/A Precision:  N/A F1:  0.3470916568742656\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "14cf0d24-8bd5-4a51-ac7d-bf66b7d57fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1fa823f7-6c64-4d1c-a4d3-fa95e3766fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "899bfa38-6b18-4ef7-bcc2-bfb8b4546e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_std_single_attention_balanced_best Accuracy:  0.5208333333333334 MSE:  0.05547004883940995 UAR:  0.4627799736495389 Recall:  N/A Precision:  N/A F1:  0.4724120082815735\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7821a1f6-0253-4b24-99fa-3c0ef1aa0305",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "59594835-18ea-4822-b132-ab77d5e07c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "adeaa8fb-9004-4330-8f15-9b0491ae3aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "368dd962-f399-47bf-b61d-2825fc10edc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 2048) (5641,)\n",
      "(2092, 128, 2048) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b3504519-135e-4248-b5a0-ac9ea9a3aa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4ed9b857-c44d-4d91-93a1-dd091bd41c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 5s 94ms/step - loss: 0.2169 - mae: 0.3773 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 3s 64ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "0.22412924468517303\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f263d612-f50b-4114-90d6-1b0d2584a3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8ab2f30b-a69f-4922-a6de-0dba6726666f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_std_self_attention_balanced Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b0226d7d-c261-4d5f-9919-eae9d7f28bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f5cde8bf-6510-463f-ad5e-7f85e0136dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d69280fc-74a1-46e8-8866-35960de4a869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_std_self_attention_balanced_best Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4bfe57-f153-41a0-b28a-4f5f920a9ecf",
   "metadata": {},
   "source": [
    "### Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53903341-5237-4e04-9f1d-c38ffd56fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.max\n",
    "stat_name = \"max\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f8fec5-b27f-4b90-8e0d-7658bf7238a6",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bf36ee0a-6874-43d6-925c-cfa8dda9e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f7c002df-81e4-422f-b963-dfd4816fce3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a2e516c4-7d9f-45d0-b2bb-c5eb9fa4c60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c75f106-71c9-4dc7-b999-097591f7475f",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "82c22490-f81d-4e46-acf6-7f1c2ab894fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_max_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "faa49269-f2d4-4ea2-89eb-278963024bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3b5f46f7-9eb9-4966-9758-ebf1c7f043f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2048) (5449,)\n",
      "(2284, 128, 2048) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "16c73ea5-cec8-404b-a65a-694e401d28c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a0900e2e-9bf0-496d-83f6-5eb04d5247df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.2723 - mae: 0.4406 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "0.25096189975738525\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "be7e2354-81f0-4cf2-8dcc-f9a8c5ad706e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "21130651-91b7-44ee-962c-091985ca943f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_max_single_attention_traditional Accuracy:  0.3125 MSE:  0.2226124206764275 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "56fbc493-e04c-4f2e-885a-b4c23da99a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b2b107cf-f2e5-4214-b419-8df82052fba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4f11f25d-c6ef-4027-b3b1-715c6ec57018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_max_single_attention_traditional_best Accuracy:  0.3125 MSE:  0.2226123397141818 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7870ec08-5a8d-4200-bc65-eac8df1b9e03",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6040d5a2-d93f-4c92-91b9-fc27d3abf123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_max_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c688b11b-3bbf-4470-816a-7b6f04299bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f458f0d8-21a7-4c34-a322-d4c94157cb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2048) (5449,)\n",
      "(2284, 128, 2048) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ed7899f7-1964-4e82-9184-c3e6e7c16362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_2 (Attention)     (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention_2[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention_2[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a5bad1ef-5624-44a9-93cf-396f44b14166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 131ms/step - loss: 0.4446 - mae: 0.6123 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.4538 - mae: 0.6224 - val_loss: 0.5077 - val_mae: 0.6284\n",
      "0.5077046155929565\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "46541a48-dc5d-428f-93f6-711700cede03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1403b5f7-3165-43bc-8c92-9ab536714ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_max_self_attention_traditional Accuracy:  0.08333333333333333 MSE:  0.5076125 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.038461538461538464\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e3a68a51-5db7-427d-8a16-702447e7cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "05766c0d-88c4-4872-badc-7685accabb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3864770/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d849d4bc-8052-4f79-92ff-090f051a2b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_max_self_attention_traditional_best Accuracy:  0.08333333333333333 MSE:  0.5076125 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.038461538461538464\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdde1c9-809a-4331-82c2-c2e651096ece",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6eed71f-7937-44dd-b740-d444c7385e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "696c2c22-572a-40b3-95cc-68bbc78f50f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42731249-1940-482b-bf85-552f30a0ceb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "287d37bf-ddd9-4dc2-bd15-ebf247cd2f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147,) (147,)\n",
      "(48,) (48,)\n",
      "(195,) (195,)\n",
      "[0.   0.33 0.66 1.  ] [ 9 45 98 43]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.767)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e22d53a-b458-4116-9af9-1881794bf714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 6/147: 4.081632653061225%\n",
      "0.33 34/147: 23.12925170068027%\n",
      "0.66 75/147: 51.02040816326531%\n",
      "1.0 32/147: 21.768707482993197%\n",
      "val:\n",
      "0.0 3/48: 6.25%\n",
      "0.33 11/48: 22.916666666666668%\n",
      "0.66 23/48: 47.916666666666664%\n",
      "1.0 11/48: 22.916666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a4f729-629b-4df1-8800-f61873462683",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e38f9faf-3363-4017-9812-80706868b674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_max_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74cefe18-c0b9-4f31-9e6c-be2958765c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b85b564-27b1-4807-83a8-d8c6f9163e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 2048) (5641,)\n",
      "(2092, 128, 2048) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90c68b0e-937a-408a-bef4-139569d93498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 16:10:15.235180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab08318e-4e7f-47ed-a24b-c4c91a715955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 16:10:22.778323: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb0a4d93cb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-23 16:10:22.778478: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-23 16:10:22.782701: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-23 16:10:22.813671: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-07-23 16:10:22.865698: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 5s 77ms/step - loss: 0.2181 - mae: 0.3792 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "0.22412924468517303\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d170749c-4162-472b-8b25-13d1ea01513c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3881236/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c32090fa-7af2-487a-a562-9fedf44520a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_max_single_attention_balanced Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d6aa022-c869-47c8-8804-817fc2b81a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "885c3097-9c4f-47d5-a561-5752fb4b86ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3881236/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c94e6e5-b279-4052-91d9-32203f9b05ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_max_single_attention_balanced_best Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf2f2bb-5e05-41a3-abfe-ba06087f6bc9",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c420b6d7-a8d5-4f9a-955e-5f23fb3da80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_max_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97a027d0-5bdd-4991-80a2-da4604093c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "427e1cf9-27e7-405a-a29d-7f1ac422556b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 2048) (5641,)\n",
      "(2092, 128, 2048) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7ca8b2d-02fc-43af-82fc-5c27ac6cfb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9bee3b98-49f1-4e58-aa66-990c3f7898ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 6s 118ms/step - loss: 0.2176 - mae: 0.3782 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 3s 64ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 3s 64ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "0.22412924468517303\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b00872a-3302-4d6f-a50e-1615b98fc012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3881236/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "42e03d2f-3b3f-42a2-ac1a-7414b478afaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_max_self_attention_balanced Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35ba92af-a219-413a-958f-d4da0a985c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12d5cfd0-bd51-4db6-ba41-6f5559b47512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3881236/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7cac8542-46a8-41dd-8ef3-dcfe592f85aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_max_self_attention_balanced_best Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad1ee20-2e16-40a5-a660-2ffc91ba13a1",
   "metadata": {},
   "source": [
    "### STAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c000f0c7-cf2d-4314-ae2f-a7209ecdcb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = compute_descriptor\n",
    "stat_name = \"STAT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5934ab-e5db-4d24-94c0-cec037fff2a9",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0098982b-15de-4272-805b-2a835d3481d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d41a70a3-95c2-494c-9a43-aeb65a806fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ceea9231-4ac9-4aa2-8c0d-39879e1e5d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4696aad1-d9e1-4b09-8744-e4a7626d8e59",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "953cb930-932b-4e18-a92a-dc84d8374a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_STAT_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8227f360-78d3-4bf6-a465-51e6de7d5bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3b2fd979-1222-45e5-bdc9-dc16924ab13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 3072) (5449,)\n",
      "(2284, 128, 3072) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d265e8d3-9475-448c-8d56-78fe8b7f7505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1573376   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1576962 (6.02 MB)\n",
      "Trainable params: 1576962 (6.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4d9181b8-8c1e-4ef4-aeac-76b7e54365fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 94ms/step - loss: 0.0865 - mae: 0.2254 - val_loss: 0.1025 - val_mae: 0.2601\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.0176 - mae: 0.1052 - val_loss: 0.1070 - val_mae: 0.2633\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0099 - mae: 0.0749 - val_loss: 0.1113 - val_mae: 0.2645\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0064 - mae: 0.0582 - val_loss: 0.1196 - val_mae: 0.2699\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0043 - mae: 0.0473 - val_loss: 0.1217 - val_mae: 0.2721\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.0030 - mae: 0.0385 - val_loss: 0.1276 - val_mae: 0.2794\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.0025 - mae: 0.0363 - val_loss: 0.1302 - val_mae: 0.2828\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 2s 41ms/step - loss: 0.0017 - mae: 0.0299 - val_loss: 0.1325 - val_mae: 0.2871\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.0015 - mae: 0.0276 - val_loss: 0.1371 - val_mae: 0.2895\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 9.5562e-04 - mae: 0.0210 - val_loss: 0.1398 - val_mae: 0.2907\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 8.8950e-04 - mae: 0.0213 - val_loss: 0.1391 - val_mae: 0.2936\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 7.7611e-04 - mae: 0.0200 - val_loss: 0.1427 - val_mae: 0.2949\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 6.4917e-04 - mae: 0.0184 - val_loss: 0.1434 - val_mae: 0.2971\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 5.2182e-04 - mae: 0.0160 - val_loss: 0.1459 - val_mae: 0.2998\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 4.5127e-04 - mae: 0.0149 - val_loss: 0.1460 - val_mae: 0.3002\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 3.7002e-04 - mae: 0.0133 - val_loss: 0.1490 - val_mae: 0.3007\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 3.5929e-04 - mae: 0.0134 - val_loss: 0.1502 - val_mae: 0.3041\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 5.5277e-04 - mae: 0.0176 - val_loss: 0.1498 - val_mae: 0.3030\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 6.0524e-04 - mae: 0.0189 - val_loss: 0.1510 - val_mae: 0.3063\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 5.2561e-04 - mae: 0.0173 - val_loss: 0.1497 - val_mae: 0.3031\n",
      "0.10252317041158676\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50be70eb-c0d0-4463-8281-298d2e4aeaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3881236/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e9452cb0-de96-49ba-89b6-b0de22674f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_STAT_single_attention_traditional Accuracy:  0.375 MSE:  0.1364128734837705 UAR:  0.3017543859649123 Recall:  N/A Precision:  N/A F1:  0.29008152173913043\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "30b199be-112b-4265-86a1-8ecec4ddc70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    modelAtn.set_weights(best_model_weights)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "03eae7c9-9821-47a0-8c3a-17f843972927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3881236/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6f01e069-434d-46a0-8213-8491ce75e839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_STAT_single_attention_traditional_best Accuracy:  0.4791666666666667 MSE:  0.08846163625492254 UAR:  0.34868421052631576 Recall:  N/A Precision:  N/A F1:  0.319724025974026\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583641a5-d2bc-46e9-a5de-e69375e87587",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "29060c19-b2e2-46a1-9aa6-949297694b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_STAT_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5221cf84-b162-43d7-bb74-3af0a668365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f601b8d0-6909-4f14-a44e-8942019714c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 3072) (5449,)\n",
      "(2284, 128, 3072) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bf8b083f-7f44-4986-b5f2-c1af73e1bdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 3072)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    3073      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18880514 (72.02 MB)\n",
      "Trainable params: 18880514 (72.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "57b228a2-82ba-42bf-8a7c-2aaa2f7f0d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 10s 208ms/step - loss: 0.2060 - mae: 0.3745 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 5s 124ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 5s 124ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 5s 128ms/step - loss: 0.2089 - mae: 0.3776 - val_loss: 0.2510 - val_mae: 0.3716\n",
      "0.25096195936203003\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b31cd053-343b-42b7-8f99-98c1ac5abb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3881236/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a2d88398-f03f-453f-84d7-2d2ca65bdbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_STAT_self_attention_traditional Accuracy:  0.3125 MSE:  0.22261249999999996 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "214e4dc2-f2c0-4224-bf4f-103d244ca333",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    modelAtn.set_weights(best_model_weights)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6a2d3cf6-d17e-40a0-95e5-100c7c208a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3881236/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cd848522-9320-434f-81fd-dcedbbe3f82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_STAT_self_attention_traditional_best Accuracy:  0.3125 MSE:  0.22261249999999996 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef580b8-5a94-4ea7-b0e3-a91a3aaa6f6d",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ab272e3-bd80-44a0-ba2d-5f46fc341d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3696a24e-6882-4733-86d2-aef5a874128c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0db22374-067d-4821-92d9-9633d5d57cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 5/147: 3.401360544217687%\n",
      "0.33 35/147: 23.80952380952381%\n",
      "0.66 79/147: 53.74149659863946%\n",
      "1.0 28/147: 19.047619047619047%\n",
      "val:\n",
      "0.0 4/48: 8.333333333333334%\n",
      "0.33 10/48: 20.833333333333332%\n",
      "0.66 19/48: 39.583333333333336%\n",
      "1.0 15/48: 31.25%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65fcfc76-ba44-48bc-bf90-afb01ac26795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147, 2048) (147,)\n",
      "(48, 2048) (48,)\n",
      "(195, 2048) (195,)\n",
      "[0.   0.33 0.66 1.  ] [ 9 45 98 43]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.767)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "338c38dc-930c-47f0-86c6-6448190c086f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.0 6/147: 4.081632653061225%\n",
      "0.33 34/147: 23.12925170068027%\n",
      "0.66 75/147: 51.02040816326531%\n",
      "1.0 32/147: 21.768707482993197%\n",
      "val:\n",
      "0.0 3/48: 6.25%\n",
      "0.33 11/48: 22.916666666666668%\n",
      "0.66 23/48: 47.916666666666664%\n",
      "1.0 11/48: 22.916666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542cd59e-9e94-448f-bbad-fc4a55257b05",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32d3fdc0-1dc8-434e-af28-377b224bbeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_STAT_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ea24dbf-21a4-42ed-aaa4-3cc917e5becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ee1b41a-203f-4c35-8575-5c67feb6e29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 3072) (5641,)\n",
      "(2092, 128, 3072) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "878d90cf-3629-42df-9d1d-51271bc42e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 16:25:00.604515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1573376   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1576962 (6.02 MB)\n",
      "Trainable params: 1576962 (6.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d397572-4014-446b-acb9-d3ef17b4bbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 16:25:11.002238: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0bdc043370 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-23 16:25:11.002261: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-23 16:25:11.007070: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-23 16:25:11.041331: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-07-23 16:25:11.093106: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 7s 116ms/step - loss: 0.0500 - mae: 0.1739 - val_loss: 0.0696 - val_mae: 0.2126\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 2s 36ms/step - loss: 0.0149 - mae: 0.0970 - val_loss: 0.0690 - val_mae: 0.2066\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 2s 36ms/step - loss: 0.0074 - mae: 0.0646 - val_loss: 0.0697 - val_mae: 0.2066\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 0.0047 - mae: 0.0493 - val_loss: 0.0718 - val_mae: 0.2080\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 2s 36ms/step - loss: 0.0037 - mae: 0.0436 - val_loss: 0.0804 - val_mae: 0.2211\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 0.0030 - mae: 0.0397 - val_loss: 0.0823 - val_mae: 0.2239\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 0.0025 - mae: 0.0366 - val_loss: 0.0831 - val_mae: 0.2199\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 0.0016 - mae: 0.0273 - val_loss: 0.0802 - val_mae: 0.2160\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 0.0014 - mae: 0.0259 - val_loss: 0.0827 - val_mae: 0.2199\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 2s 36ms/step - loss: 0.0010 - mae: 0.0222 - val_loss: 0.0872 - val_mae: 0.2296\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 0.0014 - mae: 0.0289 - val_loss: 0.0826 - val_mae: 0.2200\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 7.5491e-04 - mae: 0.0190 - val_loss: 0.0852 - val_mae: 0.2222\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 2s 37ms/step - loss: 5.8871e-04 - mae: 0.0167 - val_loss: 0.0870 - val_mae: 0.2238\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 5.0759e-04 - mae: 0.0157 - val_loss: 0.0873 - val_mae: 0.2252\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 2s 36ms/step - loss: 4.7194e-04 - mae: 0.0155 - val_loss: 0.0841 - val_mae: 0.2188\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 6.1348e-04 - mae: 0.0187 - val_loss: 0.0854 - val_mae: 0.2191\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 2s 36ms/step - loss: 5.5787e-04 - mae: 0.0179 - val_loss: 0.0868 - val_mae: 0.2257\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 5.4020e-04 - mae: 0.0175 - val_loss: 0.0874 - val_mae: 0.2233\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 3.2742e-04 - mae: 0.0133 - val_loss: 0.0878 - val_mae: 0.2250\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 3.3883e-04 - mae: 0.0135 - val_loss: 0.0903 - val_mae: 0.2278\n",
      "0.06898355484008789\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb213ada-65d6-42bf-810c-80712117457c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3894676/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa8a2e47-6920-4ef7-850a-6421b5f40f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_STAT_single_attention_balanced Accuracy:  0.4166666666666667 MSE:  0.07565788414361008 UAR:  0.3596837944664032 Recall:  N/A Precision:  N/A F1:  0.3188892948483741\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91b84415-b2f6-407a-9321-07a3a67c7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    modelAtn.set_weights(best_model_weights)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ac7e219-d6ed-4d69-a825-b56f3f56ed16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3894676/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b860994-6f14-46af-82c7-2d55eaed639e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_STAT_single_attention_balanced_best Accuracy:  0.5625 MSE:  0.056693993648760294 UAR:  0.4963768115942029 Recall:  N/A Precision:  N/A F1:  0.5041149068322982\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24c535a-3253-4c0c-9d26-364c844fa93b",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9fa7474a-80d9-41fb-88a0-cf90639837fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_4_STAT_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba56b4a0-fc44-4c49-a081-ff062f3a299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f978cc3d-e78d-4a53-9de3-e06742f47173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 128, 3072) (5641,)\n",
      "(2092, 128, 3072) (2092,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47dd22be-31cf-4a06-90b1-751f3aeafe61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 3072)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    3073      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18880514 (72.02 MB)\n",
      "Trainable params: 18880514 (72.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f45ab39d-71d4-48fb-8317-2995234836bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 10s 204ms/step - loss: 0.2163 - mae: 0.3772 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 5s 119ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 6s 125ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 5s 119ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 5s 120ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.2202 - mae: 0.3811 - val_loss: 0.2241 - val_mae: 0.3616\n",
      "0.22412924468517303\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a0edb119-b242-40a4-a3eb-d69a8ee9feda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3894676/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "096428ac-367c-478c-ba80-e44004af86ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_STAT_self_attention_balanced Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03d39d38-4956-4e07-97b2-f1e459210c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    modelAtn.set_weights(best_model_weights)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7ed358a-67b3-467a-8b74-009e995ecfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3894676/870029410.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67080a14-ca52-4034-92c6-862b0e57d8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_4_STAT_self_attention_balanced_best Accuracy:  0.22916666666666666 MSE:  0.2207645833333333 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.09322033898305083\n"
     ]
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7678d6-f719-40d4-bf2c-4d160fe3f1b7",
   "metadata": {},
   "source": [
    "# EngageWild dataset (2 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a1f2195-98b1-46c8-ae53-61a77c32ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_DIR = DATA_DIR + 'features_EngageWild/'\n",
    "WEIGHTS_DIR = DATA_DIR + 'weights_EngageWild/'\n",
    "TABLE_NAME = '02_EngageWild_2_classes.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3aae6a-4a9f-4bb8-b981-95fc936b9ffe",
   "metadata": {},
   "source": [
    "## enet_b0_8_best_afew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "358de87c-a64c-43e7-9364-71a8b1306d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_key = 'enet_b0_8_best_afew.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14a7dd6d-01f2-4c71-92d2-cebb84c3d1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['engaged', 'distracted']\n",
      "{'subject_1_Vid_1': 0, 'subject_1_Vid_2': 0, 'subject_1_Vid_3': 0, 'subject_1_Vid_4': 0, 'subject_1_Vid_5': 0, 'subject_31_Vid_6': 0, 'subject_2_Vid_6': 1, 'subject_3_Vid_6': 0, 'subject_3_Vid_1': 1, 'subject_3_Vid_2': 1, 'subject_3_Vid_3': 0, 'subject_3_Vid_4': 0, 'subject_3_Vid_5': 1, 'subject_3_Vid_7': 0, 'subject_4_Vid_6': 0, 'subject_5_Vid_6': 0, 'subject_6_Vid_6': 1, 'subject_7_Vid_1': 0, 'subject_7_Vid_2': 0, 'subject_7_Vid_3': 0, 'subject_7_Vid_4': 0, 'subject_7_Vid_5': 1, 'subject_8_Vid_6': 0, 'subject_9_Vid_6': 1, 'subject_10_Vid_6': 0, 'subject_11_Vid_6': 0, 'subject_12_Vid_6': 1, 'subject_13_Vid_6': 0, 'subject_14_Vid_6': 0, 'subject_15_Vid_6': 0, 'subject_16_Vid_6': 1, 'subject_17_Vid_6': 0, 'subject_18_Vid_6': 1, 'subject_19_Vid_6': 0, 'subject_20_Vid_6': 0, 'subject_20_Vid_1': 0, 'subject_20_Vid_2': 0, 'subject_20_Vid_3': 0, 'subject_20_Vid_4': 1, 'subject_20_Vid_5': 0, 'subject_20_Vid_5_1': 0, 'subject_20_Vid_5_2': 0, 'subject_20_Vid_7': 1, 'subject_21_Vid_5': 1, 'subject_22_Vid_5': 0, 'subject_23_Vid_5': 1, 'subject_24_Vid_5': 0, 'subject_25_Vid_5': 0, 'subject_26_Vid_1': 0, 'subject_26_Vid_2': 0, 'subject_26_Vid_3': 1, 'subject_26_Vid_4': 0, 'subject_26_Vid_5': 1, 'subject_26_Vid_5_1': 0, 'subject_26_Vid_5_2': 0, 'subject_26_Vid_7': 1, 'subject_27_Vid_1': 0, 'subject_29_Vid_6': 0, 'subject_29_Vid_7': 1, 'subject_30_Vid_1': 1, 'subject_30_Vid_2': 0, 'subject_30_Vid_3': 0, 'subject_30_Vid_4': 0, 'subject_30_Vid_5': 1, 'subject_32_Vid_6': 0, 'subject_32_Vid_1': 0, 'subject_32_Vid_2': 0, 'subject_32_Vid_3': 0, 'subject_32_Vid_4': 0, 'subject_32_Vid_5': 0, 'subject_32_Vid_7': 1, 'subject_33_Vid_1': 1, 'subject_33_Vid_2': 0, 'subject_33_Vid_3': 0, 'subject_33_Vid_4': 0, 'subject_33_Vid_7': 0, 'subject_34_Vid_7': 0, 'subject_34_Vid_1': 0, 'subject_34_Vid_5': 0, 'subject_35_Vid_6': 1, 'subject_35_Vid_7': 0, 'subject_36_Vid_7': 0, 'subject_37_Vid_7': 0, 'subject_38_Vid_7': 0, 'subject_39_Vid_6': 0, 'subject_39_Vid_7': 1, 'subject_40_Vid_6': 0, 'subject_40_Vid_7': 1, 'subject_41_Vid_6': 0, 'subject_41_Vid_2': 1, 'subject_41_Vid_3': 0, 'subject_41_Vid_4': 1, 'subject_41_Vid_5': 1, 'subject_41_Vid_5_1': 0, 'subject_41_Vid_5_2': 1, 'subject_41_Vid_7': 0, 'subject_42_Vid_7': 0, 'subject_43_Vid_7': 0, 'subject_44_Vid_7': 1, 'subject_45_Vid_7': 1, 'subject_46_Vid_6': 0, 'subject_47_Vid_6': 0, 'subject_48_Vid_6': 0, 'subject_48_Vid_7': 0, 'subject_49_Vid_7': 0, 'subject_50_Vid_6': 0, 'subject_50_Vid_1': 0, 'subject_50_Vid_2': 1, 'subject_50_Vid_3': 1, 'subject_50_Vid_4': 1, 'subject_50_Vid_5': 1, 'subject_51_Vid_7': 0, 'subject_52_Vid_7': 1, 'subject_53_Vid_2': 0, 'subject_53_Vid_3': 0, 'subject_53_Vid_4': 0, 'subject_53_Vid_5': 0, 'subject_54_Vid_6': 0, 'subject_55_Vid_6': 0, 'subject_56_Vid_6': 0, 'subject_56_Vid_1': 0, 'subject_56_Vid_2': 0, 'subject_56_Vid_3': 0, 'subject_56_Vid_4': 0, 'subject_56_Vid_5': 0, 'subject_57_Vid_7': 0, 'subject_58_Vid_6': 0, 'subject_58_Vid_7': 0, 'subject_59_Vid_7': 0, 'subject_60_Vid_6': 0, 'subject_60_Vid_7': 0, 'subject_62_Vid_6': 0, 'subject_62_Vid_1': 0, 'subject_62_Vid_2': 0, 'subject_62_Vid_3': 1, 'subject_62_Vid_4': 0, 'subject_62_Vid_5': 0, 'subject_62_Vid_7': 0, 'subject_63_Vid_7': 1, 'subject_64_Vid_6': 0, 'subject_64_Vid_7': 1, 'subject_65_Vid_6': 0, 'subject_66_Vid_6': 0, 'subject_66_Vid_7': 1, 'subject_67_Vid_6': 0, 'subject_67_Vid_1': 0, 'subject_67_Vid_2': 0, 'subject_67_Vid_4': 0, 'subject_67_Vid_5': 0, 'subject_68_Vid_6': 0, 'subject_68_Vid_7': 1, 'subject_69_Vid_6': 0, 'subject_69_Vid_7': 0, 'subject_70_Vid_6': 0, 'subject_70_Vid_1': 0, 'subject_70_Vid_2': 0, 'subject_70_Vid_3': 0, 'subject_70_Vid_4': 0, 'subject_70_Vid_5': 1, 'subject_72_Vid_6': 0, 'subject_73_Vid_6': 0, 'subject_73_Vid_7': 0, 'subject_74_Vid_7': 1, 'subject_75_Vid_7': 0, 'subject_76_Vid_6': 0, 'subject_76_Vid_7': 0, 'subject_77_Vid_6': 0, 'subject_77_Vid_1': 1, 'subject_77_Vid_2': 1, 'subject_77_Vid_3': 0, 'subject_77_Vid_4': 0, 'subject_77_Vid_5': 1, 'subject_78_Vid_6': 0, 'subject_79_Vid_7': 0, 'subject_80_Vid_6': 0, 'subject_80_Vid_1': 0, 'subject_80_Vid_2': 0, 'subject_80_Vid_3': 0, 'subject_80_Vid_4': 0, 'subject_80_Vid_5': 0, 'subject_81_Vid_7': 1, 'subject_82_Vid_7': 0, 'subject_83_Vid_7': 0, 'subject_84_Vid_6': 1, 'subject_84_Vid_1': 1, 'subject_84_Vid_2': 1, 'subject_84_Vid_3': 1, 'subject_84_Vid_4': 1, 'subject_84_Vid_5': 1, 'subject_85_Vid_7': 0, 'subject_86_Vid_7': 0, 'subject_77_Vid_7': 1, 'subject_34_Vid_2': 0, 'subject_34_Vid_3': 0, 'subject_34_Vid_4': 0, 'subject_87_Vid_3': 0}\n"
     ]
    }
   ],
   "source": [
    "ENGAGE_WILD_DATASET, BIN_CLASSIFICATION, N_CLASSES, DATASET_NAME, BASE_DATASET_DIR, ext = define_dataset(True, True)\n",
    "video2label, labels_list = get_video2label()\n",
    "print(labels_list)\n",
    "print(video2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14234aeb-1964-4608-acb7-62f1a822423c",
   "metadata": {},
   "source": [
    "### Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "634d7c96-03ca-4db1-9ccb-463ea129446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.std\n",
    "stat_name = \"std\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f403e3a1-ced7-4862-9534-4e5428722b87",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6f1ead8-4f92-4907-864e-cc9e6bd69df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6f391ff-749a-4de5-82d9-39e69bf1ad0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cfd17a5-aad8-48b5-881a-bcd61417ed0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4570191f-f073-4147-9474-209e16d95d63",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62680171-26d6-4e01-b3aa-8a8fc6d587c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "606c9512-2be0-4b78-867c-41ae1429dd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "094bd2ad-3de8-427b-b28b-bf52ab0a319a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2560) (5449,)\n",
      "(2284, 128, 2560) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36a585a5-3380-496f-9573-62889e5cbb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 07:06:57.092910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10858bd5-73a3-4dde-8ad9-84cb17b20664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 07:07:06.933872: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f07b81ff2b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-30 07:07:06.934044: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-30 07:07:06.938196: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-30 07:07:06.993674: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-07-30 07:07:07.046402: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 8s 109ms/step - loss: 0.3125 - acc: 0.8807 - auc: 0.9209 - binary_accuracy: 0.8807 - recall: 0.6660 - precision: 0.8886 - val_loss: 0.7877 - val_acc: 0.6432 - val_auc: 0.6720 - val_binary_accuracy: 0.6432 - val_recall: 0.5172 - val_precision: 0.4822\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1500 - acc: 0.9453 - auc: 0.9848 - binary_accuracy: 0.9453 - recall: 0.8760 - precision: 0.9285 - val_loss: 0.8964 - val_acc: 0.7229 - val_auc: 0.7030 - val_binary_accuracy: 0.7229 - val_recall: 0.5019 - val_precision: 0.6195\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0845 - acc: 0.9754 - auc: 0.9969 - binary_accuracy: 0.9754 - recall: 0.9409 - precision: 0.9721 - val_loss: 0.9080 - val_acc: 0.7053 - val_auc: 0.7138 - val_binary_accuracy: 0.7053 - val_recall: 0.5873 - val_precision: 0.5691\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0552 - acc: 0.9840 - auc: 0.9991 - binary_accuracy: 0.9840 - recall: 0.9621 - precision: 0.9817 - val_loss: 1.0142 - val_acc: 0.6918 - val_auc: 0.7139 - val_binary_accuracy: 0.6918 - val_recall: 0.4318 - val_precision: 0.5678\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0411 - acc: 0.9910 - auc: 0.9995 - binary_accuracy: 0.9910 - recall: 0.9807 - precision: 0.9877 - val_loss: 1.2630 - val_acc: 0.7382 - val_auc: 0.7000 - val_binary_accuracy: 0.7382 - val_recall: 0.3975 - val_precision: 0.7140\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.0347 - acc: 0.9910 - auc: 0.9996 - binary_accuracy: 0.9910 - recall: 0.9762 - precision: 0.9922 - val_loss: 1.1636 - val_acc: 0.7303 - val_auc: 0.7189 - val_binary_accuracy: 0.7303 - val_recall: 0.5631 - val_precision: 0.6182\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0182 - acc: 0.9976 - auc: 1.0000 - binary_accuracy: 0.9976 - recall: 0.9936 - precision: 0.9981 - val_loss: 1.2184 - val_acc: 0.7561 - val_auc: 0.7210 - val_binary_accuracy: 0.7561 - val_recall: 0.4726 - val_precision: 0.7218\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0134 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall: 0.9974 - precision: 1.0000 - val_loss: 1.2526 - val_acc: 0.7137 - val_auc: 0.7241 - val_binary_accuracy: 0.7137 - val_recall: 0.5745 - val_precision: 0.5850\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0095 - acc: 0.9991 - auc: 1.0000 - binary_accuracy: 0.9991 - recall: 0.9994 - precision: 0.9974 - val_loss: 1.3699 - val_acc: 0.7172 - val_auc: 0.6871 - val_binary_accuracy: 0.7172 - val_recall: 0.5299 - val_precision: 0.6003\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0060 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.4117 - val_acc: 0.7049 - val_auc: 0.6901 - val_binary_accuracy: 0.7049 - val_recall: 0.5376 - val_precision: 0.5757\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0049 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.4990 - val_acc: 0.6835 - val_auc: 0.6861 - val_binary_accuracy: 0.6835 - val_recall: 0.6127 - val_precision: 0.5344\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0040 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.5024 - val_acc: 0.7110 - val_auc: 0.6978 - val_binary_accuracy: 0.7110 - val_recall: 0.5274 - val_precision: 0.5889\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0031 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.5274 - val_acc: 0.7005 - val_auc: 0.6948 - val_binary_accuracy: 0.7005 - val_recall: 0.5427 - val_precision: 0.5672\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0030 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.5654 - val_acc: 0.7093 - val_auc: 0.6819 - val_binary_accuracy: 0.7093 - val_recall: 0.5962 - val_precision: 0.5742\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0024 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.5955 - val_acc: 0.6975 - val_auc: 0.6883 - val_binary_accuracy: 0.6975 - val_recall: 0.5618 - val_precision: 0.5596\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0019 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.6445 - val_acc: 0.7045 - val_auc: 0.6852 - val_binary_accuracy: 0.7045 - val_recall: 0.5860 - val_precision: 0.5679\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0016 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.6489 - val_acc: 0.7097 - val_auc: 0.6959 - val_binary_accuracy: 0.7097 - val_recall: 0.5325 - val_precision: 0.5854\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0015 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.6998 - val_acc: 0.6961 - val_auc: 0.6910 - val_binary_accuracy: 0.6961 - val_recall: 0.5490 - val_precision: 0.5590\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0012 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.7066 - val_acc: 0.7014 - val_auc: 0.6922 - val_binary_accuracy: 0.7014 - val_recall: 0.5682 - val_precision: 0.5653\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0011 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.7247 - val_acc: 0.6953 - val_auc: 0.6928 - val_binary_accuracy: 0.6953 - val_recall: 0.5427 - val_precision: 0.5583\n",
      "0.7876731157302856\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "189b6a6e-a2a2-4681-9871-04f93cb85ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4014914/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8793ed73-c69e-47ab-b2fe-28ed77ba2d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional Accuracy:  0.5416666666666666 MSE:  0.4583333333333333 UAR:  0.5504201680672269 Recall:  0.5714285714285714 Precision:  0.3333333333333333 F1:  0.4210526315789474\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.6092436974789917 Recall:  0.5714285714285714 Precision:  0.4 F1:  0.47058823529411764\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6239495798319328 Recall:  0.5714285714285714 Precision:  0.42105263157894735 F1:  0.48484848484848486\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6533613445378151 Recall:  0.5714285714285714 Precision:  0.47058823529411764 F1:  0.5161290322580646\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6176470588235294 Recall:  0.5 Precision:  0.4375 F1:  0.4666666666666667\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6323529411764706 Recall:  0.5 Precision:  0.4666666666666667 F1:  0.4827586206896552\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6617647058823529 Recall:  0.5 Precision:  0.5384615384615384 F1:  0.5185185185185186\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional Accuracy:  0.75 MSE:  0.25 UAR:  0.6764705882352942 Recall:  0.5 Precision:  0.5833333333333334 F1:  0.5384615384615384\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional Accuracy:  0.6875 MSE:  0.3125 UAR:  0.569327731092437 Recall:  0.2857142857142857 Precision:  0.4444444444444444 F1:  0.34782608695652173\n",
      "0.8 0.6764705882352942\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "edbf95d2-964a-45ac-b252-09ca08746246",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35308f28-c321-4299-96f9-33abd1627365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4014914/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0108e0d-6171-4f1f-b336-a51760d45f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.5208333333333334 MSE:  0.4791666666666667 UAR:  0.5777310924369747 Recall:  0.7142857142857143 Precision:  0.3448275862068966 F1:  0.46511627906976755\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5735294117647058 Recall:  0.5 Precision:  0.3684210526315789 F1:  0.4242424242424242\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.625 MSE:  0.375 UAR:  0.5882352941176471 Recall:  0.5 Precision:  0.3888888888888889 F1:  0.43750000000000006\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6029411764705883 Recall:  0.5 Precision:  0.4117647058823529 F1:  0.45161290322580644\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5819327731092437 Recall:  0.42857142857142855 Precision:  0.4 F1:  0.4137931034482759\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.634453781512605 Recall:  0.35714285714285715 Precision:  0.625 F1:  0.45454545454545453\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.5714285714285714 Recall:  0.14285714285714285 Precision:  1.0 F1:  0.25\n",
      "0.7 0.634453781512605\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1d590b-6168-4fb4-a3bf-a3414ea78f0d",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14bdda6b-0039-4425-bd27-6b56ed4b8e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ae86870-775e-49fd-81be-1a81f377679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9741e956-1fd5-4753-a103-38496ac6e26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2560) (5449,)\n",
      "(2284, 128, 2560) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43e7e8e8-cfbe-4cc2-a005-f31a43dc0b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9b771713-bbb2-4407-a8fd-cd7cac3b5e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 140ms/step - loss: 0.5918 - acc: 0.7847 - auc: 0.7871 - binary_accuracy: 0.7847 - recall_1: 0.5607 - precision_1: 0.6410 - val_loss: 0.8495 - val_acc: 0.6475 - val_auc: 0.6537 - val_binary_accuracy: 0.6475 - val_recall_1: 0.5758 - val_precision_1: 0.4892\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.2312 - acc: 0.9095 - auc: 0.9594 - binary_accuracy: 0.9095 - recall_1: 0.7868 - precision_1: 0.8838 - val_loss: 0.7742 - val_acc: 0.7408 - val_auc: 0.7044 - val_binary_accuracy: 0.7408 - val_recall_1: 0.5057 - val_precision_1: 0.6606\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 103ms/step - loss: 0.1426 - acc: 0.9549 - auc: 0.9865 - binary_accuracy: 0.9549 - recall_1: 0.8940 - precision_1: 0.9450 - val_loss: 1.0746 - val_acc: 0.6756 - val_auc: 0.7150 - val_binary_accuracy: 0.6756 - val_recall_1: 0.2140 - val_precision_1: 0.5753\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.1210 - acc: 0.9593 - auc: 0.9899 - binary_accuracy: 0.9593 - recall_1: 0.9075 - precision_1: 0.9477 - val_loss: 1.0406 - val_acc: 0.7172 - val_auc: 0.7272 - val_binary_accuracy: 0.7172 - val_recall_1: 0.4242 - val_precision_1: 0.6319\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0896 - acc: 0.9701 - auc: 0.9946 - binary_accuracy: 0.9701 - recall_1: 0.9345 - precision_1: 0.9598 - val_loss: 1.2989 - val_acc: 0.6856 - val_auc: 0.7472 - val_binary_accuracy: 0.6856 - val_recall_1: 0.2522 - val_precision_1: 0.6018\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 103ms/step - loss: 0.0617 - acc: 0.9824 - auc: 0.9973 - binary_accuracy: 0.9824 - recall_1: 0.9615 - precision_1: 0.9765 - val_loss: 1.2513 - val_acc: 0.7071 - val_auc: 0.7324 - val_binary_accuracy: 0.7071 - val_recall_1: 0.3643 - val_precision_1: 0.6272\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0498 - acc: 0.9861 - auc: 0.9988 - binary_accuracy: 0.9861 - recall_1: 0.9666 - precision_1: 0.9843 - val_loss: 1.4187 - val_acc: 0.6926 - val_auc: 0.7563 - val_binary_accuracy: 0.6926 - val_recall_1: 0.2573 - val_precision_1: 0.6293\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0340 - acc: 0.9921 - auc: 0.9995 - binary_accuracy: 0.9921 - recall_1: 0.9814 - precision_1: 0.9909 - val_loss: 1.2756 - val_acc: 0.7215 - val_auc: 0.7755 - val_binary_accuracy: 0.7215 - val_recall_1: 0.3796 - val_precision_1: 0.6667\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0192 - acc: 0.9978 - auc: 0.9999 - binary_accuracy: 0.9978 - recall_1: 0.9929 - precision_1: 0.9994 - val_loss: 1.5351 - val_acc: 0.7128 - val_auc: 0.7476 - val_binary_accuracy: 0.7128 - val_recall_1: 0.3236 - val_precision_1: 0.6702\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 103ms/step - loss: 0.0151 - acc: 0.9983 - auc: 1.0000 - binary_accuracy: 0.9983 - recall_1: 0.9968 - precision_1: 0.9974 - val_loss: 1.3556 - val_acc: 0.7456 - val_auc: 0.7595 - val_binary_accuracy: 0.7456 - val_recall_1: 0.4701 - val_precision_1: 0.6910\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0134 - acc: 0.9980 - auc: 1.0000 - binary_accuracy: 0.9980 - recall_1: 0.9949 - precision_1: 0.9981 - val_loss: 1.5372 - val_acc: 0.7316 - val_auc: 0.7560 - val_binary_accuracy: 0.7316 - val_recall_1: 0.4102 - val_precision_1: 0.6822\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0130 - acc: 0.9972 - auc: 0.9999 - binary_accuracy: 0.9972 - recall_1: 0.9949 - precision_1: 0.9955 - val_loss: 2.0147 - val_acc: 0.6940 - val_auc: 0.7257 - val_binary_accuracy: 0.6940 - val_recall_1: 0.2306 - val_precision_1: 0.6558\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0216 - acc: 0.9947 - auc: 0.9997 - binary_accuracy: 0.9947 - recall_1: 0.9878 - precision_1: 0.9935 - val_loss: 1.6828 - val_acc: 0.7482 - val_auc: 0.7529 - val_binary_accuracy: 0.7482 - val_recall_1: 0.4841 - val_precision_1: 0.6909\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0299 - acc: 0.9906 - auc: 0.9989 - binary_accuracy: 0.9906 - recall_1: 0.9827 - precision_1: 0.9846 - val_loss: 1.6251 - val_acc: 0.7754 - val_auc: 0.7863 - val_binary_accuracy: 0.7754 - val_recall_1: 0.6127 - val_precision_1: 0.6971\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0219 - acc: 0.9932 - auc: 0.9996 - binary_accuracy: 0.9932 - recall_1: 0.9865 - precision_1: 0.9897 - val_loss: 1.8373 - val_acc: 0.7382 - val_auc: 0.7654 - val_binary_accuracy: 0.7382 - val_recall_1: 0.4522 - val_precision_1: 0.6788\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0119 - acc: 0.9971 - auc: 0.9999 - binary_accuracy: 0.9971 - recall_1: 0.9942 - precision_1: 0.9955 - val_loss: 2.3806 - val_acc: 0.6870 - val_auc: 0.7152 - val_binary_accuracy: 0.6870 - val_recall_1: 0.2854 - val_precision_1: 0.5926\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0043 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_1: 0.9987 - precision_1: 0.9987 - val_loss: 1.9901 - val_acc: 0.7426 - val_auc: 0.7454 - val_binary_accuracy: 0.7426 - val_recall_1: 0.4586 - val_precision_1: 0.6883\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0039 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_1: 0.9994 - precision_1: 0.9981 - val_loss: 2.1846 - val_acc: 0.6961 - val_auc: 0.7334 - val_binary_accuracy: 0.6961 - val_recall_1: 0.3070 - val_precision_1: 0.6164\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0074 - acc: 0.9987 - auc: 0.9999 - binary_accuracy: 0.9987 - recall_1: 0.9968 - precision_1: 0.9987 - val_loss: 1.9295 - val_acc: 0.7518 - val_auc: 0.7615 - val_binary_accuracy: 0.7518 - val_recall_1: 0.4943 - val_precision_1: 0.6953\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0034 - acc: 0.9991 - auc: 1.0000 - binary_accuracy: 0.9991 - recall_1: 0.9987 - precision_1: 0.9981 - val_loss: 1.9903 - val_acc: 0.7491 - val_auc: 0.7626 - val_binary_accuracy: 0.7491 - val_recall_1: 0.4777 - val_precision_1: 0.6970\n",
      "0.7741798758506775\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e3b30fa-46c2-40ab-9ed9-738c5ecf10a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4014914/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3051e935-a4c3-4288-a630-a1aa8e4e8ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional Accuracy:  0.8125 MSE:  0.1875 UAR:  0.7626050420168067 Recall:  0.6428571428571429 Precision:  0.6923076923076923 F1:  0.6666666666666666\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional Accuracy:  0.8333333333333334 MSE:  0.16666666666666666 UAR:  0.7773109243697479 Recall:  0.6428571428571429 Precision:  0.75 F1:  0.6923076923076924\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional Accuracy:  0.8333333333333334 MSE:  0.16666666666666666 UAR:  0.7773109243697479 Recall:  0.6428571428571429 Precision:  0.75 F1:  0.6923076923076924\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional Accuracy:  0.8333333333333334 MSE:  0.16666666666666666 UAR:  0.7773109243697479 Recall:  0.6428571428571429 Precision:  0.75 F1:  0.6923076923076924\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional Accuracy:  0.8333333333333334 MSE:  0.16666666666666666 UAR:  0.7773109243697479 Recall:  0.6428571428571429 Precision:  0.75 F1:  0.6923076923076924\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional Accuracy:  0.8333333333333334 MSE:  0.16666666666666666 UAR:  0.7773109243697479 Recall:  0.6428571428571429 Precision:  0.75 F1:  0.6923076923076924\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional Accuracy:  0.8125 MSE:  0.1875 UAR:  0.7415966386554622 Recall:  0.5714285714285714 Precision:  0.7272727272727273 F1:  0.64\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional Accuracy:  0.7916666666666666 MSE:  0.20833333333333334 UAR:  0.7058823529411764 Recall:  0.5 Precision:  0.7 F1:  0.5833333333333334\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional Accuracy:  0.8125 MSE:  0.1875 UAR:  0.7205882352941176 Recall:  0.5 Precision:  0.7777777777777778 F1:  0.6086956521739131\n",
      "0.2 0.7773109243697479\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4aeb0ea3-a59f-4d1e-b9a4-b6975802aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60a4809e-8e51-4421-87b4-ca6a56f00037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4014914/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aa0beb9d-9295-4374-a538-8b974dbd0b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.5625 MSE:  0.4375 UAR:  0.6281512605042017 Recall:  0.7857142857142857 Precision:  0.3793103448275862 F1:  0.5116279069767441\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.703781512605042 Recall:  0.6428571428571429 Precision:  0.5294117647058824 F1:  0.5806451612903226\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.7331932773109244 Recall:  0.6428571428571429 Precision:  0.6 F1:  0.6206896551724138\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.8125 MSE:  0.1875 UAR:  0.7626050420168067 Recall:  0.6428571428571429 Precision:  0.6923076923076923 F1:  0.6666666666666666\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.8125 MSE:  0.1875 UAR:  0.7415966386554622 Recall:  0.5714285714285714 Precision:  0.7272727272727273 F1:  0.64\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.8333333333333334 MSE:  0.16666666666666666 UAR:  0.7563025210084033 Recall:  0.5714285714285714 Precision:  0.8 F1:  0.6666666666666666\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.8125 MSE:  0.1875 UAR:  0.6995798319327731 Recall:  0.42857142857142855 Precision:  0.8571428571428571 F1:  0.5714285714285714\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.8125 MSE:  0.1875 UAR:  0.6995798319327731 Recall:  0.42857142857142855 Precision:  0.8571428571428571 F1:  0.5714285714285714\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6281512605042017 Recall:  0.2857142857142857 Precision:  0.8 F1:  0.4210526315789473\n",
      "0.4 0.7626050420168067\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9677bbad-49c6-41a1-83b4-8715a05d64ac",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87a2de58-8279-49c4-822e-6735ad797aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4812a76a-f10c-4eca-a228-ff0fe3075cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f47049d-d760-421a-8788-2b6008124667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "27b3263a-4726-4159-9d54-d9670564b9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147,) (147,)\n",
      "(48,) (48,)\n",
      "(195,) (195,)\n",
      "[0 1] [141  54]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.759)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d2e5ff98-304e-45ee-a75f-a1739ede3fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3936e31-b87e-41b8-a0a5-5a5f8d567d99",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f35f0641-3b18-42a3-beb2-d3e85ce7e175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9e8b6c73-80c8-4f6c-86a1-d13c0292e160",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a58e0b8-2538-42a7-ae5a-d110e8b652cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 2560) (5631,)\n",
      "(2102, 128, 2560) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d7cd10aa-aa1b-4fd3-9d82-f09b0d260da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ff3f367f-1ceb-4d24-a077-a5384442d1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44/44 [==============================] - 5s 83ms/step - loss: 0.3716 - acc: 0.8430 - auc: 0.8928 - binary_accuracy: 0.8430 - recall_2: 0.6052 - precision_2: 0.8311 - val_loss: 0.7749 - val_acc: 0.6698 - val_auc: 0.6856 - val_binary_accuracy: 0.6698 - val_recall_2: 0.4567 - val_precision_2: 0.4538\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.1450 - acc: 0.9563 - auc: 0.9877 - binary_accuracy: 0.9563 - recall_2: 0.8910 - precision_2: 0.9620 - val_loss: 0.9226 - val_acc: 0.6613 - val_auc: 0.6917 - val_binary_accuracy: 0.6613 - val_recall_2: 0.5039 - val_precision_2: 0.4463\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0865 - acc: 0.9746 - auc: 0.9960 - binary_accuracy: 0.9746 - recall_2: 0.9426 - precision_2: 0.9728 - val_loss: 1.1081 - val_acc: 0.6613 - val_auc: 0.7015 - val_binary_accuracy: 0.6613 - val_recall_2: 0.4945 - val_precision_2: 0.4454\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0515 - acc: 0.9886 - auc: 0.9992 - binary_accuracy: 0.9886 - recall_2: 0.9713 - precision_2: 0.9910 - val_loss: 1.2214 - val_acc: 0.6893 - val_auc: 0.7125 - val_binary_accuracy: 0.6893 - val_recall_2: 0.4646 - val_precision_2: 0.4852\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0354 - acc: 0.9918 - auc: 0.9997 - binary_accuracy: 0.9918 - recall_2: 0.9813 - precision_2: 0.9917 - val_loss: 1.3244 - val_acc: 0.7055 - val_auc: 0.7030 - val_binary_accuracy: 0.7055 - val_recall_2: 0.5071 - val_precision_2: 0.5127\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0203 - acc: 0.9984 - auc: 1.0000 - binary_accuracy: 0.9984 - recall_2: 0.9982 - precision_2: 0.9965 - val_loss: 1.5204 - val_acc: 0.6889 - val_auc: 0.6889 - val_binary_accuracy: 0.6889 - val_recall_2: 0.4677 - val_precision_2: 0.4845\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0131 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_2: 0.9994 - precision_2: 0.9982 - val_loss: 1.5954 - val_acc: 0.7008 - val_auc: 0.6935 - val_binary_accuracy: 0.7008 - val_recall_2: 0.5228 - val_precision_2: 0.5046\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0094 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_2: 0.9994 - precision_2: 0.9994 - val_loss: 1.7367 - val_acc: 0.6927 - val_auc: 0.6891 - val_binary_accuracy: 0.6927 - val_recall_2: 0.4976 - val_precision_2: 0.4914\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0078 - acc: 0.9995 - auc: 1.0000 - binary_accuracy: 0.9995 - recall_2: 0.9994 - precision_2: 0.9988 - val_loss: 1.7580 - val_acc: 0.6984 - val_auc: 0.6882 - val_binary_accuracy: 0.6984 - val_recall_2: 0.5165 - val_precision_2: 0.5008\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0058 - acc: 0.9995 - auc: 1.0000 - binary_accuracy: 0.9995 - recall_2: 0.9994 - precision_2: 0.9988 - val_loss: 1.8344 - val_acc: 0.7022 - val_auc: 0.6958 - val_binary_accuracy: 0.7022 - val_recall_2: 0.5228 - val_precision_2: 0.5069\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.0048 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_2: 1.0000 - precision_2: 0.9994 - val_loss: 1.8852 - val_acc: 0.7022 - val_auc: 0.6939 - val_binary_accuracy: 0.7022 - val_recall_2: 0.5386 - val_precision_2: 0.5067\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.0035 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_2: 1.0000 - precision_2: 0.9994 - val_loss: 1.9795 - val_acc: 0.7103 - val_auc: 0.6860 - val_binary_accuracy: 0.7103 - val_recall_2: 0.5717 - val_precision_2: 0.5186\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0028 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.0042 - val_acc: 0.7041 - val_auc: 0.6794 - val_binary_accuracy: 0.7041 - val_recall_2: 0.5780 - val_precision_2: 0.5090\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0025 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.0925 - val_acc: 0.6998 - val_auc: 0.6791 - val_binary_accuracy: 0.6998 - val_recall_2: 0.5433 - val_precision_2: 0.5029\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0020 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.1306 - val_acc: 0.7055 - val_auc: 0.6821 - val_binary_accuracy: 0.7055 - val_recall_2: 0.5732 - val_precision_2: 0.5112\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0017 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.1228 - val_acc: 0.7022 - val_auc: 0.6788 - val_binary_accuracy: 0.7022 - val_recall_2: 0.5780 - val_precision_2: 0.5062\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.0015 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_2: 0.9994 - precision_2: 1.0000 - val_loss: 2.1580 - val_acc: 0.7122 - val_auc: 0.6865 - val_binary_accuracy: 0.7122 - val_recall_2: 0.6000 - val_precision_2: 0.5205\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0018 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_2: 1.0000 - precision_2: 0.9994 - val_loss: 2.2350 - val_acc: 0.6912 - val_auc: 0.6821 - val_binary_accuracy: 0.6912 - val_recall_2: 0.5024 - val_precision_2: 0.4893\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.0013 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.2721 - val_acc: 0.7088 - val_auc: 0.6810 - val_binary_accuracy: 0.7088 - val_recall_2: 0.5953 - val_precision_2: 0.5157\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.0013 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.2590 - val_acc: 0.7079 - val_auc: 0.6849 - val_binary_accuracy: 0.7079 - val_recall_2: 0.5622 - val_precision_2: 0.5152\n",
      "0.7748990654945374\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "155d28a2-e514-4504-a408-ad39c115abba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4014914/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9aa8aaa9-d2cb-4bd4-8d54-86784bf19586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6323529411764706 Recall:  0.5 Precision:  0.4666666666666667 F1:  0.4827586206896552\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6323529411764706 Recall:  0.5 Precision:  0.4666666666666667 F1:  0.4827586206896552\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6323529411764706 Recall:  0.5 Precision:  0.4666666666666667 F1:  0.4827586206896552\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6323529411764706 Recall:  0.5 Precision:  0.4666666666666667 F1:  0.4827586206896552\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.611344537815126 Recall:  0.42857142857142855 Precision:  0.46153846153846156 F1:  0.4444444444444445\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6260504201680672 Recall:  0.42857142857142855 Precision:  0.5 F1:  0.4615384615384615\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.569327731092437 Recall:  0.2857142857142857 Precision:  0.4444444444444444 F1:  0.34782608695652173\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.569327731092437 Recall:  0.2857142857142857 Precision:  0.4444444444444444 F1:  0.34782608695652173\n",
      "0.5 0.6470588235294117\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0c640ace-a303-4134-bc75-d62d821e070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c66ce3e8-dd9d-469c-b119-9b418973aa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4014914/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aad2aa4b-5b54-44a7-89cb-018b02a90ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.625 MSE:  0.375 UAR:  0.6932773109243697 Recall:  0.8571428571428571 Precision:  0.42857142857142855 F1:  0.5714285714285714\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.7016806722689075 Recall:  0.7857142857142857 Precision:  0.4583333333333333 F1:  0.5789473684210527\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6449579831932774 Recall:  0.6428571428571429 Precision:  0.42857142857142855 F1:  0.5142857142857143\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6407563025210083 Recall:  0.42857142857142855 Precision:  0.5454545454545454 F1:  0.4799999999999999\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6554621848739496 Recall:  0.42857142857142855 Precision:  0.6 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6491596638655462 Recall:  0.35714285714285715 Precision:  0.7142857142857143 F1:  0.4761904761904762\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6491596638655462 Recall:  0.35714285714285715 Precision:  0.7142857142857143 F1:  0.4761904761904762\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6491596638655462 Recall:  0.35714285714285715 Precision:  0.7142857142857143 F1:  0.4761904761904762\n",
      "0.2 0.7016806722689075\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bfcf66-775e-476e-9978-bde714e3c475",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d60a18f6-3b50-4b78-80a6-29ce5eca775f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0eae7c25-d0d7-4f2d-885c-400235e34fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b5e76e32-3321-4ad9-8dc8-b42e0ddefb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 2560) (5631,)\n",
      "(2102, 128, 2560) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "837444f0-d640-40bc-832a-f0180c2bfca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a5adfe0d-85c9-4ba6-a1ff-ce24ccaac64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44/44 [==============================] - 8s 168ms/step - loss: 0.5993 - acc: 0.7878 - auc: 0.8036 - binary_accuracy: 0.7878 - recall_3: 0.6098 - precision_3: 0.6631 - val_loss: 0.6822 - val_acc: 0.6817 - val_auc: 0.6883 - val_binary_accuracy: 0.6817 - val_recall_3: 0.2850 - val_precision_3: 0.4571\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.2049 - acc: 0.9215 - auc: 0.9697 - binary_accuracy: 0.9215 - recall_3: 0.8278 - precision_3: 0.9052 - val_loss: 0.8615 - val_acc: 0.7122 - val_auc: 0.6816 - val_binary_accuracy: 0.7122 - val_recall_3: 0.3953 - val_precision_3: 0.5318\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 4s 90ms/step - loss: 0.1210 - acc: 0.9549 - auc: 0.9905 - binary_accuracy: 0.9549 - recall_3: 0.9086 - precision_3: 0.9406 - val_loss: 0.8721 - val_acc: 0.7393 - val_auc: 0.7289 - val_binary_accuracy: 0.7393 - val_recall_3: 0.5764 - val_precision_3: 0.5674\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.0802 - acc: 0.9753 - auc: 0.9957 - binary_accuracy: 0.9753 - recall_3: 0.9484 - precision_3: 0.9695 - val_loss: 1.2375 - val_acc: 0.7222 - val_auc: 0.6932 - val_binary_accuracy: 0.7222 - val_recall_3: 0.3858 - val_precision_3: 0.5581\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0678 - acc: 0.9776 - auc: 0.9966 - binary_accuracy: 0.9776 - recall_3: 0.9531 - precision_3: 0.9725 - val_loss: 1.2947 - val_acc: 0.7184 - val_auc: 0.7018 - val_binary_accuracy: 0.7184 - val_recall_3: 0.3717 - val_precision_3: 0.5501\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0560 - acc: 0.9790 - auc: 0.9976 - binary_accuracy: 0.9790 - recall_3: 0.9602 - precision_3: 0.9704 - val_loss: 1.2551 - val_acc: 0.7193 - val_auc: 0.7293 - val_binary_accuracy: 0.7193 - val_recall_3: 0.5748 - val_precision_3: 0.5328\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0372 - acc: 0.9886 - auc: 0.9986 - binary_accuracy: 0.9886 - recall_3: 0.9801 - precision_3: 0.9824 - val_loss: 1.5555 - val_acc: 0.6984 - val_auc: 0.6967 - val_binary_accuracy: 0.6984 - val_recall_3: 0.5071 - val_precision_3: 0.5008\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0222 - acc: 0.9948 - auc: 0.9998 - binary_accuracy: 0.9948 - recall_3: 0.9912 - precision_3: 0.9918 - val_loss: 1.4482 - val_acc: 0.7203 - val_auc: 0.7204 - val_binary_accuracy: 0.7203 - val_recall_3: 0.4898 - val_precision_3: 0.5409\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0242 - acc: 0.9929 - auc: 0.9996 - binary_accuracy: 0.9929 - recall_3: 0.9848 - precision_3: 0.9917 - val_loss: 1.7579 - val_acc: 0.7141 - val_auc: 0.7120 - val_binary_accuracy: 0.7141 - val_recall_3: 0.4000 - val_precision_3: 0.5359\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.1447 - acc: 0.9554 - auc: 0.9849 - binary_accuracy: 0.9554 - recall_3: 0.9227 - precision_3: 0.9298 - val_loss: 1.7190 - val_acc: 0.6974 - val_auc: 0.6963 - val_binary_accuracy: 0.6974 - val_recall_3: 0.5827 - val_precision_3: 0.4993\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0443 - acc: 0.9858 - auc: 0.9972 - binary_accuracy: 0.9858 - recall_3: 0.9695 - precision_3: 0.9834 - val_loss: 1.7971 - val_acc: 0.6741 - val_auc: 0.6820 - val_binary_accuracy: 0.6741 - val_recall_3: 0.5276 - val_precision_3: 0.4653\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0219 - acc: 0.9943 - auc: 0.9997 - binary_accuracy: 0.9943 - recall_3: 0.9877 - precision_3: 0.9935 - val_loss: 1.7530 - val_acc: 0.6903 - val_auc: 0.6999 - val_binary_accuracy: 0.6903 - val_recall_3: 0.4866 - val_precision_3: 0.4874\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0231 - acc: 0.9933 - auc: 0.9989 - binary_accuracy: 0.9933 - recall_3: 0.9877 - precision_3: 0.9900 - val_loss: 1.8787 - val_acc: 0.6779 - val_auc: 0.6843 - val_binary_accuracy: 0.6779 - val_recall_3: 0.4551 - val_precision_3: 0.4661\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.0084 - acc: 0.9984 - auc: 1.0000 - binary_accuracy: 0.9984 - recall_3: 0.9965 - precision_3: 0.9982 - val_loss: 2.0328 - val_acc: 0.6798 - val_auc: 0.6776 - val_binary_accuracy: 0.6798 - val_recall_3: 0.4205 - val_precision_3: 0.4668\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.0065 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_3: 0.9988 - precision_3: 0.9988 - val_loss: 2.1406 - val_acc: 0.6846 - val_auc: 0.6713 - val_binary_accuracy: 0.6846 - val_recall_3: 0.3921 - val_precision_3: 0.4734\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0059 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_3: 0.9988 - precision_3: 0.9988 - val_loss: 2.1636 - val_acc: 0.6551 - val_auc: 0.6861 - val_binary_accuracy: 0.6551 - val_recall_3: 0.4756 - val_precision_3: 0.4352\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0039 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_3: 0.9994 - precision_3: 1.0000 - val_loss: 2.2946 - val_acc: 0.6665 - val_auc: 0.6766 - val_binary_accuracy: 0.6665 - val_recall_3: 0.4110 - val_precision_3: 0.4439\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0029 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_3: 0.9988 - precision_3: 1.0000 - val_loss: 2.4013 - val_acc: 0.6608 - val_auc: 0.6743 - val_binary_accuracy: 0.6608 - val_recall_3: 0.4205 - val_precision_3: 0.4363\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.0026 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 2.3555 - val_acc: 0.6603 - val_auc: 0.6869 - val_binary_accuracy: 0.6603 - val_recall_3: 0.4850 - val_precision_3: 0.4432\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0024 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_3: 1.0000 - precision_3: 0.9994 - val_loss: 2.4045 - val_acc: 0.6803 - val_auc: 0.6819 - val_binary_accuracy: 0.6803 - val_recall_3: 0.4268 - val_precision_3: 0.4680\n",
      "0.6822482347488403\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c51c4798-a69c-4796-b773-767a09c310c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4014914/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f1c3e890-06ea-4c66-baee-e877e63b6ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6176470588235294 Recall:  0.5 Precision:  0.4375 F1:  0.4666666666666667\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6176470588235294 Recall:  0.5 Precision:  0.4375 F1:  0.4666666666666667\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6323529411764706 Recall:  0.5 Precision:  0.4666666666666667 F1:  0.4827586206896552\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6260504201680672 Recall:  0.42857142857142855 Precision:  0.5 F1:  0.4615384615384615\n",
      "0.4 0.6470588235294117\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "21745e3f-dd52-448c-8950-e70659921e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8702c6cd-4445-4790-ab18-20b43b9f4969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4014914/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "558c17e6-9d6b-49da-bc50-c742ef1880c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.6785714285714286 Recall:  0.8571428571428571 Precision:  0.41379310344827586 F1:  0.5581395348837208\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.7163865546218487 Recall:  0.7857142857142857 Precision:  0.4782608695652174 F1:  0.5945945945945946\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6533613445378151 Recall:  0.5714285714285714 Precision:  0.47058823529411764 F1:  0.5161290322580646\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6050420168067226 Recall:  0.35714285714285715 Precision:  0.5 F1:  0.41666666666666663\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6134453781512605 Recall:  0.2857142857142857 Precision:  0.6666666666666666 F1:  0.4\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5567226890756303 Recall:  0.14285714285714285 Precision:  0.6666666666666666 F1:  0.23529411764705882\n",
      "0.2 0.7163865546218487\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671e642a-d61e-4756-aef2-bb03532ec868",
   "metadata": {},
   "source": [
    "### Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0096a65-d6b4-4981-ae21-a8933b44042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.max\n",
    "stat_name = \"max\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf4f808-12f4-4f00-9d6f-78aa0bf3e9d1",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a6b55a7-8034-4b99-ac86-19d1a7bad672",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1523c7f4-4b43-42df-9ed7-617aa551b9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b837bcf5-04d1-469b-8aa4-e1409a4ad5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1632637-12e5-43c0-b0ba-bb59462eadc6",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0bbe2ee2-44e1-46fb-8326-02bc02a77ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c48f4b0b-3c28-41c6-a3ec-224b5c387e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fdd3c9bd-d28e-49e4-aaed-f6323aef5b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2560) (5449,)\n",
      "(2284, 128, 2560) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02cce768-fe09-4225-a155-73080b17697b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 07:17:43.974052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af592b3d-5a83-4f1f-9f88-fdc9fcc9c85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 07:17:53.529710: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbadc14df40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-30 07:17:53.530074: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-30 07:17:53.534425: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-30 07:17:53.581539: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-07-30 07:17:53.646642: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 8s 110ms/step - loss: 0.3723 - acc: 0.8541 - auc: 0.8832 - binary_accuracy: 0.8541 - recall: 0.6513 - precision: 0.8009 - val_loss: 0.7008 - val_acc: 0.7452 - val_auc: 0.7242 - val_binary_accuracy: 0.7452 - val_recall: 0.5045 - val_precision: 0.6723\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.1272 - acc: 0.9638 - auc: 0.9940 - binary_accuracy: 0.9638 - recall: 0.9056 - precision: 0.9658 - val_loss: 0.7590 - val_acc: 0.7303 - val_auc: 0.7296 - val_binary_accuracy: 0.7303 - val_recall: 0.5682 - val_precision: 0.6169\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0557 - acc: 0.9890 - auc: 0.9997 - binary_accuracy: 0.9890 - recall: 0.9769 - precision: 0.9845 - val_loss: 0.8781 - val_acc: 0.7570 - val_auc: 0.7387 - val_binary_accuracy: 0.7570 - val_recall: 0.5682 - val_precision: 0.6737\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0225 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.9448 - val_acc: 0.7806 - val_auc: 0.7408 - val_binary_accuracy: 0.7806 - val_recall: 0.5682 - val_precision: 0.7336\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0126 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.0343 - val_acc: 0.7456 - val_auc: 0.7385 - val_binary_accuracy: 0.7456 - val_recall: 0.5682 - val_precision: 0.6483\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0070 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.1110 - val_acc: 0.7706 - val_auc: 0.7402 - val_binary_accuracy: 0.7706 - val_recall: 0.5682 - val_precision: 0.7068\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0046 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.1252 - val_acc: 0.7693 - val_auc: 0.7446 - val_binary_accuracy: 0.7693 - val_recall: 0.5682 - val_precision: 0.7035\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0034 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.1717 - val_acc: 0.7688 - val_auc: 0.7435 - val_binary_accuracy: 0.7688 - val_recall: 0.5682 - val_precision: 0.7024\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0025 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.2163 - val_acc: 0.7767 - val_auc: 0.7462 - val_binary_accuracy: 0.7767 - val_recall: 0.5682 - val_precision: 0.7229\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0020 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.2249 - val_acc: 0.7719 - val_auc: 0.7487 - val_binary_accuracy: 0.7719 - val_recall: 0.5682 - val_precision: 0.7102\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0016 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.2799 - val_acc: 0.7701 - val_auc: 0.7453 - val_binary_accuracy: 0.7701 - val_recall: 0.5682 - val_precision: 0.7057\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0013 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.3074 - val_acc: 0.7728 - val_auc: 0.7439 - val_binary_accuracy: 0.7728 - val_recall: 0.5682 - val_precision: 0.7125\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0011 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.3234 - val_acc: 0.7728 - val_auc: 0.7451 - val_binary_accuracy: 0.7728 - val_recall: 0.5682 - val_precision: 0.7125\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 9.7321e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.3430 - val_acc: 0.7531 - val_auc: 0.7482 - val_binary_accuracy: 0.7531 - val_recall: 0.5682 - val_precision: 0.6647\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 8.1330e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.3613 - val_acc: 0.7728 - val_auc: 0.7438 - val_binary_accuracy: 0.7728 - val_recall: 0.5682 - val_precision: 0.7125\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 6.7977e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.3931 - val_acc: 0.7728 - val_auc: 0.7419 - val_binary_accuracy: 0.7728 - val_recall: 0.5682 - val_precision: 0.7125\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 6.0516e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.4118 - val_acc: 0.7728 - val_auc: 0.7434 - val_binary_accuracy: 0.7728 - val_recall: 0.5682 - val_precision: 0.7125\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 5.3242e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.4241 - val_acc: 0.7728 - val_auc: 0.7449 - val_binary_accuracy: 0.7728 - val_recall: 0.5682 - val_precision: 0.7125\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 4.7800e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.4422 - val_acc: 0.7728 - val_auc: 0.7422 - val_binary_accuracy: 0.7728 - val_recall: 0.5682 - val_precision: 0.7125\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 4.2573e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.4589 - val_acc: 0.7728 - val_auc: 0.7406 - val_binary_accuracy: 0.7728 - val_recall: 0.5682 - val_precision: 0.7125\n",
      "0.7008012533187866\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a29d7a7-7184-4c7d-9c52-70dda758d8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4027200/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5557626c-f4fa-4e25-9b64-787cca642065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6386554621848739 Recall:  0.5714285714285714 Precision:  0.4444444444444444 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6911764705882353 Recall:  0.5 Precision:  0.6363636363636364 F1:  0.56\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6911764705882353 Recall:  0.5 Precision:  0.6363636363636364 F1:  0.56\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6911764705882353 Recall:  0.5 Precision:  0.6363636363636364 F1:  0.56\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional Accuracy:  0.7916666666666666 MSE:  0.20833333333333334 UAR:  0.7058823529411764 Recall:  0.5 Precision:  0.7 F1:  0.5833333333333334\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional Accuracy:  0.8125 MSE:  0.1875 UAR:  0.7205882352941176 Recall:  0.5 Precision:  0.7777777777777778 F1:  0.6086956521739131\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional Accuracy:  0.8125 MSE:  0.1875 UAR:  0.7205882352941176 Recall:  0.5 Precision:  0.7777777777777778 F1:  0.6086956521739131\n",
      "0.8 0.7205882352941176\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0cecedbb-dc74-44a2-ab1b-949f9b7624d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ddf37e5-0310-4739-b9f1-5ff148917b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4027200/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "69ff8ba2-7355-4a3a-8d31-7aaa30169ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.5208333333333334 MSE:  0.4791666666666667 UAR:  0.5357142857142857 Recall:  0.5714285714285714 Precision:  0.32 F1:  0.41025641025641024\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.5588235294117647 Recall:  0.5 Precision:  0.35 F1:  0.4117647058823529\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5735294117647058 Recall:  0.5 Precision:  0.3684210526315789 F1:  0.4242424242424242\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6617647058823529 Recall:  0.5 Precision:  0.5384615384615384 F1:  0.5185185185185186\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6701680672268907 Recall:  0.42857142857142855 Precision:  0.6666666666666666 F1:  0.5217391304347826\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.634453781512605 Recall:  0.35714285714285715 Precision:  0.625 F1:  0.45454545454545453\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5777310924369747 Recall:  0.21428571428571427 Precision:  0.6 F1:  0.3157894736842105\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5063025210084033 Recall:  0.07142857142857142 Precision:  0.3333333333333333 F1:  0.11764705882352941\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5357142857142857 Recall:  0.07142857142857142 Precision:  1.0 F1:  0.13333333333333333\n",
      "0.5 0.6701680672268907\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23e301d-31bb-424f-a82d-cdf366b49db7",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8cf03d56-38ce-46ce-a9c0-18b647c08141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5be30832-66ea-431f-be2e-dcccd79cf925",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99b3cb7b-a498-4d5a-ad24-bda81f00799e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2560) (5449,)\n",
      "(2284, 128, 2560) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "803e838f-d4f8-47be-8975-5d487c708c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "26ca876d-600f-496e-b993-2a4f2df0ab4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 8s 155ms/step - loss: 1.5761 - acc: 0.7234 - auc: 0.7081 - binary_accuracy: 0.7234 - recall_1: 0.5414 - precision_1: 0.5153 - val_loss: 1.2094 - val_acc: 0.6493 - val_auc: 0.6822 - val_binary_accuracy: 0.6493 - val_recall_1: 0.1108 - val_precision_1: 0.4579\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.2213 - acc: 0.9189 - auc: 0.9613 - binary_accuracy: 0.9189 - recall_1: 0.8182 - precision_1: 0.8890 - val_loss: 0.8240 - val_acc: 0.6528 - val_auc: 0.6992 - val_binary_accuracy: 0.6528 - val_recall_1: 0.3261 - val_precision_1: 0.4923\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.1190 - acc: 0.9660 - auc: 0.9940 - binary_accuracy: 0.9660 - recall_1: 0.9249 - precision_1: 0.9549 - val_loss: 0.9960 - val_acc: 0.6909 - val_auc: 0.6846 - val_binary_accuracy: 0.6909 - val_recall_1: 0.2586 - val_precision_1: 0.6208\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0755 - acc: 0.9846 - auc: 0.9981 - binary_accuracy: 0.9846 - recall_1: 0.9685 - precision_1: 0.9773 - val_loss: 0.8987 - val_acc: 0.6870 - val_auc: 0.7175 - val_binary_accuracy: 0.6870 - val_recall_1: 0.3439 - val_precision_1: 0.5745\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0409 - acc: 0.9954 - auc: 0.9998 - binary_accuracy: 0.9954 - recall_1: 0.9923 - precision_1: 0.9917 - val_loss: 0.9313 - val_acc: 0.7137 - val_auc: 0.7298 - val_binary_accuracy: 0.7137 - val_recall_1: 0.4446 - val_precision_1: 0.6155\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0261 - acc: 0.9980 - auc: 0.9999 - binary_accuracy: 0.9980 - recall_1: 0.9961 - precision_1: 0.9968 - val_loss: 1.0685 - val_acc: 0.7058 - val_auc: 0.7267 - val_binary_accuracy: 0.7058 - val_recall_1: 0.3439 - val_precision_1: 0.6323\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0194 - acc: 0.9985 - auc: 1.0000 - binary_accuracy: 0.9985 - recall_1: 0.9961 - precision_1: 0.9987 - val_loss: 1.1140 - val_acc: 0.7018 - val_auc: 0.7129 - val_binary_accuracy: 0.7018 - val_recall_1: 0.4115 - val_precision_1: 0.5959\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0123 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_1: 0.9981 - precision_1: 0.9994 - val_loss: 1.1572 - val_acc: 0.6948 - val_auc: 0.7195 - val_binary_accuracy: 0.6948 - val_recall_1: 0.4318 - val_precision_1: 0.5746\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 104ms/step - loss: 0.0076 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_1: 0.9987 - precision_1: 1.0000 - val_loss: 1.1992 - val_acc: 0.7084 - val_auc: 0.7242 - val_binary_accuracy: 0.7084 - val_recall_1: 0.4497 - val_precision_1: 0.6014\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0061 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_1: 0.9987 - precision_1: 1.0000 - val_loss: 1.2325 - val_acc: 0.6996 - val_auc: 0.7232 - val_binary_accuracy: 0.6996 - val_recall_1: 0.4420 - val_precision_1: 0.5832\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 103ms/step - loss: 0.0042 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 1.3115 - val_acc: 0.7032 - val_auc: 0.7215 - val_binary_accuracy: 0.7032 - val_recall_1: 0.4229 - val_precision_1: 0.5961\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0034 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 1.3569 - val_acc: 0.7049 - val_auc: 0.7209 - val_binary_accuracy: 0.7049 - val_recall_1: 0.4318 - val_precision_1: 0.5979\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 103ms/step - loss: 0.0026 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 1.3692 - val_acc: 0.7062 - val_auc: 0.7233 - val_binary_accuracy: 0.7062 - val_recall_1: 0.4357 - val_precision_1: 0.6000\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0021 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 1.4375 - val_acc: 0.7023 - val_auc: 0.7202 - val_binary_accuracy: 0.7023 - val_recall_1: 0.4153 - val_precision_1: 0.5960\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0018 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 1.4434 - val_acc: 0.7049 - val_auc: 0.7220 - val_binary_accuracy: 0.7049 - val_recall_1: 0.4318 - val_precision_1: 0.5979\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0015 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 1.4823 - val_acc: 0.7045 - val_auc: 0.7185 - val_binary_accuracy: 0.7045 - val_recall_1: 0.4306 - val_precision_1: 0.5972\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0013 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 1.4932 - val_acc: 0.7045 - val_auc: 0.7214 - val_binary_accuracy: 0.7045 - val_recall_1: 0.4357 - val_precision_1: 0.5958\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0012 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 1.5517 - val_acc: 0.7014 - val_auc: 0.7160 - val_binary_accuracy: 0.7014 - val_recall_1: 0.4102 - val_precision_1: 0.5952\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0010 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 1.5930 - val_acc: 0.7001 - val_auc: 0.7128 - val_binary_accuracy: 0.7001 - val_recall_1: 0.4038 - val_precision_1: 0.5936\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 9.3099e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 1.5534 - val_acc: 0.7005 - val_auc: 0.7204 - val_binary_accuracy: 0.7005 - val_recall_1: 0.4382 - val_precision_1: 0.5860\n",
      "0.8239837288856506\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aad77efb-dfcb-4109-aa07-5b97aa1ac8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4027200/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c5d22eef-4a43-4b61-9300-8311181ea948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6176470588235294 Recall:  0.5 Precision:  0.4375 F1:  0.4666666666666667\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6260504201680672 Recall:  0.42857142857142855 Precision:  0.5 F1:  0.4615384615384615\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional Accuracy:  0.75 MSE:  0.25 UAR:  0.6554621848739496 Recall:  0.42857142857142855 Precision:  0.6 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional Accuracy:  0.75 MSE:  0.25 UAR:  0.6554621848739496 Recall:  0.42857142857142855 Precision:  0.6 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional Accuracy:  0.75 MSE:  0.25 UAR:  0.6554621848739496 Recall:  0.42857142857142855 Precision:  0.6 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6197478991596639 Recall:  0.35714285714285715 Precision:  0.5555555555555556 F1:  0.43478260869565216\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional Accuracy:  0.75 MSE:  0.25 UAR:  0.634453781512605 Recall:  0.35714285714285715 Precision:  0.625 F1:  0.45454545454545453\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional Accuracy:  0.75 MSE:  0.25 UAR:  0.6134453781512605 Recall:  0.2857142857142857 Precision:  0.6666666666666666 F1:  0.4\n",
      "0.4 0.6554621848739496\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd747654-22f2-4d0e-8996-552ece373e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4590c3f8-27d1-486b-875b-b08909c9d5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4027200/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "390b8f4a-001d-49ec-bb24-2e32248a8006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.6785714285714286 Recall:  0.8571428571428571 Precision:  0.41379310344827586 F1:  0.5581395348837208\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6533613445378151 Recall:  0.5714285714285714 Precision:  0.47058823529411764 F1:  0.5161290322580646\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6260504201680672 Recall:  0.42857142857142855 Precision:  0.5 F1:  0.4615384615384615\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5903361344537815 Recall:  0.35714285714285715 Precision:  0.45454545454545453 F1:  0.4\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6050420168067226 Recall:  0.35714285714285715 Precision:  0.5 F1:  0.41666666666666663\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.634453781512605 Recall:  0.35714285714285715 Precision:  0.625 F1:  0.45454545454545453\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6134453781512605 Recall:  0.2857142857142857 Precision:  0.6666666666666666 F1:  0.4\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5567226890756303 Recall:  0.14285714285714285 Precision:  0.6666666666666666 F1:  0.23529411764705882\n",
      "0.1 0.6785714285714286\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac71908-4122-4cfd-9f00-6973bf65b4c7",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c2bff731-caa2-4f09-83f0-58c7bb5bc532",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "184e4b63-20e2-4ddd-a4c2-5b067abb33c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e745a3ad-464a-42e2-8ef1-727d25ca9466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "07c9bf86-b1ce-4216-a8c5-e202f8211f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147,) (147,)\n",
      "(48,) (48,)\n",
      "(195,) (195,)\n",
      "[0 1] [141  54]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.759)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7260c74e-6fd0-445d-ab06-6b439c7de819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2fd455-0612-41b9-835a-5d920fca36b8",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "659683bb-207c-4be1-8636-a2b414843e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c237a993-9ba6-44ad-ab4d-1d529316dc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "35d55d43-8b99-4042-b2d2-324cc0f8ea21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 2560) (5631,)\n",
      "(2102, 128, 2560) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4b65d76c-49a9-404f-8d35-23d03eb4d1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ceff91a5-ed9e-4bd5-9ae6-ebf95fc55b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44/44 [==============================] - 4s 74ms/step - loss: 0.4721 - acc: 0.7949 - auc: 0.8205 - binary_accuracy: 0.7949 - recall_2: 0.5489 - precision_2: 0.7088 - val_loss: 0.6953 - val_acc: 0.5951 - val_auc: 0.7154 - val_binary_accuracy: 0.5951 - val_recall_2: 0.3984 - val_precision_2: 0.3504\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.1780 - acc: 0.9469 - auc: 0.9814 - binary_accuracy: 0.9469 - recall_2: 0.8541 - precision_2: 0.9668 - val_loss: 0.9529 - val_acc: 0.6066 - val_auc: 0.7030 - val_binary_accuracy: 0.6066 - val_recall_2: 0.4787 - val_precision_2: 0.3800\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0862 - acc: 0.9798 - auc: 0.9976 - binary_accuracy: 0.9798 - recall_2: 0.9432 - precision_2: 0.9896 - val_loss: 1.1213 - val_acc: 0.6560 - val_auc: 0.6707 - val_binary_accuracy: 0.6560 - val_recall_2: 0.3984 - val_precision_2: 0.4259\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0427 - acc: 0.9941 - auc: 0.9999 - binary_accuracy: 0.9941 - recall_2: 0.9818 - precision_2: 0.9988 - val_loss: 1.2820 - val_acc: 0.6342 - val_auc: 0.6859 - val_binary_accuracy: 0.6342 - val_recall_2: 0.4724 - val_precision_2: 0.4087\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.0262 - acc: 0.9989 - auc: 1.0000 - binary_accuracy: 0.9989 - recall_2: 0.9971 - precision_2: 0.9994 - val_loss: 1.4945 - val_acc: 0.6108 - val_auc: 0.6704 - val_binary_accuracy: 0.6108 - val_recall_2: 0.4220 - val_precision_2: 0.3727\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0134 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_2: 0.9994 - precision_2: 1.0000 - val_loss: 1.6076 - val_acc: 0.6637 - val_auc: 0.6619 - val_binary_accuracy: 0.6637 - val_recall_2: 0.4016 - val_precision_2: 0.4381\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0088 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_2: 0.9994 - precision_2: 1.0000 - val_loss: 1.6819 - val_acc: 0.6522 - val_auc: 0.6610 - val_binary_accuracy: 0.6522 - val_recall_2: 0.4110 - val_precision_2: 0.4223\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0071 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.7749 - val_acc: 0.6494 - val_auc: 0.6597 - val_binary_accuracy: 0.6494 - val_recall_2: 0.4126 - val_precision_2: 0.4185\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0050 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.8627 - val_acc: 0.6670 - val_auc: 0.6566 - val_binary_accuracy: 0.6670 - val_recall_2: 0.4110 - val_precision_2: 0.4446\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0035 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.9108 - val_acc: 0.6522 - val_auc: 0.6542 - val_binary_accuracy: 0.6522 - val_recall_2: 0.4126 - val_precision_2: 0.4226\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.0028 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.9757 - val_acc: 0.6361 - val_auc: 0.6536 - val_binary_accuracy: 0.6361 - val_recall_2: 0.4142 - val_precision_2: 0.4009\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0023 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.0384 - val_acc: 0.6399 - val_auc: 0.6528 - val_binary_accuracy: 0.6399 - val_recall_2: 0.4094 - val_precision_2: 0.4050\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0019 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.0915 - val_acc: 0.6660 - val_auc: 0.6571 - val_binary_accuracy: 0.6660 - val_recall_2: 0.4063 - val_precision_2: 0.4425\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0017 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.1303 - val_acc: 0.6342 - val_auc: 0.6530 - val_binary_accuracy: 0.6342 - val_recall_2: 0.4205 - val_precision_2: 0.3997\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.0014 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.1545 - val_acc: 0.6598 - val_auc: 0.6558 - val_binary_accuracy: 0.6598 - val_recall_2: 0.4110 - val_precision_2: 0.4336\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0012 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.2072 - val_acc: 0.6546 - val_auc: 0.6569 - val_binary_accuracy: 0.6546 - val_recall_2: 0.4079 - val_precision_2: 0.4253\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0011 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.2473 - val_acc: 0.6422 - val_auc: 0.6573 - val_binary_accuracy: 0.6422 - val_recall_2: 0.4126 - val_precision_2: 0.4087\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 9.4335e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.2756 - val_acc: 0.6351 - val_auc: 0.6559 - val_binary_accuracy: 0.6351 - val_recall_2: 0.4220 - val_precision_2: 0.4012\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 8.4522e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.2955 - val_acc: 0.6432 - val_auc: 0.6585 - val_binary_accuracy: 0.6432 - val_recall_2: 0.4157 - val_precision_2: 0.4106\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 7.5379e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.3402 - val_acc: 0.6484 - val_auc: 0.6588 - val_binary_accuracy: 0.6484 - val_recall_2: 0.4110 - val_precision_2: 0.4169\n",
      "0.6952969431877136\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6b53229a-77fa-49da-aacf-006749c53731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4027200/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3bf17979-e3dd-4b72-a609-c879a76614be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced Accuracy:  0.625 MSE:  0.375 UAR:  0.5672268907563025 Recall:  0.42857142857142855 Precision:  0.375 F1:  0.39999999999999997\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced Accuracy:  0.625 MSE:  0.375 UAR:  0.5672268907563025 Recall:  0.42857142857142855 Precision:  0.375 F1:  0.39999999999999997\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5756302521008403 Recall:  0.35714285714285715 Precision:  0.4166666666666667 F1:  0.3846153846153846\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5756302521008403 Recall:  0.35714285714285715 Precision:  0.4166666666666667 F1:  0.3846153846153846\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6050420168067226 Recall:  0.35714285714285715 Precision:  0.5 F1:  0.41666666666666663\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6050420168067226 Recall:  0.35714285714285715 Precision:  0.5 F1:  0.41666666666666663\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6050420168067226 Recall:  0.35714285714285715 Precision:  0.5 F1:  0.41666666666666663\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6050420168067226 Recall:  0.35714285714285715 Precision:  0.5 F1:  0.41666666666666663\n",
      "0.6 0.6050420168067226\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "81d80c25-7b07-4ec2-a261-c8b45dff88d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "07a64468-3efb-43cf-9883-898f1fc478fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4027200/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cd31902f-a6c8-4118-b404-3ad2db54d7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.5416666666666666 MSE:  0.4583333333333333 UAR:  0.634453781512605 Recall:  0.8571428571428571 Precision:  0.375 F1:  0.5217391304347825\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.625 MSE:  0.375 UAR:  0.6302521008403361 Recall:  0.6428571428571429 Precision:  0.4090909090909091 F1:  0.5000000000000001\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6596638655462186 Recall:  0.6428571428571429 Precision:  0.45 F1:  0.5294117647058824\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.625 MSE:  0.375 UAR:  0.546218487394958 Recall:  0.35714285714285715 Precision:  0.35714285714285715 F1:  0.35714285714285715\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5609243697478992 Recall:  0.35714285714285715 Precision:  0.38461538461538464 F1:  0.3703703703703704\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5756302521008403 Recall:  0.35714285714285715 Precision:  0.4166666666666667 F1:  0.3846153846153846\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6197478991596639 Recall:  0.35714285714285715 Precision:  0.5555555555555556 F1:  0.43478260869565216\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.592436974789916 Recall:  0.21428571428571427 Precision:  0.75 F1:  0.3333333333333333\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5210084033613446 Recall:  0.07142857142857142 Precision:  0.5 F1:  0.125\n",
      "0.3 0.6596638655462186\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf835a9c-5077-47e2-96f2-2f7b47039cb2",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eddd5c5a-e35f-4613-bee8-89e1274bd15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1bc89c55-a68c-4087-bcf6-56be8834160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c9a4781a-3f06-4fe6-abd8-177e6b2a0082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 2560) (5631,)\n",
      "(2102, 128, 2560) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "db4af0fa-9381-4a59-86d1-117186dc3afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3977aa56-d2e8-4d5f-9c97-b51fe37a606d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44/44 [==============================] - 8s 168ms/step - loss: 1.2116 - acc: 0.7714 - auc: 0.7812 - binary_accuracy: 0.7714 - recall_3: 0.6333 - precision_3: 0.6206 - val_loss: 1.0200 - val_acc: 0.6042 - val_auc: 0.6351 - val_binary_accuracy: 0.6042 - val_recall_3: 0.5496 - val_precision_3: 0.3899\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 0.1467 - acc: 0.9515 - auc: 0.9866 - binary_accuracy: 0.9515 - recall_3: 0.8928 - precision_3: 0.9442 - val_loss: 0.9340 - val_acc: 0.6275 - val_auc: 0.6549 - val_binary_accuracy: 0.6275 - val_recall_3: 0.4173 - val_precision_3: 0.3909\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0680 - acc: 0.9876 - auc: 0.9990 - binary_accuracy: 0.9876 - recall_3: 0.9690 - precision_3: 0.9898 - val_loss: 1.1035 - val_acc: 0.6213 - val_auc: 0.6565 - val_binary_accuracy: 0.6213 - val_recall_3: 0.3732 - val_precision_3: 0.3732\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 5s 103ms/step - loss: 0.0379 - acc: 0.9940 - auc: 0.9997 - binary_accuracy: 0.9940 - recall_3: 0.9859 - precision_3: 0.9941 - val_loss: 1.2975 - val_acc: 0.6446 - val_auc: 0.6308 - val_binary_accuracy: 0.6446 - val_recall_3: 0.4205 - val_precision_3: 0.4133\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.0198 - acc: 0.9986 - auc: 1.0000 - binary_accuracy: 0.9986 - recall_3: 0.9965 - precision_3: 0.9988 - val_loss: 1.4142 - val_acc: 0.6403 - val_auc: 0.6274 - val_binary_accuracy: 0.6403 - val_recall_3: 0.4220 - val_precision_3: 0.4079\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.0120 - acc: 0.9995 - auc: 1.0000 - binary_accuracy: 0.9995 - recall_3: 0.9982 - precision_3: 1.0000 - val_loss: 1.5439 - val_acc: 0.6522 - val_auc: 0.5914 - val_binary_accuracy: 0.6522 - val_recall_3: 0.3780 - val_precision_3: 0.4167\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.0081 - acc: 0.9995 - auc: 1.0000 - binary_accuracy: 0.9995 - recall_3: 0.9982 - precision_3: 1.0000 - val_loss: 1.6381 - val_acc: 0.6537 - val_auc: 0.5967 - val_binary_accuracy: 0.6537 - val_recall_3: 0.4173 - val_precision_3: 0.4254\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0051 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_3: 0.9994 - precision_3: 1.0000 - val_loss: 1.7271 - val_acc: 0.6575 - val_auc: 0.5856 - val_binary_accuracy: 0.6575 - val_recall_3: 0.4110 - val_precision_3: 0.4300\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0043 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_3: 0.9994 - precision_3: 1.0000 - val_loss: 1.8166 - val_acc: 0.6551 - val_auc: 0.5757 - val_binary_accuracy: 0.6551 - val_recall_3: 0.3433 - val_precision_3: 0.4144\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.0037 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 1.9184 - val_acc: 0.6503 - val_auc: 0.5715 - val_binary_accuracy: 0.6503 - val_recall_3: 0.3764 - val_precision_3: 0.4135\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 5s 104ms/step - loss: 0.0023 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 1.9899 - val_acc: 0.6384 - val_auc: 0.5884 - val_binary_accuracy: 0.6384 - val_recall_3: 0.4331 - val_precision_3: 0.4074\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.0019 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 2.0304 - val_acc: 0.6394 - val_auc: 0.5853 - val_binary_accuracy: 0.6394 - val_recall_3: 0.4315 - val_precision_3: 0.4083\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0014 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 2.0697 - val_acc: 0.6499 - val_auc: 0.5787 - val_binary_accuracy: 0.6499 - val_recall_3: 0.4236 - val_precision_3: 0.4210\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.0012 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 2.1040 - val_acc: 0.6394 - val_auc: 0.5916 - val_binary_accuracy: 0.6394 - val_recall_3: 0.4346 - val_precision_3: 0.4089\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.0011 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 2.1532 - val_acc: 0.6413 - val_auc: 0.5851 - val_binary_accuracy: 0.6413 - val_recall_3: 0.4315 - val_precision_3: 0.4108\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 8.9386e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 2.1874 - val_acc: 0.6518 - val_auc: 0.5779 - val_binary_accuracy: 0.6518 - val_recall_3: 0.4220 - val_precision_3: 0.4234\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 7.6760e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 2.2041 - val_acc: 0.6565 - val_auc: 0.5767 - val_binary_accuracy: 0.6565 - val_recall_3: 0.3937 - val_precision_3: 0.4259\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 6.7617e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 2.2375 - val_acc: 0.6570 - val_auc: 0.5760 - val_binary_accuracy: 0.6570 - val_recall_3: 0.4157 - val_precision_3: 0.4300\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 6.1662e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 2.2689 - val_acc: 0.6594 - val_auc: 0.5786 - val_binary_accuracy: 0.6594 - val_recall_3: 0.4047 - val_precision_3: 0.4319\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 5.4005e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 2.2958 - val_acc: 0.6594 - val_auc: 0.5789 - val_binary_accuracy: 0.6594 - val_recall_3: 0.4157 - val_precision_3: 0.4335\n",
      "0.9339626431465149\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6883f189-8f67-4809-99de-32609971bcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4027200/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "88b6068f-c732-4187-b2ec-24e7dd16cb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced Accuracy:  0.625 MSE:  0.375 UAR:  0.5882352941176471 Recall:  0.5 Precision:  0.3888888888888889 F1:  0.43750000000000006\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6029411764705883 Recall:  0.5 Precision:  0.4117647058823529 F1:  0.45161290322580644\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6260504201680672 Recall:  0.42857142857142855 Precision:  0.5 F1:  0.4615384615384615\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5903361344537815 Recall:  0.35714285714285715 Precision:  0.45454545454545453 F1:  0.4\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5903361344537815 Recall:  0.35714285714285715 Precision:  0.45454545454545453 F1:  0.4\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5903361344537815 Recall:  0.35714285714285715 Precision:  0.45454545454545453 F1:  0.4\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5903361344537815 Recall:  0.35714285714285715 Precision:  0.45454545454545453 F1:  0.4\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.569327731092437 Recall:  0.2857142857142857 Precision:  0.4444444444444444 F1:  0.34782608695652173\n",
      "0.4 0.6260504201680672\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f0d714d6-2d6c-436e-81dc-442a9cc14715",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "62a52370-3e0c-407f-b096-6b65f456b08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4027200/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d7190ac7-6ac6-43a6-9643-23e276d450da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.5625 MSE:  0.4375 UAR:  0.5861344537815126 Recall:  0.6428571428571429 Precision:  0.36 F1:  0.4615384615384615\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.625 MSE:  0.375 UAR:  0.6302521008403361 Recall:  0.6428571428571429 Precision:  0.4090909090909091 F1:  0.5000000000000001\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.625 MSE:  0.375 UAR:  0.6092436974789917 Recall:  0.5714285714285714 Precision:  0.4 F1:  0.47058823529411764\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6386554621848739 Recall:  0.5714285714285714 Precision:  0.4444444444444444 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5819327731092437 Recall:  0.42857142857142855 Precision:  0.4 F1:  0.4137931034482759\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.611344537815126 Recall:  0.42857142857142855 Precision:  0.46153846153846156 F1:  0.4444444444444445\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.611344537815126 Recall:  0.42857142857142855 Precision:  0.46153846153846156 F1:  0.4444444444444445\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5336134453781513 Recall:  0.21428571428571427 Precision:  0.375 F1:  0.2727272727272727\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.45588235294117646 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.4 0.6386554621848739\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956d63cd-4d28-4933-b603-baa894e7e83f",
   "metadata": {},
   "source": [
    "### STAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0bb9be4-3092-4bec-84ab-d8ad893629e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = compute_descriptor\n",
    "stat_name = \"STAT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404e64e3-f13f-47fc-8035-eb2a70e7b75e",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4cba168-1179-48b7-85da-73b4776871e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e33f684-3833-4521-a733-51f5f2739cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4ebb9dc-4636-4698-87f9-aebb2cd213be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd62ec-ef0a-477a-8178-c75f65958e12",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f113ed6e-9c91-4042-8d8f-5c0ffd3d4344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "125cd68b-a3f5-41ca-9d00-ef41b3d0be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ae748bc-ba96-4495-a499-fdf5026bb288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 3840) (5449,)\n",
      "(2284, 128, 3840) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1d9b4ce-b98f-4e58-91ea-2d6265b097a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 07:24:49.986587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1966592   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1970946 (7.52 MB)\n",
      "Trainable params: 1970946 (7.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17cdc14c-65bd-4860-92c8-7e7940ee9565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 07:25:03.152418: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2ec8232af0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-30 07:25:03.152594: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-30 07:25:03.156757: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-30 07:25:03.198857: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-07-30 07:25:03.250678: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 10s 159ms/step - loss: 0.4052 - acc: 0.8391 - auc: 0.8601 - binary_accuracy: 0.8391 - recall: 0.5382 - precision: 0.8414 - val_loss: 0.7601 - val_acc: 0.7084 - val_auc: 0.6645 - val_binary_accuracy: 0.7084 - val_recall: 0.2459 - val_precision: 0.7228\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.1796 - acc: 0.9352 - auc: 0.9801 - binary_accuracy: 0.9352 - recall: 0.8343 - precision: 0.9319 - val_loss: 0.9309 - val_acc: 0.6537 - val_auc: 0.6570 - val_binary_accuracy: 0.6537 - val_recall: 0.5070 - val_precision: 0.4963\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.1088 - acc: 0.9635 - auc: 0.9935 - binary_accuracy: 0.9635 - recall: 0.9242 - precision: 0.9467 - val_loss: 1.0701 - val_acc: 0.6821 - val_auc: 0.6794 - val_binary_accuracy: 0.6821 - val_recall: 0.4013 - val_precision: 0.5517\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.0668 - acc: 0.9846 - auc: 0.9985 - binary_accuracy: 0.9846 - recall: 0.9660 - precision: 0.9798 - val_loss: 1.1460 - val_acc: 0.6957 - val_auc: 0.7017 - val_binary_accuracy: 0.6957 - val_recall: 0.4178 - val_precision: 0.5795\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.0475 - acc: 0.9873 - auc: 0.9992 - binary_accuracy: 0.9873 - recall: 0.9672 - precision: 0.9882 - val_loss: 1.2157 - val_acc: 0.6782 - val_auc: 0.6876 - val_binary_accuracy: 0.6782 - val_recall: 0.5172 - val_precision: 0.5328\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.0277 - acc: 0.9960 - auc: 0.9999 - binary_accuracy: 0.9960 - recall: 0.9917 - precision: 0.9942 - val_loss: 1.2752 - val_acc: 0.6537 - val_auc: 0.6923 - val_binary_accuracy: 0.6537 - val_recall: 0.5019 - val_precision: 0.4962\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.0200 - acc: 0.9971 - auc: 1.0000 - binary_accuracy: 0.9971 - recall: 0.9923 - precision: 0.9974 - val_loss: 1.2530 - val_acc: 0.6996 - val_auc: 0.7142 - val_binary_accuracy: 0.6996 - val_recall: 0.4904 - val_precision: 0.5738\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.0137 - acc: 0.9994 - auc: 1.0000 - binary_accuracy: 0.9994 - recall: 0.9987 - precision: 0.9994 - val_loss: 1.3680 - val_acc: 0.7027 - val_auc: 0.7071 - val_binary_accuracy: 0.7027 - val_recall: 0.5070 - val_precision: 0.5768\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.0113 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall: 0.9987 - precision: 1.0000 - val_loss: 1.4306 - val_acc: 0.6799 - val_auc: 0.6953 - val_binary_accuracy: 0.6799 - val_recall: 0.5159 - val_precision: 0.5357\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.0080 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall: 0.9994 - precision: 0.9994 - val_loss: 1.4651 - val_acc: 0.6410 - val_auc: 0.7058 - val_binary_accuracy: 0.6410 - val_recall: 0.5121 - val_precision: 0.4791\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.0063 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.5767 - val_acc: 0.6813 - val_auc: 0.6926 - val_binary_accuracy: 0.6813 - val_recall: 0.4904 - val_precision: 0.5400\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.0049 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.6114 - val_acc: 0.6931 - val_auc: 0.6826 - val_binary_accuracy: 0.6931 - val_recall: 0.4866 - val_precision: 0.5618\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.0037 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall: 1.0000 - precision: 0.9994 - val_loss: 1.5918 - val_acc: 0.6515 - val_auc: 0.7093 - val_binary_accuracy: 0.6515 - val_recall: 0.5096 - val_precision: 0.4932\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.0032 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.6637 - val_acc: 0.6668 - val_auc: 0.6942 - val_binary_accuracy: 0.6668 - val_recall: 0.5248 - val_precision: 0.5150\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.0025 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.6990 - val_acc: 0.6651 - val_auc: 0.6957 - val_binary_accuracy: 0.6651 - val_recall: 0.5146 - val_precision: 0.5127\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.0022 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.6910 - val_acc: 0.6738 - val_auc: 0.6993 - val_binary_accuracy: 0.6738 - val_recall: 0.5096 - val_precision: 0.5263\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.0019 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.7624 - val_acc: 0.6996 - val_auc: 0.6890 - val_binary_accuracy: 0.6996 - val_recall: 0.5096 - val_precision: 0.5706\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.0016 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.7726 - val_acc: 0.6607 - val_auc: 0.6932 - val_binary_accuracy: 0.6607 - val_recall: 0.5223 - val_precision: 0.5062\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.0014 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.8197 - val_acc: 0.6629 - val_auc: 0.6877 - val_binary_accuracy: 0.6629 - val_recall: 0.5108 - val_precision: 0.5095\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.0013 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.8185 - val_acc: 0.6567 - val_auc: 0.6961 - val_binary_accuracy: 0.6567 - val_recall: 0.5210 - val_precision: 0.5006\n",
      "0.7600646615028381\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7a61e9f-4d8c-4c53-900f-51854c52539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4038218/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5612a979-c8b4-4f67-a208-a1904aab07a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.5208333333333334 MSE:  0.4791666666666667 UAR:  0.5357142857142857 Recall:  0.5714285714285714 Precision:  0.32 F1:  0.41025641025641024\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.5416666666666666 MSE:  0.4583333333333333 UAR:  0.5504201680672269 Recall:  0.5714285714285714 Precision:  0.3333333333333333 F1:  0.4210526315789474\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5945378151260504 Recall:  0.5714285714285714 Precision:  0.38095238095238093 F1:  0.4571428571428571\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.5588235294117647 Recall:  0.5 Precision:  0.35 F1:  0.4117647058823529\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.5588235294117647 Recall:  0.5 Precision:  0.35 F1:  0.4117647058823529\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5735294117647058 Recall:  0.5 Precision:  0.3684210526315789 F1:  0.4242424242424242\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6176470588235294 Recall:  0.5 Precision:  0.4375 F1:  0.4666666666666667\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6617647058823529 Recall:  0.5 Precision:  0.5384615384615384 F1:  0.5185185185185186\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.75 MSE:  0.25 UAR:  0.6764705882352942 Recall:  0.5 Precision:  0.5833333333333334 F1:  0.5384615384615384\n",
      "0.9 0.6764705882352942\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "825184ce-9e1f-487c-8132-3510d48458bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f3c33a2-bec6-4b21-b2df-b1b01a74f2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4038218/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac368311-0278-4fd9-a3e1-634bf2b711ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.5625 MSE:  0.4375 UAR:  0.5651260504201681 Recall:  0.5714285714285714 Precision:  0.34782608695652173 F1:  0.4324324324324324\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6176470588235294 Recall:  0.5 Precision:  0.4375 F1:  0.4666666666666667\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5903361344537815 Recall:  0.35714285714285715 Precision:  0.45454545454545453 F1:  0.4\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6134453781512605 Recall:  0.2857142857142857 Precision:  0.6666666666666666 F1:  0.4\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5777310924369747 Recall:  0.21428571428571427 Precision:  0.6 F1:  0.3157894736842105\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6071428571428571 Recall:  0.21428571428571427 Precision:  1.0 F1:  0.35294117647058826\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.5714285714285714 Recall:  0.14285714285714285 Precision:  1.0 F1:  0.25\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.5714285714285714 Recall:  0.14285714285714285 Precision:  1.0 F1:  0.25\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.2 0.6176470588235294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44e8bb0-65b3-4abe-8354-76f912f9722b",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9891e4f4-2b60-4131-8462-765765cd22a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86e5cf30-0a20-4559-bfab-9b68793a1c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f886fd1-4c63-4ef4-85bb-d51608f32b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 3840) (5449,)\n",
      "(2284, 128, 3840) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "479bce73-585c-4365-89f5-0c685dfdef77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 3840)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    3841      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29498882 (112.53 MB)\n",
      "Trainable params: 29498882 (112.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2cc2f86f-bc71-47bf-b472-cd5e2132f424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 13s 267ms/step - loss: 0.8178 - acc: 0.7937 - auc: 0.7978 - binary_accuracy: 0.7937 - recall_1: 0.6275 - precision_1: 0.6423 - val_loss: 0.9124 - val_acc: 0.7469 - val_auc: 0.6501 - val_binary_accuracy: 0.7469 - val_recall_1: 0.4089 - val_precision_1: 0.7379\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 9s 204ms/step - loss: 0.1831 - acc: 0.9378 - auc: 0.9740 - binary_accuracy: 0.9378 - recall_1: 0.8401 - precision_1: 0.9356 - val_loss: 0.9893 - val_acc: 0.6865 - val_auc: 0.6679 - val_binary_accuracy: 0.6865 - val_recall_1: 0.4255 - val_precision_1: 0.5576\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 8s 178ms/step - loss: 0.1127 - acc: 0.9642 - auc: 0.9914 - binary_accuracy: 0.9642 - recall_1: 0.9274 - precision_1: 0.9463 - val_loss: 1.2325 - val_acc: 0.6773 - val_auc: 0.6565 - val_binary_accuracy: 0.6773 - val_recall_1: 0.4408 - val_precision_1: 0.5373\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 8s 179ms/step - loss: 0.0860 - acc: 0.9721 - auc: 0.9940 - binary_accuracy: 0.9721 - recall_1: 0.9383 - precision_1: 0.9631 - val_loss: 1.2284 - val_acc: 0.6699 - val_auc: 0.6801 - val_binary_accuracy: 0.6699 - val_recall_1: 0.4573 - val_precision_1: 0.5226\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 8s 179ms/step - loss: 0.0619 - acc: 0.9807 - auc: 0.9973 - binary_accuracy: 0.9807 - recall_1: 0.9531 - precision_1: 0.9789 - val_loss: 1.3655 - val_acc: 0.6524 - val_auc: 0.6976 - val_binary_accuracy: 0.6524 - val_recall_1: 0.3796 - val_precision_1: 0.4926\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 8s 180ms/step - loss: 0.0330 - acc: 0.9916 - auc: 0.9996 - binary_accuracy: 0.9916 - recall_1: 0.9814 - precision_1: 0.9890 - val_loss: 1.7350 - val_acc: 0.6392 - val_auc: 0.6599 - val_binary_accuracy: 0.6392 - val_recall_1: 0.3083 - val_precision_1: 0.4627\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 8s 180ms/step - loss: 0.0290 - acc: 0.9921 - auc: 0.9995 - binary_accuracy: 0.9921 - recall_1: 0.9852 - precision_1: 0.9871 - val_loss: 1.5910 - val_acc: 0.6410 - val_auc: 0.6754 - val_binary_accuracy: 0.6410 - val_recall_1: 0.4268 - val_precision_1: 0.4752\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 8s 179ms/step - loss: 0.0134 - acc: 0.9978 - auc: 0.9999 - binary_accuracy: 0.9978 - recall_1: 0.9961 - precision_1: 0.9961 - val_loss: 1.7238 - val_acc: 0.6581 - val_auc: 0.6798 - val_binary_accuracy: 0.6581 - val_recall_1: 0.4433 - val_precision_1: 0.5029\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 8s 179ms/step - loss: 0.0069 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_1: 0.9987 - precision_1: 0.9987 - val_loss: 1.7973 - val_acc: 0.6633 - val_auc: 0.6734 - val_binary_accuracy: 0.6633 - val_recall_1: 0.4064 - val_precision_1: 0.5129\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 8s 178ms/step - loss: 0.0053 - acc: 0.9994 - auc: 1.0000 - binary_accuracy: 0.9994 - recall_1: 0.9994 - precision_1: 0.9987 - val_loss: 1.9653 - val_acc: 0.6436 - val_auc: 0.6577 - val_binary_accuracy: 0.6436 - val_recall_1: 0.3478 - val_precision_1: 0.4748\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 8s 180ms/step - loss: 0.0045 - acc: 0.9994 - auc: 1.0000 - binary_accuracy: 0.9994 - recall_1: 0.9987 - precision_1: 0.9994 - val_loss: 1.9237 - val_acc: 0.6410 - val_auc: 0.6698 - val_binary_accuracy: 0.6410 - val_recall_1: 0.4879 - val_precision_1: 0.4782\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 8s 179ms/step - loss: 0.0028 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 2.0181 - val_acc: 0.6480 - val_auc: 0.6636 - val_binary_accuracy: 0.6480 - val_recall_1: 0.4242 - val_precision_1: 0.4861\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 8s 180ms/step - loss: 0.0021 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 2.1345 - val_acc: 0.6489 - val_auc: 0.6517 - val_binary_accuracy: 0.6489 - val_recall_1: 0.4204 - val_precision_1: 0.4874\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 8s 180ms/step - loss: 0.0021 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 2.0908 - val_acc: 0.6506 - val_auc: 0.6605 - val_binary_accuracy: 0.6506 - val_recall_1: 0.4344 - val_precision_1: 0.4906\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 8s 179ms/step - loss: 0.0021 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 2.1434 - val_acc: 0.6449 - val_auc: 0.6576 - val_binary_accuracy: 0.6449 - val_recall_1: 0.4701 - val_precision_1: 0.4830\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 8s 180ms/step - loss: 0.0021 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_1: 1.0000 - precision_1: 0.9994 - val_loss: 2.1191 - val_acc: 0.6493 - val_auc: 0.6634 - val_binary_accuracy: 0.6493 - val_recall_1: 0.4968 - val_precision_1: 0.4899\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 8s 178ms/step - loss: 0.0011 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 2.2636 - val_acc: 0.6414 - val_auc: 0.6506 - val_binary_accuracy: 0.6414 - val_recall_1: 0.4127 - val_precision_1: 0.4751\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 8s 179ms/step - loss: 8.7256e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 2.3057 - val_acc: 0.6475 - val_auc: 0.6507 - val_binary_accuracy: 0.6475 - val_recall_1: 0.4471 - val_precision_1: 0.4861\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 8s 181ms/step - loss: 7.4486e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 2.3173 - val_acc: 0.6497 - val_auc: 0.6520 - val_binary_accuracy: 0.6497 - val_recall_1: 0.4548 - val_precision_1: 0.4897\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 8s 180ms/step - loss: 8.0688e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 2.4626 - val_acc: 0.6362 - val_auc: 0.6352 - val_binary_accuracy: 0.6362 - val_recall_1: 0.3529 - val_precision_1: 0.4617\n",
      "0.9123796224594116\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85210f6b-5a91-47ea-9e1f-84edc28d7ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4038218/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61e14c44-8aab-4e8b-8069-1859c3901f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6239495798319328 Recall:  0.5714285714285714 Precision:  0.42105263157894735 F1:  0.48484848484848486\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6029411764705883 Recall:  0.5 Precision:  0.4117647058823529 F1:  0.45161290322580644\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5315126050420168 Recall:  0.35714285714285715 Precision:  0.3333333333333333 F1:  0.3448275862068965\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5315126050420168 Recall:  0.35714285714285715 Precision:  0.3333333333333333 F1:  0.3448275862068965\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.5252100840336134 Recall:  0.2857142857142857 Precision:  0.3333333333333333 F1:  0.30769230769230765\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.5042016806722689 Recall:  0.21428571428571427 Precision:  0.3 F1:  0.25\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.51890756302521 Recall:  0.21428571428571427 Precision:  0.3333333333333333 F1:  0.2608695652173913\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.51890756302521 Recall:  0.21428571428571427 Precision:  0.3333333333333333 F1:  0.2608695652173913\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.51890756302521 Recall:  0.21428571428571427 Precision:  0.3333333333333333 F1:  0.2608695652173913\n",
      "0.1 0.6239495798319328\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d8d681ba-d645-4f6f-b977-1cd6334a2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "63036ae2-0b47-446f-8f82-20d889eba320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4038218/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5fff338-9a08-4173-8463-8a6a050b140b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.6008403361344539 Recall:  0.6428571428571429 Precision:  0.375 F1:  0.4736842105263159\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5945378151260504 Recall:  0.5714285714285714 Precision:  0.38095238095238093 F1:  0.4571428571428571\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.625 MSE:  0.375 UAR:  0.6092436974789917 Recall:  0.5714285714285714 Precision:  0.4 F1:  0.47058823529411764\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6029411764705883 Recall:  0.5 Precision:  0.4117647058823529 F1:  0.45161290322580644\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6617647058823529 Recall:  0.5 Precision:  0.5384615384615384 F1:  0.5185185185185186\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6554621848739496 Recall:  0.42857142857142855 Precision:  0.6 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6554621848739496 Recall:  0.42857142857142855 Precision:  0.6 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5777310924369747 Recall:  0.21428571428571427 Precision:  0.6 F1:  0.3157894736842105\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6071428571428571 Recall:  0.21428571428571427 Precision:  1.0 F1:  0.35294117647058826\n",
      "0.5 0.6617647058823529\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6595df78-c264-451b-9931-52eed307851c",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfeb12bf-8b02-45ad-92a2-5730229364b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ddb12f2-4747-4497-b005-3566a87bc3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43b41fd0-dec1-42d1-b7bc-6f1ddf6af8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6b9aab4-a888-43e0-9e3e-6c036c80176b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147, 2560) (147,)\n",
      "(48, 2560) (48,)\n",
      "(195, 2560) (195,)\n",
      "[0 1] [141  54]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.759)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bbf7fc54-2de1-4e92-a362-5bbc5c66e89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5ff124-2f93-4736-b8f4-baffd8ba8b17",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d0767b5-6c8a-4dc6-ac64-585091e61933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52be6759-059c-4478-8a38-bbb4c833f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a55bc299-8136-4cd7-8c58-accd61d3563a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 3840) (5631,)\n",
      "(2102, 128, 3840) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1675ffcd-d913-4120-8ce7-e50e426e089f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 07:39:08.167930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1966592   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1970946 (7.52 MB)\n",
      "Trainable params: 1970946 (7.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c4960d3-a455-410c-8949-2aa531512675",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fdfc4bcd-03e7-4bd9-9d00-be8dc5eab841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "00f9ec8a-e94d-4dc0-8e28-0d6e22c325c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6533613445378151 Recall:  0.5714285714285714 Precision:  0.47058823529411764 F1:  0.5161290322580646\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6680672268907563 Recall:  0.5714285714285714 Precision:  0.5 F1:  0.5333333333333333\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6323529411764706 Recall:  0.5 Precision:  0.4666666666666667 F1:  0.4827586206896552\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5609243697478992 Recall:  0.35714285714285715 Precision:  0.38461538461538464 F1:  0.3703703703703704\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5609243697478992 Recall:  0.35714285714285715 Precision:  0.38461538461538464 F1:  0.3703703703703704\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5903361344537815 Recall:  0.35714285714285715 Precision:  0.45454545454545453 F1:  0.4\n",
      "0.2 0.6680672268907563\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66e5e047-2190-46db-a38e-279e87ec422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    modelAtn.set_weights(best_model_weights)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3fee9185-8af6-4f28-a984-c25105680b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4c5f8e9-94e3-4fbd-8040-87049d4ad986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.6785714285714286 Recall:  0.8571428571428571 Precision:  0.41379310344827586 F1:  0.5581395348837208\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.7016806722689075 Recall:  0.7857142857142857 Precision:  0.4583333333333333 F1:  0.5789473684210527\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6449579831932774 Recall:  0.6428571428571429 Precision:  0.42857142857142855 F1:  0.5142857142857143\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6827731092436975 Recall:  0.5714285714285714 Precision:  0.5333333333333333 F1:  0.5517241379310344\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6260504201680672 Recall:  0.42857142857142855 Precision:  0.5 F1:  0.4615384615384615\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6554621848739496 Recall:  0.42857142857142855 Precision:  0.6 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6491596638655462 Recall:  0.35714285714285715 Precision:  0.7142857142857143 F1:  0.4761904761904762\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6491596638655462 Recall:  0.35714285714285715 Precision:  0.7142857142857143 F1:  0.4761904761904762\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6491596638655462 Recall:  0.35714285714285715 Precision:  0.7142857142857143 F1:  0.4761904761904762\n",
      "0.2 0.7016806722689075\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0422bf-9325-4770-abfb-fbb77298b929",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5597d72-77d6-4475-860d-145c40f9a505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb64287d-91a4-450e-b6e0-5ea4d1b26335",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea3efdce-24e1-46b1-aa49-1e1920d4df49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 3840) (5631,)\n",
      "(2102, 128, 3840) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ac112ae-6df6-4ef8-a4c0-6267e19e1fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3840)           1474560   ['image_set[0][0]']           \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 3840)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    3841      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29498882 (112.53 MB)\n",
      "Trainable params: 29498882 (112.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "387e145b-1fa0-412e-bd0d-bb6d119f5dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 07:39:49.605252: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x25ee422a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-30 07:39:49.605415: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-30 07:39:49.609556: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-30 07:39:49.656270: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-07-30 07:39:49.708038: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 16s 319ms/step - loss: 0.5446 - acc: 0.8439 - auc: 0.8782 - binary_accuracy: 0.8439 - recall_1: 0.7293 - precision_1: 0.7491 - val_loss: 1.0620 - val_acc: 0.5718 - val_auc: 0.6492 - val_binary_accuracy: 0.5718 - val_recall_1: 0.5780 - val_precision_1: 0.3674\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 0.1441 - acc: 0.9499 - auc: 0.9835 - binary_accuracy: 0.9499 - recall_1: 0.8910 - precision_1: 0.9406 - val_loss: 0.8972 - val_acc: 0.7350 - val_auc: 0.7195 - val_binary_accuracy: 0.7350 - val_recall_1: 0.4819 - val_precision_1: 0.5730\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.0828 - acc: 0.9705 - auc: 0.9953 - binary_accuracy: 0.9705 - recall_1: 0.9397 - precision_1: 0.9622 - val_loss: 1.0392 - val_acc: 0.6946 - val_auc: 0.7199 - val_binary_accuracy: 0.6946 - val_recall_1: 0.5480 - val_precision_1: 0.4950\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 8s 177ms/step - loss: 0.0497 - acc: 0.9860 - auc: 0.9981 - binary_accuracy: 0.9860 - recall_1: 0.9725 - precision_1: 0.9811 - val_loss: 1.2016 - val_acc: 0.6784 - val_auc: 0.6943 - val_binary_accuracy: 0.6784 - val_recall_1: 0.4315 - val_precision_1: 0.4652\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.0291 - acc: 0.9920 - auc: 0.9993 - binary_accuracy: 0.9920 - recall_1: 0.9807 - precision_1: 0.9929 - val_loss: 1.4856 - val_acc: 0.6560 - val_auc: 0.7086 - val_binary_accuracy: 0.6560 - val_recall_1: 0.6299 - val_precision_1: 0.4505\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 0.0196 - acc: 0.9956 - auc: 0.9995 - binary_accuracy: 0.9956 - recall_1: 0.9912 - precision_1: 0.9941 - val_loss: 1.4498 - val_acc: 0.6784 - val_auc: 0.6954 - val_binary_accuracy: 0.6784 - val_recall_1: 0.4992 - val_precision_1: 0.4696\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 8s 177ms/step - loss: 0.0123 - acc: 0.9977 - auc: 0.9999 - binary_accuracy: 0.9977 - recall_1: 0.9947 - precision_1: 0.9976 - val_loss: 1.5958 - val_acc: 0.6775 - val_auc: 0.6938 - val_binary_accuracy: 0.6775 - val_recall_1: 0.5370 - val_precision_1: 0.4703\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 8s 177ms/step - loss: 0.0080 - acc: 0.9991 - auc: 1.0000 - binary_accuracy: 0.9991 - recall_1: 0.9977 - precision_1: 0.9994 - val_loss: 1.6810 - val_acc: 0.6646 - val_auc: 0.6974 - val_binary_accuracy: 0.6646 - val_recall_1: 0.4913 - val_precision_1: 0.4496\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 0.0061 - acc: 0.9991 - auc: 1.0000 - binary_accuracy: 0.9991 - recall_1: 0.9977 - precision_1: 0.9994 - val_loss: 1.7859 - val_acc: 0.6456 - val_auc: 0.6914 - val_binary_accuracy: 0.6456 - val_recall_1: 0.4646 - val_precision_1: 0.4214\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 0.0267 - acc: 0.9909 - auc: 0.9992 - binary_accuracy: 0.9909 - recall_1: 0.9836 - precision_1: 0.9865 - val_loss: 2.1652 - val_acc: 0.6494 - val_auc: 0.6601 - val_binary_accuracy: 0.6494 - val_recall_1: 0.5165 - val_precision_1: 0.4327\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 0.0102 - acc: 0.9980 - auc: 0.9997 - binary_accuracy: 0.9980 - recall_1: 0.9959 - precision_1: 0.9977 - val_loss: 2.2432 - val_acc: 0.6213 - val_auc: 0.6454 - val_binary_accuracy: 0.6213 - val_recall_1: 0.4457 - val_precision_1: 0.3893\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 0.0073 - acc: 0.9984 - auc: 1.0000 - binary_accuracy: 0.9984 - recall_1: 0.9971 - precision_1: 0.9977 - val_loss: 2.3628 - val_acc: 0.6618 - val_auc: 0.6691 - val_binary_accuracy: 0.6618 - val_recall_1: 0.5669 - val_precision_1: 0.4523\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 0.0025 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_1: 0.9994 - precision_1: 1.0000 - val_loss: 2.3211 - val_acc: 0.6189 - val_auc: 0.6636 - val_binary_accuracy: 0.6189 - val_recall_1: 0.4126 - val_precision_1: 0.3797\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.0569 - acc: 0.9837 - auc: 0.9965 - binary_accuracy: 0.9837 - recall_1: 0.9742 - precision_1: 0.9719 - val_loss: 2.8214 - val_acc: 0.6508 - val_auc: 0.6909 - val_binary_accuracy: 0.6508 - val_recall_1: 0.5323 - val_precision_1: 0.4361\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 8s 179ms/step - loss: 0.0086 - acc: 0.9979 - auc: 0.9997 - binary_accuracy: 0.9979 - recall_1: 0.9965 - precision_1: 0.9965 - val_loss: 2.7515 - val_acc: 0.6475 - val_auc: 0.6854 - val_binary_accuracy: 0.6475 - val_recall_1: 0.5276 - val_precision_1: 0.4317\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 0.0051 - acc: 0.9984 - auc: 1.0000 - binary_accuracy: 0.9984 - recall_1: 0.9977 - precision_1: 0.9971 - val_loss: 2.6271 - val_acc: 0.6832 - val_auc: 0.6880 - val_binary_accuracy: 0.6832 - val_recall_1: 0.4378 - val_precision_1: 0.4736\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 0.0028 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_1: 0.9994 - precision_1: 0.9994 - val_loss: 2.6400 - val_acc: 0.6675 - val_auc: 0.6912 - val_binary_accuracy: 0.6675 - val_recall_1: 0.4693 - val_precision_1: 0.4515\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 8s 177ms/step - loss: 8.9276e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 2.6399 - val_acc: 0.6618 - val_auc: 0.6955 - val_binary_accuracy: 0.6618 - val_recall_1: 0.4756 - val_precision_1: 0.4441\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 9s 205ms/step - loss: 5.7489e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 2.6688 - val_acc: 0.6698 - val_auc: 0.6912 - val_binary_accuracy: 0.6698 - val_recall_1: 0.4614 - val_precision_1: 0.4543\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 8s 178ms/step - loss: 5.0782e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 2.6800 - val_acc: 0.6717 - val_auc: 0.6903 - val_binary_accuracy: 0.6717 - val_recall_1: 0.4488 - val_precision_1: 0.4560\n",
      "0.897188127040863\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7658dcd9-5206-4385-8576-d3b825f190f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "58be0e57-d1da-425b-9e8f-d526cf83b7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6596638655462186 Recall:  0.6428571428571429 Precision:  0.45 F1:  0.5294117647058824\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6386554621848739 Recall:  0.5714285714285714 Precision:  0.4444444444444444 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6533613445378151 Recall:  0.5714285714285714 Precision:  0.47058823529411764 F1:  0.5161290322580646\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6533613445378151 Recall:  0.5714285714285714 Precision:  0.47058823529411764 F1:  0.5161290322580646\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6533613445378151 Recall:  0.5714285714285714 Precision:  0.47058823529411764 F1:  0.5161290322580646\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6533613445378151 Recall:  0.5714285714285714 Precision:  0.47058823529411764 F1:  0.5161290322580646\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6176470588235294 Recall:  0.5 Precision:  0.4375 F1:  0.4666666666666667\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5819327731092437 Recall:  0.42857142857142855 Precision:  0.4 F1:  0.4137931034482759\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5819327731092437 Recall:  0.42857142857142855 Precision:  0.4 F1:  0.4137931034482759\n",
      "0.1 0.6596638655462186\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f162f19-90b9-4bfa-87c8-f6f9402a86b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    modelAtn.set_weights(best_model_weights)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2bc978df-734b-4c11-a362-86e05ae20a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b65dda6c-8539-4e7d-a1d7-a3540985a9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.625 MSE:  0.375 UAR:  0.6302521008403361 Recall:  0.6428571428571429 Precision:  0.4090909090909091 F1:  0.5000000000000001\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.625 MSE:  0.375 UAR:  0.6092436974789917 Recall:  0.5714285714285714 Precision:  0.4 F1:  0.47058823529411764\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6386554621848739 Recall:  0.5714285714285714 Precision:  0.4444444444444444 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6680672268907563 Recall:  0.5714285714285714 Precision:  0.5 F1:  0.5333333333333333\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6323529411764706 Recall:  0.5 Precision:  0.4666666666666667 F1:  0.4827586206896552\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6554621848739496 Recall:  0.42857142857142855 Precision:  0.6 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6554621848739496 Recall:  0.42857142857142855 Precision:  0.6 F1:  0.5\n",
      "Metric_name:  enet_b0_8_best_afew.pt_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.592436974789916 Recall:  0.21428571428571427 Precision:  0.75 F1:  0.3333333333333333\n",
      "0.4 0.6680672268907563\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7a9bbe-8439-4a4e-95ee-7eed003c7434",
   "metadata": {},
   "source": [
    "## MobileNet_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06db56e2-b51d-45c2-8e41-ef166bb7b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_key = 'mobilenet_7.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32be9f26-061d-4bd7-9362-979c1c2031b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['engaged', 'distracted']\n",
      "{'subject_1_Vid_1': 0, 'subject_1_Vid_2': 0, 'subject_1_Vid_3': 0, 'subject_1_Vid_4': 0, 'subject_1_Vid_5': 0, 'subject_31_Vid_6': 0, 'subject_2_Vid_6': 1, 'subject_3_Vid_6': 0, 'subject_3_Vid_1': 1, 'subject_3_Vid_2': 1, 'subject_3_Vid_3': 0, 'subject_3_Vid_4': 0, 'subject_3_Vid_5': 1, 'subject_3_Vid_7': 0, 'subject_4_Vid_6': 0, 'subject_5_Vid_6': 0, 'subject_6_Vid_6': 1, 'subject_7_Vid_1': 0, 'subject_7_Vid_2': 0, 'subject_7_Vid_3': 0, 'subject_7_Vid_4': 0, 'subject_7_Vid_5': 1, 'subject_8_Vid_6': 0, 'subject_9_Vid_6': 1, 'subject_10_Vid_6': 0, 'subject_11_Vid_6': 0, 'subject_12_Vid_6': 1, 'subject_13_Vid_6': 0, 'subject_14_Vid_6': 0, 'subject_15_Vid_6': 0, 'subject_16_Vid_6': 1, 'subject_17_Vid_6': 0, 'subject_18_Vid_6': 1, 'subject_19_Vid_6': 0, 'subject_20_Vid_6': 0, 'subject_20_Vid_1': 0, 'subject_20_Vid_2': 0, 'subject_20_Vid_3': 0, 'subject_20_Vid_4': 1, 'subject_20_Vid_5': 0, 'subject_20_Vid_5_1': 0, 'subject_20_Vid_5_2': 0, 'subject_20_Vid_7': 1, 'subject_21_Vid_5': 1, 'subject_22_Vid_5': 0, 'subject_23_Vid_5': 1, 'subject_24_Vid_5': 0, 'subject_25_Vid_5': 0, 'subject_26_Vid_1': 0, 'subject_26_Vid_2': 0, 'subject_26_Vid_3': 1, 'subject_26_Vid_4': 0, 'subject_26_Vid_5': 1, 'subject_26_Vid_5_1': 0, 'subject_26_Vid_5_2': 0, 'subject_26_Vid_7': 1, 'subject_27_Vid_1': 0, 'subject_29_Vid_6': 0, 'subject_29_Vid_7': 1, 'subject_30_Vid_1': 1, 'subject_30_Vid_2': 0, 'subject_30_Vid_3': 0, 'subject_30_Vid_4': 0, 'subject_30_Vid_5': 1, 'subject_32_Vid_6': 0, 'subject_32_Vid_1': 0, 'subject_32_Vid_2': 0, 'subject_32_Vid_3': 0, 'subject_32_Vid_4': 0, 'subject_32_Vid_5': 0, 'subject_32_Vid_7': 1, 'subject_33_Vid_1': 1, 'subject_33_Vid_2': 0, 'subject_33_Vid_3': 0, 'subject_33_Vid_4': 0, 'subject_33_Vid_7': 0, 'subject_34_Vid_7': 0, 'subject_34_Vid_1': 0, 'subject_34_Vid_5': 0, 'subject_35_Vid_6': 1, 'subject_35_Vid_7': 0, 'subject_36_Vid_7': 0, 'subject_37_Vid_7': 0, 'subject_38_Vid_7': 0, 'subject_39_Vid_6': 0, 'subject_39_Vid_7': 1, 'subject_40_Vid_6': 0, 'subject_40_Vid_7': 1, 'subject_41_Vid_6': 0, 'subject_41_Vid_2': 1, 'subject_41_Vid_3': 0, 'subject_41_Vid_4': 1, 'subject_41_Vid_5': 1, 'subject_41_Vid_5_1': 0, 'subject_41_Vid_5_2': 1, 'subject_41_Vid_7': 0, 'subject_42_Vid_7': 0, 'subject_43_Vid_7': 0, 'subject_44_Vid_7': 1, 'subject_45_Vid_7': 1, 'subject_46_Vid_6': 0, 'subject_47_Vid_6': 0, 'subject_48_Vid_6': 0, 'subject_48_Vid_7': 0, 'subject_49_Vid_7': 0, 'subject_50_Vid_6': 0, 'subject_50_Vid_1': 0, 'subject_50_Vid_2': 1, 'subject_50_Vid_3': 1, 'subject_50_Vid_4': 1, 'subject_50_Vid_5': 1, 'subject_51_Vid_7': 0, 'subject_52_Vid_7': 1, 'subject_53_Vid_2': 0, 'subject_53_Vid_3': 0, 'subject_53_Vid_4': 0, 'subject_53_Vid_5': 0, 'subject_54_Vid_6': 0, 'subject_55_Vid_6': 0, 'subject_56_Vid_6': 0, 'subject_56_Vid_1': 0, 'subject_56_Vid_2': 0, 'subject_56_Vid_3': 0, 'subject_56_Vid_4': 0, 'subject_56_Vid_5': 0, 'subject_57_Vid_7': 0, 'subject_58_Vid_6': 0, 'subject_58_Vid_7': 0, 'subject_59_Vid_7': 0, 'subject_60_Vid_6': 0, 'subject_60_Vid_7': 0, 'subject_62_Vid_6': 0, 'subject_62_Vid_1': 0, 'subject_62_Vid_2': 0, 'subject_62_Vid_3': 1, 'subject_62_Vid_4': 0, 'subject_62_Vid_5': 0, 'subject_62_Vid_7': 0, 'subject_63_Vid_7': 1, 'subject_64_Vid_6': 0, 'subject_64_Vid_7': 1, 'subject_65_Vid_6': 0, 'subject_66_Vid_6': 0, 'subject_66_Vid_7': 1, 'subject_67_Vid_6': 0, 'subject_67_Vid_1': 0, 'subject_67_Vid_2': 0, 'subject_67_Vid_4': 0, 'subject_67_Vid_5': 0, 'subject_68_Vid_6': 0, 'subject_68_Vid_7': 1, 'subject_69_Vid_6': 0, 'subject_69_Vid_7': 0, 'subject_70_Vid_6': 0, 'subject_70_Vid_1': 0, 'subject_70_Vid_2': 0, 'subject_70_Vid_3': 0, 'subject_70_Vid_4': 0, 'subject_70_Vid_5': 1, 'subject_72_Vid_6': 0, 'subject_73_Vid_6': 0, 'subject_73_Vid_7': 0, 'subject_74_Vid_7': 1, 'subject_75_Vid_7': 0, 'subject_76_Vid_6': 0, 'subject_76_Vid_7': 0, 'subject_77_Vid_6': 0, 'subject_77_Vid_1': 1, 'subject_77_Vid_2': 1, 'subject_77_Vid_3': 0, 'subject_77_Vid_4': 0, 'subject_77_Vid_5': 1, 'subject_78_Vid_6': 0, 'subject_79_Vid_7': 0, 'subject_80_Vid_6': 0, 'subject_80_Vid_1': 0, 'subject_80_Vid_2': 0, 'subject_80_Vid_3': 0, 'subject_80_Vid_4': 0, 'subject_80_Vid_5': 0, 'subject_81_Vid_7': 1, 'subject_82_Vid_7': 0, 'subject_83_Vid_7': 0, 'subject_84_Vid_6': 1, 'subject_84_Vid_1': 1, 'subject_84_Vid_2': 1, 'subject_84_Vid_3': 1, 'subject_84_Vid_4': 1, 'subject_84_Vid_5': 1, 'subject_85_Vid_7': 0, 'subject_86_Vid_7': 0, 'subject_77_Vid_7': 1, 'subject_34_Vid_2': 0, 'subject_34_Vid_3': 0, 'subject_34_Vid_4': 0, 'subject_87_Vid_3': 0}\n"
     ]
    }
   ],
   "source": [
    "ENGAGE_WILD_DATASET, BIN_CLASSIFICATION, N_CLASSES, DATASET_NAME, BASE_DATASET_DIR, ext = define_dataset(True, True)\n",
    "video2label, labels_list = get_video2label()\n",
    "print(labels_list)\n",
    "print(video2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4379ba-9bc6-4fbf-a5eb-909fafe465b7",
   "metadata": {},
   "source": [
    "### Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ec98c271-18aa-493e-acba-1461f0d91f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.std\n",
    "stat_name = \"std\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c604817-a029-42ba-83e5-1f57e824fa5a",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e632b343-0911-4b9a-8827-88944f3688be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "22f3452a-84e1-4ad5-827c-d30826a29df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bdafdc6c-6e48-449f-a848-05e701668789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5db959-16e4-43ba-ac0b-e01e6b6429b5",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f0c08d0-b7ce-43c3-ae5d-80b6d595b8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_std_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "605490db-686f-428a-b3ad-e4c5ed0257ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "da850ae6-fa37-4b2a-82e3-0e82d87cf51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2048) (5449,)\n",
      "(2284, 128, 2048) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "537e618f-b6e4-462a-b769-228b1270d613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9c0628a2-9caf-4a6c-ba66-16048437d065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 88ms/step - loss: 0.4456 - acc: 0.8064 - auc: 0.8214 - binary_accuracy: 0.8064 - recall_2: 0.4817 - precision_2: 0.7515 - val_loss: 0.6893 - val_acc: 0.6475 - val_auc: 0.6929 - val_binary_accuracy: 0.6475 - val_recall_2: 0.2701 - val_precision_2: 0.4775\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.2183 - acc: 0.9169 - auc: 0.9671 - binary_accuracy: 0.9169 - recall_2: 0.8112 - precision_2: 0.8882 - val_loss: 0.8184 - val_acc: 0.6690 - val_auc: 0.6946 - val_binary_accuracy: 0.6690 - val_recall_2: 0.1427 - val_precision_2: 0.5744\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.1261 - acc: 0.9552 - auc: 0.9915 - binary_accuracy: 0.9552 - recall_2: 0.8844 - precision_2: 0.9556 - val_loss: 0.7918 - val_acc: 0.6957 - val_auc: 0.7102 - val_binary_accuracy: 0.6957 - val_recall_2: 0.3376 - val_precision_2: 0.6023\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.0837 - acc: 0.9727 - auc: 0.9968 - binary_accuracy: 0.9727 - recall_2: 0.9416 - precision_2: 0.9619 - val_loss: 1.1134 - val_acc: 0.6957 - val_auc: 0.6675 - val_binary_accuracy: 0.6957 - val_recall_2: 0.2242 - val_precision_2: 0.6718\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.0565 - acc: 0.9839 - auc: 0.9989 - binary_accuracy: 0.9839 - recall_2: 0.9576 - precision_2: 0.9855 - val_loss: 1.0597 - val_acc: 0.6708 - val_auc: 0.6795 - val_binary_accuracy: 0.6708 - val_recall_2: 0.5096 - val_precision_2: 0.5215\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.0375 - acc: 0.9943 - auc: 0.9998 - binary_accuracy: 0.9943 - recall_2: 0.9839 - precision_2: 0.9961 - val_loss: 1.2594 - val_acc: 0.6581 - val_auc: 0.6595 - val_binary_accuracy: 0.6581 - val_recall_2: 0.2968 - val_precision_2: 0.5043\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.0251 - acc: 0.9972 - auc: 1.0000 - binary_accuracy: 0.9972 - recall_2: 0.9917 - precision_2: 0.9987 - val_loss: 1.3066 - val_acc: 0.6436 - val_auc: 0.6514 - val_binary_accuracy: 0.6436 - val_recall_2: 0.4127 - val_precision_2: 0.4786\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.0175 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_2: 0.9981 - precision_2: 0.9994 - val_loss: 1.4270 - val_acc: 0.6283 - val_auc: 0.6369 - val_binary_accuracy: 0.6283 - val_recall_2: 0.3643 - val_precision_2: 0.4497\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0141 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_2: 0.9994 - precision_2: 1.0000 - val_loss: 1.4597 - val_acc: 0.6327 - val_auc: 0.6308 - val_binary_accuracy: 0.6327 - val_recall_2: 0.4369 - val_precision_2: 0.4635\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0098 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.5394 - val_acc: 0.6327 - val_auc: 0.6262 - val_binary_accuracy: 0.6327 - val_recall_2: 0.4471 - val_precision_2: 0.4643\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0078 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.6954 - val_acc: 0.6151 - val_auc: 0.6153 - val_binary_accuracy: 0.6151 - val_recall_2: 0.2637 - val_precision_2: 0.4075\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.0064 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.6745 - val_acc: 0.6252 - val_auc: 0.6187 - val_binary_accuracy: 0.6252 - val_recall_2: 0.4191 - val_precision_2: 0.4513\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0052 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.7435 - val_acc: 0.6178 - val_auc: 0.6121 - val_binary_accuracy: 0.6178 - val_recall_2: 0.3924 - val_precision_2: 0.4375\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0039 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.7891 - val_acc: 0.6138 - val_auc: 0.6114 - val_binary_accuracy: 0.6138 - val_recall_2: 0.3745 - val_precision_2: 0.4292\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0031 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.8460 - val_acc: 0.6020 - val_auc: 0.6067 - val_binary_accuracy: 0.6020 - val_recall_2: 0.3325 - val_precision_2: 0.4040\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0026 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.8635 - val_acc: 0.5963 - val_auc: 0.6012 - val_binary_accuracy: 0.5963 - val_recall_2: 0.3312 - val_precision_2: 0.3957\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0023 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.9298 - val_acc: 0.5968 - val_auc: 0.6010 - val_binary_accuracy: 0.5968 - val_recall_2: 0.3363 - val_precision_2: 0.3976\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0020 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 1.9610 - val_acc: 0.5937 - val_auc: 0.6001 - val_binary_accuracy: 0.5937 - val_recall_2: 0.3439 - val_precision_2: 0.3953\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.0018 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.0488 - val_acc: 0.5898 - val_auc: 0.5935 - val_binary_accuracy: 0.5898 - val_recall_2: 0.2917 - val_precision_2: 0.3754\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0017 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_2: 1.0000 - precision_2: 1.0000 - val_loss: 2.0560 - val_acc: 0.5898 - val_auc: 0.5950 - val_binary_accuracy: 0.5898 - val_recall_2: 0.3159 - val_precision_2: 0.3827\n",
      "0.6893184185028076\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8653a050-0bc7-43bf-afea-c8aacc51f1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4e720122-1dd2-4b53-bc88-28b05003c8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional Accuracy:  0.5416666666666666 MSE:  0.4583333333333333 UAR:  0.5084033613445378 Recall:  0.42857142857142855 Precision:  0.3 F1:  0.3529411764705882\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.5672268907563025 Recall:  0.42857142857142855 Precision:  0.375 F1:  0.39999999999999997\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5315126050420168 Recall:  0.35714285714285715 Precision:  0.3333333333333333 F1:  0.3448275862068965\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5315126050420168 Recall:  0.35714285714285715 Precision:  0.3333333333333333 F1:  0.3448275862068965\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5105042016806722 Recall:  0.2857142857142857 Precision:  0.3076923076923077 F1:  0.29629629629629634\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5105042016806722 Recall:  0.2857142857142857 Precision:  0.3076923076923077 F1:  0.29629629629629634\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5399159663865546 Recall:  0.2857142857142857 Precision:  0.36363636363636365 F1:  0.32\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.51890756302521 Recall:  0.21428571428571427 Precision:  0.3333333333333333 F1:  0.2608695652173913\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5273109243697479 Recall:  0.14285714285714285 Precision:  0.4 F1:  0.21052631578947364\n",
      "0.2 0.5672268907563025\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cb95f85b-4cd4-417a-b3be-fe67e86e35f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fc2d6fc5-38f3-4a1b-b8d9-206b554a9b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "72c7240d-0830-41f1-b48c-6d0f08667ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.4791666666666667 MSE:  0.5208333333333334 UAR:  0.5903361344537815 Recall:  0.8571428571428571 Precision:  0.34285714285714286 F1:  0.4897959183673469\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.7247899159663866 Recall:  0.7142857142857143 Precision:  0.5263157894736842 F1:  0.6060606060606061\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6554621848739496 Recall:  0.42857142857142855 Precision:  0.6 F1:  0.5\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5630252100840336 Recall:  0.21428571428571427 Precision:  0.5 F1:  0.3\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.49159663865546216 Recall:  0.07142857142857142 Precision:  0.25 F1:  0.11111111111111112\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5063025210084033 Recall:  0.07142857142857142 Precision:  0.3333333333333333 F1:  0.11764705882352941\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5210084033613446 Recall:  0.07142857142857142 Precision:  0.5 F1:  0.125\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.2 0.7247899159663866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f83970-d331-4bb4-8c13-e8bf8e32d8c5",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "773e12f1-cb18-4996-905f-c80405c49d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_std_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "df0996e0-0709-4cb8-a908-3e1b2dfe5642",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "57095026-0b27-4d5f-8ba8-e1a5ff0cbe14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2048) (5449,)\n",
      "(2284, 128, 2048) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ebb813bf-d6a9-4d92-a28b-befb86b3948e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bfedf4f5-dceb-4047-bac6-711c36949547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 137ms/step - loss: 0.5493 - acc: 0.7932 - auc: 0.7957 - binary_accuracy: 0.7932 - recall_3: 0.5549 - precision_3: 0.6656 - val_loss: 0.6722 - val_acc: 0.6848 - val_auc: 0.6613 - val_binary_accuracy: 0.6848 - val_recall_3: 0.4255 - val_precision_3: 0.5539\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.2095 - acc: 0.9286 - auc: 0.9708 - binary_accuracy: 0.9286 - recall_3: 0.8420 - precision_3: 0.9017 - val_loss: 0.7188 - val_acc: 0.7097 - val_auc: 0.6857 - val_binary_accuracy: 0.7097 - val_recall_3: 0.3465 - val_precision_3: 0.6445\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.1524 - acc: 0.9435 - auc: 0.9828 - binary_accuracy: 0.9435 - recall_3: 0.8741 - precision_3: 0.9240 - val_loss: 0.7936 - val_acc: 0.6515 - val_auc: 0.6645 - val_binary_accuracy: 0.6515 - val_recall_3: 0.4229 - val_precision_3: 0.4919\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0990 - acc: 0.9670 - auc: 0.9944 - binary_accuracy: 0.9670 - recall_3: 0.9229 - precision_3: 0.9599 - val_loss: 0.7759 - val_acc: 0.6541 - val_auc: 0.7028 - val_binary_accuracy: 0.6541 - val_recall_3: 0.5414 - val_precision_3: 0.4971\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0678 - acc: 0.9791 - auc: 0.9975 - binary_accuracy: 0.9791 - recall_3: 0.9531 - precision_3: 0.9731 - val_loss: 0.8344 - val_acc: 0.6331 - val_auc: 0.7045 - val_binary_accuracy: 0.6331 - val_recall_3: 0.4803 - val_precision_3: 0.4672\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0478 - acc: 0.9864 - auc: 0.9990 - binary_accuracy: 0.9864 - recall_3: 0.9711 - precision_3: 0.9812 - val_loss: 1.0916 - val_acc: 0.6173 - val_auc: 0.6458 - val_binary_accuracy: 0.6173 - val_recall_3: 0.4752 - val_precision_3: 0.4467\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0327 - acc: 0.9921 - auc: 0.9993 - binary_accuracy: 0.9921 - recall_3: 0.9801 - precision_3: 0.9922 - val_loss: 1.1268 - val_acc: 0.6677 - val_auc: 0.6431 - val_binary_accuracy: 0.6677 - val_recall_3: 0.4038 - val_precision_3: 0.5214\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0218 - acc: 0.9963 - auc: 0.9999 - binary_accuracy: 0.9963 - recall_3: 0.9929 - precision_3: 0.9942 - val_loss: 1.2154 - val_acc: 0.6528 - val_auc: 0.6319 - val_binary_accuracy: 0.6528 - val_recall_3: 0.3898 - val_precision_3: 0.4935\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0136 - acc: 0.9980 - auc: 1.0000 - binary_accuracy: 0.9980 - recall_3: 0.9968 - precision_3: 0.9961 - val_loss: 1.2538 - val_acc: 0.6427 - val_auc: 0.6367 - val_binary_accuracy: 0.6427 - val_recall_3: 0.4573 - val_precision_3: 0.4793\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0118 - acc: 0.9980 - auc: 1.0000 - binary_accuracy: 0.9980 - recall_3: 0.9968 - precision_3: 0.9961 - val_loss: 1.2100 - val_acc: 0.6528 - val_auc: 0.6605 - val_binary_accuracy: 0.6528 - val_recall_3: 0.4854 - val_precision_3: 0.4948\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0100 - acc: 0.9987 - auc: 1.0000 - binary_accuracy: 0.9987 - recall_3: 0.9974 - precision_3: 0.9981 - val_loss: 1.3990 - val_acc: 0.6808 - val_auc: 0.6348 - val_binary_accuracy: 0.6808 - val_recall_3: 0.4051 - val_precision_3: 0.5483\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0087 - acc: 0.9983 - auc: 1.0000 - binary_accuracy: 0.9983 - recall_3: 0.9968 - precision_3: 0.9974 - val_loss: 1.4049 - val_acc: 0.6537 - val_auc: 0.6364 - val_binary_accuracy: 0.6537 - val_recall_3: 0.4446 - val_precision_3: 0.4957\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0050 - acc: 0.9994 - auc: 1.0000 - binary_accuracy: 0.9994 - recall_3: 1.0000 - precision_3: 0.9981 - val_loss: 1.4246 - val_acc: 0.6147 - val_auc: 0.6408 - val_binary_accuracy: 0.6147 - val_recall_3: 0.5261 - val_precision_3: 0.4484\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0054 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_3: 0.9994 - precision_3: 1.0000 - val_loss: 1.4936 - val_acc: 0.6694 - val_auc: 0.6407 - val_binary_accuracy: 0.6694 - val_recall_3: 0.4471 - val_precision_3: 0.5223\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0104 - acc: 0.9976 - auc: 1.0000 - binary_accuracy: 0.9976 - recall_3: 0.9961 - precision_3: 0.9955 - val_loss: 1.5697 - val_acc: 0.6546 - val_auc: 0.6327 - val_binary_accuracy: 0.6546 - val_recall_3: 0.4892 - val_precision_3: 0.4974\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0110 - acc: 0.9952 - auc: 0.9999 - binary_accuracy: 0.9952 - recall_3: 0.9910 - precision_3: 0.9923 - val_loss: 1.7352 - val_acc: 0.6791 - val_auc: 0.6461 - val_binary_accuracy: 0.6791 - val_recall_3: 0.3796 - val_precision_3: 0.5478\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0054 - acc: 0.9991 - auc: 1.0000 - binary_accuracy: 0.9991 - recall_3: 0.9987 - precision_3: 0.9981 - val_loss: 1.5921 - val_acc: 0.6703 - val_auc: 0.6503 - val_binary_accuracy: 0.6703 - val_recall_3: 0.4280 - val_precision_3: 0.5250\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0043 - acc: 0.9991 - auc: 1.0000 - binary_accuracy: 0.9991 - recall_3: 0.9974 - precision_3: 0.9994 - val_loss: 1.7323 - val_acc: 0.6559 - val_auc: 0.6310 - val_binary_accuracy: 0.6559 - val_recall_3: 0.4140 - val_precision_3: 0.4992\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0013 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 1.7658 - val_acc: 0.6594 - val_auc: 0.6242 - val_binary_accuracy: 0.6594 - val_recall_3: 0.4268 - val_precision_3: 0.5053\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 9.1206e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_3: 1.0000 - precision_3: 1.0000 - val_loss: 1.7790 - val_acc: 0.6585 - val_auc: 0.6302 - val_binary_accuracy: 0.6585 - val_recall_3: 0.4561 - val_precision_3: 0.5035\n",
      "0.6722456812858582\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "702ae742-1b78-4342-b1e7-52669e4a74b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fce99a5b-0bb5-45e7-8d25-91a21daa8d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.6365546218487395 Recall:  0.7142857142857143 Precision:  0.4 F1:  0.5128205128205129\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.6512605042016807 Recall:  0.7142857142857143 Precision:  0.4166666666666667 F1:  0.5263157894736842\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6596638655462186 Recall:  0.6428571428571429 Precision:  0.45 F1:  0.5294117647058824\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6239495798319328 Recall:  0.5714285714285714 Precision:  0.42105263157894735 F1:  0.48484848484848486\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6239495798319328 Recall:  0.5714285714285714 Precision:  0.42105263157894735 F1:  0.48484848484848486\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6533613445378151 Recall:  0.5714285714285714 Precision:  0.47058823529411764 F1:  0.5161290322580646\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6176470588235294 Recall:  0.5 Precision:  0.4375 F1:  0.4666666666666667\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6176470588235294 Recall:  0.5 Precision:  0.4375 F1:  0.4666666666666667\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6323529411764706 Recall:  0.5 Precision:  0.4666666666666667 F1:  0.4827586206896552\n",
      "0.3 0.6596638655462186\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7bfc9ac6-8615-4363-9d44-e02d9ef8081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b719d35e-7c8a-4964-a311-a3ea24e2a1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d71ff922-921b-4aa1-9a3f-c648df9e63a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.375 MSE:  0.625 UAR:  0.5378151260504201 Recall:  0.9285714285714286 Precision:  0.30952380952380953 F1:  0.46428571428571436\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.5 MSE:  0.5 UAR:  0.6260504201680672 Recall:  0.9285714285714286 Precision:  0.3611111111111111 F1:  0.52\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.5416666666666666 MSE:  0.4583333333333333 UAR:  0.6554621848739496 Recall:  0.9285714285714286 Precision:  0.38235294117647056 F1:  0.5416666666666667\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.7584033613445378 Recall:  0.9285714285714286 Precision:  0.48148148148148145 F1:  0.6341463414634146\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.7100840336134454 Recall:  0.7142857142857143 Precision:  0.5 F1:  0.588235294117647\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.569327731092437 Recall:  0.2857142857142857 Precision:  0.4444444444444444 F1:  0.34782608695652173\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.542016806722689 Recall:  0.14285714285714285 Precision:  0.5 F1:  0.22222222222222224\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.75 MSE:  0.25 UAR:  0.5714285714285714 Recall:  0.14285714285714285 Precision:  1.0 F1:  0.25\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5357142857142857 Recall:  0.07142857142857142 Precision:  1.0 F1:  0.13333333333333333\n",
      "0.4 0.7584033613445378\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f656968c-eb67-459d-bff3-9e0a511fca62",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a69355e0-28c9-4082-8f19-c44dfa8bb30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "17e3f1be-5a1c-4ec1-bcef-f251c4259e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "58944233-29d4-4646-a767-03bbf3738b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "52c767ac-0bdc-4ffa-8ced-23183568075c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147,) (147,)\n",
      "(48,) (48,)\n",
      "(195,) (195,)\n",
      "[0 1] [141  54]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.759)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ef05bda7-a42f-42f3-94e7-35535bcdfc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036cbc86-ba85-4e33-9dca-40c7604331c4",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eba90268-6dce-4a4d-8e97-02e1018cb2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_std_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b0e74705-c9df-4fa3-806e-2b956b1922fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "081a003b-c7e0-451b-9d46-0aacbab9f323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 2048) (5631,)\n",
      "(2102, 128, 2048) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0d5e7802-2d68-4435-8fdd-423f05b65e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "82910270-3350-4056-a878-f4416e47ced3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44/44 [==============================] - 4s 61ms/step - loss: 0.3941 - acc: 0.8283 - auc: 0.8757 - binary_accuracy: 0.8283 - recall_4: 0.5595 - precision_4: 0.8162 - val_loss: 0.6503 - val_acc: 0.7174 - val_auc: 0.6976 - val_binary_accuracy: 0.7174 - val_recall_4: 0.5465 - val_precision_4: 0.5314\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1789 - acc: 0.9357 - auc: 0.9808 - binary_accuracy: 0.9357 - recall_4: 0.8535 - precision_4: 0.9286 - val_loss: 0.8561 - val_acc: 0.6422 - val_auc: 0.6693 - val_binary_accuracy: 0.6422 - val_recall_4: 0.5449 - val_precision_4: 0.4277\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.0990 - acc: 0.9663 - auc: 0.9958 - binary_accuracy: 0.9663 - recall_4: 0.9080 - precision_4: 0.9792 - val_loss: 0.9587 - val_acc: 0.6584 - val_auc: 0.6736 - val_binary_accuracy: 0.6584 - val_recall_4: 0.4945 - val_precision_4: 0.4416\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0633 - acc: 0.9845 - auc: 0.9987 - binary_accuracy: 0.9845 - recall_4: 0.9584 - precision_4: 0.9903 - val_loss: 1.0479 - val_acc: 0.6974 - val_auc: 0.6797 - val_binary_accuracy: 0.6974 - val_recall_4: 0.3969 - val_precision_4: 0.4990\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0416 - acc: 0.9906 - auc: 0.9998 - binary_accuracy: 0.9906 - recall_4: 0.9777 - precision_4: 0.9911 - val_loss: 1.2626 - val_acc: 0.7103 - val_auc: 0.6602 - val_binary_accuracy: 0.7103 - val_recall_4: 0.3638 - val_precision_4: 0.5298\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0310 - acc: 0.9940 - auc: 0.9999 - binary_accuracy: 0.9940 - recall_4: 0.9859 - precision_4: 0.9941 - val_loss: 1.2527 - val_acc: 0.7079 - val_auc: 0.6749 - val_binary_accuracy: 0.7079 - val_recall_4: 0.3701 - val_precision_4: 0.5234\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0211 - acc: 0.9972 - auc: 1.0000 - binary_accuracy: 0.9972 - recall_4: 0.9947 - precision_4: 0.9959 - val_loss: 1.3511 - val_acc: 0.7031 - val_auc: 0.6725 - val_binary_accuracy: 0.7031 - val_recall_4: 0.3969 - val_precision_4: 0.5112\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0153 - acc: 0.9986 - auc: 1.0000 - binary_accuracy: 0.9986 - recall_4: 0.9977 - precision_4: 0.9977 - val_loss: 1.4308 - val_acc: 0.7046 - val_auc: 0.6692 - val_binary_accuracy: 0.7046 - val_recall_4: 0.3701 - val_precision_4: 0.5154\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0112 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_4: 0.9988 - precision_4: 0.9988 - val_loss: 1.5544 - val_acc: 0.7098 - val_auc: 0.6693 - val_binary_accuracy: 0.7098 - val_recall_4: 0.3685 - val_precision_4: 0.5282\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0088 - acc: 0.9995 - auc: 1.0000 - binary_accuracy: 0.9995 - recall_4: 0.9988 - precision_4: 0.9994 - val_loss: 1.5280 - val_acc: 0.7108 - val_auc: 0.6753 - val_binary_accuracy: 0.7108 - val_recall_4: 0.3858 - val_precision_4: 0.5292\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0065 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_4: 1.0000 - precision_4: 0.9994 - val_loss: 1.5406 - val_acc: 0.7155 - val_auc: 0.6821 - val_binary_accuracy: 0.7155 - val_recall_4: 0.4094 - val_precision_4: 0.5383\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0056 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_4: 1.0000 - precision_4: 1.0000 - val_loss: 1.6207 - val_acc: 0.7108 - val_auc: 0.6766 - val_binary_accuracy: 0.7108 - val_recall_4: 0.4283 - val_precision_4: 0.5261\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0045 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_4: 1.0000 - precision_4: 1.0000 - val_loss: 1.6638 - val_acc: 0.7122 - val_auc: 0.6743 - val_binary_accuracy: 0.7122 - val_recall_4: 0.4031 - val_precision_4: 0.5311\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0038 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_4: 1.0000 - precision_4: 1.0000 - val_loss: 1.7112 - val_acc: 0.7088 - val_auc: 0.6751 - val_binary_accuracy: 0.7088 - val_recall_4: 0.4063 - val_precision_4: 0.5233\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0030 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_4: 1.0000 - precision_4: 1.0000 - val_loss: 1.7255 - val_acc: 0.7127 - val_auc: 0.6873 - val_binary_accuracy: 0.7127 - val_recall_4: 0.3984 - val_precision_4: 0.5326\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.0026 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_4: 1.0000 - precision_4: 1.0000 - val_loss: 1.7906 - val_acc: 0.7165 - val_auc: 0.6872 - val_binary_accuracy: 0.7165 - val_recall_4: 0.3795 - val_precision_4: 0.5440\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.0023 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_4: 1.0000 - precision_4: 1.0000 - val_loss: 1.8556 - val_acc: 0.7103 - val_auc: 0.6837 - val_binary_accuracy: 0.7103 - val_recall_4: 0.3717 - val_precision_4: 0.5291\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0020 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_4: 1.0000 - precision_4: 1.0000 - val_loss: 1.8321 - val_acc: 0.7131 - val_auc: 0.6842 - val_binary_accuracy: 0.7131 - val_recall_4: 0.3969 - val_precision_4: 0.5339\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0018 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_4: 1.0000 - precision_4: 1.0000 - val_loss: 1.8709 - val_acc: 0.7122 - val_auc: 0.6849 - val_binary_accuracy: 0.7122 - val_recall_4: 0.3937 - val_precision_4: 0.5319\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.0015 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_4: 1.0000 - precision_4: 1.0000 - val_loss: 1.9244 - val_acc: 0.7150 - val_auc: 0.6840 - val_binary_accuracy: 0.7150 - val_recall_4: 0.3780 - val_precision_4: 0.5405\n",
      "0.6503463387489319\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ab0823c3-d0d5-4ac1-85d9-0f872165074d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d13c44c3-6ae8-4c4e-b754-0a499767a691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced Accuracy:  0.75 MSE:  0.25 UAR:  0.6764705882352942 Recall:  0.5 Precision:  0.5833333333333334 F1:  0.5384615384615384\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6197478991596639 Recall:  0.35714285714285715 Precision:  0.5555555555555556 F1:  0.43478260869565216\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced Accuracy:  0.75 MSE:  0.25 UAR:  0.634453781512605 Recall:  0.35714285714285715 Precision:  0.625 F1:  0.45454545454545453\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "0.1 0.6764705882352942\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f56f22e8-9e64-4ffc-8d23-32504224e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ee348feb-81cc-4bea-a738-6ff57ef7fbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0873991c-6685-4894-8afe-e30d95b6d9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.5 MSE:  0.5 UAR:  0.6260504201680672 Recall:  0.9285714285714286 Precision:  0.3611111111111111 F1:  0.52\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.6428571428571428 Recall:  0.7857142857142857 Precision:  0.39285714285714285 F1:  0.5238095238095237\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.6008403361344539 Recall:  0.6428571428571429 Precision:  0.375 F1:  0.4736842105263159\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6890756302521008 Recall:  0.6428571428571429 Precision:  0.5 F1:  0.5625000000000001\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6974789915966386 Recall:  0.5714285714285714 Precision:  0.5714285714285714 F1:  0.5714285714285714\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6260504201680672 Recall:  0.42857142857142855 Precision:  0.5 F1:  0.4615384615384615\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6197478991596639 Recall:  0.35714285714285715 Precision:  0.5555555555555556 F1:  0.43478260869565216\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6134453781512605 Recall:  0.2857142857142857 Precision:  0.6666666666666666 F1:  0.4\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_single_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.592436974789916 Recall:  0.21428571428571427 Precision:  0.75 F1:  0.3333333333333333\n",
      "0.5 0.6974789915966386\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81276529-9ebb-4dac-8e69-8a9e3a7c9046",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9f652128-8e3d-47e8-a2d3-058f7653aa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0dc69551-d50a-46ab-a797-a40c44ff6fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f23b600a-0e37-42e8-8770-487299d53d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 2048) (5631,)\n",
      "(2102, 128, 2048) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a8d1f206-a36b-403f-9a57-3f83dccc5e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_2 (Attention)     (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention_2[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention_2[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a026a1c4-5dc0-4ec2-8be7-01263d9d6ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44/44 [==============================] - 6s 111ms/step - loss: 0.5453 - acc: 0.7906 - auc: 0.8068 - binary_accuracy: 0.7906 - recall_5: 0.5946 - precision_5: 0.6758 - val_loss: 0.6830 - val_acc: 0.6603 - val_auc: 0.6268 - val_binary_accuracy: 0.6603 - val_recall_5: 0.4031 - val_precision_5: 0.4332\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.1889 - acc: 0.9352 - auc: 0.9804 - binary_accuracy: 0.9352 - recall_5: 0.8436 - precision_5: 0.9363 - val_loss: 0.7894 - val_acc: 0.6456 - val_auc: 0.6385 - val_binary_accuracy: 0.6456 - val_recall_5: 0.4331 - val_precision_5: 0.4167\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.1139 - acc: 0.9639 - auc: 0.9934 - binary_accuracy: 0.9639 - recall_5: 0.9203 - precision_5: 0.9591 - val_loss: 0.8956 - val_acc: 0.6618 - val_auc: 0.6308 - val_binary_accuracy: 0.6618 - val_recall_5: 0.3701 - val_precision_5: 0.4304\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0641 - acc: 0.9808 - auc: 0.9984 - binary_accuracy: 0.9808 - recall_5: 0.9543 - precision_5: 0.9819 - val_loss: 1.1442 - val_acc: 0.6598 - val_auc: 0.6061 - val_binary_accuracy: 0.6598 - val_recall_5: 0.3354 - val_precision_5: 0.4209\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0420 - acc: 0.9888 - auc: 0.9994 - binary_accuracy: 0.9888 - recall_5: 0.9754 - precision_5: 0.9875 - val_loss: 1.3030 - val_acc: 0.6346 - val_auc: 0.5862 - val_binary_accuracy: 0.6346 - val_recall_5: 0.3764 - val_precision_5: 0.3912\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0518 - acc: 0.9840 - auc: 0.9979 - binary_accuracy: 0.9840 - recall_5: 0.9678 - precision_5: 0.9793 - val_loss: 1.3257 - val_acc: 0.6760 - val_auc: 0.5927 - val_binary_accuracy: 0.6760 - val_recall_5: 0.3921 - val_precision_5: 0.4577\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 0.0405 - acc: 0.9874 - auc: 0.9990 - binary_accuracy: 0.9874 - recall_5: 0.9760 - precision_5: 0.9823 - val_loss: 1.5190 - val_acc: 0.6803 - val_auc: 0.6062 - val_binary_accuracy: 0.6803 - val_recall_5: 0.3118 - val_precision_5: 0.4573\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0178 - acc: 0.9948 - auc: 0.9999 - binary_accuracy: 0.9948 - recall_5: 0.9877 - precision_5: 0.9953 - val_loss: 1.6097 - val_acc: 0.6537 - val_auc: 0.5952 - val_binary_accuracy: 0.6537 - val_recall_5: 0.3559 - val_precision_5: 0.4147\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 0.0119 - acc: 0.9977 - auc: 1.0000 - binary_accuracy: 0.9977 - recall_5: 0.9941 - precision_5: 0.9982 - val_loss: 1.6691 - val_acc: 0.6389 - val_auc: 0.5965 - val_binary_accuracy: 0.6389 - val_recall_5: 0.3827 - val_precision_5: 0.3984\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 0.0089 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_5: 0.9988 - precision_5: 0.9988 - val_loss: 1.7715 - val_acc: 0.6717 - val_auc: 0.6078 - val_binary_accuracy: 0.6717 - val_recall_5: 0.3307 - val_precision_5: 0.4421\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0065 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_5: 0.9988 - precision_5: 1.0000 - val_loss: 1.7709 - val_acc: 0.6270 - val_auc: 0.5925 - val_binary_accuracy: 0.6270 - val_recall_5: 0.4220 - val_precision_5: 0.3912\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 3s 68ms/step - loss: 0.0059 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_5: 0.9994 - precision_5: 1.0000 - val_loss: 1.7812 - val_acc: 0.6503 - val_auc: 0.6074 - val_binary_accuracy: 0.6503 - val_recall_5: 0.3654 - val_precision_5: 0.4113\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 3s 68ms/step - loss: 0.0039 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_5: 0.9994 - precision_5: 1.0000 - val_loss: 1.8388 - val_acc: 0.6422 - val_auc: 0.6026 - val_binary_accuracy: 0.6422 - val_recall_5: 0.3638 - val_precision_5: 0.3990\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 3s 68ms/step - loss: 0.0032 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_5: 1.0000 - precision_5: 1.0000 - val_loss: 1.8864 - val_acc: 0.6380 - val_auc: 0.5974 - val_binary_accuracy: 0.6380 - val_recall_5: 0.3717 - val_precision_5: 0.3946\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0027 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_5: 1.0000 - precision_5: 1.0000 - val_loss: 1.9557 - val_acc: 0.6608 - val_auc: 0.6027 - val_binary_accuracy: 0.6608 - val_recall_5: 0.3276 - val_precision_5: 0.4211\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0020 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_5: 1.0000 - precision_5: 1.0000 - val_loss: 1.9513 - val_acc: 0.6470 - val_auc: 0.6012 - val_binary_accuracy: 0.6470 - val_recall_5: 0.3449 - val_precision_5: 0.4018\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 3s 68ms/step - loss: 0.0017 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_5: 1.0000 - precision_5: 1.0000 - val_loss: 2.0283 - val_acc: 0.6541 - val_auc: 0.5980 - val_binary_accuracy: 0.6541 - val_recall_5: 0.3323 - val_precision_5: 0.4105\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0015 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_5: 1.0000 - precision_5: 1.0000 - val_loss: 2.0847 - val_acc: 0.6432 - val_auc: 0.5955 - val_binary_accuracy: 0.6432 - val_recall_5: 0.3276 - val_precision_5: 0.3917\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0014 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_5: 1.0000 - precision_5: 1.0000 - val_loss: 2.1263 - val_acc: 0.6622 - val_auc: 0.5987 - val_binary_accuracy: 0.6622 - val_recall_5: 0.3181 - val_precision_5: 0.4217\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 3s 67ms/step - loss: 0.0013 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_5: 1.0000 - precision_5: 1.0000 - val_loss: 2.1336 - val_acc: 0.6418 - val_auc: 0.5940 - val_binary_accuracy: 0.6418 - val_recall_5: 0.3417 - val_precision_5: 0.3931\n",
      "0.6829870939254761\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cdb14140-c92b-4272-a0ea-f595eeeada70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6aff4392-197b-4bbb-b89c-fb21b046c336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6449579831932774 Recall:  0.6428571428571429 Precision:  0.42857142857142855 F1:  0.5142857142857143\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6029411764705883 Recall:  0.5 Precision:  0.4117647058823529 F1:  0.45161290322580644\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced Accuracy:  0.625 MSE:  0.375 UAR:  0.5672268907563025 Recall:  0.42857142857142855 Precision:  0.375 F1:  0.39999999999999997\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced Accuracy:  0.625 MSE:  0.375 UAR:  0.5672268907563025 Recall:  0.42857142857142855 Precision:  0.375 F1:  0.39999999999999997\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5819327731092437 Recall:  0.42857142857142855 Precision:  0.4 F1:  0.4137931034482759\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5819327731092437 Recall:  0.42857142857142855 Precision:  0.4 F1:  0.4137931034482759\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6050420168067226 Recall:  0.35714285714285715 Precision:  0.5 F1:  0.41666666666666663\n",
      "0.1 0.6449579831932774\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b292dbed-e65d-478f-bf59-19de43315826",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d214ac9b-1512-4367-a1e1-ecc8735b6f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8cc07d5d-cdf9-4fee-9a65-f8c8dc8592fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.375 MSE:  0.625 UAR:  0.5378151260504201 Recall:  0.9285714285714286 Precision:  0.30952380952380953 F1:  0.46428571428571436\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.5416666666666666 MSE:  0.4583333333333333 UAR:  0.6554621848739496 Recall:  0.9285714285714286 Precision:  0.38235294117647056 F1:  0.5416666666666667\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.5625 MSE:  0.4375 UAR:  0.6281512605042017 Recall:  0.7857142857142857 Precision:  0.3793103448275862 F1:  0.5116279069767441\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.5625 MSE:  0.4375 UAR:  0.5651260504201681 Recall:  0.5714285714285714 Precision:  0.34782608695652173 F1:  0.4324324324324324\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.5588235294117647 Recall:  0.5 Precision:  0.35 F1:  0.4117647058823529\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.5378151260504201 Recall:  0.42857142857142855 Precision:  0.3333333333333333 F1:  0.375\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5819327731092437 Recall:  0.42857142857142855 Precision:  0.4 F1:  0.4137931034482759\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5777310924369747 Recall:  0.21428571428571427 Precision:  0.6 F1:  0.3157894736842105\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_std_self_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.5714285714285714 Recall:  0.14285714285714285 Precision:  1.0 F1:  0.25\n",
      "0.2 0.6554621848739496\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a70ed6-c182-4a59-9703-ba1cf64aa090",
   "metadata": {},
   "source": [
    "### Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "105112a2-c080-4f99-8c04-8d8e49c3ae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.max\n",
    "stat_name = \"max\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375d9213-e641-4647-93b2-85f48e3d4997",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "95d555a7-9e6f-464a-8655-24d31d2e1bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2757dd90-cdad-4062-af5c-89cd0d9da117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6b4b79fe-40c4-481c-a392-e7b9509f3e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d53790-53a9-49ac-b9d3-4aa4beb7e72f",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4848a5dd-a3ef-40a1-956a-d7e9f619adab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_max_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "932fd504-3080-4ff9-81d4-6bb7222cc219",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4823bafd-f6f1-46fb-8593-fef87b457479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2048) (5449,)\n",
      "(2284, 128, 2048) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "39bc57a4-e15c-47fd-a970-456cf921eccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "17ef6cda-5856-484e-a2c1-ee0e28dd379d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 4s 66ms/step - loss: 0.6302 - acc: 0.7288 - auc: 0.6793 - binary_accuracy: 0.7288 - recall_6: 0.3455 - precision_6: 0.5396 - val_loss: 0.6465 - val_acc: 0.5898 - val_auc: 0.6219 - val_binary_accuracy: 0.5898 - val_recall_6: 0.0994 - val_precision_6: 0.2532\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.3227 - acc: 0.8873 - auc: 0.9345 - binary_accuracy: 0.8873 - recall_6: 0.6808 - precision_6: 0.9006 - val_loss: 0.7450 - val_acc: 0.6116 - val_auc: 0.6218 - val_binary_accuracy: 0.6116 - val_recall_6: 0.1465 - val_precision_6: 0.3464\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.2100 - acc: 0.9312 - auc: 0.9718 - binary_accuracy: 0.9312 - recall_6: 0.8247 - precision_6: 0.9264 - val_loss: 0.8559 - val_acc: 0.6620 - val_auc: 0.5774 - val_binary_accuracy: 0.6620 - val_recall_6: 0.1631 - val_precision_6: 0.5267\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.1303 - acc: 0.9631 - auc: 0.9936 - binary_accuracy: 0.9631 - recall_6: 0.8927 - precision_6: 0.9761 - val_loss: 0.8566 - val_acc: 0.6016 - val_auc: 0.6039 - val_binary_accuracy: 0.6016 - val_recall_6: 0.2293 - val_precision_6: 0.3711\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.0752 - acc: 0.9899 - auc: 0.9996 - binary_accuracy: 0.9899 - recall_6: 0.9705 - precision_6: 0.9941 - val_loss: 0.9253 - val_acc: 0.5959 - val_auc: 0.6041 - val_binary_accuracy: 0.5959 - val_recall_6: 0.2968 - val_precision_6: 0.3858\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0492 - acc: 0.9963 - auc: 1.0000 - binary_accuracy: 0.9963 - recall_6: 0.9884 - precision_6: 0.9987 - val_loss: 1.2670 - val_acc: 0.6642 - val_auc: 0.5615 - val_binary_accuracy: 0.6642 - val_recall_6: 0.1465 - val_precision_6: 0.5425\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0304 - acc: 0.9991 - auc: 1.0000 - binary_accuracy: 0.9991 - recall_6: 0.9974 - precision_6: 0.9994 - val_loss: 1.1441 - val_acc: 0.5788 - val_auc: 0.5911 - val_binary_accuracy: 0.5788 - val_recall_6: 0.2446 - val_precision_6: 0.3422\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0203 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_6: 0.9994 - precision_6: 1.0000 - val_loss: 1.2192 - val_acc: 0.5823 - val_auc: 0.5918 - val_binary_accuracy: 0.5823 - val_recall_6: 0.2624 - val_precision_6: 0.3546\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0139 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_6: 0.9994 - precision_6: 1.0000 - val_loss: 1.2721 - val_acc: 0.5954 - val_auc: 0.5926 - val_binary_accuracy: 0.5954 - val_recall_6: 0.3032 - val_precision_6: 0.3870\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0106 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_6: 1.0000 - precision_6: 1.0000 - val_loss: 1.4021 - val_acc: 0.5867 - val_auc: 0.5811 - val_binary_accuracy: 0.5867 - val_recall_6: 0.2318 - val_precision_6: 0.3480\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0082 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_6: 1.0000 - precision_6: 1.0000 - val_loss: 1.4052 - val_acc: 0.5906 - val_auc: 0.5857 - val_binary_accuracy: 0.5906 - val_recall_6: 0.2777 - val_precision_6: 0.3720\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.0069 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_6: 1.0000 - precision_6: 1.0000 - val_loss: 1.4921 - val_acc: 0.5863 - val_auc: 0.5821 - val_binary_accuracy: 0.5863 - val_recall_6: 0.2510 - val_precision_6: 0.3556\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0053 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_6: 1.0000 - precision_6: 1.0000 - val_loss: 1.4963 - val_acc: 0.6025 - val_auc: 0.5866 - val_binary_accuracy: 0.6025 - val_recall_6: 0.2930 - val_precision_6: 0.3945\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.0044 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_6: 1.0000 - precision_6: 1.0000 - val_loss: 1.5591 - val_acc: 0.5963 - val_auc: 0.5850 - val_binary_accuracy: 0.5963 - val_recall_6: 0.2637 - val_precision_6: 0.3757\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.0038 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_6: 1.0000 - precision_6: 1.0000 - val_loss: 1.5871 - val_acc: 0.6042 - val_auc: 0.5888 - val_binary_accuracy: 0.6042 - val_recall_6: 0.2841 - val_precision_6: 0.3947\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0032 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_6: 1.0000 - precision_6: 1.0000 - val_loss: 1.6706 - val_acc: 0.6033 - val_auc: 0.5825 - val_binary_accuracy: 0.6033 - val_recall_6: 0.2382 - val_precision_6: 0.3778\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0027 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_6: 1.0000 - precision_6: 1.0000 - val_loss: 1.7297 - val_acc: 0.6033 - val_auc: 0.5743 - val_binary_accuracy: 0.6033 - val_recall_6: 0.2255 - val_precision_6: 0.3726\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.0024 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_6: 1.0000 - precision_6: 1.0000 - val_loss: 1.6779 - val_acc: 0.6130 - val_auc: 0.5879 - val_binary_accuracy: 0.6130 - val_recall_6: 0.3159 - val_precision_6: 0.4168\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.0021 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_6: 1.0000 - precision_6: 1.0000 - val_loss: 1.7371 - val_acc: 0.6081 - val_auc: 0.5828 - val_binary_accuracy: 0.6081 - val_recall_6: 0.2688 - val_precision_6: 0.3966\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.0019 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_6: 1.0000 - precision_6: 1.0000 - val_loss: 1.7727 - val_acc: 0.6095 - val_auc: 0.5803 - val_binary_accuracy: 0.6095 - val_recall_6: 0.2611 - val_precision_6: 0.3965\n",
      "0.6465309262275696\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "da4a1ad4-f7d3-40ca-baf0-75ea6b906d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b69305da-d50b-42eb-9c14-33f2efce6188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional Accuracy:  0.5625 MSE:  0.4375 UAR:  0.5441176470588236 Recall:  0.5 Precision:  0.3333333333333333 F1:  0.4\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.5378151260504201 Recall:  0.42857142857142855 Precision:  0.3333333333333333 F1:  0.375\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5315126050420168 Recall:  0.35714285714285715 Precision:  0.3333333333333333 F1:  0.3448275862068965\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.546218487394958 Recall:  0.35714285714285715 Precision:  0.35714285714285715 F1:  0.35714285714285715\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5399159663865546 Recall:  0.2857142857142857 Precision:  0.36363636363636365 F1:  0.32\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.5042016806722689 Recall:  0.21428571428571427 Precision:  0.3 F1:  0.25\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.4831932773109243 Recall:  0.14285714285714285 Precision:  0.25 F1:  0.18181818181818182\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5126050420168067 Recall:  0.14285714285714285 Precision:  0.3333333333333333 F1:  0.2\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5567226890756303 Recall:  0.14285714285714285 Precision:  0.6666666666666666 F1:  0.23529411764705882\n",
      "0.9 0.5567226890756303\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5cd6a93a-db61-44cc-8680-a63c63cc7316",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "15ab486a-c60b-43fc-86b3-57eab5c44bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d1d45959-bd25-4f72-81c7-6761d2bb8581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.3125 MSE:  0.6875 UAR:  0.5147058823529411 Recall:  1.0 Precision:  0.2978723404255319 F1:  0.45901639344262296\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.5208333333333334 MSE:  0.4791666666666667 UAR:  0.6407563025210085 Recall:  0.9285714285714286 Precision:  0.37142857142857144 F1:  0.5306122448979592\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.5625 MSE:  0.4375 UAR:  0.5441176470588236 Recall:  0.5 Precision:  0.3333333333333333 F1:  0.4\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5336134453781513 Recall:  0.21428571428571427 Precision:  0.375 F1:  0.2727272727272727\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.49159663865546216 Recall:  0.07142857142857142 Precision:  0.25 F1:  0.11111111111111112\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5063025210084033 Recall:  0.07142857142857142 Precision:  0.3333333333333333 F1:  0.11764705882352941\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.4852941176470588 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.2 0.6407563025210085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dad4a7-4195-48d3-8082-279e8967d21d",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8900bb06-b9a4-4ab2-af3f-f675710701ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_max_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "56b2c73b-8a37-4792-a7bd-476959fe290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2f833da7-7cf8-4efe-8cac-11a3c49488a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 2048) (5449,)\n",
      "(2284, 128, 2048) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "217780ed-a2cb-4a9f-8823-a4e4ca3a9eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_3 (Attention)     (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention_3[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention_3[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "761bdab9-80f1-4ff0-b535-e131642aaecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 110ms/step - loss: 3.1838 - acc: 0.6818 - auc: 0.6361 - binary_accuracy: 0.6818 - recall_7: 0.4483 - precision_7: 0.4437 - val_loss: 1.0201 - val_acc: 0.6502 - val_auc: 0.6093 - val_binary_accuracy: 0.6502 - val_recall_7: 0.1172 - val_precision_7: 0.4646\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.3023 - acc: 0.8789 - auc: 0.9268 - binary_accuracy: 0.8789 - recall_7: 0.7405 - precision_7: 0.8183 - val_loss: 0.7808 - val_acc: 0.6467 - val_auc: 0.5626 - val_binary_accuracy: 0.6467 - val_recall_7: 0.3146 - val_precision_7: 0.4787\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.1850 - acc: 0.9383 - auc: 0.9809 - binary_accuracy: 0.9383 - recall_7: 0.8504 - precision_7: 0.9278 - val_loss: 0.8676 - val_acc: 0.6454 - val_auc: 0.5438 - val_binary_accuracy: 0.6454 - val_recall_7: 0.1885 - val_precision_7: 0.4611\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.1295 - acc: 0.9659 - auc: 0.9946 - binary_accuracy: 0.9659 - recall_7: 0.9146 - precision_7: 0.9641 - val_loss: 0.9136 - val_acc: 0.6300 - val_auc: 0.5597 - val_binary_accuracy: 0.6300 - val_recall_7: 0.3006 - val_precision_7: 0.4436\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0841 - acc: 0.9846 - auc: 0.9989 - binary_accuracy: 0.9846 - recall_7: 0.9634 - precision_7: 0.9823 - val_loss: 1.0994 - val_acc: 0.6327 - val_auc: 0.5229 - val_binary_accuracy: 0.6327 - val_recall_7: 0.1898 - val_precision_7: 0.4233\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0565 - acc: 0.9941 - auc: 0.9998 - binary_accuracy: 0.9941 - recall_7: 0.9839 - precision_7: 0.9955 - val_loss: 1.0483 - val_acc: 0.5613 - val_auc: 0.5497 - val_binary_accuracy: 0.5613 - val_recall_7: 0.3452 - val_precision_7: 0.3570\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0442 - acc: 0.9965 - auc: 0.9998 - binary_accuracy: 0.9965 - recall_7: 0.9917 - precision_7: 0.9961 - val_loss: 1.3385 - val_acc: 0.6375 - val_auc: 0.5132 - val_binary_accuracy: 0.6375 - val_recall_7: 0.2166 - val_precision_7: 0.4439\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0341 - acc: 0.9972 - auc: 0.9998 - binary_accuracy: 0.9972 - recall_7: 0.9968 - precision_7: 0.9936 - val_loss: 1.1952 - val_acc: 0.5736 - val_auc: 0.5440 - val_binary_accuracy: 0.5736 - val_recall_7: 0.2675 - val_precision_7: 0.3448\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0222 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_7: 0.9994 - precision_7: 0.9981 - val_loss: 1.3136 - val_acc: 0.5968 - val_auc: 0.5343 - val_binary_accuracy: 0.5968 - val_recall_7: 0.2561 - val_precision_7: 0.3736\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0168 - acc: 0.9989 - auc: 1.0000 - binary_accuracy: 0.9989 - recall_7: 0.9994 - precision_7: 0.9968 - val_loss: 1.3898 - val_acc: 0.6046 - val_auc: 0.5333 - val_binary_accuracy: 0.6046 - val_recall_7: 0.2459 - val_precision_7: 0.3829\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0111 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_7: 0.9994 - precision_7: 0.9994 - val_loss: 1.3922 - val_acc: 0.5718 - val_auc: 0.5321 - val_binary_accuracy: 0.5718 - val_recall_7: 0.2662 - val_precision_7: 0.3421\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0092 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_7: 1.0000 - precision_7: 0.9994 - val_loss: 1.5273 - val_acc: 0.5976 - val_auc: 0.5435 - val_binary_accuracy: 0.5976 - val_recall_7: 0.2357 - val_precision_7: 0.3671\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0076 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_7: 1.0000 - precision_7: 0.9994 - val_loss: 1.4526 - val_acc: 0.5661 - val_auc: 0.5365 - val_binary_accuracy: 0.5661 - val_recall_7: 0.2764 - val_precision_7: 0.3391\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0062 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_7: 1.0000 - precision_7: 0.9994 - val_loss: 1.5274 - val_acc: 0.5648 - val_auc: 0.5247 - val_binary_accuracy: 0.5648 - val_recall_7: 0.2713 - val_precision_7: 0.3354\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0051 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_7: 1.0000 - precision_7: 0.9994 - val_loss: 1.6340 - val_acc: 0.5836 - val_auc: 0.5202 - val_binary_accuracy: 0.5836 - val_recall_7: 0.2586 - val_precision_7: 0.3549\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0052 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_7: 0.9994 - precision_7: 0.9994 - val_loss: 1.7369 - val_acc: 0.5902 - val_auc: 0.5139 - val_binary_accuracy: 0.5902 - val_recall_7: 0.2497 - val_precision_7: 0.3610\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0037 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_7: 1.0000 - precision_7: 1.0000 - val_loss: 1.6406 - val_acc: 0.5644 - val_auc: 0.5190 - val_binary_accuracy: 0.5644 - val_recall_7: 0.2713 - val_precision_7: 0.3349\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0030 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_7: 1.0000 - precision_7: 1.0000 - val_loss: 1.7172 - val_acc: 0.5788 - val_auc: 0.5145 - val_binary_accuracy: 0.5788 - val_recall_7: 0.2675 - val_precision_7: 0.3518\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0026 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_7: 1.0000 - precision_7: 1.0000 - val_loss: 1.7813 - val_acc: 0.5771 - val_auc: 0.5053 - val_binary_accuracy: 0.5771 - val_recall_7: 0.2637 - val_precision_7: 0.3479\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0023 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_7: 1.0000 - precision_7: 1.0000 - val_loss: 1.7356 - val_acc: 0.5652 - val_auc: 0.5139 - val_binary_accuracy: 0.5652 - val_recall_7: 0.2713 - val_precision_7: 0.3360\n",
      "0.7807735204696655\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "71ced305-d4bb-4028-afe5-30da4f5cfdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a00bb3b6-adfc-42dd-bd86-5745803a78eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional Accuracy:  0.5625 MSE:  0.4375 UAR:  0.5861344537815126 Recall:  0.6428571428571429 Precision:  0.36 F1:  0.4615384615384615\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.6302521008403361 Recall:  0.6428571428571429 Precision:  0.4090909090909091 F1:  0.5000000000000001\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5525210084033614 Recall:  0.42857142857142855 Precision:  0.35294117647058826 F1:  0.3870967741935484\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.5672268907563025 Recall:  0.42857142857142855 Precision:  0.375 F1:  0.39999999999999997\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.5672268907563025 Recall:  0.42857142857142855 Precision:  0.375 F1:  0.39999999999999997\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.4957983193277311 Recall:  0.2857142857142857 Precision:  0.2857142857142857 F1:  0.2857142857142857\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5105042016806722 Recall:  0.2857142857142857 Precision:  0.3076923076923077 F1:  0.29629629629629634\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional Accuracy:  0.625 MSE:  0.375 UAR:  0.5252100840336134 Recall:  0.2857142857142857 Precision:  0.3333333333333333 F1:  0.30769230769230765\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5399159663865546 Recall:  0.2857142857142857 Precision:  0.36363636363636365 F1:  0.32\n",
      "0.2 0.6302521008403361\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "231f46bd-cc16-4db5-9fee-dbc158caaa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "badb5173-d967-4b2a-aee1-75b2f5bdd295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d16209ac-98c6-4acc-ae5d-b44054a45b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.3541666666666667 MSE:  0.6458333333333334 UAR:  0.5441176470588235 Recall:  1.0 Precision:  0.3111111111111111 F1:  0.4745762711864407\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.375 MSE:  0.625 UAR:  0.5168067226890756 Recall:  0.8571428571428571 Precision:  0.3 F1:  0.4444444444444444\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.4583333333333333 MSE:  0.5416666666666666 UAR:  0.5756302521008403 Recall:  0.8571428571428571 Precision:  0.3333333333333333 F1:  0.48\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.625 MSE:  0.375 UAR:  0.6302521008403361 Recall:  0.6428571428571429 Precision:  0.4090909090909091 F1:  0.5000000000000001\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6617647058823529 Recall:  0.5 Precision:  0.5384615384615384 F1:  0.5185185185185186\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6491596638655462 Recall:  0.35714285714285715 Precision:  0.7142857142857143 F1:  0.4761904761904762\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6491596638655462 Recall:  0.35714285714285715 Precision:  0.7142857142857143 F1:  0.4761904761904762\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5567226890756303 Recall:  0.14285714285714285 Precision:  0.6666666666666666 F1:  0.23529411764705882\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5357142857142857 Recall:  0.07142857142857142 Precision:  1.0 F1:  0.13333333333333333\n",
      "0.5 0.6617647058823529\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5427606c-8791-4339-9599-e124dd3f164b",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "825b34f3-a700-48a6-8386-a07c1a3ff565",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "570cc58d-61f6-4f83-9c2a-76b0f79a0888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dd646970-fcb2-475c-9c2e-54b6adf5658f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8e9d270d-ebdb-49f6-ac6a-cf9648f32337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147,) (147,)\n",
      "(48,) (48,)\n",
      "(195,) (195,)\n",
      "[0 1] [141  54]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.759)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f140789c-4ac7-4971-82bf-857727fcbb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087a013b-0d41-4f23-85d7-9d70b297c638",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9abf70bd-8e74-4a12-8645-8e7caec10f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_max_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "41b19e76-1b79-412a-aa91-f52f6024c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d316180c-1da7-4716-93ae-8f3e809e9a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 2048) (5631,)\n",
      "(2102, 128, 2048) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ff4752f0-93d9-416d-970b-1bb0a9fbe0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7db1e610-7725-4ba0-904d-12ab6fdcda05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44/44 [==============================] - 4s 61ms/step - loss: 0.6190 - acc: 0.7223 - auc: 0.7111 - binary_accuracy: 0.7223 - recall_8: 0.3849 - precision_8: 0.5611 - val_loss: 0.6488 - val_acc: 0.6151 - val_auc: 0.5859 - val_binary_accuracy: 0.6151 - val_recall_8: 0.0945 - val_precision_8: 0.2041\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.3018 - acc: 0.8863 - auc: 0.9412 - binary_accuracy: 0.8863 - recall_8: 0.7036 - precision_8: 0.8996 - val_loss: 0.6827 - val_acc: 0.6813 - val_auc: 0.6146 - val_binary_accuracy: 0.6813 - val_recall_8: 0.3638 - val_precision_8: 0.4648\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.1704 - acc: 0.9533 - auc: 0.9885 - binary_accuracy: 0.9533 - recall_8: 0.8735 - precision_8: 0.9694 - val_loss: 0.8436 - val_acc: 0.6518 - val_auc: 0.6007 - val_binary_accuracy: 0.6518 - val_recall_8: 0.3370 - val_precision_8: 0.4076\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0926 - acc: 0.9792 - auc: 0.9988 - binary_accuracy: 0.9792 - recall_8: 0.9361 - precision_8: 0.9950 - val_loss: 0.9732 - val_acc: 0.6427 - val_auc: 0.6070 - val_binary_accuracy: 0.6427 - val_recall_8: 0.4331 - val_precision_8: 0.4129\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.0518 - acc: 0.9959 - auc: 0.9999 - binary_accuracy: 0.9959 - recall_8: 0.9877 - precision_8: 0.9988 - val_loss: 1.1110 - val_acc: 0.6365 - val_auc: 0.6158 - val_binary_accuracy: 0.6365 - val_recall_8: 0.4441 - val_precision_8: 0.4069\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0308 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_8: 0.9982 - precision_8: 0.9994 - val_loss: 1.1762 - val_acc: 0.6532 - val_auc: 0.6093 - val_binary_accuracy: 0.6532 - val_recall_8: 0.4205 - val_precision_8: 0.4252\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0200 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_8: 0.9988 - precision_8: 1.0000 - val_loss: 1.2922 - val_acc: 0.6427 - val_auc: 0.6139 - val_binary_accuracy: 0.6427 - val_recall_8: 0.4409 - val_precision_8: 0.4142\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0138 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_8: 0.9994 - precision_8: 1.0000 - val_loss: 1.3740 - val_acc: 0.6522 - val_auc: 0.6177 - val_binary_accuracy: 0.6522 - val_recall_8: 0.4394 - val_precision_8: 0.4266\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0099 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_8: 1.0000 - precision_8: 1.0000 - val_loss: 1.4435 - val_acc: 0.6494 - val_auc: 0.6218 - val_binary_accuracy: 0.6494 - val_recall_8: 0.4346 - val_precision_8: 0.4220\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.0072 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_8: 0.9994 - precision_8: 1.0000 - val_loss: 1.4866 - val_acc: 0.6441 - val_auc: 0.6290 - val_binary_accuracy: 0.6441 - val_recall_8: 0.4425 - val_precision_8: 0.4163\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.0059 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_8: 0.9994 - precision_8: 1.0000 - val_loss: 1.5485 - val_acc: 0.6437 - val_auc: 0.6244 - val_binary_accuracy: 0.6437 - val_recall_8: 0.4409 - val_precision_8: 0.4154\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0045 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_8: 1.0000 - precision_8: 1.0000 - val_loss: 1.5932 - val_acc: 0.6427 - val_auc: 0.6274 - val_binary_accuracy: 0.6427 - val_recall_8: 0.4425 - val_precision_8: 0.4145\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.0038 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_8: 0.9994 - precision_8: 1.0000 - val_loss: 1.6401 - val_acc: 0.6494 - val_auc: 0.6197 - val_binary_accuracy: 0.6494 - val_recall_8: 0.4173 - val_precision_8: 0.4193\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 1s 28ms/step - loss: 0.0031 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_8: 1.0000 - precision_8: 1.0000 - val_loss: 1.6849 - val_acc: 0.6503 - val_auc: 0.6119 - val_binary_accuracy: 0.6503 - val_recall_8: 0.4094 - val_precision_8: 0.4194\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0027 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_8: 1.0000 - precision_8: 1.0000 - val_loss: 1.7103 - val_acc: 0.6503 - val_auc: 0.6214 - val_binary_accuracy: 0.6503 - val_recall_8: 0.4283 - val_precision_8: 0.4224\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0022 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_8: 1.0000 - precision_8: 1.0000 - val_loss: 1.7474 - val_acc: 0.6475 - val_auc: 0.6247 - val_binary_accuracy: 0.6475 - val_recall_8: 0.4378 - val_precision_8: 0.4199\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0019 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_8: 1.0000 - precision_8: 1.0000 - val_loss: 1.7846 - val_acc: 0.6484 - val_auc: 0.6234 - val_binary_accuracy: 0.6484 - val_recall_8: 0.4378 - val_precision_8: 0.4212\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0017 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_8: 1.0000 - precision_8: 1.0000 - val_loss: 1.8122 - val_acc: 0.6508 - val_auc: 0.6180 - val_binary_accuracy: 0.6508 - val_recall_8: 0.4047 - val_precision_8: 0.4192\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0015 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_8: 1.0000 - precision_8: 1.0000 - val_loss: 1.8381 - val_acc: 0.6480 - val_auc: 0.6205 - val_binary_accuracy: 0.6480 - val_recall_8: 0.4378 - val_precision_8: 0.4206\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.0013 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_8: 1.0000 - precision_8: 1.0000 - val_loss: 1.8633 - val_acc: 0.6518 - val_auc: 0.6187 - val_binary_accuracy: 0.6518 - val_recall_8: 0.4299 - val_precision_8: 0.4246\n",
      "0.6487721800804138\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b1fb2825-af62-4d99-a046-d5f4c77afec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7408d730-891d-4822-8224-986e040585fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6176470588235294 Recall:  0.5 Precision:  0.4375 F1:  0.4666666666666667\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5819327731092437 Recall:  0.42857142857142855 Precision:  0.4 F1:  0.4137931034482759\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5819327731092437 Recall:  0.42857142857142855 Precision:  0.4 F1:  0.4137931034482759\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.611344537815126 Recall:  0.42857142857142855 Precision:  0.46153846153846156 F1:  0.4444444444444445\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.611344537815126 Recall:  0.42857142857142855 Precision:  0.46153846153846156 F1:  0.4444444444444445\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5756302521008403 Recall:  0.35714285714285715 Precision:  0.4166666666666667 F1:  0.3846153846153846\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5903361344537815 Recall:  0.35714285714285715 Precision:  0.45454545454545453 F1:  0.4\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.569327731092437 Recall:  0.2857142857142857 Precision:  0.4444444444444444 F1:  0.34782608695652173\n",
      "0.1 0.6176470588235294\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "484af713-90c0-495d-a9c8-7ce2b63f6c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "15782efe-e18e-4b63-846f-4c172f6c8035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5e8ab221-b93c-4405-8336-fbc607fe2dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.4166666666666667 MSE:  0.5833333333333334 UAR:  0.5882352941176471 Recall:  1.0 Precision:  0.3333333333333333 F1:  0.5\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.5 MSE:  0.5 UAR:  0.5840336134453781 Recall:  0.7857142857142857 Precision:  0.34375 F1:  0.4782608695652174\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.5 MSE:  0.5 UAR:  0.45798319327731096 Recall:  0.35714285714285715 Precision:  0.25 F1:  0.2941176470588235\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.4747899159663866 Recall:  0.21428571428571427 Precision:  0.25 F1:  0.23076923076923075\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5126050420168067 Recall:  0.14285714285714285 Precision:  0.3333333333333333 F1:  0.2\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5063025210084033 Recall:  0.07142857142857142 Precision:  0.3333333333333333 F1:  0.11764705882352941\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5063025210084033 Recall:  0.07142857142857142 Precision:  0.3333333333333333 F1:  0.11764705882352941\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_single_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.5882352941176471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7aadfe-7d79-4642-b62b-b10a159b1f3a",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0029b249-9723-4469-ac6a-4451eb6debe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_max_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ad95ca45-be66-4a87-9bde-0fcce4110465",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "00619164-4fec-4efd-a4b3-e7e86b24412e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 2048) (5631,)\n",
      "(2102, 128, 2048) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "15d3b104-d439-47a5-8438-3e4b81cfa2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2048)           4194304   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_4 (Attention)     (None, None, 2048)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['attention_4[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['attention_4[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 1)                    2049      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8392706 (32.02 MB)\n",
      "Trainable params: 8392706 (32.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c3222580-4fdc-4fa5-9e0e-437eb20a67a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44/44 [==============================] - 6s 108ms/step - loss: 1.0655 - acc: 0.7862 - auc: 0.7845 - binary_accuracy: 0.7862 - recall_9: 0.6233 - precision_9: 0.6548 - val_loss: 0.8465 - val_acc: 0.6089 - val_auc: 0.5998 - val_binary_accuracy: 0.6089 - val_recall_9: 0.3543 - val_precision_9: 0.3532\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 0.1544 - acc: 0.9494 - auc: 0.9865 - binary_accuracy: 0.9494 - recall_9: 0.8822 - precision_9: 0.9472 - val_loss: 0.9989 - val_acc: 0.5966 - val_auc: 0.6011 - val_binary_accuracy: 0.5966 - val_recall_9: 0.1969 - val_precision_9: 0.2700\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 0.0840 - acc: 0.9805 - auc: 0.9981 - binary_accuracy: 0.9805 - recall_9: 0.9514 - precision_9: 0.9836 - val_loss: 1.2105 - val_acc: 0.5861 - val_auc: 0.5777 - val_binary_accuracy: 0.5861 - val_recall_9: 0.1591 - val_precision_9: 0.2311\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0461 - acc: 0.9954 - auc: 0.9999 - binary_accuracy: 0.9954 - recall_9: 0.9912 - precision_9: 0.9935 - val_loss: 1.4838 - val_acc: 0.5875 - val_auc: 0.5504 - val_binary_accuracy: 0.5875 - val_recall_9: 0.0740 - val_precision_9: 0.1442\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 0.0350 - acc: 0.9941 - auc: 0.9999 - binary_accuracy: 0.9941 - recall_9: 0.9854 - precision_9: 0.9953 - val_loss: 1.5506 - val_acc: 0.5699 - val_auc: 0.5473 - val_binary_accuracy: 0.5699 - val_recall_9: 0.1386 - val_precision_9: 0.1978\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 3s 67ms/step - loss: 0.0155 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 1.7683 - val_acc: 0.5604 - val_auc: 0.5318 - val_binary_accuracy: 0.5604 - val_recall_9: 0.0772 - val_precision_9: 0.1266\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0105 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 1.7934 - val_acc: 0.5690 - val_auc: 0.5314 - val_binary_accuracy: 0.5690 - val_recall_9: 0.1339 - val_precision_9: 0.1927\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0075 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 1.8658 - val_acc: 0.5633 - val_auc: 0.5351 - val_binary_accuracy: 0.5633 - val_recall_9: 0.1150 - val_precision_9: 0.1702\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0059 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 1.9428 - val_acc: 0.5652 - val_auc: 0.5256 - val_binary_accuracy: 0.5652 - val_recall_9: 0.1291 - val_precision_9: 0.1851\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0046 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 1.9782 - val_acc: 0.5628 - val_auc: 0.5187 - val_binary_accuracy: 0.5628 - val_recall_9: 0.1150 - val_precision_9: 0.1698\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0038 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 1.9786 - val_acc: 0.5747 - val_auc: 0.5427 - val_binary_accuracy: 0.5747 - val_recall_9: 0.2173 - val_precision_9: 0.2579\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0033 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 2.0945 - val_acc: 0.5614 - val_auc: 0.5263 - val_binary_accuracy: 0.5614 - val_recall_9: 0.1260 - val_precision_9: 0.1790\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 0.0027 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 2.1326 - val_acc: 0.5728 - val_auc: 0.5294 - val_binary_accuracy: 0.5728 - val_recall_9: 0.1732 - val_precision_9: 0.2277\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0022 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 2.2374 - val_acc: 0.5599 - val_auc: 0.5158 - val_binary_accuracy: 0.5599 - val_recall_9: 0.1118 - val_precision_9: 0.1644\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0018 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 2.2695 - val_acc: 0.5657 - val_auc: 0.5194 - val_binary_accuracy: 0.5657 - val_recall_9: 0.1354 - val_precision_9: 0.1911\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0016 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 2.3616 - val_acc: 0.5623 - val_auc: 0.5060 - val_binary_accuracy: 0.5623 - val_recall_9: 0.1181 - val_precision_9: 0.1724\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0014 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 2.3799 - val_acc: 0.5642 - val_auc: 0.5131 - val_binary_accuracy: 0.5642 - val_recall_9: 0.1291 - val_precision_9: 0.1843\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.0012 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 2.4077 - val_acc: 0.5699 - val_auc: 0.5136 - val_binary_accuracy: 0.5699 - val_recall_9: 0.1512 - val_precision_9: 0.2082\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 0.0010 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 2.4676 - val_acc: 0.5618 - val_auc: 0.5056 - val_binary_accuracy: 0.5618 - val_recall_9: 0.1197 - val_precision_9: 0.1735\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 3s 67ms/step - loss: 9.2233e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_9: 1.0000 - precision_9: 1.0000 - val_loss: 2.4901 - val_acc: 0.5671 - val_auc: 0.5080 - val_binary_accuracy: 0.5671 - val_recall_9: 0.1386 - val_precision_9: 0.1951\n",
      "0.8465239405632019\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "abe8cdf3-c0d4-421b-8d87-754744dcc064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e746f185-2f42-4e22-87c9-1ea4e38051cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5399159663865546 Recall:  0.2857142857142857 Precision:  0.36363636363636365 F1:  0.32\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.4684873949579832 Recall:  0.14285714285714285 Precision:  0.2222222222222222 F1:  0.17391304347826086\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.4684873949579832 Recall:  0.14285714285714285 Precision:  0.2222222222222222 F1:  0.17391304347826086\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.4684873949579832 Recall:  0.14285714285714285 Precision:  0.2222222222222222 F1:  0.17391304347826086\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.4684873949579832 Recall:  0.14285714285714285 Precision:  0.2222222222222222 F1:  0.17391304347826086\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.4684873949579832 Recall:  0.14285714285714285 Precision:  0.2222222222222222 F1:  0.17391304347826086\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.4474789915966386 Recall:  0.07142857142857142 Precision:  0.14285714285714285 F1:  0.09523809523809523\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced Accuracy:  0.625 MSE:  0.375 UAR:  0.4621848739495798 Recall:  0.07142857142857142 Precision:  0.16666666666666666 F1:  0.1\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.476890756302521 Recall:  0.07142857142857142 Precision:  0.2 F1:  0.10526315789473682\n",
      "0.1 0.5399159663865546\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b01f3f07-eff4-4a6e-9548-b306629677eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "83647194-c352-4844-a159-890145ed137d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "324c8ad9-a58c-46cc-b953-0c4c6e7f2402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.4791666666666667 MSE:  0.5208333333333334 UAR:  0.5903361344537815 Recall:  0.8571428571428571 Precision:  0.34285714285714286 F1:  0.4897959183673469\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.5208333333333334 MSE:  0.4791666666666667 UAR:  0.5987394957983193 Recall:  0.7857142857142857 Precision:  0.3548387096774194 F1:  0.48888888888888893\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.657563025210084 Recall:  0.7857142857142857 Precision:  0.4074074074074074 F1:  0.5365853658536585\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6239495798319328 Recall:  0.5714285714285714 Precision:  0.42105263157894735 F1:  0.48484848484848486\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.625 MSE:  0.375 UAR:  0.546218487394958 Recall:  0.35714285714285715 Precision:  0.35714285714285715 F1:  0.35714285714285715\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5609243697478992 Recall:  0.35714285714285715 Precision:  0.38461538461538464 F1:  0.3703703703703704\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5903361344537815 Recall:  0.35714285714285715 Precision:  0.45454545454545453 F1:  0.4\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5483193277310924 Recall:  0.21428571428571427 Precision:  0.42857142857142855 F1:  0.2857142857142857\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_max_self_attention_balanced_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.45588235294117646 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.3 0.657563025210084\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda36c01-50ce-4528-8b49-0acdeab5f377",
   "metadata": {},
   "source": [
    "### STAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70effef6-d8d6-400b-8e07-cc42331388f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = compute_descriptor\n",
    "stat_name = \"STAT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b51565-821f-4bef-a206-842230dac71a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "450698b7-20bd-4fff-ace8-fa15ad9c9a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a9040385-d454-44fa-846f-6aaecfc2433d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c6e409d7-4f1e-423b-8873-f1805a4efbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb17a33b-087d-4eaf-b2b8-dc948a8f17f7",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ac333c5a-f95b-4244-b6ee-1b5f8678b370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7c453eb0-6306-44ea-bc53-31f64e2650b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "85661bc2-7aa6-431c-a57c-2485b243599b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 3072) (5449,)\n",
      "(2284, 128, 3072) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "dc5a9f59-1cba-4993-a80d-7b45519bb2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1573376   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1576962 (6.02 MB)\n",
      "Trainable params: 1576962 (6.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "55dd90aa-e5ef-4a50-b75f-ff59b5108641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 94ms/step - loss: 0.4465 - acc: 0.8012 - auc: 0.8244 - binary_accuracy: 0.8012 - recall_10: 0.5067 - precision_10: 0.7147 - val_loss: 0.6960 - val_acc: 0.6585 - val_auc: 0.6723 - val_binary_accuracy: 0.6585 - val_recall_10: 0.3019 - val_precision_10: 0.5053\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.2180 - acc: 0.9095 - auc: 0.9672 - binary_accuracy: 0.9095 - recall_10: 0.7938 - precision_10: 0.8778 - val_loss: 0.8028 - val_acc: 0.6546 - val_auc: 0.6677 - val_binary_accuracy: 0.6546 - val_recall_10: 0.1962 - val_precision_10: 0.4936\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.1432 - acc: 0.9424 - auc: 0.9876 - binary_accuracy: 0.9424 - recall_10: 0.8696 - precision_10: 0.9242 - val_loss: 0.7691 - val_acc: 0.6563 - val_auc: 0.6781 - val_binary_accuracy: 0.6563 - val_recall_10: 0.2803 - val_precision_10: 0.5000\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0962 - acc: 0.9673 - auc: 0.9950 - binary_accuracy: 0.9673 - recall_10: 0.9287 - precision_10: 0.9557 - val_loss: 0.8402 - val_acc: 0.6944 - val_auc: 0.6787 - val_binary_accuracy: 0.6944 - val_recall_10: 0.2803 - val_precision_10: 0.6232\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.0639 - acc: 0.9809 - auc: 0.9987 - binary_accuracy: 0.9809 - recall_10: 0.9518 - precision_10: 0.9808 - val_loss: 0.9629 - val_acc: 0.6690 - val_auc: 0.6604 - val_binary_accuracy: 0.6690 - val_recall_10: 0.4166 - val_precision_10: 0.5232\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.0498 - acc: 0.9873 - auc: 0.9992 - binary_accuracy: 0.9873 - recall_10: 0.9737 - precision_10: 0.9819 - val_loss: 1.1731 - val_acc: 0.6567 - val_auc: 0.6416 - val_binary_accuracy: 0.6567 - val_recall_10: 0.2522 - val_precision_10: 0.5013\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.0303 - acc: 0.9965 - auc: 0.9999 - binary_accuracy: 0.9965 - recall_10: 0.9917 - precision_10: 0.9961 - val_loss: 1.1640 - val_acc: 0.6655 - val_auc: 0.6475 - val_binary_accuracy: 0.6655 - val_recall_10: 0.3299 - val_precision_10: 0.5211\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0262 - acc: 0.9950 - auc: 0.9999 - binary_accuracy: 0.9950 - recall_10: 0.9897 - precision_10: 0.9929 - val_loss: 1.2941 - val_acc: 0.6651 - val_auc: 0.6456 - val_binary_accuracy: 0.6651 - val_recall_10: 0.3439 - val_precision_10: 0.5192\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.0166 - acc: 0.9991 - auc: 1.0000 - binary_accuracy: 0.9991 - recall_10: 0.9987 - precision_10: 0.9981 - val_loss: 1.3687 - val_acc: 0.6309 - val_auc: 0.6239 - val_binary_accuracy: 0.6309 - val_recall_10: 0.4064 - val_precision_10: 0.4583\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0126 - acc: 0.9991 - auc: 1.0000 - binary_accuracy: 0.9991 - recall_10: 0.9981 - precision_10: 0.9987 - val_loss: 1.4045 - val_acc: 0.6305 - val_auc: 0.6202 - val_binary_accuracy: 0.6305 - val_recall_10: 0.4166 - val_precision_10: 0.4586\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0101 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_10: 1.0000 - precision_10: 0.9994 - val_loss: 1.4889 - val_acc: 0.6243 - val_auc: 0.6165 - val_binary_accuracy: 0.6243 - val_recall_10: 0.3936 - val_precision_10: 0.4472\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0077 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_10: 1.0000 - precision_10: 0.9994 - val_loss: 1.5534 - val_acc: 0.6182 - val_auc: 0.6124 - val_binary_accuracy: 0.6182 - val_recall_10: 0.3554 - val_precision_10: 0.4326\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.0061 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_10: 1.0000 - precision_10: 0.9987 - val_loss: 1.6238 - val_acc: 0.6143 - val_auc: 0.6098 - val_binary_accuracy: 0.6143 - val_recall_10: 0.3490 - val_precision_10: 0.4255\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0052 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_10: 1.0000 - precision_10: 0.9994 - val_loss: 1.6620 - val_acc: 0.6169 - val_auc: 0.6075 - val_binary_accuracy: 0.6169 - val_recall_10: 0.3376 - val_precision_10: 0.4274\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0053 - acc: 0.9994 - auc: 1.0000 - binary_accuracy: 0.9994 - recall_10: 0.9987 - precision_10: 0.9994 - val_loss: 1.7031 - val_acc: 0.6130 - val_auc: 0.6107 - val_binary_accuracy: 0.6130 - val_recall_10: 0.3452 - val_precision_10: 0.4228\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0038 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_10: 1.0000 - precision_10: 1.0000 - val_loss: 1.7756 - val_acc: 0.6130 - val_auc: 0.6061 - val_binary_accuracy: 0.6130 - val_recall_10: 0.3389 - val_precision_10: 0.4216\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.0030 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_10: 1.0000 - precision_10: 1.0000 - val_loss: 1.7657 - val_acc: 0.6156 - val_auc: 0.6058 - val_binary_accuracy: 0.6156 - val_recall_10: 0.3783 - val_precision_10: 0.4323\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.0027 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_10: 1.0000 - precision_10: 1.0000 - val_loss: 1.8403 - val_acc: 0.6156 - val_auc: 0.6115 - val_binary_accuracy: 0.6156 - val_recall_10: 0.3083 - val_precision_10: 0.4194\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.0024 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_10: 1.0000 - precision_10: 1.0000 - val_loss: 1.8061 - val_acc: 0.6169 - val_auc: 0.6063 - val_binary_accuracy: 0.6169 - val_recall_10: 0.3936 - val_precision_10: 0.4364\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.0021 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_10: 1.0000 - precision_10: 1.0000 - val_loss: 2.0041 - val_acc: 0.6121 - val_auc: 0.6156 - val_binary_accuracy: 0.6121 - val_recall_10: 0.2242 - val_precision_10: 0.3885\n",
      "0.6960271000862122\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a935710e-f47e-4b16-bee8-73291eee8112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "026c9001-619c-421a-9c27-a42fb97302bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.5625 MSE:  0.4375 UAR:  0.523109243697479 Recall:  0.42857142857142855 Precision:  0.3157894736842105 F1:  0.36363636363636365\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.5833333333333334 MSE:  0.4166666666666667 UAR:  0.5168067226890757 Recall:  0.35714285714285715 Precision:  0.3125 F1:  0.3333333333333333\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5105042016806722 Recall:  0.2857142857142857 Precision:  0.3076923076923077 F1:  0.29629629629629634\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.5399159663865546 Recall:  0.2857142857142857 Precision:  0.36363636363636365 F1:  0.32\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.51890756302521 Recall:  0.21428571428571427 Precision:  0.3333333333333333 F1:  0.2608695652173913\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.51890756302521 Recall:  0.21428571428571427 Precision:  0.3333333333333333 F1:  0.2608695652173913\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5483193277310924 Recall:  0.21428571428571427 Precision:  0.42857142857142855 F1:  0.2857142857142857\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5777310924369747 Recall:  0.21428571428571427 Precision:  0.6 F1:  0.3157894736842105\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional Accuracy:  0.75 MSE:  0.25 UAR:  0.592436974789916 Recall:  0.21428571428571427 Precision:  0.75 F1:  0.3333333333333333\n",
      "0.9 0.592436974789916\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "177c6f4f-3131-48f1-a933-a43fecbd0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "454cdb88-3838-414b-ba95-45004fed656b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9bfc0290-811a-420e-9424-c176c6cf04d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.4791666666666667 MSE:  0.5208333333333334 UAR:  0.6113445378151261 Recall:  0.9285714285714286 Precision:  0.35135135135135137 F1:  0.5098039215686275\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.6458333333333334 MSE:  0.3541666666666667 UAR:  0.6659663865546219 Recall:  0.7142857142857143 Precision:  0.43478260869565216 F1:  0.5405405405405405\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6911764705882353 Recall:  0.5 Precision:  0.6363636363636364 F1:  0.56\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5630252100840336 Recall:  0.21428571428571427 Precision:  0.5 F1:  0.3\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5273109243697479 Recall:  0.14285714285714285 Precision:  0.4 F1:  0.21052631578947364\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.49159663865546216 Recall:  0.07142857142857142 Precision:  0.25 F1:  0.11111111111111112\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5210084033613446 Recall:  0.07142857142857142 Precision:  0.5 F1:  0.125\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.3 0.6911764705882353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a75538-24c3-46fb-b317-c15bce4281ff",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f4632151-5142-4326-8fc8-05559d18ef5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d222dd91-89cd-4b46-b6d6-053721610bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7295c39a-aacd-420e-917d-fea0ebd0bb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 128, 3072) (5449,)\n",
      "(2284, 128, 3072) (2284,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "49d4f07d-cb66-4d54-a480-5ff9b7dd6a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_5 (Attention)     (None, None, 3072)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['attention_5[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['attention_5[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 1)                    3073      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18880514 (72.02 MB)\n",
      "Trainable params: 18880514 (72.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "365bb602-b139-4151-a3ee-2d09f07ffd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 9s 181ms/step - loss: 0.8626 - acc: 0.7851 - auc: 0.7786 - binary_accuracy: 0.7851 - recall_11: 0.5793 - precision_11: 0.6361 - val_loss: 0.7451 - val_acc: 0.6213 - val_auc: 0.6604 - val_binary_accuracy: 0.6213 - val_recall_11: 0.1554 - val_precision_11: 0.3765\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.1910 - acc: 0.9284 - auc: 0.9751 - binary_accuracy: 0.9284 - recall_11: 0.8382 - precision_11: 0.9044 - val_loss: 0.7915 - val_acc: 0.6694 - val_auc: 0.6388 - val_binary_accuracy: 0.6694 - val_recall_11: 0.3389 - val_precision_11: 0.5299\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 6s 130ms/step - loss: 0.1192 - acc: 0.9604 - auc: 0.9929 - binary_accuracy: 0.9604 - recall_11: 0.9094 - precision_11: 0.9497 - val_loss: 0.7957 - val_acc: 0.6677 - val_auc: 0.6517 - val_binary_accuracy: 0.6677 - val_recall_11: 0.3643 - val_precision_11: 0.5238\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 5s 124ms/step - loss: 0.0777 - acc: 0.9783 - auc: 0.9968 - binary_accuracy: 0.9783 - recall_11: 0.9538 - precision_11: 0.9700 - val_loss: 0.9277 - val_acc: 0.6051 - val_auc: 0.6224 - val_binary_accuracy: 0.6051 - val_recall_11: 0.4102 - val_precision_11: 0.4231\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 6s 130ms/step - loss: 0.0507 - acc: 0.9875 - auc: 0.9991 - binary_accuracy: 0.9875 - recall_11: 0.9743 - precision_11: 0.9819 - val_loss: 1.1552 - val_acc: 0.5972 - val_auc: 0.5963 - val_binary_accuracy: 0.5972 - val_recall_11: 0.2522 - val_precision_11: 0.3729\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0385 - acc: 0.9910 - auc: 0.9993 - binary_accuracy: 0.9910 - recall_11: 0.9782 - precision_11: 0.9902 - val_loss: 1.1056 - val_acc: 0.5898 - val_auc: 0.6361 - val_binary_accuracy: 0.5898 - val_recall_11: 0.5452 - val_precision_11: 0.4246\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0346 - acc: 0.9916 - auc: 0.9991 - binary_accuracy: 0.9916 - recall_11: 0.9807 - precision_11: 0.9896 - val_loss: 1.1737 - val_acc: 0.5937 - val_auc: 0.6411 - val_binary_accuracy: 0.5937 - val_recall_11: 0.4777 - val_precision_11: 0.4199\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 6s 130ms/step - loss: 0.0557 - acc: 0.9798 - auc: 0.9975 - binary_accuracy: 0.9798 - recall_11: 0.9615 - precision_11: 0.9677 - val_loss: 1.5133 - val_acc: 0.6480 - val_auc: 0.5737 - val_binary_accuracy: 0.6480 - val_recall_11: 0.2318 - val_precision_11: 0.4752\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0211 - acc: 0.9947 - auc: 0.9994 - binary_accuracy: 0.9947 - recall_11: 0.9878 - precision_11: 0.9935 - val_loss: 1.4806 - val_acc: 0.5832 - val_auc: 0.5884 - val_binary_accuracy: 0.5832 - val_recall_11: 0.3401 - val_precision_11: 0.3809\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0113 - acc: 0.9985 - auc: 0.9996 - binary_accuracy: 0.9985 - recall_11: 0.9974 - precision_11: 0.9974 - val_loss: 1.6837 - val_acc: 0.5639 - val_auc: 0.5660 - val_binary_accuracy: 0.5639 - val_recall_11: 0.3210 - val_precision_11: 0.3524\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0062 - acc: 0.9991 - auc: 1.0000 - binary_accuracy: 0.9991 - recall_11: 0.9974 - precision_11: 0.9994 - val_loss: 1.6462 - val_acc: 0.5727 - val_auc: 0.5792 - val_binary_accuracy: 0.5727 - val_recall_11: 0.4025 - val_precision_11: 0.3840\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0045 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_11: 0.9987 - precision_11: 1.0000 - val_loss: 1.7269 - val_acc: 0.5525 - val_auc: 0.5765 - val_binary_accuracy: 0.5525 - val_recall_11: 0.4599 - val_precision_11: 0.3764\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0051 - acc: 0.9998 - auc: 0.9997 - binary_accuracy: 0.9998 - recall_11: 0.9994 - precision_11: 1.0000 - val_loss: 1.8486 - val_acc: 0.5368 - val_auc: 0.5726 - val_binary_accuracy: 0.5368 - val_recall_11: 0.5567 - val_precision_11: 0.3810\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0040 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_11: 0.9994 - precision_11: 1.0000 - val_loss: 1.9046 - val_acc: 0.5381 - val_auc: 0.5773 - val_binary_accuracy: 0.5381 - val_recall_11: 0.5720 - val_precision_11: 0.3844\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0053 - acc: 0.9993 - auc: 1.0000 - binary_accuracy: 0.9993 - recall_11: 0.9987 - precision_11: 0.9987 - val_loss: 1.8540 - val_acc: 0.5648 - val_auc: 0.5825 - val_binary_accuracy: 0.5648 - val_recall_11: 0.5159 - val_precision_11: 0.3974\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 5s 126ms/step - loss: 0.0025 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_11: 1.0000 - precision_11: 1.0000 - val_loss: 1.8222 - val_acc: 0.5727 - val_auc: 0.5682 - val_binary_accuracy: 0.5727 - val_recall_11: 0.3771 - val_precision_11: 0.3780\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 5s 126ms/step - loss: 0.0035 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall_11: 0.9994 - precision_11: 0.9994 - val_loss: 2.2142 - val_acc: 0.5184 - val_auc: 0.5503 - val_binary_accuracy: 0.5184 - val_recall_11: 0.5707 - val_precision_11: 0.3699\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 5s 127ms/step - loss: 0.0021 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall_11: 1.0000 - precision_11: 0.9994 - val_loss: 1.9467 - val_acc: 0.5539 - val_auc: 0.5675 - val_binary_accuracy: 0.5539 - val_recall_11: 0.4382 - val_precision_11: 0.3731\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0011 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_11: 1.0000 - precision_11: 1.0000 - val_loss: 2.0309 - val_acc: 0.5517 - val_auc: 0.5617 - val_binary_accuracy: 0.5517 - val_recall_11: 0.4420 - val_precision_11: 0.3719\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 6s 131ms/step - loss: 9.0873e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall_11: 1.0000 - precision_11: 1.0000 - val_loss: 2.0718 - val_acc: 0.5460 - val_auc: 0.5587 - val_binary_accuracy: 0.5460 - val_recall_11: 0.4268 - val_precision_11: 0.3633\n",
      "0.7450645565986633\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "178aa29c-8b19-4b53-991d-8fb7737613a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3927caaa-7800-46ee-8b9c-698f01a52929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.5416666666666666 MSE:  0.4583333333333333 UAR:  0.592436974789916 Recall:  0.7142857142857143 Precision:  0.35714285714285715 F1:  0.4761904761904762\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.5208333333333334 MSE:  0.4791666666666667 UAR:  0.5567226890756303 Recall:  0.6428571428571429 Precision:  0.3333333333333333 F1:  0.43902439024390244\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.5 MSE:  0.5 UAR:  0.5210084033613445 Recall:  0.5714285714285714 Precision:  0.3076923076923077 F1:  0.4\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.5208333333333334 MSE:  0.4791666666666667 UAR:  0.5357142857142857 Recall:  0.5714285714285714 Precision:  0.32 F1:  0.41025641025641024\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.5208333333333334 MSE:  0.4791666666666667 UAR:  0.5357142857142857 Recall:  0.5714285714285714 Precision:  0.32 F1:  0.41025641025641024\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.5416666666666666 MSE:  0.4583333333333333 UAR:  0.5504201680672269 Recall:  0.5714285714285714 Precision:  0.3333333333333333 F1:  0.4210526315789474\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.5416666666666666 MSE:  0.4583333333333333 UAR:  0.5084033613445378 Recall:  0.42857142857142855 Precision:  0.3 F1:  0.3529411764705882\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.5416666666666666 MSE:  0.4583333333333333 UAR:  0.4873949579831933 Recall:  0.35714285714285715 Precision:  0.2777777777777778 F1:  0.31250000000000006\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.5105042016806722 Recall:  0.2857142857142857 Precision:  0.3076923076923077 F1:  0.29629629629629634\n",
      "0.1 0.592436974789916\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d0c64119-6f0d-4147-ac3d-4c866836a29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "bfe10083-a048-49eb-9995-b97d20a47472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4051215/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b9046195-56f8-4558-9f2a-70efe47c5472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.5 MSE:  0.5 UAR:  0.5840336134453781 Recall:  0.7857142857142857 Precision:  0.34375 F1:  0.4782608695652174\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.625 MSE:  0.375 UAR:  0.6302521008403361 Recall:  0.6428571428571429 Precision:  0.4090909090909091 F1:  0.5000000000000001\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6911764705882353 Recall:  0.5 Precision:  0.6363636363636364 F1:  0.56\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5063025210084033 Recall:  0.07142857142857142 Precision:  0.3333333333333333 F1:  0.11764705882352941\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5357142857142857 Recall:  0.07142857142857142 Precision:  1.0 F1:  0.13333333333333333\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_traditional_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5357142857142857 Recall:  0.07142857142857142 Precision:  1.0 F1:  0.13333333333333333\n",
      "0.4 0.6911764705882353\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d32b1-03fc-4ca4-bc11-333e741a5a7c",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "491ce530-0fb8-4b6e-b6d9-c1d3f0550227",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c79d316-39b9-436b-a54b-9d562125daa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  147\n",
      "Test:  48\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ccd3531-b083-4e02-b89e-26e7ec455fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58f619ca-8ca0-4103-a841-847c58acf4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147, 2048) (147,)\n",
      "(48, 2048) (48,)\n",
      "(195, 2048) (195,)\n",
      "[0 1] [141  54]\n",
      "195\n",
      "147\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.759)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36812f26-f97d-4317-96b8-2b138ba31341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 107/147: 72.78911564625851%\n",
      "1 40/147: 27.210884353741495%\n",
      "val:\n",
      "0 34/48: 70.83333333333333%\n",
      "1 14/48: 29.166666666666668%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4acc34-36d8-4fc1-95b6-502f61f4f0ff",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67d1fe28-1877-4f6d-b063-e79cf0897eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d079d16-1e3e-4fb8-a58b-89d091954d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "648be070-d781-47fc-8998-1a95ee41f8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 3072) (5631,)\n",
      "(2102, 128, 3072) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "593fa723-b8bc-4b86-b8f0-c860011e3993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 08:14:20.359963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1573376   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1576962 (6.02 MB)\n",
      "Trainable params: 1576962 (6.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4eb34668-fc19-4b8d-8721-e6b5a315bbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 08:14:31.460675: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f36bbf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-30 08:14:31.460844: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-30 08:14:31.464965: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-30 08:14:31.510415: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-07-30 08:14:31.563412: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 8s 123ms/step - loss: 0.3858 - acc: 0.8304 - auc: 0.8784 - binary_accuracy: 0.8304 - recall: 0.6104 - precision: 0.7823 - val_loss: 0.7626 - val_acc: 0.6665 - val_auc: 0.6457 - val_binary_accuracy: 0.6665 - val_recall: 0.3291 - val_precision: 0.4318\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.1524 - acc: 0.9433 - auc: 0.9869 - binary_accuracy: 0.9433 - recall: 0.8670 - precision: 0.9415 - val_loss: 0.9998 - val_acc: 0.6056 - val_auc: 0.6323 - val_binary_accuracy: 0.6056 - val_recall: 0.2520 - val_precision: 0.3113\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.0812 - acc: 0.9718 - auc: 0.9975 - binary_accuracy: 0.9718 - recall: 0.9262 - precision: 0.9796 - val_loss: 1.1166 - val_acc: 0.6598 - val_auc: 0.6427 - val_binary_accuracy: 0.6598 - val_recall: 0.3669 - val_precision: 0.4267\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.0486 - acc: 0.9874 - auc: 0.9995 - binary_accuracy: 0.9874 - recall: 0.9649 - precision: 0.9934 - val_loss: 1.2219 - val_acc: 0.6746 - val_auc: 0.6649 - val_binary_accuracy: 0.6746 - val_recall: 0.3811 - val_precision: 0.4540\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.0304 - acc: 0.9957 - auc: 0.9999 - binary_accuracy: 0.9957 - recall: 0.9889 - precision: 0.9970 - val_loss: 1.2785 - val_acc: 0.6941 - val_auc: 0.6713 - val_binary_accuracy: 0.6941 - val_recall: 0.4016 - val_precision: 0.4923\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.0234 - acc: 0.9957 - auc: 0.9999 - binary_accuracy: 0.9957 - recall: 0.9895 - precision: 0.9965 - val_loss: 1.3624 - val_acc: 0.7036 - val_auc: 0.6779 - val_binary_accuracy: 0.7036 - val_recall: 0.4646 - val_precision: 0.5104\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.0183 - acc: 0.9970 - auc: 1.0000 - binary_accuracy: 0.9970 - recall: 0.9930 - precision: 0.9971 - val_loss: 1.5535 - val_acc: 0.6970 - val_auc: 0.6722 - val_binary_accuracy: 0.6970 - val_recall: 0.3606 - val_precision: 0.4978\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.0099 - acc: 0.9995 - auc: 1.0000 - binary_accuracy: 0.9995 - recall: 0.9988 - precision: 0.9994 - val_loss: 1.5459 - val_acc: 0.7074 - val_auc: 0.6753 - val_binary_accuracy: 0.7074 - val_recall: 0.4031 - val_precision: 0.5203\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.0069 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall: 0.9994 - precision: 0.9994 - val_loss: 1.6713 - val_acc: 0.7150 - val_auc: 0.6686 - val_binary_accuracy: 0.7150 - val_recall: 0.3638 - val_precision: 0.5423\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.0054 - acc: 0.9996 - auc: 1.0000 - binary_accuracy: 0.9996 - recall: 0.9994 - precision: 0.9994 - val_loss: 1.6704 - val_acc: 0.7060 - val_auc: 0.6747 - val_binary_accuracy: 0.7060 - val_recall: 0.4189 - val_precision: 0.5165\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.0042 - acc: 0.9998 - auc: 1.0000 - binary_accuracy: 0.9998 - recall: 1.0000 - precision: 0.9994 - val_loss: 1.7844 - val_acc: 0.7117 - val_auc: 0.6670 - val_binary_accuracy: 0.7117 - val_recall: 0.3732 - val_precision: 0.5326\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.0034 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.8123 - val_acc: 0.7093 - val_auc: 0.6736 - val_binary_accuracy: 0.7093 - val_recall: 0.3984 - val_precision: 0.5249\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.0033 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.8047 - val_acc: 0.7012 - val_auc: 0.6750 - val_binary_accuracy: 0.7012 - val_recall: 0.4142 - val_precision: 0.5067\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.0023 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.8749 - val_acc: 0.7060 - val_auc: 0.6720 - val_binary_accuracy: 0.7060 - val_recall: 0.3969 - val_precision: 0.5175\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.0020 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.8857 - val_acc: 0.7060 - val_auc: 0.6739 - val_binary_accuracy: 0.7060 - val_recall: 0.4094 - val_precision: 0.5169\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.0017 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.9161 - val_acc: 0.7027 - val_auc: 0.6748 - val_binary_accuracy: 0.7027 - val_recall: 0.4142 - val_precision: 0.5097\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.0014 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.9330 - val_acc: 0.7036 - val_auc: 0.6770 - val_binary_accuracy: 0.7036 - val_recall: 0.4189 - val_precision: 0.5115\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.0012 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 1.9804 - val_acc: 0.7031 - val_auc: 0.6770 - val_binary_accuracy: 0.7031 - val_recall: 0.4220 - val_precision: 0.5105\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.0011 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 2.0085 - val_acc: 0.7017 - val_auc: 0.6774 - val_binary_accuracy: 0.7017 - val_recall: 0.4063 - val_precision: 0.5079\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 9.8342e-04 - acc: 1.0000 - auc: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - val_loss: 2.0640 - val_acc: 0.7065 - val_auc: 0.6728 - val_binary_accuracy: 0.7065 - val_recall: 0.3969 - val_precision: 0.5185\n",
      "0.7625898718833923\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b00f562-ee20-4eda-b476-fd056294ca0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4087404/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51e7e492-e8bb-456b-9169-88547350501e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6176470588235294 Recall:  0.5 Precision:  0.4375 F1:  0.4666666666666667\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6407563025210083 Recall:  0.42857142857142855 Precision:  0.5454545454545454 F1:  0.4799999999999999\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.75 MSE:  0.25 UAR:  0.6554621848739496 Recall:  0.42857142857142855 Precision:  0.6 F1:  0.5\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.75 MSE:  0.25 UAR:  0.634453781512605 Recall:  0.35714285714285715 Precision:  0.625 F1:  0.45454545454545453\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.5987394957983193 Recall:  0.2857142857142857 Precision:  0.5714285714285714 F1:  0.38095238095238093\n",
      "0.3 0.6554621848739496\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ca9870e-ac9c-4ed9-86aa-09c1529969ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90de8cb9-7713-4d5e-8314-628c91916b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4087404/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a7e94a3-8e25-4b59-ba42-bd5453468ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.5208333333333334 MSE:  0.4791666666666667 UAR:  0.5777310924369747 Recall:  0.7142857142857143 Precision:  0.3448275862068966 F1:  0.46511627906976755\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6596638655462186 Recall:  0.6428571428571429 Precision:  0.45 F1:  0.5294117647058824\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6533613445378151 Recall:  0.5714285714285714 Precision:  0.47058823529411764 F1:  0.5161290322580646\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.5966386554621849 Recall:  0.42857142857142855 Precision:  0.42857142857142855 F1:  0.42857142857142855\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6050420168067226 Recall:  0.35714285714285715 Precision:  0.5 F1:  0.41666666666666663\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5840336134453781 Recall:  0.2857142857142857 Precision:  0.5 F1:  0.36363636363636365\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.5630252100840336 Recall:  0.21428571428571427 Precision:  0.5 F1:  0.3\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.592436974789916 Recall:  0.21428571428571427 Precision:  0.75 F1:  0.3333333333333333\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_single_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.5714285714285714 Recall:  0.14285714285714285 Precision:  1.0 F1:  0.25\n",
      "0.2 0.6596638655462186\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cd3671-5192-4c16-8264-fd46d08a4900",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d696040-17fe-4d3f-a598-9d20fec27e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab03fed4-6cd7-4462-b0ae-130a6418eea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d025517-89fb-4cdf-bf69-4306b16a45e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5631, 128, 3072) (5631,)\n",
      "(2102, 128, 3072) (2102,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7f65b27-d7ff-4a8f-8804-a25eeb0a3cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 08:30:39.929705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 3072)           9437184   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 3072)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    3073      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18880514 (72.02 MB)\n",
      "Trainable params: 18880514 (72.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9dcdbc9c-66dc-4064-9460-e7cdbd23db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e81117d-15ce-4532-9d80-524d1127fcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4095000/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13347845-daa4-4a6b-918c-a2730823ceab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.6666666666666666 MSE:  0.3333333333333333 UAR:  0.6386554621848739 Recall:  0.5714285714285714 Precision:  0.4444444444444444 F1:  0.5\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.6875 MSE:  0.3125 UAR:  0.6533613445378151 Recall:  0.5714285714285714 Precision:  0.47058823529411764 F1:  0.5161290322580646\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6470588235294117 Recall:  0.5 Precision:  0.5 F1:  0.5\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.6260504201680672 Recall:  0.42857142857142855 Precision:  0.5 F1:  0.4615384615384615\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6407563025210083 Recall:  0.42857142857142855 Precision:  0.5454545454545454 F1:  0.4799999999999999\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6407563025210083 Recall:  0.42857142857142855 Precision:  0.5454545454545454 F1:  0.4799999999999999\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6407563025210083 Recall:  0.42857142857142855 Precision:  0.5454545454545454 F1:  0.4799999999999999\n",
      "0.2 0.6533613445378151\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e31fae0-8882-4e26-b58c-72a27f9f547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    modelAtn.set_weights(best_model_weights)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91c22d6d-fc86-42bc-9b1b-791e0bc24892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_4095000/1902217451.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f34d57d-8a9a-438e-9470-48f3e1f9e6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.4375 MSE:  0.5625 UAR:  0.5819327731092437 Recall:  0.9285714285714286 Precision:  0.3333333333333333 F1:  0.4905660377358491\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.6041666666666666 MSE:  0.3958333333333333 UAR:  0.6785714285714286 Recall:  0.8571428571428571 Precision:  0.41379310344827586 F1:  0.5581395348837208\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.7083333333333334 MSE:  0.2916666666666667 UAR:  0.73109243697479 Recall:  0.7857142857142857 Precision:  0.5 F1:  0.6111111111111112\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6827731092436975 Recall:  0.5714285714285714 Precision:  0.5333333333333333 F1:  0.5517241379310344\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.75 MSE:  0.25 UAR:  0.6764705882352942 Recall:  0.5 Precision:  0.5833333333333334 F1:  0.5384615384615384\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6407563025210083 Recall:  0.42857142857142855 Precision:  0.5454545454545454 F1:  0.4799999999999999\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.7291666666666666 MSE:  0.2708333333333333 UAR:  0.6197478991596639 Recall:  0.35714285714285715 Precision:  0.5555555555555556 F1:  0.43478260869565216\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.6875 MSE:  0.3125 UAR:  0.5483193277310924 Recall:  0.21428571428571427 Precision:  0.42857142857142855 F1:  0.2857142857142857\n",
      "Metric_name:  mobilenet_7.h5_EngageWild_2_STAT_self_attention_balanced_best Accuracy:  0.7708333333333334 MSE:  0.22916666666666666 UAR:  0.6071428571428571 Recall:  0.21428571428571427 Precision:  1.0 F1:  0.35294117647058826\n",
      "0.3 0.73109243697479\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0ab158-318f-445a-b774-8f15055a2ae5",
   "metadata": {},
   "source": [
    "# DAiSEE dataset (4 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23a7dc29-b807-451a-b8a8-b60a1bc6f017",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_DIR = DATA_DIR + 'features_DAiSEE/'\n",
    "WEIGHTS_DIR = DATA_DIR + 'weights_DAiSEE/'\n",
    "WEIGHTS_DIR = DATA_DIR + 'weights_DAiSEE_classifier/'\n",
    "TABLE_NAME = '02_DAiSEE_4_classes.xlsx'\n",
    "TABLE_NAME = '02_DAiSEE_4_classes_classifier.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756e5a1-ebff-4271-a7d5-db3925d92d4a",
   "metadata": {},
   "source": [
    "## enet_b0_8_best_afew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5ee3138-e033-4ae4-83eb-3d4a54d6f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_key = 'enet_b0_8_best_afew.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "606239de-c805-4079-9451-8be70a198e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['very distracted', 'distracted', 'engaged', 'very engaged']\n",
      "{'1100011002': 2, '1100011003': 2, '1100011004': 3, '1100011005': 3, '1100011006': 3, '1100011007': 2, '1100011008': 3, '1100011009': 2, '1100011010': 3, '1100011011': 3, '1100011012': 2, '1100011013': 3, '1100011014': 3, '1100011015': 3, '1100011016': 3, '1100011017': 3, '1100011018': 3, '1100011019': 3, '1100011020': 3, '1100011021': 3, '1100011022': 3, '1100011023': 3, '1100011025': 3, '1100011026': 3, '1100011027': 3, '1100011028': 3, '1100011029': 3, '1100011031': 3, '1100011032': 3, '1100011034': 3, '1100011035': 3, '1100011037': 3, '1100011038': 3, '1100011040': 2, '1100011046': 3, '1100011047': 3, '1100011048': 2, '1100011049': 3, '1100011050': 3, '1100011051': 3, '1100011052': 3, '1100011053': 3, '1100011054': 3, '1100011055': 3, '1100011056': 3, '1100011057': 3, '1100011058': 3, '1100011059': 3, '1100011060': 3, '1100011062': 3, '1100011063': 3, '1100011064': 3, '1100011066': 3, '1100011067': 3, '1100011068': 3, '1100011069': 3, '1100011070': 3, '1100011071': 3, '1100011072': 3, '1100011073': 3, '1100011075': 3, '1100011076': 3, '1100011078': 2, '1100011079': 3, '1100011080': 3, '1100011081': 3, '1100011082': 3, '1100011083': 3, '1100012001': 3, '1100012003': 3, '1100012007': 3, '1100012008': 3, '1100012009': 3, '1100012010': 3, '1100012011': 3, '1100012013': 3, '1100012014': 3, '1100012015': 3, '1100012016': 3, '1100012017': 3, '1100012018': 3, '1100012021': 2, '1100012022': 3, '1100012023': 3, '1100012025': 3, '1100012026': 3, '1100012027': 3, '1100012028': 3, '1100012030': 3, '1100012031': 3, '1100012032': 3, '1100012033': 3, '1100012036': 3, '1100012037': 3, '1100012038': 3, '1100012041': 3, '1100012042': 2, '1100012045': 2, '1100012046': 3, '1100012047': 2, '1100012049': 3, '1100012050': 3, '1100012051': 3, '1100012052': 3, '1100012057': 3, '1100012059': 3, '1100012060': 3, '1100012061': 3, '1100012062': 3, '1100012063': 3, '1100012064': 3, '1100012065': 3, '1100012066': 3, '1100012069': 3, '1100021001': 2, '1100021003': 1, '1100021015': 2, '1100021038': 2, '1100021039': 2, '1100021040': 3, '1100021045': 3, '1100021050': 3, '1100021055': 1, '1100022001': 3, '1100022002': 2, '1100022003': 3, '1100022004': 3, '1100022005': 1, '1100022008': 2, '1100022009': 3, '1100022014': 3, '1100022019': 3, '1100022020': 2, '1100022021': 2, '1100022022': 2, '1100022026': 3, '1100022027': 3, '1100022028': 3, '1100022029': 3, '1100022031': 3, '1100022035': 2, '1100022038': 3, '1100022039': 3, '1100022045': 3, '1100022046': 3, '1100022047': 3, '1100022048': 2, '1100022049': 2, '1100022051': 3, '1100022052': 2, '1100022053': 2, '1100022054': 2, '1100022055': 2, '1100022056': 3, '1100022057': 2, '1100041006': 3, '1100041015': 3, '1100041016': 3, '1100041017': 2, '1100041018': 2, '1100041021': 2, '1100041022': 2, '1100041023': 2, '1100041024': 2, '1100041029': 3, '1100041034': 2, '1100041044': 2, '1100041051': 3, '1100041052': 2, '1100042009': 2, '1100042010': 2, '1100042011': 2, '1100042017': 2, '1100042018': 2, '1100042019': 3, '1100042020': 3, '1100042023': 1, '1100042024': 2, '1100042025': 2, '1100042026': 1, '1100042029': 3, '1100042030': 2, '1100042031': 3, '1100042034': 2, '1100042040': 2, '1100042041': 3, '1100042058': 2, '1100042059': 2, '1100042060': 2, '1100051002': 2, '1100051004': 2, '1100051006': 2, '1100051007': 1, '1100051008': 2, '1100051009': 2, '1100051011': 2, '1100051012': 2, '1100051013': 2, '1100051014': 2, '1100051016': 1, '1100051017': 2, '1100051019': 3, '1100051020': 2, '1100051021': 2, '1100051022': 2, '1100051023': 2, '1100051024': 2, '1100051025': 2, '1100051026': 2, '1100051028': 2, '1100051029': 2, '1100051030': 1, '1100051031': 1, '1100051032': 3, '1100051033': 2, '1100051034': 2, '1100051035': 2, '1100051036': 2, '1100051037': 2, '1100051039': 2, '1100051041': 3, '1100051042': 2, '1100051044': 2, '1100051045': 3, '1100051046': 2, '1100051048': 2, '1100051049': 2, '1100051050': 3, '1100051051': 2, '1100051052': 2, '1100051053': 1, '1100051054': 2, '1100051055': 2, '1100051056': 2, '1100051057': 3, '1100051059': 3, '1100051061': 2, '1100051062': 3, '1100051064': 3, '1100051065': 2, '1100051066': 3, '1100051067': 3, '1100051068': 3, '1100051071': 3, '1100051076': 2, '1100051078': 2, '1100051079': 3, '1100052001': 2, '1100052002': 2, '1100052006': 2, '1100052007': 2, '1100052008': 3, '1100052009': 2, '1100052014': 1, '1100052023': 2, '1100052024': 2, '1100052026': 2, '1100052027': 2, '1100052028': 3, '1100052030': 2, '1100052031': 2, '1100052032': 2, '1100052033': 2, '1100052035': 2, '1100052036': 2, '1100052037': 2, '1100052038': 2, '1100052039': 2, '1100052040': 3, '1100052041': 2, '1100052047': 2, '1100052048': 2, '1100052049': 2, '1100052051': 2, '1100052055': 2, '1100052057': 2, '1100052060': 3, '1100052061': 2, '1100052062': 2, '1100052065': 3, '1100052068': 2, '1100052070': 2, '1100061009': 3, '1100061010': 3, '1100061011': 3, '1100061012': 2, '1100061013': 3, '1100061015': 2, '1100061016': 2, '1100061018': 2, '1100061019': 2, '1100061022': 3, '1100061023': 2, '1100061025': 2, '1100061027': 3, '1100061028': 2, '1100061030': 2, '1100061031': 2, '1100061032': 2, '1100061033': 3, '1100061034': 2, '1100061035': 2, '1100061036': 3, '1100061038': 3, '1100061039': 2, '1100061040': 3, '1100061042': 3, '1100061043': 3, '1100061044': 2, '1100061046': 3, '1100061047': 3, '1100061048': 3, '1100061049': 2, '1100061050': 2, '1100061051': 3, '1100061053': 2, '1100061057': 2, '1100061058': 2, '1100061061': 3, '1100061063': 3, '1100061064': 3, '1100061067': 3, '1100061068': 3, '1100061069': 3, '1100061073': 2, '1100061074': 2, '1100061077': 2, '1100061078': 2, '1100062004': 3, '1100062005': 3, '1100062007': 3, '1100062008': 1, '1100062009': 3, '1100062016': 2, '1100062017': 3, '1100062024': 2, '1100062028': 2, '1100062029': 2, '1100062036': 2, '1100062037': 2, '1100062044': 2, '1100062045': 1, '1100062046': 2, '1100062049': 1, '1100062051': 2, '1100062053': 3, '1100062054': 2, '1100062059': 2, '1100062060': 2, '1100062061': 2, '1100062062': 2, '1100062063': 2, '1100062064': 2, '1100062065': 2, '1100062066': 3, '1100062067': 3, '1100062068': 2, '1100062069': 2, '1100062070': 2, '1100062071': 3, '1100062072': 3, '1100071005': 2, '1100071006': 2, '1100071007': 2, '1100071008': 3, '1100071009': 2, '1100071010': 2, '1100071011': 2, '1100071012': 3, '1100071013': 2, '1100071014': 3, '1100071015': 2, '1100071016': 3, '1100071017': 2, '1100071018': 2, '1100071019': 2, '1100071020': 2, '1100071021': 3, '1100071022': 2, '1100071023': 2, '1100071024': 2, '1100071026': 2, '1100071027': 2, '1100071028': 2, '1100071029': 2, '1100071030': 3, '1100071031': 3, '1100071032': 2, '1100071033': 2, '1100071034': 3, '1100071035': 2, '1100071036': 2, '1100071037': 2, '1100071040': 3, '1100071041': 2, '1100071042': 2, '1100071043': 3, '1100071044': 2, '1100071045': 2, '1100071046': 2, '1100071047': 2, '1100071049': 2, '1100071050': 3, '1100071052': 2, '1100071054': 2, '1100071055': 3, '1100071056': 2, '1100071057': 3, '1100071058': 2, '1100071059': 2, '1100071060': 2, '1100071061': 3, '1100071062': 2, '1100071063': 3, '1100071064': 3, '1100071065': 2, '1100071066': 2, '1100071067': 3, '1100071069': 2, '1100071070': 3, '1100071071': 2, '1100071072': 2, '1100071073': 2, '1100071074': 2, '1100071075': 2, '1100071076': 2, '1100071077': 3, '1100071078': 3, '1100071079': 3, '1100071080': 3, '1100071081': 3, '1100072001': 2, '1100072002': 3, '1100072003': 3, '1100072004': 2, '1100072006': 2, '1100072007': 2, '1100072008': 2, '1100072009': 3, '1100072010': 2, '1100072011': 3, '1100072012': 3, '1100072013': 2, '1100072014': 2, '1100072015': 2, '1100072016': 2, '1100072021': 2, '1100072022': 2, '1100072023': 3, '1100072024': 2, '1100072027': 2, '1100072028': 2, '1100072029': 2, '1100072030': 2, '1100072031': 2, '1100072032': 3, '1100072033': 3, '1100072034': 2, '1100072036': 2, '1100072037': 2, '1100072038': 2, '1100072039': 2, '1100072040': 2, '1100072042': 2, '1100072043': 3, '1100072045': 2, '1100072047': 3, '1100072048': 2, '1100072049': 2, '1100072050': 2, '1100072051': 3, '1100072052': 3, '1100072053': 2, '1100072054': 2, '1100072056': 2, '1100072057': 2, '1100072058': 3, '1100072059': 2, '1100072060': 2, '1100072061': 2, '1100072062': 2, '1100072063': 3, '1100072065': 2, '1100072066': 3, '1100072067': 2, '1100072068': 2, '1100072069': 2, '1100072070': 2, '1100072071': 2, '1100072072': 2, '1100072073': 2, '1100072074': 3, '1100072075': 2, '1100072076': 2, '1100072077': 3, '1100072078': 3, '1100072079': 2, '1100072080': 2, '1100072081': 2, '1100072082': 3, '1100072083': 2, '1100072084': 2, '1100072085': 2, '1100081044': 2, '1100081045': 2, '1100081046': 2, '1100081047': 3, '1100081048': 3, '1100082002': 3, '1100082003': 3, '1100082018': 2, '1100082027': 2, '1100102003': 2, '1100111001': 3, '1100111002': 3, '1100111003': 2, '1100111008': 2, '1100111009': 2, '1100111010': 3, '1100111011': 2, '1100111012': 2, '1100111013': 2, '1100111014': 2, '1100111016': 2, '1100111017': 2, '1100111018': 2, '1100111019': 2, '1100111021': 2, '1100111023': 3, '1100111025': 3, '1100111026': 2, '1100111027': 3, '1100111029': 2, '1100111030': 3, '1100111032': 2, '1100112001': 2, '1100112002': 1, '1100112003': 3, '1100112004': 3, '1100112006': 1, '1100112007': 3, '1100112008': 3, '1100112009': 3, '1100112010': 2, '1100112011': 2, '1100112012': 3, '1100112013': 2, '1100112014': 2, '1100112015': 3, '1100112016': 3, '1100112017': 3, '1100112018': 3, '1100112021': 2, '1100112022': 2, '1100112024': 3, '1100112025': 2, '1100112026': 2, '1100112029': 3, '1100112030': 3, '1100112033': 3, '1100112035': 2, '1100112036': 3, '1100112037': 3, '1100112038': 2, '1100112039': 3, '1100112040': 2, '1100112041': 2, '1100112042': 3, '1100112043': 2, '1100112044': 2, '1100112045': 2, '1100112047': 3, '1100112048': 2, '1100112051': 3, '1100112052': 3, '1100112053': 3, '1100112056': 2, '1100112057': 3, '1100112058': 2, '1100112059': 3, '1100112060': 3, '1100112061': 2, '1100112062': 2, '1100112063': 2, '1100112064': 3, '1100112065': 2, '1100112066': 3, '1100112068': 3, '1100121002': 3, '1100121003': 2, '1100121004': 3, '1100121005': 3, '1100121006': 3, '1100121007': 3, '1100121008': 3, '1100121009': 3, '1100121010': 3, '1100121011': 3, '1100121012': 3, '1100121015': 2, '1100121016': 3, '1100121017': 3, '1100121018': 2, '1100121019': 2, '1100121020': 3, '1100121024': 2, '1100121025': 2, '1100121028': 3, '1100121031': 2, '1100121032': 3, '1100121033': 2, '1100121034': 2, '1100121035': 3, '1100121036': 2, '1100121038': 3, '1100121040': 3, '1100121041': 2, '1100121042': 2, '1100121044': 3, '1100121045': 3, '1100121047': 3, '1100121049': 2, '1100121050': 3, '1100121052': 2, '1100121053': 3, '1100121054': 3, '1100121056': 2, '1100121057': 3, '1100121059': 2, '1100121060': 2, '1100121061': 2, '1100121064': 3, '1100122001': 2, '1100122002': 2, '1100122003': 2, '1100122005': 2, '1100122006': 3, '1100122007': 3, '1100122008': 3, '1100122009': 2, '1100122010': 3, '1100122011': 3, '1100122012': 3, '1100122013': 3, '1100122014': 3, '1100122015': 2, '1100122017': 2, '1100122018': 3, '1100122019': 3, '1100122020': 3, '1100122021': 2, '1100122023': 2, '1100122024': 3, '1100122025': 2, '1100122026': 2, '1100122031': 3, '1100122032': 3, '1100122033': 2, '1100122034': 3, '1100122035': 2, '1100122036': 3, '1100122037': 3, '1100122038': 3, '1100122039': 3, '1100122040': 2, '1100122041': 2, '1100122045': 2, '1100122047': 2, '1100122048': 3, '1100122050': 3, '1100122051': 2, '1100122052': 3, '1100122053': 2, '1100122054': 2, '1100122056': 1, '1100131006': 3, '1100131007': 2, '1100131009': 3, '1100131010': 3, '1100131011': 3, '1100131012': 3, '1100131017': 0, '1100131019': 3, '1100141001': 3, '1100141002': 2, '1100141003': 3, '1100141004': 3, '1100141005': 2, '1100141006': 2, '1100141007': 3, '1100141008': 2, '1100141009': 2, '1100141010': 3, '1100141011': 2, '1100141012': 2, '1100141013': 1, '1100141014': 2, '1100141015': 2, '1100141016': 3, '1100141017': 2, '1100141019': 2, '1100141020': 2, '1100141021': 2, '1100141023': 3, '1100141027': 1, '1100141028': 2, '1100141029': 2, '1100141030': 2, '1100141031': 2, '1100141032': 2, '1100141033': 2, '1100141034': 2, '1100141035': 2, '1100141036': 2, '1100141039': 3, '1100141040': 2, '1100141042': 2, '1100141044': 2, '1100141045': 3, '1100141046': 2, '1100141049': 2, '1100141050': 2, '1100141052': 2, '1100141053': 2, '1100141054': 3, '1100141055': 3, '1100141056': 2, '1100141057': 2, '1100142002': 3, '1100142003': 2, '1100142004': 2, '1100142007': 2, '1100142008': 2, '1100142009': 2, '1100142010': 2, '1100142011': 3, '1100142013': 2, '1100142014': 2, '1100142015': 2, '1100142017': 2, '1100142018': 2, '1100142019': 2, '1100142021': 3, '1100142022': 2, '1100142023': 2, '1100142024': 2, '1100142027': 3, '1100142028': 2, '1100142029': 3, '1100142030': 2, '1100142031': 2, '1100142032': 3, '1100142033': 1, '1100142034': 3, '1100142035': 3, '1100142038': 2, '1100142041': 3, '1100142043': 2, '1100142044': 2, '1100142045': 2, '1100142046': 3, '1100142048': 3, '1100142049': 2, '1100142050': 2, '1100142051': 2, '1100142052': 2, '1100142053': 3, '1100142056': 3, '1100142057': 3, '1100142058': 2, '1100142059': 2, '1100142060': 2, '1100151003': 2, '1100151004': 3, '1100151008': 3, '1100151009': 2, '1100151010': 2, '1100151011': 1, '1100151012': 2, '1100151013': 2, '1100151014': 3, '1100151015': 2, '1100151016': 2, '1100151017': 2, '1100151018': 2, '1100151019': 2, '1100151020': 2, '1100151021': 3, '1100151022': 3, '1100151023': 2, '1100151024': 2, '1100151028': 2, '1100151030': 2, '1100151032': 3, '1100151033': 2, '1100151035': 3, '1100151037': 3, '1100151038': 2, '1100151039': 2, '1100151040': 3, '1100151042': 3, '1100151043': 2, '1100151044': 2, '1100151047': 2, '1100151049': 3, '1100151050': 2, '1100151051': 2, '1100151052': 3, '1100151054': 3, '1100151055': 2, '1100151056': 3, '1100151057': 1, '1100151058': 2, '1100151062': 2, '1100152001': 2, '1100152004': 3, '1100152005': 2, '1100152006': 2, '1100152008': 2, '1100152009': 2, '1100152010': 1, '1100152013': 3, '1100152014': 2, '1100152015': 2, '1100152017': 1, '1100152019': 3, '1100152020': 3, '1100152022': 2, '1100152024': 2, '1100152025': 2, '1100152026': 2, '1100152027': 3, '1100152031': 1, '1100152032': 2, '1100152039': 3, '1100152040': 2, '1100152041': 2, '1100152042': 2, '1100152043': 2, '1100152048': 2, '1100152049': 2, '1100152050': 2, '1100152051': 2, '1100152055': 1, '1100152056': 2, '1100152061': 2, '1100152062': 2, '1100152067': 2, '1100152069': 2, '1100152070': 0, '1100161002': 2, '1100161004': 3, '1100161011': 3, '1100161012': 3, '1100161013': 2, '1100161014': 2, '1100161015': 3, '1100161016': 2, '1100161020': 3, '1100161021': 3, '1100161022': 2, '1100161023': 2, '1100161028': 2, '1100161029': 2, '1100161032': 2, '1100161035': 2, '1100161036': 2, '1100161038': 2, '1100161039': 3, '1100161041': 3, '1100161043': 3, '1100161044': 2, '1100161045': 2, '1100161046': 2, '1100161048': 2, '1100161050': 3, '1100161053': 1, '1100162005': 1, '1100162007': 2, '1100162011': 2, '1100162016': 1, '1100171001': 2, '1100171002': 2, '1100171004': 0, '1100171005': 2, '1100171007': 2, '1100171008': 0, '1100171009': 2, '1100171010': 2, '1100171011': 3, '1100171012': 2, '1100171013': 2, '1100171015': 2, '1100171016': 2, '1100171017': 2, '1100171019': 2, '1100171021': 3, '1100171022': 2, '1100171023': 2, '1100171031': 2, '1100171035': 2, '1100171036': 2, '1100171038': 3, '1100171039': 3, '1100171040': 3, '1100171041': 2, '1100171043': 2, '1100171045': 2, '1100171049': 2, '1100171055': 2, '1100171056': 3, '1100171057': 2, '1100171059': 1, '1100171061': 3, '1100171063': 3, '1100171064': 3, '1100171065': 2, '1100171067': 2, '1100171069': 3, '1100171070': 2, '1100171071': 3, '1100171072': 2, '1100171073': 3, '1100171074': 2, '1100171075': 2, '1100171076': 2, '1100171077': 3, '1100171078': 3, '1100171080': 2, '1100171083': 2, '1100172003': 2, '1100172004': 2, '1100172007': 2, '1100172012': 1, '1100172013': 2, '1100172014': 2, '1100172015': 2, '1100172016': 2, '1100172017': 1, '1100172018': 3, '1100172020': 2, '1100172021': 2, '1100172022': 2, '1100172026': 2, '1100172028': 2, '1100172030': 3, '1100172032': 2, '1100172033': 1, '1100172034': 1, '1100172035': 3, '1100172037': 2, '1100172039': 2, '1100172042': 2, '1100172043': 1, '1100172047': 3, '1100172050': 2, '1100172058': 1, '1100172063': 3, '1100172066': 2, '1100411010': 2, '1100411011': 3, '1100411012': 2, '1100411013': 3, '1100411015': 3, '1100411016': 3, '1100411018': 2, '1100411020': 2, '1100411023': 3, '1100411036': 2, '1100411041': 3, '1100411045': 3, '1100411047': 2, '1100411048': 2, '1100411049': 2, '1100411050': 3, '1100411051': 3, '1100411053': 3, '1100411054': 2, '1100411055': 2, '1100411057': 2, '1100412001': 3, '1100412003': 2, '1100412010': 2, '1100412018': 0, '1100412033': 1, '1100412038': 2, '1100412039': 1, '1100412040': 2, '1110031003': 2, '1110031007': 3, '1110031010': 1, '1110031011': 2, '1110031012': 3, '1110031014': 2, '1110031019': 2, '1110031020': 2, '1110031021': 2, '1110031025': 0, '1110031027': 1, '1110031031': 3, '1110031033': 1, '1110031037': 3, '1110031038': 0, '1110031039': 2, '1110031040': 3, '1110031042': 2, '1110031048': 2, '1110031049': 2, '1110031050': 3, '1110031056': 1, '1110031061': 2, '1110031062': 2, '1110031063': 0, '1110031064': 2, '1110031065': 3, '1110032002': 3, '1110032004': 2, '1110032006': 3, '1110032008': 2, '1110032010': 2, '1110032014': 1, '1110032015': 3, '1110032018': 3, '1110032019': 2, '1110032020': 2, '1110032021': 2, '1110032022': 2, '1110032023': 2, '1110032024': 3, '1110032025': 2, '1110032027': 1, '1110032029': 3, '1110032031': 2, '1110032032': 3, '1110032033': 3, '1110032034': 2, '1110032036': 3, '1110032037': 2, '1110032042': 2, '1110032043': 1, '1110032045': 2, '1110032047': 2, '1110032048': 2, '1110032049': 2, '1110032050': 3, '1110032051': 2, '1110032052': 3, '1110032053': 2, '1110032055': 2, '1110032056': 2, '1110032058': 3, '1110032059': 2, '1110032060': 3, '1110032061': 2, '1110032062': 2, '1110032063': 2, '1813740111': 3, '1813740112': 2, '1813740115': 3, '1813740116': 3, '1813740118': 2, '1813740119': 2, '1813740122': 2, '1813740123': 3, '1813740124': 2, '1813740126': 3, '1813740127': 3, '1813740128': 3, '1813740131': 2, '1813740133': 3, '1813740135': 2, '1813740137': 2, '1813740138': 0, '1813740143': 2, '1813740144': 2, '1813740149': 3, '181374015': 2, '1813740150': 2, '1813740153': 2, '1813740155': 2, '1813740157': 2, '1813740159': 2, '181374016': 3, '1813740162': 3, '1813740164': 3, '1813740165': 3, '1813740167': 3, '1813740168': 3, '1813740169': 2, '181374017': 2, '1813740171': 2, '1813740172': 3, '1813740173': 2, '1813740174': 3, '1813740176': 2, '1813740178': 2, '1813740179': 2, '1813740180': 2, '1813740181': 3, '1813740182': 3, '1813740183': 2, '1813740184': 1, '1813740185': 1, '181374019': 3, '1813740210': 3, '1813740211': 3, '1813740212': 2, '1813740213': 2, '1813740214': 3, '1813740218': 3, '1813740219': 3, '1813740220': 3, '1813740221': 3, '1813740224': 2, '1813740225': 2, '1813740226': 3, '1813740227': 2, '1813740229': 2, '181374023': 2, '1813740231': 3, '1813740232': 2, '1813740233': 2, '1813740234': 3, '1813740235': 2, '1813740236': 3, '1813740237': 3, '1813740238': 3, '181374024': 3, '1813740240': 3, '1813740241': 3, '1813740242': 3, '1813740243': 3, '1813740245': 3, '1813740249': 3, '181374025': 3, '1813740250': 2, '1813740251': 3, '1813740252': 3, '1813740253': 2, '1813740255': 3, '1813740256': 3, '1813740257': 3, '1813740258': 3, '1813740259': 3, '181374026': 2, '1813740260': 2, '1813740261': 3, '1813740262': 3, '1813740263': 3, '1813740264': 3, '1813740265': 3, '1813740266': 3, '1813740267': 2, '1813740268': 3, '1813740269': 2, '181374027': 2, '1813740270': 3, '1813740271': 2, '1813740272': 3, '1813740273': 3, '1813740274': 3, '1813740275': 2, '1813740276': 3, '1813740277': 3, '1813740278': 2, '1813740279': 3, '181374028': 3, '181374029': 3, '2000481035': 2, '2000481036': 3, '2000481037': 3, '2000481038': 3, '2000481039': 2, '2000481040': 2, '2000481041': 2, '2000481043': 2, '2000481048': 2, '2000482008': 2, '2000482009': 3, '2000482012': 2, '2000482018': 2, '2000482021': 2, '2000482034': 2, '2000482037': 2, '2000482038': 2, '2000482039': 3, '2000482041': 3, '2000482042': 2, '2000482043': 3, '2000482044': 2, '2000482049': 2, '2000482050': 2, '2000482052': 2, '2000482059': 3, '2000482065': 2, '2000482066': 3, '2000482067': 3, '2000482068': 3, '2000482070': 2, '2000491062': 2, '2000491064': 2, '2000491065': 2, '2000491066': 3, '2000491067': 2, '2000491068': 2, '2000491070': 2, '2000491072': 3, '2000491074': 2, '2000491075': 2, '2000491076': 2, '2000491077': 1, '2000491078': 2, '2000491079': 3, '2000501001': 3, '2000501002': 2, '2000501003': 2, '2000501004': 3, '2000501006': 1, '2000501009': 3, '2000501010': 3, '2000501011': 3, '2000501012': 2, '2000501014': 2, '2000501015': 3, '2000501016': 3, '2000501018': 2, '2000501019': 3, '2000501020': 3, '2000501021': 3, '2000501023': 3, '2000501027': 2, '2000501028': 2, '2000501030': 1, '2000501031': 2, '2000501032': 3, '2000501033': 3, '2000501035': 2, '2000501036': 3, '2000501037': 3, '2000501038': 3, '2000501039': 3, '2000501040': 3, '2000501041': 3, '2000501042': 2, '2000501043': 2, '2000501044': 3, '2000501045': 2, '2000501046': 2, '2000501049': 3, '2000501050': 2, '2000501051': 2, '2000501052': 3, '2000501053': 2, '2000501054': 3, '2000501056': 2, '2000501057': 2, '2000501060': 3, '2000501061': 2, '2000501062': 2, '2000501063': 3, '2000501065': 3, '2000501066': 3, '2000501067': 2, '2000501071': 3, '2000501074': 2, '2000501075': 3, '2000501076': 3, '2000501078': 3, '2000502002': 2, '2000502005': 2, '2000502006': 2, '2000502007': 2, '2000502009': 2, '2000502010': 3, '2000502012': 2, '2000502013': 3, '2000502014': 3, '2000502015': 2, '2000502019': 2, '2000502020': 2, '2000502023': 2, '2000502025': 3, '2000502033': 2, '2000502036': 2, '2000502037': 2, '2000502039': 2, '2000502040': 3, '2000502041': 2, '2000502043': 2, '2000502044': 3, '2000502045': 3, '2000502047': 3, '2000502048': 3, '2000502049': 2, '2000502050': 2, '2000502051': 2, '2000502053': 1, '2000502054': 3, '2000502055': 3, '2000502056': 2, '2000502057': 3, '2000502058': 2, '2000502059': 2, '2000502061': 2, '2000502062': 2, '2000502063': 2, '2000502065': 1, '2000502066': 2, '2000502067': 2, '2000502069': 2, '2000502070': 2, '2000502072': 2, '2000502073': 2, '2000502075': 2, '2000502076': 2, '2000502077': 2, '2000502078': 2, '2000502081': 1, '2000502084': 2, '2000502087': 2, '2000502088': 2, '2000502090': 2, '2000541001': 2, '2000541002': 2, '2000541003': 2, '2000541006': 2, '2000541007': 3, '2000541010': 3, '2000541011': 2, '2000541014': 3, '2000541015': 2, '2000541016': 2, '2000541018': 2, '2000541019': 3, '2000541020': 3, '2000541021': 3, '2000541022': 3, '2000541023': 2, '2000541024': 3, '2000541025': 3, '2000541027': 2, '2000541028': 3, '2000541029': 2, '2000541030': 3, '2000541031': 3, '2000541032': 3, '2000541034': 2, '2000541035': 2, '2000541038': 2, '2000541039': 2, '2000541040': 2, '2000541041': 2, '2000541043': 3, '2000541044': 3, '2000541045': 2, '2000541046': 2, '2000541049': 2, '2000541050': 3, '2000541051': 2, '2000541052': 2, '2000541053': 2, '2000541054': 2, '2000541055': 3, '2000541056': 3, '2000541057': 2, '2000541059': 3, '2000541062': 3, '2000541064': 2, '2000541066': 2, '2000541067': 2, '2000541068': 2, '2000541069': 2, '2000541070': 2, '2000541071': 2, '2000541072': 3, '2000541073': 3, '2000541074': 3, '2000541075': 2, '2000541076': 3, '2000541077': 2, '2000541079': 2, '2000541080': 3, '2000541081': 3, '2000542001': 2, '2000542002': 2, '2000542007': 2, '2000542008': 2, '2000542009': 2, '2000542010': 2, '2000542013': 3, '2000542015': 3, '2000542016': 2, '2000542021': 2, '2000542022': 2, '2000542025': 3, '2000542026': 3, '2000542027': 3, '2000542029': 3, '2000542030': 3, '2000542032': 2, '2000542033': 3, '2000542034': 2, '2000542035': 3, '2000542036': 2, '2000542042': 3, '2000542049': 2, '2000542050': 3, '2000542051': 2, '2000542052': 3, '2000542054': 2, '2000542056': 2, '2026140111': 3, '2026140113': 3, '2026140116': 3, '2026140117': 3, '2026140118': 2, '2026140119': 3, '2026140120': 3, '2026140122': 3, '2026140124': 2, '2026140125': 3, '2026140126': 2, '2026140128': 2, '2026140129': 3, '2026140130': 3, '2026140131': 3, '2026140133': 3, '2026140134': 3, '2026140135': 2, '2026140138': 3, '2026140141': 3, '2026140145': 2, '2026140147': 3, '2026140149': 2, '202614015': 3, '2026140151': 3, '2026140154': 2, '2026140158': 3, '2026140159': 3, '202614016': 3, '2026140160': 2, '2026140161': 3, '2026140165': 3, '2026140169': 3, '202614017': 3, '2026140170': 2, '2026140172': 2, '202614018': 3, '202614019': 2, '202614020': 3, '202614021': 3, '2026140210': 2, '2026140212': 3, '2026140213': 2, '2026140220': 2, '2026140221': 3, '2026140223': 3, '2026140224': 3, '2026140225': 2, '202614023': 3, '2026140230': 2, '2026140233': 2, '2026140236': 3, '2026140237': 2, '2026140239': 2, '2026140241': 3, '2026140243': 3, '2026140246': 3, '2026140247': 3, '2026140249': 3, '202614025': 3, '2026140250': 3, '2026140253': 2, '2026140254': 2, '2026140255': 2, '2026140257': 1, '2026140259': 3, '2026140260': 3, '2026140263': 2, '2026140264': 1, '2026140272': 3, '2026140273': 1, '2026140275': 3, '2026140276': 3, '2026140277': 3, '2026140279': 3, '2026140281': 3, '202614029': 2, '205601011': 3, '2056010112': 2, '2056010113': 2, '2056010114': 2, '2056010116': 2, '2056010118': 2, '2056010119': 2, '205601012': 2, '2056010120': 3, '2056010122': 3, '2056010123': 3, '2056010124': 3, '2056010126': 2, '2056010130': 2, '2056010133': 3, '2056010134': 0, '2056010136': 2, '2056010137': 2, '2056010139': 3, '2056010141': 3, '2056010142': 2, '2056010148': 2, '2056010149': 2, '2056010153': 3, '2056010155': 3, '2056010156': 2, '2056010157': 2, '205601016': 3, '2056010160': 3, '2056010162': 2, '2056010164': 2, '2056010165': 2, '2056010167': 3, '205601017': 3, '205601018': 2, '2056010210': 2, '2056010212': 3, '2056010213': 2, '2056010214': 3, '2056010215': 2, '2056010218': 3, '2056010219': 2, '2056010222': 2, '2056010224': 1, '2056010225': 3, '2056010226': 3, '2056010228': 3, '2056010229': 3, '2056010230': 3, '2056010232': 3, '2056010233': 3, '2056010234': 2, '2056010235': 3, '2056010236': 2, '2056010238': 3, '2056010239': 3, '205601024': 2, '2056010240': 2, '2056010241': 2, '2056010242': 2, '2056010244': 2, '2056010245': 2, '2056010247': 3, '2056010249': 3, '205601025': 3, '2056010250': 2, '2056010252': 2, '2056010253': 3, '2056010254': 3, '2056010255': 3, '2056010258': 2, '2056010260': 3, '2056010261': 2, '2056010262': 3, '2056010263': 3, '2056010265': 3, '2056010267': 2, '2056010269': 3, '205601027': 3, '2056010272': 2, '2056010274': 2, '2056010275': 3, '2056010276': 3, '2056010277': 3, '2056010279': 2, '205601028': 2, '2056010281': 3, '2056010283': 2, '2100511002': 3, '2100511003': 3, '2100511005': 2, '2100511008': 3, '2100511011': 2, '2100511012': 3, '2100511013': 2, '2100511015': 2, '2100511016': 3, '2100511018': 3, '2100511019': 2, '2100511024': 2, '2100511026': 2, '2100511027': 2, '2100511028': 3, '2100511031': 3, '2100511032': 2, '2100511034': 2, '2100511035': 2, '2100511036': 2, '2100511038': 3, '2100511039': 2, '2100511040': 3, '2100511044': 2, '2100511048': 2, '2100511057': 3, '2100511058': 3, '2100511059': 2, '2100511060': 3, '2100511061': 2, '2100511062': 3, '2100511063': 3, '2100511064': 2, '2100511065': 3, '2100511067': 3, '2100511069': 1, '2100511070': 2, '2100511071': 3, '2100511072': 3, '2100511073': 3, '2100511074': 3, '2100511076': 2, '2100511077': 3, '2100511078': 3, '2100511079': 3, '2100511080': 3, '2100511081': 2, '2100511082': 3, '2100512001': 3, '2100512002': 2, '2100512003': 2, '2100512006': 2, '2100512007': 3, '2100512009': 3, '2100512010': 3, '2100512011': 2, '2100512012': 3, '2100512014': 3, '2100512015': 2, '2100512016': 3, '2100512017': 3, '2100512018': 2, '2100512020': 3, '2100512021': 3, '2100512025': 3, '2100512026': 2, '2100512028': 2, '2100512029': 3, '2100512032': 3, '2100512034': 3, '2100512035': 2, '2100512036': 2, '2100512037': 2, '2100512038': 3, '2100512039': 2, '2100512041': 2, '2100512042': 3, '2100512044': 2, '2100512045': 2, '2100512051': 1, '2100512052': 3, '2100512053': 3, '2100512055': 2, '2100512057': 3, '2100512058': 3, '2100512061': 3, '2100512062': 3, '2100512063': 3, '2100512064': 1, '2100512065': 2, '2100521002': 3, '2100521005': 3, '2100521006': 3, '2100521008': 3, '2100521009': 2, '2100521010': 2, '2100521013': 2, '2100521014': 2, '2100521015': 3, '2100521016': 3, '2100521017': 2, '2100521018': 2, '2100521021': 3, '2100521022': 2, '2100521023': 2, '2100521024': 2, '2100521025': 2, '2100521026': 2, '2100521027': 2, '2100521028': 2, '2100521029': 3, '2100521030': 2, '2100521031': 2, '2100521032': 1, '2100521033': 3, '2100521034': 2, '2100521035': 2, '2100521037': 3, '2100521038': 2, '2100521039': 2, '2100521040': 3, '2100521041': 2, '2100521042': 2, '2100521043': 2, '2100521044': 3, '2100521046': 2, '2100521047': 2, '2100521048': 2, '2100521049': 2, '2100521050': 2, '2100521051': 2, '2100521052': 2, '2100521054': 2, '2100521055': 2, '2100521056': 2, '2100521057': 2, '2100521059': 3, '2100521060': 2, '2100521061': 2, '2100521062': 2, '2100521063': 2, '2100521067': 2, '2100521069': 2, '2100521070': 2, '2100521072': 3, '2100521073': 2, '2100521074': 3, '2100521075': 2, '2100521076': 3, '2100521077': 2, '2100521078': 3, '2100521079': 2, '2100522001': 2, '2100522004': 3, '2100522005': 2, '2100522006': 2, '2100522007': 3, '2100522008': 2, '2100522009': 3, '2100522010': 2, '2100522011': 2, '2100522012': 2, '2100522013': 2, '2100522018': 2, '2100522019': 3, '2100522020': 2, '2100522021': 2, '2100522023': 3, '2100522024': 3, '2100522026': 3, '2100522028': 2, '2100522031': 3, '2100522033': 2, '2100522034': 2, '2100522035': 2, '2100522036': 2, '2100522038': 2, '2100522039': 2, '2100522040': 2, '2100522041': 2, '2100522042': 2, '2100522046': 2, '2100522047': 2, '2100522048': 2, '2100522049': 3, '2100522050': 2, '2100522051': 2, '2100522052': 2, '2100522053': 2, '2100522054': 3, '2100522055': 3, '2100522056': 2, '2100522059': 2, '2100522060': 2, '2100522061': 2, '2100522062': 2, '2100522063': 3, '2100522064': 2, '2100522067': 2, '2100522068': 2, '2100522070': 2, '2100531001': 3, '2100531002': 2, '2100531003': 3, '2100531004': 3, '2100531006': 3, '2100531007': 2, '2100531008': 2, '2100531009': 3, '2100531010': 3, '2100531012': 3, '2100531013': 2, '2100531014': 3, '2100531015': 3, '2100531016': 2, '2100531017': 2, '2100531018': 3, '2100531019': 3, '2100531021': 3, '2100531022': 2, '2100531023': 3, '2100531024': 3, '2100531025': 2, '2100531026': 2, '2100531027': 3, '2100531028': 3, '2100531030': 2, '2100531031': 2, '2100531033': 2, '2100531034': 3, '2100531035': 3, '2100531036': 2, '2100531037': 2, '2100531040': 3, '2100531041': 2, '2100531042': 3, '2100531043': 3, '2100531044': 3, '2100531045': 3, '2100531047': 3, '2100531048': 2, '2100531049': 3, '2100531050': 2, '2100531051': 3, '2100531052': 3, '2100531053': 2, '2100531054': 1, '2100531055': 3, '2100531056': 2, '2100531057': 3, '2100531058': 3, '2100531059': 2, '2100531060': 3, '2100531061': 2, '2100531063': 3, '2100531064': 2, '2100531065': 2, '2100531066': 3, '2100531067': 3, '2100531068': 3, '2100531070': 2, '2100531071': 2, '2100531072': 2, '2100531073': 2, '2100531074': 3, '2100531076': 3, '2100531077': 3, '2100531078': 3, '2100531079': 3, '2100531080': 3, '2100531081': 2, '2100531082': 3, '2100531084': 3, '2100532002': 2, '2100532003': 2, '2100532004': 2, '2100532005': 3, '2100532007': 2, '2100532008': 2, '2100532010': 2, '2100532012': 2, '2100532013': 2, '2100532015': 2, '2100532016': 1, '2100532017': 3, '2100532019': 2, '2100532020': 2, '2100532022': 0, '2100532023': 2, '2100532024': 3, '2100532025': 3, '2100532026': 3, '2100532027': 3, '2100532028': 3, '2100532029': 2, '2100532030': 2, '2100532031': 2, '2100532032': 3, '2100532033': 2, '2100532034': 2, '2100532037': 3, '2100532042': 2, '2100532043': 3, '2100532044': 2, '2100532045': 2, '2100532046': 3, '2100532047': 2, '2100532048': 3, '2100532050': 3, '2100532052': 2, '2100532053': 3, '2100532054': 3, '2100532055': 3, '2100532056': 2, '2100532057': 2, '2100532058': 3, '2100532059': 3, '2100532060': 3, '2100532061': 3, '2100532062': 2, '2100532063': 3, '2100532064': 3, '2100532066': 3, '2100532067': 2, '2100532068': 3, '2100532070': 3, '2100532071': 3, '2100532072': 2, '2100551002': 2, '2100551005': 0, '2100551006': 2, '2100551007': 3, '2100551010': 1, '2100551011': 2, '2100551013': 3, '2100551014': 2, '2100551015': 2, '2100551016': 2, '2100551017': 3, '2100551018': 3, '2100551019': 3, '2100551020': 2, '2100551021': 3, '2100551022': 2, '2100551023': 2, '2100551024': 3, '2100551025': 2, '2100551027': 2, '2100551028': 3, '2100551029': 2, '2100551032': 1, '2100551033': 2, '2100551034': 2, '2100551035': 1, '2100551036': 2, '2100551037': 2, '2100551039': 2, '2100551041': 2, '2100551042': 1, '2100551043': 2, '2100551044': 2, '2100551045': 2, '2100551046': 2, '2100551049': 3, '2100551050': 3, '2100551051': 2, '2100551052': 2, '2100551053': 3, '2100551054': 2, '2100551055': 2, '2100551056': 3, '2100551057': 3, '2100551059': 2, '2100551060': 3, '2100551061': 2, '2100551062': 2, '2100551063': 2, '2100551064': 2, '2100551065': 2, '2100551066': 3, '2100551067': 2, '2100551068': 3, '2100551069': 3, '2100551071': 3, '2100551072': 2, '2100551073': 2, '2100551074': 2, '2100551075': 2, '2100551076': 3, '2100551077': 2, '2100551079': 2, '2100551080': 3, '2100551081': 2, '2100552002': 3, '2100552003': 2, '2100552004': 2, '2100552005': 2, '2100552006': 2, '2100552007': 2, '2100552008': 2, '2100552009': 3, '2100552010': 2, '2100552011': 2, '2100552012': 2, '2100552013': 2, '2100552014': 2, '2100552015': 3, '2100552016': 2, '2100552017': 2, '2100552018': 2, '2100552019': 3, '2100552021': 2, '2100552022': 3, '2100552023': 2, '2100552024': 2, '2100552025': 3, '2100552027': 3, '2100552028': 3, '2100552029': 3, '2100552030': 3, '2100552031': 2, '2100552032': 3, '2100552033': 3, '2100552034': 3, '2100552035': 2, '2100552037': 2, '2100552038': 2, '2100552039': 2, '2100552041': 2, '2100552042': 3, '2100552043': 2, '2100552044': 3, '2100552045': 2, '2100552047': 3, '2100552048': 1, '2100552051': 3, '2100552052': 3, '2100552053': 2, '2100552055': 2, '2100552057': 3, '2100552059': 3, '2100552060': 2, '2100552061': 3, '2100552062': 2, '2100552063': 1, '2100552065': 2, '2100552066': 2, '2100552068': 2, '2100552072': 2, '2100561006': 2, '2100561010': 2, '2100561011': 2, '2100561013': 3, '2100561014': 3, '2100561015': 2, '2100561016': 2, '2100561018': 3, '2100561019': 3, '2100561020': 3, '2100561021': 3, '2100561022': 2, '2100561023': 3, '2100561024': 2, '2100561027': 3, '2100561029': 3, '2100561032': 2, '2100561038': 2, '2100561043': 3, '2100561044': 3, '2100561046': 3, '2100561051': 2, '2100561052': 3, '2100561053': 3, '2100561054': 2, '2100561056': 2, '2100561057': 3, '2100561058': 3, '2100561059': 3, '2100561062': 3, '2100561063': 2, '2100561064': 3, '2100561065': 3, '2100561070': 3, '2100561071': 2, '2100561074': 3, '2100561079': 2, '2100562001': 3, '2100562002': 3, '2100562003': 3, '2100562004': 3, '2100562005': 2, '2100562007': 3, '2100562008': 2, '2100562009': 3, '2100562010': 3, '2100562011': 3, '2100562012': 3, '2100562013': 2, '2100562014': 3, '2100562015': 3, '2100562017': 3, '2100562018': 3, '2100562019': 1, '2100562020': 2, '2100562024': 1, '2100562026': 2, '2100562027': 2, '2100562029': 3, '2100562030': 2, '2100562032': 2, '2100562033': 2, '2100562034': 3, '2100562035': 3, '2100562037': 3, '2100562038': 2, '2100562039': 2, '2100562040': 2, '2100562042': 3, '2100562043': 2, '2100562044': 2, '2100562046': 2, '2100562047': 3, '2100562048': 3, '2100562049': 2, '2100562050': 2, '2100562051': 2, '2100562053': 3, '2100562054': 2, '2100562055': 2, '2100562056': 3, '2100562058': 3, '2100562059': 3, '2100562060': 2, '2100562061': 3, '2100571001': 2, '2100571002': 1, '2100571004': 2, '2100571007': 1, '2100571008': 3, '2100571009': 2, '2100571011': 2, '2100571012': 2, '2100571013': 3, '2100571015': 2, '2100571017': 2, '2100571018': 2, '2100571019': 2, '2100571020': 2, '2100571021': 1, '2100571022': 2, '2100571023': 1, '2100571024': 2, '2100571025': 2, '2100571027': 2, '2100571029': 2, '2100571030': 2, '2100571031': 2, '2100571033': 2, '2100571034': 2, '2100571036': 2, '2100571038': 1, '2100571039': 2, '2100571040': 3, '2100571041': 3, '2100571042': 3, '2100571044': 1, '2100571045': 3, '2100571046': 3, '2100571047': 2, '2100571048': 3, '2100571049': 1, '2100571050': 2, '2100571051': 2, '2100571052': 2, '2100571053': 2, '2100571055': 3, '2100571056': 2, '2100571057': 2, '2100571058': 2, '2100571061': 2, '2100571062': 1, '2100571063': 2, '2100571064': 2, '2100571065': 3, '2100571066': 2, '2100571067': 2, '2100571068': 2, '2100571069': 2, '2100571070': 2, '2100571072': 3, '2100571073': 2, '2100571074': 2, '2100571075': 3, '2100571077': 3, '2100571078': 3, '2100571079': 2, '2100571081': 3, '2100571082': 2, '2100572001': 2, '2100572002': 3, '2100572004': 2, '2100572006': 3, '2100572009': 2, '2100572010': 3, '2100572011': 3, '2100572012': 2, '2100572013': 3, '2100572015': 3, '2100572017': 3, '2100572018': 3, '2100572019': 2, '2100572020': 2, '2100572021': 1, '2100572023': 2, '2100572024': 3, '2100572025': 2, '2100572026': 2, '2100572027': 2, '2100572028': 2, '2100572029': 2, '2100572030': 2, '2100572032': 2, '2100572033': 3, '2100572034': 2, '2100572036': 2, '2100572038': 2, '2100572039': 3, '2100572040': 2, '2100572041': 3, '2100572042': 2, '2100572043': 2, '2100572044': 2, '2100572045': 2, '2100572046': 3, '2100572047': 3, '2100572048': 3, '2100572050': 3, '2100572051': 3, '2100572054': 2, '2100572055': 3, '2100572056': 3, '2100572057': 1, '2100572058': 2, '2100572059': 2, '2100572060': 2, '2100572061': 2, '2100572062': 3, '2100572063': 2, '2100572064': 3, '2100572067': 2, '2100572068': 2, '2100572069': 2, '2100581001': 1, '2100581002': 3, '2100581003': 2, '2100581004': 2, '2100581005': 2, '2100581006': 2, '2100581007': 3, '2100581009': 2, '2100581010': 2, '2100581011': 3, '2100581012': 3, '2100581013': 2, '2100581014': 3, '2100581015': 3, '2100581018': 3, '2100581019': 3, '2100581021': 1, '2100581022': 2, '2100581024': 2, '2100581025': 3, '2100581026': 2, '2100581027': 2, '2100581028': 3, '2100581029': 2, '2100581030': 2, '2100581034': 2, '2100581035': 2, '2100581036': 3, '2100581037': 3, '2100581038': 2, '2100581039': 2, '2100581040': 2, '2100581041': 2, '2100581042': 2, '2100581044': 2, '2100581045': 2, '2100581051': 2, '2100581054': 3, '2100581056': 3, '2100581057': 3, '2100581058': 3, '2100581059': 2, '2100581061': 2, '2100581062': 3, '2100581064': 3, '2100581066': 2, '2100581067': 2, '2100581068': 2, '2100581069': 2, '2100581070': 2, '2100581071': 2, '2100581072': 2, '2100581073': 2, '2100581074': 2, '2100581075': 3, '2100581076': 2, '2100581077': 3, '2100582001': 2, '2100582002': 2, '2100582003': 3, '2100582004': 3, '2100582005': 3, '2100582006': 2, '2100582008': 2, '2100582009': 3, '2100582012': 2, '2100582013': 2, '2100582015': 2, '2100582017': 2, '2100582019': 2, '2100582020': 2, '2100582021': 2, '2100582023': 2, '2100582024': 2, '2100582025': 3, '2100582026': 3, '2100582027': 1, '2100582028': 2, '2100582038': 2, '2100582043': 3, '2100582044': 2, '2100582045': 2, '2100582046': 2, '2100582048': 3, '2100582050': 2, '2100582051': 2, '2100582052': 0, '2100582053': 3, '2100582054': 2, '2100582055': 0, '2100582056': 0, '2100582057': 0, '2100582058': 0, '2100582060': 0, '2100582061': 1, '2100582062': 0, '2100582064': 3, '2100582067': 2, '2100582069': 2, '2100591002': 3, '2100591003': 3, '2100591004': 3, '2100591005': 3, '2100591006': 3, '2100591007': 3, '2100591008': 3, '2100591010': 3, '2100591013': 2, '2100591015': 2, '2100591016': 3, '2100591017': 2, '2100591019': 2, '2100591020': 3, '2100591021': 2, '2100591022': 3, '2100591023': 2, '2100591025': 3, '2100591026': 2, '2100591027': 2, '2100591028': 2, '2100591030': 2, '2100591034': 3, '2100591035': 3, '2100591036': 3, '2100591037': 2, '2100591038': 2, '2100591039': 2, '2100591040': 3, '2100591041': 2, '2100591042': 3, '2100591043': 2, '2100591044': 3, '2100591045': 2, '2100591046': 1, '2100591047': 3, '2100591048': 3, '2100591049': 2, '2100591050': 3, '2100591053': 3, '2100591054': 3, '2100591055': 3, '2100591056': 3, '2100591057': 3, '2100591059': 3, '2100591060': 2, '2100591061': 3, '2100591062': 2, '2100591064': 2, '2100591065': 3, '2100591066': 3, '2100591067': 3, '2100591068': 3, '2100591069': 3, '2100591070': 3, '2100591072': 3, '2100591073': 3, '2100591074': 3, '2100591075': 3, '2100591076': 3, '2100591077': 3, '2100591078': 3, '2100591080': 3, '2100591081': 2, '2100591082': 3, '2100592002': 3, '2100592003': 3, '2100592004': 2, '2100592005': 3, '2100592007': 3, '2100592009': 3, '2100592010': 3, '2100592011': 2, '2100592012': 3, '2100592013': 2, '2100592014': 2, '2100592015': 3, '2100592016': 3, '2100592017': 3, '2100592018': 2, '2100592019': 3, '2100592020': 3, '2100592021': 3, '2100592022': 2, '2100592023': 3, '2100592024': 3, '2100592025': 2, '2100592026': 3, '2100592027': 2, '2100592028': 3, '2100592029': 3, '2100592030': 2, '2100592032': 3, '2100592033': 3, '2100592034': 3, '2100592035': 2, '2100592036': 2, '2100592038': 2, '2100592040': 2, '2100592041': 3, '2100592042': 3, '2100592043': 2, '2100592044': 3, '2100592046': 2, '2100592047': 3, '2100592048': 2, '2100592049': 3, '2100592052': 2, '2100592053': 3, '2100592054': 2, '2100592056': 2, '2100592057': 2, '2100592058': 2, '2100592059': 3, '2100592060': 2, '2100592064': 2, '2100592065': 2, '2100592066': 2, '2100592067': 3, '2100592068': 2, '2100592069': 3, '2100592070': 2, '2100592071': 2, '2100592072': 3, '2100601001': 3, '2100601002': 3, '2100601004': 2, '2100601005': 2, '2100601006': 2, '2100601007': 2, '2100601008': 3, '2100601009': 2, '2100601010': 3, '2100601011': 3, '2100601012': 1, '2100601013': 2, '2100601014': 3, '2100601015': 2, '2100601016': 3, '2100601017': 3, '2100601018': 1, '2100601020': 3, '2100601021': 2, '2100601023': 2, '2100601024': 2, '2100601025': 2, '2100601027': 2, '2100601028': 2, '2100601029': 2, '2100601030': 3, '2100601031': 2, '2100601032': 2, '2100601033': 3, '2100601035': 3, '2100601036': 2, '2100601037': 3, '2100601038': 3, '2100601039': 2, '2100601040': 3, '2100601041': 3, '2100601042': 3, '2100601043': 3, '2100601044': 3, '2100601045': 3, '2100601046': 3, '2100601049': 2, '2100601050': 2, '2100601052': 2, '2100601053': 2, '2100601054': 2, '2100601055': 3, '2100601056': 2, '2100601057': 3, '2100601059': 2, '2100601062': 3, '2100601063': 3, '2100601064': 2, '2100601065': 3, '2100601066': 3, '2100601067': 3, '2100601068': 2, '2100601069': 3, '2100601071': 3, '2100601073': 3, '2100601074': 2, '2100601075': 2, '2100601077': 3, '2100601078': 2, '2100602001': 2, '2100602002': 2, '2100602003': 2, '2100602004': 2, '2100602005': 2, '2100602006': 3, '2100602008': 2, '2100602009': 2, '2100602010': 3, '2100602011': 2, '2100602012': 2, '2100602014': 2, '2100602015': 2, '2100602017': 3, '2100602018': 2, '2100602019': 2, '2100602020': 3, '2100602022': 2, '2100602023': 2, '2100602024': 2, '2100602025': 3, '2100602026': 2, '2100602027': 3, '2100602028': 2, '2100602029': 2, '2100602030': 2, '2100602032': 2, '2100602033': 3, '2100602034': 2, '2100602035': 2, '2100602036': 2, '2100602038': 2, '2100602040': 2, '2100602041': 0, '2100602042': 2, '2100602043': 3, '2100602044': 2, '2100602046': 2, '2100602047': 3, '2100602049': 3, '2100602050': 3, '2100602051': 2, '2100602052': 3, '2100602053': 2, '2100602054': 3, '2100602056': 2, '2100602058': 2, '2100602059': 2, '2100602060': 2, '2100602061': 2, '2100602062': 3, '2100602063': 3, '2100602065': 2, '2100602067': 3, '2100602068': 2, '2100602069': 2, '2100602072': 3, '2100611002': 3, '2100611003': 3, '2100611004': 3, '2100611005': 2, '2100611006': 2, '2100611010': 2, '2100611011': 3, '2100611012': 3, '2100611013': 3, '2100611014': 3, '2100611015': 3, '2100611016': 2, '2100611017': 2, '2100611018': 2, '2100611019': 2, '2100611021': 3, '2100611023': 2, '2100611024': 3, '2100611025': 3, '2100611026': 3, '2100611027': 1, '2100611028': 2, '2100611029': 2, '2100611031': 2, '2100611032': 3, '2100611034': 3, '2100611035': 3, '2100611036': 2, '2100611037': 2, '2100611038': 3, '2100611039': 3, '2100611040': 2, '2100611041': 3, '2100611042': 2, '2100611043': 2, '2100611044': 3, '2100611045': 2, '2100611046': 3, '2100611047': 2, '2100611048': 3, '2100611049': 3, '2100611050': 2, '2100611051': 3, '2100611052': 2, '2100611055': 3, '2100611056': 3, '2100611057': 2, '2100611058': 2, '2100611059': 3, '2100611060': 2, '2100611061': 3, '2100611062': 2, '2100611063': 3, '2100611064': 3, '2100611066': 3, '2100611067': 2, '2100611068': 2, '2100611069': 3, '2100611070': 2, '2100611071': 2, '2100611075': 2, '2100611076': 3, '2100611077': 3, '2100611078': 2, '2100611079': 2, '2100611081': 3, '2100611083': 2, '2100612001': 3, '2100612002': 3, '2100612003': 2, '2100612005': 2, '2100612006': 2, '2100612007': 3, '2100612008': 3, '2100612009': 1, '2100612010': 3, '2100612011': 3, '2100612012': 3, '2100612014': 3, '2100612015': 3, '2100612020': 3, '2100612022': 3, '2100612024': 3, '2100612025': 3, '2100612026': 3, '2100612027': 2, '2100612028': 2, '2100612029': 3, '2100612030': 2, '2100612031': 3, '2100612033': 2, '2100612034': 2, '2100612035': 3, '2100612037': 2, '2100612038': 3, '2100612040': 3, '2100612041': 2, '2100612042': 2, '2100612043': 3, '2100612044': 2, '2100612045': 3, '2100612046': 3, '2100612047': 3, '2100612048': 3, '2100612051': 3, '2100612053': 3, '2100612056': 2, '2100612057': 3, '2100612058': 3, '2100612059': 3, '2100612060': 3, '2100612061': 3, '2100612062': 3, '2100612063': 2, '2100612064': 2, '2100612065': 3, '2100612066': 3, '2100612067': 3, '2100612068': 2, '2100612069': 2, '2100612070': 2, '2100612071': 2, '2100612072': 3, '2260510110': 2, '2260510113': 3, '2260510114': 2, '2260510115': 3, '2260510116': 2, '2260510118': 2, '2260510122': 2, '2260510124': 2, '2260510125': 2, '2260510126': 2, '2260510127': 3, '2260510129': 2, '226051013': 2, '2260510131': 2, '2260510134': 2, '2260510136': 2, '2260510138': 2, '2260510139': 2, '226051014': 2, '2260510140': 3, '2260510141': 2, '2260510142': 2, '2260510143': 2, '2260510146': 3, '2260510147': 2, '2260510148': 2, '2260510151': 3, '2260510152': 3, '2260510155': 1, '2260510156': 2, '2260510158': 2, '2260510159': 2, '226051016': 2, '2260510160': 2, '2260510162': 2, '2260510163': 1, '2260510167': 2, '2260510168': 3, '226051017': 2, '2260510172': 3, '2260510174': 2, '2260510176': 2, '2260510177': 1, '2260510180': 2, '2260510182': 2, '2260510183': 2, '2260510185': 2, '226051019': 3, '226051021': 2, '2260510212': 3, '2260510213': 3, '2260510214': 3, '2260510217': 2, '226051022': 3, '2260510220': 3, '2260510221': 2, '2260510222': 3, '2260510223': 3, '2260510227': 3, '2260510228': 2, '2260510229': 3, '226051023': 3, '2260510230': 3, '2260510231': 3, '2260510232': 3, '2260510233': 3, '2260510237': 3, '2260510238': 3, '2260510240': 3, '2260510241': 3, '2260510242': 3, '2260510243': 3, '2260510244': 3, '2260510247': 3, '2260510248': 3, '226051025': 3, '2260510250': 2, '2260510252': 3, '2260510253': 3, '2260510254': 2, '2260510257': 2, '2260510258': 3, '2260510259': 3, '226051026': 3, '2260510260': 3, '2260510262': 2, '2260510266': 3, '2260510267': 3, '226051027': 3, '2260510270': 3, '2260510271': 2, '2260510272': 3, '2260510276': 2, '2260510277': 2, '2260510278': 3, '240846010': 3, '240846011': 3, '2408460110': 3, '2408460111': 2, '2408460118': 1, '240846012': 2, '2408460120': 2, '2408460123': 3, '2408460125': 3, '2408460126': 2, '2408460127': 2, '2408460129': 2, '240846013': 2, '2408460130': 2, '2408460131': 2, '2408460132': 2, '2408460133': 3, '2408460134': 3, '2408460135': 3, '2408460137': 1, '2408460139': 3, '2408460143': 2, '2408460145': 3, '2408460146': 3, '2408460148': 2, '2408460149': 2, '240846015': 2, '2408460150': 2, '2408460151': 3, '2408460152': 3, '2408460154': 3, '2408460155': 3, '2408460156': 2, '2408460158': 2, '2408460159': 2, '240846016': 2, '2408460163': 2, '2408460166': 2, '240846017': 2, '240846018': 2, '240846019': 2, '2408460211': 2, '2408460212': 3, '2408460213': 3, '2408460215': 3, '2408460217': 2, '2408460219': 2, '240846022': 2, '2408460220': 3, '2408460221': 3, '2408460222': 2, '2408460223': 2, '2408460225': 3, '2408460226': 2, '2408460227': 3, '2408460229': 2, '240846023': 2, '2408460234': 2, '2408460236': 3, '2408460237': 3, '2408460238': 2, '240846024': 2, '2408460240': 2, '2408460242': 3, '2408460243': 3, '2408460244': 2, '2408460246': 3, '2408460247': 3, '2408460249': 3, '2408460252': 3, '2408460254': 2, '2408460255': 3, '2408460257': 3, '2408460260': 3, '2408460261': 3, '2408460265': 3, '2408460266': 3, '2408460268': 3, '2408460269': 2, '240846027': 2, '2408460271': 2, '2408460272': 2, '2408460274': 2, '2408460276': 3, '2408460277': 3, '2408460278': 2, '240846028': 2, '2408460280': 3, '240846029': 2, '24851011': 2, '248510111': 3, '248510112': 3, '248510114': 2, '248510116': 3, '248510117': 3, '248510118': 2, '248510119': 3, '248510120': 3, '248510125': 3, '248510127': 2, '248510128': 3, '248510129': 3, '24851013': 3, '248510131': 2, '248510136': 3, '248510137': 3, '24851014': 2, '248510142': 2, '248510147': 3, '248510148': 3, '24851015': 3, '248510150': 3, '248510151': 3, '248510153': 2, '248510155': 3, '248510156': 2, '248510157': 2, '248510160': 3, '248510161': 3, '248510163': 2, '248510164': 3, '248510167': 3, '248510170': 3, '24851018': 3, '24851019': 3, '248510211': 3, '248510212': 3, '248510213': 2, '248510214': 2, '248510215': 3, '248510216': 3, '24851022': 3, '248510220': 3, '248510223': 3, '248510225': 3, '248510227': 3, '248510229': 3, '248510230': 3, '248510232': 3, '248510233': 3, '248510235': 3, '248510236': 3, '24851024': 3, '248510241': 3, '248510242': 3, '248510245': 3, '248510246': 3, '248510248': 3, '248510249': 3, '248510250': 2, '248510251': 3, '248510253': 3, '248510255': 3, '248510256': 3, '248510259': 3, '24851026': 3, '248510260': 3, '248510262': 3, '248510264': 2, '248510265': 3, '248510267': 3, '248510268': 3, '24851027': 3, '248510271': 3, '248510272': 3, '248510273': 3, '248510276': 3, '248510278': 2, '24851028': 3, '2904280110': 3, '29042801110': 3, '29042801170': 3, '29042801180': 2, '2904280120': 3, '29042801220': 2, '29042801230': 3, '29042801250': 3, '29042801260': 3, '29042801290': 3, '29042801300': 3, '29042801320': 3, '29042801340': 3, '29042801350': 3, '29042801370': 1, '29042801390': 3, '2904280140': 2, '29042801440': 2, '29042801450': 3, '29042801470': 3, '29042801480': 2, '2904280150': 3, '29042801500': 3, '29042801550': 2, '29042801570': 2, '29042801580': 3, '2904280160': 2, '29042801600': 3, '29042801630': 3, '29042801640': 3, '29042801650': 2, '29042801680': 2, '29042801690': 2, '2904280170': 2, '29042801710': 3, '29042801740': 3, '29042801750': 3, '29042801770': 3, '29042801780': 2, '29042801790': 2, '2904280180': 3, '2904280190': 3, '29042802110': 2, '29042802140': 2, '29042802150': 2, '29042802180': 3, '29042802200': 3, '29042802220': 3, '29042802240': 3, '29042802260': 3, '29042802280': 3, '2904280230': 3, '29042802310': 3, '29042802320': 3, '29042802340': 3, '29042802350': 3, '29042802380': 2, '29042802390': 2, '29042802410': 3, '29042802420': 3, '29042802430': 3, '29042802440': 3, '29042802450': 3, '29042802460': 3, '29042802470': 3, '29042802480': 3, '2904280250': 2, '29042802500': 3, '29042802510': 3, '29042802520': 3, '29042802530': 3, '29042802560': 3, '29042802570': 3, '2904280260': 1, '29042802600': 2, '29042802640': 3, '29042802660': 2, '29042802670': 3, '29042802680': 3, '29042802690': 3, '2904280270': 2, '29042802700': 3, '29042802720': 3, '29042802740': 3, '29042802750': 3, '29042802760': 3, '29042802770': 2, '29042802790': 3, '2904280280': 3, '29042802800': 3, '29042802830': 3, '29042802860': 3, '2904280290': 2, '303830110': 2, '303830113': 1, '303830115': 2, '303830117': 3, '303830118': 3, '303830121': 3, '303830122': 3, '303830123': 2, '303830126': 1, '303830127': 3, '303830128': 2, '30383013': 3, '303830131': 2, '303830132': 2, '303830133': 2, '303830138': 3, '303830139': 1, '30383014': 3, '303830141': 3, '303830143': 2, '303830144': 3, '303830146': 2, '303830147': 3, '303830148': 2, '303830149': 0, '30383015': 2, '303830151': 3, '303830155': 1, '303830156': 3, '303830157': 3, '303830158': 3, '303830159': 2, '30383016': 3, '303830160': 2, '303830161': 2, '303830162': 3, '303830166': 3, '303830167': 2, '303830169': 2, '303830171': 3, '303830174': 3, '303830175': 2, '303830178': 2, '303830182': 3, '303830183': 2, '303830184': 3, '303830210': 3, '303830211': 3, '303830212': 3, '303830216': 2, '303830217': 3, '303830218': 2, '30383022': 2, '303830220': 3, '303830221': 3, '303830223': 3, '303830224': 2, '303830225': 2, '303830227': 3, '303830229': 2, '30383023': 1, '303830234': 3, '303830236': 3, '303830239': 3, '303830240': 3, '303830241': 3, '303830242': 3, '303830245': 3, '303830246': 2, '303830247': 3, '303830249': 3, '30383025': 2, '303830250': 2, '303830255': 3, '303830258': 3, '303830259': 3, '303830263': 3, '303830269': 2, '303830270': 3, '303830273': 3, '303830274': 3, '303830278': 2, '30383028': 3, '3100621001': 3, '3100621002': 3, '3100621003': 3, '3100621004': 2, '3100621005': 3, '3100621007': 3, '3100621009': 2, '3100621010': 3, '3100621011': 3, '3100621012': 2, '3100621013': 3, '3100621014': 3, '3100621016': 3, '3100621018': 2, '3100621019': 2, '3100621020': 2, '3100621022': 2, '3100621023': 3, '3100621024': 3, '3100621025': 2, '3100621026': 3, '3100621027': 3, '3100621028': 3, '3100621030': 2, '3100621031': 3, '3100621032': 2, '3100621033': 3, '3100621034': 2, '3100621035': 2, '3100621037': 1, '3100621039': 3, '3100621040': 3, '3100621041': 3, '3100621042': 2, '3100621043': 3, '3100621045': 3, '3100621046': 3, '3100621047': 3, '3100621048': 3, '3100621049': 3, '3100621051': 2, '3100621052': 2, '3100621053': 3, '3100621055': 3, '3100621057': 3, '3100621058': 3, '3100621059': 3, '3100621061': 2, '3100621062': 2, '3100621063': 3, '3100621064': 3, '3100622001': 2, '3100622002': 3, '3100622003': 3, '3100622006': 2, '3100622007': 3, '3100622008': 3, '3100622009': 2, '3100622011': 3, '3100622013': 3, '3100622015': 3, '3100622019': 2, '3100622020': 2, '3100622021': 2, '3100622023': 3, '3100622024': 2, '3100622026': 2, '3100622027': 2, '3100622033': 2, '3100622034': 3, '3100622036': 3, '3100622037': 2, '3100622038': 3, '3100622040': 3, '3100622041': 3, '3100622042': 3, '3100622043': 3, '3100622044': 2, '3100622045': 3, '3100622047': 3, '3100622048': 3, '3100622049': 2, '3100622051': 3, '3100622053': 2, '3100622054': 3, '3100622057': 2, '3100631001': 3, '3100631002': 3, '3100631003': 2, '3100631004': 3, '3100631005': 2, '3100631006': 3, '3100631008': 3, '3100631009': 3, '3100631010': 3, '3100631011': 3, '3100631013': 2, '3100631014': 2, '3100631015': 2, '3100631016': 3, '3100631018': 2, '3100631019': 3, '3100631022': 2, '3100631023': 2, '3100631025': 3, '3100631026': 3, '3100631027': 2, '3100631029': 3, '3100631032': 3, '3100631035': 3, '3100631037': 3, '3100631042': 2, '3100631043': 3, '3100631044': 3, '3100631045': 3, '3100631046': 3, '3100631047': 3, '3100631048': 2, '3100631049': 2, '3100631051': 3, '3100631052': 3, '3100631053': 2, '3100631054': 3, '3100631055': 2, '3100631056': 3, '3100631057': 2, '3100631058': 3, '3100631059': 3, '3100631062': 3, '3100632001': 2, '3100632002': 3, '3100632003': 2, '3100632004': 3, '3100632007': 3, '3100632008': 2, '3100632011': 2, '3100632012': 2, '3100632015': 3, '3100632016': 2, '3100632017': 3, '3100632018': 2, '3100632019': 3, '3100632021': 2, '3100632023': 3, '3100632024': 3, '3100632025': 3, '3100632026': 2, '3100632027': 3, '3100632030': 2, '3100632031': 3, '3100632039': 2, '3100632041': 3, '3100632042': 3, '3100632043': 3, '3100632044': 3, '3100632045': 2, '3100641002': 2, '3100641003': 1, '3100641004': 1, '3100641006': 1, '3100641007': 2, '3100641008': 2, '3100641023': 1, '3100642002': 3, '3100642003': 2, '3100642005': 2, '3100642006': 2, '3100642007': 1, '3100642008': 3, '3100642009': 3, '3100642011': 3, '3100642012': 2, '3100642013': 3, '3100642015': 2, '3100642017': 1, '3100642019': 3, '3100642020': 3, '3100642021': 2, '3100642022': 2, '3100642024': 3, '3100642025': 2, '3100642026': 2, '3100642027': 2, '3100642028': 2, '3100642030': 2, '3100642031': 2, '3100642032': 2, '3100642033': 3, '3100642034': 2, '3100642035': 2, '3100642036': 1, '3100642037': 2, '3100642038': 2, '3100642040': 2, '3100642045': 2, '3100642047': 3, '3100642052': 2, '3100642054': 3, '3100642055': 1, '3100642056': 3, '3100642057': 2, '3100642058': 2, '3100642060': 2, '3100642061': 2, '3100642063': 2, '3100642064': 2, '3100642066': 3, '3100642069': 2, '3100642070': 2, '3100661002': 2, '3100661007': 3, '3100661009': 2, '3100661015': 2, '3100661016': 3, '3100661022': 2, '3100661023': 2, '3100661024': 2, '3100661025': 2, '3100661027': 2, '3100661028': 2, '3100661029': 3, '3100661031': 2, '3100661032': 3, '3100661033': 2, '3100661036': 2, '3100661037': 2, '3100661038': 2, '3100661040': 2, '3100661043': 2, '3100661044': 2, '3100661046': 3, '3100661049': 2, '3100661050': 2, '3100662014': 3, '3100662015': 3, '3100662016': 2, '3100662017': 2, '3100662020': 3, '3100662022': 2, '3100662023': 2, '3100662026': 3, '3100662029': 2, '3100662032': 2, '3100662035': 2, '3100662036': 2, '3100662037': 1, '3100662045': 3, '3100662046': 2, '3100662048': 3, '3100662049': 3, '3100662050': 2, '3100662052': 3, '3100662053': 2, '3100662055': 2, '3100681001': 2, '3100681002': 2, '3100681005': 3, '3100681006': 3, '3100681015': 1, '3100681017': 1, '3100681018': 1, '3100681042': 1, '3100681043': 2, '3100681044': 3, '3100681045': 2, '3100681046': 2, '3100682001': 2, '3100682002': 3, '3100682003': 2, '3100682007': 3, '3100682008': 2, '3100682030': 2, '3100682040': 2, '3100691005': 2, '3100691006': 2, '3100691007': 2, '3100691011': 2, '3100691012': 2, '3100691021': 2, '3100691026': 2, '3100691042': 2, '3100691045': 2, '3100691048': 2, '3100692002': 2, '3100692005': 3, '3100692006': 2, '3100692007': 2, '3100692009': 3, '3100692010': 2, '3100692011': 3, '3100692012': 2, '3100692013': 2, '3100692015': 1, '3100692016': 2, '3100692020': 2, '3100692022': 2, '3100692023': 2, '3100692024': 2, '3100692025': 2, '3100692028': 2, '3100692029': 3, '3100692032': 2, '3100692034': 3, '3100692035': 3, '3100692038': 2, '3100692039': 2, '3100692045': 3, '3100692052': 2, '3100692054': 2, '3100692055': 2, '3100692056': 2, '3100701001': 2, '3100701002': 3, '3100701004': 3, '3100701005': 3, '3100701008': 2, '3100701009': 2, '3100701010': 1, '3100701011': 2, '3100701012': 3, '3100701013': 3, '3100701014': 2, '3100701015': 2, '3100701016': 3, '3100701019': 2, '3100701021': 2, '3100701022': 2, '3100701023': 1, '3100701024': 2, '3100701029': 2, '3100701031': 3, '3100701032': 2, '3100701036': 2, '3100701043': 2, '3100701044': 2, '3100701050': 2, '3100701051': 2, '3100701056': 3, '3100701057': 2, '3100701058': 3, '3100701061': 2, '3100701063': 2, '3100701072': 3, '3100701073': 2, '3100702004': 2, '3100702005': 3, '3100702006': 2, '3100702010': 2, '3100702012': 3, '3100702013': 3, '3100702016': 3, '3100702017': 2, '3100702019': 2, '3100702020': 2, '3100702021': 2, '3100702022': 2, '3100702023': 2, '3100702024': 2, '3100702025': 3, '3100702026': 2, '3100702027': 2, '3100702028': 2, '3100702029': 2, '3100702030': 2, '3100702031': 2, '3100702033': 2, '3100702034': 2, '3100702035': 2, '3100702036': 3, '3100702037': 3, '3100702038': 1, '3100702039': 3, '3100702040': 3, '3100702041': 3, '3100702043': 3, '3100702044': 2, '3100702045': 3, '3100702046': 3, '3100702047': 3, '3100702048': 3, '3100702051': 2, '3100702052': 3, '3100702054': 2, '3100702055': 2, '3100702059': 3, '3100702060': 2, '3100702061': 2, '3100702062': 2, '3100702063': 2, '3100702064': 2, '3100702065': 3, '3100702066': 2, '3100702067': 3, '3100702068': 2, '3100711007': 2, '3100711009': 2, '3100711042': 2, '3100711043': 3, '3100711049': 2, '3100711050': 2, '3100711051': 3, '3100711052': 2, '3100712014': 2, '3100721002': 2, '3100721003': 3, '3100721004': 3, '3100721005': 2, '3100721006': 2, '3100721007': 2, '3100721008': 2, '3100721011': 2, '3100721012': 3, '3100721013': 2, '3100721014': 3, '3100721015': 3, '3100721016': 3, '3100721018': 3, '3100721019': 3, '3100721020': 3, '3100721021': 2, '3100721022': 3, '3100721023': 3, '3100721024': 3, '3100721028': 2, '3100721029': 3, '3100721030': 3, '3100721031': 1, '3100721032': 3, '3100721033': 2, '3100721034': 2, '3100721036': 2, '3100721038': 2, '3100721039': 3, '3100721040': 3, '3100721041': 3, '3100721042': 3, '3100721044': 2, '3100721045': 3, '3100721046': 3, '3100721047': 3, '3100721048': 2, '3100721049': 2, '3100721050': 2, '3100721051': 3, '3100721052': 3, '3100721053': 2, '3100721054': 3, '3100721055': 3, '3100721056': 3, '3100721057': 3, '3100721058': 2, '3100721059': 3, '3100721060': 3, '3100721062': 3, '3100721063': 3, '3100721064': 3, '3100721065': 3, '3100721066': 3, '3100721068': 3, '3100721070': 3, '3100721071': 2, '3100721072': 2, '3100722003': 2, '3100722004': 3, '3100722005': 3, '3100722006': 2, '3100722007': 3, '3100722012': 3, '3100722013': 3, '3100722014': 3, '3100722016': 3, '3100722017': 3, '3100722020': 3, '3100722021': 3, '3100722022': 3, '3100722023': 3, '3100722024': 2, '3100722025': 3, '3100722026': 3, '3100722027': 2, '3100722030': 2, '3100722031': 3, '3100722032': 2, '3100722033': 2, '3100722034': 3, '3100722036': 2, '3100722038': 3, '3100722039': 3, '3100722040': 3, '3100722042': 3, '3100722044': 3, '3100722045': 2, '3100722046': 2, '3100722047': 3, '3100722048': 2, '3100722054': 3, '3100722055': 3, '3100722057': 3, '3100722059': 3, '3100722061': 3, '3100722062': 3, '3100722063': 3, '3100722064': 3, '3100722065': 3, '3100722066': 3, '3100722067': 3, '3100722068': 3, '3100722069': 3, '3100722070': 3, '3100722072': 3, '3100722073': 3, '3100722074': 2, '3100722076': 3, '3100722077': 3, '3100722078': 3, '3100722079': 3, '3100731001': 2, '3100731006': 2, '3100731007': 2, '3100731008': 2, '3100731009': 2, '3100731011': 2, '3100731012': 3, '3100731013': 3, '3100731014': 2, '3100731025': 3, '3100731026': 3, '3100731028': 2, '3100731029': 3, '3100731030': 2, '3100731031': 2, '3100731037': 3, '3100731038': 3, '3100731050': 2, '3100731052': 3, '3100731054': 3, '3100731056': 2, '3100731057': 3, '3100731058': 3, '3100732001': 3, '3100732002': 3, '3100732003': 2, '3100732006': 3, '3100732013': 2, '3100732014': 3, '3100732015': 2, '3100732017': 2, '3100732018': 3, '3100732020': 2, '3100732021': 2, '3100732022': 2, '3100732023': 2, '3100732025': 2, '3100732027': 2, '3100732028': 3, '3100732029': 3, '3100732031': 2, '3100732036': 2, '3100732040': 3, '3100732041': 2, '3100732042': 3, '3100732067': 3, '3100741001': 2, '3100741002': 2, '3100741003': 3, '3100741004': 3, '3100741011': 3, '3100741012': 2, '3100741013': 2, '3100741014': 2, '3100741016': 3, '3100741017': 3, '3100741018': 3, '3100741019': 3, '3100741020': 3, '3100741022': 3, '3100741023': 3, '3100741024': 3, '3100741025': 3, '3100741026': 3, '3100741027': 2, '3100741028': 2, '3100741029': 3, '3100741030': 2, '3100741032': 3, '3100741034': 3, '3100741035': 3, '3100741036': 3, '3100741037': 2, '3100741038': 3, '3100741039': 3, '3100741042': 3, '3100741043': 2, '3100741044': 3, '3100741045': 3, '3100741047': 3, '3100741049': 2, '3100741053': 2, '3100741054': 2, '3100741056': 2, '3100741057': 3, '3100741058': 3, '3100741059': 3, '3100741060': 3, '3100741061': 3, '3100741063': 3, '3100741064': 2, '3100741065': 3, '3100741066': 1, '3100741068': 2, '3100741069': 3, '3100741070': 3, '3100741071': 3, '3100741072': 3, '3100741073': 2, '3100741074': 3, '3100741075': 2, '3100741076': 3, '3100741077': 3, '3100741079': 3, '3100742001': 2, '3100742003': 2, '3100742004': 2, '3100742005': 2, '3100742007': 2, '3100742010': 2, '3100742011': 3, '3100742012': 3, '3100742013': 3, '3100742014': 2, '3100742015': 2, '3100742016': 2, '3100742018': 3, '3100742020': 2, '3100742021': 2, '3100742022': 3, '3100742023': 2, '3100742024': 3, '3100742025': 2, '3100742027': 2, '3100742028': 3, '3100742033': 3, '3100742034': 2, '3100742037': 2, '3100742038': 2, '3100742041': 3, '3100742042': 3, '3100742044': 2, '3100742045': 3, '3100742046': 2, '3100742047': 2, '3100742048': 2, '3100742050': 2, '3100742051': 2, '3100742052': 2, '3100742053': 2, '3100742054': 2, '3100742055': 2, '3100742056': 2, '3100742057': 3, '3100742058': 1, '3100742059': 3, '3100742060': 3, '3100742061': 2, '3100742062': 2, '3100742063': 2, '3100742065': 2, '3100742067': 3, '3100742068': 3, '3100751003': 2, '3100751004': 2, '3100751005': 2, '3100751006': 1, '3100751007': 0, '3100751008': 1, '3100751009': 3, '3100751010': 0, '3100751011': 3, '3100751012': 1, '3100751014': 2, '3100751015': 2, '3100751016': 2, '3100751017': 2, '3100751018': 3, '3100751019': 1, '3100751020': 3, '3100751021': 2, '3100751022': 2, '3100751024': 3, '3100751026': 2, '3100751027': 2, '3100751028': 2, '3100751032': 3, '3100751033': 2, '3100751034': 2, '3100751035': 2, '3100751037': 2, '3100751039': 2, '3100751040': 3, '3100751041': 2, '3100751043': 3, '3100751044': 3, '3100751045': 2, '3100751048': 2, '3100751050': 2, '3100751055': 3, '3100751056': 1, '3100751057': 1, '3100751058': 2, '3100751059': 2, '3100751063': 2, '3100751064': 2, '3100751065': 2, '3100751068': 3, '3100751069': 2, '3100751070': 2, '3100751072': 2, '3100751073': 3, '3100751074': 2, '3100751075': 3, '3100751076': 2, '3100751077': 2, '3100751078': 2, '3100751079': 2, '3100752001': 2, '3100752002': 3, '3100752003': 2, '3100752004': 2, '3100752005': 2, '3100752007': 2, '3100752008': 2, '3100752009': 2, '3100752010': 2, '3100752012': 2, '3100752014': 1, '3100752015': 3, '3100752016': 2, '3100752017': 2, '3100752018': 3, '3100752019': 3, '3100752020': 2, '3100752021': 1, '3100752022': 2, '3100752023': 2, '3100752026': 2, '3100752027': 2, '3100752029': 2, '3100752030': 1, '3100752032': 2, '3100752034': 3, '3100752035': 2, '3100752036': 2, '3100752037': 1, '3100752038': 2, '3100752039': 2, '3100752040': 3, '3100752041': 3, '3100752042': 2, '3100752043': 2, '3100752044': 3, '3100752045': 3, '3100752046': 2, '3100752047': 2, '3100752048': 1, '3100752049': 2, '3100752050': 3, '3100752051': 1, '3100752052': 3, '3100752054': 2, '3100752055': 1, '3100752056': 2, '3100752057': 2, '3100752058': 3, '3100752059': 2, '3100752060': 2, '3100752061': 2, '3100752063': 2, '3100752068': 2, '3100761003': 1, '3100761004': 3, '3100761005': 1, '3100761007': 2, '3100761008': 1, '3100761013': 2, '3100761014': 2, '3100761015': 2, '3100761016': 2, '3100761017': 2, '3100761019': 2, '3100761020': 3, '3100761021': 3, '3100761023': 2, '3100761027': 3, '3100761028': 3, '3100761029': 3, '3100761030': 2, '3100761031': 2, '3100761034': 2, '3100761042': 2, '3100761046': 2, '3100761047': 2, '3100761048': 3, '3100761049': 2, '3100761050': 2, '3100761051': 2, '3100761056': 2, '3100761062': 2, '3100761063': 3, '3100762003': 2, '3100762004': 1, '3100762005': 2, '3100762007': 3, '3100762012': 2, '3100762013': 2, '3100762016': 2, '3100762027': 1, '3100762029': 3, '3100762030': 1, '3100762052': 2, '3100762053': 2, '3100762055': 1, '3100771001': 1, '3100771002': 2, '3100771003': 3, '3100771005': 2, '3100771007': 1, '3100771008': 2, '3100771009': 2, '3100771012': 3, '3100771014': 2, '3100771016': 2, '3100771018': 2, '3100771019': 2, '3100771020': 2, '3100771021': 2, '3100771022': 2, '3100771024': 2, '3100771027': 2, '3100771028': 2, '3100771029': 2, '3100771030': 2, '3100771031': 2, '3100771032': 2, '3100771033': 2, '3100771034': 2, '3100771036': 2, '3100771037': 2, '3100771039': 2, '3100771040': 2, '3100771041': 3, '3100771042': 3, '3100771043': 2, '3100771046': 2, '3100771047': 2, '3100771048': 3, '3100771049': 2, '3100771050': 3, '3100771052': 2, '3100771054': 2, '3100771055': 2, '3100771056': 3, '3100771057': 3, '3100771058': 3, '3100771059': 3, '3100771062': 2, '3100771063': 3, '3100771064': 2, '3100771065': 2, '3100771066': 2, '3100771067': 2, '3100771068': 2, '3100771069': 2, '3100771071': 2, '3100771072': 3, '3100771073': 2, '3100771075': 2, '3100771076': 3, '3100771077': 3, '3100771078': 2, '3100771080': 2, '3100771081': 3, '3100772002': 3, '3100772004': 2, '3100772005': 2, '3100772006': 2, '3100772007': 3, '3100772008': 3, '3100772009': 2, '3100772010': 3, '3100772011': 3, '3100772013': 2, '3100772014': 3, '3100772015': 3, '3100772018': 3, '3100772019': 3, '3100772020': 2, '3100772021': 3, '3100772022': 3, '3100772023': 2, '3100772024': 3, '3100772025': 2, '3100772026': 3, '3100772027': 3, '3100772028': 3, '3100772029': 2, '3100772031': 2, '3100772032': 3, '3100772033': 3, '3100772034': 2, '3100772035': 2, '3100772036': 3, '3100772037': 3, '3100772039': 3, '3100772040': 3, '3100772041': 3, '3100772042': 3, '3100772043': 2, '3100772045': 2, '3100772046': 2, '3100772048': 2, '3100772050': 2, '3100772051': 1, '3100772052': 2, '3100772053': 3, '3100772054': 3, '3100772055': 3, '3100772056': 3, '3100772058': 3, '3100772059': 3, '3100772063': 2, '3100772065': 3, '3100772066': 2, '3100772067': 2, '3100772068': 2, '3100772069': 3, '3100781001': 2, '3100781002': 1, '3100781004': 2, '3100781006': 3, '3100781007': 1, '3100781008': 3, '3100781009': 3, '3100781010': 2, '3100781011': 3, '3100781013': 2, '3100781015': 2, '3100781016': 3, '3100781017': 2, '3100781019': 3, '3100781020': 3, '3100781021': 3, '3100781023': 3, '3100781024': 3, '3100781027': 3, '3100781029': 3, '3100781030': 3, '3100781031': 3, '3100781032': 2, '3100781033': 2, '3100781034': 1, '3100781036': 3, '3100781038': 2, '3100781040': 3, '3100781041': 3, '3100781043': 3, '3100781044': 2, '3100781046': 3, '3100781047': 3, '3100781048': 3, '3100781051': 3, '3100781052': 3, '3100781053': 3, '3100781054': 3, '3100781055': 3, '3100781056': 3, '3100781057': 2, '3100781058': 3, '3100781059': 2, '3100781061': 3, '3100781062': 3, '3100781064': 3, '3100781065': 2, '3100781066': 2, '3100781068': 2, '3100781069': 3, '3100781070': 2, '3100781071': 2, '3100781073': 2, '3100781074': 3, '3100781075': 3, '3100781076': 3, '3100781078': 3, '3100781079': 3, '3100781080': 3, '3100781081': 3, '3100782001': 2, '3100782003': 3, '3100782004': 3, '3100782005': 3, '3100782006': 2, '3100782008': 3, '3100782010': 2, '3100782011': 3, '3100782012': 3, '3100782013': 2, '3100782014': 3, '3100782015': 3, '3100782016': 3, '3100782017': 3, '3100782018': 2, '3100782019': 3, '3100782021': 3, '3100782022': 3, '3100782023': 3, '3100782024': 3, '3100782025': 3, '3100782026': 2, '3100782027': 3, '3100782028': 2, '3100782031': 2, '3100782032': 3, '3100782033': 3, '3100782035': 2, '3100782036': 2, '3100782037': 2, '3100782038': 3, '3100782039': 2, '3100782042': 3, '3100782043': 3, '3100782045': 3, '3100782046': 3, '3100782047': 3, '3100782049': 3, '3100782050': 2, '3100782053': 3, '3100782054': 2, '3100782055': 2, '3100782057': 3, '3100782058': 3, '3100782059': 2, '3100782061': 3, '3100782062': 3, '3100782063': 2, '3100782064': 3, '3100782065': 3, '3100782066': 3, '3100782067': 1, '3100782068': 3, '3100782069': 2, '3100782071': 2, '3100782072': 2, '3100791004': 3, '3100791006': 2, '3100791007': 2, '3100791008': 3, '3100791016': 2, '3100791018': 2, '3100791020': 3, '3100791021': 3, '3100791026': 3, '3100791028': 2, '3100791031': 3, '3100791033': 3, '3100791034': 3, '3100791035': 3, '3100791042': 3, '3100791044': 2, '3100791045': 3, '3100791046': 2, '3100791047': 3, '3100791049': 2, '3100791050': 2, '3100791052': 3, '3100791054': 2, '3100791056': 2, '3100791058': 1, '3100791059': 3, '3100791060': 3, '3100791061': 3, '3100791062': 2, '3100791063': 2, '3100791064': 3, '3100791065': 2, '3100791066': 2, '3100791067': 2, '3100791069': 2, '3100791070': 2, '3100791071': 3, '3100791072': 2, '3100791073': 2, '3100792002': 2, '3100792003': 2, '3100792004': 2, '3100792005': 2, '3100792006': 2, '3100792007': 3, '3100792008': 2, '3100792009': 2, '3100792010': 2, '3100792011': 2, '3100792013': 2, '3100792014': 3, '3100792015': 2, '3100792016': 2, '3100792019': 3, '3100792020': 2, '3100792021': 2, '3100792022': 2, '3100792023': 2, '3100792024': 2, '3100792025': 2, '3100792027': 3, '3100792028': 2, '3100792030': 2, '3100792031': 3, '3100792032': 2, '3100792033': 2, '3100792035': 2, '3100792036': 2, '3100792037': 2, '3100792038': 2, '3100792039': 2, '3100792040': 2, '3100792041': 2, '3100792042': 3, '3100792043': 2, '3100792044': 2, '3100792045': 1, '3100792046': 3, '3100792048': 3, '3100792050': 2, '3100792051': 2, '3100792052': 2, '3100792053': 2, '3100792057': 2, '3100792058': 2, '3100792060': 2, '3100792069': 2, '3100801006': 2, '3100802001': 3, '3100802028': 3, '3100811002': 2, '3100811018': 2, '3100811027': 2, '3100811034': 2, '3100811035': 2, '3100811036': 3, '3100811037': 2, '3100811038': 2, '3100811039': 2, '3100811040': 3, '3100811041': 3, '3100811042': 2, '3100811043': 2, '3100811045': 2, '3100811046': 2, '3100811047': 2, '3100811050': 3, '3100811051': 2, '3100811053': 2, '3100811054': 2, '3100811055': 2, '3100811056': 3, '3100811059': 2, '3100811060': 3, '3100811061': 2, '3100811063': 3, '3100811068': 2, '3100811075': 2, '3100812003': 3, '3100812004': 2, '3100812005': 3, '3100812006': 3, '3100812007': 2, '3100812008': 3, '3100812013': 3, '3100812014': 2, '3100812016': 2, '3100812017': 3, '3100812018': 2, '3100812019': 2, '3100812020': 2, '3100812021': 2, '3100812026': 2, '3100812027': 2, '3100812028': 1, '3100812040': 2, '3100821004': 2, '3100821015': 2, '3100821016': 3, '3100821019': 2, '3100821020': 3, '3100821021': 2, '3100821022': 1, '3100821030': 3, '3100821031': 2, '3100821032': 1, '3100821033': 0, '3100821034': 3, '3100821035': 3, '3100821036': 3, '3100821037': 2, '3100821038': 1, '3100821039': 2, '3100821040': 2, '3100821041': 2, '3100821042': 3, '3100821045': 2, '3100821046': 2, '3100821047': 2, '3100821048': 1, '3100821049': 3, '3100821051': 3, '3100821052': 0, '3100821054': 2, '3100821055': 2, '3100821057': 1, '3100821067': 2, '3100821068': 3, '3100821069': 0, '3100821075': 0, '3100822001': 2, '3100822011': 1, '3100822012': 2, '3100822014': 2, '3100822030': 3, '3100822031': 0, '3100822044': 3, '3100822050': 3, '3100822051': 3, '3100822057': 3, '3100822058': 3, '3100822059': 2, '3100822064': 3, '3100822065': 1, '3100822066': 0, '3100822067': 2, '3100822068': 2, '3100822069': 3, '3100822070': 2, '3100822075': 3, '3100822080': 2, '3100831003': 2, '3100831004': 3, '3100831006': 2, '3100831007': 3, '3100831008': 3, '3100831010': 2, '3100831011': 2, '3100831013': 2, '3100831014': 2, '3100831015': 2, '3100831016': 2, '3100831018': 2, '3100831019': 3, '3100831020': 3, '3100831022': 3, '3100831024': 2, '3100831026': 3, '3100831027': 3, '3100831028': 2, '3100831029': 2, '3100831032': 2, '3100831033': 2, '3100831035': 3, '3100831036': 2, '3100831037': 2, '3100831044': 2, '3100831045': 3, '3100831046': 3, '3100831047': 3, '3344630110': 3, '33446301100': 2, '33446301101': 2, '33446301103': 3, '33446301104': 2, '33446301107': 3, '3344630112': 3, '3344630113': 2, '3344630115': 3, '3344630116': 2, '3344630117': 3, '3344630119': 2, '334463012': 3, '3344630120': 3, '3344630121': 1, '3344630127': 2, '3344630130': 3, '3344630131': 1, '3344630132': 2, '3344630133': 2, '3344630136': 2, '3344630139': 2, '334463014': 2, '3344630140': 3, '3344630141': 2, '3344630142': 3, '3344630143': 3, '3344630146': 2, '3344630147': 2, '3344630148': 3, '3344630149': 3, '3344630150': 2, '3344630151': 2, '3344630153': 2, '3344630156': 2, '3344630161': 3, '3344630162': 1, '3344630163': 3, '3344630164': 2, '3344630166': 2, '3344630170': 3, '3344630171': 2, '3344630172': 2, '3344630173': 3, '3344630176': 3, '3344630179': 2, '3344630180': 2, '3344630181': 2, '3344630182': 2, '3344630184': 3, '3344630185': 2, '3344630186': 2, '3344630188': 3, '3344630189': 3, '334463019': 2, '3344630190': 3, '3344630196': 2, '3344630197': 2, '3344630198': 3, '3344630199': 2, '334463021': 3, '3344630210': 2, '3344630211': 1, '3344630213': 3, '3344630215': 3, '3344630216': 3, '3344630219': 3, '334463022': 2, '3344630220': 3, '3344630221': 2, '3344630224': 2, '3344630225': 3, '3344630226': 2, '3344630231': 2, '3344630232': 2, '3344630233': 2, '3344630236': 3, '3344630238': 2, '3344630240': 3, '3344630241': 3, '3344630242': 3, '3344630243': 3, '3344630245': 3, '3344630247': 3, '3344630248': 2, '334463025': 2, '3344630251': 3, '3344630252': 2, '3344630255': 2, '3344630257': 3, '334463026': 2, '3344630260': 3, '3344630262': 2, '3344630264': 2, '3344630265': 3, '3344630266': 2, '3344630267': 2, '334463027': 2, '3344630270': 2, '3344630271': 3, '3344630273': 2, '3344630276': 2, '3344630278': 3, '334463028': 3, '3344630280': 2, '3344630281': 2, '3344630282': 1, '334463029': 3, '33702101100': 3, '33702101110': 3, '33702101130': 3, '33702101140': 3, '33702101150': 3, '33702101180': 2, '33702101200': 3, '33702101210': 3, '33702101250': 2, '33702101260': 3, '33702101270': 3, '33702101280': 3, '33702101290': 2, '33702101300': 3, '33702101340': 3, '33702101350': 3, '33702101360': 3, '33702101370': 3, '33702101410': 3, '33702101430': 2, '33702101450': 2, '33702101460': 3, '33702101470': 2, '33702101480': 2, '33702101490': 2, '3370210150': 2, '33702101500': 3, '33702101530': 3, '33702101540': 2, '33702101550': 3, '33702101580': 3, '33702101590': 3, '33702101600': 2, '33702101620': 2, '33702101630': 3, '33702101640': 3, '33702101650': 3, '33702101660': 3, '33702101700': 3, '33702101710': 3, '33702101730': 3, '33702101740': 3, '33702101750': 3, '33702101760': 3, '3370210180': 3, '33702102100': 3, '33702102110': 3, '33702102130': 2, '33702102140': 2, '33702102160': 3, '33702102170': 3, '33702102180': 3, '33702102190': 3, '33702102200': 3, '33702102220': 2, '33702102230': 3, '33702102240': 3, '33702102250': 3, '33702102280': 3, '3370210230': 3, '33702102300': 3, '33702102310': 3, '33702102330': 3, '33702102350': 3, '33702102390': 3, '3370210240': 3, '33702102400': 3, '33702102420': 3, '33702102430': 3, '33702102470': 2, '33702102500': 3, '33702102530': 3, '33702102540': 3, '33702102550': 3, '33702102570': 3, '33702102580': 3, '33702102590': 3, '3370210260': 3, '33702102600': 3, '33702102640': 2, '33702102670': 3, '33702102690': 3, '33702102710': 3, '33702102740': 3, '3370210280': 3, '33702102820': 3, '33702102840': 3, '33702102850': 3, '33702102870': 3, '33702102880': 3, '342227010': 3, '342227011': 3, '3422270111': 1, '3422270112': 3, '3422270115': 2, '3422270116': 3, '3422270117': 2, '3422270118': 2, '3422270121': 3, '3422270122': 3, '3422270123': 3, '3422270126': 2, '3422270127': 3, '3422270128': 3, '3422270129': 1, '342227013': 3, '3422270130': 2, '3422270131': 2, '3422270133': 3, '3422270134': 3, '3422270135': 2, '3422270138': 3, '3422270139': 3, '3422270140': 3, '3422270141': 2, '3422270142': 2, '3422270143': 3, '3422270144': 3, '3422270149': 2, '3422270151': 2, '3422270152': 2, '3422270153': 2, '3422270154': 3, '3422270155': 2, '3422270157': 2, '3422270158': 2, '3422270160': 2, '3422270165': 3, '3422270166': 3, '3422270167': 1, '3422270168': 3, '3422270169': 3, '3422270171': 2, '3422270172': 3, '342227020': 3, '342227021': 3, '3422270210': 3, '3422270211': 3, '3422270212': 2, '3422270213': 3, '3422270215': 2, '3422270216': 3, '3422270217': 3, '3422270219': 2, '3422270220': 2, '3422270221': 2, '3422270222': 3, '3422270223': 3, '3422270224': 3, '3422270225': 2, '3422270227': 2, '342227023': 3, '3422270230': 2, '3422270238': 3, '3422270239': 3, '342227024': 3, '3422270240': 2, '3422270241': 3, '3422270242': 3, '3422270244': 2, '3422270245': 3, '3422270246': 2, '3422270247': 3, '3422270249': 2, '342227025': 3, '3422270250': 3, '3422270251': 2, '3422270252': 3, '3422270253': 3, '3422270254': 3, '3422270255': 3, '3422270256': 3, '3422270257': 2, '3422270261': 3, '3422270262': 2, '3422270263': 3, '3422270264': 3, '3422270267': 3, '3422270268': 3, '3422270269': 3, '342227027': 3, '3422270274': 2, '3422270278': 3, '3422270279': 3, '3422270280': 3, '3422270281': 3, '342227029': 3, '350361011': 2, '3503610110': 3, '3503610111': 3, '3503610112': 3, '3503610113': 2, '3503610114': 2, '3503610115': 2, '3503610116': 3, '3503610117': 3, '3503610118': 3, '3503610119': 3, '350361012': 3, '3503610120': 2, '3503610121': 3, '3503610122': 3, '3503610123': 3, '3503610124': 3, '3503610125': 3, '3503610126': 3, '3503610127': 2, '3503610128': 3, '3503610129': 2, '350361013': 2, '3503610130': 3, '3503610131': 3, '3503610132': 3, '3503610133': 2, '3503610134': 3, '3503610135': 3, '3503610136': 3, '3503610137': 2, '3503610138': 3, '3503610139': 2, '350361014': 3, '3503610140': 3, '3503610141': 3, '3503610142': 2, '3503610143': 3, '3503610144': 3, '3503610145': 3, '3503610146': 3, '3503610147': 3, '3503610148': 3, '3503610149': 2, '350361015': 3, '3503610150': 3, '3503610151': 3, '3503610152': 3, '3503610154': 3, '3503610156': 3, '3503610157': 2, '3503610158': 1, '350361016': 2, '3503610163': 3, '3503610168': 0, '350361017': 3, '350361019': 3, '350361021': 3, '3503610210': 3, '3503610212': 3, '3503610213': 2, '3503610214': 2, '3503610217': 3, '350361022': 2, '3503610223': 3, '3503610224': 3, '3503610225': 3, '3503610226': 3, '3503610227': 3, '3503610228': 3, '350361023': 3, '3503610230': 3, '3503610231': 3, '3503610233': 3, '3503610234': 2, '3503610235': 3, '3503610236': 3, '3503610237': 3, '3503610238': 3, '350361024': 3, '3503610240': 3, '3503610241': 2, '3503610242': 3, '3503610245': 3, '3503610246': 3, '3503610248': 3, '3503610250': 3, '3503610251': 2, '3503610252': 3, '3503610253': 3, '3503610254': 3, '3503610255': 2, '3503610256': 3, '3503610257': 3, '350361026': 3, '3503610260': 3, '3503610261': 3, '3503610264': 3, '3503610265': 2, '3503610266': 3, '3503610267': 3, '3503610268': 3, '3503610269': 2, '3503610270': 3, '3503610272': 2, '3503610273': 3, '3503610275': 2, '3503610276': 2, '3503610277': 3, '3503610278': 2, '3503610279': 3, '350361028': 1, '350361029': 2, '4000181002': 2, '4000181004': 1, '4000181005': 2, '4000181006': 2, '4000181007': 2, '4000181008': 2, '4000181010': 2, '4000181011': 2, '4000181012': 2, '4000181013': 3, '4000181014': 3, '4000181015': 1, '4000181016': 2, '4000181017': 2, '4000181019': 2, '4000181020': 3, '4000181022': 3, '4000181023': 2, '4000181024': 3, '4000181026': 3, '4000181027': 2, '4000181028': 3, '4000181029': 2, '4000181030': 3, '4000181031': 2, '4000181032': 2, '4000181033': 3, '4000181035': 3, '4000181036': 2, '4000181037': 2, '4000181039': 2, '4000181041': 3, '4000181042': 3, '4000181043': 2, '4000181044': 3, '4000181045': 2, '4000181046': 2, '4000181047': 2, '4000181048': 3, '4000181049': 3, '4000181053': 2, '4000181054': 2, '4000181055': 2, '4000181056': 3, '4000181057': 2, '4000181060': 2, '4000181061': 3, '4000181062': 2, '4000181063': 2, '4000181064': 2, '4000181065': 2, '4000181066': 3, '4000181067': 2, '4000181068': 2, '4000181069': 2, '4000181070': 3, '4000181072': 2, '4000181073': 2, '4000181074': 2, '4000181075': 2, '4000181076': 2, '4000181077': 2, '4000181078': 3, '4000181079': 2, '4000181080': 3, '4000182003': 3, '4000182004': 2, '4000182005': 2, '4000182006': 2, '4000182007': 3, '4000182008': 2, '4000182009': 3, '4000182010': 3, '4000182011': 2, '4000182013': 3, '4000182014': 3, '4000182015': 2, '4000182016': 2, '4000182017': 3, '4000182018': 2, '4000182020': 3, '4000182022': 2, '4000182024': 2, '4000182025': 3, '4000182026': 2, '4000182027': 2, '4000182028': 2, '4000182029': 2, '4000182030': 3, '4000182031': 2, '4000182032': 3, '4000182033': 2, '4000182035': 1, '4000182036': 2, '4000182037': 2, '4000182038': 2, '4000182039': 2, '4000182040': 3, '4000182041': 3, '4000182042': 3, '4000182044': 3, '4000182046': 2, '4000182047': 2, '4000182049': 3, '4000182050': 2, '4000182051': 2, '4000182053': 2, '4000182054': 2, '4000182055': 2, '4000182058': 2, '4000182059': 3, '4000182060': 3, '4000182062': 2, '4000182063': 2, '4000182064': 3, '4000182067': 2, '4000182068': 2, '4000182069': 2, '4000221001': 2, '4000221002': 3, '4000221006': 2, '4000221008': 3, '4000221009': 2, '4000221010': 2, '4000221011': 2, '4000221013': 2, '4000221014': 2, '4000221015': 2, '4000221016': 3, '4000221017': 3, '4000221018': 2, '4000221024': 2, '4000221033': 2, '4000221034': 2, '4000221035': 2, '4000221036': 2, '4000221040': 1, '4000221041': 2, '4000221042': 3, '4000221054': 2, '4000221055': 2, '4000221061': 3, '4000221062': 3, '4000221064': 2, '4000221065': 2, '4000221066': 2, '4000221067': 2, '4000221071': 2, '4000221072': 2, '4000222001': 3, '4000222003': 2, '4000222004': 3, '4000222007': 2, '4000222012': 3, '4000222013': 2, '4000222014': 2, '4000222015': 2, '4000222017': 2, '4000222031': 1, '4000222032': 0, '4000222035': 2, '4000222036': 1, '4000222038': 3, '4000222039': 3, '4000222040': 2, '4000222041': 1, '4000222042': 2, '4000222044': 2, '4000222045': 2, '4000222046': 3, '4000222051': 2, '4000222052': 2, '4000222054': 3, '4000222056': 2, '4000222057': 2, '4000222068': 2, '4000222069': 2, '4000222070': 3, '4000231001': 3, '4000231008': 2, '4000231010': 2, '4000231011': 3, '4000231012': 3, '4000231013': 2, '4000231014': 2, '4000231021': 3, '4000231032': 3, '4000231033': 2, '4000231034': 2, '4000231037': 3, '4000231038': 3, '4000231047': 2, '4000231049': 2, '4000231052': 2, '4000231060': 2, '4000231061': 2, '4000231063': 2, '4000231065': 3, '4000231070': 3, '4000231071': 2, '4000231073': 2, '4000231074': 3, '4000231081': 3, '4000232001': 2, '4000232004': 2, '4000232005': 2, '4000232006': 2, '4000232007': 3, '4000232010': 2, '4000232016': 3, '4000232017': 3, '4000232018': 3, '4000232022': 2, '4000232024': 2, '4000232027': 3, '4000232034': 2, '4000232035': 3, '4000232036': 3, '4000232037': 2, '4000232038': 2, '4000232042': 2, '4000232044': 3, '4000232045': 3, '4000232048': 2, '4000232051': 2, '4000232054': 2, '4000232059': 2, '4000232062': 2, '4000232065': 2, '4000232068': 3, '4000232071': 1, '4000232072': 2, '4000301002': 2, '4000301003': 2, '4000301005': 1, '4000301006': 1, '4000301007': 2, '4000301008': 2, '4000301010': 1, '4000301011': 0, '4000301012': 2, '4000301013': 2, '4000301014': 2, '4000301015': 2, '4000301016': 2, '4000301018': 2, '4000301019': 2, '4000301020': 2, '4000301021': 1, '4000301022': 3, '4000301023': 3, '4000301025': 3, '4000301026': 2, '4000301027': 2, '4000301028': 0, '4000301030': 0, '4000301031': 2, '4000301032': 3, '4000301034': 2, '4000301038': 3, '4000301039': 3, '4000301040': 3, '4000301041': 3, '4000301042': 0, '4000301043': 3, '4000301044': 2, '4000301045': 3, '4000301047': 3, '4000301049': 1, '4000301052': 3, '4000301053': 2, '4000301054': 2, '4000301055': 1, '4000301056': 2, '4000301057': 2, '4000301058': 2, '4000301059': 2, '4000301060': 1, '4000301061': 2, '4000301062': 2, '4000301063': 3, '4000301064': 2, '4000301065': 1, '4000301066': 1, '4000301067': 1, '4000301068': 2, '4000301069': 2, '4000301070': 0, '4000301071': 2, '4000301072': 3, '4000301073': 3, '4000301074': 2, '4000301076': 2, '4000301079': 2, '4000331001': 2, '4000331002': 2, '4000331003': 3, '4000331004': 3, '4000331005': 3, '4000331006': 3, '4000331007': 2, '4000331008': 3, '4000331011': 3, '4000331012': 3, '4000331013': 2, '4000331015': 2, '4000331017': 2, '4000331019': 3, '4000331020': 3, '4000331021': 2, '4000331022': 2, '4000331023': 3, '4000331025': 3, '4000331027': 3, '4000331029': 2, '4000331030': 2, '4000331031': 2, '4000331032': 2, '4000331033': 3, '4000331035': 3, '4000331036': 2, '4000331037': 2, '4000331038': 3, '4000331039': 2, '4000331040': 2, '4000331041': 2, '4000331042': 3, '4000331043': 3, '4000331044': 3, '4000331045': 2, '4000331046': 2, '4000331051': 2, '4000331052': 3, '4000331053': 3, '4000331054': 2, '4000331055': 2, '4000331056': 2, '4000331057': 3, '4000331058': 2, '4000331060': 2, '4000331062': 2, '4000331063': 2, '4000331064': 2, '4000331067': 3, '4000331068': 2, '4000331069': 2, '4000332001': 2, '4000332002': 2, '4000332007': 2, '4000332008': 3, '4000332009': 2, '4000332010': 2, '4000332012': 2, '4000332013': 2, '4000332014': 3, '4000332015': 2, '4000332017': 3, '4000332019': 2, '4000332020': 2, '4000332021': 2, '4000332022': 2, '4000332023': 2, '4000332025': 3, '4000332027': 2, '4000332030': 3, '4000332031': 2, '4000332032': 2, '4000332034': 3, '4000332035': 2, '4000332036': 3, '4000332037': 3, '4000332038': 2, '4000332039': 2, '4000332041': 3, '4000332044': 3, '4000332045': 3, '4000332046': 2, '4000332048': 3, '4000332050': 3, '4000332051': 2, '4000332052': 2, '4000332057': 2, '4000332059': 2, '4000332060': 3, '4000332061': 2, '4000332062': 2, '4000332063': 3, '4000332064': 2, '4000332066': 3, '4000332067': 3, '4000332068': 3, '4000332071': 2, '4000332072': 2, '4000332073': 2, '4000332074': 3, '4000332075': 2, '4000332077': 3, '4000332078': 2, '4000332079': 3, '4000332080': 3, '4000332081': 2, '4000332082': 1, '401835011': 3, '4018350112': 2, '4018350115': 3, '4018350116': 2, '4018350118': 3, '4018350119': 2, '4018350120': 3, '4018350121': 3, '4018350122': 2, '4018350126': 2, '4018350127': 2, '401835013': 3, '4018350130': 3, '4018350132': 3, '4018350134': 3, '4018350136': 3, '4018350137': 3, '4018350138': 3, '4018350139': 3, '4018350140': 3, '4018350141': 3, '4018350143': 3, '4018350144': 2, '4018350145': 2, '4018350146': 3, '4018350147': 2, '4018350149': 3, '401835015': 1, '4018350150': 2, '4018350152': 3, '4018350156': 3, '4018350157': 3, '4018350159': 3, '4018350160': 3, '4018350161': 3, '4018350162': 3, '4018350163': 3, '4018350166': 3, '4018350167': 3, '401835017': 2, '401835018': 3, '401835021': 2, '4018350213': 3, '4018350215': 2, '4018350217': 2, '4018350219': 2, '4018350220': 3, '4018350221': 2, '4018350222': 3, '4018350223': 3, '4018350224': 2, '4018350225': 3, '4018350226': 3, '4018350227': 3, '4018350231': 2, '4018350232': 3, '4018350233': 2, '4018350234': 3, '4018350236': 3, '4018350239': 2, '401835024': 2, '4018350240': 2, '4018350241': 3, '4018350244': 3, '4018350247': 2, '4018350251': 2, '4018350254': 3, '4018350256': 3, '4018350257': 3, '4018350258': 3, '4018350259': 2, '4018350260': 3, '4018350261': 3, '4018350263': 2, '4018350268': 3, '4018350269': 3, '4018350274': 2, '4018350276': 3, '4018350277': 2, '4018350279': 2, '401835028': 3, '4018350281': 2, '4018350282': 1, '4100191001': 2, '4100191002': 2, '4100191003': 3, '4100191004': 3, '4100191006': 2, '4100191007': 2, '4100191008': 1, '4100191010': 2, '4100191012': 2, '4100191014': 2, '4100191016': 2, '4100191017': 2, '4100191018': 3, '4100191020': 3, '4100191021': 2, '4100191023': 2, '4100191024': 2, '4100191025': 2, '4100191026': 2, '4100191030': 3, '4100191031': 2, '4100191032': 2, '4100191033': 0, '4100191034': 3, '4100191035': 2, '4100191038': 2, '4100191039': 2, '4100191041': 1, '4100191042': 2, '4100191043': 2, '4100191045': 2, '4100191046': 2, '4100191052': 2, '4100191053': 2, '4100192001': 2, '4100192002': 2, '4100192003': 2, '4100192004': 2, '4100192005': 2, '4100192006': 3, '4100192007': 2, '4100192010': 1, '4100192011': 1, '4100192012': 2, '4100192013': 2, '4100192014': 3, '4100192015': 1, '4100192016': 1, '4100192019': 2, '4100192020': 2, '4100192022': 2, '4100192023': 3, '4100192024': 2, '4100192025': 3, '4100192026': 0, '4100192027': 2, '4100192028': 3, '4100192029': 0, '4100192031': 1, '4100192032': 3, '4100192033': 2, '4100192034': 2, '4100192036': 2, '4100192037': 2, '4100192038': 2, '4100192039': 2, '4100192040': 2, '4100192043': 2, '4100192044': 2, '4100192045': 2, '4100192046': 2, '4100192047': 3, '4100192048': 2, '4100192049': 1, '4100192050': 2, '4100192051': 2, '4100192052': 2, '4100192053': 1, '4100192054': 2, '4100192055': 2, '4100192056': 2, '4100192057': 3, '4100192058': 2, '4100192060': 1, '4100192061': 2, '4100192062': 3, '4100192063': 2, '4100192066': 2, '4100192068': 2, '4100201001': 3, '4100201003': 2, '4100201004': 3, '4100201005': 2, '4100201006': 2, '4100201007': 2, '4100201008': 3, '4100201009': 2, '4100201010': 3, '4100201011': 2, '4100201013': 3, '4100201014': 3, '4100201016': 2, '4100201017': 3, '4100201018': 3, '4100201020': 3, '4100201021': 2, '4100201022': 3, '4100201023': 3, '4100201024': 3, '4100201025': 3, '4100201026': 2, '4100201027': 2, '4100201030': 1, '4100201031': 3, '4100201032': 1, '4100201033': 2, '4100201034': 2, '4100201035': 3, '4100201039': 1, '4100201040': 3, '4100201041': 2, '4100201042': 3, '4100201043': 1, '4100201044': 2, '4100201045': 2, '4100201046': 2, '4100201048': 2, '4100201049': 3, '4100201051': 3, '4100201052': 2, '4100201053': 2, '4100201054': 3, '4100201055': 3, '4100201056': 2, '4100201058': 3, '4100201059': 2, '4100201060': 2, '4100201061': 0, '4100201062': 3, '4100201063': 2, '4100201064': 2, '4100201068': 3, '4100201069': 3, '4100201071': 2, '4100201072': 3, '4100201073': 3, '4100201074': 2, '4100201075': 3, '4100201076': 2, '4100201078': 3, '4100201079': 3, '4100201081': 2, '4100201082': 2, '4100202001': 2, '4100202004': 2, '4100202005': 2, '4100202006': 2, '4100202007': 3, '4100202008': 3, '4100202009': 3, '4100202010': 2, '4100202011': 2, '4100202012': 2, '4100202013': 2, '4100202014': 1, '4100202015': 3, '4100202016': 3, '4100202017': 3, '4100202018': 2, '4100202019': 3, '4100202021': 3, '4100202022': 2, '4100202023': 3, '4100202024': 2, '4100202025': 2, '4100202032': 2, '4100202037': 2, '4100202039': 2, '4100202040': 2, '4100202041': 3, '4100202042': 2, '4100202043': 3, '4100202045': 2, '4100202046': 1, '4100202048': 2, '4100202052': 2, '4100202053': 2, '4100202054': 3, '4100202055': 3, '4100202056': 2, '4100202063': 3, '4100202065': 1, '4100202067': 3, '4100202068': 2, '4100241001': 2, '4100241002': 2, '4100241003': 2, '4100241004': 2, '4100241006': 2, '4100241007': 2, '4100241008': 2, '4100241009': 2, '4100241011': 2, '4100241013': 2, '4100241016': 3, '4100241017': 2, '4100241018': 3, '4100241020': 2, '4100241029': 1, '4100241030': 2, '4100241031': 2, '4100241042': 2, '4100241045': 2, '4100241046': 3, '4100241049': 2, '4100241051': 3, '4100241052': 3, '4100241053': 3, '4100241054': 2, '4100241055': 1, '4100241056': 3, '4100241059': 1, '4100241060': 3, '4100241061': 3, '4100241062': 2, '4100241063': 3, '4100241064': 2, '4100241068': 1, '4100241069': 3, '4100241075': 3, '4100242001': 2, '4100242002': 2, '4100242003': 1, '4100242004': 3, '4100242005': 2, '4100242006': 2, '4100242008': 2, '4100242011': 2, '4100242020': 2, '4100242021': 2, '4100242029': 2, '4100242031': 2, '4100242032': 0, '4100242033': 1, '4100242034': 2, '4100242035': 1, '4100242036': 2, '4100242037': 2, '4100242038': 2, '4100242040': 2, '4100242045': 2, '4100242048': 3, '4100242050': 2, '4100242053': 2, '4100242054': 2, '4100242057': 1, '4100242059': 2, '4100242060': 2, '4100242063': 1, '4100242065': 2, '4100242066': 2, '4100242067': 2, '4100251003': 2, '4100251004': 3, '4100251005': 3, '4100251006': 1, '4100251010': 3, '4100251011': 2, '4100251012': 2, '4100251013': 2, '4100251014': 2, '4100251015': 3, '4100251016': 1, '4100251017': 2, '4100251018': 2, '4100251019': 2, '4100251020': 1, '4100251021': 1, '4100251022': 2, '4100251024': 1, '4100251026': 3, '4100251027': 1, '4100251028': 1, '4100251029': 1, '4100251030': 2, '4100251031': 2, '4100251032': 1, '4100251033': 1, '4100251034': 2, '4100251035': 2, '4100251036': 1, '4100251038': 1, '4100251039': 2, '4100251040': 2, '4100251041': 1, '4100251042': 2, '4100251044': 2, '4100251046': 1, '4100251047': 2, '4100251048': 2, '4100251049': 1, '4100251051': 2, '4100251052': 2, '4100251053': 3, '4100251054': 3, '4100251056': 2, '4100251057': 0, '4100251059': 2, '4100251060': 2, '4100251061': 1, '4100251062': 2, '4100251063': 2, '4100251064': 2, '4100251065': 2, '4100251068': 1, '4100251069': 2, '4100251070': 2, '4100252001': 2, '4100252003': 2, '4100252004': 3, '4100252005': 2, '4100252007': 3, '4100252010': 2, '4100252011': 2, '4100252012': 3, '4100252013': 2, '4100252014': 2, '4100252015': 2, '4100252016': 2, '4100252019': 2, '4100252021': 2, '4100252022': 2, '4100252023': 2, '4100252024': 3, '4100252027': 2, '4100252031': 3, '4100252032': 2, '4100252033': 2, '4100252034': 2, '4100252035': 2, '4100252036': 1, '4100252037': 3, '4100252038': 2, '4100252039': 2, '4100252040': 2, '4100252041': 1, '4100252043': 3, '4100252044': 1, '4100252045': 3, '4100252048': 2, '4100252049': 3, '4100252050': 3, '4100252051': 3, '4100252053': 2, '4100252054': 2, '4100252055': 2, '4100252056': 3, '4100252057': 3, '4100252058': 2, '4100252060': 2, '4100252061': 1, '4100252062': 3, '4100252063': 3, '4100252066': 2, '4100252069': 2, '4100252070': 3, '4100252071': 2, '4100252072': 3, '4100252073': 2, '4100252074': 2, '4100252075': 2, '4100252076': 2, '4100252078': 2, '4100252081': 2, '4100261001': 2, '4100261002': 2, '4100261003': 3, '4100261004': 2, '4100261005': 1, '4100261006': 1, '4100261007': 3, '4100261010': 2, '4100261012': 2, '4100261013': 2, '4100261015': 2, '4100261016': 3, '4100261020': 2, '4100261023': 2, '4100261025': 2, '4100261027': 1, '4100261028': 2, '4100261029': 2, '4100261030': 1, '4100261031': 2, '4100261032': 2, '4100261033': 3, '4100261034': 1, '4100261035': 3, '4100261036': 2, '4100261038': 2, '4100261041': 1, '4100261044': 2, '4100261045': 2, '4100261046': 2, '4100261047': 2, '4100261048': 2, '4100261049': 2, '4100261050': 1, '4100261055': 3, '4100261056': 1, '4100261057': 2, '4100261058': 1, '4100261060': 2, '4100261061': 2, '4100262001': 2, '4100262003': 2, '4100262004': 1, '4100262006': 0, '4100262007': 2, '4100262008': 2, '4100262009': 2, '4100262010': 2, '4100262014': 2, '4100262015': 3, '4100262016': 2, '4100262017': 3, '4100262018': 2, '4100262019': 2, '4100262020': 2, '4100262022': 2, '4100262023': 2, '4100262024': 2, '4100262025': 2, '4100262027': 2, '4100262034': 1, '4100262035': 2, '4100262037': 3, '4100262038': 2, '4100262040': 2, '4100262041': 2, '4100262042': 2, '4100262043': 3, '4100262044': 2, '4100262045': 2, '4100262046': 3, '4100262047': 2, '4100262052': 2, '4100262053': 2, '4100262056': 1, '4100262057': 2, '4100262060': 2, '4100262063': 2, '4100262064': 2, '4100262065': 2, '4100262066': 2, '4100262067': 2, '4100262068': 2, '4100262069': 3, '4100262070': 2, '4100271007': 2, '4100271008': 2, '4100271009': 2, '4100271010': 3, '4100271011': 3, '4100271012': 2, '4100271026': 2, '4100271028': 2, '4100271029': 2, '4100271030': 2, '4100271032': 3, '4100271033': 3, '4100271034': 3, '4100271038': 1, '4100271039': 2, '4100271041': 1, '4100271042': 2, '4100271043': 3, '4100271056': 1, '4100272024': 2, '4100272029': 3, '4100272033': 3, '4100272034': 2, '4100272036': 3, '4100272037': 2, '4100272043': 3, '4100272051': 2, '4100272052': 2, '4100272056': 3, '4100281001': 2, '4100281002': 2, '4100281015': 2, '4100281016': 2, '4100281019': 3, '4100281022': 2, '4100281023': 2, '4100281027': 2, '4100281029': 2, '4100281030': 2, '4100281032': 1, '4100281033': 2, '4100281034': 2, '4100281035': 2, '4100281036': 2, '4100281037': 2, '4100281041': 3, '4100281042': 2, '4100281045': 2, '4100281046': 1, '4100281048': 2, '4100281049': 2, '4100281050': 2, '4100281052': 2, '4100281053': 1, '4100281054': 2, '4100281057': 2, '4100281058': 2, '4100281059': 2, '4100281060': 3, '4100281061': 2, '4100281062': 2, '4100281063': 2, '4100281066': 2, '4100281067': 0, '4100281068': 2, '4100281070': 1, '4100281072': 2, '4100281075': 2, '4100281076': 1, '4100281078': 3, '4100281079': 2, '4100281080': 2, '4100281081': 2, '4100282001': 2, '4100282002': 2, '4100282003': 3, '4100282004': 2, '4100282005': 2, '4100282007': 2, '4100282008': 2, '4100282009': 1, '4100282012': 2, '4100282013': 2, '4100282014': 3, '4100282015': 2, '4100282017': 3, '4100282018': 2, '4100282019': 3, '4100282020': 3, '4100282021': 3, '4100282022': 3, '4100282023': 2, '4100282024': 3, '4100282033': 2, '4100282043': 2, '4100282048': 2, '4100282053': 3, '4100282057': 2, '4100282058': 2, '4100282066': 1, '4100282067': 2, '4100282068': 2, '4100282070': 2, '4100291002': 2, '4100291003': 3, '4100291004': 2, '4100291005': 2, '4100291006': 1, '4100291007': 1, '4100291008': 2, '4100291009': 2, '4100291010': 1, '4100291011': 2, '4100291012': 2, '4100291014': 2, '4100291015': 2, '4100291016': 2, '4100291017': 2, '4100291018': 2, '4100291019': 1, '4100291021': 2, '4100291022': 2, '4100291025': 2, '4100291026': 1, '4100291027': 1, '4100291028': 2, '4100291032': 1, '4100291033': 2, '4100291034': 2, '4100291036': 1, '4100291037': 2, '4100291039': 2, '4100291040': 2, '4100291041': 1, '4100291043': 2, '4100291046': 2, '4100291047': 2, '4100291048': 2, '4100291049': 2, '4100291050': 2, '4100291051': 2, '4100291055': 2, '4100291056': 2, '4100291059': 2, '4100291060': 3, '4100291061': 2, '4100291062': 2, '4100291063': 3, '4100291064': 3, '4100291065': 2, '4100291070': 1, '4100291073': 1, '4100291074': 2, '4100291076': 2, '4100291077': 2, '4100291078': 1, '4100291079': 2, '4100291080': 2, '4100291081': 1, '4100291082': 1, '4100291083': 2, '4100291084': 1, '4100292001': 2, '4100292003': 2, '4100292005': 2, '4100292008': 2, '4100292010': 2, '4100292016': 2, '4100292019': 2, '4100292020': 2, '4100292021': 3, '4100292022': 2, '4100292023': 2, '4100292024': 3, '4100292025': 2, '4100292026': 2, '4100292027': 2, '4100292028': 2, '4100292035': 2, '4100292036': 3, '4100292037': 2, '4100292040': 2, '4100292041': 2, '4100292042': 3, '4100292043': 2, '4100292044': 3, '4100292045': 3, '4100292046': 3, '4100292048': 1, '4100292049': 2, '4100292050': 2, '4100292052': 2, '4100292053': 2, '4100292056': 2, '4100292057': 2, '4100292059': 2, '4100292060': 2, '4100292061': 3, '4100292062': 2, '4100292063': 2, '4100292064': 3, '4100292065': 2, '4100292066': 3, '4100292067': 3, '4100292068': 3, '4100292069': 2, '4100292070': 2, '4100292071': 2, '4100292072': 3, '4100292073': 3, '4100292074': 2, '4100292075': 3, '4100292077': 2, '4100292078': 3, '4100292079': 2, '4100292081': 3, '4100292083': 3, '4100292084': 2, '4100292085': 3, '4100292087': 2, '4100292088': 2, '4100302002': 3, '4100302013': 1, '4100302014': 3, '4100302016': 1, '4100302017': 2, '4100302018': 1, '4100302019': 2, '4100302020': 2, '4100302024': 2, '4100302028': 3, '4100302030': 1, '4100302040': 0, '4100302041': 2, '4100302042': 0, '4100302043': 1, '4100302044': 0, '4100302045': 0, '4100302046': 2, '4100302047': 2, '4100302048': 1, '4100302049': 3, '4100302050': 2, '4100302051': 2, '4100302052': 2, '4100302053': 2, '4100302054': 3, '4100302055': 1, '4100302058': 0, '4100302061': 2, '4100302063': 2, '4100302064': 0, '4100302066': 1, '4100302067': 3, '4100302068': 2, '4100302069': 3, '4100321001': 1, '4100321002': 2, '4100321003': 3, '4100321004': 2, '4100321005': 3, '4100321006': 2, '4100321008': 2, '4100321009': 1, '4100321010': 3, '4100321011': 2, '4100321012': 2, '4100321014': 2, '4100321015': 3, '4100321016': 2, '4100321019': 1, '4100321020': 2, '4100321021': 2, '4100321022': 3, '4100321023': 3, '4100321024': 3, '4100321026': 3, '4100321027': 3, '4100321028': 3, '4100321029': 2, '4100321030': 3, '4100321032': 3, '4100321033': 2, '4100321034': 2, '4100321037': 3, '4100321038': 3, '4100321039': 2, '4100321041': 3, '4100321042': 1, '4100321043': 1, '4100321044': 1, '4100321045': 2, '4100321046': 3, '4100321049': 3, '4100321051': 2, '4100321052': 3, '4100321053': 2, '4100322001': 2, '4100322007': 3, '4100322025': 2, '4100322031': 2, '4100322032': 1, '4100322033': 2, '4100322034': 2, '4100322035': 2, '4100322037': 2, '4100322038': 2, '4100322039': 2, '4100322040': 3, '4100322041': 2, '4100322042': 3, '4100322044': 3, '4100322045': 3, '4100322048': 2, '4100322051': 3, '4100322052': 3, '4100322053': 2, '4100322055': 2, '4100322056': 2, '4100322057': 2, '4100322058': 2, '4100322059': 3, '4100322060': 2, '4100322061': 2, '4110211001': 1, '4110211004': 1, '4110211005': 1, '4110211006': 2, '4110211007': 2, '4110211008': 2, '4110211009': 2, '4110211011': 2, '4110211013': 1, '4110211014': 1, '4110211015': 0, '4110211016': 3, '4110211018': 2, '4110211019': 3, '4110211020': 2, '4110211021': 1, '4110211022': 1, '4110211023': 1, '4110211024': 2, '4110211025': 0, '4110211026': 2, '4110211027': 1, '4110211028': 1, '4110211030': 2, '4110211032': 2, '4110211033': 2, '4110211034': 2, '4110211035': 2, '4110211036': 1, '4110211037': 2, '4110211038': 1, '4110211039': 1, '4110211040': 0, '4110211041': 2, '4110211043': 2, '4110211044': 3, '4110211045': 1, '4110211046': 3, '4110211047': 3, '4110211048': 2, '4110211049': 2, '4110211050': 2, '4110211051': 3, '4110211052': 2, '4110211053': 1, '4110211054': 2, '4110211055': 1, '4110211056': 3, '4110211057': 2, '4110211058': 3, '4110211060': 2, '4110211061': 0, '4110211062': 2, '4110211063': 2, '4110211064': 2, '4110211065': 2, '4110211067': 3, '4110211068': 2, '4110211072': 2, '4110211073': 2, '4110211075': 1, '4110211076': 3, '4110211078': 1, '4110211079': 2, '4110211080': 2, '4110212003': 2, '4110212004': 2, '4110212007': 2, '4110212008': 2, '4110212009': 2, '4110212010': 2, '4110212011': 2, '4110212013': 3, '4110212014': 3, '4110212015': 2, '4110212016': 2, '4110212017': 2, '4110212018': 2, '4110212019': 2, '4110212021': 3, '4110212023': 2, '4110212024': 2, '4110212026': 2, '4110212027': 2, '4110212029': 2, '4110212030': 3, '4110212033': 2, '4110212034': 1, '4110212035': 2, '4110212036': 1, '4110212038': 2, '4110212039': 3, '4110212041': 2, '4110212042': 2, '4110212044': 3, '4110212045': 2, '4110212046': 2, '4110212047': 3, '4110212049': 1, '4110212050': 2, '4110212051': 1, '4110212052': 3, '4110212053': 2, '4110212054': 2, '4110212055': 2, '4110212056': 2, '4110212059': 2, '4110212061': 2, '4110212062': 1, '4110212063': 2, '4110212064': 2, '4110212069': 2, '4110311001': 3, '4110311003': 3, '4110311004': 3, '4110311005': 2, '4110311006': 1, '4110311012': 2, '4110311015': 3, '4110311017': 2, '4110311018': 3, '4110311019': 2, '4110311020': 2, '4110311021': 2, '4110311023': 1, '4110311030': 2, '4110311031': 3, '4110311032': 2, '4110311033': 2, '4110311034': 2, '4110311036': 3, '4110311037': 3, '4110311038': 3, '4110311042': 3, '4110311043': 3, '4110311044': 2, '4110311045': 1, '4110311046': 2, '4110311048': 1, '4110311049': 2, '4110311050': 2, '4110311053': 3, '4110311054': 1, '4110311057': 2, '4110311061': 2, '4110311062': 1, '4110311064': 2, '4110311065': 2, '4110311067': 2, '4110311068': 2, '4110311072': 2, '4110312006': 3, '4110312007': 2, '4110312008': 2, '4110312009': 1, '4110312013': 2, '4110312023': 3, '4110312024': 3, '4110312025': 3, '4110312027': 2, '4110312030': 3, '4110312031': 2, '4110312048': 2, '4110312049': 2, '4110312078': 3, '414081010': 3, '414081011': 3, '4140810110': 3, '4140810114': 3, '4140810117': 3, '4140810122': 3, '4140810124': 3, '4140810125': 3, '4140810126': 3, '4140810127': 3, '4140810128': 3, '4140810129': 2, '414081013': 2, '4140810132': 3, '4140810133': 3, '4140810135': 2, '4140810136': 3, '4140810138': 3, '4140810139': 2, '4140810140': 2, '4140810142': 3, '4140810143': 3, '4140810144': 3, '4140810145': 3, '4140810146': 3, '4140810148': 3, '414081015': 2, '4140810150': 3, '4140810151': 3, '4140810152': 3, '4140810153': 1, '4140810154': 3, '4140810158': 3, '4140810159': 2, '414081016': 3, '4140810162': 1, '4140810163': 3, '4140810164': 3, '4140810165': 3, '414081017': 3, '4140810171': 2, '4140810173': 3, '4140810175': 3, '4140810176': 3, '4140810179': 2, '414081018': 3, '4140810180': 3, '4140810181': 3, '4140810182': 3, '4140810183': 3, '4140810184': 2, '4140810185': 3, '414081019': 3, '414081021': 3, '4140810210': 1, '4140810211': 3, '4140810212': 2, '4140810215': 2, '4140810217': 1, '4140810219': 1, '4140810220': 3, '4140810221': 2, '4140810222': 3, '4140810223': 3, '4140810224': 3, '4140810225': 2, '4140810226': 2, '4140810228': 3, '4140810229': 3, '414081023': 3, '4140810230': 3, '4140810233': 3, '4140810234': 2, '4140810237': 3, '4140810239': 3, '4140810240': 3, '4140810242': 2, '4140810244': 2, '4140810246': 3, '4140810247': 2, '4140810249': 2, '414081025': 3, '4140810250': 2, '4140810251': 3, '4140810252': 3, '4140810253': 2, '4140810254': 3, '4140810255': 3, '4140810256': 3, '4140810257': 2, '4140810258': 3, '4140810259': 3, '414081026': 3, '4140810264': 3, '4140810265': 3, '4140810266': 3, '4140810268': 3, '4140810269': 3, '414081027': 3, '4140810270': 2, '4140810271': 3, '4140810272': 1, '4140810273': 2, '4140810274': 3, '4140810276': 3, '4140810277': 3, '4140810278': 2, '4140810279': 3, '414081028': 2, '4140810280': 3, '414081029': 2, '459999011': 3, '4599990110': 2, '4599990112': 3, '4599990113': 3, '4599990114': 3, '4599990116': 3, '4599990117': 3, '4599990118': 3, '4599990119': 3, '459999012': 2, '4599990120': 2, '4599990125': 3, '4599990126': 2, '4599990128': 3, '4599990129': 2, '459999013': 3, '4599990130': 3, '4599990131': 3, '4599990132': 1, '4599990133': 2, '4599990134': 3, '4599990136': 3, '4599990137': 3, '4599990139': 3, '4599990141': 3, '4599990144': 3, '4599990146': 3, '4599990148': 2, '4599990149': 3, '4599990153': 3, '4599990154': 3, '4599990155': 3, '459999016': 3, '4599990163': 2, '4599990165': 3, '4599990166': 3, '4599990168': 3, '459999017': 2, '4599990171': 3, '459999021': 3, '4599990211': 3, '4599990212': 3, '4599990214': 2, '4599990216': 3, '4599990218': 3, '459999022': 3, '4599990221': 3, '4599990222': 3, '4599990223': 3, '4599990224': 3, '4599990226': 3, '4599990231': 3, '4599990233': 2, '4599990234': 3, '4599990235': 1, '4599990238': 3, '459999024': 3, '4599990240': 3, '4599990241': 3, '4599990243': 2, '4599990244': 3, '4599990245': 2, '4599990246': 3, '4599990247': 3, '4599990248': 2, '4599990249': 3, '459999025': 3, '4599990253': 3, '4599990254': 3, '4599990255': 2, '4599990256': 3, '4599990263': 3, '4599990264': 2, '4599990269': 2, '4599990270': 3, '4599990272': 2, '4599990273': 3, '4599990274': 3, '4599990275': 3, '4599990276': 2, '459999028': 2, '4599990283': 3, '5000391001': 2, '5000391002': 2, '5000391004': 3, '5000391005': 2, '5000391007': 3, '5000391008': 2, '5000391010': 2, '5000391012': 2, '5000391013': 3, '5000391014': 2, '5000391015': 3, '5000391016': 3, '5000391017': 1, '5000391019': 2, '5000391020': 2, '5000391022': 3, '5000391023': 2, '5000391024': 2, '5000391026': 2, '5000391028': 3, '5000391029': 2, '5000391030': 3, '5000391031': 3, '5000391032': 3, '5000391034': 2, '5000391035': 3, '5000391036': 2, '5000391037': 3, '5000391038': 2, '5000391040': 2, '5000391045': 1, '5000391046': 2, '5000391047': 3, '5000391049': 2, '5000391050': 2, '5000391054': 2, '5000391055': 1, '5000391056': 1, '5000391059': 2, '5000391060': 1, '5000391061': 2, '5000391062': 3, '5000391063': 3, '5000391064': 2, '5000391065': 2, '5000391066': 3, '5000391067': 2, '5000391068': 3, '5000391069': 3, '5000391070': 2, '5000391071': 2, '5000391072': 2, '5000391073': 2, '5000391074': 2, '5000391076': 2, '5000391078': 2, '5000391079': 2, '5000391080': 3, '5000391081': 2, '5000392001': 2, '5000392002': 2, '5000392003': 3, '5000392006': 2, '5000392007': 2, '5000392010': 3, '5000392011': 2, '5000392015': 2, '5000392016': 2, '5000392017': 2, '5000392018': 2, '5000392019': 2, '5000392020': 2, '5000392021': 2, '5000392022': 2, '5000392025': 2, '5000392026': 2, '5000392027': 2, '5000392029': 2, '5000392033': 1, '5000392035': 2, '5000392036': 3, '5000392038': 2, '5000392039': 2, '5000392040': 3, '5000392041': 3, '5000392042': 2, '5000392044': 2, '5000392047': 2, '5000392048': 2, '5000392049': 3, '5000392050': 3, '5000392051': 3, '5000392052': 1, '5000392053': 2, '5000392054': 2, '5000392055': 2, '5000392056': 2, '5000392058': 2, '5000392060': 1, '5000392062': 2, '5000392063': 2, '5000392064': 2, '5000392065': 2, '5000392066': 2, '5000392067': 2, '5000392070': 2, '5000392071': 2, '5000392072': 2, '5000431019': 2, '5000431020': 3, '5000431021': 3, '5000431022': 2, '5000431023': 3, '5000431025': 2, '5000431026': 2, '5000431049': 3, '5000431050': 3, '5000432001': 3, '5000432003': 2, '5000432006': 2, '5000432059': 3, '5000441001': 2, '5000441002': 2, '5000441003': 2, '5000441005': 2, '5000441006': 2, '5000441007': 2, '5000441008': 2, '5000441009': 3, '5000441010': 2, '5000441012': 2, '5000441013': 2, '5000441014': 2, '5000441015': 2, '5000441016': 3, '5000441017': 2, '5000441018': 3, '5000441021': 3, '5000441022': 2, '5000441023': 3, '5000441024': 1, '5000441027': 3, '5000441030': 2, '5000441031': 2, '5000441032': 2, '5000441033': 2, '5000441034': 2, '5000441035': 3, '5000441037': 2, '5000441038': 3, '5000441039': 3, '5000441040': 3, '5000441041': 3, '5000441042': 2, '5000441043': 2, '5000441044': 2, '5000441045': 2, '5000441046': 3, '5000441047': 2, '5000441048': 2, '5000441050': 2, '5000441051': 2, '5000441052': 2, '5000441053': 3, '5000441054': 2, '5000441055': 3, '5000441058': 1, '5000441059': 2, '5000441061': 3, '5000441062': 2, '5000441064': 2, '5000441065': 2, '5000441066': 2, '5000441067': 1, '5000441068': 2, '5000441069': 2, '5000441070': 3, '5000441071': 3, '5000441072': 3, '5000442001': 3, '5000442002': 2, '5000442003': 2, '5000442004': 2, '5000442005': 2, '5000442007': 2, '5000442008': 2, '5000442009': 3, '5000442010': 2, '5000442014': 3, '5000442015': 2, '5000442016': 2, '5000442019': 2, '5000442021': 2, '5000442022': 3, '5000442024': 2, '5000442025': 2, '5000442026': 2, '5000442027': 3, '5000442028': 2, '5000442029': 3, '5000442033': 2, '5000442034': 3, '5000442035': 3, '5000442036': 2, '5000442037': 3, '5000442038': 3, '5000442039': 3, '5000442040': 3, '5000442042': 2, '5000442043': 3, '5000442045': 3, '5000442047': 2, '5000442048': 2, '5000442050': 2, '5000442051': 2, '5000442052': 2, '5000442053': 2, '5000442054': 3, '5000442055': 3, '5000442056': 2, '5000442057': 3, '5000442058': 3, '5000442059': 3, '5000442060': 2, '5000442062': 2, '5000442063': 3, '5000442064': 3, '5000442065': 3, '5000442066': 3, '5000442067': 2, '5000442068': 3, '5000442069': 3, '5000442070': 3, '5000442072': 2, '5000442073': 3, '5000442074': 2, '5000442075': 2, '5000442076': 2, '5000442077': 2, '5000442078': 2, '5000671001': 3, '5000671002': 2, '5000671003': 2, '5000671004': 3, '5000671005': 2, '5000671006': 2, '5000671008': 3, '5000671009': 2, '5000671010': 3, '5000671011': 3, '5000671012': 3, '5000671013': 2, '5000671014': 3, '5000671015': 3, '5000671016': 2, '5000671017': 2, '5000671018': 3, '5000671019': 2, '5000671020': 2, '5000671022': 2, '5000671023': 3, '5000671024': 2, '5000671026': 3, '5000671027': 2, '5000671028': 3, '5000671029': 2, '5000671030': 3, '5000671031': 2, '5000671032': 3, '5000671033': 3, '5000671034': 2, '5000671035': 3, '5000671036': 2, '5000671037': 2, '5000671038': 2, '5000671039': 2, '5000671040': 2, '5000671041': 1, '5000671042': 1, '5000671043': 2, '5000671046': 2, '5000671047': 2, '5000671048': 1, '5000671049': 1, '5000671050': 2, '5000671051': 2, '5000671053': 2, '5000671055': 2, '5000671056': 3, '5000671057': 2, '5000671058': 1, '5000671059': 2, '5000671060': 2, '5000671061': 1, '5000671062': 2, '5000671063': 2, '5000671064': 3, '5000671065': 2, '5000671066': 2, '5000671067': 2, '5000671069': 1, '5000671070': 1, '5000671071': 2, '5000672002': 2, '5000672004': 2, '5000672005': 2, '5000672006': 3, '5000672007': 2, '5000672008': 2, '5000672010': 2, '5000672011': 3, '5000672012': 2, '5000672013': 3, '5000672014': 3, '5000672016': 2, '5000672017': 2, '5000672019': 3, '5000672020': 3, '5000672021': 3, '5000672022': 3, '5000672023': 2, '5000672024': 2, '5000672025': 3, '5000672026': 3, '5000672027': 2, '5000672030': 2, '5000672031': 2, '5000672033': 2, '5000672034': 2, '5000672035': 3, '5000672036': 2, '5000672038': 3, '5000672042': 3, '5000672043': 3, '5000672044': 3, '5000672045': 3, '5000672046': 2, '5000672047': 2, '5000672048': 2, '5000672049': 2, '5000672050': 2, '5000672051': 3, '5000672052': 3, '5000672053': 2, '5000672054': 3, '5000672055': 3, '5000672056': 3, '5000672057': 2, '5000672058': 2, '5000672059': 2, '5000672060': 2, '5000672062': 3, '5000672064': 2, '5000672065': 2, '5000672066': 2, '5000672067': 2, '5000672068': 2, '5000672070': 3, '5000672071': 2, '5000672072': 2, '5000672074': 3, '5000672075': 3, '5000672076': 3, '5000672077': 2, '5000672081': 2, '5000672082': 2, '5000951001': 2, '5000951002': 2, '5000951003': 3, '5000951004': 2, '5000951005': 2, '5000951006': 2, '5000951007': 3, '5000951008': 2, '5000951009': 3, '5000951010': 2, '5000951011': 3, '5000951012': 2, '5000951013': 2, '5000951015': 3, '5000951016': 2, '5000951017': 2, '5000951018': 2, '5000951019': 1, '5000951021': 2, '5000951023': 1, '5000951024': 1, '5000951025': 2, '5000951027': 1, '5000951028': 3, '5000951033': 2, '5000951034': 2, '5000951035': 2, '5000951037': 2, '5000951039': 2, '5000951040': 3, '5000951042': 2, '5000951043': 3, '5000951044': 2, '5000951045': 2, '5000951047': 2, '5000951049': 3, '5000951051': 3, '5000951052': 2, '5000951053': 2, '5000951054': 3, '5000951055': 2, '5000951056': 3, '5000951057': 3, '5000951058': 3, '5000951060': 3, '5000951061': 2, '5000951062': 2, '5000951063': 2, '5000951065': 3, '5000951066': 2, '5000951067': 2, '5000952002': 2, '5000952003': 2, '5000952004': 2, '5000952005': 3, '5000952007': 3, '5000952008': 3, '5000952011': 2, '5000952013': 2, '5000952014': 2, '5000952015': 3, '5000952016': 2, '5000952017': 2, '5000952018': 2, '5000952020': 2, '5000952021': 2, '5000952022': 2, '5000952023': 3, '5000952024': 2, '5000952025': 3, '5000952026': 3, '5000952027': 2, '5000952028': 2, '5000952029': 2, '5000952031': 2, '5000952032': 2, '5000952033': 2, '5000952034': 1, '5000952035': 2, '5000952036': 2, '5000952038': 3, '5000952040': 3, '5000952041': 2, '5000952042': 2, '5000952044': 2, '5000952045': 2, '5000952046': 3, '5000952048': 2, '5000952050': 3, '5000952052': 2, '5000952053': 3, '5000952054': 2, '5000952055': 2, '5000952060': 2, '5000952061': 2, '5000952062': 1, '5000952063': 2, '5000952064': 3, '5000952065': 2, '5000952066': 2, '5000952068': 3, '5000952069': 2, '5000952070': 3, '5000952071': 2, '5000952072': 3, '5000952073': 2, '5000952075': 2, '5000952076': 3, '5000952077': 2, '5000952078': 2, '5000952080': 3, '5000952083': 1, '5100091001': 2, '5100091003': 3, '5100091004': 3, '5100091005': 2, '5100091006': 2, '5100091007': 3, '5100091008': 3, '5100091009': 2, '5100091010': 3, '5100091012': 2, '5100091017': 2, '5100091019': 2, '5100091020': 3, '5100091025': 2, '5100091026': 3, '5100091027': 2, '5100091028': 2, '5100091032': 3, '5100091033': 2, '5100091034': 3, '5100091035': 3, '5100091036': 3, '5100091038': 3, '5100091039': 3, '5100091042': 3, '5100091046': 3, '5100091049': 1, '5100091050': 2, '5100091051': 2, '5100091053': 2, '5100091055': 3, '5100091056': 2, '5100091057': 2, '5100091058': 2, '5100091059': 2, '5100091062': 2, '5100091064': 2, '5100091065': 3, '5100091066': 2, '5100091067': 3, '5100091068': 2, '5100091069': 3, '5100092002': 3, '5100092003': 3, '5100092005': 3, '5100092006': 3, '5100092008': 3, '5100092010': 3, '5100092011': 2, '5100092013': 3, '5100092017': 2, '5100092019': 3, '5100092021': 2, '5100092022': 3, '5100092023': 3, '5100092026': 3, '5100092027': 3, '5100092032': 2, '5100092033': 3, '5100092034': 2, '5100092035': 2, '5100092037': 2, '5100092038': 2, '5100092039': 3, '5100092040': 3, '5100092041': 2, '5100092042': 3, '5100092043': 2, '5100092044': 3, '5100092045': 3, '5100092053': 2, '5100092056': 2, '5100092057': 2, '5100092060': 3, '5100092061': 3, '5100092062': 2, '5100092063': 2, '5100092064': 3, '5100092065': 2, '5100092067': 3, '5100092068': 2, '5100092069': 3, '5100092071': 3, '5100092072': 3, '5100341002': 2, '5100341003': 2, '5100341004': 3, '5100341005': 2, '5100341006': 2, '5100341008': 2, '5100341009': 2, '5100341010': 2, '5100341012': 3, '5100341013': 2, '5100341014': 3, '5100341015': 2, '5100341016': 2, '5100341017': 2, '5100341019': 2, '5100341020': 3, '5100341021': 3, '5100341022': 2, '5100341023': 2, '5100341024': 3, '5100341025': 2, '5100341026': 3, '5100341027': 3, '5100341028': 2, '5100341030': 2, '5100341031': 3, '5100341032': 2, '5100341033': 2, '5100341034': 3, '5100341035': 2, '5100341037': 2, '5100341038': 2, '5100341039': 3, '5100341042': 2, '5100341043': 1, '5100341046': 2, '5100341048': 3, '5100341050': 3, '5100341052': 3, '5100341054': 3, '5100341055': 3, '5100341056': 2, '5100341057': 2, '5100341058': 3, '5100341061': 2, '5100341062': 3, '5100341065': 3, '5100341067': 3, '5100341068': 3, '5100341070': 3, '5100341071': 3, '5100341072': 3, '5100341074': 1, '5100341075': 3, '5100341076': 3, '5100341077': 2, '5100341078': 3, '5100341079': 3, '5100342002': 3, '5100342003': 2, '5100342007': 3, '5100342008': 2, '5100342009': 2, '5100342012': 2, '5100342016': 2, '5100342017': 3, '5100342018': 2, '5100342020': 3, '5100342022': 0, '5100342023': 1, '5100342024': 1, '5100342025': 2, '5100342028': 1, '5100342030': 2, '5100342031': 2, '5100342034': 2, '5100342036': 1, '5100342042': 2, '5100342043': 2, '5100342045': 2, '5100342048': 1, '5100351001': 1, '5100351002': 1, '5100351004': 2, '5100351005': 2, '5100351007': 2, '5100351009': 2, '5100351010': 2, '5100351012': 3, '5100351013': 1, '5100351015': 2, '5100351016': 2, '5100351019': 2, '5100351020': 2, '5100351021': 2, '5100351022': 0, '5100351023': 2, '5100351024': 2, '5100351025': 2, '5100351026': 3, '5100351032': 3, '5100351034': 3, '5100351035': 2, '5100351036': 2, '5100351038': 2, '5100351039': 3, '5100351040': 2, '5100351042': 1, '5100351043': 3, '5100351044': 2, '5100351045': 2, '5100351046': 3, '5100351049': 3, '5100351051': 3, '5100351054': 2, '5100351058': 2, '5100352001': 2, '5100352002': 2, '5100352003': 2, '5100352004': 3, '5100352005': 2, '5100352006': 2, '5100352007': 3, '5100352008': 2, '5100352009': 3, '5100352011': 2, '5100352012': 2, '5100352013': 3, '5100352014': 2, '5100352015': 2, '5100352016': 2, '5100352017': 3, '5100352018': 2, '5100352020': 3, '5100352021': 2, '5100352022': 1, '5100352026': 3, '5100352027': 3, '5100352028': 2, '5100352030': 3, '5100352031': 3, '5100352032': 2, '5100352033': 2, '5100352034': 2, '5100352035': 2, '5100352037': 2, '5100352038': 3, '5100352039': 3, '5100352041': 2, '5100352042': 2, '5100352043': 1, '5100352044': 2, '5100352045': 3, '5100352046': 3, '5100352049': 2, '5100352050': 2, '5100352051': 2, '5100352052': 3, '5100352054': 1, '5100352055': 3, '5100352056': 2, '5100352057': 2, '5100352060': 2, '5100352061': 2, '5100352063': 2, '5100361009': 2, '5100361056': 2, '5100362028': 3, '5100362029': 2, '5100362030': 3, '5100362052': 2, '5100371022': 2, '5100371023': 3, '5100371024': 2, '5100371026': 3, '5100371027': 3, '5100371042': 3, '5100371055': 2, '5100371056': 2, '5100371067': 2, '5100371079': 2, '5100372001': 3, '5100372002': 2, '5100372003': 2, '5100372005': 2, '5100372006': 3, '5100372007': 3, '5100372009': 3, '5100372011': 3, '5100372015': 3, '5100372016': 3, '5100372017': 3, '5100372018': 3, '5100372019': 2, '5100372020': 3, '5100372021': 2, '5100372022': 3, '5100372023': 3, '5100372026': 3, '5100372027': 3, '5100372028': 2, '5100372069': 3, '5100381002': 3, '5100381003': 3, '5100381004': 2, '5100381005': 2, '5100381006': 2, '5100381007': 2, '5100381008': 2, '5100381009': 2, '5100381010': 2, '5100381011': 3, '5100381012': 3, '5100381015': 3, '5100381016': 3, '5100381017': 2, '5100381018': 2, '5100381019': 3, '5100381020': 2, '5100381021': 2, '5100381022': 2, '5100381023': 3, '5100381024': 3, '5100381026': 2, '5100381027': 3, '5100381028': 3, '5100381029': 3, '5100381031': 2, '5100381032': 2, '5100381034': 3, '5100381035': 2, '5100381037': 2, '5100381038': 2, '5100381039': 2, '5100381040': 3, '5100381041': 3, '5100381042': 2, '5100381043': 2, '5100381044': 2, '5100381045': 3, '5100381046': 3, '5100381047': 3, '5100381048': 3, '5100381049': 2, '5100381050': 3, '5100381051': 2, '5100381052': 3, '5100381053': 3, '5100381054': 2, '5100381055': 2, '5100381056': 3, '5100381058': 2, '5100381059': 3, '5100381060': 2, '5100381061': 2, '5100381063': 2, '5100381065': 2, '5100381066': 2, '5100381067': 2, '5100381069': 2, '5100382001': 2, '5100382003': 3, '5100382007': 2, '5100382008': 2, '5100382010': 3, '5100382011': 3, '5100382012': 3, '5100382013': 3, '5100382014': 3, '5100382015': 2, '5100382016': 3, '5100382018': 3, '5100382019': 3, '5100382020': 2, '5100382021': 3, '5100382022': 3, '5100382023': 3, '5100382025': 3, '5100382026': 3, '5100382027': 3, '5100382028': 2, '5100382029': 3, '5100382030': 3, '5100382031': 2, '5100382032': 2, '5100382033': 3, '5100382034': 2, '5100382035': 2, '5100382036': 3, '5100382037': 2, '5100382038': 3, '5100382039': 3, '5100382040': 2, '5100382042': 3, '5100382045': 3, '5100382046': 2, '5100382048': 2, '5100382050': 3, '5100382051': 2, '5100382052': 3, '5100382053': 3, '5100382054': 2, '5100382055': 3, '5100382056': 3, '5100382057': 3, '5100382058': 2, '5100382059': 2, '5100382060': 3, '5100382061': 3, '5100382062': 3, '5100382063': 3, '5100382064': 3, '5100382065': 3, '5100382066': 2, '5100382067': 2, '5100382068': 3, '5100382069': 2, '5100382070': 3, '5100382071': 3, '5100382072': 3, '5100382073': 2, '5100382075': 2, '5100382076': 2, '5100382077': 2, '5100382078': 2, '5100382079': 2, '5100401001': 2, '5100401003': 2, '5100401005': 2, '5100401006': 2, '5100401007': 3, '5100401008': 3, '5100401010': 2, '5100401011': 2, '5100401012': 2, '5100401014': 3, '5100401015': 2, '5100401016': 2, '5100401018': 2, '5100401021': 3, '5100401022': 3, '5100401023': 1, '5100401025': 3, '5100401026': 3, '5100401028': 2, '5100401029': 2, '5100401030': 3, '5100401031': 2, '5100401032': 2, '5100401033': 2, '5100401034': 1, '5100401035': 2, '5100401036': 2, '5100401038': 3, '5100401039': 2, '5100401040': 2, '5100401042': 2, '5100401043': 1, '5100401044': 3, '5100401045': 3, '5100401046': 2, '5100401047': 2, '5100401048': 2, '5100401049': 2, '5100401050': 2, '5100401051': 2, '5100401053': 3, '5100401054': 2, '5100401055': 2, '5100401056': 3, '5100401057': 3, '5100401059': 2, '5100401060': 2, '5100401061': 2, '5100401062': 3, '5100401063': 2, '5100401064': 2, '5100401065': 1, '5100401066': 3, '5100401067': 2, '5100401069': 3, '5100401070': 2, '5100401071': 2, '5100401072': 3, '5100401073': 2, '5100401074': 3, '5100401075': 2, '5100401076': 2, '5100401077': 2, '5100401078': 2, '5100402001': 1, '5100402002': 2, '5100402004': 3, '5100402005': 3, '5100402007': 2, '5100402008': 3, '5100402009': 2, '5100402011': 2, '5100402012': 2, '5100402015': 2, '5100402016': 2, '5100402017': 2, '5100402019': 3, '5100402020': 2, '5100402023': 3, '5100402024': 3, '5100402028': 2, '5100402029': 2, '5100402031': 2, '5100402032': 3, '5100402033': 2, '5100402034': 2, '5100402035': 3, '5100402036': 2, '5100402037': 2, '5100402038': 3, '5100402039': 2, '5100402040': 3, '5100402046': 2, '5100402047': 2, '5100402048': 2, '5100402049': 3, '5100402050': 2, '5100402051': 2, '5100402052': 2, '5100402053': 2, '5100402054': 2, '5100402055': 2, '5100402057': 2, '5100402058': 2, '5100402059': 2, '5100402062': 1, '5100402063': 1, '5100402065': 3, '5100402066': 2, '5100402067': 2, '5100402068': 2, '5100402069': 2, '5100421001': 3, '5100421002': 2, '5100421003': 3, '5100421005': 3, '5100421007': 2, '5100421009': 2, '5100421011': 2, '5100421012': 3, '5100421013': 2, '5100421015': 3, '5100421016': 3, '5100421017': 2, '5100421018': 2, '5100421019': 3, '5100421020': 2, '5100421021': 3, '5100421024': 3, '5100421025': 2, '5100421026': 3, '5100421027': 2, '5100421029': 3, '5100421032': 3, '5100421033': 3, '5100421034': 3, '5100421038': 2, '5100421039': 3, '5100421040': 2, '5100421041': 2, '5100421043': 2, '5100421045': 2, '5100421047': 2, '5100421048': 3, '5100421049': 3, '5100421050': 2, '5100421051': 2, '5100421052': 2, '5100421053': 3, '5100421054': 2, '5100421056': 3, '5100421057': 3, '5100421058': 2, '5100421059': 2, '5100421060': 2, '5100421061': 2, '5100421062': 3, '5100421063': 2, '5100421064': 3, '5100421065': 3, '5100421067': 2, '5100421068': 3, '5100421069': 2, '5100421070': 3, '5100421071': 2, '5100421072': 2, '5100421073': 3, '5100421074': 2, '5100421076': 3, '5100421078': 3, '5100421079': 3, '5100421080': 3, '5100421081': 3, '5100422002': 2, '5100422003': 2, '5100422004': 3, '5100422005': 2, '5100422006': 3, '5100422007': 2, '5100422008': 2, '5100422009': 2, '5100422011': 2, '5100422012': 3, '5100422013': 2, '5100422014': 2, '5100422016': 2, '5100422017': 3, '5100422018': 2, '5100422019': 3, '5100422022': 2, '5100422023': 2, '5100422024': 2, '5100422025': 3, '5100422026': 3, '5100422027': 2, '5100422028': 3, '5100422029': 2, '5100422030': 2, '5100422033': 2, '5100422034': 2, '5100422035': 2, '5100422036': 3, '5100422037': 2, '5100422038': 3, '5100422039': 3, '5100422041': 2, '5100422042': 3, '5100422044': 2, '5100422045': 2, '5100422046': 3, '5100422047': 2, '5100422049': 2, '5100422050': 3, '5100422051': 2, '5100422052': 2, '5100422055': 3, '5100422056': 3, '5100422057': 2, '5100422058': 2, '5100422059': 3, '5100422060': 2, '5100422061': 3, '5100422062': 2, '5100422063': 3, '5100422065': 3, '5100422066': 2, '5100422067': 2, '5100422068': 2, '5100422069': 2, '5100422071': 3, '5100422072': 2, '5100422073': 2, '5100422074': 2, '5100422075': 3, '5100422077': 2, '5100422078': 2, '5100422079': 3, '5100422080': 2, '5100422081': 2, '5100422084': 2, '5100422085': 2, '5100451001': 2, '5100451003': 3, '5100451004': 3, '5100451006': 3, '5100451007': 3, '5100451012': 3, '5100451013': 3, '5100451015': 3, '5100451016': 3, '5100451017': 2, '5100451018': 3, '5100451019': 3, '5100451020': 2, '5100451024': 3, '5100451026': 3, '5100451027': 3, '5100451033': 2, '5100451034': 3, '5100451035': 3, '5100451036': 2, '5100451038': 2, '5100451041': 3, '5100451043': 2, '5100451044': 3, '5100451045': 2, '5100451049': 3, '5100451050': 3, '5100451051': 2, '5100451052': 3, '5100451055': 2, '5100451056': 3, '5100451059': 3, '5100451060': 3, '5100451061': 3, '5100451064': 2, '5100451065': 3, '5100451066': 2, '5100451067': 3, '5100451070': 3, '5100451071': 3, '5100452002': 2, '5100452004': 3, '5100452005': 2, '5100452006': 3, '5100452007': 2, '5100452008': 3, '5100452009': 3, '5100452010': 2, '5100452011': 2, '5100452012': 3, '5100452013': 3, '5100452014': 3, '5100452016': 1, '5100452017': 3, '5100452018': 3, '5100452021': 2, '5100452023': 2, '5100452025': 2, '5100452027': 2, '5100452028': 3, '5100452030': 3, '5100452031': 3, '5100452032': 2, '5100452033': 2, '5100452034': 3, '5100452035': 2, '5100452036': 3, '5100452037': 3, '5100452038': 3, '5100452039': 2, '5100452040': 2, '5100452047': 3, '5100452049': 3, '5100452050': 3, '5100452053': 2, '5100452054': 3, '5100452055': 2, '5100452059': 3, '5100452060': 3, '5100452061': 2, '5100452065': 3, '5100452066': 3, '5100452067': 3, '5100452076': 3, '5100452078': 3, '5100452079': 3, '5100452080': 3, '5100452081': 2, '5100461004': 2, '5100461005': 2, '5100461006': 2, '5100461007': 1, '5100461008': 2, '5100461009': 3, '5100461010': 2, '5100461011': 2, '5100461014': 2, '5100461015': 3, '5100461016': 2, '5100461017': 3, '5100461018': 2, '5100461020': 2, '5100461021': 2, '5100461022': 3, '5100461023': 3, '5100461025': 2, '5100461029': 2, '5100461030': 3, '5100461031': 2, '5100461032': 2, '5100461033': 2, '5100461034': 2, '5100461035': 2, '5100461036': 2, '5100461037': 2, '5100461038': 2, '5100461039': 3, '5100461040': 2, '5100461042': 3, '5100461043': 2, '5100461044': 3, '5100461046': 2, '5100461047': 2, '5100461048': 2, '5100461049': 2, '5100461050': 2, '5100461051': 3, '5100461052': 2, '5100461053': 3, '5100461054': 2, '5100461055': 3, '5100461056': 3, '5100461057': 2, '5100461058': 2, '5100461061': 3, '5100461062': 2, '5100461063': 2, '5100461064': 3, '5100461065': 3, '5100461066': 3, '5100461067': 2, '5100461068': 2, '5100461069': 3, '5100462001': 2, '5100462002': 2, '5100462003': 1, '5100462005': 2, '5100462009': 2, '5100462010': 3, '5100462011': 3, '5100462012': 2, '5100462014': 3, '5100462015': 2, '5100462016': 2, '5100462017': 2, '5100462018': 2, '5100462019': 2, '5100462021': 3, '5100462022': 2, '5100462023': 2, '5100462024': 2, '5100462025': 2, '5100462026': 3, '5100462027': 2, '5100462028': 3, '5100462029': 3, '5100462031': 2, '5100462032': 2, '5100462033': 2, '5100462035': 3, '5100462037': 3, '5100462038': 2, '5100462039': 2, '5100462040': 2, '5100462041': 3, '5100462042': 2, '5100462043': 2, '5100462044': 2, '5100462045': 2, '5100462046': 2, '5100462047': 3, '5100462048': 2, '5100462050': 2, '5100462051': 2, '5100462052': 2, '5100462053': 3, '5100462054': 2, '5100462055': 3, '5100462057': 2, '5100462058': 3, '5100462059': 2, '5100462061': 2, '5100462062': 2, '5100462063': 3, '5100462064': 3, '5100462066': 2, '5100462067': 2, '5100462068': 2, '5100462069': 3, '5100462070': 3, '5100462071': 2, '5100462072': 3, '5100462074': 2, '5100462075': 3, '5100462077': 3, '5100462078': 2, '5100462079': 2, '5100462080': 2, '5100462081': 2, '5100462082': 2, '5100471001': 2, '5100471002': 3, '5100471003': 3, '5100471011': 2, '5100471012': 2, '5100471013': 2, '5100471015': 2, '5100471016': 3, '5100471018': 2, '5100471019': 3, '5100471020': 2, '5100471021': 2, '5100471023': 2, '5100471026': 3, '5100471027': 2, '5100471028': 3, '5100471029': 2, '5100471030': 3, '5100471031': 2, '5100471034': 2, '5100471037': 3, '5100471038': 3, '5100471039': 3, '5100471041': 3, '5100471042': 2, '5100471044': 2, '5100471045': 2, '5100471047': 3, '5100471049': 2, '5100471050': 3, '5100471051': 2, '5100471052': 2, '5100471054': 2, '5100471056': 2, '5100471057': 3, '5100471058': 2, '5100471059': 2, '5100471060': 2, '5100471062': 3, '5100471063': 3, '5100471065': 2, '5100471068': 2, '5100471069': 3, '5100471070': 2, '5100471072': 2, '5100471074': 2, '5100471075': 2, '5100471080': 2, '5100471081': 2, '5100472001': 1, '5100472002': 2, '5100472003': 2, '5100472004': 3, '5100472005': 2, '5100472007': 3, '5100472009': 3, '5100472010': 3, '5100472011': 2, '5100472012': 2, '5100472014': 2, '5100472019': 2, '5100472020': 3, '5100472021': 3, '5100472027': 3, '5100472030': 2, '5100472031': 2, '5100472032': 3, '5100472035': 2, '5100472039': 2, '5100472040': 2, '5100472041': 3, '5100472042': 2, '5100472044': 2, '5100472045': 3, '5100472047': 2, '5100472050': 2, '5100472052': 3, '5100472053': 2, '5100472054': 2, '5100472058': 1, '5100472060': 2, '5100472063': 2, '5100472064': 2, '5221290110': 3, '5221290111': 3, '5221290112': 3, '5221290114': 3, '5221290115': 2, '5221290116': 2, '5221290118': 3, '5221290119': 3, '5221290121': 3, '5221290122': 3, '5221290123': 2, '5221290124': 3, '5221290126': 3, '5221290127': 3, '5221290129': 3, '522129013': 3, '5221290131': 2, '5221290132': 3, '5221290134': 3, '5221290135': 3, '5221290137': 3, '5221290138': 3, '5221290140': 3, '5221290141': 3, '5221290142': 2, '5221290144': 3, '5221290145': 3, '5221290147': 3, '5221290149': 3, '5221290150': 3, '5221290151': 3, '5221290155': 3, '5221290158': 3, '522129016': 3, '5221290161': 2, '5221290162': 2, '5221290163': 2, '5221290164': 2, '5221290165': 3, '5221290166': 3, '5221290167': 3, '5221290169': 3, '522129017': 3, '5221290171': 2, '5221290172': 3, '5221290173': 3, '5221290174': 3, '5221290175': 3, '5221290177': 3, '5221290178': 3, '5221290179': 2, '522129018': 2, '5221290180': 3, '5221290184': 2, '522129021': 2, '5221290210': 3, '5221290212': 3, '5221290213': 3, '5221290214': 3, '5221290215': 3, '5221290216': 3, '5221290217': 3, '522129022': 3, '5221290220': 3, '5221290221': 3, '5221290222': 3, '5221290223': 3, '5221290226': 3, '5221290227': 2, '5221290228': 2, '5221290230': 2, '5221290231': 3, '5221290235': 2, '5221290237': 2, '5221290238': 3, '5221290239': 3, '522129024': 2, '5221290240': 3, '5221290242': 3, '5221290247': 3, '5221290249': 3, '522129025': 3, '5221290250': 2, '5221290251': 3, '5221290252': 3, '5221290253': 3, '5221290254': 3, '5221290255': 3, '5221290256': 3, '5221290257': 2, '5221290258': 3, '5221290259': 3, '522129026': 3, '5221290263': 3, '5221290264': 3, '5221290266': 3, '5221290268': 3, '5221290269': 2, '522129027': 3, '5221290270': 3, '5221290271': 2, '5221290272': 2, '5221290273': 3, '5221290274': 3, '5221290275': 2, '5221290279': 3, '5221290280': 1, '5221290282': 3, '5221290284': 3, '5564630110': 2, '5564630112': 2, '5564630115': 2, '5564630117': 3, '556463012': 3, '5564630121': 3, '5564630122': 2, '5564630123': 3, '5564630126': 0, '5564630127': 3, '5564630128': 3, '5564630129': 3, '556463013': 3, '5564630130': 2, '5564630132': 1, '5564630133': 2, '5564630134': 2, '5564630135': 3, '5564630137': 1, '5564630138': 1, '5564630139': 2, '556463014': 1, '5564630140': 2, '5564630141': 1, '5564630142': 2, '5564630143': 2, '5564630145': 3, '5564630147': 2, '5564630148': 3, '5564630149': 2, '5564630150': 2, '5564630152': 2, '5564630153': 3, '5564630154': 1, '5564630156': 1, '5564630157': 3, '5564630158': 3, '556463016': 3, '5564630160': 2, '5564630161': 2, '5564630162': 3, '5564630163': 3, '5564630165': 2, '5564630166': 2, '5564630167': 3, '5564630168': 1, '556463018': 3, '556463019': 2, '5564630211': 1, '5564630212': 2, '5564630213': 3, '5564630215': 2, '5564630216': 3, '5564630217': 3, '5564630218': 2, '5564630219': 2, '556463022': 1, '5564630221': 3, '5564630222': 3, '5564630226': 1, '5564630228': 3, '5564630229': 3, '5564630230': 3, '5564630232': 2, '5564630233': 2, '5564630234': 3, '5564630235': 2, '5564630236': 3, '5564630237': 3, '5564630238': 1, '556463024': 3, '5564630240': 2, '5564630241': 3, '5564630247': 3, '5564630249': 3, '556463025': 1, '5564630252': 2, '5564630253': 3, '5564630254': 3, '5564630256': 2, '5564630257': 1, '5564630258': 3, '556463026': 2, '5564630261': 3, '5564630262': 3, '5564630264': 2, '5564630265': 3, '5564630269': 2, '556463027': 3, '5564630273': 2, '5564630275': 2, '5564630276': 3, '556463028': 2, '5564630281': 3, '556463029': 2, '567496011': 3, '5674960111': 2, '5674960114': 3, '5674960115': 2, '5674960116': 3, '5674960117': 2, '5674960118': 2, '5674960121': 3, '5674960123': 3, '5674960124': 2, '5674960125': 3, '5674960126': 3, '567496013': 2, '5674960131': 2, '5674960132': 3, '5674960134': 3, '5674960136': 2, '5674960138': 2, '567496014': 3, '5674960142': 2, '5674960144': 3, '5674960145': 3, '5674960146': 3, '5674960148': 3, '5674960151': 3, '5674960153': 3, '5674960154': 3, '5674960155': 1, '5674960156': 2, '5674960157': 2, '5674960158': 2, '5674960160': 3, '5674960161': 2, '5674960166': 3, '567496017': 2, '5674960170': 3, '567496018': 2, '567496019': 3, '567496021': 1, '5674960211': 2, '5674960215': 3, '5674960216': 3, '5674960219': 3, '567496022': 1, '5674960220': 3, '5674960221': 3, '5674960222': 1, '5674960224': 3, '5674960225': 0, '5674960227': 3, '5674960228': 3, '5674960229': 2, '5674960230': 3, '5674960234': 2, '5674960235': 2, '567496024': 2, '5674960242': 2, '5674960246': 3, '5674960249': 2, '5674960251': 3, '5674960252': 2, '5674960255': 2, '5674960257': 2, '567496026': 3, '5674960261': 2, '5674960264': 3, '5674960268': 3, '5674960272': 3, '5674960273': 2, '5674960274': 3, '5674960275': 3, '5674960276': 3, '5674960277': 3, '5674960278': 3, '5674960279': 3, '567496028': 2, '5674960281': 3, '5674960282': 3, '5674960283': 0, '567496029': 3, '5912920111': 2, '5912920112': 3, '5912920113': 3, '5912920114': 2, '5912920119': 3, '5912920121': 3, '5912920123': 3, '5912920124': 2, '5912920125': 2, '5912920126': 3, '5912920127': 3, '5912920128': 1, '5912920129': 2, '5912920131': 3, '5912920133': 2, '5912920135': 3, '5912920137': 3, '5912920140': 3, '5912920142': 3, '5912920143': 2, '5912920145': 2, '5912920146': 2, '5912920147': 3, '5912920148': 3, '5912920149': 2, '591292015': 3, '5912920151': 3, '5912920152': 3, '5912920154': 3, '5912920156': 3, '5912920158': 3, '5912920159': 3, '5912920160': 3, '5912920163': 2, '5912920167': 2, '5912920168': 3, '5912920169': 2, '5912920170': 3, '5912920171': 3, '5912920172': 3, '591292019': 3, '591292021': 3, '5912920211': 3, '5912920212': 3, '5912920213': 3, '5912920216': 3, '5912920217': 2, '5912920220': 2, '5912920222': 3, '5912920223': 2, '5912920225': 3, '5912920227': 3, '5912920228': 2, '5912920230': 3, '5912920231': 3, '5912920233': 3, '5912920234': 2, '5912920235': 3, '5912920236': 3, '5912920239': 2, '591292024': 3, '5912920240': 3, '5912920241': 3, '5912920242': 2, '5912920243': 2, '5912920244': 2, '5912920245': 3, '5912920249': 3, '5912920250': 3, '5912920256': 3, '5912920260': 3, '5912920263': 3, '5912920265': 3, '5912920266': 2, '5912920267': 3, '5912920268': 3, '5912920273': 3, '5912920274': 3, '5912920275': 3, '5912920276': 3, '5912920277': 3, '5912920279': 3, '5912920280': 3, '769862011': 3, '7698620112': 3, '7698620113': 3, '7698620115': 3, '7698620116': 3, '7698620118': 2, '7698620120': 3, '7698620122': 3, '7698620123': 3, '7698620126': 3, '7698620129': 3, '7698620130': 2, '7698620131': 2, '7698620132': 3, '7698620133': 3, '7698620134': 3, '7698620136': 2, '7698620138': 3, '7698620139': 3, '769862014': 3, '7698620141': 3, '7698620144': 3, '7698620145': 2, '7698620149': 3, '769862015': 2, '7698620150': 3, '7698620151': 3, '7698620152': 3, '7698620153': 3, '7698620156': 2, '7698620158': 3, '769862016': 2, '7698620160': 3, '7698620161': 3, '7698620163': 3, '7698620165': 3, '7698620166': 2, '7698620167': 3, '7698620169': 3, '769862017': 1, '7698620170': 2, '7698620171': 3, '769862018': 3, '769862019': 3, '769862021': 3, '7698620211': 3, '7698620212': 3, '7698620217': 3, '7698620218': 3, '769862022': 3, '7698620221': 3, '7698620222': 3, '7698620224': 3, '7698620225': 2, '7698620227': 2, '7698620229': 2, '7698620230': 3, '7698620231': 3, '7698620233': 1, '7698620236': 2, '7698620238': 3, '7698620239': 3, '7698620240': 3, '7698620241': 2, '7698620244': 3, '7698620245': 3, '7698620248': 2, '7698620250': 3, '7698620252': 1, '7698620253': 2, '7698620255': 2, '7698620256': 3, '7698620257': 3, '7698620258': 3, '7698620260': 2, '7698620261': 3, '7698620262': 2, '7698620264': 2, '7698620265': 3, '7698620267': 3, '7698620268': 3, '769862027': 3, '7698620270': 3, '7698620272': 3, '7698620274': 3, '7698620275': 3, '7698620278': 2, '769862028': 3, '7698620281': 3, '7698620283': 3, '7994020110': 3, '79940201100': 2, '79940201110': 3, '79940201140': 3, '79940201150': 3, '79940201160': 3, '79940201180': 3, '79940201210': 3, '79940201230': 3, '79940201250': 3, '79940201270': 2, '7994020130': 2, '79940201300': 1, '79940201320': 3, '79940201330': 3, '79940201340': 3, '79940201350': 3, '79940201360': 3, '79940201370': 2, '79940201380': 3, '79940201390': 1, '7994020140': 2, '79940201410': 3, '79940201420': 3, '79940201430': 3, '79940201470': 3, '79940201490': 3, '79940201510': 2, '79940201560': 2, '79940201570': 3, '79940201580': 2, '7994020160': 3, '79940201620': 3, '79940201650': 2, '79940201660': 1, '79940201690': 3, '79940201700': 2, '79940201710': 3, '79940201720': 3, '79940201730': 2, '79940201740': 3, '79940201750': 2, '79940201760': 3, '79940201770': 3, '79940201780': 3, '79940201790': 1, '79940201810': 3, '79940201820': 3, '79940201850': 2, '79940201860': 3, '79940201880': 3, '79940201930': 2, '79940201950': 3, '79940202100': 3, '79940202120': 3, '79940202130': 2, '79940202140': 2, '79940202160': 3, '79940202170': 2, '79940202180': 2, '79940202190': 2, '79940202200': 3, '79940202210': 2, '79940202220': 2, '79940202230': 3, '79940202270': 1, '79940202280': 1, '7994020230': 1, '79940202300': 2, '79940202310': 1, '79940202320': 3, '79940202340': 2, '79940202350': 2, '79940202370': 3, '79940202390': 2, '79940202400': 2, '79940202410': 2, '79940202450': 2, '79940202470': 2, '79940202480': 2, '79940202490': 1, '7994020250': 3, '79940202510': 2, '79940202520': 3, '79940202540': 3, '79940202560': 3, '79940202570': 3, '79940202580': 2, '79940202620': 3, '79940202690': 3, '7994020270': 3, '79940202700': 3, '79940202710': 2, '79940202750': 2, '79940202760': 3, '79940202790': 3, '7994020280': 2, '79940202800': 1, '79940202820': 2, '79940202840': 1, '79940202850': 1, '79940202860': 1, '79940202870': 2, '79940202890': 3, '7994020290': 3, '8263820112': 3, '8263820113': 2, '8263820120': 2, '8263820123': 2, '8263820124': 2, '8263820126': 3, '8263820132': 3, '8263820135': 2, '8263820136': 3, '8263820138': 2, '8263820139': 2, '8263820140': 2, '8263820141': 2, '8263820144': 3, '8263820145': 2, '8263820146': 2, '8263820147': 3, '8263820148': 3, '826382015': 2, '8263820150': 3, '8263820151': 3, '8263820152': 2, '8263820155': 2, '8263820156': 2, '8263820159': 3, '826382016': 3, '8263820160': 3, '8263820162': 3, '8263820165': 3, '8263820169': 2, '8263820170': 3, '826382018': 3, '826382021': 2, '8263820210': 2, '8263820211': 3, '8263820212': 3, '8263820213': 2, '8263820214': 3, '8263820221': 3, '8263820223': 2, '8263820224': 2, '8263820227': 2, '8263820228': 2, '826382023': 3, '8263820231': 3, '8263820233': 3, '8263820234': 3, '8263820235': 3, '8263820237': 3, '8263820239': 3, '826382024': 1, '8263820240': 3, '8263820242': 2, '8263820243': 3, '8263820245': 2, '8263820246': 3, '8263820247': 2, '8263820251': 3, '8263820253': 2, '8263820254': 3, '8263820255': 2, '8263820256': 2, '8263820257': 2, '8263820259': 3, '826382026': 3, '8263820260': 2, '8263820264': 3, '8263820265': 2, '8263820266': 2, '8263820268': 3, '8263820269': 2, '826382027': 2, '8263820272': 3, '8263820273': 3, '8263820275': 2, '8263820277': 2, '8263820278': 2, '8263820279': 3, '826382028': 2, '826412010': 3, '8264120110': 2, '8264120111': 2, '8264120112': 2, '8264120113': 3, '8264120116': 1, '8264120117': 3, '8264120119': 3, '8264120120': 1, '8264120121': 2, '8264120122': 2, '8264120123': 1, '8264120124': 2, '8264120125': 2, '8264120126': 2, '8264120127': 1, '826412013': 1, '8264120131': 2, '8264120132': 2, '8264120136': 2, '8264120139': 3, '8264120141': 2, '8264120144': 3, '8264120145': 3, '8264120146': 3, '8264120149': 2, '8264120150': 1, '8264120156': 1, '8264120157': 2, '8264120159': 2, '8264120165': 3, '8264120166': 3, '8264120169': 1, '826412017': 2, '826412018': 2, '826412019': 2, '8264120210': 2, '8264120211': 1, '8264120213': 3, '8264120215': 3, '8264120216': 3, '8264120218': 3, '8264120219': 3, '8264120220': 2, '8264120221': 3, '8264120223': 2, '8264120224': 3, '8264120227': 3, '8264120228': 3, '8264120229': 2, '826412023': 3, '8264120231': 1, '8264120232': 2, '8264120233': 3, '8264120234': 2, '8264120239': 1, '826412024': 3, '8264120240': 0, '8264120241': 2, '8264120242': 2, '8264120243': 1, '8264120245': 2, '8264120247': 3, '8264120248': 2, '8264120249': 1, '826412025': 2, '8264120254': 1, '8264120256': 1, '8264120257': 3, '8264120258': 2, '8264120261': 1, '8264120262': 1, '8264120263': 1, '8264120265': 1, '8264120266': 1, '8264120268': 3, '8264120269': 1, '826412027': 2, '8264120274': 3, '8264120275': 3, '8264120279': 1, '8264120280': 2, '8264120282': 1, '8264120284': 1, '88265401100': 3, '88265401130': 3, '88265401140': 3, '88265401150': 3, '88265401160': 3, '88265401170': 2, '88265401190': 3, '8826540120': 3, '88265401200': 2, '88265401240': 3, '88265401260': 3, '88265401270': 3, '88265401280': 3, '88265401300': 3, '88265401320': 3, '88265401350': 3, '88265401360': 3, '88265401380': 3, '88265401390': 3, '88265401400': 3, '88265401410': 3, '88265401420': 2, '88265401430': 3, '88265401450': 3, '88265401470': 2, '88265401480': 3, '88265401490': 3, '8826540150': 3, '88265401520': 3, '88265401550': 3, '88265401630': 2, '88265401640': 2, '88265401660': 3, '88265401690': 3, '8826540170': 3, '88265401730': 3, '88265401740': 3, '88265401750': 1, '8826540180': 3, '88265402120': 3, '88265402150': 3, '88265402160': 2, '88265402170': 3, '88265402180': 2, '88265402190': 3, '88265402200': 3, '88265402230': 2, '88265402240': 2, '88265402270': 2, '8826540230': 3, '88265402300': 3, '88265402310': 3, '88265402320': 2, '88265402330': 3, '88265402340': 2, '88265402350': 3, '88265402370': 3, '88265402380': 3, '8826540240': 3, '88265402400': 2, '88265402420': 3, '88265402440': 2, '88265402450': 3, '88265402480': 2, '88265402490': 3, '88265402500': 3, '88265402520': 3, '88265402540': 2, '88265402570': 2, '88265402580': 3, '88265402590': 3, '8826540260': 2, '88265402600': 2, '88265402630': 3, '88265402660': 3, '88265402690': 3, '8826540270': 3, '88265402700': 3, '88265402770': 3, '88265402780': 3, '88265402790': 2, '8826540280': 2, '88265402800': 3, '88265402810': 3, '88265402820': 3, '88265402840': 3, '88265402850': 3, '88265402880': 2, '88265402890': 3, '8826540290': 3, '88265402900': 3, '907001100': 3, '9070011010': 2, '9070011020': 3, '9070011060': 3, '9070011090': 2, '907001110': 3, '9070011110': 3, '907001120': 2, '907001150': 3, '907001160': 2, '907001170': 3, '907001180': 3, '907001210': 3, '907001220': 3, '907001240': 3, '907001270': 2, '907001280': 3, '907001310': 3, '907001340': 3, '907001350': 3, '907001360': 3, '907001370': 3, '907001400': 3, '907001430': 2, '907001450': 3, '907001480': 1, '907001490': 3, '90700150': 3, '907001500': 3, '907001520': 3, '907001550': 3, '907001560': 2, '907001570': 3, '907001580': 3, '90700160': 3, '907001600': 3, '907001620': 3, '907001650': 2, '907001670': 3, '907001680': 3, '90700170': 3, '907001730': 3, '907001740': 2, '907001780': 3, '907001790': 3, '90700180': 3, '907001820': 3, '907001840': 3, '907001850': 3, '907001860': 3, '90700190': 3, '907001910': 2, '907001940': 3, '907001950': 1, '907001970': 3, '9289010111': 2, '9289010112': 2, '9289010113': 2, '9289010114': 1, '9289010115': 3, '9289010117': 3, '9289010118': 3, '9289010119': 3, '9289010120': 2, '9289010121': 2, '9289010127': 2, '928901013': 3, '9289010131': 2, '9289010132': 2, '9289010133': 3, '9289010134': 3, '9289010138': 2, '9289010139': 2, '928901014': 1, '9289010143': 2, '9289010144': 2, '9289010145': 1, '9289010147': 2, '9289010149': 3, '9289010150': 3, '9289010151': 3, '9289010152': 1, '9289010153': 2, '9289010154': 2, '9289010155': 3, '9289010157': 3, '9289010158': 3, '928901016': 2, '9289010160': 3, '9289010161': 2, '9289010163': 3, '9289010166': 2, '9289010167': 3, '928901018': 3, '9289010210': 3, '9289010211': 2, '9289010216': 3, '9289010221': 3, '9289010222': 3, '9289010223': 3, '9289010227': 3, '9289010229': 3, '928901023': 3, '9289010230': 3, '9289010231': 2, '9289010232': 3, '9289010233': 3, '9289010235': 3, '9289010242': 3, '9289010243': 3, '9289010244': 3, '9289010245': 3, '9289010248': 3, '9289010249': 3, '928901025': 3, '9289010250': 2, '9289010251': 3, '9289010253': 3, '9289010254': 2, '9289010257': 3, '9289010259': 3, '928901026': 3, '9289010261': 3, '9289010262': 3, '9289010263': 2, '9289010265': 3, '9289010266': 3, '9289010267': 3, '9289010268': 3, '9289010269': 3, '9289010270': 3, '9289010271': 2, '9289010273': 3, '9289010274': 3, '9289010275': 3, '9289010276': 1, '9289010278': 3, '928901028': 3, '928901029': 3, '940328011': 3, '9403280110': 3, '9403280112': 3, '9403280114': 3, '9403280115': 2, '9403280116': 3, '9403280117': 3, '940328012': 3, '9403280126': 3, '9403280129': 3, '9403280132': 3, '9403280134': 2, '9403280136': 3, '9403280138': 2, '940328014': 3, '9403280140': 2, '9403280143': 2, '9403280145': 2, '9403280146': 2, '9403280147': 3, '9403280149': 3, '9403280150': 3, '9403280151': 2, '9403280152': 2, '9403280155': 3, '9403280156': 3, '9403280157': 2, '9403280159': 3, '940328016': 3, '9403280164': 3, '9403280165': 2, '9403280167': 3, '940328017': 3, '940328018': 3, '9403280212': 3, '9403280213': 2, '9403280217': 2, '9403280218': 2, '9403280219': 2, '940328022': 3, '9403280227': 2, '9403280229': 3, '9403280234': 3, '9403280235': 2, '9403280236': 2, '9403280238': 2, '9403280241': 3, '9403280243': 3, '9403280245': 3, '9403280246': 3, '9403280247': 2, '9403280249': 3, '9403280250': 2, '9403280251': 2, '9403280254': 3, '9403280255': 3, '9403280256': 3, '9403280259': 3, '9403280260': 3, '9403280262': 3, '9403280265': 3, '9403280266': 3, '9403280271': 1, '9403280272': 3, '9403280273': 2, '9403280277': 3, '9403280279': 3, '9877360111': 3, '9877360113': 2, '9877360114': 3, '9877360115': 3, '9877360116': 2, '9877360117': 2, '9877360120': 1, '9877360121': 2, '9877360124': 3, '9877360125': 3, '9877360126': 3, '9877360127': 2, '9877360128': 3, '9877360130': 2, '9877360131': 3, '9877360132': 2, '9877360133': 0, '9877360134': 3, '9877360135': 2, '9877360138': 2, '987736014': 3, '9877360140': 3, '9877360141': 3, '9877360143': 3, '9877360147': 3, '9877360149': 3, '987736015': 2, '9877360151': 3, '9877360152': 3, '9877360154': 2, '9877360156': 3, '9877360157': 1, '9877360158': 3, '9877360159': 3, '987736016': 3, '9877360163': 2, '9877360164': 3, '9877360165': 3, '9877360166': 3, '9877360168': 3, '9877360169': 1}\n"
     ]
    }
   ],
   "source": [
    "ENGAGE_WILD_DATASET, BIN_CLASSIFICATION, N_CLASSES, DATASET_NAME, BASE_DATASET_DIR, ext = define_dataset(False, False)\n",
    "video2label, labels_list = get_video2label()\n",
    "print(labels_list)\n",
    "print(video2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ccd708-d304-40a1-8b47-2d4094a798c0",
   "metadata": {},
   "source": [
    "### Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92034688-5c7e-4798-bf28-fee79a30908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.std\n",
    "stat_name = \"std\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a817f14-3441-41b8-b8c4-5ca679e9a9b7",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef84d332-6baa-46e8-b75b-f956cc666cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ab7055d-93a3-482c-b2f6-aebf5577a70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96288b48-4ee1-4575-b42e-ebf2fee7670e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 34/5482: 0.6202116016052536%\n",
      "1 214/5482: 3.903684786574243%\n",
      "2 2649/5482: 48.32178037212696%\n",
      "3 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0 4/1723: 0.2321532211259431%\n",
      "1 81/1723: 4.7011027278003485%\n",
      "2 861/1723: 49.97098084735926%\n",
      "3 777/1723: 45.095763203714455%\n",
      "val:\n",
      "0 23/1720: 1.3372093023255813%\n",
      "1 160/1720: 9.30232558139535%\n",
      "2 912/1720: 53.02325581395349%\n",
      "3 625/1720: 36.33720930232558%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d589b4-8321-4e06-887d-191f0551ed7a",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bf77f8a-0d5f-4a6b-a9b6-26b8c63b3d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_std_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3821728d-913f-486f-b958-b5af23d8523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d18c313-f89b-4469-9dc1-764c58545099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01e5ae4a-9b74-4d1c-a7be-ef5e77a43070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  34  214 2649 2585] {0: 77.91176470588235, 1: 12.378504672897195, 2: 1.0, 3: 1.0247582205029013} 4 [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7066054a-f186-4d25-9ba4-3a9d0e95afe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-10 08:55:02.459487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 4)                    2052      ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1315845 (5.02 MB)\n",
      "Trainable params: 1315845 (5.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "save_best_model = SaveBestModelByUAR(X_subsample_val, y_subsample_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43e73374-bd60-4a45-928b-d4480d3d6473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-10 08:55:10.725784: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa3ec9b8800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-10 08:55:10.725946: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-08-10 08:55:10.730412: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-10 08:55:10.760558: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-08-10 08:55:10.814611: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 7s 135ms/step - loss: 2.5561 - val_loss: 1.3405 - val_uar: 0.3606 - val_bacc: 0.3606 - val_f1: 0.3360 - val_mcc: 0.1279\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 2.2692 - val_loss: 1.2353 - val_uar: 0.3522 - val_bacc: 0.3522 - val_f1: 0.3267 - val_mcc: 0.1383\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 82ms/step - loss: 2.1245 - val_loss: 1.3937 - val_uar: 0.3901 - val_bacc: 0.3901 - val_f1: 0.2988 - val_mcc: 0.1048\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 0s 8ms/step\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 1.9588 - val_loss: 1.2686 - val_uar: 0.3653 - val_bacc: 0.3653 - val_f1: 0.3320 - val_mcc: 0.1072\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 76ms/step - loss: 1.8101 - val_loss: 1.1521 - val_uar: 0.3425 - val_bacc: 0.3425 - val_f1: 0.3913 - val_mcc: 0.1114\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 76ms/step - loss: 1.8585 - val_loss: 1.1547 - val_uar: 0.3283 - val_bacc: 0.3283 - val_f1: 0.3634 - val_mcc: 0.1034\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 1.7285 - val_loss: 1.0589 - val_uar: 0.3171 - val_bacc: 0.3171 - val_f1: 0.4459 - val_mcc: 0.1053\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 1.7111 - val_loss: 1.1083 - val_uar: 0.3391 - val_bacc: 0.3391 - val_f1: 0.4198 - val_mcc: 0.0961\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 1.6023 - val_loss: 1.2264 - val_uar: 0.3355 - val_bacc: 0.3355 - val_f1: 0.3436 - val_mcc: 0.1217\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 1.5370 - val_loss: 1.2589 - val_uar: 0.3376 - val_bacc: 0.3376 - val_f1: 0.3349 - val_mcc: 0.0851\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 76ms/step - loss: 1.5534 - val_loss: 1.2059 - val_uar: 0.3253 - val_bacc: 0.3253 - val_f1: 0.3285 - val_mcc: 0.1016\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 1.5143 - val_loss: 1.1838 - val_uar: 0.3187 - val_bacc: 0.3187 - val_f1: 0.3622 - val_mcc: 0.0918\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 1.5624 - val_loss: 1.3190 - val_uar: 0.3373 - val_bacc: 0.3373 - val_f1: 0.2930 - val_mcc: 0.1101\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 4s 98ms/step - loss: 1.4416 - val_loss: 1.1793 - val_uar: 0.3490 - val_bacc: 0.3490 - val_f1: 0.3587 - val_mcc: 0.0960\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 76ms/step - loss: 1.4075 - val_loss: 1.1511 - val_uar: 0.3300 - val_bacc: 0.3300 - val_f1: 0.3762 - val_mcc: 0.1240\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 1.4273 - val_loss: 1.1913 - val_uar: 0.3142 - val_bacc: 0.3142 - val_f1: 0.3483 - val_mcc: 0.1000\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 1.3836 - val_loss: 1.2039 - val_uar: 0.3171 - val_bacc: 0.3171 - val_f1: 0.3564 - val_mcc: 0.1048\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 1.4170 - val_loss: 1.2343 - val_uar: 0.3763 - val_bacc: 0.3763 - val_f1: 0.3779 - val_mcc: 0.1354\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 1.3889 - val_loss: 1.1780 - val_uar: 0.3255 - val_bacc: 0.3255 - val_f1: 0.3773 - val_mcc: 0.1214\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 1.3144 - val_loss: 1.1964 - val_uar: 0.3192 - val_bacc: 0.3192 - val_f1: 0.3686 - val_mcc: 0.1002\n",
      "0.3901005244088482\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03e74e3a-aa03-4d2e-84e3-3f1e088a1caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b85c9f44-02b3-47b6-861c-80e90f925e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 3 ... 3 0 3]\n",
      "[2 1 3 ... 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(pred)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11e84413-edb4-43b8-a26f-0bc36c0a7ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_single_attention_traditional Accuracy:  0.4567614625652931 MSE:  0.09904793964016248 UAR:  0.34427022841656985 Recall:  N/A Precision:  N/A F1:  0.2888563158896742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4567614625652931,\n",
       " 0.09904793964016248,\n",
       " 0.34427022841656985,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.2888563158896742)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b8ac7ce-ecb1-42f0-9aa7-086b4da3a058",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7810fdb7-93a7-4214-97d6-accb73551cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26467b11-7b70-41a4-8977-798a0e4c2e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_single_attention_traditional_best Accuracy:  0.375507835171213 MSE:  0.1615207196749855 UAR:  0.4206902169300544 Recall:  N/A Precision:  N/A F1:  0.2004876380940231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.375507835171213,\n",
       " 0.1615207196749855,\n",
       " 0.4206902169300544,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.2004876380940231)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b8d7a7-a421-4a5f-85de-6eb4f3f536d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e14626f-1b4f-4c2e-b73e-93e5a63f1f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "93590354-df00-4777-98bf-2961f3db973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True\n",
    "#IMAGE_SET_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf65658b-65e8-4a5d-ab34-51c5ab13e931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbb1b8d3-e357-4c2a-8254-1b3dd1a11bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 21:09:58.494035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b675b127-977e-4565-a048-fb9e022583ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 21:10:14.656351: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f86f8a32620 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-07 21:10:14.656520: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-08-07 21:10:14.660809: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-07 21:10:14.697393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-08-07 21:10:14.749217: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 8s 149ms/step - loss: 0.0813 - mae: 0.2003 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 5/20\n",
      "37/43 [========================>.....] - ETA: 0s - loss: 0.0797 - mae: 0.1962"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m     modelAtn\u001b[38;5;241m.\u001b[39mfit(train_generator,steps_per_epoch\u001b[38;5;241m=\u001b[39mnum_samples_train\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mBATCH_SIZE,\n\u001b[1;32m      3\u001b[0m                      epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[save_best_model],\n\u001b[1;32m      4\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39mtest_generator,validation_steps\u001b[38;5;241m=\u001b[39mnum_samples_test\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mBATCH_SIZE, class_weight\u001b[38;5;241m=\u001b[39mclass_weights)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mmodelAtn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_subsample_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_subsample_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msave_best_model\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m             \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_subsample_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_subsample_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, class_weight=class_weights)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m best_model_weights \u001b[38;5;241m=\u001b[39m save_best_model\u001b[38;5;241m.\u001b[39mbest_model_weights\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(save_best_model\u001b[38;5;241m.\u001b[39mbest)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if USE_GENERATORS:\n",
    "    modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                     epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                    validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "else:\n",
    "    modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "             validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "best_model_weights = save_best_model.best_model_weights\n",
    "print(save_best_model.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "235d4024-9f86-492e-8251-dc24dd9225d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 120ms/step - loss: 0.0812 - mae: 0.2005 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "0.11642508953809738\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "034fefa8-cdec-4aba-b868-933ef4adcb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "54a9a2d1-b5f4-4af7-9d5c-34cfe449db50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_traditional Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "debff917-a1bc-4103-9513-b795274ea828",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3e27e6a1-d45c-4ff7-9449-58911a392318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d4ae1a5-2cb9-49c6-b014-a222ec99e91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_traditional_best Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778ba15b-4f17-45a4-80d3-8b68e8c1388b",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c923ed91-caef-460e-a1aa-67319ae5282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42ba3ee3-7a1e-4d27-bf25-9bfb603f9ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a3b1405b-107f-473a-b4c0-ede100c676d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 34/5482: 0.6202116016052536%\n",
      "1 214/5482: 3.903684786574243%\n",
      "2 2649/5482: 48.32178037212696%\n",
      "3 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0 4/1723: 0.2321532211259431%\n",
      "1 81/1723: 4.7011027278003485%\n",
      "2 861/1723: 49.97098084735926%\n",
      "3 777/1723: 45.095763203714455%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67c80de3-2c85-4413-a0cf-824b17183133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482,) (5482,)\n",
      "(1723,) (1723,)\n",
      "(7205,) (7205,)\n",
      "[0 1 2 3] [  38  295 3510 3362]\n",
      "7205\n",
      "5474\n",
      "1731\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5eee050-fce2-4ba4-9ad5-2dc37d504680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 28/5474: 0.5115089514066496%\n",
      "1 224/5474: 4.092071611253197%\n",
      "2 2667/5474: 48.72122762148338%\n",
      "3 2555/5474: 46.67519181585678%\n",
      "test:\n",
      "0 10/1731: 0.5777007510109763%\n",
      "1 71/1731: 4.101675332177932%\n",
      "2 843/1731: 48.7001733102253%\n",
      "3 807/1731: 46.62045060658579%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad450dd6-3c9b-4dd2-98e1-5233da6f9646",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1dd93e6f-e5a4-403a-88be-cfa5ad8e974c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_std_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1dec7a40-0555-47a3-8a20-687bdb90d1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b24e8344-bdd2-44ee-93ac-d02e47b110ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 2560) (5474,)\n",
      "(1731, 128, 2560) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07608fc5-b168-450a-9b2c-0fcdba4161dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  28  224 2667 2555] {0: 95.24999999999999, 1: 11.906249999999998, 2: 1.0, 3: 1.0438356164383562} 4 [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "22223435-54ea-4175-b18c-52c1aae7b967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 4)                    2052      ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1315845 (5.02 MB)\n",
      "Trainable params: 1315845 (5.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "save_best_model = SaveBestModelByUAR(X_subsample_test, y_subsample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "175191c1-3964-44c8-b148-f774e2eca6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "55/55 [==============================] - 1s 9ms/step\n",
      "43/43 [==============================] - 5s 107ms/step - loss: 2.8604 - val_loss: 1.1903 - val_uar: 0.4301 - val_bacc: 0.4301 - val_f1: 0.4552 - val_mcc: 0.1641\n",
      "Epoch 2/20\n",
      "55/55 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 2.1280 - val_loss: 1.1279 - val_uar: 0.4507 - val_bacc: 0.4507 - val_f1: 0.4726 - val_mcc: 0.2066\n",
      "Epoch 3/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 75ms/step - loss: 2.0309 - val_loss: 1.1296 - val_uar: 0.4706 - val_bacc: 0.4706 - val_f1: 0.4477 - val_mcc: 0.2120\n",
      "Epoch 4/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 1.9098 - val_loss: 0.9823 - val_uar: 0.4863 - val_bacc: 0.4863 - val_f1: 0.5517 - val_mcc: 0.2566\n",
      "Epoch 5/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 1.9175 - val_loss: 1.1944 - val_uar: 0.4808 - val_bacc: 0.4808 - val_f1: 0.4304 - val_mcc: 0.1860\n",
      "Epoch 6/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 1.7380 - val_loss: 1.0721 - val_uar: 0.4593 - val_bacc: 0.4593 - val_f1: 0.4616 - val_mcc: 0.1959\n",
      "Epoch 7/20\n",
      "55/55 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 3s 75ms/step - loss: 1.7156 - val_loss: 0.9860 - val_uar: 0.5087 - val_bacc: 0.5087 - val_f1: 0.5286 - val_mcc: 0.2328\n",
      "Epoch 8/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 1.6362 - val_loss: 1.0317 - val_uar: 0.4862 - val_bacc: 0.4862 - val_f1: 0.5066 - val_mcc: 0.2276\n",
      "Epoch 9/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 76ms/step - loss: 1.6050 - val_loss: 0.9623 - val_uar: 0.5214 - val_bacc: 0.5214 - val_f1: 0.5280 - val_mcc: 0.2393\n",
      "Epoch 10/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 1.5887 - val_loss: 0.9427 - val_uar: 0.4843 - val_bacc: 0.4843 - val_f1: 0.5557 - val_mcc: 0.2627\n",
      "Epoch 11/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 1.5026 - val_loss: 0.9420 - val_uar: 0.4703 - val_bacc: 0.4703 - val_f1: 0.5465 - val_mcc: 0.2530\n",
      "Epoch 12/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 1.4918 - val_loss: 0.9479 - val_uar: 0.4865 - val_bacc: 0.4865 - val_f1: 0.5482 - val_mcc: 0.2557\n",
      "Epoch 13/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 1.4280 - val_loss: 1.0034 - val_uar: 0.5040 - val_bacc: 0.5040 - val_f1: 0.5188 - val_mcc: 0.2461\n",
      "Epoch 14/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 1.4795 - val_loss: 0.9537 - val_uar: 0.5181 - val_bacc: 0.5181 - val_f1: 0.5690 - val_mcc: 0.2691\n",
      "Epoch 15/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 1.4110 - val_loss: 0.8474 - val_uar: 0.4665 - val_bacc: 0.4665 - val_f1: 0.5997 - val_mcc: 0.2946\n",
      "Epoch 16/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 1.3369 - val_loss: 0.9899 - val_uar: 0.4841 - val_bacc: 0.4841 - val_f1: 0.5153 - val_mcc: 0.2358\n",
      "Epoch 17/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 1.3704 - val_loss: 0.9908 - val_uar: 0.5033 - val_bacc: 0.5033 - val_f1: 0.5113 - val_mcc: 0.2364\n",
      "Epoch 18/20\n",
      "55/55 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 1.2986 - val_loss: 0.9353 - val_uar: 0.4687 - val_bacc: 0.4687 - val_f1: 0.5667 - val_mcc: 0.2774\n",
      "Epoch 19/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 76ms/step - loss: 1.3483 - val_loss: 1.0204 - val_uar: 0.4840 - val_bacc: 0.4840 - val_f1: 0.5084 - val_mcc: 0.2508\n",
      "Epoch 20/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 74ms/step - loss: 1.2908 - val_loss: 0.9393 - val_uar: 0.4808 - val_bacc: 0.4808 - val_f1: 0.5482 - val_mcc: 0.2526\n",
      "0.5214227071318535\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "33a92363-a6d1-4e11-9440-1019b3c00d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0deafeb4-16f7-45f7-894a-2cc43419ddbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_single_attention_balanced Accuracy:  0.5459272097053726 MSE:  0.0820589832466782 UAR:  0.48608896318905737 Recall:  N/A Precision:  N/A F1:  0.3703024732283354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5459272097053726,\n",
       " 0.0820589832466782,\n",
       " 0.48608896318905737,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.3703024732283354)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "38a448e5-747f-411a-8b72-b73c53ad2173",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cbaa3ea3-352d-4139-ab49-2cec1d2362e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a53636c4-2733-499a-9a12-ef75d1fa386a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_single_attention_balanced_best Accuracy:  0.5262853841709995 MSE:  0.0799743500866551 UAR:  0.5205462568546967 Recall:  N/A Precision:  N/A F1:  0.37577872510979515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5262853841709995,\n",
       " 0.0799743500866551,\n",
       " 0.5205462568546967,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.37577872510979515)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd929ea3-6902-4ac5-aa52-17a446505804",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "57d8c6b3-298c-431d-83ba-480aba374299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d4effd30-ee3b-4feb-9467-9d22dc0f3ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a3b8932c-5f9f-4d6c-bc65-23fd8e8913e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 2560) (5474,)\n",
      "(1731, 128, 2560) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "01ada3ee-fccd-4e58-94af-aa1a36486559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ff1f78e3-c557-4133-8cb7-1aeab1723a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 125ms/step - loss: 0.0812 - mae: 0.2012 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "0.08048681914806366\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "17388a1e-fc3f-4c97-9d4b-664b14161873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dad43b85-0c67-48f1-a23e-abb66209c48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5945256c-398e-4218-b70c-5f6ed350d84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cce4646a-cd0b-4964-be28-b8c8dbf2ba4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7e018315-7fde-4a94-aecc-9be226b9d154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced_best Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f86c59f-3dd0-4f52-a6c1-93a65c892c95",
   "metadata": {},
   "source": [
    "### Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "90a40a74-d38f-4375-af1b-372f5e7d5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.max\n",
    "stat_name = \"max\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc025691-fdc7-4557-82b9-c75bc067317c",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe43bcfd-5bc3-4ff6-8ffe-2fed8d637480",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2bed4cab-7853-4a46-9cf1-1d3ffcef61bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "65c330b4-1d80-4a8f-9031-c78543dd6737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 34/5482: 0.6202116016052536%\n",
      "1 214/5482: 3.903684786574243%\n",
      "2 2649/5482: 48.32178037212696%\n",
      "3 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0 4/1723: 0.2321532211259431%\n",
      "1 81/1723: 4.7011027278003485%\n",
      "2 861/1723: 49.97098084735926%\n",
      "3 777/1723: 45.095763203714455%\n",
      "val:\n",
      "0 23/1720: 1.3372093023255813%\n",
      "1 160/1720: 9.30232558139535%\n",
      "2 912/1720: 53.02325581395349%\n",
      "3 625/1720: 36.33720930232558%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc79f56-52fe-4f4f-bad4-a6166342605f",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77ca484c-afc1-4141-a4d8-2522d975594b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_max_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a17cade5-1f99-4a76-bcb1-d2e1ee0cc3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "35106e10-c76a-4501-8124-370f722d174b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d923d925-b684-4b10-9b54-ac8dbddf9c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  34  214 2649 2585] {0: 77.91176470588235, 1: 12.378504672897195, 2: 1.0, 3: 1.0247582205029013} 4 [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fd9b9d07-75d1-45d3-9a4c-8602a9c24882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 4)                    2052      ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1315845 (5.02 MB)\n",
      "Trainable params: 1315845 (5.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "save_best_model = SaveBestModelByUAR(X_subsample_val, y_subsample_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9f0daba5-268b-472d-9d87-c444b658a6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 5s 101ms/step - loss: 2.8206 - val_loss: 1.3666 - val_uar: 0.3398 - val_bacc: 0.3398 - val_f1: 0.3017 - val_mcc: 0.0761\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 2.1727 - val_loss: 1.1116 - val_uar: 0.3239 - val_bacc: 0.3239 - val_f1: 0.3901 - val_mcc: 0.1237\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 2s 58ms/step - loss: 2.1942 - val_loss: 1.1891 - val_uar: 0.2761 - val_bacc: 0.2761 - val_f1: 0.3953 - val_mcc: 0.1055\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 1.9493 - val_loss: 1.2498 - val_uar: 0.3123 - val_bacc: 0.3123 - val_f1: 0.3419 - val_mcc: 0.1023\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 2s 58ms/step - loss: 1.7473 - val_loss: 1.2055 - val_uar: 0.3477 - val_bacc: 0.3477 - val_f1: 0.3779 - val_mcc: 0.1319\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 2s 58ms/step - loss: 1.7498 - val_loss: 1.1955 - val_uar: 0.3337 - val_bacc: 0.3337 - val_f1: 0.3663 - val_mcc: 0.1401\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 1.6926 - val_loss: 1.1173 - val_uar: 0.3330 - val_bacc: 0.3330 - val_f1: 0.3994 - val_mcc: 0.1441\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 2s 58ms/step - loss: 1.6325 - val_loss: 1.0700 - val_uar: 0.3275 - val_bacc: 0.3275 - val_f1: 0.4593 - val_mcc: 0.1354\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 2s 58ms/step - loss: 1.6030 - val_loss: 1.2875 - val_uar: 0.4125 - val_bacc: 0.4125 - val_f1: 0.3535 - val_mcc: 0.1375\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 1.5699 - val_loss: 1.0808 - val_uar: 0.3327 - val_bacc: 0.3327 - val_f1: 0.4419 - val_mcc: 0.1129\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 1.5138 - val_loss: 1.1125 - val_uar: 0.3465 - val_bacc: 0.3465 - val_f1: 0.4215 - val_mcc: 0.1496\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 1.5036 - val_loss: 1.1425 - val_uar: 0.3372 - val_bacc: 0.3372 - val_f1: 0.4233 - val_mcc: 0.1612\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 2s 58ms/step - loss: 1.4422 - val_loss: 1.1063 - val_uar: 0.3407 - val_bacc: 0.3407 - val_f1: 0.4273 - val_mcc: 0.1281\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 2s 58ms/step - loss: 1.3941 - val_loss: 1.3187 - val_uar: 0.3150 - val_bacc: 0.3150 - val_f1: 0.3634 - val_mcc: 0.0892\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 2s 58ms/step - loss: 1.3441 - val_loss: 1.1267 - val_uar: 0.3288 - val_bacc: 0.3288 - val_f1: 0.4279 - val_mcc: 0.1240\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 1.3031 - val_loss: 1.0879 - val_uar: 0.3244 - val_bacc: 0.3244 - val_f1: 0.4535 - val_mcc: 0.1181\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 2s 59ms/step - loss: 1.3043 - val_loss: 1.1198 - val_uar: 0.2988 - val_bacc: 0.2988 - val_f1: 0.4285 - val_mcc: 0.1260\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 2s 58ms/step - loss: 1.2838 - val_loss: 1.0906 - val_uar: 0.2929 - val_bacc: 0.2929 - val_f1: 0.4535 - val_mcc: 0.1204\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 1.2697 - val_loss: 1.0890 - val_uar: 0.3051 - val_bacc: 0.3051 - val_f1: 0.4785 - val_mcc: 0.1082\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 1.2932 - val_loss: 1.1245 - val_uar: 0.3161 - val_bacc: 0.3161 - val_f1: 0.4622 - val_mcc: 0.1346\n",
      "0.4124623188405797\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d426d345-ae9b-4c30-8fdb-44b2383e9b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b3aa8467-f3bf-4c6f-9a5c-25485dc5d8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 3 ... 3 1 3]\n",
      "[2 1 3 ... 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(pred)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d04a2274-0e87-49f4-8ce7-711ca1475e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_max_single_attention_traditional Accuracy:  0.5089959373186302 MSE:  0.07671346488682529 UAR:  0.3447078757038107 Recall:  N/A Precision:  N/A F1:  0.28946179418657036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5089959373186302,\n",
       " 0.07671346488682529,\n",
       " 0.3447078757038107,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.28946179418657036)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ae9eed13-ca1e-415e-a0fd-957a3158167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3725a390-c2d4-40e6-93da-34ad04a3316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "65b78110-252d-4660-812a-daaba03996ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_max_single_attention_traditional_best Accuracy:  0.4265815438189205 MSE:  0.1339059199071387 UAR:  0.40709364997982883 Recall:  N/A Precision:  N/A F1:  0.2672821730663535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4265815438189205,\n",
       " 0.1339059199071387,\n",
       " 0.40709364997982883,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.2672821730663535)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed96e25b-6812-416f-b895-1aa74901c778",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e61b15b-30cc-4dcf-8766-b0467b98f9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e8b0674-efc6-429e-9f38-8d306799b32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True\n",
    "#IMAGE_SET_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "567f6df8-2fde-404d-af18-d7821aab763c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d537d69-83c5-4be3-a834-d7ff2ad250b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 21:09:58.494035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "831543dc-4e98-4a7f-8212-87e2f0f15db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 21:10:14.656351: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f86f8a32620 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-07 21:10:14.656520: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-08-07 21:10:14.660809: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-07 21:10:14.697393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-08-07 21:10:14.749217: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 8s 149ms/step - loss: 0.0813 - mae: 0.2003 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 5/20\n",
      "37/43 [========================>.....] - ETA: 0s - loss: 0.0797 - mae: 0.1962"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m     modelAtn\u001b[38;5;241m.\u001b[39mfit(train_generator,steps_per_epoch\u001b[38;5;241m=\u001b[39mnum_samples_train\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mBATCH_SIZE,\n\u001b[1;32m      3\u001b[0m                      epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[save_best_model],\n\u001b[1;32m      4\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39mtest_generator,validation_steps\u001b[38;5;241m=\u001b[39mnum_samples_test\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mBATCH_SIZE, class_weight\u001b[38;5;241m=\u001b[39mclass_weights)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mmodelAtn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_subsample_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_subsample_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msave_best_model\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m             \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_subsample_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_subsample_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, class_weight=class_weights)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m best_model_weights \u001b[38;5;241m=\u001b[39m save_best_model\u001b[38;5;241m.\u001b[39mbest_model_weights\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(save_best_model\u001b[38;5;241m.\u001b[39mbest)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if USE_GENERATORS:\n",
    "    modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                     epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                    validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "else:\n",
    "    modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "             validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "best_model_weights = save_best_model.best_model_weights\n",
    "print(save_best_model.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fceb74c2-6cc7-4d6a-b82f-5a663358d37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 120ms/step - loss: 0.0812 - mae: 0.2005 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "0.11642508953809738\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2bfab839-0880-414a-8600-ed25e6ae9596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d3b1865-e2a0-48be-b91b-cd8930666dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_traditional Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f956d2e0-a9a0-4a36-a556-369fd68471a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "018f43e9-f987-4d90-b445-89e3d72b3bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "348ded3c-b100-40b6-b343-c7fdd488a093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_traditional_best Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1eb6a59-edc0-472b-ad94-488d19c91ebb",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c03acede-886e-4d79-91bf-33511a88dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "06c018f2-8f10-4b3f-9129-9cee2c614a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "589748bc-f2ee-4b54-907f-4fd69b75025c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 34/5482: 0.6202116016052536%\n",
      "1 214/5482: 3.903684786574243%\n",
      "2 2649/5482: 48.32178037212696%\n",
      "3 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0 4/1723: 0.2321532211259431%\n",
      "1 81/1723: 4.7011027278003485%\n",
      "2 861/1723: 49.97098084735926%\n",
      "3 777/1723: 45.095763203714455%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "134004fe-ee68-4a75-aa90-f27cf4d04645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482,) (5482,)\n",
      "(1723,) (1723,)\n",
      "(7205,) (7205,)\n",
      "[0 1 2 3] [  38  295 3510 3362]\n",
      "7205\n",
      "5474\n",
      "1731\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0b67f60d-addc-4671-8b60-322d4e317b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 28/5474: 0.5115089514066496%\n",
      "1 224/5474: 4.092071611253197%\n",
      "2 2667/5474: 48.72122762148338%\n",
      "3 2555/5474: 46.67519181585678%\n",
      "test:\n",
      "0 10/1731: 0.5777007510109763%\n",
      "1 71/1731: 4.101675332177932%\n",
      "2 843/1731: 48.7001733102253%\n",
      "3 807/1731: 46.62045060658579%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3502ee-ff21-48b1-8070-79bfb3ef6699",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cb71da61-0ed2-4251-a2f7-c59aa9c29882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_max_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5037e233-68ec-4c4a-94d8-ebfa4794d820",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "95a86760-25e9-4ebf-979d-72609eb8a816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 2560) (5474,)\n",
      "(1731, 128, 2560) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7a432e7b-9a53-4c7e-8fa7-ec9955012d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  28  224 2667 2555] {0: 95.24999999999999, 1: 11.906249999999998, 2: 1.0, 3: 1.0438356164383562} 4 [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "49bea503-f0a1-4a60-9962-92af281f03e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 4)                    2052      ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1315845 (5.02 MB)\n",
      "Trainable params: 1315845 (5.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "save_best_model = SaveBestModelByUAR(X_subsample_test, y_subsample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b6ad6f90-0b10-4b8c-b869-5f02793fcfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "55/55 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 5s 103ms/step - loss: 2.9690 - val_loss: 1.1538 - val_uar: 0.4879 - val_bacc: 0.4879 - val_f1: 0.5014 - val_mcc: 0.2059\n",
      "Epoch 2/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 2.1228 - val_loss: 1.1295 - val_uar: 0.4565 - val_bacc: 0.4565 - val_f1: 0.4645 - val_mcc: 0.2017\n",
      "Epoch 3/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 2.0177 - val_loss: 1.1079 - val_uar: 0.4449 - val_bacc: 0.4449 - val_f1: 0.4835 - val_mcc: 0.2197\n",
      "Epoch 4/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 1.8869 - val_loss: 1.1620 - val_uar: 0.4830 - val_bacc: 0.4830 - val_f1: 0.4321 - val_mcc: 0.1871\n",
      "Epoch 5/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 1.7714 - val_loss: 1.0371 - val_uar: 0.4639 - val_bacc: 0.4639 - val_f1: 0.5228 - val_mcc: 0.2363\n",
      "Epoch 6/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 1.6597 - val_loss: 1.1303 - val_uar: 0.4729 - val_bacc: 0.4729 - val_f1: 0.4570 - val_mcc: 0.1967\n",
      "Epoch 7/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 1.5750 - val_loss: 1.1146 - val_uar: 0.4937 - val_bacc: 0.4937 - val_f1: 0.4425 - val_mcc: 0.1986\n",
      "Epoch 8/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 1.6523 - val_loss: 0.9816 - val_uar: 0.4676 - val_bacc: 0.4676 - val_f1: 0.5407 - val_mcc: 0.2575\n",
      "Epoch 9/20\n",
      "55/55 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 1.5805 - val_loss: 1.3048 - val_uar: 0.4894 - val_bacc: 0.4894 - val_f1: 0.3957 - val_mcc: 0.1884\n",
      "Epoch 10/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 71ms/step - loss: 1.4852 - val_loss: 0.9774 - val_uar: 0.4982 - val_bacc: 0.4982 - val_f1: 0.5274 - val_mcc: 0.2390\n",
      "Epoch 11/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 1.4683 - val_loss: 0.9586 - val_uar: 0.4903 - val_bacc: 0.4903 - val_f1: 0.5384 - val_mcc: 0.2486\n",
      "Epoch 12/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 75ms/step - loss: 1.4801 - val_loss: 1.1135 - val_uar: 0.5151 - val_bacc: 0.5151 - val_f1: 0.5136 - val_mcc: 0.2396\n",
      "Epoch 13/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 76ms/step - loss: 1.4548 - val_loss: 1.0006 - val_uar: 0.4951 - val_bacc: 0.4951 - val_f1: 0.5350 - val_mcc: 0.2542\n",
      "Epoch 14/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 1.3996 - val_loss: 1.0037 - val_uar: 0.5009 - val_bacc: 0.5009 - val_f1: 0.5263 - val_mcc: 0.2333\n",
      "Epoch 15/20\n",
      "55/55 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 3s 76ms/step - loss: 1.3331 - val_loss: 1.0357 - val_uar: 0.5199 - val_bacc: 0.5199 - val_f1: 0.5153 - val_mcc: 0.2484\n",
      "Epoch 16/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 1.2729 - val_loss: 0.9622 - val_uar: 0.5115 - val_bacc: 0.5115 - val_f1: 0.5656 - val_mcc: 0.2703\n",
      "Epoch 17/20\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 1.2554 - val_loss: 1.1300 - val_uar: 0.4949 - val_bacc: 0.4949 - val_f1: 0.4437 - val_mcc: 0.1998\n",
      "Epoch 18/20\n",
      "55/55 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 1.2224 - val_loss: 1.0795 - val_uar: 0.4651 - val_bacc: 0.4651 - val_f1: 0.4708 - val_mcc: 0.2138\n",
      "Epoch 19/20\n",
      "55/55 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 1.2309 - val_loss: 0.9479 - val_uar: 0.5180 - val_bacc: 0.5180 - val_f1: 0.5604 - val_mcc: 0.2673\n",
      "Epoch 20/20\n",
      "55/55 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 1.2121 - val_loss: 0.9256 - val_uar: 0.5125 - val_bacc: 0.5125 - val_f1: 0.5557 - val_mcc: 0.2555\n",
      "0.5198790552963808\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7861e2a0-ae10-4cb0-9417-b45b5f34383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d9acb0cc-1f82-400e-a31f-6f803b95e951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_max_single_attention_balanced Accuracy:  0.5522819179664934 MSE:  0.07418399768919698 UAR:  0.4860207197845378 Recall:  N/A Precision:  N/A F1:  0.3891380836798306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5522819179664934,\n",
       " 0.07418399768919698,\n",
       " 0.4860207197845378,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.3891380836798306)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3f34077a-e787-4621-b5ff-a4f052fa87ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cee7a7b0-891a-4cdb-b9c7-843dff1b3299",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9fe21d92-4631-48a7-9a67-34d0d0da42e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_max_single_attention_balanced_best Accuracy:  0.514153668399769 MSE:  0.09369428076256497 UAR:  0.5192991649243248 Recall:  N/A Precision:  N/A F1:  0.36274105669822676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.514153668399769,\n",
       " 0.09369428076256497,\n",
       " 0.5192991649243248,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.36274105669822676)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc92620-fc2f-47aa-9be5-461345475b4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7aa22caa-f45d-4782-960d-6686bdcdbe4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "80595802-092e-4868-a7bb-dd70d509b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "74452d60-42d1-4a20-9ebc-2026c9c79120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 2560) (5474,)\n",
      "(1731, 128, 2560) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e444e055-219f-43bb-b055-a9e83a9c6a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "21030356-3e77-4f6d-b5a4-954a1180f642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 125ms/step - loss: 0.0812 - mae: 0.2012 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "0.08048681914806366\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "40ecfcef-31d4-4f76-a533-88b2fae07584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2632e7f3-2a07-4aca-b0fa-db4c385f7999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2e0a91cc-1d81-4d8b-a637-69ac94129639",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a736502e-4221-4d57-b302-874df122ea0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "823015df-f26e-4999-9f95-ff95d8234c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced_best Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d29a7f-6df3-49ea-8d3a-e26345f0e584",
   "metadata": {},
   "source": [
    "### STAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ec5db598-4a55-4c87-be61-cc68b9f85fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = compute_descriptor\n",
    "stat_name = \"STAT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041da77d-a5cb-4328-875f-8a3d540e521e",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90e3e14f-e585-43b9-bdcc-f4171e70ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f25453ae-7068-4177-9119-fe457e61c689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84d86eeb-1f1a-4fad-90a7-0d0c640a8840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 34/5482: 0.6202116016052536%\n",
      "1 214/5482: 3.903684786574243%\n",
      "2 2649/5482: 48.32178037212696%\n",
      "3 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0 4/1723: 0.2321532211259431%\n",
      "1 81/1723: 4.7011027278003485%\n",
      "2 861/1723: 49.97098084735926%\n",
      "3 777/1723: 45.095763203714455%\n",
      "val:\n",
      "0 23/1720: 1.3372093023255813%\n",
      "1 160/1720: 9.30232558139535%\n",
      "2 912/1720: 53.02325581395349%\n",
      "3 625/1720: 36.33720930232558%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fd3910-0e62-4614-9bfd-4f9310547b1e",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38cefe60-1afd-4544-b794-eaa6a1d09f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_STAT_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0263cda4-f4a2-4651-9a42-0feaddcf8c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df4078e6-ba02-4c85-a3bc-ca9a931039d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 3840) (5482,)\n",
      "(1723, 128, 3840) (1723,)\n",
      "(1720, 128, 3840) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "650b5c15-520e-420a-8f2b-04e9d375045b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  34  214 2649 2585] {0: 77.91176470588235, 1: 12.378504672897195, 2: 1.0, 3: 1.0247582205029013} 4 [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa19e168-3ac2-49a5-af53-2e2cc817484f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-10 09:14:07.086533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1966592   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 4)                    2052      ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1972485 (7.52 MB)\n",
      "Trainable params: 1972485 (7.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "save_best_model = SaveBestModelByUAR(X_subsample_val, y_subsample_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8c14140-08ba-46bb-a870-ab4f6bac2e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-10 09:14:18.892667: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc8001f51b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-10 09:14:18.892831: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-08-10 09:14:18.897138: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-10 09:14:18.931061: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-08-10 09:14:18.984733: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 1s 8ms/step\n",
      "43/43 [==============================] - 11s 214ms/step - loss: 2.7601 - val_loss: 1.4051 - val_uar: 0.3376 - val_bacc: 0.3376 - val_f1: 0.2558 - val_mcc: 0.1220\n",
      "Epoch 2/11\n",
      "54/54 [==============================] - 0s 8ms/step\n",
      "43/43 [==============================] - 5s 127ms/step - loss: 2.1591 - val_loss: 1.2207 - val_uar: 0.3482 - val_bacc: 0.3482 - val_f1: 0.3727 - val_mcc: 0.1417\n",
      "Epoch 3/11\n",
      "54/54 [==============================] - 0s 8ms/step\n",
      "43/43 [==============================] - 6s 132ms/step - loss: 2.0772 - val_loss: 1.3887 - val_uar: 0.3360 - val_bacc: 0.3360 - val_f1: 0.2936 - val_mcc: 0.1190\n",
      "Epoch 4/11\n",
      "54/54 [==============================] - 1s 11ms/step\n",
      "43/43 [==============================] - 6s 131ms/step - loss: 1.9000 - val_loss: 1.3405 - val_uar: 0.3756 - val_bacc: 0.3756 - val_f1: 0.3157 - val_mcc: 0.1088\n",
      "Epoch 5/11\n",
      "54/54 [==============================] - 0s 8ms/step\n",
      "43/43 [==============================] - 6s 135ms/step - loss: 1.8157 - val_loss: 1.5789 - val_uar: 0.3670 - val_bacc: 0.3670 - val_f1: 0.2448 - val_mcc: 0.0955\n",
      "Epoch 6/11\n",
      "54/54 [==============================] - 0s 8ms/step\n",
      "43/43 [==============================] - 5s 128ms/step - loss: 1.8149 - val_loss: 1.4600 - val_uar: 0.4052 - val_bacc: 0.4052 - val_f1: 0.2831 - val_mcc: 0.1055\n",
      "Epoch 7/11\n",
      "54/54 [==============================] - 0s 8ms/step\n",
      "43/43 [==============================] - 4s 102ms/step - loss: 1.8178 - val_loss: 1.2551 - val_uar: 0.3461 - val_bacc: 0.3461 - val_f1: 0.3337 - val_mcc: 0.1276\n",
      "Epoch 8/11\n",
      "54/54 [==============================] - 0s 8ms/step\n",
      "43/43 [==============================] - 4s 97ms/step - loss: 1.6521 - val_loss: 1.4240 - val_uar: 0.4051 - val_bacc: 0.4051 - val_f1: 0.2977 - val_mcc: 0.1254\n",
      "Epoch 9/11\n",
      "54/54 [==============================] - 0s 8ms/step\n",
      "43/43 [==============================] - 4s 97ms/step - loss: 1.6250 - val_loss: 1.2217 - val_uar: 0.3823 - val_bacc: 0.3823 - val_f1: 0.3477 - val_mcc: 0.1175\n",
      "Epoch 10/11\n",
      "54/54 [==============================] - 0s 8ms/step\n",
      "43/43 [==============================] - 4s 98ms/step - loss: 1.5920 - val_loss: 1.0924 - val_uar: 0.3865 - val_bacc: 0.3865 - val_f1: 0.4465 - val_mcc: 0.1470\n",
      "Epoch 11/11\n",
      "54/54 [==============================] - 0s 8ms/step\n",
      "43/43 [==============================] - 4s 99ms/step - loss: 1.5235 - val_loss: 1.1764 - val_uar: 0.3774 - val_bacc: 0.3774 - val_f1: 0.3971 - val_mcc: 0.1044\n",
      "0.405230615942029\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=11, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f60b354e-be83-4fec-95fe-3032e48bcab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7024312d-0658-4c8e-b8b0-c524428c6c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 3 ... 1 0 2]\n",
      "[2 1 3 ... 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(pred)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2480ed12-f05c-42db-b0d2-fe0f712339df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_STAT_single_attention_traditional Accuracy:  0.526407428903076 MSE:  0.09123847939640162 UAR:  0.44104862702423675 Recall:  N/A Precision:  N/A F1:  0.3261485401548058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.526407428903076,\n",
       " 0.09123847939640162,\n",
       " 0.44104862702423675,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.3261485401548058)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6738253e-9bfe-40cf-8236-8d3058cb7aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7b90857-c861-4e87-acea-96b92e2767b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4030dc0b-7e40-49e2-be22-e6a81bfef6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_STAT_single_attention_traditional_best Accuracy:  0.367382472431805 MSE:  0.15167486941381308 UAR:  0.4381775067750677 Recall:  N/A Precision:  N/A F1:  0.20662949234996184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.367382472431805,\n",
       " 0.15167486941381308,\n",
       " 0.4381775067750677,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.20662949234996184)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80d01b0-14d4-48ab-8ff7-46ae6d396ea4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "707c32b0-4990-44e8-a595-1ee598ac0717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bcba1cfb-6487-4945-9132-715e76ee06da",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True\n",
    "#IMAGE_SET_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd047ce6-e93e-4b99-90bc-bba6e7ce387e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f054010e-9039-404c-96e8-b70e2e814306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 21:09:58.494035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9eeec542-461b-4fa7-9cf8-bbd4d8255545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 21:10:14.656351: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f86f8a32620 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-07 21:10:14.656520: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-08-07 21:10:14.660809: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-07 21:10:14.697393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-08-07 21:10:14.749217: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 8s 149ms/step - loss: 0.0813 - mae: 0.2003 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 5/20\n",
      "37/43 [========================>.....] - ETA: 0s - loss: 0.0797 - mae: 0.1962"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m     modelAtn\u001b[38;5;241m.\u001b[39mfit(train_generator,steps_per_epoch\u001b[38;5;241m=\u001b[39mnum_samples_train\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mBATCH_SIZE,\n\u001b[1;32m      3\u001b[0m                      epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[save_best_model],\n\u001b[1;32m      4\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39mtest_generator,validation_steps\u001b[38;5;241m=\u001b[39mnum_samples_test\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mBATCH_SIZE, class_weight\u001b[38;5;241m=\u001b[39mclass_weights)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mmodelAtn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_subsample_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_subsample_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msave_best_model\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m             \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_subsample_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_subsample_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, class_weight=class_weights)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m best_model_weights \u001b[38;5;241m=\u001b[39m save_best_model\u001b[38;5;241m.\u001b[39mbest_model_weights\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(save_best_model\u001b[38;5;241m.\u001b[39mbest)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if USE_GENERATORS:\n",
    "    modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                     epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                    validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "else:\n",
    "    modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "             validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "best_model_weights = save_best_model.best_model_weights\n",
    "print(save_best_model.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a681fd60-eca8-4ab4-822e-fae6e2f26f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 120ms/step - loss: 0.0812 - mae: 0.2005 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "0.11642508953809738\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8627ed55-eb39-47bf-a5ff-f85e3f2e3ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00666008-5954-4665-a7b0-3b95827fb58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_traditional Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71217089-e4dc-454f-b8d1-d2983c731b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8dfa1fb4-19c5-442d-8711-4ba853dace75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d7df91e-c3aa-4fc9-8bf0-8282bbf22474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_traditional_best Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f974cb6-3fce-4c0f-820e-6c96baa651f0",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04735251-0076-4623-8194-f58682136646",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e849e0a2-b899-40ff-8a93-8ed48d44cff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de2d7828-a0cf-464a-be9e-1d5b0fcf4a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 34/5482: 0.6202116016052536%\n",
      "1 214/5482: 3.903684786574243%\n",
      "2 2649/5482: 48.32178037212696%\n",
      "3 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0 4/1723: 0.2321532211259431%\n",
      "1 81/1723: 4.7011027278003485%\n",
      "2 861/1723: 49.97098084735926%\n",
      "3 777/1723: 45.095763203714455%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ad13a8e-fd93-4aef-9726-fb6cbb2fefa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 2560) (5482,)\n",
      "(1723, 2560) (1723,)\n",
      "(7205, 2560) (7205,)\n",
      "[0 1 2 3] [  38  295 3510 3362]\n",
      "7205\n",
      "5474\n",
      "1731\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b636f85-45e0-451c-abc4-7a747d0ae7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 28/5474: 0.5115089514066496%\n",
      "1 224/5474: 4.092071611253197%\n",
      "2 2667/5474: 48.72122762148338%\n",
      "3 2555/5474: 46.67519181585678%\n",
      "test:\n",
      "0 10/1731: 0.5777007510109763%\n",
      "1 71/1731: 4.101675332177932%\n",
      "2 843/1731: 48.7001733102253%\n",
      "3 807/1731: 46.62045060658579%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ae7939-fdcc-4f5d-9f0d-16307529be03",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b6e5d41-937d-419e-8a3e-a397b883bd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_STAT_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "662b5d61-9431-465b-9f38-a33243b5d118",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5138bdfa-2581-4624-afa5-7d18c95e910e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 3840) (5474,)\n",
      "(1731, 128, 3840) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f3dc6013-e77a-4686-9230-756bf047ce68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  28  224 2667 2555] {0: 95.24999999999999, 1: 11.906249999999998, 2: 1.0, 3: 1.0438356164383562} 4 [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd394c3b-2f3d-4876-8ff7-1d2a5e930c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1966592   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 4)                    2052      ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1972485 (7.52 MB)\n",
      "Trainable params: 1972485 (7.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "save_best_model = SaveBestModelByUAR(X_subsample_test, y_subsample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ac2b8a2-b9c4-4f75-b557-82872899b781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "55/55 [==============================] - 1s 8ms/step\n",
      "43/43 [==============================] - 7s 150ms/step - loss: 2.8207 - val_loss: 1.4596 - val_uar: 0.4073 - val_bacc: 0.4073 - val_f1: 0.3033 - val_mcc: 0.1223\n",
      "Epoch 2/11\n",
      "55/55 [==============================] - 0s 8ms/step\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 2.2515 - val_loss: 1.3171 - val_uar: 0.4337 - val_bacc: 0.4337 - val_f1: 0.3911 - val_mcc: 0.1543\n",
      "Epoch 3/11\n",
      "55/55 [==============================] - 0s 8ms/step\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 1.9962 - val_loss: 1.0595 - val_uar: 0.4939 - val_bacc: 0.4939 - val_f1: 0.5142 - val_mcc: 0.2301\n",
      "Epoch 4/11\n",
      "55/55 [==============================] - 0s 8ms/step\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 1.8844 - val_loss: 1.0038 - val_uar: 0.4905 - val_bacc: 0.4905 - val_f1: 0.5448 - val_mcc: 0.2479\n",
      "Epoch 5/11\n",
      "55/55 [==============================] - 0s 8ms/step\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 1.7452 - val_loss: 0.9520 - val_uar: 0.4975 - val_bacc: 0.4975 - val_f1: 0.5511 - val_mcc: 0.2571\n",
      "Epoch 6/11\n",
      "55/55 [==============================] - 0s 7ms/step\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 1.7521 - val_loss: 0.9479 - val_uar: 0.4483 - val_bacc: 0.4483 - val_f1: 0.5453 - val_mcc: 0.2494\n",
      "Epoch 7/11\n",
      "55/55 [==============================] - 0s 8ms/step\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 1.7537 - val_loss: 1.1911 - val_uar: 0.4699 - val_bacc: 0.4699 - val_f1: 0.3917 - val_mcc: 0.1872\n",
      "Epoch 8/11\n",
      "55/55 [==============================] - 0s 7ms/step\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 1.6867 - val_loss: 1.0190 - val_uar: 0.5120 - val_bacc: 0.5120 - val_f1: 0.5321 - val_mcc: 0.2521\n",
      "Epoch 9/11\n",
      "55/55 [==============================] - 0s 8ms/step\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 1.5574 - val_loss: 1.0899 - val_uar: 0.4667 - val_bacc: 0.4667 - val_f1: 0.4379 - val_mcc: 0.2074\n",
      "Epoch 10/11\n",
      "55/55 [==============================] - 0s 8ms/step\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 1.5649 - val_loss: 1.0504 - val_uar: 0.4700 - val_bacc: 0.4700 - val_f1: 0.5234 - val_mcc: 0.2404\n",
      "Epoch 11/11\n",
      "55/55 [==============================] - 0s 8ms/step\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 1.5025 - val_loss: 1.0155 - val_uar: 0.4792 - val_bacc: 0.4792 - val_f1: 0.5124 - val_mcc: 0.2193\n",
      "0.5119860339989107\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=11, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5940d90e-b55b-43ba-9c47-7eb7fcfa502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0f36678-0340-447e-a35a-6c65cd08c1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_STAT_single_attention_balanced Accuracy:  0.512420566146736 MSE:  0.0906271519352975 UAR:  0.4792070156766358 Recall:  N/A Precision:  N/A F1:  0.35138349223233034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.512420566146736,\n",
       " 0.0906271519352975,\n",
       " 0.4792070156766358,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.35138349223233034)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "50fb716a-4616-43f7-b43e-7a2eca73684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8784f288-d4f8-49af-b4df-37d79671ffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "136c1f0e-a4ed-42aa-b22a-a311e6b7106f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_STAT_single_attention_balanced_best Accuracy:  0.5309069901790873 MSE:  0.09154962449451182 UAR:  0.5113796847505633 Recall:  N/A Precision:  N/A F1:  0.36558525970956424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5309069901790873,\n",
       " 0.09154962449451182,\n",
       " 0.5113796847505633,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.36558525970956424)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8172c03-474c-4b89-accd-5ac260b6efa0",
   "metadata": {},
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "68fd339a-b811-487a-9b02-44544279f0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "70d686b1-8100-478d-9653-afe38894510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4366025a-df32-451e-ae30-39a95e64f060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 2560) (5474,)\n",
      "(1731, 128, 2560) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4623b19c-314b-48c5-8204-2f12757f7032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6b4840de-e996-4e86-88c5-33ea610a85f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 125ms/step - loss: 0.0812 - mae: 0.2012 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "0.08048681914806366\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b5e011a3-de50-45f8-b854-b772349f4b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "06b95085-f510-4712-bd42-f37c4fba8358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4f64ec52-602f-457b-8ba2-0196cf4d976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d7865c14-8c19-44c3-aa80-df20eaf079bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a361982b-27c5-4c06-b650-583a8f7d1753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced_best Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c269d7c8-5485-416c-9068-1b3218fdda39",
   "metadata": {},
   "source": [
    "## MobileNet_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "373618c1-1854-4ecf-be7b-2ac345083791",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_key = 'mobilenet_7.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d48bce1a-b00d-4ab7-bedf-620c5f087632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['very distracted', 'distracted', 'engaged', 'very engaged']\n",
      "{'1100011002': 2, '1100011003': 2, '1100011004': 3, '1100011005': 3, '1100011006': 3, '1100011007': 2, '1100011008': 3, '1100011009': 2, '1100011010': 3, '1100011011': 3, '1100011012': 2, '1100011013': 3, '1100011014': 3, '1100011015': 3, '1100011016': 3, '1100011017': 3, '1100011018': 3, '1100011019': 3, '1100011020': 3, '1100011021': 3, '1100011022': 3, '1100011023': 3, '1100011025': 3, '1100011026': 3, '1100011027': 3, '1100011028': 3, '1100011029': 3, '1100011031': 3, '1100011032': 3, '1100011034': 3, '1100011035': 3, '1100011037': 3, '1100011038': 3, '1100011040': 2, '1100011046': 3, '1100011047': 3, '1100011048': 2, '1100011049': 3, '1100011050': 3, '1100011051': 3, '1100011052': 3, '1100011053': 3, '1100011054': 3, '1100011055': 3, '1100011056': 3, '1100011057': 3, '1100011058': 3, '1100011059': 3, '1100011060': 3, '1100011062': 3, '1100011063': 3, '1100011064': 3, '1100011066': 3, '1100011067': 3, '1100011068': 3, '1100011069': 3, '1100011070': 3, '1100011071': 3, '1100011072': 3, '1100011073': 3, '1100011075': 3, '1100011076': 3, '1100011078': 2, '1100011079': 3, '1100011080': 3, '1100011081': 3, '1100011082': 3, '1100011083': 3, '1100012001': 3, '1100012003': 3, '1100012007': 3, '1100012008': 3, '1100012009': 3, '1100012010': 3, '1100012011': 3, '1100012013': 3, '1100012014': 3, '1100012015': 3, '1100012016': 3, '1100012017': 3, '1100012018': 3, '1100012021': 2, '1100012022': 3, '1100012023': 3, '1100012025': 3, '1100012026': 3, '1100012027': 3, '1100012028': 3, '1100012030': 3, '1100012031': 3, '1100012032': 3, '1100012033': 3, '1100012036': 3, '1100012037': 3, '1100012038': 3, '1100012041': 3, '1100012042': 2, '1100012045': 2, '1100012046': 3, '1100012047': 2, '1100012049': 3, '1100012050': 3, '1100012051': 3, '1100012052': 3, '1100012057': 3, '1100012059': 3, '1100012060': 3, '1100012061': 3, '1100012062': 3, '1100012063': 3, '1100012064': 3, '1100012065': 3, '1100012066': 3, '1100012069': 3, '1100021001': 2, '1100021003': 1, '1100021015': 2, '1100021038': 2, '1100021039': 2, '1100021040': 3, '1100021045': 3, '1100021050': 3, '1100021055': 1, '1100022001': 3, '1100022002': 2, '1100022003': 3, '1100022004': 3, '1100022005': 1, '1100022008': 2, '1100022009': 3, '1100022014': 3, '1100022019': 3, '1100022020': 2, '1100022021': 2, '1100022022': 2, '1100022026': 3, '1100022027': 3, '1100022028': 3, '1100022029': 3, '1100022031': 3, '1100022035': 2, '1100022038': 3, '1100022039': 3, '1100022045': 3, '1100022046': 3, '1100022047': 3, '1100022048': 2, '1100022049': 2, '1100022051': 3, '1100022052': 2, '1100022053': 2, '1100022054': 2, '1100022055': 2, '1100022056': 3, '1100022057': 2, '1100041006': 3, '1100041015': 3, '1100041016': 3, '1100041017': 2, '1100041018': 2, '1100041021': 2, '1100041022': 2, '1100041023': 2, '1100041024': 2, '1100041029': 3, '1100041034': 2, '1100041044': 2, '1100041051': 3, '1100041052': 2, '1100042009': 2, '1100042010': 2, '1100042011': 2, '1100042017': 2, '1100042018': 2, '1100042019': 3, '1100042020': 3, '1100042023': 1, '1100042024': 2, '1100042025': 2, '1100042026': 1, '1100042029': 3, '1100042030': 2, '1100042031': 3, '1100042034': 2, '1100042040': 2, '1100042041': 3, '1100042058': 2, '1100042059': 2, '1100042060': 2, '1100051002': 2, '1100051004': 2, '1100051006': 2, '1100051007': 1, '1100051008': 2, '1100051009': 2, '1100051011': 2, '1100051012': 2, '1100051013': 2, '1100051014': 2, '1100051016': 1, '1100051017': 2, '1100051019': 3, '1100051020': 2, '1100051021': 2, '1100051022': 2, '1100051023': 2, '1100051024': 2, '1100051025': 2, '1100051026': 2, '1100051028': 2, '1100051029': 2, '1100051030': 1, '1100051031': 1, '1100051032': 3, '1100051033': 2, '1100051034': 2, '1100051035': 2, '1100051036': 2, '1100051037': 2, '1100051039': 2, '1100051041': 3, '1100051042': 2, '1100051044': 2, '1100051045': 3, '1100051046': 2, '1100051048': 2, '1100051049': 2, '1100051050': 3, '1100051051': 2, '1100051052': 2, '1100051053': 1, '1100051054': 2, '1100051055': 2, '1100051056': 2, '1100051057': 3, '1100051059': 3, '1100051061': 2, '1100051062': 3, '1100051064': 3, '1100051065': 2, '1100051066': 3, '1100051067': 3, '1100051068': 3, '1100051071': 3, '1100051076': 2, '1100051078': 2, '1100051079': 3, '1100052001': 2, '1100052002': 2, '1100052006': 2, '1100052007': 2, '1100052008': 3, '1100052009': 2, '1100052014': 1, '1100052023': 2, '1100052024': 2, '1100052026': 2, '1100052027': 2, '1100052028': 3, '1100052030': 2, '1100052031': 2, '1100052032': 2, '1100052033': 2, '1100052035': 2, '1100052036': 2, '1100052037': 2, '1100052038': 2, '1100052039': 2, '1100052040': 3, '1100052041': 2, '1100052047': 2, '1100052048': 2, '1100052049': 2, '1100052051': 2, '1100052055': 2, '1100052057': 2, '1100052060': 3, '1100052061': 2, '1100052062': 2, '1100052065': 3, '1100052068': 2, '1100052070': 2, '1100061009': 3, '1100061010': 3, '1100061011': 3, '1100061012': 2, '1100061013': 3, '1100061015': 2, '1100061016': 2, '1100061018': 2, '1100061019': 2, '1100061022': 3, '1100061023': 2, '1100061025': 2, '1100061027': 3, '1100061028': 2, '1100061030': 2, '1100061031': 2, '1100061032': 2, '1100061033': 3, '1100061034': 2, '1100061035': 2, '1100061036': 3, '1100061038': 3, '1100061039': 2, '1100061040': 3, '1100061042': 3, '1100061043': 3, '1100061044': 2, '1100061046': 3, '1100061047': 3, '1100061048': 3, '1100061049': 2, '1100061050': 2, '1100061051': 3, '1100061053': 2, '1100061057': 2, '1100061058': 2, '1100061061': 3, '1100061063': 3, '1100061064': 3, '1100061067': 3, '1100061068': 3, '1100061069': 3, '1100061073': 2, '1100061074': 2, '1100061077': 2, '1100061078': 2, '1100062004': 3, '1100062005': 3, '1100062007': 3, '1100062008': 1, '1100062009': 3, '1100062016': 2, '1100062017': 3, '1100062024': 2, '1100062028': 2, '1100062029': 2, '1100062036': 2, '1100062037': 2, '1100062044': 2, '1100062045': 1, '1100062046': 2, '1100062049': 1, '1100062051': 2, '1100062053': 3, '1100062054': 2, '1100062059': 2, '1100062060': 2, '1100062061': 2, '1100062062': 2, '1100062063': 2, '1100062064': 2, '1100062065': 2, '1100062066': 3, '1100062067': 3, '1100062068': 2, '1100062069': 2, '1100062070': 2, '1100062071': 3, '1100062072': 3, '1100071005': 2, '1100071006': 2, '1100071007': 2, '1100071008': 3, '1100071009': 2, '1100071010': 2, '1100071011': 2, '1100071012': 3, '1100071013': 2, '1100071014': 3, '1100071015': 2, '1100071016': 3, '1100071017': 2, '1100071018': 2, '1100071019': 2, '1100071020': 2, '1100071021': 3, '1100071022': 2, '1100071023': 2, '1100071024': 2, '1100071026': 2, '1100071027': 2, '1100071028': 2, '1100071029': 2, '1100071030': 3, '1100071031': 3, '1100071032': 2, '1100071033': 2, '1100071034': 3, '1100071035': 2, '1100071036': 2, '1100071037': 2, '1100071040': 3, '1100071041': 2, '1100071042': 2, '1100071043': 3, '1100071044': 2, '1100071045': 2, '1100071046': 2, '1100071047': 2, '1100071049': 2, '1100071050': 3, '1100071052': 2, '1100071054': 2, '1100071055': 3, '1100071056': 2, '1100071057': 3, '1100071058': 2, '1100071059': 2, '1100071060': 2, '1100071061': 3, '1100071062': 2, '1100071063': 3, '1100071064': 3, '1100071065': 2, '1100071066': 2, '1100071067': 3, '1100071069': 2, '1100071070': 3, '1100071071': 2, '1100071072': 2, '1100071073': 2, '1100071074': 2, '1100071075': 2, '1100071076': 2, '1100071077': 3, '1100071078': 3, '1100071079': 3, '1100071080': 3, '1100071081': 3, '1100072001': 2, '1100072002': 3, '1100072003': 3, '1100072004': 2, '1100072006': 2, '1100072007': 2, '1100072008': 2, '1100072009': 3, '1100072010': 2, '1100072011': 3, '1100072012': 3, '1100072013': 2, '1100072014': 2, '1100072015': 2, '1100072016': 2, '1100072021': 2, '1100072022': 2, '1100072023': 3, '1100072024': 2, '1100072027': 2, '1100072028': 2, '1100072029': 2, '1100072030': 2, '1100072031': 2, '1100072032': 3, '1100072033': 3, '1100072034': 2, '1100072036': 2, '1100072037': 2, '1100072038': 2, '1100072039': 2, '1100072040': 2, '1100072042': 2, '1100072043': 3, '1100072045': 2, '1100072047': 3, '1100072048': 2, '1100072049': 2, '1100072050': 2, '1100072051': 3, '1100072052': 3, '1100072053': 2, '1100072054': 2, '1100072056': 2, '1100072057': 2, '1100072058': 3, '1100072059': 2, '1100072060': 2, '1100072061': 2, '1100072062': 2, '1100072063': 3, '1100072065': 2, '1100072066': 3, '1100072067': 2, '1100072068': 2, '1100072069': 2, '1100072070': 2, '1100072071': 2, '1100072072': 2, '1100072073': 2, '1100072074': 3, '1100072075': 2, '1100072076': 2, '1100072077': 3, '1100072078': 3, '1100072079': 2, '1100072080': 2, '1100072081': 2, '1100072082': 3, '1100072083': 2, '1100072084': 2, '1100072085': 2, '1100081044': 2, '1100081045': 2, '1100081046': 2, '1100081047': 3, '1100081048': 3, '1100082002': 3, '1100082003': 3, '1100082018': 2, '1100082027': 2, '1100102003': 2, '1100111001': 3, '1100111002': 3, '1100111003': 2, '1100111008': 2, '1100111009': 2, '1100111010': 3, '1100111011': 2, '1100111012': 2, '1100111013': 2, '1100111014': 2, '1100111016': 2, '1100111017': 2, '1100111018': 2, '1100111019': 2, '1100111021': 2, '1100111023': 3, '1100111025': 3, '1100111026': 2, '1100111027': 3, '1100111029': 2, '1100111030': 3, '1100111032': 2, '1100112001': 2, '1100112002': 1, '1100112003': 3, '1100112004': 3, '1100112006': 1, '1100112007': 3, '1100112008': 3, '1100112009': 3, '1100112010': 2, '1100112011': 2, '1100112012': 3, '1100112013': 2, '1100112014': 2, '1100112015': 3, '1100112016': 3, '1100112017': 3, '1100112018': 3, '1100112021': 2, '1100112022': 2, '1100112024': 3, '1100112025': 2, '1100112026': 2, '1100112029': 3, '1100112030': 3, '1100112033': 3, '1100112035': 2, '1100112036': 3, '1100112037': 3, '1100112038': 2, '1100112039': 3, '1100112040': 2, '1100112041': 2, '1100112042': 3, '1100112043': 2, '1100112044': 2, '1100112045': 2, '1100112047': 3, '1100112048': 2, '1100112051': 3, '1100112052': 3, '1100112053': 3, '1100112056': 2, '1100112057': 3, '1100112058': 2, '1100112059': 3, '1100112060': 3, '1100112061': 2, '1100112062': 2, '1100112063': 2, '1100112064': 3, '1100112065': 2, '1100112066': 3, '1100112068': 3, '1100121002': 3, '1100121003': 2, '1100121004': 3, '1100121005': 3, '1100121006': 3, '1100121007': 3, '1100121008': 3, '1100121009': 3, '1100121010': 3, '1100121011': 3, '1100121012': 3, '1100121015': 2, '1100121016': 3, '1100121017': 3, '1100121018': 2, '1100121019': 2, '1100121020': 3, '1100121024': 2, '1100121025': 2, '1100121028': 3, '1100121031': 2, '1100121032': 3, '1100121033': 2, '1100121034': 2, '1100121035': 3, '1100121036': 2, '1100121038': 3, '1100121040': 3, '1100121041': 2, '1100121042': 2, '1100121044': 3, '1100121045': 3, '1100121047': 3, '1100121049': 2, '1100121050': 3, '1100121052': 2, '1100121053': 3, '1100121054': 3, '1100121056': 2, '1100121057': 3, '1100121059': 2, '1100121060': 2, '1100121061': 2, '1100121064': 3, '1100122001': 2, '1100122002': 2, '1100122003': 2, '1100122005': 2, '1100122006': 3, '1100122007': 3, '1100122008': 3, '1100122009': 2, '1100122010': 3, '1100122011': 3, '1100122012': 3, '1100122013': 3, '1100122014': 3, '1100122015': 2, '1100122017': 2, '1100122018': 3, '1100122019': 3, '1100122020': 3, '1100122021': 2, '1100122023': 2, '1100122024': 3, '1100122025': 2, '1100122026': 2, '1100122031': 3, '1100122032': 3, '1100122033': 2, '1100122034': 3, '1100122035': 2, '1100122036': 3, '1100122037': 3, '1100122038': 3, '1100122039': 3, '1100122040': 2, '1100122041': 2, '1100122045': 2, '1100122047': 2, '1100122048': 3, '1100122050': 3, '1100122051': 2, '1100122052': 3, '1100122053': 2, '1100122054': 2, '1100122056': 1, '1100131006': 3, '1100131007': 2, '1100131009': 3, '1100131010': 3, '1100131011': 3, '1100131012': 3, '1100131017': 0, '1100131019': 3, '1100141001': 3, '1100141002': 2, '1100141003': 3, '1100141004': 3, '1100141005': 2, '1100141006': 2, '1100141007': 3, '1100141008': 2, '1100141009': 2, '1100141010': 3, '1100141011': 2, '1100141012': 2, '1100141013': 1, '1100141014': 2, '1100141015': 2, '1100141016': 3, '1100141017': 2, '1100141019': 2, '1100141020': 2, '1100141021': 2, '1100141023': 3, '1100141027': 1, '1100141028': 2, '1100141029': 2, '1100141030': 2, '1100141031': 2, '1100141032': 2, '1100141033': 2, '1100141034': 2, '1100141035': 2, '1100141036': 2, '1100141039': 3, '1100141040': 2, '1100141042': 2, '1100141044': 2, '1100141045': 3, '1100141046': 2, '1100141049': 2, '1100141050': 2, '1100141052': 2, '1100141053': 2, '1100141054': 3, '1100141055': 3, '1100141056': 2, '1100141057': 2, '1100142002': 3, '1100142003': 2, '1100142004': 2, '1100142007': 2, '1100142008': 2, '1100142009': 2, '1100142010': 2, '1100142011': 3, '1100142013': 2, '1100142014': 2, '1100142015': 2, '1100142017': 2, '1100142018': 2, '1100142019': 2, '1100142021': 3, '1100142022': 2, '1100142023': 2, '1100142024': 2, '1100142027': 3, '1100142028': 2, '1100142029': 3, '1100142030': 2, '1100142031': 2, '1100142032': 3, '1100142033': 1, '1100142034': 3, '1100142035': 3, '1100142038': 2, '1100142041': 3, '1100142043': 2, '1100142044': 2, '1100142045': 2, '1100142046': 3, '1100142048': 3, '1100142049': 2, '1100142050': 2, '1100142051': 2, '1100142052': 2, '1100142053': 3, '1100142056': 3, '1100142057': 3, '1100142058': 2, '1100142059': 2, '1100142060': 2, '1100151003': 2, '1100151004': 3, '1100151008': 3, '1100151009': 2, '1100151010': 2, '1100151011': 1, '1100151012': 2, '1100151013': 2, '1100151014': 3, '1100151015': 2, '1100151016': 2, '1100151017': 2, '1100151018': 2, '1100151019': 2, '1100151020': 2, '1100151021': 3, '1100151022': 3, '1100151023': 2, '1100151024': 2, '1100151028': 2, '1100151030': 2, '1100151032': 3, '1100151033': 2, '1100151035': 3, '1100151037': 3, '1100151038': 2, '1100151039': 2, '1100151040': 3, '1100151042': 3, '1100151043': 2, '1100151044': 2, '1100151047': 2, '1100151049': 3, '1100151050': 2, '1100151051': 2, '1100151052': 3, '1100151054': 3, '1100151055': 2, '1100151056': 3, '1100151057': 1, '1100151058': 2, '1100151062': 2, '1100152001': 2, '1100152004': 3, '1100152005': 2, '1100152006': 2, '1100152008': 2, '1100152009': 2, '1100152010': 1, '1100152013': 3, '1100152014': 2, '1100152015': 2, '1100152017': 1, '1100152019': 3, '1100152020': 3, '1100152022': 2, '1100152024': 2, '1100152025': 2, '1100152026': 2, '1100152027': 3, '1100152031': 1, '1100152032': 2, '1100152039': 3, '1100152040': 2, '1100152041': 2, '1100152042': 2, '1100152043': 2, '1100152048': 2, '1100152049': 2, '1100152050': 2, '1100152051': 2, '1100152055': 1, '1100152056': 2, '1100152061': 2, '1100152062': 2, '1100152067': 2, '1100152069': 2, '1100152070': 0, '1100161002': 2, '1100161004': 3, '1100161011': 3, '1100161012': 3, '1100161013': 2, '1100161014': 2, '1100161015': 3, '1100161016': 2, '1100161020': 3, '1100161021': 3, '1100161022': 2, '1100161023': 2, '1100161028': 2, '1100161029': 2, '1100161032': 2, '1100161035': 2, '1100161036': 2, '1100161038': 2, '1100161039': 3, '1100161041': 3, '1100161043': 3, '1100161044': 2, '1100161045': 2, '1100161046': 2, '1100161048': 2, '1100161050': 3, '1100161053': 1, '1100162005': 1, '1100162007': 2, '1100162011': 2, '1100162016': 1, '1100171001': 2, '1100171002': 2, '1100171004': 0, '1100171005': 2, '1100171007': 2, '1100171008': 0, '1100171009': 2, '1100171010': 2, '1100171011': 3, '1100171012': 2, '1100171013': 2, '1100171015': 2, '1100171016': 2, '1100171017': 2, '1100171019': 2, '1100171021': 3, '1100171022': 2, '1100171023': 2, '1100171031': 2, '1100171035': 2, '1100171036': 2, '1100171038': 3, '1100171039': 3, '1100171040': 3, '1100171041': 2, '1100171043': 2, '1100171045': 2, '1100171049': 2, '1100171055': 2, '1100171056': 3, '1100171057': 2, '1100171059': 1, '1100171061': 3, '1100171063': 3, '1100171064': 3, '1100171065': 2, '1100171067': 2, '1100171069': 3, '1100171070': 2, '1100171071': 3, '1100171072': 2, '1100171073': 3, '1100171074': 2, '1100171075': 2, '1100171076': 2, '1100171077': 3, '1100171078': 3, '1100171080': 2, '1100171083': 2, '1100172003': 2, '1100172004': 2, '1100172007': 2, '1100172012': 1, '1100172013': 2, '1100172014': 2, '1100172015': 2, '1100172016': 2, '1100172017': 1, '1100172018': 3, '1100172020': 2, '1100172021': 2, '1100172022': 2, '1100172026': 2, '1100172028': 2, '1100172030': 3, '1100172032': 2, '1100172033': 1, '1100172034': 1, '1100172035': 3, '1100172037': 2, '1100172039': 2, '1100172042': 2, '1100172043': 1, '1100172047': 3, '1100172050': 2, '1100172058': 1, '1100172063': 3, '1100172066': 2, '1100411010': 2, '1100411011': 3, '1100411012': 2, '1100411013': 3, '1100411015': 3, '1100411016': 3, '1100411018': 2, '1100411020': 2, '1100411023': 3, '1100411036': 2, '1100411041': 3, '1100411045': 3, '1100411047': 2, '1100411048': 2, '1100411049': 2, '1100411050': 3, '1100411051': 3, '1100411053': 3, '1100411054': 2, '1100411055': 2, '1100411057': 2, '1100412001': 3, '1100412003': 2, '1100412010': 2, '1100412018': 0, '1100412033': 1, '1100412038': 2, '1100412039': 1, '1100412040': 2, '1110031003': 2, '1110031007': 3, '1110031010': 1, '1110031011': 2, '1110031012': 3, '1110031014': 2, '1110031019': 2, '1110031020': 2, '1110031021': 2, '1110031025': 0, '1110031027': 1, '1110031031': 3, '1110031033': 1, '1110031037': 3, '1110031038': 0, '1110031039': 2, '1110031040': 3, '1110031042': 2, '1110031048': 2, '1110031049': 2, '1110031050': 3, '1110031056': 1, '1110031061': 2, '1110031062': 2, '1110031063': 0, '1110031064': 2, '1110031065': 3, '1110032002': 3, '1110032004': 2, '1110032006': 3, '1110032008': 2, '1110032010': 2, '1110032014': 1, '1110032015': 3, '1110032018': 3, '1110032019': 2, '1110032020': 2, '1110032021': 2, '1110032022': 2, '1110032023': 2, '1110032024': 3, '1110032025': 2, '1110032027': 1, '1110032029': 3, '1110032031': 2, '1110032032': 3, '1110032033': 3, '1110032034': 2, '1110032036': 3, '1110032037': 2, '1110032042': 2, '1110032043': 1, '1110032045': 2, '1110032047': 2, '1110032048': 2, '1110032049': 2, '1110032050': 3, '1110032051': 2, '1110032052': 3, '1110032053': 2, '1110032055': 2, '1110032056': 2, '1110032058': 3, '1110032059': 2, '1110032060': 3, '1110032061': 2, '1110032062': 2, '1110032063': 2, '1813740111': 3, '1813740112': 2, '1813740115': 3, '1813740116': 3, '1813740118': 2, '1813740119': 2, '1813740122': 2, '1813740123': 3, '1813740124': 2, '1813740126': 3, '1813740127': 3, '1813740128': 3, '1813740131': 2, '1813740133': 3, '1813740135': 2, '1813740137': 2, '1813740138': 0, '1813740143': 2, '1813740144': 2, '1813740149': 3, '181374015': 2, '1813740150': 2, '1813740153': 2, '1813740155': 2, '1813740157': 2, '1813740159': 2, '181374016': 3, '1813740162': 3, '1813740164': 3, '1813740165': 3, '1813740167': 3, '1813740168': 3, '1813740169': 2, '181374017': 2, '1813740171': 2, '1813740172': 3, '1813740173': 2, '1813740174': 3, '1813740176': 2, '1813740178': 2, '1813740179': 2, '1813740180': 2, '1813740181': 3, '1813740182': 3, '1813740183': 2, '1813740184': 1, '1813740185': 1, '181374019': 3, '1813740210': 3, '1813740211': 3, '1813740212': 2, '1813740213': 2, '1813740214': 3, '1813740218': 3, '1813740219': 3, '1813740220': 3, '1813740221': 3, '1813740224': 2, '1813740225': 2, '1813740226': 3, '1813740227': 2, '1813740229': 2, '181374023': 2, '1813740231': 3, '1813740232': 2, '1813740233': 2, '1813740234': 3, '1813740235': 2, '1813740236': 3, '1813740237': 3, '1813740238': 3, '181374024': 3, '1813740240': 3, '1813740241': 3, '1813740242': 3, '1813740243': 3, '1813740245': 3, '1813740249': 3, '181374025': 3, '1813740250': 2, '1813740251': 3, '1813740252': 3, '1813740253': 2, '1813740255': 3, '1813740256': 3, '1813740257': 3, '1813740258': 3, '1813740259': 3, '181374026': 2, '1813740260': 2, '1813740261': 3, '1813740262': 3, '1813740263': 3, '1813740264': 3, '1813740265': 3, '1813740266': 3, '1813740267': 2, '1813740268': 3, '1813740269': 2, '181374027': 2, '1813740270': 3, '1813740271': 2, '1813740272': 3, '1813740273': 3, '1813740274': 3, '1813740275': 2, '1813740276': 3, '1813740277': 3, '1813740278': 2, '1813740279': 3, '181374028': 3, '181374029': 3, '2000481035': 2, '2000481036': 3, '2000481037': 3, '2000481038': 3, '2000481039': 2, '2000481040': 2, '2000481041': 2, '2000481043': 2, '2000481048': 2, '2000482008': 2, '2000482009': 3, '2000482012': 2, '2000482018': 2, '2000482021': 2, '2000482034': 2, '2000482037': 2, '2000482038': 2, '2000482039': 3, '2000482041': 3, '2000482042': 2, '2000482043': 3, '2000482044': 2, '2000482049': 2, '2000482050': 2, '2000482052': 2, '2000482059': 3, '2000482065': 2, '2000482066': 3, '2000482067': 3, '2000482068': 3, '2000482070': 2, '2000491062': 2, '2000491064': 2, '2000491065': 2, '2000491066': 3, '2000491067': 2, '2000491068': 2, '2000491070': 2, '2000491072': 3, '2000491074': 2, '2000491075': 2, '2000491076': 2, '2000491077': 1, '2000491078': 2, '2000491079': 3, '2000501001': 3, '2000501002': 2, '2000501003': 2, '2000501004': 3, '2000501006': 1, '2000501009': 3, '2000501010': 3, '2000501011': 3, '2000501012': 2, '2000501014': 2, '2000501015': 3, '2000501016': 3, '2000501018': 2, '2000501019': 3, '2000501020': 3, '2000501021': 3, '2000501023': 3, '2000501027': 2, '2000501028': 2, '2000501030': 1, '2000501031': 2, '2000501032': 3, '2000501033': 3, '2000501035': 2, '2000501036': 3, '2000501037': 3, '2000501038': 3, '2000501039': 3, '2000501040': 3, '2000501041': 3, '2000501042': 2, '2000501043': 2, '2000501044': 3, '2000501045': 2, '2000501046': 2, '2000501049': 3, '2000501050': 2, '2000501051': 2, '2000501052': 3, '2000501053': 2, '2000501054': 3, '2000501056': 2, '2000501057': 2, '2000501060': 3, '2000501061': 2, '2000501062': 2, '2000501063': 3, '2000501065': 3, '2000501066': 3, '2000501067': 2, '2000501071': 3, '2000501074': 2, '2000501075': 3, '2000501076': 3, '2000501078': 3, '2000502002': 2, '2000502005': 2, '2000502006': 2, '2000502007': 2, '2000502009': 2, '2000502010': 3, '2000502012': 2, '2000502013': 3, '2000502014': 3, '2000502015': 2, '2000502019': 2, '2000502020': 2, '2000502023': 2, '2000502025': 3, '2000502033': 2, '2000502036': 2, '2000502037': 2, '2000502039': 2, '2000502040': 3, '2000502041': 2, '2000502043': 2, '2000502044': 3, '2000502045': 3, '2000502047': 3, '2000502048': 3, '2000502049': 2, '2000502050': 2, '2000502051': 2, '2000502053': 1, '2000502054': 3, '2000502055': 3, '2000502056': 2, '2000502057': 3, '2000502058': 2, '2000502059': 2, '2000502061': 2, '2000502062': 2, '2000502063': 2, '2000502065': 1, '2000502066': 2, '2000502067': 2, '2000502069': 2, '2000502070': 2, '2000502072': 2, '2000502073': 2, '2000502075': 2, '2000502076': 2, '2000502077': 2, '2000502078': 2, '2000502081': 1, '2000502084': 2, '2000502087': 2, '2000502088': 2, '2000502090': 2, '2000541001': 2, '2000541002': 2, '2000541003': 2, '2000541006': 2, '2000541007': 3, '2000541010': 3, '2000541011': 2, '2000541014': 3, '2000541015': 2, '2000541016': 2, '2000541018': 2, '2000541019': 3, '2000541020': 3, '2000541021': 3, '2000541022': 3, '2000541023': 2, '2000541024': 3, '2000541025': 3, '2000541027': 2, '2000541028': 3, '2000541029': 2, '2000541030': 3, '2000541031': 3, '2000541032': 3, '2000541034': 2, '2000541035': 2, '2000541038': 2, '2000541039': 2, '2000541040': 2, '2000541041': 2, '2000541043': 3, '2000541044': 3, '2000541045': 2, '2000541046': 2, '2000541049': 2, '2000541050': 3, '2000541051': 2, '2000541052': 2, '2000541053': 2, '2000541054': 2, '2000541055': 3, '2000541056': 3, '2000541057': 2, '2000541059': 3, '2000541062': 3, '2000541064': 2, '2000541066': 2, '2000541067': 2, '2000541068': 2, '2000541069': 2, '2000541070': 2, '2000541071': 2, '2000541072': 3, '2000541073': 3, '2000541074': 3, '2000541075': 2, '2000541076': 3, '2000541077': 2, '2000541079': 2, '2000541080': 3, '2000541081': 3, '2000542001': 2, '2000542002': 2, '2000542007': 2, '2000542008': 2, '2000542009': 2, '2000542010': 2, '2000542013': 3, '2000542015': 3, '2000542016': 2, '2000542021': 2, '2000542022': 2, '2000542025': 3, '2000542026': 3, '2000542027': 3, '2000542029': 3, '2000542030': 3, '2000542032': 2, '2000542033': 3, '2000542034': 2, '2000542035': 3, '2000542036': 2, '2000542042': 3, '2000542049': 2, '2000542050': 3, '2000542051': 2, '2000542052': 3, '2000542054': 2, '2000542056': 2, '2026140111': 3, '2026140113': 3, '2026140116': 3, '2026140117': 3, '2026140118': 2, '2026140119': 3, '2026140120': 3, '2026140122': 3, '2026140124': 2, '2026140125': 3, '2026140126': 2, '2026140128': 2, '2026140129': 3, '2026140130': 3, '2026140131': 3, '2026140133': 3, '2026140134': 3, '2026140135': 2, '2026140138': 3, '2026140141': 3, '2026140145': 2, '2026140147': 3, '2026140149': 2, '202614015': 3, '2026140151': 3, '2026140154': 2, '2026140158': 3, '2026140159': 3, '202614016': 3, '2026140160': 2, '2026140161': 3, '2026140165': 3, '2026140169': 3, '202614017': 3, '2026140170': 2, '2026140172': 2, '202614018': 3, '202614019': 2, '202614020': 3, '202614021': 3, '2026140210': 2, '2026140212': 3, '2026140213': 2, '2026140220': 2, '2026140221': 3, '2026140223': 3, '2026140224': 3, '2026140225': 2, '202614023': 3, '2026140230': 2, '2026140233': 2, '2026140236': 3, '2026140237': 2, '2026140239': 2, '2026140241': 3, '2026140243': 3, '2026140246': 3, '2026140247': 3, '2026140249': 3, '202614025': 3, '2026140250': 3, '2026140253': 2, '2026140254': 2, '2026140255': 2, '2026140257': 1, '2026140259': 3, '2026140260': 3, '2026140263': 2, '2026140264': 1, '2026140272': 3, '2026140273': 1, '2026140275': 3, '2026140276': 3, '2026140277': 3, '2026140279': 3, '2026140281': 3, '202614029': 2, '205601011': 3, '2056010112': 2, '2056010113': 2, '2056010114': 2, '2056010116': 2, '2056010118': 2, '2056010119': 2, '205601012': 2, '2056010120': 3, '2056010122': 3, '2056010123': 3, '2056010124': 3, '2056010126': 2, '2056010130': 2, '2056010133': 3, '2056010134': 0, '2056010136': 2, '2056010137': 2, '2056010139': 3, '2056010141': 3, '2056010142': 2, '2056010148': 2, '2056010149': 2, '2056010153': 3, '2056010155': 3, '2056010156': 2, '2056010157': 2, '205601016': 3, '2056010160': 3, '2056010162': 2, '2056010164': 2, '2056010165': 2, '2056010167': 3, '205601017': 3, '205601018': 2, '2056010210': 2, '2056010212': 3, '2056010213': 2, '2056010214': 3, '2056010215': 2, '2056010218': 3, '2056010219': 2, '2056010222': 2, '2056010224': 1, '2056010225': 3, '2056010226': 3, '2056010228': 3, '2056010229': 3, '2056010230': 3, '2056010232': 3, '2056010233': 3, '2056010234': 2, '2056010235': 3, '2056010236': 2, '2056010238': 3, '2056010239': 3, '205601024': 2, '2056010240': 2, '2056010241': 2, '2056010242': 2, '2056010244': 2, '2056010245': 2, '2056010247': 3, '2056010249': 3, '205601025': 3, '2056010250': 2, '2056010252': 2, '2056010253': 3, '2056010254': 3, '2056010255': 3, '2056010258': 2, '2056010260': 3, '2056010261': 2, '2056010262': 3, '2056010263': 3, '2056010265': 3, '2056010267': 2, '2056010269': 3, '205601027': 3, '2056010272': 2, '2056010274': 2, '2056010275': 3, '2056010276': 3, '2056010277': 3, '2056010279': 2, '205601028': 2, '2056010281': 3, '2056010283': 2, '2100511002': 3, '2100511003': 3, '2100511005': 2, '2100511008': 3, '2100511011': 2, '2100511012': 3, '2100511013': 2, '2100511015': 2, '2100511016': 3, '2100511018': 3, '2100511019': 2, '2100511024': 2, '2100511026': 2, '2100511027': 2, '2100511028': 3, '2100511031': 3, '2100511032': 2, '2100511034': 2, '2100511035': 2, '2100511036': 2, '2100511038': 3, '2100511039': 2, '2100511040': 3, '2100511044': 2, '2100511048': 2, '2100511057': 3, '2100511058': 3, '2100511059': 2, '2100511060': 3, '2100511061': 2, '2100511062': 3, '2100511063': 3, '2100511064': 2, '2100511065': 3, '2100511067': 3, '2100511069': 1, '2100511070': 2, '2100511071': 3, '2100511072': 3, '2100511073': 3, '2100511074': 3, '2100511076': 2, '2100511077': 3, '2100511078': 3, '2100511079': 3, '2100511080': 3, '2100511081': 2, '2100511082': 3, '2100512001': 3, '2100512002': 2, '2100512003': 2, '2100512006': 2, '2100512007': 3, '2100512009': 3, '2100512010': 3, '2100512011': 2, '2100512012': 3, '2100512014': 3, '2100512015': 2, '2100512016': 3, '2100512017': 3, '2100512018': 2, '2100512020': 3, '2100512021': 3, '2100512025': 3, '2100512026': 2, '2100512028': 2, '2100512029': 3, '2100512032': 3, '2100512034': 3, '2100512035': 2, '2100512036': 2, '2100512037': 2, '2100512038': 3, '2100512039': 2, '2100512041': 2, '2100512042': 3, '2100512044': 2, '2100512045': 2, '2100512051': 1, '2100512052': 3, '2100512053': 3, '2100512055': 2, '2100512057': 3, '2100512058': 3, '2100512061': 3, '2100512062': 3, '2100512063': 3, '2100512064': 1, '2100512065': 2, '2100521002': 3, '2100521005': 3, '2100521006': 3, '2100521008': 3, '2100521009': 2, '2100521010': 2, '2100521013': 2, '2100521014': 2, '2100521015': 3, '2100521016': 3, '2100521017': 2, '2100521018': 2, '2100521021': 3, '2100521022': 2, '2100521023': 2, '2100521024': 2, '2100521025': 2, '2100521026': 2, '2100521027': 2, '2100521028': 2, '2100521029': 3, '2100521030': 2, '2100521031': 2, '2100521032': 1, '2100521033': 3, '2100521034': 2, '2100521035': 2, '2100521037': 3, '2100521038': 2, '2100521039': 2, '2100521040': 3, '2100521041': 2, '2100521042': 2, '2100521043': 2, '2100521044': 3, '2100521046': 2, '2100521047': 2, '2100521048': 2, '2100521049': 2, '2100521050': 2, '2100521051': 2, '2100521052': 2, '2100521054': 2, '2100521055': 2, '2100521056': 2, '2100521057': 2, '2100521059': 3, '2100521060': 2, '2100521061': 2, '2100521062': 2, '2100521063': 2, '2100521067': 2, '2100521069': 2, '2100521070': 2, '2100521072': 3, '2100521073': 2, '2100521074': 3, '2100521075': 2, '2100521076': 3, '2100521077': 2, '2100521078': 3, '2100521079': 2, '2100522001': 2, '2100522004': 3, '2100522005': 2, '2100522006': 2, '2100522007': 3, '2100522008': 2, '2100522009': 3, '2100522010': 2, '2100522011': 2, '2100522012': 2, '2100522013': 2, '2100522018': 2, '2100522019': 3, '2100522020': 2, '2100522021': 2, '2100522023': 3, '2100522024': 3, '2100522026': 3, '2100522028': 2, '2100522031': 3, '2100522033': 2, '2100522034': 2, '2100522035': 2, '2100522036': 2, '2100522038': 2, '2100522039': 2, '2100522040': 2, '2100522041': 2, '2100522042': 2, '2100522046': 2, '2100522047': 2, '2100522048': 2, '2100522049': 3, '2100522050': 2, '2100522051': 2, '2100522052': 2, '2100522053': 2, '2100522054': 3, '2100522055': 3, '2100522056': 2, '2100522059': 2, '2100522060': 2, '2100522061': 2, '2100522062': 2, '2100522063': 3, '2100522064': 2, '2100522067': 2, '2100522068': 2, '2100522070': 2, '2100531001': 3, '2100531002': 2, '2100531003': 3, '2100531004': 3, '2100531006': 3, '2100531007': 2, '2100531008': 2, '2100531009': 3, '2100531010': 3, '2100531012': 3, '2100531013': 2, '2100531014': 3, '2100531015': 3, '2100531016': 2, '2100531017': 2, '2100531018': 3, '2100531019': 3, '2100531021': 3, '2100531022': 2, '2100531023': 3, '2100531024': 3, '2100531025': 2, '2100531026': 2, '2100531027': 3, '2100531028': 3, '2100531030': 2, '2100531031': 2, '2100531033': 2, '2100531034': 3, '2100531035': 3, '2100531036': 2, '2100531037': 2, '2100531040': 3, '2100531041': 2, '2100531042': 3, '2100531043': 3, '2100531044': 3, '2100531045': 3, '2100531047': 3, '2100531048': 2, '2100531049': 3, '2100531050': 2, '2100531051': 3, '2100531052': 3, '2100531053': 2, '2100531054': 1, '2100531055': 3, '2100531056': 2, '2100531057': 3, '2100531058': 3, '2100531059': 2, '2100531060': 3, '2100531061': 2, '2100531063': 3, '2100531064': 2, '2100531065': 2, '2100531066': 3, '2100531067': 3, '2100531068': 3, '2100531070': 2, '2100531071': 2, '2100531072': 2, '2100531073': 2, '2100531074': 3, '2100531076': 3, '2100531077': 3, '2100531078': 3, '2100531079': 3, '2100531080': 3, '2100531081': 2, '2100531082': 3, '2100531084': 3, '2100532002': 2, '2100532003': 2, '2100532004': 2, '2100532005': 3, '2100532007': 2, '2100532008': 2, '2100532010': 2, '2100532012': 2, '2100532013': 2, '2100532015': 2, '2100532016': 1, '2100532017': 3, '2100532019': 2, '2100532020': 2, '2100532022': 0, '2100532023': 2, '2100532024': 3, '2100532025': 3, '2100532026': 3, '2100532027': 3, '2100532028': 3, '2100532029': 2, '2100532030': 2, '2100532031': 2, '2100532032': 3, '2100532033': 2, '2100532034': 2, '2100532037': 3, '2100532042': 2, '2100532043': 3, '2100532044': 2, '2100532045': 2, '2100532046': 3, '2100532047': 2, '2100532048': 3, '2100532050': 3, '2100532052': 2, '2100532053': 3, '2100532054': 3, '2100532055': 3, '2100532056': 2, '2100532057': 2, '2100532058': 3, '2100532059': 3, '2100532060': 3, '2100532061': 3, '2100532062': 2, '2100532063': 3, '2100532064': 3, '2100532066': 3, '2100532067': 2, '2100532068': 3, '2100532070': 3, '2100532071': 3, '2100532072': 2, '2100551002': 2, '2100551005': 0, '2100551006': 2, '2100551007': 3, '2100551010': 1, '2100551011': 2, '2100551013': 3, '2100551014': 2, '2100551015': 2, '2100551016': 2, '2100551017': 3, '2100551018': 3, '2100551019': 3, '2100551020': 2, '2100551021': 3, '2100551022': 2, '2100551023': 2, '2100551024': 3, '2100551025': 2, '2100551027': 2, '2100551028': 3, '2100551029': 2, '2100551032': 1, '2100551033': 2, '2100551034': 2, '2100551035': 1, '2100551036': 2, '2100551037': 2, '2100551039': 2, '2100551041': 2, '2100551042': 1, '2100551043': 2, '2100551044': 2, '2100551045': 2, '2100551046': 2, '2100551049': 3, '2100551050': 3, '2100551051': 2, '2100551052': 2, '2100551053': 3, '2100551054': 2, '2100551055': 2, '2100551056': 3, '2100551057': 3, '2100551059': 2, '2100551060': 3, '2100551061': 2, '2100551062': 2, '2100551063': 2, '2100551064': 2, '2100551065': 2, '2100551066': 3, '2100551067': 2, '2100551068': 3, '2100551069': 3, '2100551071': 3, '2100551072': 2, '2100551073': 2, '2100551074': 2, '2100551075': 2, '2100551076': 3, '2100551077': 2, '2100551079': 2, '2100551080': 3, '2100551081': 2, '2100552002': 3, '2100552003': 2, '2100552004': 2, '2100552005': 2, '2100552006': 2, '2100552007': 2, '2100552008': 2, '2100552009': 3, '2100552010': 2, '2100552011': 2, '2100552012': 2, '2100552013': 2, '2100552014': 2, '2100552015': 3, '2100552016': 2, '2100552017': 2, '2100552018': 2, '2100552019': 3, '2100552021': 2, '2100552022': 3, '2100552023': 2, '2100552024': 2, '2100552025': 3, '2100552027': 3, '2100552028': 3, '2100552029': 3, '2100552030': 3, '2100552031': 2, '2100552032': 3, '2100552033': 3, '2100552034': 3, '2100552035': 2, '2100552037': 2, '2100552038': 2, '2100552039': 2, '2100552041': 2, '2100552042': 3, '2100552043': 2, '2100552044': 3, '2100552045': 2, '2100552047': 3, '2100552048': 1, '2100552051': 3, '2100552052': 3, '2100552053': 2, '2100552055': 2, '2100552057': 3, '2100552059': 3, '2100552060': 2, '2100552061': 3, '2100552062': 2, '2100552063': 1, '2100552065': 2, '2100552066': 2, '2100552068': 2, '2100552072': 2, '2100561006': 2, '2100561010': 2, '2100561011': 2, '2100561013': 3, '2100561014': 3, '2100561015': 2, '2100561016': 2, '2100561018': 3, '2100561019': 3, '2100561020': 3, '2100561021': 3, '2100561022': 2, '2100561023': 3, '2100561024': 2, '2100561027': 3, '2100561029': 3, '2100561032': 2, '2100561038': 2, '2100561043': 3, '2100561044': 3, '2100561046': 3, '2100561051': 2, '2100561052': 3, '2100561053': 3, '2100561054': 2, '2100561056': 2, '2100561057': 3, '2100561058': 3, '2100561059': 3, '2100561062': 3, '2100561063': 2, '2100561064': 3, '2100561065': 3, '2100561070': 3, '2100561071': 2, '2100561074': 3, '2100561079': 2, '2100562001': 3, '2100562002': 3, '2100562003': 3, '2100562004': 3, '2100562005': 2, '2100562007': 3, '2100562008': 2, '2100562009': 3, '2100562010': 3, '2100562011': 3, '2100562012': 3, '2100562013': 2, '2100562014': 3, '2100562015': 3, '2100562017': 3, '2100562018': 3, '2100562019': 1, '2100562020': 2, '2100562024': 1, '2100562026': 2, '2100562027': 2, '2100562029': 3, '2100562030': 2, '2100562032': 2, '2100562033': 2, '2100562034': 3, '2100562035': 3, '2100562037': 3, '2100562038': 2, '2100562039': 2, '2100562040': 2, '2100562042': 3, '2100562043': 2, '2100562044': 2, '2100562046': 2, '2100562047': 3, '2100562048': 3, '2100562049': 2, '2100562050': 2, '2100562051': 2, '2100562053': 3, '2100562054': 2, '2100562055': 2, '2100562056': 3, '2100562058': 3, '2100562059': 3, '2100562060': 2, '2100562061': 3, '2100571001': 2, '2100571002': 1, '2100571004': 2, '2100571007': 1, '2100571008': 3, '2100571009': 2, '2100571011': 2, '2100571012': 2, '2100571013': 3, '2100571015': 2, '2100571017': 2, '2100571018': 2, '2100571019': 2, '2100571020': 2, '2100571021': 1, '2100571022': 2, '2100571023': 1, '2100571024': 2, '2100571025': 2, '2100571027': 2, '2100571029': 2, '2100571030': 2, '2100571031': 2, '2100571033': 2, '2100571034': 2, '2100571036': 2, '2100571038': 1, '2100571039': 2, '2100571040': 3, '2100571041': 3, '2100571042': 3, '2100571044': 1, '2100571045': 3, '2100571046': 3, '2100571047': 2, '2100571048': 3, '2100571049': 1, '2100571050': 2, '2100571051': 2, '2100571052': 2, '2100571053': 2, '2100571055': 3, '2100571056': 2, '2100571057': 2, '2100571058': 2, '2100571061': 2, '2100571062': 1, '2100571063': 2, '2100571064': 2, '2100571065': 3, '2100571066': 2, '2100571067': 2, '2100571068': 2, '2100571069': 2, '2100571070': 2, '2100571072': 3, '2100571073': 2, '2100571074': 2, '2100571075': 3, '2100571077': 3, '2100571078': 3, '2100571079': 2, '2100571081': 3, '2100571082': 2, '2100572001': 2, '2100572002': 3, '2100572004': 2, '2100572006': 3, '2100572009': 2, '2100572010': 3, '2100572011': 3, '2100572012': 2, '2100572013': 3, '2100572015': 3, '2100572017': 3, '2100572018': 3, '2100572019': 2, '2100572020': 2, '2100572021': 1, '2100572023': 2, '2100572024': 3, '2100572025': 2, '2100572026': 2, '2100572027': 2, '2100572028': 2, '2100572029': 2, '2100572030': 2, '2100572032': 2, '2100572033': 3, '2100572034': 2, '2100572036': 2, '2100572038': 2, '2100572039': 3, '2100572040': 2, '2100572041': 3, '2100572042': 2, '2100572043': 2, '2100572044': 2, '2100572045': 2, '2100572046': 3, '2100572047': 3, '2100572048': 3, '2100572050': 3, '2100572051': 3, '2100572054': 2, '2100572055': 3, '2100572056': 3, '2100572057': 1, '2100572058': 2, '2100572059': 2, '2100572060': 2, '2100572061': 2, '2100572062': 3, '2100572063': 2, '2100572064': 3, '2100572067': 2, '2100572068': 2, '2100572069': 2, '2100581001': 1, '2100581002': 3, '2100581003': 2, '2100581004': 2, '2100581005': 2, '2100581006': 2, '2100581007': 3, '2100581009': 2, '2100581010': 2, '2100581011': 3, '2100581012': 3, '2100581013': 2, '2100581014': 3, '2100581015': 3, '2100581018': 3, '2100581019': 3, '2100581021': 1, '2100581022': 2, '2100581024': 2, '2100581025': 3, '2100581026': 2, '2100581027': 2, '2100581028': 3, '2100581029': 2, '2100581030': 2, '2100581034': 2, '2100581035': 2, '2100581036': 3, '2100581037': 3, '2100581038': 2, '2100581039': 2, '2100581040': 2, '2100581041': 2, '2100581042': 2, '2100581044': 2, '2100581045': 2, '2100581051': 2, '2100581054': 3, '2100581056': 3, '2100581057': 3, '2100581058': 3, '2100581059': 2, '2100581061': 2, '2100581062': 3, '2100581064': 3, '2100581066': 2, '2100581067': 2, '2100581068': 2, '2100581069': 2, '2100581070': 2, '2100581071': 2, '2100581072': 2, '2100581073': 2, '2100581074': 2, '2100581075': 3, '2100581076': 2, '2100581077': 3, '2100582001': 2, '2100582002': 2, '2100582003': 3, '2100582004': 3, '2100582005': 3, '2100582006': 2, '2100582008': 2, '2100582009': 3, '2100582012': 2, '2100582013': 2, '2100582015': 2, '2100582017': 2, '2100582019': 2, '2100582020': 2, '2100582021': 2, '2100582023': 2, '2100582024': 2, '2100582025': 3, '2100582026': 3, '2100582027': 1, '2100582028': 2, '2100582038': 2, '2100582043': 3, '2100582044': 2, '2100582045': 2, '2100582046': 2, '2100582048': 3, '2100582050': 2, '2100582051': 2, '2100582052': 0, '2100582053': 3, '2100582054': 2, '2100582055': 0, '2100582056': 0, '2100582057': 0, '2100582058': 0, '2100582060': 0, '2100582061': 1, '2100582062': 0, '2100582064': 3, '2100582067': 2, '2100582069': 2, '2100591002': 3, '2100591003': 3, '2100591004': 3, '2100591005': 3, '2100591006': 3, '2100591007': 3, '2100591008': 3, '2100591010': 3, '2100591013': 2, '2100591015': 2, '2100591016': 3, '2100591017': 2, '2100591019': 2, '2100591020': 3, '2100591021': 2, '2100591022': 3, '2100591023': 2, '2100591025': 3, '2100591026': 2, '2100591027': 2, '2100591028': 2, '2100591030': 2, '2100591034': 3, '2100591035': 3, '2100591036': 3, '2100591037': 2, '2100591038': 2, '2100591039': 2, '2100591040': 3, '2100591041': 2, '2100591042': 3, '2100591043': 2, '2100591044': 3, '2100591045': 2, '2100591046': 1, '2100591047': 3, '2100591048': 3, '2100591049': 2, '2100591050': 3, '2100591053': 3, '2100591054': 3, '2100591055': 3, '2100591056': 3, '2100591057': 3, '2100591059': 3, '2100591060': 2, '2100591061': 3, '2100591062': 2, '2100591064': 2, '2100591065': 3, '2100591066': 3, '2100591067': 3, '2100591068': 3, '2100591069': 3, '2100591070': 3, '2100591072': 3, '2100591073': 3, '2100591074': 3, '2100591075': 3, '2100591076': 3, '2100591077': 3, '2100591078': 3, '2100591080': 3, '2100591081': 2, '2100591082': 3, '2100592002': 3, '2100592003': 3, '2100592004': 2, '2100592005': 3, '2100592007': 3, '2100592009': 3, '2100592010': 3, '2100592011': 2, '2100592012': 3, '2100592013': 2, '2100592014': 2, '2100592015': 3, '2100592016': 3, '2100592017': 3, '2100592018': 2, '2100592019': 3, '2100592020': 3, '2100592021': 3, '2100592022': 2, '2100592023': 3, '2100592024': 3, '2100592025': 2, '2100592026': 3, '2100592027': 2, '2100592028': 3, '2100592029': 3, '2100592030': 2, '2100592032': 3, '2100592033': 3, '2100592034': 3, '2100592035': 2, '2100592036': 2, '2100592038': 2, '2100592040': 2, '2100592041': 3, '2100592042': 3, '2100592043': 2, '2100592044': 3, '2100592046': 2, '2100592047': 3, '2100592048': 2, '2100592049': 3, '2100592052': 2, '2100592053': 3, '2100592054': 2, '2100592056': 2, '2100592057': 2, '2100592058': 2, '2100592059': 3, '2100592060': 2, '2100592064': 2, '2100592065': 2, '2100592066': 2, '2100592067': 3, '2100592068': 2, '2100592069': 3, '2100592070': 2, '2100592071': 2, '2100592072': 3, '2100601001': 3, '2100601002': 3, '2100601004': 2, '2100601005': 2, '2100601006': 2, '2100601007': 2, '2100601008': 3, '2100601009': 2, '2100601010': 3, '2100601011': 3, '2100601012': 1, '2100601013': 2, '2100601014': 3, '2100601015': 2, '2100601016': 3, '2100601017': 3, '2100601018': 1, '2100601020': 3, '2100601021': 2, '2100601023': 2, '2100601024': 2, '2100601025': 2, '2100601027': 2, '2100601028': 2, '2100601029': 2, '2100601030': 3, '2100601031': 2, '2100601032': 2, '2100601033': 3, '2100601035': 3, '2100601036': 2, '2100601037': 3, '2100601038': 3, '2100601039': 2, '2100601040': 3, '2100601041': 3, '2100601042': 3, '2100601043': 3, '2100601044': 3, '2100601045': 3, '2100601046': 3, '2100601049': 2, '2100601050': 2, '2100601052': 2, '2100601053': 2, '2100601054': 2, '2100601055': 3, '2100601056': 2, '2100601057': 3, '2100601059': 2, '2100601062': 3, '2100601063': 3, '2100601064': 2, '2100601065': 3, '2100601066': 3, '2100601067': 3, '2100601068': 2, '2100601069': 3, '2100601071': 3, '2100601073': 3, '2100601074': 2, '2100601075': 2, '2100601077': 3, '2100601078': 2, '2100602001': 2, '2100602002': 2, '2100602003': 2, '2100602004': 2, '2100602005': 2, '2100602006': 3, '2100602008': 2, '2100602009': 2, '2100602010': 3, '2100602011': 2, '2100602012': 2, '2100602014': 2, '2100602015': 2, '2100602017': 3, '2100602018': 2, '2100602019': 2, '2100602020': 3, '2100602022': 2, '2100602023': 2, '2100602024': 2, '2100602025': 3, '2100602026': 2, '2100602027': 3, '2100602028': 2, '2100602029': 2, '2100602030': 2, '2100602032': 2, '2100602033': 3, '2100602034': 2, '2100602035': 2, '2100602036': 2, '2100602038': 2, '2100602040': 2, '2100602041': 0, '2100602042': 2, '2100602043': 3, '2100602044': 2, '2100602046': 2, '2100602047': 3, '2100602049': 3, '2100602050': 3, '2100602051': 2, '2100602052': 3, '2100602053': 2, '2100602054': 3, '2100602056': 2, '2100602058': 2, '2100602059': 2, '2100602060': 2, '2100602061': 2, '2100602062': 3, '2100602063': 3, '2100602065': 2, '2100602067': 3, '2100602068': 2, '2100602069': 2, '2100602072': 3, '2100611002': 3, '2100611003': 3, '2100611004': 3, '2100611005': 2, '2100611006': 2, '2100611010': 2, '2100611011': 3, '2100611012': 3, '2100611013': 3, '2100611014': 3, '2100611015': 3, '2100611016': 2, '2100611017': 2, '2100611018': 2, '2100611019': 2, '2100611021': 3, '2100611023': 2, '2100611024': 3, '2100611025': 3, '2100611026': 3, '2100611027': 1, '2100611028': 2, '2100611029': 2, '2100611031': 2, '2100611032': 3, '2100611034': 3, '2100611035': 3, '2100611036': 2, '2100611037': 2, '2100611038': 3, '2100611039': 3, '2100611040': 2, '2100611041': 3, '2100611042': 2, '2100611043': 2, '2100611044': 3, '2100611045': 2, '2100611046': 3, '2100611047': 2, '2100611048': 3, '2100611049': 3, '2100611050': 2, '2100611051': 3, '2100611052': 2, '2100611055': 3, '2100611056': 3, '2100611057': 2, '2100611058': 2, '2100611059': 3, '2100611060': 2, '2100611061': 3, '2100611062': 2, '2100611063': 3, '2100611064': 3, '2100611066': 3, '2100611067': 2, '2100611068': 2, '2100611069': 3, '2100611070': 2, '2100611071': 2, '2100611075': 2, '2100611076': 3, '2100611077': 3, '2100611078': 2, '2100611079': 2, '2100611081': 3, '2100611083': 2, '2100612001': 3, '2100612002': 3, '2100612003': 2, '2100612005': 2, '2100612006': 2, '2100612007': 3, '2100612008': 3, '2100612009': 1, '2100612010': 3, '2100612011': 3, '2100612012': 3, '2100612014': 3, '2100612015': 3, '2100612020': 3, '2100612022': 3, '2100612024': 3, '2100612025': 3, '2100612026': 3, '2100612027': 2, '2100612028': 2, '2100612029': 3, '2100612030': 2, '2100612031': 3, '2100612033': 2, '2100612034': 2, '2100612035': 3, '2100612037': 2, '2100612038': 3, '2100612040': 3, '2100612041': 2, '2100612042': 2, '2100612043': 3, '2100612044': 2, '2100612045': 3, '2100612046': 3, '2100612047': 3, '2100612048': 3, '2100612051': 3, '2100612053': 3, '2100612056': 2, '2100612057': 3, '2100612058': 3, '2100612059': 3, '2100612060': 3, '2100612061': 3, '2100612062': 3, '2100612063': 2, '2100612064': 2, '2100612065': 3, '2100612066': 3, '2100612067': 3, '2100612068': 2, '2100612069': 2, '2100612070': 2, '2100612071': 2, '2100612072': 3, '2260510110': 2, '2260510113': 3, '2260510114': 2, '2260510115': 3, '2260510116': 2, '2260510118': 2, '2260510122': 2, '2260510124': 2, '2260510125': 2, '2260510126': 2, '2260510127': 3, '2260510129': 2, '226051013': 2, '2260510131': 2, '2260510134': 2, '2260510136': 2, '2260510138': 2, '2260510139': 2, '226051014': 2, '2260510140': 3, '2260510141': 2, '2260510142': 2, '2260510143': 2, '2260510146': 3, '2260510147': 2, '2260510148': 2, '2260510151': 3, '2260510152': 3, '2260510155': 1, '2260510156': 2, '2260510158': 2, '2260510159': 2, '226051016': 2, '2260510160': 2, '2260510162': 2, '2260510163': 1, '2260510167': 2, '2260510168': 3, '226051017': 2, '2260510172': 3, '2260510174': 2, '2260510176': 2, '2260510177': 1, '2260510180': 2, '2260510182': 2, '2260510183': 2, '2260510185': 2, '226051019': 3, '226051021': 2, '2260510212': 3, '2260510213': 3, '2260510214': 3, '2260510217': 2, '226051022': 3, '2260510220': 3, '2260510221': 2, '2260510222': 3, '2260510223': 3, '2260510227': 3, '2260510228': 2, '2260510229': 3, '226051023': 3, '2260510230': 3, '2260510231': 3, '2260510232': 3, '2260510233': 3, '2260510237': 3, '2260510238': 3, '2260510240': 3, '2260510241': 3, '2260510242': 3, '2260510243': 3, '2260510244': 3, '2260510247': 3, '2260510248': 3, '226051025': 3, '2260510250': 2, '2260510252': 3, '2260510253': 3, '2260510254': 2, '2260510257': 2, '2260510258': 3, '2260510259': 3, '226051026': 3, '2260510260': 3, '2260510262': 2, '2260510266': 3, '2260510267': 3, '226051027': 3, '2260510270': 3, '2260510271': 2, '2260510272': 3, '2260510276': 2, '2260510277': 2, '2260510278': 3, '240846010': 3, '240846011': 3, '2408460110': 3, '2408460111': 2, '2408460118': 1, '240846012': 2, '2408460120': 2, '2408460123': 3, '2408460125': 3, '2408460126': 2, '2408460127': 2, '2408460129': 2, '240846013': 2, '2408460130': 2, '2408460131': 2, '2408460132': 2, '2408460133': 3, '2408460134': 3, '2408460135': 3, '2408460137': 1, '2408460139': 3, '2408460143': 2, '2408460145': 3, '2408460146': 3, '2408460148': 2, '2408460149': 2, '240846015': 2, '2408460150': 2, '2408460151': 3, '2408460152': 3, '2408460154': 3, '2408460155': 3, '2408460156': 2, '2408460158': 2, '2408460159': 2, '240846016': 2, '2408460163': 2, '2408460166': 2, '240846017': 2, '240846018': 2, '240846019': 2, '2408460211': 2, '2408460212': 3, '2408460213': 3, '2408460215': 3, '2408460217': 2, '2408460219': 2, '240846022': 2, '2408460220': 3, '2408460221': 3, '2408460222': 2, '2408460223': 2, '2408460225': 3, '2408460226': 2, '2408460227': 3, '2408460229': 2, '240846023': 2, '2408460234': 2, '2408460236': 3, '2408460237': 3, '2408460238': 2, '240846024': 2, '2408460240': 2, '2408460242': 3, '2408460243': 3, '2408460244': 2, '2408460246': 3, '2408460247': 3, '2408460249': 3, '2408460252': 3, '2408460254': 2, '2408460255': 3, '2408460257': 3, '2408460260': 3, '2408460261': 3, '2408460265': 3, '2408460266': 3, '2408460268': 3, '2408460269': 2, '240846027': 2, '2408460271': 2, '2408460272': 2, '2408460274': 2, '2408460276': 3, '2408460277': 3, '2408460278': 2, '240846028': 2, '2408460280': 3, '240846029': 2, '24851011': 2, '248510111': 3, '248510112': 3, '248510114': 2, '248510116': 3, '248510117': 3, '248510118': 2, '248510119': 3, '248510120': 3, '248510125': 3, '248510127': 2, '248510128': 3, '248510129': 3, '24851013': 3, '248510131': 2, '248510136': 3, '248510137': 3, '24851014': 2, '248510142': 2, '248510147': 3, '248510148': 3, '24851015': 3, '248510150': 3, '248510151': 3, '248510153': 2, '248510155': 3, '248510156': 2, '248510157': 2, '248510160': 3, '248510161': 3, '248510163': 2, '248510164': 3, '248510167': 3, '248510170': 3, '24851018': 3, '24851019': 3, '248510211': 3, '248510212': 3, '248510213': 2, '248510214': 2, '248510215': 3, '248510216': 3, '24851022': 3, '248510220': 3, '248510223': 3, '248510225': 3, '248510227': 3, '248510229': 3, '248510230': 3, '248510232': 3, '248510233': 3, '248510235': 3, '248510236': 3, '24851024': 3, '248510241': 3, '248510242': 3, '248510245': 3, '248510246': 3, '248510248': 3, '248510249': 3, '248510250': 2, '248510251': 3, '248510253': 3, '248510255': 3, '248510256': 3, '248510259': 3, '24851026': 3, '248510260': 3, '248510262': 3, '248510264': 2, '248510265': 3, '248510267': 3, '248510268': 3, '24851027': 3, '248510271': 3, '248510272': 3, '248510273': 3, '248510276': 3, '248510278': 2, '24851028': 3, '2904280110': 3, '29042801110': 3, '29042801170': 3, '29042801180': 2, '2904280120': 3, '29042801220': 2, '29042801230': 3, '29042801250': 3, '29042801260': 3, '29042801290': 3, '29042801300': 3, '29042801320': 3, '29042801340': 3, '29042801350': 3, '29042801370': 1, '29042801390': 3, '2904280140': 2, '29042801440': 2, '29042801450': 3, '29042801470': 3, '29042801480': 2, '2904280150': 3, '29042801500': 3, '29042801550': 2, '29042801570': 2, '29042801580': 3, '2904280160': 2, '29042801600': 3, '29042801630': 3, '29042801640': 3, '29042801650': 2, '29042801680': 2, '29042801690': 2, '2904280170': 2, '29042801710': 3, '29042801740': 3, '29042801750': 3, '29042801770': 3, '29042801780': 2, '29042801790': 2, '2904280180': 3, '2904280190': 3, '29042802110': 2, '29042802140': 2, '29042802150': 2, '29042802180': 3, '29042802200': 3, '29042802220': 3, '29042802240': 3, '29042802260': 3, '29042802280': 3, '2904280230': 3, '29042802310': 3, '29042802320': 3, '29042802340': 3, '29042802350': 3, '29042802380': 2, '29042802390': 2, '29042802410': 3, '29042802420': 3, '29042802430': 3, '29042802440': 3, '29042802450': 3, '29042802460': 3, '29042802470': 3, '29042802480': 3, '2904280250': 2, '29042802500': 3, '29042802510': 3, '29042802520': 3, '29042802530': 3, '29042802560': 3, '29042802570': 3, '2904280260': 1, '29042802600': 2, '29042802640': 3, '29042802660': 2, '29042802670': 3, '29042802680': 3, '29042802690': 3, '2904280270': 2, '29042802700': 3, '29042802720': 3, '29042802740': 3, '29042802750': 3, '29042802760': 3, '29042802770': 2, '29042802790': 3, '2904280280': 3, '29042802800': 3, '29042802830': 3, '29042802860': 3, '2904280290': 2, '303830110': 2, '303830113': 1, '303830115': 2, '303830117': 3, '303830118': 3, '303830121': 3, '303830122': 3, '303830123': 2, '303830126': 1, '303830127': 3, '303830128': 2, '30383013': 3, '303830131': 2, '303830132': 2, '303830133': 2, '303830138': 3, '303830139': 1, '30383014': 3, '303830141': 3, '303830143': 2, '303830144': 3, '303830146': 2, '303830147': 3, '303830148': 2, '303830149': 0, '30383015': 2, '303830151': 3, '303830155': 1, '303830156': 3, '303830157': 3, '303830158': 3, '303830159': 2, '30383016': 3, '303830160': 2, '303830161': 2, '303830162': 3, '303830166': 3, '303830167': 2, '303830169': 2, '303830171': 3, '303830174': 3, '303830175': 2, '303830178': 2, '303830182': 3, '303830183': 2, '303830184': 3, '303830210': 3, '303830211': 3, '303830212': 3, '303830216': 2, '303830217': 3, '303830218': 2, '30383022': 2, '303830220': 3, '303830221': 3, '303830223': 3, '303830224': 2, '303830225': 2, '303830227': 3, '303830229': 2, '30383023': 1, '303830234': 3, '303830236': 3, '303830239': 3, '303830240': 3, '303830241': 3, '303830242': 3, '303830245': 3, '303830246': 2, '303830247': 3, '303830249': 3, '30383025': 2, '303830250': 2, '303830255': 3, '303830258': 3, '303830259': 3, '303830263': 3, '303830269': 2, '303830270': 3, '303830273': 3, '303830274': 3, '303830278': 2, '30383028': 3, '3100621001': 3, '3100621002': 3, '3100621003': 3, '3100621004': 2, '3100621005': 3, '3100621007': 3, '3100621009': 2, '3100621010': 3, '3100621011': 3, '3100621012': 2, '3100621013': 3, '3100621014': 3, '3100621016': 3, '3100621018': 2, '3100621019': 2, '3100621020': 2, '3100621022': 2, '3100621023': 3, '3100621024': 3, '3100621025': 2, '3100621026': 3, '3100621027': 3, '3100621028': 3, '3100621030': 2, '3100621031': 3, '3100621032': 2, '3100621033': 3, '3100621034': 2, '3100621035': 2, '3100621037': 1, '3100621039': 3, '3100621040': 3, '3100621041': 3, '3100621042': 2, '3100621043': 3, '3100621045': 3, '3100621046': 3, '3100621047': 3, '3100621048': 3, '3100621049': 3, '3100621051': 2, '3100621052': 2, '3100621053': 3, '3100621055': 3, '3100621057': 3, '3100621058': 3, '3100621059': 3, '3100621061': 2, '3100621062': 2, '3100621063': 3, '3100621064': 3, '3100622001': 2, '3100622002': 3, '3100622003': 3, '3100622006': 2, '3100622007': 3, '3100622008': 3, '3100622009': 2, '3100622011': 3, '3100622013': 3, '3100622015': 3, '3100622019': 2, '3100622020': 2, '3100622021': 2, '3100622023': 3, '3100622024': 2, '3100622026': 2, '3100622027': 2, '3100622033': 2, '3100622034': 3, '3100622036': 3, '3100622037': 2, '3100622038': 3, '3100622040': 3, '3100622041': 3, '3100622042': 3, '3100622043': 3, '3100622044': 2, '3100622045': 3, '3100622047': 3, '3100622048': 3, '3100622049': 2, '3100622051': 3, '3100622053': 2, '3100622054': 3, '3100622057': 2, '3100631001': 3, '3100631002': 3, '3100631003': 2, '3100631004': 3, '3100631005': 2, '3100631006': 3, '3100631008': 3, '3100631009': 3, '3100631010': 3, '3100631011': 3, '3100631013': 2, '3100631014': 2, '3100631015': 2, '3100631016': 3, '3100631018': 2, '3100631019': 3, '3100631022': 2, '3100631023': 2, '3100631025': 3, '3100631026': 3, '3100631027': 2, '3100631029': 3, '3100631032': 3, '3100631035': 3, '3100631037': 3, '3100631042': 2, '3100631043': 3, '3100631044': 3, '3100631045': 3, '3100631046': 3, '3100631047': 3, '3100631048': 2, '3100631049': 2, '3100631051': 3, '3100631052': 3, '3100631053': 2, '3100631054': 3, '3100631055': 2, '3100631056': 3, '3100631057': 2, '3100631058': 3, '3100631059': 3, '3100631062': 3, '3100632001': 2, '3100632002': 3, '3100632003': 2, '3100632004': 3, '3100632007': 3, '3100632008': 2, '3100632011': 2, '3100632012': 2, '3100632015': 3, '3100632016': 2, '3100632017': 3, '3100632018': 2, '3100632019': 3, '3100632021': 2, '3100632023': 3, '3100632024': 3, '3100632025': 3, '3100632026': 2, '3100632027': 3, '3100632030': 2, '3100632031': 3, '3100632039': 2, '3100632041': 3, '3100632042': 3, '3100632043': 3, '3100632044': 3, '3100632045': 2, '3100641002': 2, '3100641003': 1, '3100641004': 1, '3100641006': 1, '3100641007': 2, '3100641008': 2, '3100641023': 1, '3100642002': 3, '3100642003': 2, '3100642005': 2, '3100642006': 2, '3100642007': 1, '3100642008': 3, '3100642009': 3, '3100642011': 3, '3100642012': 2, '3100642013': 3, '3100642015': 2, '3100642017': 1, '3100642019': 3, '3100642020': 3, '3100642021': 2, '3100642022': 2, '3100642024': 3, '3100642025': 2, '3100642026': 2, '3100642027': 2, '3100642028': 2, '3100642030': 2, '3100642031': 2, '3100642032': 2, '3100642033': 3, '3100642034': 2, '3100642035': 2, '3100642036': 1, '3100642037': 2, '3100642038': 2, '3100642040': 2, '3100642045': 2, '3100642047': 3, '3100642052': 2, '3100642054': 3, '3100642055': 1, '3100642056': 3, '3100642057': 2, '3100642058': 2, '3100642060': 2, '3100642061': 2, '3100642063': 2, '3100642064': 2, '3100642066': 3, '3100642069': 2, '3100642070': 2, '3100661002': 2, '3100661007': 3, '3100661009': 2, '3100661015': 2, '3100661016': 3, '3100661022': 2, '3100661023': 2, '3100661024': 2, '3100661025': 2, '3100661027': 2, '3100661028': 2, '3100661029': 3, '3100661031': 2, '3100661032': 3, '3100661033': 2, '3100661036': 2, '3100661037': 2, '3100661038': 2, '3100661040': 2, '3100661043': 2, '3100661044': 2, '3100661046': 3, '3100661049': 2, '3100661050': 2, '3100662014': 3, '3100662015': 3, '3100662016': 2, '3100662017': 2, '3100662020': 3, '3100662022': 2, '3100662023': 2, '3100662026': 3, '3100662029': 2, '3100662032': 2, '3100662035': 2, '3100662036': 2, '3100662037': 1, '3100662045': 3, '3100662046': 2, '3100662048': 3, '3100662049': 3, '3100662050': 2, '3100662052': 3, '3100662053': 2, '3100662055': 2, '3100681001': 2, '3100681002': 2, '3100681005': 3, '3100681006': 3, '3100681015': 1, '3100681017': 1, '3100681018': 1, '3100681042': 1, '3100681043': 2, '3100681044': 3, '3100681045': 2, '3100681046': 2, '3100682001': 2, '3100682002': 3, '3100682003': 2, '3100682007': 3, '3100682008': 2, '3100682030': 2, '3100682040': 2, '3100691005': 2, '3100691006': 2, '3100691007': 2, '3100691011': 2, '3100691012': 2, '3100691021': 2, '3100691026': 2, '3100691042': 2, '3100691045': 2, '3100691048': 2, '3100692002': 2, '3100692005': 3, '3100692006': 2, '3100692007': 2, '3100692009': 3, '3100692010': 2, '3100692011': 3, '3100692012': 2, '3100692013': 2, '3100692015': 1, '3100692016': 2, '3100692020': 2, '3100692022': 2, '3100692023': 2, '3100692024': 2, '3100692025': 2, '3100692028': 2, '3100692029': 3, '3100692032': 2, '3100692034': 3, '3100692035': 3, '3100692038': 2, '3100692039': 2, '3100692045': 3, '3100692052': 2, '3100692054': 2, '3100692055': 2, '3100692056': 2, '3100701001': 2, '3100701002': 3, '3100701004': 3, '3100701005': 3, '3100701008': 2, '3100701009': 2, '3100701010': 1, '3100701011': 2, '3100701012': 3, '3100701013': 3, '3100701014': 2, '3100701015': 2, '3100701016': 3, '3100701019': 2, '3100701021': 2, '3100701022': 2, '3100701023': 1, '3100701024': 2, '3100701029': 2, '3100701031': 3, '3100701032': 2, '3100701036': 2, '3100701043': 2, '3100701044': 2, '3100701050': 2, '3100701051': 2, '3100701056': 3, '3100701057': 2, '3100701058': 3, '3100701061': 2, '3100701063': 2, '3100701072': 3, '3100701073': 2, '3100702004': 2, '3100702005': 3, '3100702006': 2, '3100702010': 2, '3100702012': 3, '3100702013': 3, '3100702016': 3, '3100702017': 2, '3100702019': 2, '3100702020': 2, '3100702021': 2, '3100702022': 2, '3100702023': 2, '3100702024': 2, '3100702025': 3, '3100702026': 2, '3100702027': 2, '3100702028': 2, '3100702029': 2, '3100702030': 2, '3100702031': 2, '3100702033': 2, '3100702034': 2, '3100702035': 2, '3100702036': 3, '3100702037': 3, '3100702038': 1, '3100702039': 3, '3100702040': 3, '3100702041': 3, '3100702043': 3, '3100702044': 2, '3100702045': 3, '3100702046': 3, '3100702047': 3, '3100702048': 3, '3100702051': 2, '3100702052': 3, '3100702054': 2, '3100702055': 2, '3100702059': 3, '3100702060': 2, '3100702061': 2, '3100702062': 2, '3100702063': 2, '3100702064': 2, '3100702065': 3, '3100702066': 2, '3100702067': 3, '3100702068': 2, '3100711007': 2, '3100711009': 2, '3100711042': 2, '3100711043': 3, '3100711049': 2, '3100711050': 2, '3100711051': 3, '3100711052': 2, '3100712014': 2, '3100721002': 2, '3100721003': 3, '3100721004': 3, '3100721005': 2, '3100721006': 2, '3100721007': 2, '3100721008': 2, '3100721011': 2, '3100721012': 3, '3100721013': 2, '3100721014': 3, '3100721015': 3, '3100721016': 3, '3100721018': 3, '3100721019': 3, '3100721020': 3, '3100721021': 2, '3100721022': 3, '3100721023': 3, '3100721024': 3, '3100721028': 2, '3100721029': 3, '3100721030': 3, '3100721031': 1, '3100721032': 3, '3100721033': 2, '3100721034': 2, '3100721036': 2, '3100721038': 2, '3100721039': 3, '3100721040': 3, '3100721041': 3, '3100721042': 3, '3100721044': 2, '3100721045': 3, '3100721046': 3, '3100721047': 3, '3100721048': 2, '3100721049': 2, '3100721050': 2, '3100721051': 3, '3100721052': 3, '3100721053': 2, '3100721054': 3, '3100721055': 3, '3100721056': 3, '3100721057': 3, '3100721058': 2, '3100721059': 3, '3100721060': 3, '3100721062': 3, '3100721063': 3, '3100721064': 3, '3100721065': 3, '3100721066': 3, '3100721068': 3, '3100721070': 3, '3100721071': 2, '3100721072': 2, '3100722003': 2, '3100722004': 3, '3100722005': 3, '3100722006': 2, '3100722007': 3, '3100722012': 3, '3100722013': 3, '3100722014': 3, '3100722016': 3, '3100722017': 3, '3100722020': 3, '3100722021': 3, '3100722022': 3, '3100722023': 3, '3100722024': 2, '3100722025': 3, '3100722026': 3, '3100722027': 2, '3100722030': 2, '3100722031': 3, '3100722032': 2, '3100722033': 2, '3100722034': 3, '3100722036': 2, '3100722038': 3, '3100722039': 3, '3100722040': 3, '3100722042': 3, '3100722044': 3, '3100722045': 2, '3100722046': 2, '3100722047': 3, '3100722048': 2, '3100722054': 3, '3100722055': 3, '3100722057': 3, '3100722059': 3, '3100722061': 3, '3100722062': 3, '3100722063': 3, '3100722064': 3, '3100722065': 3, '3100722066': 3, '3100722067': 3, '3100722068': 3, '3100722069': 3, '3100722070': 3, '3100722072': 3, '3100722073': 3, '3100722074': 2, '3100722076': 3, '3100722077': 3, '3100722078': 3, '3100722079': 3, '3100731001': 2, '3100731006': 2, '3100731007': 2, '3100731008': 2, '3100731009': 2, '3100731011': 2, '3100731012': 3, '3100731013': 3, '3100731014': 2, '3100731025': 3, '3100731026': 3, '3100731028': 2, '3100731029': 3, '3100731030': 2, '3100731031': 2, '3100731037': 3, '3100731038': 3, '3100731050': 2, '3100731052': 3, '3100731054': 3, '3100731056': 2, '3100731057': 3, '3100731058': 3, '3100732001': 3, '3100732002': 3, '3100732003': 2, '3100732006': 3, '3100732013': 2, '3100732014': 3, '3100732015': 2, '3100732017': 2, '3100732018': 3, '3100732020': 2, '3100732021': 2, '3100732022': 2, '3100732023': 2, '3100732025': 2, '3100732027': 2, '3100732028': 3, '3100732029': 3, '3100732031': 2, '3100732036': 2, '3100732040': 3, '3100732041': 2, '3100732042': 3, '3100732067': 3, '3100741001': 2, '3100741002': 2, '3100741003': 3, '3100741004': 3, '3100741011': 3, '3100741012': 2, '3100741013': 2, '3100741014': 2, '3100741016': 3, '3100741017': 3, '3100741018': 3, '3100741019': 3, '3100741020': 3, '3100741022': 3, '3100741023': 3, '3100741024': 3, '3100741025': 3, '3100741026': 3, '3100741027': 2, '3100741028': 2, '3100741029': 3, '3100741030': 2, '3100741032': 3, '3100741034': 3, '3100741035': 3, '3100741036': 3, '3100741037': 2, '3100741038': 3, '3100741039': 3, '3100741042': 3, '3100741043': 2, '3100741044': 3, '3100741045': 3, '3100741047': 3, '3100741049': 2, '3100741053': 2, '3100741054': 2, '3100741056': 2, '3100741057': 3, '3100741058': 3, '3100741059': 3, '3100741060': 3, '3100741061': 3, '3100741063': 3, '3100741064': 2, '3100741065': 3, '3100741066': 1, '3100741068': 2, '3100741069': 3, '3100741070': 3, '3100741071': 3, '3100741072': 3, '3100741073': 2, '3100741074': 3, '3100741075': 2, '3100741076': 3, '3100741077': 3, '3100741079': 3, '3100742001': 2, '3100742003': 2, '3100742004': 2, '3100742005': 2, '3100742007': 2, '3100742010': 2, '3100742011': 3, '3100742012': 3, '3100742013': 3, '3100742014': 2, '3100742015': 2, '3100742016': 2, '3100742018': 3, '3100742020': 2, '3100742021': 2, '3100742022': 3, '3100742023': 2, '3100742024': 3, '3100742025': 2, '3100742027': 2, '3100742028': 3, '3100742033': 3, '3100742034': 2, '3100742037': 2, '3100742038': 2, '3100742041': 3, '3100742042': 3, '3100742044': 2, '3100742045': 3, '3100742046': 2, '3100742047': 2, '3100742048': 2, '3100742050': 2, '3100742051': 2, '3100742052': 2, '3100742053': 2, '3100742054': 2, '3100742055': 2, '3100742056': 2, '3100742057': 3, '3100742058': 1, '3100742059': 3, '3100742060': 3, '3100742061': 2, '3100742062': 2, '3100742063': 2, '3100742065': 2, '3100742067': 3, '3100742068': 3, '3100751003': 2, '3100751004': 2, '3100751005': 2, '3100751006': 1, '3100751007': 0, '3100751008': 1, '3100751009': 3, '3100751010': 0, '3100751011': 3, '3100751012': 1, '3100751014': 2, '3100751015': 2, '3100751016': 2, '3100751017': 2, '3100751018': 3, '3100751019': 1, '3100751020': 3, '3100751021': 2, '3100751022': 2, '3100751024': 3, '3100751026': 2, '3100751027': 2, '3100751028': 2, '3100751032': 3, '3100751033': 2, '3100751034': 2, '3100751035': 2, '3100751037': 2, '3100751039': 2, '3100751040': 3, '3100751041': 2, '3100751043': 3, '3100751044': 3, '3100751045': 2, '3100751048': 2, '3100751050': 2, '3100751055': 3, '3100751056': 1, '3100751057': 1, '3100751058': 2, '3100751059': 2, '3100751063': 2, '3100751064': 2, '3100751065': 2, '3100751068': 3, '3100751069': 2, '3100751070': 2, '3100751072': 2, '3100751073': 3, '3100751074': 2, '3100751075': 3, '3100751076': 2, '3100751077': 2, '3100751078': 2, '3100751079': 2, '3100752001': 2, '3100752002': 3, '3100752003': 2, '3100752004': 2, '3100752005': 2, '3100752007': 2, '3100752008': 2, '3100752009': 2, '3100752010': 2, '3100752012': 2, '3100752014': 1, '3100752015': 3, '3100752016': 2, '3100752017': 2, '3100752018': 3, '3100752019': 3, '3100752020': 2, '3100752021': 1, '3100752022': 2, '3100752023': 2, '3100752026': 2, '3100752027': 2, '3100752029': 2, '3100752030': 1, '3100752032': 2, '3100752034': 3, '3100752035': 2, '3100752036': 2, '3100752037': 1, '3100752038': 2, '3100752039': 2, '3100752040': 3, '3100752041': 3, '3100752042': 2, '3100752043': 2, '3100752044': 3, '3100752045': 3, '3100752046': 2, '3100752047': 2, '3100752048': 1, '3100752049': 2, '3100752050': 3, '3100752051': 1, '3100752052': 3, '3100752054': 2, '3100752055': 1, '3100752056': 2, '3100752057': 2, '3100752058': 3, '3100752059': 2, '3100752060': 2, '3100752061': 2, '3100752063': 2, '3100752068': 2, '3100761003': 1, '3100761004': 3, '3100761005': 1, '3100761007': 2, '3100761008': 1, '3100761013': 2, '3100761014': 2, '3100761015': 2, '3100761016': 2, '3100761017': 2, '3100761019': 2, '3100761020': 3, '3100761021': 3, '3100761023': 2, '3100761027': 3, '3100761028': 3, '3100761029': 3, '3100761030': 2, '3100761031': 2, '3100761034': 2, '3100761042': 2, '3100761046': 2, '3100761047': 2, '3100761048': 3, '3100761049': 2, '3100761050': 2, '3100761051': 2, '3100761056': 2, '3100761062': 2, '3100761063': 3, '3100762003': 2, '3100762004': 1, '3100762005': 2, '3100762007': 3, '3100762012': 2, '3100762013': 2, '3100762016': 2, '3100762027': 1, '3100762029': 3, '3100762030': 1, '3100762052': 2, '3100762053': 2, '3100762055': 1, '3100771001': 1, '3100771002': 2, '3100771003': 3, '3100771005': 2, '3100771007': 1, '3100771008': 2, '3100771009': 2, '3100771012': 3, '3100771014': 2, '3100771016': 2, '3100771018': 2, '3100771019': 2, '3100771020': 2, '3100771021': 2, '3100771022': 2, '3100771024': 2, '3100771027': 2, '3100771028': 2, '3100771029': 2, '3100771030': 2, '3100771031': 2, '3100771032': 2, '3100771033': 2, '3100771034': 2, '3100771036': 2, '3100771037': 2, '3100771039': 2, '3100771040': 2, '3100771041': 3, '3100771042': 3, '3100771043': 2, '3100771046': 2, '3100771047': 2, '3100771048': 3, '3100771049': 2, '3100771050': 3, '3100771052': 2, '3100771054': 2, '3100771055': 2, '3100771056': 3, '3100771057': 3, '3100771058': 3, '3100771059': 3, '3100771062': 2, '3100771063': 3, '3100771064': 2, '3100771065': 2, '3100771066': 2, '3100771067': 2, '3100771068': 2, '3100771069': 2, '3100771071': 2, '3100771072': 3, '3100771073': 2, '3100771075': 2, '3100771076': 3, '3100771077': 3, '3100771078': 2, '3100771080': 2, '3100771081': 3, '3100772002': 3, '3100772004': 2, '3100772005': 2, '3100772006': 2, '3100772007': 3, '3100772008': 3, '3100772009': 2, '3100772010': 3, '3100772011': 3, '3100772013': 2, '3100772014': 3, '3100772015': 3, '3100772018': 3, '3100772019': 3, '3100772020': 2, '3100772021': 3, '3100772022': 3, '3100772023': 2, '3100772024': 3, '3100772025': 2, '3100772026': 3, '3100772027': 3, '3100772028': 3, '3100772029': 2, '3100772031': 2, '3100772032': 3, '3100772033': 3, '3100772034': 2, '3100772035': 2, '3100772036': 3, '3100772037': 3, '3100772039': 3, '3100772040': 3, '3100772041': 3, '3100772042': 3, '3100772043': 2, '3100772045': 2, '3100772046': 2, '3100772048': 2, '3100772050': 2, '3100772051': 1, '3100772052': 2, '3100772053': 3, '3100772054': 3, '3100772055': 3, '3100772056': 3, '3100772058': 3, '3100772059': 3, '3100772063': 2, '3100772065': 3, '3100772066': 2, '3100772067': 2, '3100772068': 2, '3100772069': 3, '3100781001': 2, '3100781002': 1, '3100781004': 2, '3100781006': 3, '3100781007': 1, '3100781008': 3, '3100781009': 3, '3100781010': 2, '3100781011': 3, '3100781013': 2, '3100781015': 2, '3100781016': 3, '3100781017': 2, '3100781019': 3, '3100781020': 3, '3100781021': 3, '3100781023': 3, '3100781024': 3, '3100781027': 3, '3100781029': 3, '3100781030': 3, '3100781031': 3, '3100781032': 2, '3100781033': 2, '3100781034': 1, '3100781036': 3, '3100781038': 2, '3100781040': 3, '3100781041': 3, '3100781043': 3, '3100781044': 2, '3100781046': 3, '3100781047': 3, '3100781048': 3, '3100781051': 3, '3100781052': 3, '3100781053': 3, '3100781054': 3, '3100781055': 3, '3100781056': 3, '3100781057': 2, '3100781058': 3, '3100781059': 2, '3100781061': 3, '3100781062': 3, '3100781064': 3, '3100781065': 2, '3100781066': 2, '3100781068': 2, '3100781069': 3, '3100781070': 2, '3100781071': 2, '3100781073': 2, '3100781074': 3, '3100781075': 3, '3100781076': 3, '3100781078': 3, '3100781079': 3, '3100781080': 3, '3100781081': 3, '3100782001': 2, '3100782003': 3, '3100782004': 3, '3100782005': 3, '3100782006': 2, '3100782008': 3, '3100782010': 2, '3100782011': 3, '3100782012': 3, '3100782013': 2, '3100782014': 3, '3100782015': 3, '3100782016': 3, '3100782017': 3, '3100782018': 2, '3100782019': 3, '3100782021': 3, '3100782022': 3, '3100782023': 3, '3100782024': 3, '3100782025': 3, '3100782026': 2, '3100782027': 3, '3100782028': 2, '3100782031': 2, '3100782032': 3, '3100782033': 3, '3100782035': 2, '3100782036': 2, '3100782037': 2, '3100782038': 3, '3100782039': 2, '3100782042': 3, '3100782043': 3, '3100782045': 3, '3100782046': 3, '3100782047': 3, '3100782049': 3, '3100782050': 2, '3100782053': 3, '3100782054': 2, '3100782055': 2, '3100782057': 3, '3100782058': 3, '3100782059': 2, '3100782061': 3, '3100782062': 3, '3100782063': 2, '3100782064': 3, '3100782065': 3, '3100782066': 3, '3100782067': 1, '3100782068': 3, '3100782069': 2, '3100782071': 2, '3100782072': 2, '3100791004': 3, '3100791006': 2, '3100791007': 2, '3100791008': 3, '3100791016': 2, '3100791018': 2, '3100791020': 3, '3100791021': 3, '3100791026': 3, '3100791028': 2, '3100791031': 3, '3100791033': 3, '3100791034': 3, '3100791035': 3, '3100791042': 3, '3100791044': 2, '3100791045': 3, '3100791046': 2, '3100791047': 3, '3100791049': 2, '3100791050': 2, '3100791052': 3, '3100791054': 2, '3100791056': 2, '3100791058': 1, '3100791059': 3, '3100791060': 3, '3100791061': 3, '3100791062': 2, '3100791063': 2, '3100791064': 3, '3100791065': 2, '3100791066': 2, '3100791067': 2, '3100791069': 2, '3100791070': 2, '3100791071': 3, '3100791072': 2, '3100791073': 2, '3100792002': 2, '3100792003': 2, '3100792004': 2, '3100792005': 2, '3100792006': 2, '3100792007': 3, '3100792008': 2, '3100792009': 2, '3100792010': 2, '3100792011': 2, '3100792013': 2, '3100792014': 3, '3100792015': 2, '3100792016': 2, '3100792019': 3, '3100792020': 2, '3100792021': 2, '3100792022': 2, '3100792023': 2, '3100792024': 2, '3100792025': 2, '3100792027': 3, '3100792028': 2, '3100792030': 2, '3100792031': 3, '3100792032': 2, '3100792033': 2, '3100792035': 2, '3100792036': 2, '3100792037': 2, '3100792038': 2, '3100792039': 2, '3100792040': 2, '3100792041': 2, '3100792042': 3, '3100792043': 2, '3100792044': 2, '3100792045': 1, '3100792046': 3, '3100792048': 3, '3100792050': 2, '3100792051': 2, '3100792052': 2, '3100792053': 2, '3100792057': 2, '3100792058': 2, '3100792060': 2, '3100792069': 2, '3100801006': 2, '3100802001': 3, '3100802028': 3, '3100811002': 2, '3100811018': 2, '3100811027': 2, '3100811034': 2, '3100811035': 2, '3100811036': 3, '3100811037': 2, '3100811038': 2, '3100811039': 2, '3100811040': 3, '3100811041': 3, '3100811042': 2, '3100811043': 2, '3100811045': 2, '3100811046': 2, '3100811047': 2, '3100811050': 3, '3100811051': 2, '3100811053': 2, '3100811054': 2, '3100811055': 2, '3100811056': 3, '3100811059': 2, '3100811060': 3, '3100811061': 2, '3100811063': 3, '3100811068': 2, '3100811075': 2, '3100812003': 3, '3100812004': 2, '3100812005': 3, '3100812006': 3, '3100812007': 2, '3100812008': 3, '3100812013': 3, '3100812014': 2, '3100812016': 2, '3100812017': 3, '3100812018': 2, '3100812019': 2, '3100812020': 2, '3100812021': 2, '3100812026': 2, '3100812027': 2, '3100812028': 1, '3100812040': 2, '3100821004': 2, '3100821015': 2, '3100821016': 3, '3100821019': 2, '3100821020': 3, '3100821021': 2, '3100821022': 1, '3100821030': 3, '3100821031': 2, '3100821032': 1, '3100821033': 0, '3100821034': 3, '3100821035': 3, '3100821036': 3, '3100821037': 2, '3100821038': 1, '3100821039': 2, '3100821040': 2, '3100821041': 2, '3100821042': 3, '3100821045': 2, '3100821046': 2, '3100821047': 2, '3100821048': 1, '3100821049': 3, '3100821051': 3, '3100821052': 0, '3100821054': 2, '3100821055': 2, '3100821057': 1, '3100821067': 2, '3100821068': 3, '3100821069': 0, '3100821075': 0, '3100822001': 2, '3100822011': 1, '3100822012': 2, '3100822014': 2, '3100822030': 3, '3100822031': 0, '3100822044': 3, '3100822050': 3, '3100822051': 3, '3100822057': 3, '3100822058': 3, '3100822059': 2, '3100822064': 3, '3100822065': 1, '3100822066': 0, '3100822067': 2, '3100822068': 2, '3100822069': 3, '3100822070': 2, '3100822075': 3, '3100822080': 2, '3100831003': 2, '3100831004': 3, '3100831006': 2, '3100831007': 3, '3100831008': 3, '3100831010': 2, '3100831011': 2, '3100831013': 2, '3100831014': 2, '3100831015': 2, '3100831016': 2, '3100831018': 2, '3100831019': 3, '3100831020': 3, '3100831022': 3, '3100831024': 2, '3100831026': 3, '3100831027': 3, '3100831028': 2, '3100831029': 2, '3100831032': 2, '3100831033': 2, '3100831035': 3, '3100831036': 2, '3100831037': 2, '3100831044': 2, '3100831045': 3, '3100831046': 3, '3100831047': 3, '3344630110': 3, '33446301100': 2, '33446301101': 2, '33446301103': 3, '33446301104': 2, '33446301107': 3, '3344630112': 3, '3344630113': 2, '3344630115': 3, '3344630116': 2, '3344630117': 3, '3344630119': 2, '334463012': 3, '3344630120': 3, '3344630121': 1, '3344630127': 2, '3344630130': 3, '3344630131': 1, '3344630132': 2, '3344630133': 2, '3344630136': 2, '3344630139': 2, '334463014': 2, '3344630140': 3, '3344630141': 2, '3344630142': 3, '3344630143': 3, '3344630146': 2, '3344630147': 2, '3344630148': 3, '3344630149': 3, '3344630150': 2, '3344630151': 2, '3344630153': 2, '3344630156': 2, '3344630161': 3, '3344630162': 1, '3344630163': 3, '3344630164': 2, '3344630166': 2, '3344630170': 3, '3344630171': 2, '3344630172': 2, '3344630173': 3, '3344630176': 3, '3344630179': 2, '3344630180': 2, '3344630181': 2, '3344630182': 2, '3344630184': 3, '3344630185': 2, '3344630186': 2, '3344630188': 3, '3344630189': 3, '334463019': 2, '3344630190': 3, '3344630196': 2, '3344630197': 2, '3344630198': 3, '3344630199': 2, '334463021': 3, '3344630210': 2, '3344630211': 1, '3344630213': 3, '3344630215': 3, '3344630216': 3, '3344630219': 3, '334463022': 2, '3344630220': 3, '3344630221': 2, '3344630224': 2, '3344630225': 3, '3344630226': 2, '3344630231': 2, '3344630232': 2, '3344630233': 2, '3344630236': 3, '3344630238': 2, '3344630240': 3, '3344630241': 3, '3344630242': 3, '3344630243': 3, '3344630245': 3, '3344630247': 3, '3344630248': 2, '334463025': 2, '3344630251': 3, '3344630252': 2, '3344630255': 2, '3344630257': 3, '334463026': 2, '3344630260': 3, '3344630262': 2, '3344630264': 2, '3344630265': 3, '3344630266': 2, '3344630267': 2, '334463027': 2, '3344630270': 2, '3344630271': 3, '3344630273': 2, '3344630276': 2, '3344630278': 3, '334463028': 3, '3344630280': 2, '3344630281': 2, '3344630282': 1, '334463029': 3, '33702101100': 3, '33702101110': 3, '33702101130': 3, '33702101140': 3, '33702101150': 3, '33702101180': 2, '33702101200': 3, '33702101210': 3, '33702101250': 2, '33702101260': 3, '33702101270': 3, '33702101280': 3, '33702101290': 2, '33702101300': 3, '33702101340': 3, '33702101350': 3, '33702101360': 3, '33702101370': 3, '33702101410': 3, '33702101430': 2, '33702101450': 2, '33702101460': 3, '33702101470': 2, '33702101480': 2, '33702101490': 2, '3370210150': 2, '33702101500': 3, '33702101530': 3, '33702101540': 2, '33702101550': 3, '33702101580': 3, '33702101590': 3, '33702101600': 2, '33702101620': 2, '33702101630': 3, '33702101640': 3, '33702101650': 3, '33702101660': 3, '33702101700': 3, '33702101710': 3, '33702101730': 3, '33702101740': 3, '33702101750': 3, '33702101760': 3, '3370210180': 3, '33702102100': 3, '33702102110': 3, '33702102130': 2, '33702102140': 2, '33702102160': 3, '33702102170': 3, '33702102180': 3, '33702102190': 3, '33702102200': 3, '33702102220': 2, '33702102230': 3, '33702102240': 3, '33702102250': 3, '33702102280': 3, '3370210230': 3, '33702102300': 3, '33702102310': 3, '33702102330': 3, '33702102350': 3, '33702102390': 3, '3370210240': 3, '33702102400': 3, '33702102420': 3, '33702102430': 3, '33702102470': 2, '33702102500': 3, '33702102530': 3, '33702102540': 3, '33702102550': 3, '33702102570': 3, '33702102580': 3, '33702102590': 3, '3370210260': 3, '33702102600': 3, '33702102640': 2, '33702102670': 3, '33702102690': 3, '33702102710': 3, '33702102740': 3, '3370210280': 3, '33702102820': 3, '33702102840': 3, '33702102850': 3, '33702102870': 3, '33702102880': 3, '342227010': 3, '342227011': 3, '3422270111': 1, '3422270112': 3, '3422270115': 2, '3422270116': 3, '3422270117': 2, '3422270118': 2, '3422270121': 3, '3422270122': 3, '3422270123': 3, '3422270126': 2, '3422270127': 3, '3422270128': 3, '3422270129': 1, '342227013': 3, '3422270130': 2, '3422270131': 2, '3422270133': 3, '3422270134': 3, '3422270135': 2, '3422270138': 3, '3422270139': 3, '3422270140': 3, '3422270141': 2, '3422270142': 2, '3422270143': 3, '3422270144': 3, '3422270149': 2, '3422270151': 2, '3422270152': 2, '3422270153': 2, '3422270154': 3, '3422270155': 2, '3422270157': 2, '3422270158': 2, '3422270160': 2, '3422270165': 3, '3422270166': 3, '3422270167': 1, '3422270168': 3, '3422270169': 3, '3422270171': 2, '3422270172': 3, '342227020': 3, '342227021': 3, '3422270210': 3, '3422270211': 3, '3422270212': 2, '3422270213': 3, '3422270215': 2, '3422270216': 3, '3422270217': 3, '3422270219': 2, '3422270220': 2, '3422270221': 2, '3422270222': 3, '3422270223': 3, '3422270224': 3, '3422270225': 2, '3422270227': 2, '342227023': 3, '3422270230': 2, '3422270238': 3, '3422270239': 3, '342227024': 3, '3422270240': 2, '3422270241': 3, '3422270242': 3, '3422270244': 2, '3422270245': 3, '3422270246': 2, '3422270247': 3, '3422270249': 2, '342227025': 3, '3422270250': 3, '3422270251': 2, '3422270252': 3, '3422270253': 3, '3422270254': 3, '3422270255': 3, '3422270256': 3, '3422270257': 2, '3422270261': 3, '3422270262': 2, '3422270263': 3, '3422270264': 3, '3422270267': 3, '3422270268': 3, '3422270269': 3, '342227027': 3, '3422270274': 2, '3422270278': 3, '3422270279': 3, '3422270280': 3, '3422270281': 3, '342227029': 3, '350361011': 2, '3503610110': 3, '3503610111': 3, '3503610112': 3, '3503610113': 2, '3503610114': 2, '3503610115': 2, '3503610116': 3, '3503610117': 3, '3503610118': 3, '3503610119': 3, '350361012': 3, '3503610120': 2, '3503610121': 3, '3503610122': 3, '3503610123': 3, '3503610124': 3, '3503610125': 3, '3503610126': 3, '3503610127': 2, '3503610128': 3, '3503610129': 2, '350361013': 2, '3503610130': 3, '3503610131': 3, '3503610132': 3, '3503610133': 2, '3503610134': 3, '3503610135': 3, '3503610136': 3, '3503610137': 2, '3503610138': 3, '3503610139': 2, '350361014': 3, '3503610140': 3, '3503610141': 3, '3503610142': 2, '3503610143': 3, '3503610144': 3, '3503610145': 3, '3503610146': 3, '3503610147': 3, '3503610148': 3, '3503610149': 2, '350361015': 3, '3503610150': 3, '3503610151': 3, '3503610152': 3, '3503610154': 3, '3503610156': 3, '3503610157': 2, '3503610158': 1, '350361016': 2, '3503610163': 3, '3503610168': 0, '350361017': 3, '350361019': 3, '350361021': 3, '3503610210': 3, '3503610212': 3, '3503610213': 2, '3503610214': 2, '3503610217': 3, '350361022': 2, '3503610223': 3, '3503610224': 3, '3503610225': 3, '3503610226': 3, '3503610227': 3, '3503610228': 3, '350361023': 3, '3503610230': 3, '3503610231': 3, '3503610233': 3, '3503610234': 2, '3503610235': 3, '3503610236': 3, '3503610237': 3, '3503610238': 3, '350361024': 3, '3503610240': 3, '3503610241': 2, '3503610242': 3, '3503610245': 3, '3503610246': 3, '3503610248': 3, '3503610250': 3, '3503610251': 2, '3503610252': 3, '3503610253': 3, '3503610254': 3, '3503610255': 2, '3503610256': 3, '3503610257': 3, '350361026': 3, '3503610260': 3, '3503610261': 3, '3503610264': 3, '3503610265': 2, '3503610266': 3, '3503610267': 3, '3503610268': 3, '3503610269': 2, '3503610270': 3, '3503610272': 2, '3503610273': 3, '3503610275': 2, '3503610276': 2, '3503610277': 3, '3503610278': 2, '3503610279': 3, '350361028': 1, '350361029': 2, '4000181002': 2, '4000181004': 1, '4000181005': 2, '4000181006': 2, '4000181007': 2, '4000181008': 2, '4000181010': 2, '4000181011': 2, '4000181012': 2, '4000181013': 3, '4000181014': 3, '4000181015': 1, '4000181016': 2, '4000181017': 2, '4000181019': 2, '4000181020': 3, '4000181022': 3, '4000181023': 2, '4000181024': 3, '4000181026': 3, '4000181027': 2, '4000181028': 3, '4000181029': 2, '4000181030': 3, '4000181031': 2, '4000181032': 2, '4000181033': 3, '4000181035': 3, '4000181036': 2, '4000181037': 2, '4000181039': 2, '4000181041': 3, '4000181042': 3, '4000181043': 2, '4000181044': 3, '4000181045': 2, '4000181046': 2, '4000181047': 2, '4000181048': 3, '4000181049': 3, '4000181053': 2, '4000181054': 2, '4000181055': 2, '4000181056': 3, '4000181057': 2, '4000181060': 2, '4000181061': 3, '4000181062': 2, '4000181063': 2, '4000181064': 2, '4000181065': 2, '4000181066': 3, '4000181067': 2, '4000181068': 2, '4000181069': 2, '4000181070': 3, '4000181072': 2, '4000181073': 2, '4000181074': 2, '4000181075': 2, '4000181076': 2, '4000181077': 2, '4000181078': 3, '4000181079': 2, '4000181080': 3, '4000182003': 3, '4000182004': 2, '4000182005': 2, '4000182006': 2, '4000182007': 3, '4000182008': 2, '4000182009': 3, '4000182010': 3, '4000182011': 2, '4000182013': 3, '4000182014': 3, '4000182015': 2, '4000182016': 2, '4000182017': 3, '4000182018': 2, '4000182020': 3, '4000182022': 2, '4000182024': 2, '4000182025': 3, '4000182026': 2, '4000182027': 2, '4000182028': 2, '4000182029': 2, '4000182030': 3, '4000182031': 2, '4000182032': 3, '4000182033': 2, '4000182035': 1, '4000182036': 2, '4000182037': 2, '4000182038': 2, '4000182039': 2, '4000182040': 3, '4000182041': 3, '4000182042': 3, '4000182044': 3, '4000182046': 2, '4000182047': 2, '4000182049': 3, '4000182050': 2, '4000182051': 2, '4000182053': 2, '4000182054': 2, '4000182055': 2, '4000182058': 2, '4000182059': 3, '4000182060': 3, '4000182062': 2, '4000182063': 2, '4000182064': 3, '4000182067': 2, '4000182068': 2, '4000182069': 2, '4000221001': 2, '4000221002': 3, '4000221006': 2, '4000221008': 3, '4000221009': 2, '4000221010': 2, '4000221011': 2, '4000221013': 2, '4000221014': 2, '4000221015': 2, '4000221016': 3, '4000221017': 3, '4000221018': 2, '4000221024': 2, '4000221033': 2, '4000221034': 2, '4000221035': 2, '4000221036': 2, '4000221040': 1, '4000221041': 2, '4000221042': 3, '4000221054': 2, '4000221055': 2, '4000221061': 3, '4000221062': 3, '4000221064': 2, '4000221065': 2, '4000221066': 2, '4000221067': 2, '4000221071': 2, '4000221072': 2, '4000222001': 3, '4000222003': 2, '4000222004': 3, '4000222007': 2, '4000222012': 3, '4000222013': 2, '4000222014': 2, '4000222015': 2, '4000222017': 2, '4000222031': 1, '4000222032': 0, '4000222035': 2, '4000222036': 1, '4000222038': 3, '4000222039': 3, '4000222040': 2, '4000222041': 1, '4000222042': 2, '4000222044': 2, '4000222045': 2, '4000222046': 3, '4000222051': 2, '4000222052': 2, '4000222054': 3, '4000222056': 2, '4000222057': 2, '4000222068': 2, '4000222069': 2, '4000222070': 3, '4000231001': 3, '4000231008': 2, '4000231010': 2, '4000231011': 3, '4000231012': 3, '4000231013': 2, '4000231014': 2, '4000231021': 3, '4000231032': 3, '4000231033': 2, '4000231034': 2, '4000231037': 3, '4000231038': 3, '4000231047': 2, '4000231049': 2, '4000231052': 2, '4000231060': 2, '4000231061': 2, '4000231063': 2, '4000231065': 3, '4000231070': 3, '4000231071': 2, '4000231073': 2, '4000231074': 3, '4000231081': 3, '4000232001': 2, '4000232004': 2, '4000232005': 2, '4000232006': 2, '4000232007': 3, '4000232010': 2, '4000232016': 3, '4000232017': 3, '4000232018': 3, '4000232022': 2, '4000232024': 2, '4000232027': 3, '4000232034': 2, '4000232035': 3, '4000232036': 3, '4000232037': 2, '4000232038': 2, '4000232042': 2, '4000232044': 3, '4000232045': 3, '4000232048': 2, '4000232051': 2, '4000232054': 2, '4000232059': 2, '4000232062': 2, '4000232065': 2, '4000232068': 3, '4000232071': 1, '4000232072': 2, '4000301002': 2, '4000301003': 2, '4000301005': 1, '4000301006': 1, '4000301007': 2, '4000301008': 2, '4000301010': 1, '4000301011': 0, '4000301012': 2, '4000301013': 2, '4000301014': 2, '4000301015': 2, '4000301016': 2, '4000301018': 2, '4000301019': 2, '4000301020': 2, '4000301021': 1, '4000301022': 3, '4000301023': 3, '4000301025': 3, '4000301026': 2, '4000301027': 2, '4000301028': 0, '4000301030': 0, '4000301031': 2, '4000301032': 3, '4000301034': 2, '4000301038': 3, '4000301039': 3, '4000301040': 3, '4000301041': 3, '4000301042': 0, '4000301043': 3, '4000301044': 2, '4000301045': 3, '4000301047': 3, '4000301049': 1, '4000301052': 3, '4000301053': 2, '4000301054': 2, '4000301055': 1, '4000301056': 2, '4000301057': 2, '4000301058': 2, '4000301059': 2, '4000301060': 1, '4000301061': 2, '4000301062': 2, '4000301063': 3, '4000301064': 2, '4000301065': 1, '4000301066': 1, '4000301067': 1, '4000301068': 2, '4000301069': 2, '4000301070': 0, '4000301071': 2, '4000301072': 3, '4000301073': 3, '4000301074': 2, '4000301076': 2, '4000301079': 2, '4000331001': 2, '4000331002': 2, '4000331003': 3, '4000331004': 3, '4000331005': 3, '4000331006': 3, '4000331007': 2, '4000331008': 3, '4000331011': 3, '4000331012': 3, '4000331013': 2, '4000331015': 2, '4000331017': 2, '4000331019': 3, '4000331020': 3, '4000331021': 2, '4000331022': 2, '4000331023': 3, '4000331025': 3, '4000331027': 3, '4000331029': 2, '4000331030': 2, '4000331031': 2, '4000331032': 2, '4000331033': 3, '4000331035': 3, '4000331036': 2, '4000331037': 2, '4000331038': 3, '4000331039': 2, '4000331040': 2, '4000331041': 2, '4000331042': 3, '4000331043': 3, '4000331044': 3, '4000331045': 2, '4000331046': 2, '4000331051': 2, '4000331052': 3, '4000331053': 3, '4000331054': 2, '4000331055': 2, '4000331056': 2, '4000331057': 3, '4000331058': 2, '4000331060': 2, '4000331062': 2, '4000331063': 2, '4000331064': 2, '4000331067': 3, '4000331068': 2, '4000331069': 2, '4000332001': 2, '4000332002': 2, '4000332007': 2, '4000332008': 3, '4000332009': 2, '4000332010': 2, '4000332012': 2, '4000332013': 2, '4000332014': 3, '4000332015': 2, '4000332017': 3, '4000332019': 2, '4000332020': 2, '4000332021': 2, '4000332022': 2, '4000332023': 2, '4000332025': 3, '4000332027': 2, '4000332030': 3, '4000332031': 2, '4000332032': 2, '4000332034': 3, '4000332035': 2, '4000332036': 3, '4000332037': 3, '4000332038': 2, '4000332039': 2, '4000332041': 3, '4000332044': 3, '4000332045': 3, '4000332046': 2, '4000332048': 3, '4000332050': 3, '4000332051': 2, '4000332052': 2, '4000332057': 2, '4000332059': 2, '4000332060': 3, '4000332061': 2, '4000332062': 2, '4000332063': 3, '4000332064': 2, '4000332066': 3, '4000332067': 3, '4000332068': 3, '4000332071': 2, '4000332072': 2, '4000332073': 2, '4000332074': 3, '4000332075': 2, '4000332077': 3, '4000332078': 2, '4000332079': 3, '4000332080': 3, '4000332081': 2, '4000332082': 1, '401835011': 3, '4018350112': 2, '4018350115': 3, '4018350116': 2, '4018350118': 3, '4018350119': 2, '4018350120': 3, '4018350121': 3, '4018350122': 2, '4018350126': 2, '4018350127': 2, '401835013': 3, '4018350130': 3, '4018350132': 3, '4018350134': 3, '4018350136': 3, '4018350137': 3, '4018350138': 3, '4018350139': 3, '4018350140': 3, '4018350141': 3, '4018350143': 3, '4018350144': 2, '4018350145': 2, '4018350146': 3, '4018350147': 2, '4018350149': 3, '401835015': 1, '4018350150': 2, '4018350152': 3, '4018350156': 3, '4018350157': 3, '4018350159': 3, '4018350160': 3, '4018350161': 3, '4018350162': 3, '4018350163': 3, '4018350166': 3, '4018350167': 3, '401835017': 2, '401835018': 3, '401835021': 2, '4018350213': 3, '4018350215': 2, '4018350217': 2, '4018350219': 2, '4018350220': 3, '4018350221': 2, '4018350222': 3, '4018350223': 3, '4018350224': 2, '4018350225': 3, '4018350226': 3, '4018350227': 3, '4018350231': 2, '4018350232': 3, '4018350233': 2, '4018350234': 3, '4018350236': 3, '4018350239': 2, '401835024': 2, '4018350240': 2, '4018350241': 3, '4018350244': 3, '4018350247': 2, '4018350251': 2, '4018350254': 3, '4018350256': 3, '4018350257': 3, '4018350258': 3, '4018350259': 2, '4018350260': 3, '4018350261': 3, '4018350263': 2, '4018350268': 3, '4018350269': 3, '4018350274': 2, '4018350276': 3, '4018350277': 2, '4018350279': 2, '401835028': 3, '4018350281': 2, '4018350282': 1, '4100191001': 2, '4100191002': 2, '4100191003': 3, '4100191004': 3, '4100191006': 2, '4100191007': 2, '4100191008': 1, '4100191010': 2, '4100191012': 2, '4100191014': 2, '4100191016': 2, '4100191017': 2, '4100191018': 3, '4100191020': 3, '4100191021': 2, '4100191023': 2, '4100191024': 2, '4100191025': 2, '4100191026': 2, '4100191030': 3, '4100191031': 2, '4100191032': 2, '4100191033': 0, '4100191034': 3, '4100191035': 2, '4100191038': 2, '4100191039': 2, '4100191041': 1, '4100191042': 2, '4100191043': 2, '4100191045': 2, '4100191046': 2, '4100191052': 2, '4100191053': 2, '4100192001': 2, '4100192002': 2, '4100192003': 2, '4100192004': 2, '4100192005': 2, '4100192006': 3, '4100192007': 2, '4100192010': 1, '4100192011': 1, '4100192012': 2, '4100192013': 2, '4100192014': 3, '4100192015': 1, '4100192016': 1, '4100192019': 2, '4100192020': 2, '4100192022': 2, '4100192023': 3, '4100192024': 2, '4100192025': 3, '4100192026': 0, '4100192027': 2, '4100192028': 3, '4100192029': 0, '4100192031': 1, '4100192032': 3, '4100192033': 2, '4100192034': 2, '4100192036': 2, '4100192037': 2, '4100192038': 2, '4100192039': 2, '4100192040': 2, '4100192043': 2, '4100192044': 2, '4100192045': 2, '4100192046': 2, '4100192047': 3, '4100192048': 2, '4100192049': 1, '4100192050': 2, '4100192051': 2, '4100192052': 2, '4100192053': 1, '4100192054': 2, '4100192055': 2, '4100192056': 2, '4100192057': 3, '4100192058': 2, '4100192060': 1, '4100192061': 2, '4100192062': 3, '4100192063': 2, '4100192066': 2, '4100192068': 2, '4100201001': 3, '4100201003': 2, '4100201004': 3, '4100201005': 2, '4100201006': 2, '4100201007': 2, '4100201008': 3, '4100201009': 2, '4100201010': 3, '4100201011': 2, '4100201013': 3, '4100201014': 3, '4100201016': 2, '4100201017': 3, '4100201018': 3, '4100201020': 3, '4100201021': 2, '4100201022': 3, '4100201023': 3, '4100201024': 3, '4100201025': 3, '4100201026': 2, '4100201027': 2, '4100201030': 1, '4100201031': 3, '4100201032': 1, '4100201033': 2, '4100201034': 2, '4100201035': 3, '4100201039': 1, '4100201040': 3, '4100201041': 2, '4100201042': 3, '4100201043': 1, '4100201044': 2, '4100201045': 2, '4100201046': 2, '4100201048': 2, '4100201049': 3, '4100201051': 3, '4100201052': 2, '4100201053': 2, '4100201054': 3, '4100201055': 3, '4100201056': 2, '4100201058': 3, '4100201059': 2, '4100201060': 2, '4100201061': 0, '4100201062': 3, '4100201063': 2, '4100201064': 2, '4100201068': 3, '4100201069': 3, '4100201071': 2, '4100201072': 3, '4100201073': 3, '4100201074': 2, '4100201075': 3, '4100201076': 2, '4100201078': 3, '4100201079': 3, '4100201081': 2, '4100201082': 2, '4100202001': 2, '4100202004': 2, '4100202005': 2, '4100202006': 2, '4100202007': 3, '4100202008': 3, '4100202009': 3, '4100202010': 2, '4100202011': 2, '4100202012': 2, '4100202013': 2, '4100202014': 1, '4100202015': 3, '4100202016': 3, '4100202017': 3, '4100202018': 2, '4100202019': 3, '4100202021': 3, '4100202022': 2, '4100202023': 3, '4100202024': 2, '4100202025': 2, '4100202032': 2, '4100202037': 2, '4100202039': 2, '4100202040': 2, '4100202041': 3, '4100202042': 2, '4100202043': 3, '4100202045': 2, '4100202046': 1, '4100202048': 2, '4100202052': 2, '4100202053': 2, '4100202054': 3, '4100202055': 3, '4100202056': 2, '4100202063': 3, '4100202065': 1, '4100202067': 3, '4100202068': 2, '4100241001': 2, '4100241002': 2, '4100241003': 2, '4100241004': 2, '4100241006': 2, '4100241007': 2, '4100241008': 2, '4100241009': 2, '4100241011': 2, '4100241013': 2, '4100241016': 3, '4100241017': 2, '4100241018': 3, '4100241020': 2, '4100241029': 1, '4100241030': 2, '4100241031': 2, '4100241042': 2, '4100241045': 2, '4100241046': 3, '4100241049': 2, '4100241051': 3, '4100241052': 3, '4100241053': 3, '4100241054': 2, '4100241055': 1, '4100241056': 3, '4100241059': 1, '4100241060': 3, '4100241061': 3, '4100241062': 2, '4100241063': 3, '4100241064': 2, '4100241068': 1, '4100241069': 3, '4100241075': 3, '4100242001': 2, '4100242002': 2, '4100242003': 1, '4100242004': 3, '4100242005': 2, '4100242006': 2, '4100242008': 2, '4100242011': 2, '4100242020': 2, '4100242021': 2, '4100242029': 2, '4100242031': 2, '4100242032': 0, '4100242033': 1, '4100242034': 2, '4100242035': 1, '4100242036': 2, '4100242037': 2, '4100242038': 2, '4100242040': 2, '4100242045': 2, '4100242048': 3, '4100242050': 2, '4100242053': 2, '4100242054': 2, '4100242057': 1, '4100242059': 2, '4100242060': 2, '4100242063': 1, '4100242065': 2, '4100242066': 2, '4100242067': 2, '4100251003': 2, '4100251004': 3, '4100251005': 3, '4100251006': 1, '4100251010': 3, '4100251011': 2, '4100251012': 2, '4100251013': 2, '4100251014': 2, '4100251015': 3, '4100251016': 1, '4100251017': 2, '4100251018': 2, '4100251019': 2, '4100251020': 1, '4100251021': 1, '4100251022': 2, '4100251024': 1, '4100251026': 3, '4100251027': 1, '4100251028': 1, '4100251029': 1, '4100251030': 2, '4100251031': 2, '4100251032': 1, '4100251033': 1, '4100251034': 2, '4100251035': 2, '4100251036': 1, '4100251038': 1, '4100251039': 2, '4100251040': 2, '4100251041': 1, '4100251042': 2, '4100251044': 2, '4100251046': 1, '4100251047': 2, '4100251048': 2, '4100251049': 1, '4100251051': 2, '4100251052': 2, '4100251053': 3, '4100251054': 3, '4100251056': 2, '4100251057': 0, '4100251059': 2, '4100251060': 2, '4100251061': 1, '4100251062': 2, '4100251063': 2, '4100251064': 2, '4100251065': 2, '4100251068': 1, '4100251069': 2, '4100251070': 2, '4100252001': 2, '4100252003': 2, '4100252004': 3, '4100252005': 2, '4100252007': 3, '4100252010': 2, '4100252011': 2, '4100252012': 3, '4100252013': 2, '4100252014': 2, '4100252015': 2, '4100252016': 2, '4100252019': 2, '4100252021': 2, '4100252022': 2, '4100252023': 2, '4100252024': 3, '4100252027': 2, '4100252031': 3, '4100252032': 2, '4100252033': 2, '4100252034': 2, '4100252035': 2, '4100252036': 1, '4100252037': 3, '4100252038': 2, '4100252039': 2, '4100252040': 2, '4100252041': 1, '4100252043': 3, '4100252044': 1, '4100252045': 3, '4100252048': 2, '4100252049': 3, '4100252050': 3, '4100252051': 3, '4100252053': 2, '4100252054': 2, '4100252055': 2, '4100252056': 3, '4100252057': 3, '4100252058': 2, '4100252060': 2, '4100252061': 1, '4100252062': 3, '4100252063': 3, '4100252066': 2, '4100252069': 2, '4100252070': 3, '4100252071': 2, '4100252072': 3, '4100252073': 2, '4100252074': 2, '4100252075': 2, '4100252076': 2, '4100252078': 2, '4100252081': 2, '4100261001': 2, '4100261002': 2, '4100261003': 3, '4100261004': 2, '4100261005': 1, '4100261006': 1, '4100261007': 3, '4100261010': 2, '4100261012': 2, '4100261013': 2, '4100261015': 2, '4100261016': 3, '4100261020': 2, '4100261023': 2, '4100261025': 2, '4100261027': 1, '4100261028': 2, '4100261029': 2, '4100261030': 1, '4100261031': 2, '4100261032': 2, '4100261033': 3, '4100261034': 1, '4100261035': 3, '4100261036': 2, '4100261038': 2, '4100261041': 1, '4100261044': 2, '4100261045': 2, '4100261046': 2, '4100261047': 2, '4100261048': 2, '4100261049': 2, '4100261050': 1, '4100261055': 3, '4100261056': 1, '4100261057': 2, '4100261058': 1, '4100261060': 2, '4100261061': 2, '4100262001': 2, '4100262003': 2, '4100262004': 1, '4100262006': 0, '4100262007': 2, '4100262008': 2, '4100262009': 2, '4100262010': 2, '4100262014': 2, '4100262015': 3, '4100262016': 2, '4100262017': 3, '4100262018': 2, '4100262019': 2, '4100262020': 2, '4100262022': 2, '4100262023': 2, '4100262024': 2, '4100262025': 2, '4100262027': 2, '4100262034': 1, '4100262035': 2, '4100262037': 3, '4100262038': 2, '4100262040': 2, '4100262041': 2, '4100262042': 2, '4100262043': 3, '4100262044': 2, '4100262045': 2, '4100262046': 3, '4100262047': 2, '4100262052': 2, '4100262053': 2, '4100262056': 1, '4100262057': 2, '4100262060': 2, '4100262063': 2, '4100262064': 2, '4100262065': 2, '4100262066': 2, '4100262067': 2, '4100262068': 2, '4100262069': 3, '4100262070': 2, '4100271007': 2, '4100271008': 2, '4100271009': 2, '4100271010': 3, '4100271011': 3, '4100271012': 2, '4100271026': 2, '4100271028': 2, '4100271029': 2, '4100271030': 2, '4100271032': 3, '4100271033': 3, '4100271034': 3, '4100271038': 1, '4100271039': 2, '4100271041': 1, '4100271042': 2, '4100271043': 3, '4100271056': 1, '4100272024': 2, '4100272029': 3, '4100272033': 3, '4100272034': 2, '4100272036': 3, '4100272037': 2, '4100272043': 3, '4100272051': 2, '4100272052': 2, '4100272056': 3, '4100281001': 2, '4100281002': 2, '4100281015': 2, '4100281016': 2, '4100281019': 3, '4100281022': 2, '4100281023': 2, '4100281027': 2, '4100281029': 2, '4100281030': 2, '4100281032': 1, '4100281033': 2, '4100281034': 2, '4100281035': 2, '4100281036': 2, '4100281037': 2, '4100281041': 3, '4100281042': 2, '4100281045': 2, '4100281046': 1, '4100281048': 2, '4100281049': 2, '4100281050': 2, '4100281052': 2, '4100281053': 1, '4100281054': 2, '4100281057': 2, '4100281058': 2, '4100281059': 2, '4100281060': 3, '4100281061': 2, '4100281062': 2, '4100281063': 2, '4100281066': 2, '4100281067': 0, '4100281068': 2, '4100281070': 1, '4100281072': 2, '4100281075': 2, '4100281076': 1, '4100281078': 3, '4100281079': 2, '4100281080': 2, '4100281081': 2, '4100282001': 2, '4100282002': 2, '4100282003': 3, '4100282004': 2, '4100282005': 2, '4100282007': 2, '4100282008': 2, '4100282009': 1, '4100282012': 2, '4100282013': 2, '4100282014': 3, '4100282015': 2, '4100282017': 3, '4100282018': 2, '4100282019': 3, '4100282020': 3, '4100282021': 3, '4100282022': 3, '4100282023': 2, '4100282024': 3, '4100282033': 2, '4100282043': 2, '4100282048': 2, '4100282053': 3, '4100282057': 2, '4100282058': 2, '4100282066': 1, '4100282067': 2, '4100282068': 2, '4100282070': 2, '4100291002': 2, '4100291003': 3, '4100291004': 2, '4100291005': 2, '4100291006': 1, '4100291007': 1, '4100291008': 2, '4100291009': 2, '4100291010': 1, '4100291011': 2, '4100291012': 2, '4100291014': 2, '4100291015': 2, '4100291016': 2, '4100291017': 2, '4100291018': 2, '4100291019': 1, '4100291021': 2, '4100291022': 2, '4100291025': 2, '4100291026': 1, '4100291027': 1, '4100291028': 2, '4100291032': 1, '4100291033': 2, '4100291034': 2, '4100291036': 1, '4100291037': 2, '4100291039': 2, '4100291040': 2, '4100291041': 1, '4100291043': 2, '4100291046': 2, '4100291047': 2, '4100291048': 2, '4100291049': 2, '4100291050': 2, '4100291051': 2, '4100291055': 2, '4100291056': 2, '4100291059': 2, '4100291060': 3, '4100291061': 2, '4100291062': 2, '4100291063': 3, '4100291064': 3, '4100291065': 2, '4100291070': 1, '4100291073': 1, '4100291074': 2, '4100291076': 2, '4100291077': 2, '4100291078': 1, '4100291079': 2, '4100291080': 2, '4100291081': 1, '4100291082': 1, '4100291083': 2, '4100291084': 1, '4100292001': 2, '4100292003': 2, '4100292005': 2, '4100292008': 2, '4100292010': 2, '4100292016': 2, '4100292019': 2, '4100292020': 2, '4100292021': 3, '4100292022': 2, '4100292023': 2, '4100292024': 3, '4100292025': 2, '4100292026': 2, '4100292027': 2, '4100292028': 2, '4100292035': 2, '4100292036': 3, '4100292037': 2, '4100292040': 2, '4100292041': 2, '4100292042': 3, '4100292043': 2, '4100292044': 3, '4100292045': 3, '4100292046': 3, '4100292048': 1, '4100292049': 2, '4100292050': 2, '4100292052': 2, '4100292053': 2, '4100292056': 2, '4100292057': 2, '4100292059': 2, '4100292060': 2, '4100292061': 3, '4100292062': 2, '4100292063': 2, '4100292064': 3, '4100292065': 2, '4100292066': 3, '4100292067': 3, '4100292068': 3, '4100292069': 2, '4100292070': 2, '4100292071': 2, '4100292072': 3, '4100292073': 3, '4100292074': 2, '4100292075': 3, '4100292077': 2, '4100292078': 3, '4100292079': 2, '4100292081': 3, '4100292083': 3, '4100292084': 2, '4100292085': 3, '4100292087': 2, '4100292088': 2, '4100302002': 3, '4100302013': 1, '4100302014': 3, '4100302016': 1, '4100302017': 2, '4100302018': 1, '4100302019': 2, '4100302020': 2, '4100302024': 2, '4100302028': 3, '4100302030': 1, '4100302040': 0, '4100302041': 2, '4100302042': 0, '4100302043': 1, '4100302044': 0, '4100302045': 0, '4100302046': 2, '4100302047': 2, '4100302048': 1, '4100302049': 3, '4100302050': 2, '4100302051': 2, '4100302052': 2, '4100302053': 2, '4100302054': 3, '4100302055': 1, '4100302058': 0, '4100302061': 2, '4100302063': 2, '4100302064': 0, '4100302066': 1, '4100302067': 3, '4100302068': 2, '4100302069': 3, '4100321001': 1, '4100321002': 2, '4100321003': 3, '4100321004': 2, '4100321005': 3, '4100321006': 2, '4100321008': 2, '4100321009': 1, '4100321010': 3, '4100321011': 2, '4100321012': 2, '4100321014': 2, '4100321015': 3, '4100321016': 2, '4100321019': 1, '4100321020': 2, '4100321021': 2, '4100321022': 3, '4100321023': 3, '4100321024': 3, '4100321026': 3, '4100321027': 3, '4100321028': 3, '4100321029': 2, '4100321030': 3, '4100321032': 3, '4100321033': 2, '4100321034': 2, '4100321037': 3, '4100321038': 3, '4100321039': 2, '4100321041': 3, '4100321042': 1, '4100321043': 1, '4100321044': 1, '4100321045': 2, '4100321046': 3, '4100321049': 3, '4100321051': 2, '4100321052': 3, '4100321053': 2, '4100322001': 2, '4100322007': 3, '4100322025': 2, '4100322031': 2, '4100322032': 1, '4100322033': 2, '4100322034': 2, '4100322035': 2, '4100322037': 2, '4100322038': 2, '4100322039': 2, '4100322040': 3, '4100322041': 2, '4100322042': 3, '4100322044': 3, '4100322045': 3, '4100322048': 2, '4100322051': 3, '4100322052': 3, '4100322053': 2, '4100322055': 2, '4100322056': 2, '4100322057': 2, '4100322058': 2, '4100322059': 3, '4100322060': 2, '4100322061': 2, '4110211001': 1, '4110211004': 1, '4110211005': 1, '4110211006': 2, '4110211007': 2, '4110211008': 2, '4110211009': 2, '4110211011': 2, '4110211013': 1, '4110211014': 1, '4110211015': 0, '4110211016': 3, '4110211018': 2, '4110211019': 3, '4110211020': 2, '4110211021': 1, '4110211022': 1, '4110211023': 1, '4110211024': 2, '4110211025': 0, '4110211026': 2, '4110211027': 1, '4110211028': 1, '4110211030': 2, '4110211032': 2, '4110211033': 2, '4110211034': 2, '4110211035': 2, '4110211036': 1, '4110211037': 2, '4110211038': 1, '4110211039': 1, '4110211040': 0, '4110211041': 2, '4110211043': 2, '4110211044': 3, '4110211045': 1, '4110211046': 3, '4110211047': 3, '4110211048': 2, '4110211049': 2, '4110211050': 2, '4110211051': 3, '4110211052': 2, '4110211053': 1, '4110211054': 2, '4110211055': 1, '4110211056': 3, '4110211057': 2, '4110211058': 3, '4110211060': 2, '4110211061': 0, '4110211062': 2, '4110211063': 2, '4110211064': 2, '4110211065': 2, '4110211067': 3, '4110211068': 2, '4110211072': 2, '4110211073': 2, '4110211075': 1, '4110211076': 3, '4110211078': 1, '4110211079': 2, '4110211080': 2, '4110212003': 2, '4110212004': 2, '4110212007': 2, '4110212008': 2, '4110212009': 2, '4110212010': 2, '4110212011': 2, '4110212013': 3, '4110212014': 3, '4110212015': 2, '4110212016': 2, '4110212017': 2, '4110212018': 2, '4110212019': 2, '4110212021': 3, '4110212023': 2, '4110212024': 2, '4110212026': 2, '4110212027': 2, '4110212029': 2, '4110212030': 3, '4110212033': 2, '4110212034': 1, '4110212035': 2, '4110212036': 1, '4110212038': 2, '4110212039': 3, '4110212041': 2, '4110212042': 2, '4110212044': 3, '4110212045': 2, '4110212046': 2, '4110212047': 3, '4110212049': 1, '4110212050': 2, '4110212051': 1, '4110212052': 3, '4110212053': 2, '4110212054': 2, '4110212055': 2, '4110212056': 2, '4110212059': 2, '4110212061': 2, '4110212062': 1, '4110212063': 2, '4110212064': 2, '4110212069': 2, '4110311001': 3, '4110311003': 3, '4110311004': 3, '4110311005': 2, '4110311006': 1, '4110311012': 2, '4110311015': 3, '4110311017': 2, '4110311018': 3, '4110311019': 2, '4110311020': 2, '4110311021': 2, '4110311023': 1, '4110311030': 2, '4110311031': 3, '4110311032': 2, '4110311033': 2, '4110311034': 2, '4110311036': 3, '4110311037': 3, '4110311038': 3, '4110311042': 3, '4110311043': 3, '4110311044': 2, '4110311045': 1, '4110311046': 2, '4110311048': 1, '4110311049': 2, '4110311050': 2, '4110311053': 3, '4110311054': 1, '4110311057': 2, '4110311061': 2, '4110311062': 1, '4110311064': 2, '4110311065': 2, '4110311067': 2, '4110311068': 2, '4110311072': 2, '4110312006': 3, '4110312007': 2, '4110312008': 2, '4110312009': 1, '4110312013': 2, '4110312023': 3, '4110312024': 3, '4110312025': 3, '4110312027': 2, '4110312030': 3, '4110312031': 2, '4110312048': 2, '4110312049': 2, '4110312078': 3, '414081010': 3, '414081011': 3, '4140810110': 3, '4140810114': 3, '4140810117': 3, '4140810122': 3, '4140810124': 3, '4140810125': 3, '4140810126': 3, '4140810127': 3, '4140810128': 3, '4140810129': 2, '414081013': 2, '4140810132': 3, '4140810133': 3, '4140810135': 2, '4140810136': 3, '4140810138': 3, '4140810139': 2, '4140810140': 2, '4140810142': 3, '4140810143': 3, '4140810144': 3, '4140810145': 3, '4140810146': 3, '4140810148': 3, '414081015': 2, '4140810150': 3, '4140810151': 3, '4140810152': 3, '4140810153': 1, '4140810154': 3, '4140810158': 3, '4140810159': 2, '414081016': 3, '4140810162': 1, '4140810163': 3, '4140810164': 3, '4140810165': 3, '414081017': 3, '4140810171': 2, '4140810173': 3, '4140810175': 3, '4140810176': 3, '4140810179': 2, '414081018': 3, '4140810180': 3, '4140810181': 3, '4140810182': 3, '4140810183': 3, '4140810184': 2, '4140810185': 3, '414081019': 3, '414081021': 3, '4140810210': 1, '4140810211': 3, '4140810212': 2, '4140810215': 2, '4140810217': 1, '4140810219': 1, '4140810220': 3, '4140810221': 2, '4140810222': 3, '4140810223': 3, '4140810224': 3, '4140810225': 2, '4140810226': 2, '4140810228': 3, '4140810229': 3, '414081023': 3, '4140810230': 3, '4140810233': 3, '4140810234': 2, '4140810237': 3, '4140810239': 3, '4140810240': 3, '4140810242': 2, '4140810244': 2, '4140810246': 3, '4140810247': 2, '4140810249': 2, '414081025': 3, '4140810250': 2, '4140810251': 3, '4140810252': 3, '4140810253': 2, '4140810254': 3, '4140810255': 3, '4140810256': 3, '4140810257': 2, '4140810258': 3, '4140810259': 3, '414081026': 3, '4140810264': 3, '4140810265': 3, '4140810266': 3, '4140810268': 3, '4140810269': 3, '414081027': 3, '4140810270': 2, '4140810271': 3, '4140810272': 1, '4140810273': 2, '4140810274': 3, '4140810276': 3, '4140810277': 3, '4140810278': 2, '4140810279': 3, '414081028': 2, '4140810280': 3, '414081029': 2, '459999011': 3, '4599990110': 2, '4599990112': 3, '4599990113': 3, '4599990114': 3, '4599990116': 3, '4599990117': 3, '4599990118': 3, '4599990119': 3, '459999012': 2, '4599990120': 2, '4599990125': 3, '4599990126': 2, '4599990128': 3, '4599990129': 2, '459999013': 3, '4599990130': 3, '4599990131': 3, '4599990132': 1, '4599990133': 2, '4599990134': 3, '4599990136': 3, '4599990137': 3, '4599990139': 3, '4599990141': 3, '4599990144': 3, '4599990146': 3, '4599990148': 2, '4599990149': 3, '4599990153': 3, '4599990154': 3, '4599990155': 3, '459999016': 3, '4599990163': 2, '4599990165': 3, '4599990166': 3, '4599990168': 3, '459999017': 2, '4599990171': 3, '459999021': 3, '4599990211': 3, '4599990212': 3, '4599990214': 2, '4599990216': 3, '4599990218': 3, '459999022': 3, '4599990221': 3, '4599990222': 3, '4599990223': 3, '4599990224': 3, '4599990226': 3, '4599990231': 3, '4599990233': 2, '4599990234': 3, '4599990235': 1, '4599990238': 3, '459999024': 3, '4599990240': 3, '4599990241': 3, '4599990243': 2, '4599990244': 3, '4599990245': 2, '4599990246': 3, '4599990247': 3, '4599990248': 2, '4599990249': 3, '459999025': 3, '4599990253': 3, '4599990254': 3, '4599990255': 2, '4599990256': 3, '4599990263': 3, '4599990264': 2, '4599990269': 2, '4599990270': 3, '4599990272': 2, '4599990273': 3, '4599990274': 3, '4599990275': 3, '4599990276': 2, '459999028': 2, '4599990283': 3, '5000391001': 2, '5000391002': 2, '5000391004': 3, '5000391005': 2, '5000391007': 3, '5000391008': 2, '5000391010': 2, '5000391012': 2, '5000391013': 3, '5000391014': 2, '5000391015': 3, '5000391016': 3, '5000391017': 1, '5000391019': 2, '5000391020': 2, '5000391022': 3, '5000391023': 2, '5000391024': 2, '5000391026': 2, '5000391028': 3, '5000391029': 2, '5000391030': 3, '5000391031': 3, '5000391032': 3, '5000391034': 2, '5000391035': 3, '5000391036': 2, '5000391037': 3, '5000391038': 2, '5000391040': 2, '5000391045': 1, '5000391046': 2, '5000391047': 3, '5000391049': 2, '5000391050': 2, '5000391054': 2, '5000391055': 1, '5000391056': 1, '5000391059': 2, '5000391060': 1, '5000391061': 2, '5000391062': 3, '5000391063': 3, '5000391064': 2, '5000391065': 2, '5000391066': 3, '5000391067': 2, '5000391068': 3, '5000391069': 3, '5000391070': 2, '5000391071': 2, '5000391072': 2, '5000391073': 2, '5000391074': 2, '5000391076': 2, '5000391078': 2, '5000391079': 2, '5000391080': 3, '5000391081': 2, '5000392001': 2, '5000392002': 2, '5000392003': 3, '5000392006': 2, '5000392007': 2, '5000392010': 3, '5000392011': 2, '5000392015': 2, '5000392016': 2, '5000392017': 2, '5000392018': 2, '5000392019': 2, '5000392020': 2, '5000392021': 2, '5000392022': 2, '5000392025': 2, '5000392026': 2, '5000392027': 2, '5000392029': 2, '5000392033': 1, '5000392035': 2, '5000392036': 3, '5000392038': 2, '5000392039': 2, '5000392040': 3, '5000392041': 3, '5000392042': 2, '5000392044': 2, '5000392047': 2, '5000392048': 2, '5000392049': 3, '5000392050': 3, '5000392051': 3, '5000392052': 1, '5000392053': 2, '5000392054': 2, '5000392055': 2, '5000392056': 2, '5000392058': 2, '5000392060': 1, '5000392062': 2, '5000392063': 2, '5000392064': 2, '5000392065': 2, '5000392066': 2, '5000392067': 2, '5000392070': 2, '5000392071': 2, '5000392072': 2, '5000431019': 2, '5000431020': 3, '5000431021': 3, '5000431022': 2, '5000431023': 3, '5000431025': 2, '5000431026': 2, '5000431049': 3, '5000431050': 3, '5000432001': 3, '5000432003': 2, '5000432006': 2, '5000432059': 3, '5000441001': 2, '5000441002': 2, '5000441003': 2, '5000441005': 2, '5000441006': 2, '5000441007': 2, '5000441008': 2, '5000441009': 3, '5000441010': 2, '5000441012': 2, '5000441013': 2, '5000441014': 2, '5000441015': 2, '5000441016': 3, '5000441017': 2, '5000441018': 3, '5000441021': 3, '5000441022': 2, '5000441023': 3, '5000441024': 1, '5000441027': 3, '5000441030': 2, '5000441031': 2, '5000441032': 2, '5000441033': 2, '5000441034': 2, '5000441035': 3, '5000441037': 2, '5000441038': 3, '5000441039': 3, '5000441040': 3, '5000441041': 3, '5000441042': 2, '5000441043': 2, '5000441044': 2, '5000441045': 2, '5000441046': 3, '5000441047': 2, '5000441048': 2, '5000441050': 2, '5000441051': 2, '5000441052': 2, '5000441053': 3, '5000441054': 2, '5000441055': 3, '5000441058': 1, '5000441059': 2, '5000441061': 3, '5000441062': 2, '5000441064': 2, '5000441065': 2, '5000441066': 2, '5000441067': 1, '5000441068': 2, '5000441069': 2, '5000441070': 3, '5000441071': 3, '5000441072': 3, '5000442001': 3, '5000442002': 2, '5000442003': 2, '5000442004': 2, '5000442005': 2, '5000442007': 2, '5000442008': 2, '5000442009': 3, '5000442010': 2, '5000442014': 3, '5000442015': 2, '5000442016': 2, '5000442019': 2, '5000442021': 2, '5000442022': 3, '5000442024': 2, '5000442025': 2, '5000442026': 2, '5000442027': 3, '5000442028': 2, '5000442029': 3, '5000442033': 2, '5000442034': 3, '5000442035': 3, '5000442036': 2, '5000442037': 3, '5000442038': 3, '5000442039': 3, '5000442040': 3, '5000442042': 2, '5000442043': 3, '5000442045': 3, '5000442047': 2, '5000442048': 2, '5000442050': 2, '5000442051': 2, '5000442052': 2, '5000442053': 2, '5000442054': 3, '5000442055': 3, '5000442056': 2, '5000442057': 3, '5000442058': 3, '5000442059': 3, '5000442060': 2, '5000442062': 2, '5000442063': 3, '5000442064': 3, '5000442065': 3, '5000442066': 3, '5000442067': 2, '5000442068': 3, '5000442069': 3, '5000442070': 3, '5000442072': 2, '5000442073': 3, '5000442074': 2, '5000442075': 2, '5000442076': 2, '5000442077': 2, '5000442078': 2, '5000671001': 3, '5000671002': 2, '5000671003': 2, '5000671004': 3, '5000671005': 2, '5000671006': 2, '5000671008': 3, '5000671009': 2, '5000671010': 3, '5000671011': 3, '5000671012': 3, '5000671013': 2, '5000671014': 3, '5000671015': 3, '5000671016': 2, '5000671017': 2, '5000671018': 3, '5000671019': 2, '5000671020': 2, '5000671022': 2, '5000671023': 3, '5000671024': 2, '5000671026': 3, '5000671027': 2, '5000671028': 3, '5000671029': 2, '5000671030': 3, '5000671031': 2, '5000671032': 3, '5000671033': 3, '5000671034': 2, '5000671035': 3, '5000671036': 2, '5000671037': 2, '5000671038': 2, '5000671039': 2, '5000671040': 2, '5000671041': 1, '5000671042': 1, '5000671043': 2, '5000671046': 2, '5000671047': 2, '5000671048': 1, '5000671049': 1, '5000671050': 2, '5000671051': 2, '5000671053': 2, '5000671055': 2, '5000671056': 3, '5000671057': 2, '5000671058': 1, '5000671059': 2, '5000671060': 2, '5000671061': 1, '5000671062': 2, '5000671063': 2, '5000671064': 3, '5000671065': 2, '5000671066': 2, '5000671067': 2, '5000671069': 1, '5000671070': 1, '5000671071': 2, '5000672002': 2, '5000672004': 2, '5000672005': 2, '5000672006': 3, '5000672007': 2, '5000672008': 2, '5000672010': 2, '5000672011': 3, '5000672012': 2, '5000672013': 3, '5000672014': 3, '5000672016': 2, '5000672017': 2, '5000672019': 3, '5000672020': 3, '5000672021': 3, '5000672022': 3, '5000672023': 2, '5000672024': 2, '5000672025': 3, '5000672026': 3, '5000672027': 2, '5000672030': 2, '5000672031': 2, '5000672033': 2, '5000672034': 2, '5000672035': 3, '5000672036': 2, '5000672038': 3, '5000672042': 3, '5000672043': 3, '5000672044': 3, '5000672045': 3, '5000672046': 2, '5000672047': 2, '5000672048': 2, '5000672049': 2, '5000672050': 2, '5000672051': 3, '5000672052': 3, '5000672053': 2, '5000672054': 3, '5000672055': 3, '5000672056': 3, '5000672057': 2, '5000672058': 2, '5000672059': 2, '5000672060': 2, '5000672062': 3, '5000672064': 2, '5000672065': 2, '5000672066': 2, '5000672067': 2, '5000672068': 2, '5000672070': 3, '5000672071': 2, '5000672072': 2, '5000672074': 3, '5000672075': 3, '5000672076': 3, '5000672077': 2, '5000672081': 2, '5000672082': 2, '5000951001': 2, '5000951002': 2, '5000951003': 3, '5000951004': 2, '5000951005': 2, '5000951006': 2, '5000951007': 3, '5000951008': 2, '5000951009': 3, '5000951010': 2, '5000951011': 3, '5000951012': 2, '5000951013': 2, '5000951015': 3, '5000951016': 2, '5000951017': 2, '5000951018': 2, '5000951019': 1, '5000951021': 2, '5000951023': 1, '5000951024': 1, '5000951025': 2, '5000951027': 1, '5000951028': 3, '5000951033': 2, '5000951034': 2, '5000951035': 2, '5000951037': 2, '5000951039': 2, '5000951040': 3, '5000951042': 2, '5000951043': 3, '5000951044': 2, '5000951045': 2, '5000951047': 2, '5000951049': 3, '5000951051': 3, '5000951052': 2, '5000951053': 2, '5000951054': 3, '5000951055': 2, '5000951056': 3, '5000951057': 3, '5000951058': 3, '5000951060': 3, '5000951061': 2, '5000951062': 2, '5000951063': 2, '5000951065': 3, '5000951066': 2, '5000951067': 2, '5000952002': 2, '5000952003': 2, '5000952004': 2, '5000952005': 3, '5000952007': 3, '5000952008': 3, '5000952011': 2, '5000952013': 2, '5000952014': 2, '5000952015': 3, '5000952016': 2, '5000952017': 2, '5000952018': 2, '5000952020': 2, '5000952021': 2, '5000952022': 2, '5000952023': 3, '5000952024': 2, '5000952025': 3, '5000952026': 3, '5000952027': 2, '5000952028': 2, '5000952029': 2, '5000952031': 2, '5000952032': 2, '5000952033': 2, '5000952034': 1, '5000952035': 2, '5000952036': 2, '5000952038': 3, '5000952040': 3, '5000952041': 2, '5000952042': 2, '5000952044': 2, '5000952045': 2, '5000952046': 3, '5000952048': 2, '5000952050': 3, '5000952052': 2, '5000952053': 3, '5000952054': 2, '5000952055': 2, '5000952060': 2, '5000952061': 2, '5000952062': 1, '5000952063': 2, '5000952064': 3, '5000952065': 2, '5000952066': 2, '5000952068': 3, '5000952069': 2, '5000952070': 3, '5000952071': 2, '5000952072': 3, '5000952073': 2, '5000952075': 2, '5000952076': 3, '5000952077': 2, '5000952078': 2, '5000952080': 3, '5000952083': 1, '5100091001': 2, '5100091003': 3, '5100091004': 3, '5100091005': 2, '5100091006': 2, '5100091007': 3, '5100091008': 3, '5100091009': 2, '5100091010': 3, '5100091012': 2, '5100091017': 2, '5100091019': 2, '5100091020': 3, '5100091025': 2, '5100091026': 3, '5100091027': 2, '5100091028': 2, '5100091032': 3, '5100091033': 2, '5100091034': 3, '5100091035': 3, '5100091036': 3, '5100091038': 3, '5100091039': 3, '5100091042': 3, '5100091046': 3, '5100091049': 1, '5100091050': 2, '5100091051': 2, '5100091053': 2, '5100091055': 3, '5100091056': 2, '5100091057': 2, '5100091058': 2, '5100091059': 2, '5100091062': 2, '5100091064': 2, '5100091065': 3, '5100091066': 2, '5100091067': 3, '5100091068': 2, '5100091069': 3, '5100092002': 3, '5100092003': 3, '5100092005': 3, '5100092006': 3, '5100092008': 3, '5100092010': 3, '5100092011': 2, '5100092013': 3, '5100092017': 2, '5100092019': 3, '5100092021': 2, '5100092022': 3, '5100092023': 3, '5100092026': 3, '5100092027': 3, '5100092032': 2, '5100092033': 3, '5100092034': 2, '5100092035': 2, '5100092037': 2, '5100092038': 2, '5100092039': 3, '5100092040': 3, '5100092041': 2, '5100092042': 3, '5100092043': 2, '5100092044': 3, '5100092045': 3, '5100092053': 2, '5100092056': 2, '5100092057': 2, '5100092060': 3, '5100092061': 3, '5100092062': 2, '5100092063': 2, '5100092064': 3, '5100092065': 2, '5100092067': 3, '5100092068': 2, '5100092069': 3, '5100092071': 3, '5100092072': 3, '5100341002': 2, '5100341003': 2, '5100341004': 3, '5100341005': 2, '5100341006': 2, '5100341008': 2, '5100341009': 2, '5100341010': 2, '5100341012': 3, '5100341013': 2, '5100341014': 3, '5100341015': 2, '5100341016': 2, '5100341017': 2, '5100341019': 2, '5100341020': 3, '5100341021': 3, '5100341022': 2, '5100341023': 2, '5100341024': 3, '5100341025': 2, '5100341026': 3, '5100341027': 3, '5100341028': 2, '5100341030': 2, '5100341031': 3, '5100341032': 2, '5100341033': 2, '5100341034': 3, '5100341035': 2, '5100341037': 2, '5100341038': 2, '5100341039': 3, '5100341042': 2, '5100341043': 1, '5100341046': 2, '5100341048': 3, '5100341050': 3, '5100341052': 3, '5100341054': 3, '5100341055': 3, '5100341056': 2, '5100341057': 2, '5100341058': 3, '5100341061': 2, '5100341062': 3, '5100341065': 3, '5100341067': 3, '5100341068': 3, '5100341070': 3, '5100341071': 3, '5100341072': 3, '5100341074': 1, '5100341075': 3, '5100341076': 3, '5100341077': 2, '5100341078': 3, '5100341079': 3, '5100342002': 3, '5100342003': 2, '5100342007': 3, '5100342008': 2, '5100342009': 2, '5100342012': 2, '5100342016': 2, '5100342017': 3, '5100342018': 2, '5100342020': 3, '5100342022': 0, '5100342023': 1, '5100342024': 1, '5100342025': 2, '5100342028': 1, '5100342030': 2, '5100342031': 2, '5100342034': 2, '5100342036': 1, '5100342042': 2, '5100342043': 2, '5100342045': 2, '5100342048': 1, '5100351001': 1, '5100351002': 1, '5100351004': 2, '5100351005': 2, '5100351007': 2, '5100351009': 2, '5100351010': 2, '5100351012': 3, '5100351013': 1, '5100351015': 2, '5100351016': 2, '5100351019': 2, '5100351020': 2, '5100351021': 2, '5100351022': 0, '5100351023': 2, '5100351024': 2, '5100351025': 2, '5100351026': 3, '5100351032': 3, '5100351034': 3, '5100351035': 2, '5100351036': 2, '5100351038': 2, '5100351039': 3, '5100351040': 2, '5100351042': 1, '5100351043': 3, '5100351044': 2, '5100351045': 2, '5100351046': 3, '5100351049': 3, '5100351051': 3, '5100351054': 2, '5100351058': 2, '5100352001': 2, '5100352002': 2, '5100352003': 2, '5100352004': 3, '5100352005': 2, '5100352006': 2, '5100352007': 3, '5100352008': 2, '5100352009': 3, '5100352011': 2, '5100352012': 2, '5100352013': 3, '5100352014': 2, '5100352015': 2, '5100352016': 2, '5100352017': 3, '5100352018': 2, '5100352020': 3, '5100352021': 2, '5100352022': 1, '5100352026': 3, '5100352027': 3, '5100352028': 2, '5100352030': 3, '5100352031': 3, '5100352032': 2, '5100352033': 2, '5100352034': 2, '5100352035': 2, '5100352037': 2, '5100352038': 3, '5100352039': 3, '5100352041': 2, '5100352042': 2, '5100352043': 1, '5100352044': 2, '5100352045': 3, '5100352046': 3, '5100352049': 2, '5100352050': 2, '5100352051': 2, '5100352052': 3, '5100352054': 1, '5100352055': 3, '5100352056': 2, '5100352057': 2, '5100352060': 2, '5100352061': 2, '5100352063': 2, '5100361009': 2, '5100361056': 2, '5100362028': 3, '5100362029': 2, '5100362030': 3, '5100362052': 2, '5100371022': 2, '5100371023': 3, '5100371024': 2, '5100371026': 3, '5100371027': 3, '5100371042': 3, '5100371055': 2, '5100371056': 2, '5100371067': 2, '5100371079': 2, '5100372001': 3, '5100372002': 2, '5100372003': 2, '5100372005': 2, '5100372006': 3, '5100372007': 3, '5100372009': 3, '5100372011': 3, '5100372015': 3, '5100372016': 3, '5100372017': 3, '5100372018': 3, '5100372019': 2, '5100372020': 3, '5100372021': 2, '5100372022': 3, '5100372023': 3, '5100372026': 3, '5100372027': 3, '5100372028': 2, '5100372069': 3, '5100381002': 3, '5100381003': 3, '5100381004': 2, '5100381005': 2, '5100381006': 2, '5100381007': 2, '5100381008': 2, '5100381009': 2, '5100381010': 2, '5100381011': 3, '5100381012': 3, '5100381015': 3, '5100381016': 3, '5100381017': 2, '5100381018': 2, '5100381019': 3, '5100381020': 2, '5100381021': 2, '5100381022': 2, '5100381023': 3, '5100381024': 3, '5100381026': 2, '5100381027': 3, '5100381028': 3, '5100381029': 3, '5100381031': 2, '5100381032': 2, '5100381034': 3, '5100381035': 2, '5100381037': 2, '5100381038': 2, '5100381039': 2, '5100381040': 3, '5100381041': 3, '5100381042': 2, '5100381043': 2, '5100381044': 2, '5100381045': 3, '5100381046': 3, '5100381047': 3, '5100381048': 3, '5100381049': 2, '5100381050': 3, '5100381051': 2, '5100381052': 3, '5100381053': 3, '5100381054': 2, '5100381055': 2, '5100381056': 3, '5100381058': 2, '5100381059': 3, '5100381060': 2, '5100381061': 2, '5100381063': 2, '5100381065': 2, '5100381066': 2, '5100381067': 2, '5100381069': 2, '5100382001': 2, '5100382003': 3, '5100382007': 2, '5100382008': 2, '5100382010': 3, '5100382011': 3, '5100382012': 3, '5100382013': 3, '5100382014': 3, '5100382015': 2, '5100382016': 3, '5100382018': 3, '5100382019': 3, '5100382020': 2, '5100382021': 3, '5100382022': 3, '5100382023': 3, '5100382025': 3, '5100382026': 3, '5100382027': 3, '5100382028': 2, '5100382029': 3, '5100382030': 3, '5100382031': 2, '5100382032': 2, '5100382033': 3, '5100382034': 2, '5100382035': 2, '5100382036': 3, '5100382037': 2, '5100382038': 3, '5100382039': 3, '5100382040': 2, '5100382042': 3, '5100382045': 3, '5100382046': 2, '5100382048': 2, '5100382050': 3, '5100382051': 2, '5100382052': 3, '5100382053': 3, '5100382054': 2, '5100382055': 3, '5100382056': 3, '5100382057': 3, '5100382058': 2, '5100382059': 2, '5100382060': 3, '5100382061': 3, '5100382062': 3, '5100382063': 3, '5100382064': 3, '5100382065': 3, '5100382066': 2, '5100382067': 2, '5100382068': 3, '5100382069': 2, '5100382070': 3, '5100382071': 3, '5100382072': 3, '5100382073': 2, '5100382075': 2, '5100382076': 2, '5100382077': 2, '5100382078': 2, '5100382079': 2, '5100401001': 2, '5100401003': 2, '5100401005': 2, '5100401006': 2, '5100401007': 3, '5100401008': 3, '5100401010': 2, '5100401011': 2, '5100401012': 2, '5100401014': 3, '5100401015': 2, '5100401016': 2, '5100401018': 2, '5100401021': 3, '5100401022': 3, '5100401023': 1, '5100401025': 3, '5100401026': 3, '5100401028': 2, '5100401029': 2, '5100401030': 3, '5100401031': 2, '5100401032': 2, '5100401033': 2, '5100401034': 1, '5100401035': 2, '5100401036': 2, '5100401038': 3, '5100401039': 2, '5100401040': 2, '5100401042': 2, '5100401043': 1, '5100401044': 3, '5100401045': 3, '5100401046': 2, '5100401047': 2, '5100401048': 2, '5100401049': 2, '5100401050': 2, '5100401051': 2, '5100401053': 3, '5100401054': 2, '5100401055': 2, '5100401056': 3, '5100401057': 3, '5100401059': 2, '5100401060': 2, '5100401061': 2, '5100401062': 3, '5100401063': 2, '5100401064': 2, '5100401065': 1, '5100401066': 3, '5100401067': 2, '5100401069': 3, '5100401070': 2, '5100401071': 2, '5100401072': 3, '5100401073': 2, '5100401074': 3, '5100401075': 2, '5100401076': 2, '5100401077': 2, '5100401078': 2, '5100402001': 1, '5100402002': 2, '5100402004': 3, '5100402005': 3, '5100402007': 2, '5100402008': 3, '5100402009': 2, '5100402011': 2, '5100402012': 2, '5100402015': 2, '5100402016': 2, '5100402017': 2, '5100402019': 3, '5100402020': 2, '5100402023': 3, '5100402024': 3, '5100402028': 2, '5100402029': 2, '5100402031': 2, '5100402032': 3, '5100402033': 2, '5100402034': 2, '5100402035': 3, '5100402036': 2, '5100402037': 2, '5100402038': 3, '5100402039': 2, '5100402040': 3, '5100402046': 2, '5100402047': 2, '5100402048': 2, '5100402049': 3, '5100402050': 2, '5100402051': 2, '5100402052': 2, '5100402053': 2, '5100402054': 2, '5100402055': 2, '5100402057': 2, '5100402058': 2, '5100402059': 2, '5100402062': 1, '5100402063': 1, '5100402065': 3, '5100402066': 2, '5100402067': 2, '5100402068': 2, '5100402069': 2, '5100421001': 3, '5100421002': 2, '5100421003': 3, '5100421005': 3, '5100421007': 2, '5100421009': 2, '5100421011': 2, '5100421012': 3, '5100421013': 2, '5100421015': 3, '5100421016': 3, '5100421017': 2, '5100421018': 2, '5100421019': 3, '5100421020': 2, '5100421021': 3, '5100421024': 3, '5100421025': 2, '5100421026': 3, '5100421027': 2, '5100421029': 3, '5100421032': 3, '5100421033': 3, '5100421034': 3, '5100421038': 2, '5100421039': 3, '5100421040': 2, '5100421041': 2, '5100421043': 2, '5100421045': 2, '5100421047': 2, '5100421048': 3, '5100421049': 3, '5100421050': 2, '5100421051': 2, '5100421052': 2, '5100421053': 3, '5100421054': 2, '5100421056': 3, '5100421057': 3, '5100421058': 2, '5100421059': 2, '5100421060': 2, '5100421061': 2, '5100421062': 3, '5100421063': 2, '5100421064': 3, '5100421065': 3, '5100421067': 2, '5100421068': 3, '5100421069': 2, '5100421070': 3, '5100421071': 2, '5100421072': 2, '5100421073': 3, '5100421074': 2, '5100421076': 3, '5100421078': 3, '5100421079': 3, '5100421080': 3, '5100421081': 3, '5100422002': 2, '5100422003': 2, '5100422004': 3, '5100422005': 2, '5100422006': 3, '5100422007': 2, '5100422008': 2, '5100422009': 2, '5100422011': 2, '5100422012': 3, '5100422013': 2, '5100422014': 2, '5100422016': 2, '5100422017': 3, '5100422018': 2, '5100422019': 3, '5100422022': 2, '5100422023': 2, '5100422024': 2, '5100422025': 3, '5100422026': 3, '5100422027': 2, '5100422028': 3, '5100422029': 2, '5100422030': 2, '5100422033': 2, '5100422034': 2, '5100422035': 2, '5100422036': 3, '5100422037': 2, '5100422038': 3, '5100422039': 3, '5100422041': 2, '5100422042': 3, '5100422044': 2, '5100422045': 2, '5100422046': 3, '5100422047': 2, '5100422049': 2, '5100422050': 3, '5100422051': 2, '5100422052': 2, '5100422055': 3, '5100422056': 3, '5100422057': 2, '5100422058': 2, '5100422059': 3, '5100422060': 2, '5100422061': 3, '5100422062': 2, '5100422063': 3, '5100422065': 3, '5100422066': 2, '5100422067': 2, '5100422068': 2, '5100422069': 2, '5100422071': 3, '5100422072': 2, '5100422073': 2, '5100422074': 2, '5100422075': 3, '5100422077': 2, '5100422078': 2, '5100422079': 3, '5100422080': 2, '5100422081': 2, '5100422084': 2, '5100422085': 2, '5100451001': 2, '5100451003': 3, '5100451004': 3, '5100451006': 3, '5100451007': 3, '5100451012': 3, '5100451013': 3, '5100451015': 3, '5100451016': 3, '5100451017': 2, '5100451018': 3, '5100451019': 3, '5100451020': 2, '5100451024': 3, '5100451026': 3, '5100451027': 3, '5100451033': 2, '5100451034': 3, '5100451035': 3, '5100451036': 2, '5100451038': 2, '5100451041': 3, '5100451043': 2, '5100451044': 3, '5100451045': 2, '5100451049': 3, '5100451050': 3, '5100451051': 2, '5100451052': 3, '5100451055': 2, '5100451056': 3, '5100451059': 3, '5100451060': 3, '5100451061': 3, '5100451064': 2, '5100451065': 3, '5100451066': 2, '5100451067': 3, '5100451070': 3, '5100451071': 3, '5100452002': 2, '5100452004': 3, '5100452005': 2, '5100452006': 3, '5100452007': 2, '5100452008': 3, '5100452009': 3, '5100452010': 2, '5100452011': 2, '5100452012': 3, '5100452013': 3, '5100452014': 3, '5100452016': 1, '5100452017': 3, '5100452018': 3, '5100452021': 2, '5100452023': 2, '5100452025': 2, '5100452027': 2, '5100452028': 3, '5100452030': 3, '5100452031': 3, '5100452032': 2, '5100452033': 2, '5100452034': 3, '5100452035': 2, '5100452036': 3, '5100452037': 3, '5100452038': 3, '5100452039': 2, '5100452040': 2, '5100452047': 3, '5100452049': 3, '5100452050': 3, '5100452053': 2, '5100452054': 3, '5100452055': 2, '5100452059': 3, '5100452060': 3, '5100452061': 2, '5100452065': 3, '5100452066': 3, '5100452067': 3, '5100452076': 3, '5100452078': 3, '5100452079': 3, '5100452080': 3, '5100452081': 2, '5100461004': 2, '5100461005': 2, '5100461006': 2, '5100461007': 1, '5100461008': 2, '5100461009': 3, '5100461010': 2, '5100461011': 2, '5100461014': 2, '5100461015': 3, '5100461016': 2, '5100461017': 3, '5100461018': 2, '5100461020': 2, '5100461021': 2, '5100461022': 3, '5100461023': 3, '5100461025': 2, '5100461029': 2, '5100461030': 3, '5100461031': 2, '5100461032': 2, '5100461033': 2, '5100461034': 2, '5100461035': 2, '5100461036': 2, '5100461037': 2, '5100461038': 2, '5100461039': 3, '5100461040': 2, '5100461042': 3, '5100461043': 2, '5100461044': 3, '5100461046': 2, '5100461047': 2, '5100461048': 2, '5100461049': 2, '5100461050': 2, '5100461051': 3, '5100461052': 2, '5100461053': 3, '5100461054': 2, '5100461055': 3, '5100461056': 3, '5100461057': 2, '5100461058': 2, '5100461061': 3, '5100461062': 2, '5100461063': 2, '5100461064': 3, '5100461065': 3, '5100461066': 3, '5100461067': 2, '5100461068': 2, '5100461069': 3, '5100462001': 2, '5100462002': 2, '5100462003': 1, '5100462005': 2, '5100462009': 2, '5100462010': 3, '5100462011': 3, '5100462012': 2, '5100462014': 3, '5100462015': 2, '5100462016': 2, '5100462017': 2, '5100462018': 2, '5100462019': 2, '5100462021': 3, '5100462022': 2, '5100462023': 2, '5100462024': 2, '5100462025': 2, '5100462026': 3, '5100462027': 2, '5100462028': 3, '5100462029': 3, '5100462031': 2, '5100462032': 2, '5100462033': 2, '5100462035': 3, '5100462037': 3, '5100462038': 2, '5100462039': 2, '5100462040': 2, '5100462041': 3, '5100462042': 2, '5100462043': 2, '5100462044': 2, '5100462045': 2, '5100462046': 2, '5100462047': 3, '5100462048': 2, '5100462050': 2, '5100462051': 2, '5100462052': 2, '5100462053': 3, '5100462054': 2, '5100462055': 3, '5100462057': 2, '5100462058': 3, '5100462059': 2, '5100462061': 2, '5100462062': 2, '5100462063': 3, '5100462064': 3, '5100462066': 2, '5100462067': 2, '5100462068': 2, '5100462069': 3, '5100462070': 3, '5100462071': 2, '5100462072': 3, '5100462074': 2, '5100462075': 3, '5100462077': 3, '5100462078': 2, '5100462079': 2, '5100462080': 2, '5100462081': 2, '5100462082': 2, '5100471001': 2, '5100471002': 3, '5100471003': 3, '5100471011': 2, '5100471012': 2, '5100471013': 2, '5100471015': 2, '5100471016': 3, '5100471018': 2, '5100471019': 3, '5100471020': 2, '5100471021': 2, '5100471023': 2, '5100471026': 3, '5100471027': 2, '5100471028': 3, '5100471029': 2, '5100471030': 3, '5100471031': 2, '5100471034': 2, '5100471037': 3, '5100471038': 3, '5100471039': 3, '5100471041': 3, '5100471042': 2, '5100471044': 2, '5100471045': 2, '5100471047': 3, '5100471049': 2, '5100471050': 3, '5100471051': 2, '5100471052': 2, '5100471054': 2, '5100471056': 2, '5100471057': 3, '5100471058': 2, '5100471059': 2, '5100471060': 2, '5100471062': 3, '5100471063': 3, '5100471065': 2, '5100471068': 2, '5100471069': 3, '5100471070': 2, '5100471072': 2, '5100471074': 2, '5100471075': 2, '5100471080': 2, '5100471081': 2, '5100472001': 1, '5100472002': 2, '5100472003': 2, '5100472004': 3, '5100472005': 2, '5100472007': 3, '5100472009': 3, '5100472010': 3, '5100472011': 2, '5100472012': 2, '5100472014': 2, '5100472019': 2, '5100472020': 3, '5100472021': 3, '5100472027': 3, '5100472030': 2, '5100472031': 2, '5100472032': 3, '5100472035': 2, '5100472039': 2, '5100472040': 2, '5100472041': 3, '5100472042': 2, '5100472044': 2, '5100472045': 3, '5100472047': 2, '5100472050': 2, '5100472052': 3, '5100472053': 2, '5100472054': 2, '5100472058': 1, '5100472060': 2, '5100472063': 2, '5100472064': 2, '5221290110': 3, '5221290111': 3, '5221290112': 3, '5221290114': 3, '5221290115': 2, '5221290116': 2, '5221290118': 3, '5221290119': 3, '5221290121': 3, '5221290122': 3, '5221290123': 2, '5221290124': 3, '5221290126': 3, '5221290127': 3, '5221290129': 3, '522129013': 3, '5221290131': 2, '5221290132': 3, '5221290134': 3, '5221290135': 3, '5221290137': 3, '5221290138': 3, '5221290140': 3, '5221290141': 3, '5221290142': 2, '5221290144': 3, '5221290145': 3, '5221290147': 3, '5221290149': 3, '5221290150': 3, '5221290151': 3, '5221290155': 3, '5221290158': 3, '522129016': 3, '5221290161': 2, '5221290162': 2, '5221290163': 2, '5221290164': 2, '5221290165': 3, '5221290166': 3, '5221290167': 3, '5221290169': 3, '522129017': 3, '5221290171': 2, '5221290172': 3, '5221290173': 3, '5221290174': 3, '5221290175': 3, '5221290177': 3, '5221290178': 3, '5221290179': 2, '522129018': 2, '5221290180': 3, '5221290184': 2, '522129021': 2, '5221290210': 3, '5221290212': 3, '5221290213': 3, '5221290214': 3, '5221290215': 3, '5221290216': 3, '5221290217': 3, '522129022': 3, '5221290220': 3, '5221290221': 3, '5221290222': 3, '5221290223': 3, '5221290226': 3, '5221290227': 2, '5221290228': 2, '5221290230': 2, '5221290231': 3, '5221290235': 2, '5221290237': 2, '5221290238': 3, '5221290239': 3, '522129024': 2, '5221290240': 3, '5221290242': 3, '5221290247': 3, '5221290249': 3, '522129025': 3, '5221290250': 2, '5221290251': 3, '5221290252': 3, '5221290253': 3, '5221290254': 3, '5221290255': 3, '5221290256': 3, '5221290257': 2, '5221290258': 3, '5221290259': 3, '522129026': 3, '5221290263': 3, '5221290264': 3, '5221290266': 3, '5221290268': 3, '5221290269': 2, '522129027': 3, '5221290270': 3, '5221290271': 2, '5221290272': 2, '5221290273': 3, '5221290274': 3, '5221290275': 2, '5221290279': 3, '5221290280': 1, '5221290282': 3, '5221290284': 3, '5564630110': 2, '5564630112': 2, '5564630115': 2, '5564630117': 3, '556463012': 3, '5564630121': 3, '5564630122': 2, '5564630123': 3, '5564630126': 0, '5564630127': 3, '5564630128': 3, '5564630129': 3, '556463013': 3, '5564630130': 2, '5564630132': 1, '5564630133': 2, '5564630134': 2, '5564630135': 3, '5564630137': 1, '5564630138': 1, '5564630139': 2, '556463014': 1, '5564630140': 2, '5564630141': 1, '5564630142': 2, '5564630143': 2, '5564630145': 3, '5564630147': 2, '5564630148': 3, '5564630149': 2, '5564630150': 2, '5564630152': 2, '5564630153': 3, '5564630154': 1, '5564630156': 1, '5564630157': 3, '5564630158': 3, '556463016': 3, '5564630160': 2, '5564630161': 2, '5564630162': 3, '5564630163': 3, '5564630165': 2, '5564630166': 2, '5564630167': 3, '5564630168': 1, '556463018': 3, '556463019': 2, '5564630211': 1, '5564630212': 2, '5564630213': 3, '5564630215': 2, '5564630216': 3, '5564630217': 3, '5564630218': 2, '5564630219': 2, '556463022': 1, '5564630221': 3, '5564630222': 3, '5564630226': 1, '5564630228': 3, '5564630229': 3, '5564630230': 3, '5564630232': 2, '5564630233': 2, '5564630234': 3, '5564630235': 2, '5564630236': 3, '5564630237': 3, '5564630238': 1, '556463024': 3, '5564630240': 2, '5564630241': 3, '5564630247': 3, '5564630249': 3, '556463025': 1, '5564630252': 2, '5564630253': 3, '5564630254': 3, '5564630256': 2, '5564630257': 1, '5564630258': 3, '556463026': 2, '5564630261': 3, '5564630262': 3, '5564630264': 2, '5564630265': 3, '5564630269': 2, '556463027': 3, '5564630273': 2, '5564630275': 2, '5564630276': 3, '556463028': 2, '5564630281': 3, '556463029': 2, '567496011': 3, '5674960111': 2, '5674960114': 3, '5674960115': 2, '5674960116': 3, '5674960117': 2, '5674960118': 2, '5674960121': 3, '5674960123': 3, '5674960124': 2, '5674960125': 3, '5674960126': 3, '567496013': 2, '5674960131': 2, '5674960132': 3, '5674960134': 3, '5674960136': 2, '5674960138': 2, '567496014': 3, '5674960142': 2, '5674960144': 3, '5674960145': 3, '5674960146': 3, '5674960148': 3, '5674960151': 3, '5674960153': 3, '5674960154': 3, '5674960155': 1, '5674960156': 2, '5674960157': 2, '5674960158': 2, '5674960160': 3, '5674960161': 2, '5674960166': 3, '567496017': 2, '5674960170': 3, '567496018': 2, '567496019': 3, '567496021': 1, '5674960211': 2, '5674960215': 3, '5674960216': 3, '5674960219': 3, '567496022': 1, '5674960220': 3, '5674960221': 3, '5674960222': 1, '5674960224': 3, '5674960225': 0, '5674960227': 3, '5674960228': 3, '5674960229': 2, '5674960230': 3, '5674960234': 2, '5674960235': 2, '567496024': 2, '5674960242': 2, '5674960246': 3, '5674960249': 2, '5674960251': 3, '5674960252': 2, '5674960255': 2, '5674960257': 2, '567496026': 3, '5674960261': 2, '5674960264': 3, '5674960268': 3, '5674960272': 3, '5674960273': 2, '5674960274': 3, '5674960275': 3, '5674960276': 3, '5674960277': 3, '5674960278': 3, '5674960279': 3, '567496028': 2, '5674960281': 3, '5674960282': 3, '5674960283': 0, '567496029': 3, '5912920111': 2, '5912920112': 3, '5912920113': 3, '5912920114': 2, '5912920119': 3, '5912920121': 3, '5912920123': 3, '5912920124': 2, '5912920125': 2, '5912920126': 3, '5912920127': 3, '5912920128': 1, '5912920129': 2, '5912920131': 3, '5912920133': 2, '5912920135': 3, '5912920137': 3, '5912920140': 3, '5912920142': 3, '5912920143': 2, '5912920145': 2, '5912920146': 2, '5912920147': 3, '5912920148': 3, '5912920149': 2, '591292015': 3, '5912920151': 3, '5912920152': 3, '5912920154': 3, '5912920156': 3, '5912920158': 3, '5912920159': 3, '5912920160': 3, '5912920163': 2, '5912920167': 2, '5912920168': 3, '5912920169': 2, '5912920170': 3, '5912920171': 3, '5912920172': 3, '591292019': 3, '591292021': 3, '5912920211': 3, '5912920212': 3, '5912920213': 3, '5912920216': 3, '5912920217': 2, '5912920220': 2, '5912920222': 3, '5912920223': 2, '5912920225': 3, '5912920227': 3, '5912920228': 2, '5912920230': 3, '5912920231': 3, '5912920233': 3, '5912920234': 2, '5912920235': 3, '5912920236': 3, '5912920239': 2, '591292024': 3, '5912920240': 3, '5912920241': 3, '5912920242': 2, '5912920243': 2, '5912920244': 2, '5912920245': 3, '5912920249': 3, '5912920250': 3, '5912920256': 3, '5912920260': 3, '5912920263': 3, '5912920265': 3, '5912920266': 2, '5912920267': 3, '5912920268': 3, '5912920273': 3, '5912920274': 3, '5912920275': 3, '5912920276': 3, '5912920277': 3, '5912920279': 3, '5912920280': 3, '769862011': 3, '7698620112': 3, '7698620113': 3, '7698620115': 3, '7698620116': 3, '7698620118': 2, '7698620120': 3, '7698620122': 3, '7698620123': 3, '7698620126': 3, '7698620129': 3, '7698620130': 2, '7698620131': 2, '7698620132': 3, '7698620133': 3, '7698620134': 3, '7698620136': 2, '7698620138': 3, '7698620139': 3, '769862014': 3, '7698620141': 3, '7698620144': 3, '7698620145': 2, '7698620149': 3, '769862015': 2, '7698620150': 3, '7698620151': 3, '7698620152': 3, '7698620153': 3, '7698620156': 2, '7698620158': 3, '769862016': 2, '7698620160': 3, '7698620161': 3, '7698620163': 3, '7698620165': 3, '7698620166': 2, '7698620167': 3, '7698620169': 3, '769862017': 1, '7698620170': 2, '7698620171': 3, '769862018': 3, '769862019': 3, '769862021': 3, '7698620211': 3, '7698620212': 3, '7698620217': 3, '7698620218': 3, '769862022': 3, '7698620221': 3, '7698620222': 3, '7698620224': 3, '7698620225': 2, '7698620227': 2, '7698620229': 2, '7698620230': 3, '7698620231': 3, '7698620233': 1, '7698620236': 2, '7698620238': 3, '7698620239': 3, '7698620240': 3, '7698620241': 2, '7698620244': 3, '7698620245': 3, '7698620248': 2, '7698620250': 3, '7698620252': 1, '7698620253': 2, '7698620255': 2, '7698620256': 3, '7698620257': 3, '7698620258': 3, '7698620260': 2, '7698620261': 3, '7698620262': 2, '7698620264': 2, '7698620265': 3, '7698620267': 3, '7698620268': 3, '769862027': 3, '7698620270': 3, '7698620272': 3, '7698620274': 3, '7698620275': 3, '7698620278': 2, '769862028': 3, '7698620281': 3, '7698620283': 3, '7994020110': 3, '79940201100': 2, '79940201110': 3, '79940201140': 3, '79940201150': 3, '79940201160': 3, '79940201180': 3, '79940201210': 3, '79940201230': 3, '79940201250': 3, '79940201270': 2, '7994020130': 2, '79940201300': 1, '79940201320': 3, '79940201330': 3, '79940201340': 3, '79940201350': 3, '79940201360': 3, '79940201370': 2, '79940201380': 3, '79940201390': 1, '7994020140': 2, '79940201410': 3, '79940201420': 3, '79940201430': 3, '79940201470': 3, '79940201490': 3, '79940201510': 2, '79940201560': 2, '79940201570': 3, '79940201580': 2, '7994020160': 3, '79940201620': 3, '79940201650': 2, '79940201660': 1, '79940201690': 3, '79940201700': 2, '79940201710': 3, '79940201720': 3, '79940201730': 2, '79940201740': 3, '79940201750': 2, '79940201760': 3, '79940201770': 3, '79940201780': 3, '79940201790': 1, '79940201810': 3, '79940201820': 3, '79940201850': 2, '79940201860': 3, '79940201880': 3, '79940201930': 2, '79940201950': 3, '79940202100': 3, '79940202120': 3, '79940202130': 2, '79940202140': 2, '79940202160': 3, '79940202170': 2, '79940202180': 2, '79940202190': 2, '79940202200': 3, '79940202210': 2, '79940202220': 2, '79940202230': 3, '79940202270': 1, '79940202280': 1, '7994020230': 1, '79940202300': 2, '79940202310': 1, '79940202320': 3, '79940202340': 2, '79940202350': 2, '79940202370': 3, '79940202390': 2, '79940202400': 2, '79940202410': 2, '79940202450': 2, '79940202470': 2, '79940202480': 2, '79940202490': 1, '7994020250': 3, '79940202510': 2, '79940202520': 3, '79940202540': 3, '79940202560': 3, '79940202570': 3, '79940202580': 2, '79940202620': 3, '79940202690': 3, '7994020270': 3, '79940202700': 3, '79940202710': 2, '79940202750': 2, '79940202760': 3, '79940202790': 3, '7994020280': 2, '79940202800': 1, '79940202820': 2, '79940202840': 1, '79940202850': 1, '79940202860': 1, '79940202870': 2, '79940202890': 3, '7994020290': 3, '8263820112': 3, '8263820113': 2, '8263820120': 2, '8263820123': 2, '8263820124': 2, '8263820126': 3, '8263820132': 3, '8263820135': 2, '8263820136': 3, '8263820138': 2, '8263820139': 2, '8263820140': 2, '8263820141': 2, '8263820144': 3, '8263820145': 2, '8263820146': 2, '8263820147': 3, '8263820148': 3, '826382015': 2, '8263820150': 3, '8263820151': 3, '8263820152': 2, '8263820155': 2, '8263820156': 2, '8263820159': 3, '826382016': 3, '8263820160': 3, '8263820162': 3, '8263820165': 3, '8263820169': 2, '8263820170': 3, '826382018': 3, '826382021': 2, '8263820210': 2, '8263820211': 3, '8263820212': 3, '8263820213': 2, '8263820214': 3, '8263820221': 3, '8263820223': 2, '8263820224': 2, '8263820227': 2, '8263820228': 2, '826382023': 3, '8263820231': 3, '8263820233': 3, '8263820234': 3, '8263820235': 3, '8263820237': 3, '8263820239': 3, '826382024': 1, '8263820240': 3, '8263820242': 2, '8263820243': 3, '8263820245': 2, '8263820246': 3, '8263820247': 2, '8263820251': 3, '8263820253': 2, '8263820254': 3, '8263820255': 2, '8263820256': 2, '8263820257': 2, '8263820259': 3, '826382026': 3, '8263820260': 2, '8263820264': 3, '8263820265': 2, '8263820266': 2, '8263820268': 3, '8263820269': 2, '826382027': 2, '8263820272': 3, '8263820273': 3, '8263820275': 2, '8263820277': 2, '8263820278': 2, '8263820279': 3, '826382028': 2, '826412010': 3, '8264120110': 2, '8264120111': 2, '8264120112': 2, '8264120113': 3, '8264120116': 1, '8264120117': 3, '8264120119': 3, '8264120120': 1, '8264120121': 2, '8264120122': 2, '8264120123': 1, '8264120124': 2, '8264120125': 2, '8264120126': 2, '8264120127': 1, '826412013': 1, '8264120131': 2, '8264120132': 2, '8264120136': 2, '8264120139': 3, '8264120141': 2, '8264120144': 3, '8264120145': 3, '8264120146': 3, '8264120149': 2, '8264120150': 1, '8264120156': 1, '8264120157': 2, '8264120159': 2, '8264120165': 3, '8264120166': 3, '8264120169': 1, '826412017': 2, '826412018': 2, '826412019': 2, '8264120210': 2, '8264120211': 1, '8264120213': 3, '8264120215': 3, '8264120216': 3, '8264120218': 3, '8264120219': 3, '8264120220': 2, '8264120221': 3, '8264120223': 2, '8264120224': 3, '8264120227': 3, '8264120228': 3, '8264120229': 2, '826412023': 3, '8264120231': 1, '8264120232': 2, '8264120233': 3, '8264120234': 2, '8264120239': 1, '826412024': 3, '8264120240': 0, '8264120241': 2, '8264120242': 2, '8264120243': 1, '8264120245': 2, '8264120247': 3, '8264120248': 2, '8264120249': 1, '826412025': 2, '8264120254': 1, '8264120256': 1, '8264120257': 3, '8264120258': 2, '8264120261': 1, '8264120262': 1, '8264120263': 1, '8264120265': 1, '8264120266': 1, '8264120268': 3, '8264120269': 1, '826412027': 2, '8264120274': 3, '8264120275': 3, '8264120279': 1, '8264120280': 2, '8264120282': 1, '8264120284': 1, '88265401100': 3, '88265401130': 3, '88265401140': 3, '88265401150': 3, '88265401160': 3, '88265401170': 2, '88265401190': 3, '8826540120': 3, '88265401200': 2, '88265401240': 3, '88265401260': 3, '88265401270': 3, '88265401280': 3, '88265401300': 3, '88265401320': 3, '88265401350': 3, '88265401360': 3, '88265401380': 3, '88265401390': 3, '88265401400': 3, '88265401410': 3, '88265401420': 2, '88265401430': 3, '88265401450': 3, '88265401470': 2, '88265401480': 3, '88265401490': 3, '8826540150': 3, '88265401520': 3, '88265401550': 3, '88265401630': 2, '88265401640': 2, '88265401660': 3, '88265401690': 3, '8826540170': 3, '88265401730': 3, '88265401740': 3, '88265401750': 1, '8826540180': 3, '88265402120': 3, '88265402150': 3, '88265402160': 2, '88265402170': 3, '88265402180': 2, '88265402190': 3, '88265402200': 3, '88265402230': 2, '88265402240': 2, '88265402270': 2, '8826540230': 3, '88265402300': 3, '88265402310': 3, '88265402320': 2, '88265402330': 3, '88265402340': 2, '88265402350': 3, '88265402370': 3, '88265402380': 3, '8826540240': 3, '88265402400': 2, '88265402420': 3, '88265402440': 2, '88265402450': 3, '88265402480': 2, '88265402490': 3, '88265402500': 3, '88265402520': 3, '88265402540': 2, '88265402570': 2, '88265402580': 3, '88265402590': 3, '8826540260': 2, '88265402600': 2, '88265402630': 3, '88265402660': 3, '88265402690': 3, '8826540270': 3, '88265402700': 3, '88265402770': 3, '88265402780': 3, '88265402790': 2, '8826540280': 2, '88265402800': 3, '88265402810': 3, '88265402820': 3, '88265402840': 3, '88265402850': 3, '88265402880': 2, '88265402890': 3, '8826540290': 3, '88265402900': 3, '907001100': 3, '9070011010': 2, '9070011020': 3, '9070011060': 3, '9070011090': 2, '907001110': 3, '9070011110': 3, '907001120': 2, '907001150': 3, '907001160': 2, '907001170': 3, '907001180': 3, '907001210': 3, '907001220': 3, '907001240': 3, '907001270': 2, '907001280': 3, '907001310': 3, '907001340': 3, '907001350': 3, '907001360': 3, '907001370': 3, '907001400': 3, '907001430': 2, '907001450': 3, '907001480': 1, '907001490': 3, '90700150': 3, '907001500': 3, '907001520': 3, '907001550': 3, '907001560': 2, '907001570': 3, '907001580': 3, '90700160': 3, '907001600': 3, '907001620': 3, '907001650': 2, '907001670': 3, '907001680': 3, '90700170': 3, '907001730': 3, '907001740': 2, '907001780': 3, '907001790': 3, '90700180': 3, '907001820': 3, '907001840': 3, '907001850': 3, '907001860': 3, '90700190': 3, '907001910': 2, '907001940': 3, '907001950': 1, '907001970': 3, '9289010111': 2, '9289010112': 2, '9289010113': 2, '9289010114': 1, '9289010115': 3, '9289010117': 3, '9289010118': 3, '9289010119': 3, '9289010120': 2, '9289010121': 2, '9289010127': 2, '928901013': 3, '9289010131': 2, '9289010132': 2, '9289010133': 3, '9289010134': 3, '9289010138': 2, '9289010139': 2, '928901014': 1, '9289010143': 2, '9289010144': 2, '9289010145': 1, '9289010147': 2, '9289010149': 3, '9289010150': 3, '9289010151': 3, '9289010152': 1, '9289010153': 2, '9289010154': 2, '9289010155': 3, '9289010157': 3, '9289010158': 3, '928901016': 2, '9289010160': 3, '9289010161': 2, '9289010163': 3, '9289010166': 2, '9289010167': 3, '928901018': 3, '9289010210': 3, '9289010211': 2, '9289010216': 3, '9289010221': 3, '9289010222': 3, '9289010223': 3, '9289010227': 3, '9289010229': 3, '928901023': 3, '9289010230': 3, '9289010231': 2, '9289010232': 3, '9289010233': 3, '9289010235': 3, '9289010242': 3, '9289010243': 3, '9289010244': 3, '9289010245': 3, '9289010248': 3, '9289010249': 3, '928901025': 3, '9289010250': 2, '9289010251': 3, '9289010253': 3, '9289010254': 2, '9289010257': 3, '9289010259': 3, '928901026': 3, '9289010261': 3, '9289010262': 3, '9289010263': 2, '9289010265': 3, '9289010266': 3, '9289010267': 3, '9289010268': 3, '9289010269': 3, '9289010270': 3, '9289010271': 2, '9289010273': 3, '9289010274': 3, '9289010275': 3, '9289010276': 1, '9289010278': 3, '928901028': 3, '928901029': 3, '940328011': 3, '9403280110': 3, '9403280112': 3, '9403280114': 3, '9403280115': 2, '9403280116': 3, '9403280117': 3, '940328012': 3, '9403280126': 3, '9403280129': 3, '9403280132': 3, '9403280134': 2, '9403280136': 3, '9403280138': 2, '940328014': 3, '9403280140': 2, '9403280143': 2, '9403280145': 2, '9403280146': 2, '9403280147': 3, '9403280149': 3, '9403280150': 3, '9403280151': 2, '9403280152': 2, '9403280155': 3, '9403280156': 3, '9403280157': 2, '9403280159': 3, '940328016': 3, '9403280164': 3, '9403280165': 2, '9403280167': 3, '940328017': 3, '940328018': 3, '9403280212': 3, '9403280213': 2, '9403280217': 2, '9403280218': 2, '9403280219': 2, '940328022': 3, '9403280227': 2, '9403280229': 3, '9403280234': 3, '9403280235': 2, '9403280236': 2, '9403280238': 2, '9403280241': 3, '9403280243': 3, '9403280245': 3, '9403280246': 3, '9403280247': 2, '9403280249': 3, '9403280250': 2, '9403280251': 2, '9403280254': 3, '9403280255': 3, '9403280256': 3, '9403280259': 3, '9403280260': 3, '9403280262': 3, '9403280265': 3, '9403280266': 3, '9403280271': 1, '9403280272': 3, '9403280273': 2, '9403280277': 3, '9403280279': 3, '9877360111': 3, '9877360113': 2, '9877360114': 3, '9877360115': 3, '9877360116': 2, '9877360117': 2, '9877360120': 1, '9877360121': 2, '9877360124': 3, '9877360125': 3, '9877360126': 3, '9877360127': 2, '9877360128': 3, '9877360130': 2, '9877360131': 3, '9877360132': 2, '9877360133': 0, '9877360134': 3, '9877360135': 2, '9877360138': 2, '987736014': 3, '9877360140': 3, '9877360141': 3, '9877360143': 3, '9877360147': 3, '9877360149': 3, '987736015': 2, '9877360151': 3, '9877360152': 3, '9877360154': 2, '9877360156': 3, '9877360157': 1, '9877360158': 3, '9877360159': 3, '987736016': 3, '9877360163': 2, '9877360164': 3, '9877360165': 3, '9877360166': 3, '9877360168': 3, '9877360169': 1}\n"
     ]
    }
   ],
   "source": [
    "ENGAGE_WILD_DATASET, BIN_CLASSIFICATION, N_CLASSES, DATASET_NAME, BASE_DATASET_DIR, ext = define_dataset(False, False)\n",
    "video2label, labels_list = get_video2label()\n",
    "print(labels_list)\n",
    "print(video2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0457c192-d2c3-4758-95d0-f66fa8236d53",
   "metadata": {},
   "source": [
    "### Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa6d971d-9289-4977-9781-978d4570376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.std\n",
    "stat_name = \"std\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217d7935-8567-42df-a191-57b896adb76a",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1c704b4-b615-42f2-957c-078db0e1e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb3844dd-b51c-44e2-99bd-92c3f955748f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74e04b98-676a-45de-a6da-5605a83cc06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 34/5482: 0.6202116016052536%\n",
      "1 214/5482: 3.903684786574243%\n",
      "2 2649/5482: 48.32178037212696%\n",
      "3 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0 4/1723: 0.2321532211259431%\n",
      "1 81/1723: 4.7011027278003485%\n",
      "2 861/1723: 49.97098084735926%\n",
      "3 777/1723: 45.095763203714455%\n",
      "val:\n",
      "0 23/1720: 1.3372093023255813%\n",
      "1 160/1720: 9.30232558139535%\n",
      "2 912/1720: 53.02325581395349%\n",
      "3 625/1720: 36.33720930232558%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4679692e-6a4c-4bc0-bd38-a2223d051fdc",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d0d1566-1f6d-4dba-b6fc-72a923743e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_4_std_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25e1caea-62f1-4ff1-bb87-62c62beb9ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7475924-8977-4018-8b91-8f63bdc60e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2048) (5482,)\n",
      "(1723, 128, 2048) (1723,)\n",
      "(1720, 128, 2048) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3257cf44-7163-4704-b0f8-e7cc30aeee43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  34  214 2649 2585] {0: 77.91176470588235, 1: 12.378504672897195, 2: 1.0, 3: 1.0247582205029013} 4 [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b34b83b-7691-4b63-9b35-2032685b7318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-10 09:28:38.764191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 4)                    2052      ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1053189 (4.02 MB)\n",
      "Trainable params: 1053189 (4.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "save_best_model = SaveBestModelByUAR(X_subsample_val, y_subsample_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ad83f16-437a-4dcd-9dd7-371c91007c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-10 09:28:45.676980: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4f2d2da680 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-10 09:28:45.677140: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-08-10 09:28:45.681443: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-10 09:28:45.713825: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-08-10 09:28:45.767543: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 6s 114ms/step - loss: 2.8375 - val_loss: 1.2770 - val_uar: 0.3432 - val_bacc: 0.3432 - val_f1: 0.3180 - val_mcc: 0.1318\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 2.2408 - val_loss: 1.5110 - val_uar: 0.3283 - val_bacc: 0.3283 - val_f1: 0.2390 - val_mcc: 0.0903\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 2.0112 - val_loss: 1.3204 - val_uar: 0.3666 - val_bacc: 0.3666 - val_f1: 0.3297 - val_mcc: 0.1206\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 76ms/step - loss: 1.9443 - val_loss: 1.3231 - val_uar: 0.3775 - val_bacc: 0.3775 - val_f1: 0.3547 - val_mcc: 0.1364\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 3s 72ms/step - loss: 1.7967 - val_loss: 1.2357 - val_uar: 0.3618 - val_bacc: 0.3618 - val_f1: 0.3459 - val_mcc: 0.1445\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 3s 74ms/step - loss: 1.8052 - val_loss: 1.1063 - val_uar: 0.3697 - val_bacc: 0.3697 - val_f1: 0.4477 - val_mcc: 0.1691\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 3s 73ms/step - loss: 1.7013 - val_loss: 1.1151 - val_uar: 0.3554 - val_bacc: 0.3554 - val_f1: 0.4663 - val_mcc: 0.1611\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 1.6271 - val_loss: 1.3984 - val_uar: 0.4168 - val_bacc: 0.4168 - val_f1: 0.3384 - val_mcc: 0.1320\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 1.5454 - val_loss: 1.2400 - val_uar: 0.3530 - val_bacc: 0.3530 - val_f1: 0.3965 - val_mcc: 0.1612\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 55ms/step - loss: 1.6054 - val_loss: 1.0790 - val_uar: 0.3437 - val_bacc: 0.3437 - val_f1: 0.4535 - val_mcc: 0.1624\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 1.5657 - val_loss: 1.3072 - val_uar: 0.3496 - val_bacc: 0.3496 - val_f1: 0.3837 - val_mcc: 0.1332\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 1.5346 - val_loss: 1.1919 - val_uar: 0.3496 - val_bacc: 0.3496 - val_f1: 0.3785 - val_mcc: 0.1497\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 3s 73ms/step - loss: 1.5016 - val_loss: 1.1817 - val_uar: 0.3767 - val_bacc: 0.3767 - val_f1: 0.4093 - val_mcc: 0.1449\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 3s 72ms/step - loss: 1.4304 - val_loss: 1.1798 - val_uar: 0.3766 - val_bacc: 0.3766 - val_f1: 0.4599 - val_mcc: 0.1833\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 3s 72ms/step - loss: 1.3978 - val_loss: 1.1787 - val_uar: 0.3444 - val_bacc: 0.3444 - val_f1: 0.4023 - val_mcc: 0.1644\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 1.3653 - val_loss: 1.1805 - val_uar: 0.3644 - val_bacc: 0.3644 - val_f1: 0.4047 - val_mcc: 0.1581\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 1.3881 - val_loss: 1.0755 - val_uar: 0.3477 - val_bacc: 0.3477 - val_f1: 0.4855 - val_mcc: 0.1836\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 1.3360 - val_loss: 1.1193 - val_uar: 0.3375 - val_bacc: 0.3375 - val_f1: 0.4436 - val_mcc: 0.1600\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 55ms/step - loss: 1.3018 - val_loss: 1.1611 - val_uar: 0.3557 - val_bacc: 0.3557 - val_f1: 0.4674 - val_mcc: 0.1629\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 54ms/step - loss: 1.3829 - val_loss: 1.0992 - val_uar: 0.3506 - val_bacc: 0.3506 - val_f1: 0.4855 - val_mcc: 0.1740\n",
      "0.4167658466819222\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5c939a7e-4fdb-432f-a7ab-01f3a9f6f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31179eae-1654-47f5-867f-a1b710575843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 ... 1 1 3]\n",
      "[2 1 3 ... 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(pred)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b07e9675-d852-44ec-9953-d2fe284c5af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_std_single_attention_traditional Accuracy:  0.3847939640162507 MSE:  0.1150275101567034 UAR:  0.3215913358189781 Recall:  N/A Precision:  N/A F1:  0.2559559740639829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3847939640162507,\n",
       " 0.1150275101567034,\n",
       " 0.3215913358189781,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.2559559740639829)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23964fe0-185e-46fd-b85e-08cb19b3eaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a6d2c5b-4b57-460e-9f8b-70fe57df3993",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dbf07197-ccfb-4354-84e0-a90b0a05e839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_std_single_attention_traditional_best Accuracy:  0.3232733604178758 MSE:  0.19624248403946606 UAR:  0.37646197300668843 Recall:  N/A Precision:  N/A F1:  0.2209256312589682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3232733604178758,\n",
       " 0.19624248403946606,\n",
       " 0.37646197300668843,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.2209256312589682)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78c46aa-961f-4ee3-971f-70526c984665",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f3ec89e-3677-44cc-b9c0-01dbcb3d229c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9007617d-8226-4866-810a-f67af0a2c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True\n",
    "#IMAGE_SET_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3bbb3cc5-be33-4f89-9694-4bf064ef6e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b092d52-838c-40df-bb99-d6a5d7025ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 21:09:58.494035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f588c80-fdba-4711-ab88-5612dc7d363c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 21:10:14.656351: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f86f8a32620 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-07 21:10:14.656520: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-08-07 21:10:14.660809: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-07 21:10:14.697393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-08-07 21:10:14.749217: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 8s 149ms/step - loss: 0.0813 - mae: 0.2003 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 5/20\n",
      "37/43 [========================>.....] - ETA: 0s - loss: 0.0797 - mae: 0.1962"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m     modelAtn\u001b[38;5;241m.\u001b[39mfit(train_generator,steps_per_epoch\u001b[38;5;241m=\u001b[39mnum_samples_train\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mBATCH_SIZE,\n\u001b[1;32m      3\u001b[0m                      epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[save_best_model],\n\u001b[1;32m      4\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39mtest_generator,validation_steps\u001b[38;5;241m=\u001b[39mnum_samples_test\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mBATCH_SIZE, class_weight\u001b[38;5;241m=\u001b[39mclass_weights)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mmodelAtn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_subsample_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_subsample_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msave_best_model\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m             \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_subsample_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_subsample_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, class_weight=class_weights)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m best_model_weights \u001b[38;5;241m=\u001b[39m save_best_model\u001b[38;5;241m.\u001b[39mbest_model_weights\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(save_best_model\u001b[38;5;241m.\u001b[39mbest)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if USE_GENERATORS:\n",
    "    modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                     epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                    validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "else:\n",
    "    modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "             validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "best_model_weights = save_best_model.best_model_weights\n",
    "print(save_best_model.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f7257f27-c6bd-4f22-988b-a2821843b727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 120ms/step - loss: 0.0812 - mae: 0.2005 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "0.11642508953809738\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a951e0d-d72f-4867-b947-136113d4e74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab99ec6d-db90-4479-83cc-53755d03cf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_traditional Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "146cfd71-9ac1-48eb-b848-2497746c197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2aca5524-e864-44d5-a838-d1cf18efa9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a45670d-9c95-4ec1-9484-113a3c6527fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_traditional_best Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae46e62e-5bb7-41b9-b4bc-6dbbe43abcb9",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fc25b1bf-4018-4efe-b36f-eb962d1b5a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "625fd42a-dfdb-4263-b3a0-8a46aa4895b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bf68574c-6ad1-41e7-8e21-b8b410e4debf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 34/5482: 0.6202116016052536%\n",
      "1 214/5482: 3.903684786574243%\n",
      "2 2649/5482: 48.32178037212696%\n",
      "3 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0 4/1723: 0.2321532211259431%\n",
      "1 81/1723: 4.7011027278003485%\n",
      "2 861/1723: 49.97098084735926%\n",
      "3 777/1723: 45.095763203714455%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "99d8575b-344a-4ec8-a873-aa68cd313a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482,) (5482,)\n",
      "(1723,) (1723,)\n",
      "(7205,) (7205,)\n",
      "[0 1 2 3] [  38  295 3510 3362]\n",
      "7205\n",
      "5474\n",
      "1731\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bbecb4c9-210e-4d33-94c5-1438b9601e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 28/5474: 0.5115089514066496%\n",
      "1 224/5474: 4.092071611253197%\n",
      "2 2667/5474: 48.72122762148338%\n",
      "3 2555/5474: 46.67519181585678%\n",
      "test:\n",
      "0 10/1731: 0.5777007510109763%\n",
      "1 71/1731: 4.101675332177932%\n",
      "2 843/1731: 48.7001733102253%\n",
      "3 807/1731: 46.62045060658579%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18ad429-ed53-4d2a-8fb9-4d5005a5a253",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cefa5cfa-95ac-49cb-a4bb-6dc9b5a69fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_4_std_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5cefcf0-0453-4d4e-b382-c9ed698d11a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "745d4921-3673-4b43-9ec0-e47cf553c812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 2048) (5474,)\n",
      "(1731, 128, 2048) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a8ab5707-eccf-4baf-8bd5-e6a26f36d100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  28  224 2667 2555] {0: 95.24999999999999, 1: 11.906249999999998, 2: 1.0, 3: 1.0438356164383562} 4 [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50604433-1da0-400a-9157-41e6edc060f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 4)                    2052      ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1053189 (4.02 MB)\n",
      "Trainable params: 1053189 (4.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "save_best_model = SaveBestModelByUAR(X_subsample_test, y_subsample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "910aa935-a625-4183-b5c4-38eee9a89c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 2.8562 - val_loss: 1.0445 - val_uar: 0.4139 - val_bacc: 0.4139 - val_f1: 0.5737 - val_mcc: 0.2508\n",
      "Epoch 2/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 2.3541 - val_loss: 1.0251 - val_uar: 0.4475 - val_bacc: 0.4475 - val_f1: 0.5540 - val_mcc: 0.2441\n",
      "Epoch 3/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 2.1370 - val_loss: 1.1285 - val_uar: 0.4525 - val_bacc: 0.4525 - val_f1: 0.4922 - val_mcc: 0.2041\n",
      "Epoch 4/20\n",
      "55/55 [==============================] - 0s 8ms/step\n",
      "43/43 [==============================] - 3s 60ms/step - loss: 2.0137 - val_loss: 1.0289 - val_uar: 0.4784 - val_bacc: 0.4784 - val_f1: 0.5448 - val_mcc: 0.2532\n",
      "Epoch 5/20\n",
      "55/55 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 2s 55ms/step - loss: 1.8519 - val_loss: 1.0533 - val_uar: 0.4685 - val_bacc: 0.4685 - val_f1: 0.5251 - val_mcc: 0.2274\n",
      "Epoch 6/20\n",
      "55/55 [==============================] - 0s 4ms/stepo\n",
      "43/43 [==============================] - 2s 55ms/step - loss: 1.8670 - val_loss: 1.0450 - val_uar: 0.4729 - val_bacc: 0.4729 - val_f1: 0.4743 - val_mcc: 0.2115\n",
      "Epoch 7/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 1.7768 - val_loss: 1.2465 - val_uar: 0.4464 - val_bacc: 0.4464 - val_f1: 0.4073 - val_mcc: 0.1612\n",
      "Epoch 8/20\n",
      "55/55 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 1.7145 - val_loss: 1.0123 - val_uar: 0.4804 - val_bacc: 0.4804 - val_f1: 0.5442 - val_mcc: 0.2472\n",
      "Epoch 9/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 58ms/step - loss: 1.6068 - val_loss: 1.0936 - val_uar: 0.4456 - val_bacc: 0.4456 - val_f1: 0.5049 - val_mcc: 0.2317\n",
      "Epoch 10/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 1.6427 - val_loss: 1.0804 - val_uar: 0.4951 - val_bacc: 0.4951 - val_f1: 0.4864 - val_mcc: 0.2260\n",
      "Epoch 11/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 1.5504 - val_loss: 1.0668 - val_uar: 0.4708 - val_bacc: 0.4708 - val_f1: 0.4801 - val_mcc: 0.2085\n",
      "Epoch 12/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 1.5055 - val_loss: 0.9806 - val_uar: 0.4586 - val_bacc: 0.4586 - val_f1: 0.5413 - val_mcc: 0.2552\n",
      "Epoch 13/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 1.4603 - val_loss: 0.9723 - val_uar: 0.4719 - val_bacc: 0.4719 - val_f1: 0.5442 - val_mcc: 0.2522\n",
      "Epoch 14/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 1.4592 - val_loss: 0.9885 - val_uar: 0.5231 - val_bacc: 0.5231 - val_f1: 0.5344 - val_mcc: 0.2520\n",
      "Epoch 15/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 1.4003 - val_loss: 0.9927 - val_uar: 0.4969 - val_bacc: 0.4969 - val_f1: 0.5355 - val_mcc: 0.2564\n",
      "Epoch 16/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 3s 60ms/step - loss: 1.4810 - val_loss: 0.9643 - val_uar: 0.4397 - val_bacc: 0.4397 - val_f1: 0.5546 - val_mcc: 0.2618\n",
      "Epoch 17/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 1.3994 - val_loss: 1.0330 - val_uar: 0.5135 - val_bacc: 0.5135 - val_f1: 0.5188 - val_mcc: 0.2294\n",
      "Epoch 18/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 1.3392 - val_loss: 0.9652 - val_uar: 0.4723 - val_bacc: 0.4723 - val_f1: 0.5402 - val_mcc: 0.2433\n",
      "Epoch 19/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 55ms/step - loss: 1.3304 - val_loss: 0.9603 - val_uar: 0.4774 - val_bacc: 0.4774 - val_f1: 0.5373 - val_mcc: 0.2540\n",
      "Epoch 20/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 1.2617 - val_loss: 0.9619 - val_uar: 0.4805 - val_bacc: 0.4805 - val_f1: 0.5407 - val_mcc: 0.2535\n",
      "0.5230576451960338\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "98f1ca23-ae8e-4082-8101-f873a07c5d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d8000e04-ebdc-4bc1-8995-7888e67b2c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_std_single_attention_balanced Accuracy:  0.5389948006932409 MSE:  0.07840184864240322 UAR:  0.4795917764942945 Recall:  N/A Precision:  N/A F1:  0.38897043657279845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5389948006932409,\n",
       " 0.07840184864240322,\n",
       " 0.4795917764942945,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.38897043657279845)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0e67a3eb-fe1e-461b-8681-302d20203108",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a5063353-1e19-49bc-8a24-76fc8d352cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "81604072-5a27-4021-ab67-7ee632ef5a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_std_single_attention_balanced_best Accuracy:  0.5326400924321202 MSE:  0.08611894858463315 UAR:  0.5286038697535108 Recall:  N/A Precision:  N/A F1:  0.3814932102066016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5326400924321202,\n",
       " 0.08611894858463315,\n",
       " 0.5286038697535108,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.3814932102066016)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b64f34c-991e-46e5-a455-ff6a6f07fd3f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bf7f3055-2cc0-45d8-a144-cf748f99e0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5eb292ee-19c8-400b-9806-3069cf8c7944",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a08d2fa9-3291-422e-a059-609b45e84630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 2560) (5474,)\n",
      "(1731, 128, 2560) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f779a475-41e6-4eed-96bb-19a66e89fc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "78ac566e-3cd4-4dfc-acae-b648bf2303cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 125ms/step - loss: 0.0812 - mae: 0.2012 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "0.08048681914806366\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "991ffdb7-9fb6-4b0d-909a-9be912e20592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0ab0ec9e-17f6-4a55-9897-12de333bb53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "32c05672-f032-4791-9141-5636a428ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "95e6304f-8a7a-402f-962e-32707dcc44df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c48ee7b8-5aad-4f05-8a41-3de4336d8be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced_best Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20371a2d-e0ae-4d7b-9cab-b0bbb7524691",
   "metadata": {},
   "source": [
    "### Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b9cc9ee8-49f1-42db-8667-84bd593a3df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.max\n",
    "stat_name = \"max\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9bfc8b-bf0a-4214-8ac5-49819b38cd88",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "06323f5e-f14f-486d-81f5-29fe6a9d17f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "74a5701b-ec4e-4cc2-bdfc-25b413de2d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3da1868b-2cf6-4003-8be3-18e453570a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 34/5482: 0.6202116016052536%\n",
      "1 214/5482: 3.903684786574243%\n",
      "2 2649/5482: 48.32178037212696%\n",
      "3 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0 4/1723: 0.2321532211259431%\n",
      "1 81/1723: 4.7011027278003485%\n",
      "2 861/1723: 49.97098084735926%\n",
      "3 777/1723: 45.095763203714455%\n",
      "val:\n",
      "0 23/1720: 1.3372093023255813%\n",
      "1 160/1720: 9.30232558139535%\n",
      "2 912/1720: 53.02325581395349%\n",
      "3 625/1720: 36.33720930232558%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7217e1-5dbd-4f80-a94d-865790d93304",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4e1232dc-2818-41d9-b5e1-4741b35d9c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_4_max_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "11c2f203-4d6a-4382-bcce-a7f6d30df50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b4ee550f-7bc0-40ab-a21c-88274b9a2f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2048) (5482,)\n",
      "(1723, 128, 2048) (1723,)\n",
      "(1720, 128, 2048) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3793a84d-51f5-4e72-bc56-27e2e25f7d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  34  214 2649 2585] {0: 77.91176470588235, 1: 12.378504672897195, 2: 1.0, 3: 1.0247582205029013} 4 [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e3a6406f-b291-4d73-b6ea-19fa35db3cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 4)                    2052      ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1053189 (4.02 MB)\n",
      "Trainable params: 1053189 (4.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "save_best_model = SaveBestModelByUAR(X_subsample_val, y_subsample_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b5c19992-d891-4be4-8249-9a675fe1b0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 4s 81ms/step - loss: 2.8296 - val_loss: 1.1937 - val_uar: 0.3330 - val_bacc: 0.3330 - val_f1: 0.3837 - val_mcc: 0.0844\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 2.2753 - val_loss: 1.0956 - val_uar: 0.3270 - val_bacc: 0.3270 - val_f1: 0.4808 - val_mcc: 0.1370\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 2.0652 - val_loss: 2.2583 - val_uar: 0.3169 - val_bacc: 0.3169 - val_f1: 0.1343 - val_mcc: 0.0522\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 2.0133 - val_loss: 1.2910 - val_uar: 0.3272 - val_bacc: 0.3272 - val_f1: 0.3959 - val_mcc: 0.0909\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 1.8269 - val_loss: 1.2060 - val_uar: 0.3585 - val_bacc: 0.3585 - val_f1: 0.3628 - val_mcc: 0.1593\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 1.8723 - val_loss: 1.0660 - val_uar: 0.3520 - val_bacc: 0.3520 - val_f1: 0.4605 - val_mcc: 0.1791\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 1.8881 - val_loss: 1.3275 - val_uar: 0.3392 - val_bacc: 0.3392 - val_f1: 0.3227 - val_mcc: 0.1317\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 1.7391 - val_loss: 1.4047 - val_uar: 0.3439 - val_bacc: 0.3439 - val_f1: 0.3349 - val_mcc: 0.1384\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 1.6703 - val_loss: 1.4426 - val_uar: 0.3299 - val_bacc: 0.3299 - val_f1: 0.3227 - val_mcc: 0.1318\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 1.6486 - val_loss: 1.0588 - val_uar: 0.3300 - val_bacc: 0.3300 - val_f1: 0.4744 - val_mcc: 0.1558\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 1.5781 - val_loss: 1.2578 - val_uar: 0.3548 - val_bacc: 0.3548 - val_f1: 0.3558 - val_mcc: 0.1486\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 1.5792 - val_loss: 1.1505 - val_uar: 0.3464 - val_bacc: 0.3464 - val_f1: 0.4558 - val_mcc: 0.1916\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 1.5223 - val_loss: 1.1313 - val_uar: 0.3462 - val_bacc: 0.3462 - val_f1: 0.4256 - val_mcc: 0.1687\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 1.4648 - val_loss: 1.6663 - val_uar: 0.3666 - val_bacc: 0.3666 - val_f1: 0.2901 - val_mcc: 0.1044\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 1.5504 - val_loss: 1.1156 - val_uar: 0.3909 - val_bacc: 0.3909 - val_f1: 0.5023 - val_mcc: 0.2041\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 1.5980 - val_loss: 1.2018 - val_uar: 0.3927 - val_bacc: 0.3927 - val_f1: 0.4547 - val_mcc: 0.1806\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 1.4900 - val_loss: 1.1975 - val_uar: 0.3403 - val_bacc: 0.3403 - val_f1: 0.3953 - val_mcc: 0.1551\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 1.3859 - val_loss: 1.1101 - val_uar: 0.3426 - val_bacc: 0.3426 - val_f1: 0.4337 - val_mcc: 0.1645\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 1.4268 - val_loss: 1.0594 - val_uar: 0.3515 - val_bacc: 0.3515 - val_f1: 0.4936 - val_mcc: 0.1953\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 1.4075 - val_loss: 1.1834 - val_uar: 0.3762 - val_bacc: 0.3762 - val_f1: 0.4390 - val_mcc: 0.1791\n",
      "0.3926827135774218\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0fc7a9ab-68fc-4ff4-a10c-f30a1126c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f99020f9-3b5e-4b89-bf9c-3a487256a8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 3 ... 1 1 3]\n",
      "[2 1 3 ... 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(pred)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b1e1b5ff-20d5-431c-ae0b-2f2d220490ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_max_single_attention_traditional Accuracy:  0.4016250725478816 MSE:  0.1195284968078932 UAR:  0.3219956309387204 Recall:  N/A Precision:  N/A F1:  0.2536220423748776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4016250725478816,\n",
       " 0.1195284968078932,\n",
       " 0.3219956309387204,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.2536220423748776)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "219fd71f-000d-417d-860b-2bb5de0bbe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c78f8aa5-2c64-4bab-8d39-02e5b12d8440",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "664fccb6-279f-4cd3-87f4-e9598c348ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_max_single_attention_traditional_best Accuracy:  0.4904236796285548 MSE:  0.1248535693557748 UAR:  0.360146078133883 Recall:  N/A Precision:  N/A F1:  0.30801328315798226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4904236796285548,\n",
       " 0.1248535693557748,\n",
       " 0.360146078133883,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.30801328315798226)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdb559e-9ef2-4c5e-8f08-48d530edb8eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b154b79-37c0-4c42-bf6d-1e72f5ff7da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "917f7128-6a05-46f4-b572-1ebcceaac07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True\n",
    "#IMAGE_SET_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "324df4e7-4f8b-494f-95b2-042944637727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db75cf12-8e9e-45b9-86de-657a98a3afd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 21:09:58.494035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3a7e256-6aa1-427d-a9f8-0781b6a23387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 21:10:14.656351: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f86f8a32620 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-07 21:10:14.656520: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-08-07 21:10:14.660809: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-07 21:10:14.697393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-08-07 21:10:14.749217: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 8s 149ms/step - loss: 0.0813 - mae: 0.2003 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 5/20\n",
      "37/43 [========================>.....] - ETA: 0s - loss: 0.0797 - mae: 0.1962"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m     modelAtn\u001b[38;5;241m.\u001b[39mfit(train_generator,steps_per_epoch\u001b[38;5;241m=\u001b[39mnum_samples_train\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mBATCH_SIZE,\n\u001b[1;32m      3\u001b[0m                      epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[save_best_model],\n\u001b[1;32m      4\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39mtest_generator,validation_steps\u001b[38;5;241m=\u001b[39mnum_samples_test\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mBATCH_SIZE, class_weight\u001b[38;5;241m=\u001b[39mclass_weights)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mmodelAtn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_subsample_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_subsample_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msave_best_model\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m             \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_subsample_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_subsample_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, class_weight=class_weights)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m best_model_weights \u001b[38;5;241m=\u001b[39m save_best_model\u001b[38;5;241m.\u001b[39mbest_model_weights\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(save_best_model\u001b[38;5;241m.\u001b[39mbest)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if USE_GENERATORS:\n",
    "    modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                     epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                    validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "else:\n",
    "    modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "             validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "best_model_weights = save_best_model.best_model_weights\n",
    "print(save_best_model.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a177ede-f68e-41bc-bec4-612fa5683cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 120ms/step - loss: 0.0812 - mae: 0.2005 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "0.11642508953809738\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53e18526-18b0-45f6-b390-bc6928299d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a5ba2559-d949-49eb-a46d-ab832b05d009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_traditional Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c4173f3-a6be-4664-9db7-7fa5ad6ac48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9fe511f0-c571-4b1c-bf03-bebf35662b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2338ef5-adf9-45e4-b903-e3d8b0a04ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_traditional_best Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f2b485-a63b-45b2-b4aa-5d4d557371ec",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f5164595-aa9c-45d8-8701-43e178b7539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "70d46e29-f55a-4c8e-83e5-1bb18e9c2533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c6c26847-d6fd-4fe2-b696-7c4c1c9c6949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 34/5482: 0.6202116016052536%\n",
      "1 214/5482: 3.903684786574243%\n",
      "2 2649/5482: 48.32178037212696%\n",
      "3 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0 4/1723: 0.2321532211259431%\n",
      "1 81/1723: 4.7011027278003485%\n",
      "2 861/1723: 49.97098084735926%\n",
      "3 777/1723: 45.095763203714455%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c06109c4-d530-45d7-babd-27c133d23d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482,) (5482,)\n",
      "(1723,) (1723,)\n",
      "(7205,) (7205,)\n",
      "[0 1 2 3] [  38  295 3510 3362]\n",
      "7205\n",
      "5474\n",
      "1731\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7c2a7a67-fe27-4520-a833-5434cadde01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 28/5474: 0.5115089514066496%\n",
      "1 224/5474: 4.092071611253197%\n",
      "2 2667/5474: 48.72122762148338%\n",
      "3 2555/5474: 46.67519181585678%\n",
      "test:\n",
      "0 10/1731: 0.5777007510109763%\n",
      "1 71/1731: 4.101675332177932%\n",
      "2 843/1731: 48.7001733102253%\n",
      "3 807/1731: 46.62045060658579%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98897fdc-36af-4305-a0dc-5a0316a8f4f2",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c03313e0-5d7c-46f5-a488-ce2824809406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_4_max_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "508957d4-251f-4b48-b49b-fed1cd03728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eeaf98f0-3821-4010-987c-533334021419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 2048) (5474,)\n",
      "(1731, 128, 2048) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "62e903ce-079a-4654-a282-ed3396d905bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  28  224 2667 2555] {0: 95.24999999999999, 1: 11.906249999999998, 2: 1.0, 3: 1.0438356164383562} 4 [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a2a1816b-6336-4519-a53f-5c76317e241d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 4)                    2052      ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1053189 (4.02 MB)\n",
      "Trainable params: 1053189 (4.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "save_best_model = SaveBestModelByUAR(X_subsample_test, y_subsample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2b2db1e6-b459-4a6e-a00e-b18e12ca3fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 5s 87ms/step - loss: 3.3253 - val_loss: 1.4163 - val_uar: 0.3347 - val_bacc: 0.3347 - val_f1: 0.2871 - val_mcc: 0.1341\n",
      "Epoch 2/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 58ms/step - loss: 2.3496 - val_loss: 0.9001 - val_uar: 0.4269 - val_bacc: 0.4269 - val_f1: 0.5904 - val_mcc: 0.2522\n",
      "Epoch 3/20\n",
      "55/55 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 2.1075 - val_loss: 1.1347 - val_uar: 0.3953 - val_bacc: 0.3953 - val_f1: 0.4702 - val_mcc: 0.1778\n",
      "Epoch 4/20\n",
      "55/55 [==============================] - 0s 4ms/stepo\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 1.9255 - val_loss: 1.1735 - val_uar: 0.4470 - val_bacc: 0.4470 - val_f1: 0.4327 - val_mcc: 0.1942\n",
      "Epoch 5/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 58ms/step - loss: 1.8859 - val_loss: 1.0467 - val_uar: 0.4734 - val_bacc: 0.4734 - val_f1: 0.5009 - val_mcc: 0.2295\n",
      "Epoch 6/20\n",
      "55/55 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 1.9275 - val_loss: 0.9346 - val_uar: 0.4531 - val_bacc: 0.4531 - val_f1: 0.5702 - val_mcc: 0.2569\n",
      "Epoch 7/20\n",
      "55/55 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 1.9912 - val_loss: 1.1906 - val_uar: 0.4413 - val_bacc: 0.4413 - val_f1: 0.4223 - val_mcc: 0.1763\n",
      "Epoch 8/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 1.6737 - val_loss: 1.0327 - val_uar: 0.4966 - val_bacc: 0.4966 - val_f1: 0.4980 - val_mcc: 0.2180\n",
      "Epoch 9/20\n",
      "55/55 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 1.6406 - val_loss: 1.2279 - val_uar: 0.4406 - val_bacc: 0.4406 - val_f1: 0.3969 - val_mcc: 0.1754\n",
      "Epoch 10/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 1.6772 - val_loss: 1.0052 - val_uar: 0.4525 - val_bacc: 0.4525 - val_f1: 0.5095 - val_mcc: 0.2045\n",
      "Epoch 11/20\n",
      "55/55 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 1.5331 - val_loss: 1.0010 - val_uar: 0.4835 - val_bacc: 0.4835 - val_f1: 0.5136 - val_mcc: 0.2398\n",
      "Epoch 12/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 1.5497 - val_loss: 1.0614 - val_uar: 0.5206 - val_bacc: 0.5206 - val_f1: 0.5049 - val_mcc: 0.2359\n",
      "Epoch 13/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 1.4988 - val_loss: 1.0842 - val_uar: 0.5171 - val_bacc: 0.5171 - val_f1: 0.4939 - val_mcc: 0.2284\n",
      "Epoch 14/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 1.4475 - val_loss: 1.0212 - val_uar: 0.4877 - val_bacc: 0.4877 - val_f1: 0.5257 - val_mcc: 0.2505\n",
      "Epoch 15/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 1.4178 - val_loss: 0.9886 - val_uar: 0.4991 - val_bacc: 0.4991 - val_f1: 0.5448 - val_mcc: 0.2589\n",
      "Epoch 16/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 1.4446 - val_loss: 1.1448 - val_uar: 0.4619 - val_bacc: 0.4619 - val_f1: 0.4483 - val_mcc: 0.2115\n",
      "Epoch 17/20\n",
      "55/55 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 1.4019 - val_loss: 1.2025 - val_uar: 0.4527 - val_bacc: 0.4527 - val_f1: 0.4159 - val_mcc: 0.1811\n",
      "Epoch 18/20\n",
      "55/55 [==============================] - 0s 4ms/stepo\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 1.4015 - val_loss: 0.8812 - val_uar: 0.4675 - val_bacc: 0.4675 - val_f1: 0.5760 - val_mcc: 0.2666\n",
      "Epoch 19/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 55ms/step - loss: 1.4280 - val_loss: 0.9465 - val_uar: 0.4452 - val_bacc: 0.4452 - val_f1: 0.5592 - val_mcc: 0.2644\n",
      "Epoch 20/20\n",
      "55/55 [==============================] - 0s 5ms/stepo\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 1.4301 - val_loss: 0.9652 - val_uar: 0.4512 - val_bacc: 0.4512 - val_f1: 0.5367 - val_mcc: 0.2340\n",
      "0.5205799981329723\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1f8be9a2-9902-45b5-87f6-592c677e6a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fbf4853e-d8ad-4eb9-bb78-f2e954e9b9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_max_single_attention_balanced Accuracy:  0.5401502021952629 MSE:  0.09019202772963603 UAR:  0.45626352562539063 Recall:  N/A Precision:  N/A F1:  0.36080485988128486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5401502021952629,\n",
       " 0.09019202772963603,\n",
       " 0.45626352562539063,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.36080485988128486)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "da77c58c-0f0a-479a-938e-85830f37cb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4ee4f45e-4c9e-448a-82aa-1fb5ead2d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "316a83b6-7b6a-4136-aaf8-395bcc851ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_max_single_attention_balanced_best Accuracy:  0.5014442518775274 MSE:  0.1020170999422299 UAR:  0.515562842408759 Recall:  N/A Precision:  N/A F1:  0.35582513498442814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5014442518775274,\n",
       " 0.1020170999422299,\n",
       " 0.515562842408759,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.35582513498442814)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a7ed0-69c5-4328-9e45-6ee5a2106e1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0758e1f5-53b9-4b8d-a0de-cbd3f222c0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "29fa5000-1008-47b6-9ce2-cb5768ac27ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c2ffc3b5-c116-4b6f-a86c-7aecfc1ce014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 2560) (5474,)\n",
      "(1731, 128, 2560) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2fad951e-a55e-40c7-948a-70a08b78b7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f551cf26-46f9-4a3e-b9ad-ebd95e548b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 125ms/step - loss: 0.0812 - mae: 0.2012 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "0.08048681914806366\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a8446910-ecba-46e0-a9bb-f49392ed348f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e9c6490c-762f-48aa-a62a-1e4bc856762d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "93a462e3-38f8-41d2-a4d1-ddf39d807a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c551bd86-ab44-4e4d-b606-da68cd76e1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4c939413-76cc-4086-940d-4e3caf248c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced_best Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "face6fa5-2c36-44ef-bf66-d342d9bd680a",
   "metadata": {},
   "source": [
    "### STAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9725fcfa-49be-428a-af04-74fecdc1b06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = compute_descriptor\n",
    "stat_name = \"STAT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b85cdf-335c-4d00-9e2e-f09fd4aee904",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "df3917d7-b1e0-4b51-93bd-8123020a6194",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c7b916cd-44db-40c5-a688-f7fba4d464b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0538a421-8ce6-4b34-9c66-e7400c7e2b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 34/5482: 0.6202116016052536%\n",
      "1 214/5482: 3.903684786574243%\n",
      "2 2649/5482: 48.32178037212696%\n",
      "3 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0 4/1723: 0.2321532211259431%\n",
      "1 81/1723: 4.7011027278003485%\n",
      "2 861/1723: 49.97098084735926%\n",
      "3 777/1723: 45.095763203714455%\n",
      "val:\n",
      "0 23/1720: 1.3372093023255813%\n",
      "1 160/1720: 9.30232558139535%\n",
      "2 912/1720: 53.02325581395349%\n",
      "3 625/1720: 36.33720930232558%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ab9ff6-38d6-4bf4-8b9e-bcf4560ab48f",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dd6a063d-52c6-442b-be76-3956f9ca1a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_4_STAT_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "50921337-82c3-49b0-93c6-7f719c324712",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "81b7dd15-340b-451d-a12b-59ca4f77cc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 3072) (5482,)\n",
      "(1723, 128, 3072) (1723,)\n",
      "(1720, 128, 3072) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "96d9f979-6c31-44ba-9321-c80a49f35800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  34  214 2649 2585] {0: 77.91176470588235, 1: 12.378504672897195, 2: 1.0, 3: 1.0247582205029013} 4 [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "35a40462-a8db-45fb-9395-458955fbb39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1573376   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 4)                    2052      ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1578501 (6.02 MB)\n",
      "Trainable params: 1578501 (6.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "save_best_model = SaveBestModelByUAR(X_subsample_val, y_subsample_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "83980e82-b73a-4ea6-8375-10a58e2ba8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "54/54 [==============================] - 0s 7ms/step\n",
      "43/43 [==============================] - 6s 126ms/step - loss: 2.7224 - val_loss: 1.2446 - val_uar: 0.3491 - val_bacc: 0.3491 - val_f1: 0.4273 - val_mcc: 0.1336\n",
      "Epoch 2/11\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 2.1700 - val_loss: 1.3028 - val_uar: 0.3894 - val_bacc: 0.3894 - val_f1: 0.3593 - val_mcc: 0.1278\n",
      "Epoch 3/11\n",
      "54/54 [==============================] - 0s 7ms/step\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 2.0271 - val_loss: 1.5549 - val_uar: 0.3501 - val_bacc: 0.3501 - val_f1: 0.2576 - val_mcc: 0.0978\n",
      "Epoch 4/11\n",
      "54/54 [==============================] - 0s 7ms/step\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 1.9183 - val_loss: 1.4204 - val_uar: 0.3368 - val_bacc: 0.3368 - val_f1: 0.3169 - val_mcc: 0.1360\n",
      "Epoch 5/11\n",
      "54/54 [==============================] - 0s 7ms/step\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 1.8289 - val_loss: 1.1447 - val_uar: 0.3873 - val_bacc: 0.3873 - val_f1: 0.4488 - val_mcc: 0.1753\n",
      "Epoch 6/11\n",
      "54/54 [==============================] - 0s 7ms/step\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 1.7841 - val_loss: 1.3198 - val_uar: 0.3645 - val_bacc: 0.3645 - val_f1: 0.3674 - val_mcc: 0.1559\n",
      "Epoch 7/11\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 1.7804 - val_loss: 1.4785 - val_uar: 0.3942 - val_bacc: 0.3942 - val_f1: 0.3395 - val_mcc: 0.1077\n",
      "Epoch 8/11\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 1.6704 - val_loss: 1.2726 - val_uar: 0.3530 - val_bacc: 0.3530 - val_f1: 0.4041 - val_mcc: 0.1309\n",
      "Epoch 9/11\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 1.5778 - val_loss: 1.1558 - val_uar: 0.3744 - val_bacc: 0.3744 - val_f1: 0.4483 - val_mcc: 0.1362\n",
      "Epoch 10/11\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 1.6509 - val_loss: 1.4971 - val_uar: 0.4004 - val_bacc: 0.4004 - val_f1: 0.3366 - val_mcc: 0.1331\n",
      "Epoch 11/11\n",
      "54/54 [==============================] - 0s 7ms/step\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 1.6201 - val_loss: 1.1830 - val_uar: 0.3698 - val_bacc: 0.3698 - val_f1: 0.4430 - val_mcc: 0.1554\n",
      "0.40037215865751336\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=11, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3c0d60c2-47fd-49a6-955a-19d85f8ab318",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f8bd9aef-fe23-4332-8c77-1ae53da83837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 2]\n",
      "[2 1 3 ... 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(pred)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0c622a92-f7aa-42d7-b98a-c0dc64a0b1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_STAT_single_attention_traditional Accuracy:  0.3639001741149158 MSE:  0.1429021474172954 UAR:  0.35949560187365065 Recall:  N/A Precision:  N/A F1:  0.2454942384467854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3639001741149158,\n",
       " 0.1429021474172954,\n",
       " 0.35949560187365065,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.2454942384467854)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "14c5a349-d014-4938-89f3-b836fa36964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9f3a36bf-9fe9-47f6-9305-ddcd95c2c74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c31ad298-83e9-43a5-9982-3117b95f803f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_STAT_single_attention_traditional_best Accuracy:  0.3360417875798027 MSE:  0.1954635519442832 UAR:  0.3190707403105777 Recall:  N/A Precision:  N/A F1:  0.23396095006664563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3360417875798027,\n",
       " 0.1954635519442832,\n",
       " 0.3190707403105777,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.23396095006664563)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d061a7bd-e51b-41b1-b2dc-049e4120ef3c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "084b1aaf-6e28-41d6-a512-9d1fccfd1896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c089fc26-b839-418a-86bc-064938bd461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True\n",
    "#IMAGE_SET_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f286ab4a-7afc-4b73-8e86-15b57d225c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce639f46-cb90-41da-b952-011fdb82a133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 21:09:58.494035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cbd4750-061f-45e9-b200-726b1e72802d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 21:10:14.656351: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f86f8a32620 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-07 21:10:14.656520: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-08-07 21:10:14.660809: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-07 21:10:14.697393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-08-07 21:10:14.749217: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 8s 149ms/step - loss: 0.0813 - mae: 0.2003 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.0812 - val_mae: 0.2037\n",
      "Epoch 5/20\n",
      "37/43 [========================>.....] - ETA: 0s - loss: 0.0797 - mae: 0.1962"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m     modelAtn\u001b[38;5;241m.\u001b[39mfit(train_generator,steps_per_epoch\u001b[38;5;241m=\u001b[39mnum_samples_train\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mBATCH_SIZE,\n\u001b[1;32m      3\u001b[0m                      epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[save_best_model],\n\u001b[1;32m      4\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39mtest_generator,validation_steps\u001b[38;5;241m=\u001b[39mnum_samples_test\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mBATCH_SIZE, class_weight\u001b[38;5;241m=\u001b[39mclass_weights)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mmodelAtn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_subsample_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_subsample_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msave_best_model\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m             \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_subsample_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_subsample_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, class_weight=class_weights)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m best_model_weights \u001b[38;5;241m=\u001b[39m save_best_model\u001b[38;5;241m.\u001b[39mbest_model_weights\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(save_best_model\u001b[38;5;241m.\u001b[39mbest)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/sciense/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if USE_GENERATORS:\n",
    "    modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                     epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                    validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "else:\n",
    "    modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "             validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "best_model_weights = save_best_model.best_model_weights\n",
    "print(save_best_model.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13143380-5bec-43e4-98f1-43a6e3a73005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 120ms/step - loss: 0.0812 - mae: 0.2005 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0796 - mae: 0.1967 - val_loss: 0.1164 - val_mae: 0.2560\n",
      "0.11642508953809738\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34b00339-3911-4170-8fc5-17df884991bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8349f7a8-7535-4f2a-99bf-96218de190fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_traditional Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2978a73-5b09-439a-8a21-dfc70228ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "485fed4f-f752-453b-8685-775fdf0f2722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f9498937-171a-4f67-86ce-c35eb85f4ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_traditional_best Accuracy:  0.4509576320371445 MSE:  0.08119123621590248 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.1554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4509576320371445, 0.08119123621590248, 0.25, 'N/A', 'N/A', 0.1554)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931d72ca-7b07-4d47-a436-d23edc81db58",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8a4d3d9d-a92c-4680-aaf9-f38ddc5aedec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "23d56d54-a435-43a3-80ab-c83bd3ba37f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "eb15c2e2-a0ef-460b-a55a-ff11865da583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 34/5482: 0.6202116016052536%\n",
      "1 214/5482: 3.903684786574243%\n",
      "2 2649/5482: 48.32178037212696%\n",
      "3 2585/5482: 47.15432323969354%\n",
      "test:\n",
      "0 4/1723: 0.2321532211259431%\n",
      "1 81/1723: 4.7011027278003485%\n",
      "2 861/1723: 49.97098084735926%\n",
      "3 777/1723: 45.095763203714455%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4599b17a-b4a2-4a40-8b46-3806a31d3786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 2048) (5482,)\n",
      "(1723, 2048) (1723,)\n",
      "(7205, 2048) (7205,)\n",
      "[0 1 2 3] [  38  295 3510 3362]\n",
      "7205\n",
      "5474\n",
      "1731\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dcdf8c1c-15fd-49dd-a242-ab909b5e78de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 28/5474: 0.5115089514066496%\n",
      "1 224/5474: 4.092071611253197%\n",
      "2 2667/5474: 48.72122762148338%\n",
      "3 2555/5474: 46.67519181585678%\n",
      "test:\n",
      "0 10/1731: 0.5777007510109763%\n",
      "1 71/1731: 4.101675332177932%\n",
      "2 843/1731: 48.7001733102253%\n",
      "3 807/1731: 46.62045060658579%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5453de-41a4-44e1-a06a-8071999a283d",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d4474410-a086-4d77-8ffa-59d21025ebee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_4_STAT_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6c539010-836f-442a-a76d-0ac7b071b35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "efb1e7e4-43e2-4e6c-8768-37b43cae0aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 3072) (5474,)\n",
      "(1731, 128, 3072) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "43db7ccf-b1d8-4f43-91ca-a6bb3edea385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  28  224 2667 2555] {0: 95.24999999999999, 1: 11.906249999999998, 2: 1.0, 3: 1.0438356164383562} 4 [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "91f8cafa-a821-4796-b4cc-bb3a1ceff74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1573376   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 4)                    2052      ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1578501 (6.02 MB)\n",
      "Trainable params: 1578501 (6.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "save_best_model = SaveBestModelByUAR(X_subsample_test, y_subsample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b3b38ad4-dd66-4da0-a142-a93e20574832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 6s 118ms/step - loss: 2.7714 - val_loss: 0.9823 - val_uar: 0.4267 - val_bacc: 0.4267 - val_f1: 0.5713 - val_mcc: 0.2471\n",
      "Epoch 2/11\n",
      "55/55 [==============================] - 0s 7ms/step\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 2.1089 - val_loss: 0.9668 - val_uar: 0.4284 - val_bacc: 0.4284 - val_f1: 0.5298 - val_mcc: 0.2038\n",
      "Epoch 3/11\n",
      "55/55 [==============================] - 0s 7ms/step\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 1.9601 - val_loss: 1.1450 - val_uar: 0.4215 - val_bacc: 0.4215 - val_f1: 0.4743 - val_mcc: 0.2053\n",
      "Epoch 4/11\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 1.9238 - val_loss: 1.1922 - val_uar: 0.4843 - val_bacc: 0.4843 - val_f1: 0.4743 - val_mcc: 0.2148\n",
      "Epoch 5/11\n",
      "55/55 [==============================] - 0s 7ms/step\n",
      "43/43 [==============================] - 3s 82ms/step - loss: 1.7696 - val_loss: 0.9927 - val_uar: 0.4488 - val_bacc: 0.4488 - val_f1: 0.5430 - val_mcc: 0.2456\n",
      "Epoch 6/11\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 1.9063 - val_loss: 0.9947 - val_uar: 0.4608 - val_bacc: 0.4608 - val_f1: 0.5124 - val_mcc: 0.2428\n",
      "Epoch 7/11\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 1.8142 - val_loss: 0.9633 - val_uar: 0.4870 - val_bacc: 0.4870 - val_f1: 0.5488 - val_mcc: 0.2554\n",
      "Epoch 8/11\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 1.6203 - val_loss: 1.1027 - val_uar: 0.4738 - val_bacc: 0.4738 - val_f1: 0.4743 - val_mcc: 0.2075\n",
      "Epoch 9/11\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 1.5418 - val_loss: 0.9465 - val_uar: 0.5007 - val_bacc: 0.5007 - val_f1: 0.5702 - val_mcc: 0.2813\n",
      "Epoch 10/11\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 1.5334 - val_loss: 1.0720 - val_uar: 0.4685 - val_bacc: 0.4685 - val_f1: 0.4708 - val_mcc: 0.2043\n",
      "Epoch 11/11\n",
      "55/55 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 1.4864 - val_loss: 1.1678 - val_uar: 0.4821 - val_bacc: 0.4821 - val_f1: 0.4495 - val_mcc: 0.1955\n",
      "0.500702410186245\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=11, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "45c3aac6-0a4f-48a5-a093-e128f37053df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5fa712d4-430d-4a78-9cb7-fe192010bb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_STAT_single_attention_balanced Accuracy:  0.44771808203350666 MSE:  0.1268165222414789 UAR:  0.48116321325537525 Recall:  N/A Precision:  N/A F1:  0.31585300025484253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.44771808203350666,\n",
       " 0.1268165222414789,\n",
       " 0.48116321325537525,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.31585300025484253)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "39f067e7-19c3-495a-92a7-091c409746e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "311d9a6e-b3b1-45cc-bc6d-0fa2a2376e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8a9f53be-47b4-44d8-820d-d8b0f2915843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_4_STAT_single_attention_balanced_best Accuracy:  0.5713460427498556 MSE:  0.08364523396880415 UAR:  0.5045200968519092 Recall:  N/A Precision:  N/A F1:  0.38182567679984347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5713460427498556,\n",
       " 0.08364523396880415,\n",
       " 0.5045200968519092,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.38182567679984347)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name, from_int=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12482a3e-9e6a-4dd4-b9f6-6ebd107e66f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "24086057-f768-476a-9db6-27207ecf26ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eae00f7b-6495-46cf-bf00-b20e11a65d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "618fce08-69f6-49d3-a755-73b906057f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 2560) (5474,)\n",
      "(1731, 128, 2560) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7dd62f78-86cf-42da-ad5f-943d104abf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "de6c581d-fc81-4366-8baf-65bbe2d32a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 125ms/step - loss: 0.0812 - mae: 0.2012 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "0.08048681914806366\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0ed86876-6dab-4db7-bd31-61798e232a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ee3a5e67-f374-4de5-869d-594976eede2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ce3fbb52-0253-4b78-bb7a-c433a7a19409",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a47a1b0c-20b2-44d9-9c29-f1f07e831dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "12a6b600-755a-43d0-8706-6d316bf9caf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced_best Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "873bcfad-28fc-4f4e-bebc-9a573368f808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0ff7115b-9993-402c-b1f7-03312981238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c514f983-fac7-4891-adc8-180d0e26ac94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5474, 128, 2560) (5474,)\n",
      "(1731, 128, 2560) (1731,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0337e8a7-6bae-493c-81c5-d582f8b0cae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_1[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e14436f9-6360-4e82-9e16-2f35ce5bf48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 6s 125ms/step - loss: 0.0812 - mae: 0.2012 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0798 - mae: 0.1982 - val_loss: 0.0805 - val_mae: 0.1988\n",
      "0.08048681914806366\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eaa4520a-6555-4da5-9806-7cbe1f08baf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8b70a4d8-5d03-4d9c-97f2-c3968c92e0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bd496d76-5a8a-4b60-a186-4e0250f8578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "63f74345-642c-45af-9c20-d981d4c1500a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_813884/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "da529842-b693-4344-a14a-7ced056e9098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_4_std_self_attention_balanced_best Accuracy:  0.4662045060658579 MSE:  0.08048682842287694 UAR:  0.25 Recall:  N/A Precision:  N/A F1:  0.15898345153664303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4662045060658579,\n",
       " 0.08048682842287694,\n",
       " 0.25,\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " 0.15898345153664303)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(pred, test_labels, table_name=TABLE_NAME, metric_name=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32f0ac6-da64-4d69-b9aa-8e7075574dcd",
   "metadata": {},
   "source": [
    "# DAiSEE dataset (2 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "756348cb-d50e-48b4-b265-fd48f251b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_DIR = DATA_DIR + 'features_DAiSEE/'\n",
    "WEIGHTS_DIR = DATA_DIR + 'weights_DAiSEE/'\n",
    "WEIGHTS_DIR = DATA_DIR + 'weights_DAiSEE_classifier_sigmoid/'\n",
    "TABLE_NAME = '02_DAiSEE_2_classes.xlsx'\n",
    "TABLE_NAME = '02_DAiSEE_2_classes_classifier_sigmoid.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd04ac4c-137d-4545-928f-d4b44afe080b",
   "metadata": {},
   "source": [
    "## enet_b0_8_best_afew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20d33da2-8d94-4865-bd82-769dd7d316b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_key = 'enet_b0_8_best_afew.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05b5f242-0359-4b6c-b40c-9c96044c332b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['engaged', 'distracted']\n",
      "{'1100011002': 0, '1100011003': 0, '1100011004': 0, '1100011005': 0, '1100011006': 0, '1100011007': 0, '1100011008': 0, '1100011009': 0, '1100011010': 0, '1100011011': 0, '1100011012': 0, '1100011013': 0, '1100011014': 0, '1100011015': 0, '1100011016': 0, '1100011017': 0, '1100011018': 0, '1100011019': 0, '1100011020': 0, '1100011021': 0, '1100011022': 0, '1100011023': 0, '1100011025': 0, '1100011026': 0, '1100011027': 0, '1100011028': 0, '1100011029': 0, '1100011031': 0, '1100011032': 0, '1100011034': 0, '1100011035': 0, '1100011037': 0, '1100011038': 0, '1100011040': 0, '1100011046': 0, '1100011047': 0, '1100011048': 0, '1100011049': 0, '1100011050': 0, '1100011051': 0, '1100011052': 0, '1100011053': 0, '1100011054': 0, '1100011055': 0, '1100011056': 0, '1100011057': 0, '1100011058': 0, '1100011059': 0, '1100011060': 0, '1100011062': 0, '1100011063': 0, '1100011064': 0, '1100011066': 0, '1100011067': 0, '1100011068': 0, '1100011069': 0, '1100011070': 0, '1100011071': 0, '1100011072': 0, '1100011073': 0, '1100011075': 0, '1100011076': 0, '1100011078': 0, '1100011079': 0, '1100011080': 0, '1100011081': 0, '1100011082': 0, '1100011083': 0, '1100012001': 0, '1100012003': 0, '1100012007': 0, '1100012008': 0, '1100012009': 0, '1100012010': 0, '1100012011': 0, '1100012013': 0, '1100012014': 0, '1100012015': 0, '1100012016': 0, '1100012017': 0, '1100012018': 0, '1100012021': 0, '1100012022': 0, '1100012023': 0, '1100012025': 0, '1100012026': 0, '1100012027': 0, '1100012028': 0, '1100012030': 0, '1100012031': 0, '1100012032': 0, '1100012033': 0, '1100012036': 0, '1100012037': 0, '1100012038': 0, '1100012041': 0, '1100012042': 0, '1100012045': 0, '1100012046': 0, '1100012047': 0, '1100012049': 0, '1100012050': 0, '1100012051': 0, '1100012052': 0, '1100012057': 0, '1100012059': 0, '1100012060': 0, '1100012061': 0, '1100012062': 0, '1100012063': 0, '1100012064': 0, '1100012065': 0, '1100012066': 0, '1100012069': 0, '1100021001': 0, '1100021003': 1, '1100021015': 0, '1100021038': 0, '1100021039': 0, '1100021040': 0, '1100021045': 0, '1100021050': 0, '1100021055': 1, '1100022001': 0, '1100022002': 0, '1100022003': 0, '1100022004': 0, '1100022005': 1, '1100022008': 0, '1100022009': 0, '1100022014': 0, '1100022019': 0, '1100022020': 0, '1100022021': 0, '1100022022': 0, '1100022026': 0, '1100022027': 0, '1100022028': 0, '1100022029': 0, '1100022031': 0, '1100022035': 0, '1100022038': 0, '1100022039': 0, '1100022045': 0, '1100022046': 0, '1100022047': 0, '1100022048': 0, '1100022049': 0, '1100022051': 0, '1100022052': 0, '1100022053': 0, '1100022054': 0, '1100022055': 0, '1100022056': 0, '1100022057': 0, '1100041006': 0, '1100041015': 0, '1100041016': 0, '1100041017': 0, '1100041018': 0, '1100041021': 0, '1100041022': 0, '1100041023': 0, '1100041024': 0, '1100041029': 0, '1100041034': 0, '1100041044': 0, '1100041051': 0, '1100041052': 0, '1100042009': 0, '1100042010': 0, '1100042011': 0, '1100042017': 0, '1100042018': 0, '1100042019': 0, '1100042020': 0, '1100042023': 1, '1100042024': 0, '1100042025': 0, '1100042026': 1, '1100042029': 0, '1100042030': 0, '1100042031': 0, '1100042034': 0, '1100042040': 0, '1100042041': 0, '1100042058': 0, '1100042059': 0, '1100042060': 0, '1100051002': 0, '1100051004': 0, '1100051006': 0, '1100051007': 1, '1100051008': 0, '1100051009': 0, '1100051011': 0, '1100051012': 0, '1100051013': 0, '1100051014': 0, '1100051016': 1, '1100051017': 0, '1100051019': 0, '1100051020': 0, '1100051021': 0, '1100051022': 0, '1100051023': 0, '1100051024': 0, '1100051025': 0, '1100051026': 0, '1100051028': 0, '1100051029': 0, '1100051030': 1, '1100051031': 1, '1100051032': 0, '1100051033': 0, '1100051034': 0, '1100051035': 0, '1100051036': 0, '1100051037': 0, '1100051039': 0, '1100051041': 0, '1100051042': 0, '1100051044': 0, '1100051045': 0, '1100051046': 0, '1100051048': 0, '1100051049': 0, '1100051050': 0, '1100051051': 0, '1100051052': 0, '1100051053': 1, '1100051054': 0, '1100051055': 0, '1100051056': 0, '1100051057': 0, '1100051059': 0, '1100051061': 0, '1100051062': 0, '1100051064': 0, '1100051065': 0, '1100051066': 0, '1100051067': 0, '1100051068': 0, '1100051071': 0, '1100051076': 0, '1100051078': 0, '1100051079': 0, '1100052001': 0, '1100052002': 0, '1100052006': 0, '1100052007': 0, '1100052008': 0, '1100052009': 0, '1100052014': 1, '1100052023': 0, '1100052024': 0, '1100052026': 0, '1100052027': 0, '1100052028': 0, '1100052030': 0, '1100052031': 0, '1100052032': 0, '1100052033': 0, '1100052035': 0, '1100052036': 0, '1100052037': 0, '1100052038': 0, '1100052039': 0, '1100052040': 0, '1100052041': 0, '1100052047': 0, '1100052048': 0, '1100052049': 0, '1100052051': 0, '1100052055': 0, '1100052057': 0, '1100052060': 0, '1100052061': 0, '1100052062': 0, '1100052065': 0, '1100052068': 0, '1100052070': 0, '1100061009': 0, '1100061010': 0, '1100061011': 0, '1100061012': 0, '1100061013': 0, '1100061015': 0, '1100061016': 0, '1100061018': 0, '1100061019': 0, '1100061022': 0, '1100061023': 0, '1100061025': 0, '1100061027': 0, '1100061028': 0, '1100061030': 0, '1100061031': 0, '1100061032': 0, '1100061033': 0, '1100061034': 0, '1100061035': 0, '1100061036': 0, '1100061038': 0, '1100061039': 0, '1100061040': 0, '1100061042': 0, '1100061043': 0, '1100061044': 0, '1100061046': 0, '1100061047': 0, '1100061048': 0, '1100061049': 0, '1100061050': 0, '1100061051': 0, '1100061053': 0, '1100061057': 0, '1100061058': 0, '1100061061': 0, '1100061063': 0, '1100061064': 0, '1100061067': 0, '1100061068': 0, '1100061069': 0, '1100061073': 0, '1100061074': 0, '1100061077': 0, '1100061078': 0, '1100062004': 0, '1100062005': 0, '1100062007': 0, '1100062008': 1, '1100062009': 0, '1100062016': 0, '1100062017': 0, '1100062024': 0, '1100062028': 0, '1100062029': 0, '1100062036': 0, '1100062037': 0, '1100062044': 0, '1100062045': 1, '1100062046': 0, '1100062049': 1, '1100062051': 0, '1100062053': 0, '1100062054': 0, '1100062059': 0, '1100062060': 0, '1100062061': 0, '1100062062': 0, '1100062063': 0, '1100062064': 0, '1100062065': 0, '1100062066': 0, '1100062067': 0, '1100062068': 0, '1100062069': 0, '1100062070': 0, '1100062071': 0, '1100062072': 0, '1100071005': 0, '1100071006': 0, '1100071007': 0, '1100071008': 0, '1100071009': 0, '1100071010': 0, '1100071011': 0, '1100071012': 0, '1100071013': 0, '1100071014': 0, '1100071015': 0, '1100071016': 0, '1100071017': 0, '1100071018': 0, '1100071019': 0, '1100071020': 0, '1100071021': 0, '1100071022': 0, '1100071023': 0, '1100071024': 0, '1100071026': 0, '1100071027': 0, '1100071028': 0, '1100071029': 0, '1100071030': 0, '1100071031': 0, '1100071032': 0, '1100071033': 0, '1100071034': 0, '1100071035': 0, '1100071036': 0, '1100071037': 0, '1100071040': 0, '1100071041': 0, '1100071042': 0, '1100071043': 0, '1100071044': 0, '1100071045': 0, '1100071046': 0, '1100071047': 0, '1100071049': 0, '1100071050': 0, '1100071052': 0, '1100071054': 0, '1100071055': 0, '1100071056': 0, '1100071057': 0, '1100071058': 0, '1100071059': 0, '1100071060': 0, '1100071061': 0, '1100071062': 0, '1100071063': 0, '1100071064': 0, '1100071065': 0, '1100071066': 0, '1100071067': 0, '1100071069': 0, '1100071070': 0, '1100071071': 0, '1100071072': 0, '1100071073': 0, '1100071074': 0, '1100071075': 0, '1100071076': 0, '1100071077': 0, '1100071078': 0, '1100071079': 0, '1100071080': 0, '1100071081': 0, '1100072001': 0, '1100072002': 0, '1100072003': 0, '1100072004': 0, '1100072006': 0, '1100072007': 0, '1100072008': 0, '1100072009': 0, '1100072010': 0, '1100072011': 0, '1100072012': 0, '1100072013': 0, '1100072014': 0, '1100072015': 0, '1100072016': 0, '1100072021': 0, '1100072022': 0, '1100072023': 0, '1100072024': 0, '1100072027': 0, '1100072028': 0, '1100072029': 0, '1100072030': 0, '1100072031': 0, '1100072032': 0, '1100072033': 0, '1100072034': 0, '1100072036': 0, '1100072037': 0, '1100072038': 0, '1100072039': 0, '1100072040': 0, '1100072042': 0, '1100072043': 0, '1100072045': 0, '1100072047': 0, '1100072048': 0, '1100072049': 0, '1100072050': 0, '1100072051': 0, '1100072052': 0, '1100072053': 0, '1100072054': 0, '1100072056': 0, '1100072057': 0, '1100072058': 0, '1100072059': 0, '1100072060': 0, '1100072061': 0, '1100072062': 0, '1100072063': 0, '1100072065': 0, '1100072066': 0, '1100072067': 0, '1100072068': 0, '1100072069': 0, '1100072070': 0, '1100072071': 0, '1100072072': 0, '1100072073': 0, '1100072074': 0, '1100072075': 0, '1100072076': 0, '1100072077': 0, '1100072078': 0, '1100072079': 0, '1100072080': 0, '1100072081': 0, '1100072082': 0, '1100072083': 0, '1100072084': 0, '1100072085': 0, '1100081044': 0, '1100081045': 0, '1100081046': 0, '1100081047': 0, '1100081048': 0, '1100082002': 0, '1100082003': 0, '1100082018': 0, '1100082027': 0, '1100102003': 0, '1100111001': 0, '1100111002': 0, '1100111003': 0, '1100111008': 0, '1100111009': 0, '1100111010': 0, '1100111011': 0, '1100111012': 0, '1100111013': 0, '1100111014': 0, '1100111016': 0, '1100111017': 0, '1100111018': 0, '1100111019': 0, '1100111021': 0, '1100111023': 0, '1100111025': 0, '1100111026': 0, '1100111027': 0, '1100111029': 0, '1100111030': 0, '1100111032': 0, '1100112001': 0, '1100112002': 1, '1100112003': 0, '1100112004': 0, '1100112006': 1, '1100112007': 0, '1100112008': 0, '1100112009': 0, '1100112010': 0, '1100112011': 0, '1100112012': 0, '1100112013': 0, '1100112014': 0, '1100112015': 0, '1100112016': 0, '1100112017': 0, '1100112018': 0, '1100112021': 0, '1100112022': 0, '1100112024': 0, '1100112025': 0, '1100112026': 0, '1100112029': 0, '1100112030': 0, '1100112033': 0, '1100112035': 0, '1100112036': 0, '1100112037': 0, '1100112038': 0, '1100112039': 0, '1100112040': 0, '1100112041': 0, '1100112042': 0, '1100112043': 0, '1100112044': 0, '1100112045': 0, '1100112047': 0, '1100112048': 0, '1100112051': 0, '1100112052': 0, '1100112053': 0, '1100112056': 0, '1100112057': 0, '1100112058': 0, '1100112059': 0, '1100112060': 0, '1100112061': 0, '1100112062': 0, '1100112063': 0, '1100112064': 0, '1100112065': 0, '1100112066': 0, '1100112068': 0, '1100121002': 0, '1100121003': 0, '1100121004': 0, '1100121005': 0, '1100121006': 0, '1100121007': 0, '1100121008': 0, '1100121009': 0, '1100121010': 0, '1100121011': 0, '1100121012': 0, '1100121015': 0, '1100121016': 0, '1100121017': 0, '1100121018': 0, '1100121019': 0, '1100121020': 0, '1100121024': 0, '1100121025': 0, '1100121028': 0, '1100121031': 0, '1100121032': 0, '1100121033': 0, '1100121034': 0, '1100121035': 0, '1100121036': 0, '1100121038': 0, '1100121040': 0, '1100121041': 0, '1100121042': 0, '1100121044': 0, '1100121045': 0, '1100121047': 0, '1100121049': 0, '1100121050': 0, '1100121052': 0, '1100121053': 0, '1100121054': 0, '1100121056': 0, '1100121057': 0, '1100121059': 0, '1100121060': 0, '1100121061': 0, '1100121064': 0, '1100122001': 0, '1100122002': 0, '1100122003': 0, '1100122005': 0, '1100122006': 0, '1100122007': 0, '1100122008': 0, '1100122009': 0, '1100122010': 0, '1100122011': 0, '1100122012': 0, '1100122013': 0, '1100122014': 0, '1100122015': 0, '1100122017': 0, '1100122018': 0, '1100122019': 0, '1100122020': 0, '1100122021': 0, '1100122023': 0, '1100122024': 0, '1100122025': 0, '1100122026': 0, '1100122031': 0, '1100122032': 0, '1100122033': 0, '1100122034': 0, '1100122035': 0, '1100122036': 0, '1100122037': 0, '1100122038': 0, '1100122039': 0, '1100122040': 0, '1100122041': 0, '1100122045': 0, '1100122047': 0, '1100122048': 0, '1100122050': 0, '1100122051': 0, '1100122052': 0, '1100122053': 0, '1100122054': 0, '1100122056': 1, '1100131006': 0, '1100131007': 0, '1100131009': 0, '1100131010': 0, '1100131011': 0, '1100131012': 0, '1100131017': 1, '1100131019': 0, '1100141001': 0, '1100141002': 0, '1100141003': 0, '1100141004': 0, '1100141005': 0, '1100141006': 0, '1100141007': 0, '1100141008': 0, '1100141009': 0, '1100141010': 0, '1100141011': 0, '1100141012': 0, '1100141013': 1, '1100141014': 0, '1100141015': 0, '1100141016': 0, '1100141017': 0, '1100141019': 0, '1100141020': 0, '1100141021': 0, '1100141023': 0, '1100141027': 1, '1100141028': 0, '1100141029': 0, '1100141030': 0, '1100141031': 0, '1100141032': 0, '1100141033': 0, '1100141034': 0, '1100141035': 0, '1100141036': 0, '1100141039': 0, '1100141040': 0, '1100141042': 0, '1100141044': 0, '1100141045': 0, '1100141046': 0, '1100141049': 0, '1100141050': 0, '1100141052': 0, '1100141053': 0, '1100141054': 0, '1100141055': 0, '1100141056': 0, '1100141057': 0, '1100142002': 0, '1100142003': 0, '1100142004': 0, '1100142007': 0, '1100142008': 0, '1100142009': 0, '1100142010': 0, '1100142011': 0, '1100142013': 0, '1100142014': 0, '1100142015': 0, '1100142017': 0, '1100142018': 0, '1100142019': 0, '1100142021': 0, '1100142022': 0, '1100142023': 0, '1100142024': 0, '1100142027': 0, '1100142028': 0, '1100142029': 0, '1100142030': 0, '1100142031': 0, '1100142032': 0, '1100142033': 1, '1100142034': 0, '1100142035': 0, '1100142038': 0, '1100142041': 0, '1100142043': 0, '1100142044': 0, '1100142045': 0, '1100142046': 0, '1100142048': 0, '1100142049': 0, '1100142050': 0, '1100142051': 0, '1100142052': 0, '1100142053': 0, '1100142056': 0, '1100142057': 0, '1100142058': 0, '1100142059': 0, '1100142060': 0, '1100151003': 0, '1100151004': 0, '1100151008': 0, '1100151009': 0, '1100151010': 0, '1100151011': 1, '1100151012': 0, '1100151013': 0, '1100151014': 0, '1100151015': 0, '1100151016': 0, '1100151017': 0, '1100151018': 0, '1100151019': 0, '1100151020': 0, '1100151021': 0, '1100151022': 0, '1100151023': 0, '1100151024': 0, '1100151028': 0, '1100151030': 0, '1100151032': 0, '1100151033': 0, '1100151035': 0, '1100151037': 0, '1100151038': 0, '1100151039': 0, '1100151040': 0, '1100151042': 0, '1100151043': 0, '1100151044': 0, '1100151047': 0, '1100151049': 0, '1100151050': 0, '1100151051': 0, '1100151052': 0, '1100151054': 0, '1100151055': 0, '1100151056': 0, '1100151057': 1, '1100151058': 0, '1100151062': 0, '1100152001': 0, '1100152004': 0, '1100152005': 0, '1100152006': 0, '1100152008': 0, '1100152009': 0, '1100152010': 1, '1100152013': 0, '1100152014': 0, '1100152015': 0, '1100152017': 1, '1100152019': 0, '1100152020': 0, '1100152022': 0, '1100152024': 0, '1100152025': 0, '1100152026': 0, '1100152027': 0, '1100152031': 1, '1100152032': 0, '1100152039': 0, '1100152040': 0, '1100152041': 0, '1100152042': 0, '1100152043': 0, '1100152048': 0, '1100152049': 0, '1100152050': 0, '1100152051': 0, '1100152055': 1, '1100152056': 0, '1100152061': 0, '1100152062': 0, '1100152067': 0, '1100152069': 0, '1100152070': 1, '1100161002': 0, '1100161004': 0, '1100161011': 0, '1100161012': 0, '1100161013': 0, '1100161014': 0, '1100161015': 0, '1100161016': 0, '1100161020': 0, '1100161021': 0, '1100161022': 0, '1100161023': 0, '1100161028': 0, '1100161029': 0, '1100161032': 0, '1100161035': 0, '1100161036': 0, '1100161038': 0, '1100161039': 0, '1100161041': 0, '1100161043': 0, '1100161044': 0, '1100161045': 0, '1100161046': 0, '1100161048': 0, '1100161050': 0, '1100161053': 1, '1100162005': 1, '1100162007': 0, '1100162011': 0, '1100162016': 1, '1100171001': 0, '1100171002': 0, '1100171004': 1, '1100171005': 0, '1100171007': 0, '1100171008': 1, '1100171009': 0, '1100171010': 0, '1100171011': 0, '1100171012': 0, '1100171013': 0, '1100171015': 0, '1100171016': 0, '1100171017': 0, '1100171019': 0, '1100171021': 0, '1100171022': 0, '1100171023': 0, '1100171031': 0, '1100171035': 0, '1100171036': 0, '1100171038': 0, '1100171039': 0, '1100171040': 0, '1100171041': 0, '1100171043': 0, '1100171045': 0, '1100171049': 0, '1100171055': 0, '1100171056': 0, '1100171057': 0, '1100171059': 1, '1100171061': 0, '1100171063': 0, '1100171064': 0, '1100171065': 0, '1100171067': 0, '1100171069': 0, '1100171070': 0, '1100171071': 0, '1100171072': 0, '1100171073': 0, '1100171074': 0, '1100171075': 0, '1100171076': 0, '1100171077': 0, '1100171078': 0, '1100171080': 0, '1100171083': 0, '1100172003': 0, '1100172004': 0, '1100172007': 0, '1100172012': 1, '1100172013': 0, '1100172014': 0, '1100172015': 0, '1100172016': 0, '1100172017': 1, '1100172018': 0, '1100172020': 0, '1100172021': 0, '1100172022': 0, '1100172026': 0, '1100172028': 0, '1100172030': 0, '1100172032': 0, '1100172033': 1, '1100172034': 1, '1100172035': 0, '1100172037': 0, '1100172039': 0, '1100172042': 0, '1100172043': 1, '1100172047': 0, '1100172050': 0, '1100172058': 1, '1100172063': 0, '1100172066': 0, '1100411010': 0, '1100411011': 0, '1100411012': 0, '1100411013': 0, '1100411015': 0, '1100411016': 0, '1100411018': 0, '1100411020': 0, '1100411023': 0, '1100411036': 0, '1100411041': 0, '1100411045': 0, '1100411047': 0, '1100411048': 0, '1100411049': 0, '1100411050': 0, '1100411051': 0, '1100411053': 0, '1100411054': 0, '1100411055': 0, '1100411057': 0, '1100412001': 0, '1100412003': 0, '1100412010': 0, '1100412018': 1, '1100412033': 1, '1100412038': 0, '1100412039': 1, '1100412040': 0, '1110031003': 0, '1110031007': 0, '1110031010': 1, '1110031011': 0, '1110031012': 0, '1110031014': 0, '1110031019': 0, '1110031020': 0, '1110031021': 0, '1110031025': 1, '1110031027': 1, '1110031031': 0, '1110031033': 1, '1110031037': 0, '1110031038': 1, '1110031039': 0, '1110031040': 0, '1110031042': 0, '1110031048': 0, '1110031049': 0, '1110031050': 0, '1110031056': 1, '1110031061': 0, '1110031062': 0, '1110031063': 1, '1110031064': 0, '1110031065': 0, '1110032002': 0, '1110032004': 0, '1110032006': 0, '1110032008': 0, '1110032010': 0, '1110032014': 1, '1110032015': 0, '1110032018': 0, '1110032019': 0, '1110032020': 0, '1110032021': 0, '1110032022': 0, '1110032023': 0, '1110032024': 0, '1110032025': 0, '1110032027': 1, '1110032029': 0, '1110032031': 0, '1110032032': 0, '1110032033': 0, '1110032034': 0, '1110032036': 0, '1110032037': 0, '1110032042': 0, '1110032043': 1, '1110032045': 0, '1110032047': 0, '1110032048': 0, '1110032049': 0, '1110032050': 0, '1110032051': 0, '1110032052': 0, '1110032053': 0, '1110032055': 0, '1110032056': 0, '1110032058': 0, '1110032059': 0, '1110032060': 0, '1110032061': 0, '1110032062': 0, '1110032063': 0, '1813740111': 0, '1813740112': 0, '1813740115': 0, '1813740116': 0, '1813740118': 0, '1813740119': 0, '1813740122': 0, '1813740123': 0, '1813740124': 0, '1813740126': 0, '1813740127': 0, '1813740128': 0, '1813740131': 0, '1813740133': 0, '1813740135': 0, '1813740137': 0, '1813740138': 1, '1813740143': 0, '1813740144': 0, '1813740149': 0, '181374015': 0, '1813740150': 0, '1813740153': 0, '1813740155': 0, '1813740157': 0, '1813740159': 0, '181374016': 0, '1813740162': 0, '1813740164': 0, '1813740165': 0, '1813740167': 0, '1813740168': 0, '1813740169': 0, '181374017': 0, '1813740171': 0, '1813740172': 0, '1813740173': 0, '1813740174': 0, '1813740176': 0, '1813740178': 0, '1813740179': 0, '1813740180': 0, '1813740181': 0, '1813740182': 0, '1813740183': 0, '1813740184': 1, '1813740185': 1, '181374019': 0, '1813740210': 0, '1813740211': 0, '1813740212': 0, '1813740213': 0, '1813740214': 0, '1813740218': 0, '1813740219': 0, '1813740220': 0, '1813740221': 0, '1813740224': 0, '1813740225': 0, '1813740226': 0, '1813740227': 0, '1813740229': 0, '181374023': 0, '1813740231': 0, '1813740232': 0, '1813740233': 0, '1813740234': 0, '1813740235': 0, '1813740236': 0, '1813740237': 0, '1813740238': 0, '181374024': 0, '1813740240': 0, '1813740241': 0, '1813740242': 0, '1813740243': 0, '1813740245': 0, '1813740249': 0, '181374025': 0, '1813740250': 0, '1813740251': 0, '1813740252': 0, '1813740253': 0, '1813740255': 0, '1813740256': 0, '1813740257': 0, '1813740258': 0, '1813740259': 0, '181374026': 0, '1813740260': 0, '1813740261': 0, '1813740262': 0, '1813740263': 0, '1813740264': 0, '1813740265': 0, '1813740266': 0, '1813740267': 0, '1813740268': 0, '1813740269': 0, '181374027': 0, '1813740270': 0, '1813740271': 0, '1813740272': 0, '1813740273': 0, '1813740274': 0, '1813740275': 0, '1813740276': 0, '1813740277': 0, '1813740278': 0, '1813740279': 0, '181374028': 0, '181374029': 0, '2000481035': 0, '2000481036': 0, '2000481037': 0, '2000481038': 0, '2000481039': 0, '2000481040': 0, '2000481041': 0, '2000481043': 0, '2000481048': 0, '2000482008': 0, '2000482009': 0, '2000482012': 0, '2000482018': 0, '2000482021': 0, '2000482034': 0, '2000482037': 0, '2000482038': 0, '2000482039': 0, '2000482041': 0, '2000482042': 0, '2000482043': 0, '2000482044': 0, '2000482049': 0, '2000482050': 0, '2000482052': 0, '2000482059': 0, '2000482065': 0, '2000482066': 0, '2000482067': 0, '2000482068': 0, '2000482070': 0, '2000491062': 0, '2000491064': 0, '2000491065': 0, '2000491066': 0, '2000491067': 0, '2000491068': 0, '2000491070': 0, '2000491072': 0, '2000491074': 0, '2000491075': 0, '2000491076': 0, '2000491077': 1, '2000491078': 0, '2000491079': 0, '2000501001': 0, '2000501002': 0, '2000501003': 0, '2000501004': 0, '2000501006': 1, '2000501009': 0, '2000501010': 0, '2000501011': 0, '2000501012': 0, '2000501014': 0, '2000501015': 0, '2000501016': 0, '2000501018': 0, '2000501019': 0, '2000501020': 0, '2000501021': 0, '2000501023': 0, '2000501027': 0, '2000501028': 0, '2000501030': 1, '2000501031': 0, '2000501032': 0, '2000501033': 0, '2000501035': 0, '2000501036': 0, '2000501037': 0, '2000501038': 0, '2000501039': 0, '2000501040': 0, '2000501041': 0, '2000501042': 0, '2000501043': 0, '2000501044': 0, '2000501045': 0, '2000501046': 0, '2000501049': 0, '2000501050': 0, '2000501051': 0, '2000501052': 0, '2000501053': 0, '2000501054': 0, '2000501056': 0, '2000501057': 0, '2000501060': 0, '2000501061': 0, '2000501062': 0, '2000501063': 0, '2000501065': 0, '2000501066': 0, '2000501067': 0, '2000501071': 0, '2000501074': 0, '2000501075': 0, '2000501076': 0, '2000501078': 0, '2000502002': 0, '2000502005': 0, '2000502006': 0, '2000502007': 0, '2000502009': 0, '2000502010': 0, '2000502012': 0, '2000502013': 0, '2000502014': 0, '2000502015': 0, '2000502019': 0, '2000502020': 0, '2000502023': 0, '2000502025': 0, '2000502033': 0, '2000502036': 0, '2000502037': 0, '2000502039': 0, '2000502040': 0, '2000502041': 0, '2000502043': 0, '2000502044': 0, '2000502045': 0, '2000502047': 0, '2000502048': 0, '2000502049': 0, '2000502050': 0, '2000502051': 0, '2000502053': 1, '2000502054': 0, '2000502055': 0, '2000502056': 0, '2000502057': 0, '2000502058': 0, '2000502059': 0, '2000502061': 0, '2000502062': 0, '2000502063': 0, '2000502065': 1, '2000502066': 0, '2000502067': 0, '2000502069': 0, '2000502070': 0, '2000502072': 0, '2000502073': 0, '2000502075': 0, '2000502076': 0, '2000502077': 0, '2000502078': 0, '2000502081': 1, '2000502084': 0, '2000502087': 0, '2000502088': 0, '2000502090': 0, '2000541001': 0, '2000541002': 0, '2000541003': 0, '2000541006': 0, '2000541007': 0, '2000541010': 0, '2000541011': 0, '2000541014': 0, '2000541015': 0, '2000541016': 0, '2000541018': 0, '2000541019': 0, '2000541020': 0, '2000541021': 0, '2000541022': 0, '2000541023': 0, '2000541024': 0, '2000541025': 0, '2000541027': 0, '2000541028': 0, '2000541029': 0, '2000541030': 0, '2000541031': 0, '2000541032': 0, '2000541034': 0, '2000541035': 0, '2000541038': 0, '2000541039': 0, '2000541040': 0, '2000541041': 0, '2000541043': 0, '2000541044': 0, '2000541045': 0, '2000541046': 0, '2000541049': 0, '2000541050': 0, '2000541051': 0, '2000541052': 0, '2000541053': 0, '2000541054': 0, '2000541055': 0, '2000541056': 0, '2000541057': 0, '2000541059': 0, '2000541062': 0, '2000541064': 0, '2000541066': 0, '2000541067': 0, '2000541068': 0, '2000541069': 0, '2000541070': 0, '2000541071': 0, '2000541072': 0, '2000541073': 0, '2000541074': 0, '2000541075': 0, '2000541076': 0, '2000541077': 0, '2000541079': 0, '2000541080': 0, '2000541081': 0, '2000542001': 0, '2000542002': 0, '2000542007': 0, '2000542008': 0, '2000542009': 0, '2000542010': 0, '2000542013': 0, '2000542015': 0, '2000542016': 0, '2000542021': 0, '2000542022': 0, '2000542025': 0, '2000542026': 0, '2000542027': 0, '2000542029': 0, '2000542030': 0, '2000542032': 0, '2000542033': 0, '2000542034': 0, '2000542035': 0, '2000542036': 0, '2000542042': 0, '2000542049': 0, '2000542050': 0, '2000542051': 0, '2000542052': 0, '2000542054': 0, '2000542056': 0, '2026140111': 0, '2026140113': 0, '2026140116': 0, '2026140117': 0, '2026140118': 0, '2026140119': 0, '2026140120': 0, '2026140122': 0, '2026140124': 0, '2026140125': 0, '2026140126': 0, '2026140128': 0, '2026140129': 0, '2026140130': 0, '2026140131': 0, '2026140133': 0, '2026140134': 0, '2026140135': 0, '2026140138': 0, '2026140141': 0, '2026140145': 0, '2026140147': 0, '2026140149': 0, '202614015': 0, '2026140151': 0, '2026140154': 0, '2026140158': 0, '2026140159': 0, '202614016': 0, '2026140160': 0, '2026140161': 0, '2026140165': 0, '2026140169': 0, '202614017': 0, '2026140170': 0, '2026140172': 0, '202614018': 0, '202614019': 0, '202614020': 0, '202614021': 0, '2026140210': 0, '2026140212': 0, '2026140213': 0, '2026140220': 0, '2026140221': 0, '2026140223': 0, '2026140224': 0, '2026140225': 0, '202614023': 0, '2026140230': 0, '2026140233': 0, '2026140236': 0, '2026140237': 0, '2026140239': 0, '2026140241': 0, '2026140243': 0, '2026140246': 0, '2026140247': 0, '2026140249': 0, '202614025': 0, '2026140250': 0, '2026140253': 0, '2026140254': 0, '2026140255': 0, '2026140257': 1, '2026140259': 0, '2026140260': 0, '2026140263': 0, '2026140264': 1, '2026140272': 0, '2026140273': 1, '2026140275': 0, '2026140276': 0, '2026140277': 0, '2026140279': 0, '2026140281': 0, '202614029': 0, '205601011': 0, '2056010112': 0, '2056010113': 0, '2056010114': 0, '2056010116': 0, '2056010118': 0, '2056010119': 0, '205601012': 0, '2056010120': 0, '2056010122': 0, '2056010123': 0, '2056010124': 0, '2056010126': 0, '2056010130': 0, '2056010133': 0, '2056010134': 1, '2056010136': 0, '2056010137': 0, '2056010139': 0, '2056010141': 0, '2056010142': 0, '2056010148': 0, '2056010149': 0, '2056010153': 0, '2056010155': 0, '2056010156': 0, '2056010157': 0, '205601016': 0, '2056010160': 0, '2056010162': 0, '2056010164': 0, '2056010165': 0, '2056010167': 0, '205601017': 0, '205601018': 0, '2056010210': 0, '2056010212': 0, '2056010213': 0, '2056010214': 0, '2056010215': 0, '2056010218': 0, '2056010219': 0, '2056010222': 0, '2056010224': 1, '2056010225': 0, '2056010226': 0, '2056010228': 0, '2056010229': 0, '2056010230': 0, '2056010232': 0, '2056010233': 0, '2056010234': 0, '2056010235': 0, '2056010236': 0, '2056010238': 0, '2056010239': 0, '205601024': 0, '2056010240': 0, '2056010241': 0, '2056010242': 0, '2056010244': 0, '2056010245': 0, '2056010247': 0, '2056010249': 0, '205601025': 0, '2056010250': 0, '2056010252': 0, '2056010253': 0, '2056010254': 0, '2056010255': 0, '2056010258': 0, '2056010260': 0, '2056010261': 0, '2056010262': 0, '2056010263': 0, '2056010265': 0, '2056010267': 0, '2056010269': 0, '205601027': 0, '2056010272': 0, '2056010274': 0, '2056010275': 0, '2056010276': 0, '2056010277': 0, '2056010279': 0, '205601028': 0, '2056010281': 0, '2056010283': 0, '2100511002': 0, '2100511003': 0, '2100511005': 0, '2100511008': 0, '2100511011': 0, '2100511012': 0, '2100511013': 0, '2100511015': 0, '2100511016': 0, '2100511018': 0, '2100511019': 0, '2100511024': 0, '2100511026': 0, '2100511027': 0, '2100511028': 0, '2100511031': 0, '2100511032': 0, '2100511034': 0, '2100511035': 0, '2100511036': 0, '2100511038': 0, '2100511039': 0, '2100511040': 0, '2100511044': 0, '2100511048': 0, '2100511057': 0, '2100511058': 0, '2100511059': 0, '2100511060': 0, '2100511061': 0, '2100511062': 0, '2100511063': 0, '2100511064': 0, '2100511065': 0, '2100511067': 0, '2100511069': 1, '2100511070': 0, '2100511071': 0, '2100511072': 0, '2100511073': 0, '2100511074': 0, '2100511076': 0, '2100511077': 0, '2100511078': 0, '2100511079': 0, '2100511080': 0, '2100511081': 0, '2100511082': 0, '2100512001': 0, '2100512002': 0, '2100512003': 0, '2100512006': 0, '2100512007': 0, '2100512009': 0, '2100512010': 0, '2100512011': 0, '2100512012': 0, '2100512014': 0, '2100512015': 0, '2100512016': 0, '2100512017': 0, '2100512018': 0, '2100512020': 0, '2100512021': 0, '2100512025': 0, '2100512026': 0, '2100512028': 0, '2100512029': 0, '2100512032': 0, '2100512034': 0, '2100512035': 0, '2100512036': 0, '2100512037': 0, '2100512038': 0, '2100512039': 0, '2100512041': 0, '2100512042': 0, '2100512044': 0, '2100512045': 0, '2100512051': 1, '2100512052': 0, '2100512053': 0, '2100512055': 0, '2100512057': 0, '2100512058': 0, '2100512061': 0, '2100512062': 0, '2100512063': 0, '2100512064': 1, '2100512065': 0, '2100521002': 0, '2100521005': 0, '2100521006': 0, '2100521008': 0, '2100521009': 0, '2100521010': 0, '2100521013': 0, '2100521014': 0, '2100521015': 0, '2100521016': 0, '2100521017': 0, '2100521018': 0, '2100521021': 0, '2100521022': 0, '2100521023': 0, '2100521024': 0, '2100521025': 0, '2100521026': 0, '2100521027': 0, '2100521028': 0, '2100521029': 0, '2100521030': 0, '2100521031': 0, '2100521032': 1, '2100521033': 0, '2100521034': 0, '2100521035': 0, '2100521037': 0, '2100521038': 0, '2100521039': 0, '2100521040': 0, '2100521041': 0, '2100521042': 0, '2100521043': 0, '2100521044': 0, '2100521046': 0, '2100521047': 0, '2100521048': 0, '2100521049': 0, '2100521050': 0, '2100521051': 0, '2100521052': 0, '2100521054': 0, '2100521055': 0, '2100521056': 0, '2100521057': 0, '2100521059': 0, '2100521060': 0, '2100521061': 0, '2100521062': 0, '2100521063': 0, '2100521067': 0, '2100521069': 0, '2100521070': 0, '2100521072': 0, '2100521073': 0, '2100521074': 0, '2100521075': 0, '2100521076': 0, '2100521077': 0, '2100521078': 0, '2100521079': 0, '2100522001': 0, '2100522004': 0, '2100522005': 0, '2100522006': 0, '2100522007': 0, '2100522008': 0, '2100522009': 0, '2100522010': 0, '2100522011': 0, '2100522012': 0, '2100522013': 0, '2100522018': 0, '2100522019': 0, '2100522020': 0, '2100522021': 0, '2100522023': 0, '2100522024': 0, '2100522026': 0, '2100522028': 0, '2100522031': 0, '2100522033': 0, '2100522034': 0, '2100522035': 0, '2100522036': 0, '2100522038': 0, '2100522039': 0, '2100522040': 0, '2100522041': 0, '2100522042': 0, '2100522046': 0, '2100522047': 0, '2100522048': 0, '2100522049': 0, '2100522050': 0, '2100522051': 0, '2100522052': 0, '2100522053': 0, '2100522054': 0, '2100522055': 0, '2100522056': 0, '2100522059': 0, '2100522060': 0, '2100522061': 0, '2100522062': 0, '2100522063': 0, '2100522064': 0, '2100522067': 0, '2100522068': 0, '2100522070': 0, '2100531001': 0, '2100531002': 0, '2100531003': 0, '2100531004': 0, '2100531006': 0, '2100531007': 0, '2100531008': 0, '2100531009': 0, '2100531010': 0, '2100531012': 0, '2100531013': 0, '2100531014': 0, '2100531015': 0, '2100531016': 0, '2100531017': 0, '2100531018': 0, '2100531019': 0, '2100531021': 0, '2100531022': 0, '2100531023': 0, '2100531024': 0, '2100531025': 0, '2100531026': 0, '2100531027': 0, '2100531028': 0, '2100531030': 0, '2100531031': 0, '2100531033': 0, '2100531034': 0, '2100531035': 0, '2100531036': 0, '2100531037': 0, '2100531040': 0, '2100531041': 0, '2100531042': 0, '2100531043': 0, '2100531044': 0, '2100531045': 0, '2100531047': 0, '2100531048': 0, '2100531049': 0, '2100531050': 0, '2100531051': 0, '2100531052': 0, '2100531053': 0, '2100531054': 1, '2100531055': 0, '2100531056': 0, '2100531057': 0, '2100531058': 0, '2100531059': 0, '2100531060': 0, '2100531061': 0, '2100531063': 0, '2100531064': 0, '2100531065': 0, '2100531066': 0, '2100531067': 0, '2100531068': 0, '2100531070': 0, '2100531071': 0, '2100531072': 0, '2100531073': 0, '2100531074': 0, '2100531076': 0, '2100531077': 0, '2100531078': 0, '2100531079': 0, '2100531080': 0, '2100531081': 0, '2100531082': 0, '2100531084': 0, '2100532002': 0, '2100532003': 0, '2100532004': 0, '2100532005': 0, '2100532007': 0, '2100532008': 0, '2100532010': 0, '2100532012': 0, '2100532013': 0, '2100532015': 0, '2100532016': 1, '2100532017': 0, '2100532019': 0, '2100532020': 0, '2100532022': 1, '2100532023': 0, '2100532024': 0, '2100532025': 0, '2100532026': 0, '2100532027': 0, '2100532028': 0, '2100532029': 0, '2100532030': 0, '2100532031': 0, '2100532032': 0, '2100532033': 0, '2100532034': 0, '2100532037': 0, '2100532042': 0, '2100532043': 0, '2100532044': 0, '2100532045': 0, '2100532046': 0, '2100532047': 0, '2100532048': 0, '2100532050': 0, '2100532052': 0, '2100532053': 0, '2100532054': 0, '2100532055': 0, '2100532056': 0, '2100532057': 0, '2100532058': 0, '2100532059': 0, '2100532060': 0, '2100532061': 0, '2100532062': 0, '2100532063': 0, '2100532064': 0, '2100532066': 0, '2100532067': 0, '2100532068': 0, '2100532070': 0, '2100532071': 0, '2100532072': 0, '2100551002': 0, '2100551005': 1, '2100551006': 0, '2100551007': 0, '2100551010': 1, '2100551011': 0, '2100551013': 0, '2100551014': 0, '2100551015': 0, '2100551016': 0, '2100551017': 0, '2100551018': 0, '2100551019': 0, '2100551020': 0, '2100551021': 0, '2100551022': 0, '2100551023': 0, '2100551024': 0, '2100551025': 0, '2100551027': 0, '2100551028': 0, '2100551029': 0, '2100551032': 1, '2100551033': 0, '2100551034': 0, '2100551035': 1, '2100551036': 0, '2100551037': 0, '2100551039': 0, '2100551041': 0, '2100551042': 1, '2100551043': 0, '2100551044': 0, '2100551045': 0, '2100551046': 0, '2100551049': 0, '2100551050': 0, '2100551051': 0, '2100551052': 0, '2100551053': 0, '2100551054': 0, '2100551055': 0, '2100551056': 0, '2100551057': 0, '2100551059': 0, '2100551060': 0, '2100551061': 0, '2100551062': 0, '2100551063': 0, '2100551064': 0, '2100551065': 0, '2100551066': 0, '2100551067': 0, '2100551068': 0, '2100551069': 0, '2100551071': 0, '2100551072': 0, '2100551073': 0, '2100551074': 0, '2100551075': 0, '2100551076': 0, '2100551077': 0, '2100551079': 0, '2100551080': 0, '2100551081': 0, '2100552002': 0, '2100552003': 0, '2100552004': 0, '2100552005': 0, '2100552006': 0, '2100552007': 0, '2100552008': 0, '2100552009': 0, '2100552010': 0, '2100552011': 0, '2100552012': 0, '2100552013': 0, '2100552014': 0, '2100552015': 0, '2100552016': 0, '2100552017': 0, '2100552018': 0, '2100552019': 0, '2100552021': 0, '2100552022': 0, '2100552023': 0, '2100552024': 0, '2100552025': 0, '2100552027': 0, '2100552028': 0, '2100552029': 0, '2100552030': 0, '2100552031': 0, '2100552032': 0, '2100552033': 0, '2100552034': 0, '2100552035': 0, '2100552037': 0, '2100552038': 0, '2100552039': 0, '2100552041': 0, '2100552042': 0, '2100552043': 0, '2100552044': 0, '2100552045': 0, '2100552047': 0, '2100552048': 1, '2100552051': 0, '2100552052': 0, '2100552053': 0, '2100552055': 0, '2100552057': 0, '2100552059': 0, '2100552060': 0, '2100552061': 0, '2100552062': 0, '2100552063': 1, '2100552065': 0, '2100552066': 0, '2100552068': 0, '2100552072': 0, '2100561006': 0, '2100561010': 0, '2100561011': 0, '2100561013': 0, '2100561014': 0, '2100561015': 0, '2100561016': 0, '2100561018': 0, '2100561019': 0, '2100561020': 0, '2100561021': 0, '2100561022': 0, '2100561023': 0, '2100561024': 0, '2100561027': 0, '2100561029': 0, '2100561032': 0, '2100561038': 0, '2100561043': 0, '2100561044': 0, '2100561046': 0, '2100561051': 0, '2100561052': 0, '2100561053': 0, '2100561054': 0, '2100561056': 0, '2100561057': 0, '2100561058': 0, '2100561059': 0, '2100561062': 0, '2100561063': 0, '2100561064': 0, '2100561065': 0, '2100561070': 0, '2100561071': 0, '2100561074': 0, '2100561079': 0, '2100562001': 0, '2100562002': 0, '2100562003': 0, '2100562004': 0, '2100562005': 0, '2100562007': 0, '2100562008': 0, '2100562009': 0, '2100562010': 0, '2100562011': 0, '2100562012': 0, '2100562013': 0, '2100562014': 0, '2100562015': 0, '2100562017': 0, '2100562018': 0, '2100562019': 1, '2100562020': 0, '2100562024': 1, '2100562026': 0, '2100562027': 0, '2100562029': 0, '2100562030': 0, '2100562032': 0, '2100562033': 0, '2100562034': 0, '2100562035': 0, '2100562037': 0, '2100562038': 0, '2100562039': 0, '2100562040': 0, '2100562042': 0, '2100562043': 0, '2100562044': 0, '2100562046': 0, '2100562047': 0, '2100562048': 0, '2100562049': 0, '2100562050': 0, '2100562051': 0, '2100562053': 0, '2100562054': 0, '2100562055': 0, '2100562056': 0, '2100562058': 0, '2100562059': 0, '2100562060': 0, '2100562061': 0, '2100571001': 0, '2100571002': 1, '2100571004': 0, '2100571007': 1, '2100571008': 0, '2100571009': 0, '2100571011': 0, '2100571012': 0, '2100571013': 0, '2100571015': 0, '2100571017': 0, '2100571018': 0, '2100571019': 0, '2100571020': 0, '2100571021': 1, '2100571022': 0, '2100571023': 1, '2100571024': 0, '2100571025': 0, '2100571027': 0, '2100571029': 0, '2100571030': 0, '2100571031': 0, '2100571033': 0, '2100571034': 0, '2100571036': 0, '2100571038': 1, '2100571039': 0, '2100571040': 0, '2100571041': 0, '2100571042': 0, '2100571044': 1, '2100571045': 0, '2100571046': 0, '2100571047': 0, '2100571048': 0, '2100571049': 1, '2100571050': 0, '2100571051': 0, '2100571052': 0, '2100571053': 0, '2100571055': 0, '2100571056': 0, '2100571057': 0, '2100571058': 0, '2100571061': 0, '2100571062': 1, '2100571063': 0, '2100571064': 0, '2100571065': 0, '2100571066': 0, '2100571067': 0, '2100571068': 0, '2100571069': 0, '2100571070': 0, '2100571072': 0, '2100571073': 0, '2100571074': 0, '2100571075': 0, '2100571077': 0, '2100571078': 0, '2100571079': 0, '2100571081': 0, '2100571082': 0, '2100572001': 0, '2100572002': 0, '2100572004': 0, '2100572006': 0, '2100572009': 0, '2100572010': 0, '2100572011': 0, '2100572012': 0, '2100572013': 0, '2100572015': 0, '2100572017': 0, '2100572018': 0, '2100572019': 0, '2100572020': 0, '2100572021': 1, '2100572023': 0, '2100572024': 0, '2100572025': 0, '2100572026': 0, '2100572027': 0, '2100572028': 0, '2100572029': 0, '2100572030': 0, '2100572032': 0, '2100572033': 0, '2100572034': 0, '2100572036': 0, '2100572038': 0, '2100572039': 0, '2100572040': 0, '2100572041': 0, '2100572042': 0, '2100572043': 0, '2100572044': 0, '2100572045': 0, '2100572046': 0, '2100572047': 0, '2100572048': 0, '2100572050': 0, '2100572051': 0, '2100572054': 0, '2100572055': 0, '2100572056': 0, '2100572057': 1, '2100572058': 0, '2100572059': 0, '2100572060': 0, '2100572061': 0, '2100572062': 0, '2100572063': 0, '2100572064': 0, '2100572067': 0, '2100572068': 0, '2100572069': 0, '2100581001': 1, '2100581002': 0, '2100581003': 0, '2100581004': 0, '2100581005': 0, '2100581006': 0, '2100581007': 0, '2100581009': 0, '2100581010': 0, '2100581011': 0, '2100581012': 0, '2100581013': 0, '2100581014': 0, '2100581015': 0, '2100581018': 0, '2100581019': 0, '2100581021': 1, '2100581022': 0, '2100581024': 0, '2100581025': 0, '2100581026': 0, '2100581027': 0, '2100581028': 0, '2100581029': 0, '2100581030': 0, '2100581034': 0, '2100581035': 0, '2100581036': 0, '2100581037': 0, '2100581038': 0, '2100581039': 0, '2100581040': 0, '2100581041': 0, '2100581042': 0, '2100581044': 0, '2100581045': 0, '2100581051': 0, '2100581054': 0, '2100581056': 0, '2100581057': 0, '2100581058': 0, '2100581059': 0, '2100581061': 0, '2100581062': 0, '2100581064': 0, '2100581066': 0, '2100581067': 0, '2100581068': 0, '2100581069': 0, '2100581070': 0, '2100581071': 0, '2100581072': 0, '2100581073': 0, '2100581074': 0, '2100581075': 0, '2100581076': 0, '2100581077': 0, '2100582001': 0, '2100582002': 0, '2100582003': 0, '2100582004': 0, '2100582005': 0, '2100582006': 0, '2100582008': 0, '2100582009': 0, '2100582012': 0, '2100582013': 0, '2100582015': 0, '2100582017': 0, '2100582019': 0, '2100582020': 0, '2100582021': 0, '2100582023': 0, '2100582024': 0, '2100582025': 0, '2100582026': 0, '2100582027': 1, '2100582028': 0, '2100582038': 0, '2100582043': 0, '2100582044': 0, '2100582045': 0, '2100582046': 0, '2100582048': 0, '2100582050': 0, '2100582051': 0, '2100582052': 1, '2100582053': 0, '2100582054': 0, '2100582055': 1, '2100582056': 1, '2100582057': 1, '2100582058': 1, '2100582060': 1, '2100582061': 1, '2100582062': 1, '2100582064': 0, '2100582067': 0, '2100582069': 0, '2100591002': 0, '2100591003': 0, '2100591004': 0, '2100591005': 0, '2100591006': 0, '2100591007': 0, '2100591008': 0, '2100591010': 0, '2100591013': 0, '2100591015': 0, '2100591016': 0, '2100591017': 0, '2100591019': 0, '2100591020': 0, '2100591021': 0, '2100591022': 0, '2100591023': 0, '2100591025': 0, '2100591026': 0, '2100591027': 0, '2100591028': 0, '2100591030': 0, '2100591034': 0, '2100591035': 0, '2100591036': 0, '2100591037': 0, '2100591038': 0, '2100591039': 0, '2100591040': 0, '2100591041': 0, '2100591042': 0, '2100591043': 0, '2100591044': 0, '2100591045': 0, '2100591046': 1, '2100591047': 0, '2100591048': 0, '2100591049': 0, '2100591050': 0, '2100591053': 0, '2100591054': 0, '2100591055': 0, '2100591056': 0, '2100591057': 0, '2100591059': 0, '2100591060': 0, '2100591061': 0, '2100591062': 0, '2100591064': 0, '2100591065': 0, '2100591066': 0, '2100591067': 0, '2100591068': 0, '2100591069': 0, '2100591070': 0, '2100591072': 0, '2100591073': 0, '2100591074': 0, '2100591075': 0, '2100591076': 0, '2100591077': 0, '2100591078': 0, '2100591080': 0, '2100591081': 0, '2100591082': 0, '2100592002': 0, '2100592003': 0, '2100592004': 0, '2100592005': 0, '2100592007': 0, '2100592009': 0, '2100592010': 0, '2100592011': 0, '2100592012': 0, '2100592013': 0, '2100592014': 0, '2100592015': 0, '2100592016': 0, '2100592017': 0, '2100592018': 0, '2100592019': 0, '2100592020': 0, '2100592021': 0, '2100592022': 0, '2100592023': 0, '2100592024': 0, '2100592025': 0, '2100592026': 0, '2100592027': 0, '2100592028': 0, '2100592029': 0, '2100592030': 0, '2100592032': 0, '2100592033': 0, '2100592034': 0, '2100592035': 0, '2100592036': 0, '2100592038': 0, '2100592040': 0, '2100592041': 0, '2100592042': 0, '2100592043': 0, '2100592044': 0, '2100592046': 0, '2100592047': 0, '2100592048': 0, '2100592049': 0, '2100592052': 0, '2100592053': 0, '2100592054': 0, '2100592056': 0, '2100592057': 0, '2100592058': 0, '2100592059': 0, '2100592060': 0, '2100592064': 0, '2100592065': 0, '2100592066': 0, '2100592067': 0, '2100592068': 0, '2100592069': 0, '2100592070': 0, '2100592071': 0, '2100592072': 0, '2100601001': 0, '2100601002': 0, '2100601004': 0, '2100601005': 0, '2100601006': 0, '2100601007': 0, '2100601008': 0, '2100601009': 0, '2100601010': 0, '2100601011': 0, '2100601012': 1, '2100601013': 0, '2100601014': 0, '2100601015': 0, '2100601016': 0, '2100601017': 0, '2100601018': 1, '2100601020': 0, '2100601021': 0, '2100601023': 0, '2100601024': 0, '2100601025': 0, '2100601027': 0, '2100601028': 0, '2100601029': 0, '2100601030': 0, '2100601031': 0, '2100601032': 0, '2100601033': 0, '2100601035': 0, '2100601036': 0, '2100601037': 0, '2100601038': 0, '2100601039': 0, '2100601040': 0, '2100601041': 0, '2100601042': 0, '2100601043': 0, '2100601044': 0, '2100601045': 0, '2100601046': 0, '2100601049': 0, '2100601050': 0, '2100601052': 0, '2100601053': 0, '2100601054': 0, '2100601055': 0, '2100601056': 0, '2100601057': 0, '2100601059': 0, '2100601062': 0, '2100601063': 0, '2100601064': 0, '2100601065': 0, '2100601066': 0, '2100601067': 0, '2100601068': 0, '2100601069': 0, '2100601071': 0, '2100601073': 0, '2100601074': 0, '2100601075': 0, '2100601077': 0, '2100601078': 0, '2100602001': 0, '2100602002': 0, '2100602003': 0, '2100602004': 0, '2100602005': 0, '2100602006': 0, '2100602008': 0, '2100602009': 0, '2100602010': 0, '2100602011': 0, '2100602012': 0, '2100602014': 0, '2100602015': 0, '2100602017': 0, '2100602018': 0, '2100602019': 0, '2100602020': 0, '2100602022': 0, '2100602023': 0, '2100602024': 0, '2100602025': 0, '2100602026': 0, '2100602027': 0, '2100602028': 0, '2100602029': 0, '2100602030': 0, '2100602032': 0, '2100602033': 0, '2100602034': 0, '2100602035': 0, '2100602036': 0, '2100602038': 0, '2100602040': 0, '2100602041': 1, '2100602042': 0, '2100602043': 0, '2100602044': 0, '2100602046': 0, '2100602047': 0, '2100602049': 0, '2100602050': 0, '2100602051': 0, '2100602052': 0, '2100602053': 0, '2100602054': 0, '2100602056': 0, '2100602058': 0, '2100602059': 0, '2100602060': 0, '2100602061': 0, '2100602062': 0, '2100602063': 0, '2100602065': 0, '2100602067': 0, '2100602068': 0, '2100602069': 0, '2100602072': 0, '2100611002': 0, '2100611003': 0, '2100611004': 0, '2100611005': 0, '2100611006': 0, '2100611010': 0, '2100611011': 0, '2100611012': 0, '2100611013': 0, '2100611014': 0, '2100611015': 0, '2100611016': 0, '2100611017': 0, '2100611018': 0, '2100611019': 0, '2100611021': 0, '2100611023': 0, '2100611024': 0, '2100611025': 0, '2100611026': 0, '2100611027': 1, '2100611028': 0, '2100611029': 0, '2100611031': 0, '2100611032': 0, '2100611034': 0, '2100611035': 0, '2100611036': 0, '2100611037': 0, '2100611038': 0, '2100611039': 0, '2100611040': 0, '2100611041': 0, '2100611042': 0, '2100611043': 0, '2100611044': 0, '2100611045': 0, '2100611046': 0, '2100611047': 0, '2100611048': 0, '2100611049': 0, '2100611050': 0, '2100611051': 0, '2100611052': 0, '2100611055': 0, '2100611056': 0, '2100611057': 0, '2100611058': 0, '2100611059': 0, '2100611060': 0, '2100611061': 0, '2100611062': 0, '2100611063': 0, '2100611064': 0, '2100611066': 0, '2100611067': 0, '2100611068': 0, '2100611069': 0, '2100611070': 0, '2100611071': 0, '2100611075': 0, '2100611076': 0, '2100611077': 0, '2100611078': 0, '2100611079': 0, '2100611081': 0, '2100611083': 0, '2100612001': 0, '2100612002': 0, '2100612003': 0, '2100612005': 0, '2100612006': 0, '2100612007': 0, '2100612008': 0, '2100612009': 1, '2100612010': 0, '2100612011': 0, '2100612012': 0, '2100612014': 0, '2100612015': 0, '2100612020': 0, '2100612022': 0, '2100612024': 0, '2100612025': 0, '2100612026': 0, '2100612027': 0, '2100612028': 0, '2100612029': 0, '2100612030': 0, '2100612031': 0, '2100612033': 0, '2100612034': 0, '2100612035': 0, '2100612037': 0, '2100612038': 0, '2100612040': 0, '2100612041': 0, '2100612042': 0, '2100612043': 0, '2100612044': 0, '2100612045': 0, '2100612046': 0, '2100612047': 0, '2100612048': 0, '2100612051': 0, '2100612053': 0, '2100612056': 0, '2100612057': 0, '2100612058': 0, '2100612059': 0, '2100612060': 0, '2100612061': 0, '2100612062': 0, '2100612063': 0, '2100612064': 0, '2100612065': 0, '2100612066': 0, '2100612067': 0, '2100612068': 0, '2100612069': 0, '2100612070': 0, '2100612071': 0, '2100612072': 0, '2260510110': 0, '2260510113': 0, '2260510114': 0, '2260510115': 0, '2260510116': 0, '2260510118': 0, '2260510122': 0, '2260510124': 0, '2260510125': 0, '2260510126': 0, '2260510127': 0, '2260510129': 0, '226051013': 0, '2260510131': 0, '2260510134': 0, '2260510136': 0, '2260510138': 0, '2260510139': 0, '226051014': 0, '2260510140': 0, '2260510141': 0, '2260510142': 0, '2260510143': 0, '2260510146': 0, '2260510147': 0, '2260510148': 0, '2260510151': 0, '2260510152': 0, '2260510155': 1, '2260510156': 0, '2260510158': 0, '2260510159': 0, '226051016': 0, '2260510160': 0, '2260510162': 0, '2260510163': 1, '2260510167': 0, '2260510168': 0, '226051017': 0, '2260510172': 0, '2260510174': 0, '2260510176': 0, '2260510177': 1, '2260510180': 0, '2260510182': 0, '2260510183': 0, '2260510185': 0, '226051019': 0, '226051021': 0, '2260510212': 0, '2260510213': 0, '2260510214': 0, '2260510217': 0, '226051022': 0, '2260510220': 0, '2260510221': 0, '2260510222': 0, '2260510223': 0, '2260510227': 0, '2260510228': 0, '2260510229': 0, '226051023': 0, '2260510230': 0, '2260510231': 0, '2260510232': 0, '2260510233': 0, '2260510237': 0, '2260510238': 0, '2260510240': 0, '2260510241': 0, '2260510242': 0, '2260510243': 0, '2260510244': 0, '2260510247': 0, '2260510248': 0, '226051025': 0, '2260510250': 0, '2260510252': 0, '2260510253': 0, '2260510254': 0, '2260510257': 0, '2260510258': 0, '2260510259': 0, '226051026': 0, '2260510260': 0, '2260510262': 0, '2260510266': 0, '2260510267': 0, '226051027': 0, '2260510270': 0, '2260510271': 0, '2260510272': 0, '2260510276': 0, '2260510277': 0, '2260510278': 0, '240846010': 0, '240846011': 0, '2408460110': 0, '2408460111': 0, '2408460118': 1, '240846012': 0, '2408460120': 0, '2408460123': 0, '2408460125': 0, '2408460126': 0, '2408460127': 0, '2408460129': 0, '240846013': 0, '2408460130': 0, '2408460131': 0, '2408460132': 0, '2408460133': 0, '2408460134': 0, '2408460135': 0, '2408460137': 1, '2408460139': 0, '2408460143': 0, '2408460145': 0, '2408460146': 0, '2408460148': 0, '2408460149': 0, '240846015': 0, '2408460150': 0, '2408460151': 0, '2408460152': 0, '2408460154': 0, '2408460155': 0, '2408460156': 0, '2408460158': 0, '2408460159': 0, '240846016': 0, '2408460163': 0, '2408460166': 0, '240846017': 0, '240846018': 0, '240846019': 0, '2408460211': 0, '2408460212': 0, '2408460213': 0, '2408460215': 0, '2408460217': 0, '2408460219': 0, '240846022': 0, '2408460220': 0, '2408460221': 0, '2408460222': 0, '2408460223': 0, '2408460225': 0, '2408460226': 0, '2408460227': 0, '2408460229': 0, '240846023': 0, '2408460234': 0, '2408460236': 0, '2408460237': 0, '2408460238': 0, '240846024': 0, '2408460240': 0, '2408460242': 0, '2408460243': 0, '2408460244': 0, '2408460246': 0, '2408460247': 0, '2408460249': 0, '2408460252': 0, '2408460254': 0, '2408460255': 0, '2408460257': 0, '2408460260': 0, '2408460261': 0, '2408460265': 0, '2408460266': 0, '2408460268': 0, '2408460269': 0, '240846027': 0, '2408460271': 0, '2408460272': 0, '2408460274': 0, '2408460276': 0, '2408460277': 0, '2408460278': 0, '240846028': 0, '2408460280': 0, '240846029': 0, '24851011': 0, '248510111': 0, '248510112': 0, '248510114': 0, '248510116': 0, '248510117': 0, '248510118': 0, '248510119': 0, '248510120': 0, '248510125': 0, '248510127': 0, '248510128': 0, '248510129': 0, '24851013': 0, '248510131': 0, '248510136': 0, '248510137': 0, '24851014': 0, '248510142': 0, '248510147': 0, '248510148': 0, '24851015': 0, '248510150': 0, '248510151': 0, '248510153': 0, '248510155': 0, '248510156': 0, '248510157': 0, '248510160': 0, '248510161': 0, '248510163': 0, '248510164': 0, '248510167': 0, '248510170': 0, '24851018': 0, '24851019': 0, '248510211': 0, '248510212': 0, '248510213': 0, '248510214': 0, '248510215': 0, '248510216': 0, '24851022': 0, '248510220': 0, '248510223': 0, '248510225': 0, '248510227': 0, '248510229': 0, '248510230': 0, '248510232': 0, '248510233': 0, '248510235': 0, '248510236': 0, '24851024': 0, '248510241': 0, '248510242': 0, '248510245': 0, '248510246': 0, '248510248': 0, '248510249': 0, '248510250': 0, '248510251': 0, '248510253': 0, '248510255': 0, '248510256': 0, '248510259': 0, '24851026': 0, '248510260': 0, '248510262': 0, '248510264': 0, '248510265': 0, '248510267': 0, '248510268': 0, '24851027': 0, '248510271': 0, '248510272': 0, '248510273': 0, '248510276': 0, '248510278': 0, '24851028': 0, '2904280110': 0, '29042801110': 0, '29042801170': 0, '29042801180': 0, '2904280120': 0, '29042801220': 0, '29042801230': 0, '29042801250': 0, '29042801260': 0, '29042801290': 0, '29042801300': 0, '29042801320': 0, '29042801340': 0, '29042801350': 0, '29042801370': 1, '29042801390': 0, '2904280140': 0, '29042801440': 0, '29042801450': 0, '29042801470': 0, '29042801480': 0, '2904280150': 0, '29042801500': 0, '29042801550': 0, '29042801570': 0, '29042801580': 0, '2904280160': 0, '29042801600': 0, '29042801630': 0, '29042801640': 0, '29042801650': 0, '29042801680': 0, '29042801690': 0, '2904280170': 0, '29042801710': 0, '29042801740': 0, '29042801750': 0, '29042801770': 0, '29042801780': 0, '29042801790': 0, '2904280180': 0, '2904280190': 0, '29042802110': 0, '29042802140': 0, '29042802150': 0, '29042802180': 0, '29042802200': 0, '29042802220': 0, '29042802240': 0, '29042802260': 0, '29042802280': 0, '2904280230': 0, '29042802310': 0, '29042802320': 0, '29042802340': 0, '29042802350': 0, '29042802380': 0, '29042802390': 0, '29042802410': 0, '29042802420': 0, '29042802430': 0, '29042802440': 0, '29042802450': 0, '29042802460': 0, '29042802470': 0, '29042802480': 0, '2904280250': 0, '29042802500': 0, '29042802510': 0, '29042802520': 0, '29042802530': 0, '29042802560': 0, '29042802570': 0, '2904280260': 1, '29042802600': 0, '29042802640': 0, '29042802660': 0, '29042802670': 0, '29042802680': 0, '29042802690': 0, '2904280270': 0, '29042802700': 0, '29042802720': 0, '29042802740': 0, '29042802750': 0, '29042802760': 0, '29042802770': 0, '29042802790': 0, '2904280280': 0, '29042802800': 0, '29042802830': 0, '29042802860': 0, '2904280290': 0, '303830110': 0, '303830113': 1, '303830115': 0, '303830117': 0, '303830118': 0, '303830121': 0, '303830122': 0, '303830123': 0, '303830126': 1, '303830127': 0, '303830128': 0, '30383013': 0, '303830131': 0, '303830132': 0, '303830133': 0, '303830138': 0, '303830139': 1, '30383014': 0, '303830141': 0, '303830143': 0, '303830144': 0, '303830146': 0, '303830147': 0, '303830148': 0, '303830149': 1, '30383015': 0, '303830151': 0, '303830155': 1, '303830156': 0, '303830157': 0, '303830158': 0, '303830159': 0, '30383016': 0, '303830160': 0, '303830161': 0, '303830162': 0, '303830166': 0, '303830167': 0, '303830169': 0, '303830171': 0, '303830174': 0, '303830175': 0, '303830178': 0, '303830182': 0, '303830183': 0, '303830184': 0, '303830210': 0, '303830211': 0, '303830212': 0, '303830216': 0, '303830217': 0, '303830218': 0, '30383022': 0, '303830220': 0, '303830221': 0, '303830223': 0, '303830224': 0, '303830225': 0, '303830227': 0, '303830229': 0, '30383023': 1, '303830234': 0, '303830236': 0, '303830239': 0, '303830240': 0, '303830241': 0, '303830242': 0, '303830245': 0, '303830246': 0, '303830247': 0, '303830249': 0, '30383025': 0, '303830250': 0, '303830255': 0, '303830258': 0, '303830259': 0, '303830263': 0, '303830269': 0, '303830270': 0, '303830273': 0, '303830274': 0, '303830278': 0, '30383028': 0, '3100621001': 0, '3100621002': 0, '3100621003': 0, '3100621004': 0, '3100621005': 0, '3100621007': 0, '3100621009': 0, '3100621010': 0, '3100621011': 0, '3100621012': 0, '3100621013': 0, '3100621014': 0, '3100621016': 0, '3100621018': 0, '3100621019': 0, '3100621020': 0, '3100621022': 0, '3100621023': 0, '3100621024': 0, '3100621025': 0, '3100621026': 0, '3100621027': 0, '3100621028': 0, '3100621030': 0, '3100621031': 0, '3100621032': 0, '3100621033': 0, '3100621034': 0, '3100621035': 0, '3100621037': 1, '3100621039': 0, '3100621040': 0, '3100621041': 0, '3100621042': 0, '3100621043': 0, '3100621045': 0, '3100621046': 0, '3100621047': 0, '3100621048': 0, '3100621049': 0, '3100621051': 0, '3100621052': 0, '3100621053': 0, '3100621055': 0, '3100621057': 0, '3100621058': 0, '3100621059': 0, '3100621061': 0, '3100621062': 0, '3100621063': 0, '3100621064': 0, '3100622001': 0, '3100622002': 0, '3100622003': 0, '3100622006': 0, '3100622007': 0, '3100622008': 0, '3100622009': 0, '3100622011': 0, '3100622013': 0, '3100622015': 0, '3100622019': 0, '3100622020': 0, '3100622021': 0, '3100622023': 0, '3100622024': 0, '3100622026': 0, '3100622027': 0, '3100622033': 0, '3100622034': 0, '3100622036': 0, '3100622037': 0, '3100622038': 0, '3100622040': 0, '3100622041': 0, '3100622042': 0, '3100622043': 0, '3100622044': 0, '3100622045': 0, '3100622047': 0, '3100622048': 0, '3100622049': 0, '3100622051': 0, '3100622053': 0, '3100622054': 0, '3100622057': 0, '3100631001': 0, '3100631002': 0, '3100631003': 0, '3100631004': 0, '3100631005': 0, '3100631006': 0, '3100631008': 0, '3100631009': 0, '3100631010': 0, '3100631011': 0, '3100631013': 0, '3100631014': 0, '3100631015': 0, '3100631016': 0, '3100631018': 0, '3100631019': 0, '3100631022': 0, '3100631023': 0, '3100631025': 0, '3100631026': 0, '3100631027': 0, '3100631029': 0, '3100631032': 0, '3100631035': 0, '3100631037': 0, '3100631042': 0, '3100631043': 0, '3100631044': 0, '3100631045': 0, '3100631046': 0, '3100631047': 0, '3100631048': 0, '3100631049': 0, '3100631051': 0, '3100631052': 0, '3100631053': 0, '3100631054': 0, '3100631055': 0, '3100631056': 0, '3100631057': 0, '3100631058': 0, '3100631059': 0, '3100631062': 0, '3100632001': 0, '3100632002': 0, '3100632003': 0, '3100632004': 0, '3100632007': 0, '3100632008': 0, '3100632011': 0, '3100632012': 0, '3100632015': 0, '3100632016': 0, '3100632017': 0, '3100632018': 0, '3100632019': 0, '3100632021': 0, '3100632023': 0, '3100632024': 0, '3100632025': 0, '3100632026': 0, '3100632027': 0, '3100632030': 0, '3100632031': 0, '3100632039': 0, '3100632041': 0, '3100632042': 0, '3100632043': 0, '3100632044': 0, '3100632045': 0, '3100641002': 0, '3100641003': 1, '3100641004': 1, '3100641006': 1, '3100641007': 0, '3100641008': 0, '3100641023': 1, '3100642002': 0, '3100642003': 0, '3100642005': 0, '3100642006': 0, '3100642007': 1, '3100642008': 0, '3100642009': 0, '3100642011': 0, '3100642012': 0, '3100642013': 0, '3100642015': 0, '3100642017': 1, '3100642019': 0, '3100642020': 0, '3100642021': 0, '3100642022': 0, '3100642024': 0, '3100642025': 0, '3100642026': 0, '3100642027': 0, '3100642028': 0, '3100642030': 0, '3100642031': 0, '3100642032': 0, '3100642033': 0, '3100642034': 0, '3100642035': 0, '3100642036': 1, '3100642037': 0, '3100642038': 0, '3100642040': 0, '3100642045': 0, '3100642047': 0, '3100642052': 0, '3100642054': 0, '3100642055': 1, '3100642056': 0, '3100642057': 0, '3100642058': 0, '3100642060': 0, '3100642061': 0, '3100642063': 0, '3100642064': 0, '3100642066': 0, '3100642069': 0, '3100642070': 0, '3100661002': 0, '3100661007': 0, '3100661009': 0, '3100661015': 0, '3100661016': 0, '3100661022': 0, '3100661023': 0, '3100661024': 0, '3100661025': 0, '3100661027': 0, '3100661028': 0, '3100661029': 0, '3100661031': 0, '3100661032': 0, '3100661033': 0, '3100661036': 0, '3100661037': 0, '3100661038': 0, '3100661040': 0, '3100661043': 0, '3100661044': 0, '3100661046': 0, '3100661049': 0, '3100661050': 0, '3100662014': 0, '3100662015': 0, '3100662016': 0, '3100662017': 0, '3100662020': 0, '3100662022': 0, '3100662023': 0, '3100662026': 0, '3100662029': 0, '3100662032': 0, '3100662035': 0, '3100662036': 0, '3100662037': 1, '3100662045': 0, '3100662046': 0, '3100662048': 0, '3100662049': 0, '3100662050': 0, '3100662052': 0, '3100662053': 0, '3100662055': 0, '3100681001': 0, '3100681002': 0, '3100681005': 0, '3100681006': 0, '3100681015': 1, '3100681017': 1, '3100681018': 1, '3100681042': 1, '3100681043': 0, '3100681044': 0, '3100681045': 0, '3100681046': 0, '3100682001': 0, '3100682002': 0, '3100682003': 0, '3100682007': 0, '3100682008': 0, '3100682030': 0, '3100682040': 0, '3100691005': 0, '3100691006': 0, '3100691007': 0, '3100691011': 0, '3100691012': 0, '3100691021': 0, '3100691026': 0, '3100691042': 0, '3100691045': 0, '3100691048': 0, '3100692002': 0, '3100692005': 0, '3100692006': 0, '3100692007': 0, '3100692009': 0, '3100692010': 0, '3100692011': 0, '3100692012': 0, '3100692013': 0, '3100692015': 1, '3100692016': 0, '3100692020': 0, '3100692022': 0, '3100692023': 0, '3100692024': 0, '3100692025': 0, '3100692028': 0, '3100692029': 0, '3100692032': 0, '3100692034': 0, '3100692035': 0, '3100692038': 0, '3100692039': 0, '3100692045': 0, '3100692052': 0, '3100692054': 0, '3100692055': 0, '3100692056': 0, '3100701001': 0, '3100701002': 0, '3100701004': 0, '3100701005': 0, '3100701008': 0, '3100701009': 0, '3100701010': 1, '3100701011': 0, '3100701012': 0, '3100701013': 0, '3100701014': 0, '3100701015': 0, '3100701016': 0, '3100701019': 0, '3100701021': 0, '3100701022': 0, '3100701023': 1, '3100701024': 0, '3100701029': 0, '3100701031': 0, '3100701032': 0, '3100701036': 0, '3100701043': 0, '3100701044': 0, '3100701050': 0, '3100701051': 0, '3100701056': 0, '3100701057': 0, '3100701058': 0, '3100701061': 0, '3100701063': 0, '3100701072': 0, '3100701073': 0, '3100702004': 0, '3100702005': 0, '3100702006': 0, '3100702010': 0, '3100702012': 0, '3100702013': 0, '3100702016': 0, '3100702017': 0, '3100702019': 0, '3100702020': 0, '3100702021': 0, '3100702022': 0, '3100702023': 0, '3100702024': 0, '3100702025': 0, '3100702026': 0, '3100702027': 0, '3100702028': 0, '3100702029': 0, '3100702030': 0, '3100702031': 0, '3100702033': 0, '3100702034': 0, '3100702035': 0, '3100702036': 0, '3100702037': 0, '3100702038': 1, '3100702039': 0, '3100702040': 0, '3100702041': 0, '3100702043': 0, '3100702044': 0, '3100702045': 0, '3100702046': 0, '3100702047': 0, '3100702048': 0, '3100702051': 0, '3100702052': 0, '3100702054': 0, '3100702055': 0, '3100702059': 0, '3100702060': 0, '3100702061': 0, '3100702062': 0, '3100702063': 0, '3100702064': 0, '3100702065': 0, '3100702066': 0, '3100702067': 0, '3100702068': 0, '3100711007': 0, '3100711009': 0, '3100711042': 0, '3100711043': 0, '3100711049': 0, '3100711050': 0, '3100711051': 0, '3100711052': 0, '3100712014': 0, '3100721002': 0, '3100721003': 0, '3100721004': 0, '3100721005': 0, '3100721006': 0, '3100721007': 0, '3100721008': 0, '3100721011': 0, '3100721012': 0, '3100721013': 0, '3100721014': 0, '3100721015': 0, '3100721016': 0, '3100721018': 0, '3100721019': 0, '3100721020': 0, '3100721021': 0, '3100721022': 0, '3100721023': 0, '3100721024': 0, '3100721028': 0, '3100721029': 0, '3100721030': 0, '3100721031': 1, '3100721032': 0, '3100721033': 0, '3100721034': 0, '3100721036': 0, '3100721038': 0, '3100721039': 0, '3100721040': 0, '3100721041': 0, '3100721042': 0, '3100721044': 0, '3100721045': 0, '3100721046': 0, '3100721047': 0, '3100721048': 0, '3100721049': 0, '3100721050': 0, '3100721051': 0, '3100721052': 0, '3100721053': 0, '3100721054': 0, '3100721055': 0, '3100721056': 0, '3100721057': 0, '3100721058': 0, '3100721059': 0, '3100721060': 0, '3100721062': 0, '3100721063': 0, '3100721064': 0, '3100721065': 0, '3100721066': 0, '3100721068': 0, '3100721070': 0, '3100721071': 0, '3100721072': 0, '3100722003': 0, '3100722004': 0, '3100722005': 0, '3100722006': 0, '3100722007': 0, '3100722012': 0, '3100722013': 0, '3100722014': 0, '3100722016': 0, '3100722017': 0, '3100722020': 0, '3100722021': 0, '3100722022': 0, '3100722023': 0, '3100722024': 0, '3100722025': 0, '3100722026': 0, '3100722027': 0, '3100722030': 0, '3100722031': 0, '3100722032': 0, '3100722033': 0, '3100722034': 0, '3100722036': 0, '3100722038': 0, '3100722039': 0, '3100722040': 0, '3100722042': 0, '3100722044': 0, '3100722045': 0, '3100722046': 0, '3100722047': 0, '3100722048': 0, '3100722054': 0, '3100722055': 0, '3100722057': 0, '3100722059': 0, '3100722061': 0, '3100722062': 0, '3100722063': 0, '3100722064': 0, '3100722065': 0, '3100722066': 0, '3100722067': 0, '3100722068': 0, '3100722069': 0, '3100722070': 0, '3100722072': 0, '3100722073': 0, '3100722074': 0, '3100722076': 0, '3100722077': 0, '3100722078': 0, '3100722079': 0, '3100731001': 0, '3100731006': 0, '3100731007': 0, '3100731008': 0, '3100731009': 0, '3100731011': 0, '3100731012': 0, '3100731013': 0, '3100731014': 0, '3100731025': 0, '3100731026': 0, '3100731028': 0, '3100731029': 0, '3100731030': 0, '3100731031': 0, '3100731037': 0, '3100731038': 0, '3100731050': 0, '3100731052': 0, '3100731054': 0, '3100731056': 0, '3100731057': 0, '3100731058': 0, '3100732001': 0, '3100732002': 0, '3100732003': 0, '3100732006': 0, '3100732013': 0, '3100732014': 0, '3100732015': 0, '3100732017': 0, '3100732018': 0, '3100732020': 0, '3100732021': 0, '3100732022': 0, '3100732023': 0, '3100732025': 0, '3100732027': 0, '3100732028': 0, '3100732029': 0, '3100732031': 0, '3100732036': 0, '3100732040': 0, '3100732041': 0, '3100732042': 0, '3100732067': 0, '3100741001': 0, '3100741002': 0, '3100741003': 0, '3100741004': 0, '3100741011': 0, '3100741012': 0, '3100741013': 0, '3100741014': 0, '3100741016': 0, '3100741017': 0, '3100741018': 0, '3100741019': 0, '3100741020': 0, '3100741022': 0, '3100741023': 0, '3100741024': 0, '3100741025': 0, '3100741026': 0, '3100741027': 0, '3100741028': 0, '3100741029': 0, '3100741030': 0, '3100741032': 0, '3100741034': 0, '3100741035': 0, '3100741036': 0, '3100741037': 0, '3100741038': 0, '3100741039': 0, '3100741042': 0, '3100741043': 0, '3100741044': 0, '3100741045': 0, '3100741047': 0, '3100741049': 0, '3100741053': 0, '3100741054': 0, '3100741056': 0, '3100741057': 0, '3100741058': 0, '3100741059': 0, '3100741060': 0, '3100741061': 0, '3100741063': 0, '3100741064': 0, '3100741065': 0, '3100741066': 1, '3100741068': 0, '3100741069': 0, '3100741070': 0, '3100741071': 0, '3100741072': 0, '3100741073': 0, '3100741074': 0, '3100741075': 0, '3100741076': 0, '3100741077': 0, '3100741079': 0, '3100742001': 0, '3100742003': 0, '3100742004': 0, '3100742005': 0, '3100742007': 0, '3100742010': 0, '3100742011': 0, '3100742012': 0, '3100742013': 0, '3100742014': 0, '3100742015': 0, '3100742016': 0, '3100742018': 0, '3100742020': 0, '3100742021': 0, '3100742022': 0, '3100742023': 0, '3100742024': 0, '3100742025': 0, '3100742027': 0, '3100742028': 0, '3100742033': 0, '3100742034': 0, '3100742037': 0, '3100742038': 0, '3100742041': 0, '3100742042': 0, '3100742044': 0, '3100742045': 0, '3100742046': 0, '3100742047': 0, '3100742048': 0, '3100742050': 0, '3100742051': 0, '3100742052': 0, '3100742053': 0, '3100742054': 0, '3100742055': 0, '3100742056': 0, '3100742057': 0, '3100742058': 1, '3100742059': 0, '3100742060': 0, '3100742061': 0, '3100742062': 0, '3100742063': 0, '3100742065': 0, '3100742067': 0, '3100742068': 0, '3100751003': 0, '3100751004': 0, '3100751005': 0, '3100751006': 1, '3100751007': 1, '3100751008': 1, '3100751009': 0, '3100751010': 1, '3100751011': 0, '3100751012': 1, '3100751014': 0, '3100751015': 0, '3100751016': 0, '3100751017': 0, '3100751018': 0, '3100751019': 1, '3100751020': 0, '3100751021': 0, '3100751022': 0, '3100751024': 0, '3100751026': 0, '3100751027': 0, '3100751028': 0, '3100751032': 0, '3100751033': 0, '3100751034': 0, '3100751035': 0, '3100751037': 0, '3100751039': 0, '3100751040': 0, '3100751041': 0, '3100751043': 0, '3100751044': 0, '3100751045': 0, '3100751048': 0, '3100751050': 0, '3100751055': 0, '3100751056': 1, '3100751057': 1, '3100751058': 0, '3100751059': 0, '3100751063': 0, '3100751064': 0, '3100751065': 0, '3100751068': 0, '3100751069': 0, '3100751070': 0, '3100751072': 0, '3100751073': 0, '3100751074': 0, '3100751075': 0, '3100751076': 0, '3100751077': 0, '3100751078': 0, '3100751079': 0, '3100752001': 0, '3100752002': 0, '3100752003': 0, '3100752004': 0, '3100752005': 0, '3100752007': 0, '3100752008': 0, '3100752009': 0, '3100752010': 0, '3100752012': 0, '3100752014': 1, '3100752015': 0, '3100752016': 0, '3100752017': 0, '3100752018': 0, '3100752019': 0, '3100752020': 0, '3100752021': 1, '3100752022': 0, '3100752023': 0, '3100752026': 0, '3100752027': 0, '3100752029': 0, '3100752030': 1, '3100752032': 0, '3100752034': 0, '3100752035': 0, '3100752036': 0, '3100752037': 1, '3100752038': 0, '3100752039': 0, '3100752040': 0, '3100752041': 0, '3100752042': 0, '3100752043': 0, '3100752044': 0, '3100752045': 0, '3100752046': 0, '3100752047': 0, '3100752048': 1, '3100752049': 0, '3100752050': 0, '3100752051': 1, '3100752052': 0, '3100752054': 0, '3100752055': 1, '3100752056': 0, '3100752057': 0, '3100752058': 0, '3100752059': 0, '3100752060': 0, '3100752061': 0, '3100752063': 0, '3100752068': 0, '3100761003': 1, '3100761004': 0, '3100761005': 1, '3100761007': 0, '3100761008': 1, '3100761013': 0, '3100761014': 0, '3100761015': 0, '3100761016': 0, '3100761017': 0, '3100761019': 0, '3100761020': 0, '3100761021': 0, '3100761023': 0, '3100761027': 0, '3100761028': 0, '3100761029': 0, '3100761030': 0, '3100761031': 0, '3100761034': 0, '3100761042': 0, '3100761046': 0, '3100761047': 0, '3100761048': 0, '3100761049': 0, '3100761050': 0, '3100761051': 0, '3100761056': 0, '3100761062': 0, '3100761063': 0, '3100762003': 0, '3100762004': 1, '3100762005': 0, '3100762007': 0, '3100762012': 0, '3100762013': 0, '3100762016': 0, '3100762027': 1, '3100762029': 0, '3100762030': 1, '3100762052': 0, '3100762053': 0, '3100762055': 1, '3100771001': 1, '3100771002': 0, '3100771003': 0, '3100771005': 0, '3100771007': 1, '3100771008': 0, '3100771009': 0, '3100771012': 0, '3100771014': 0, '3100771016': 0, '3100771018': 0, '3100771019': 0, '3100771020': 0, '3100771021': 0, '3100771022': 0, '3100771024': 0, '3100771027': 0, '3100771028': 0, '3100771029': 0, '3100771030': 0, '3100771031': 0, '3100771032': 0, '3100771033': 0, '3100771034': 0, '3100771036': 0, '3100771037': 0, '3100771039': 0, '3100771040': 0, '3100771041': 0, '3100771042': 0, '3100771043': 0, '3100771046': 0, '3100771047': 0, '3100771048': 0, '3100771049': 0, '3100771050': 0, '3100771052': 0, '3100771054': 0, '3100771055': 0, '3100771056': 0, '3100771057': 0, '3100771058': 0, '3100771059': 0, '3100771062': 0, '3100771063': 0, '3100771064': 0, '3100771065': 0, '3100771066': 0, '3100771067': 0, '3100771068': 0, '3100771069': 0, '3100771071': 0, '3100771072': 0, '3100771073': 0, '3100771075': 0, '3100771076': 0, '3100771077': 0, '3100771078': 0, '3100771080': 0, '3100771081': 0, '3100772002': 0, '3100772004': 0, '3100772005': 0, '3100772006': 0, '3100772007': 0, '3100772008': 0, '3100772009': 0, '3100772010': 0, '3100772011': 0, '3100772013': 0, '3100772014': 0, '3100772015': 0, '3100772018': 0, '3100772019': 0, '3100772020': 0, '3100772021': 0, '3100772022': 0, '3100772023': 0, '3100772024': 0, '3100772025': 0, '3100772026': 0, '3100772027': 0, '3100772028': 0, '3100772029': 0, '3100772031': 0, '3100772032': 0, '3100772033': 0, '3100772034': 0, '3100772035': 0, '3100772036': 0, '3100772037': 0, '3100772039': 0, '3100772040': 0, '3100772041': 0, '3100772042': 0, '3100772043': 0, '3100772045': 0, '3100772046': 0, '3100772048': 0, '3100772050': 0, '3100772051': 1, '3100772052': 0, '3100772053': 0, '3100772054': 0, '3100772055': 0, '3100772056': 0, '3100772058': 0, '3100772059': 0, '3100772063': 0, '3100772065': 0, '3100772066': 0, '3100772067': 0, '3100772068': 0, '3100772069': 0, '3100781001': 0, '3100781002': 1, '3100781004': 0, '3100781006': 0, '3100781007': 1, '3100781008': 0, '3100781009': 0, '3100781010': 0, '3100781011': 0, '3100781013': 0, '3100781015': 0, '3100781016': 0, '3100781017': 0, '3100781019': 0, '3100781020': 0, '3100781021': 0, '3100781023': 0, '3100781024': 0, '3100781027': 0, '3100781029': 0, '3100781030': 0, '3100781031': 0, '3100781032': 0, '3100781033': 0, '3100781034': 1, '3100781036': 0, '3100781038': 0, '3100781040': 0, '3100781041': 0, '3100781043': 0, '3100781044': 0, '3100781046': 0, '3100781047': 0, '3100781048': 0, '3100781051': 0, '3100781052': 0, '3100781053': 0, '3100781054': 0, '3100781055': 0, '3100781056': 0, '3100781057': 0, '3100781058': 0, '3100781059': 0, '3100781061': 0, '3100781062': 0, '3100781064': 0, '3100781065': 0, '3100781066': 0, '3100781068': 0, '3100781069': 0, '3100781070': 0, '3100781071': 0, '3100781073': 0, '3100781074': 0, '3100781075': 0, '3100781076': 0, '3100781078': 0, '3100781079': 0, '3100781080': 0, '3100781081': 0, '3100782001': 0, '3100782003': 0, '3100782004': 0, '3100782005': 0, '3100782006': 0, '3100782008': 0, '3100782010': 0, '3100782011': 0, '3100782012': 0, '3100782013': 0, '3100782014': 0, '3100782015': 0, '3100782016': 0, '3100782017': 0, '3100782018': 0, '3100782019': 0, '3100782021': 0, '3100782022': 0, '3100782023': 0, '3100782024': 0, '3100782025': 0, '3100782026': 0, '3100782027': 0, '3100782028': 0, '3100782031': 0, '3100782032': 0, '3100782033': 0, '3100782035': 0, '3100782036': 0, '3100782037': 0, '3100782038': 0, '3100782039': 0, '3100782042': 0, '3100782043': 0, '3100782045': 0, '3100782046': 0, '3100782047': 0, '3100782049': 0, '3100782050': 0, '3100782053': 0, '3100782054': 0, '3100782055': 0, '3100782057': 0, '3100782058': 0, '3100782059': 0, '3100782061': 0, '3100782062': 0, '3100782063': 0, '3100782064': 0, '3100782065': 0, '3100782066': 0, '3100782067': 1, '3100782068': 0, '3100782069': 0, '3100782071': 0, '3100782072': 0, '3100791004': 0, '3100791006': 0, '3100791007': 0, '3100791008': 0, '3100791016': 0, '3100791018': 0, '3100791020': 0, '3100791021': 0, '3100791026': 0, '3100791028': 0, '3100791031': 0, '3100791033': 0, '3100791034': 0, '3100791035': 0, '3100791042': 0, '3100791044': 0, '3100791045': 0, '3100791046': 0, '3100791047': 0, '3100791049': 0, '3100791050': 0, '3100791052': 0, '3100791054': 0, '3100791056': 0, '3100791058': 1, '3100791059': 0, '3100791060': 0, '3100791061': 0, '3100791062': 0, '3100791063': 0, '3100791064': 0, '3100791065': 0, '3100791066': 0, '3100791067': 0, '3100791069': 0, '3100791070': 0, '3100791071': 0, '3100791072': 0, '3100791073': 0, '3100792002': 0, '3100792003': 0, '3100792004': 0, '3100792005': 0, '3100792006': 0, '3100792007': 0, '3100792008': 0, '3100792009': 0, '3100792010': 0, '3100792011': 0, '3100792013': 0, '3100792014': 0, '3100792015': 0, '3100792016': 0, '3100792019': 0, '3100792020': 0, '3100792021': 0, '3100792022': 0, '3100792023': 0, '3100792024': 0, '3100792025': 0, '3100792027': 0, '3100792028': 0, '3100792030': 0, '3100792031': 0, '3100792032': 0, '3100792033': 0, '3100792035': 0, '3100792036': 0, '3100792037': 0, '3100792038': 0, '3100792039': 0, '3100792040': 0, '3100792041': 0, '3100792042': 0, '3100792043': 0, '3100792044': 0, '3100792045': 1, '3100792046': 0, '3100792048': 0, '3100792050': 0, '3100792051': 0, '3100792052': 0, '3100792053': 0, '3100792057': 0, '3100792058': 0, '3100792060': 0, '3100792069': 0, '3100801006': 0, '3100802001': 0, '3100802028': 0, '3100811002': 0, '3100811018': 0, '3100811027': 0, '3100811034': 0, '3100811035': 0, '3100811036': 0, '3100811037': 0, '3100811038': 0, '3100811039': 0, '3100811040': 0, '3100811041': 0, '3100811042': 0, '3100811043': 0, '3100811045': 0, '3100811046': 0, '3100811047': 0, '3100811050': 0, '3100811051': 0, '3100811053': 0, '3100811054': 0, '3100811055': 0, '3100811056': 0, '3100811059': 0, '3100811060': 0, '3100811061': 0, '3100811063': 0, '3100811068': 0, '3100811075': 0, '3100812003': 0, '3100812004': 0, '3100812005': 0, '3100812006': 0, '3100812007': 0, '3100812008': 0, '3100812013': 0, '3100812014': 0, '3100812016': 0, '3100812017': 0, '3100812018': 0, '3100812019': 0, '3100812020': 0, '3100812021': 0, '3100812026': 0, '3100812027': 0, '3100812028': 1, '3100812040': 0, '3100821004': 0, '3100821015': 0, '3100821016': 0, '3100821019': 0, '3100821020': 0, '3100821021': 0, '3100821022': 1, '3100821030': 0, '3100821031': 0, '3100821032': 1, '3100821033': 1, '3100821034': 0, '3100821035': 0, '3100821036': 0, '3100821037': 0, '3100821038': 1, '3100821039': 0, '3100821040': 0, '3100821041': 0, '3100821042': 0, '3100821045': 0, '3100821046': 0, '3100821047': 0, '3100821048': 1, '3100821049': 0, '3100821051': 0, '3100821052': 1, '3100821054': 0, '3100821055': 0, '3100821057': 1, '3100821067': 0, '3100821068': 0, '3100821069': 1, '3100821075': 1, '3100822001': 0, '3100822011': 1, '3100822012': 0, '3100822014': 0, '3100822030': 0, '3100822031': 1, '3100822044': 0, '3100822050': 0, '3100822051': 0, '3100822057': 0, '3100822058': 0, '3100822059': 0, '3100822064': 0, '3100822065': 1, '3100822066': 1, '3100822067': 0, '3100822068': 0, '3100822069': 0, '3100822070': 0, '3100822075': 0, '3100822080': 0, '3100831003': 0, '3100831004': 0, '3100831006': 0, '3100831007': 0, '3100831008': 0, '3100831010': 0, '3100831011': 0, '3100831013': 0, '3100831014': 0, '3100831015': 0, '3100831016': 0, '3100831018': 0, '3100831019': 0, '3100831020': 0, '3100831022': 0, '3100831024': 0, '3100831026': 0, '3100831027': 0, '3100831028': 0, '3100831029': 0, '3100831032': 0, '3100831033': 0, '3100831035': 0, '3100831036': 0, '3100831037': 0, '3100831044': 0, '3100831045': 0, '3100831046': 0, '3100831047': 0, '3344630110': 0, '33446301100': 0, '33446301101': 0, '33446301103': 0, '33446301104': 0, '33446301107': 0, '3344630112': 0, '3344630113': 0, '3344630115': 0, '3344630116': 0, '3344630117': 0, '3344630119': 0, '334463012': 0, '3344630120': 0, '3344630121': 1, '3344630127': 0, '3344630130': 0, '3344630131': 1, '3344630132': 0, '3344630133': 0, '3344630136': 0, '3344630139': 0, '334463014': 0, '3344630140': 0, '3344630141': 0, '3344630142': 0, '3344630143': 0, '3344630146': 0, '3344630147': 0, '3344630148': 0, '3344630149': 0, '3344630150': 0, '3344630151': 0, '3344630153': 0, '3344630156': 0, '3344630161': 0, '3344630162': 1, '3344630163': 0, '3344630164': 0, '3344630166': 0, '3344630170': 0, '3344630171': 0, '3344630172': 0, '3344630173': 0, '3344630176': 0, '3344630179': 0, '3344630180': 0, '3344630181': 0, '3344630182': 0, '3344630184': 0, '3344630185': 0, '3344630186': 0, '3344630188': 0, '3344630189': 0, '334463019': 0, '3344630190': 0, '3344630196': 0, '3344630197': 0, '3344630198': 0, '3344630199': 0, '334463021': 0, '3344630210': 0, '3344630211': 1, '3344630213': 0, '3344630215': 0, '3344630216': 0, '3344630219': 0, '334463022': 0, '3344630220': 0, '3344630221': 0, '3344630224': 0, '3344630225': 0, '3344630226': 0, '3344630231': 0, '3344630232': 0, '3344630233': 0, '3344630236': 0, '3344630238': 0, '3344630240': 0, '3344630241': 0, '3344630242': 0, '3344630243': 0, '3344630245': 0, '3344630247': 0, '3344630248': 0, '334463025': 0, '3344630251': 0, '3344630252': 0, '3344630255': 0, '3344630257': 0, '334463026': 0, '3344630260': 0, '3344630262': 0, '3344630264': 0, '3344630265': 0, '3344630266': 0, '3344630267': 0, '334463027': 0, '3344630270': 0, '3344630271': 0, '3344630273': 0, '3344630276': 0, '3344630278': 0, '334463028': 0, '3344630280': 0, '3344630281': 0, '3344630282': 1, '334463029': 0, '33702101100': 0, '33702101110': 0, '33702101130': 0, '33702101140': 0, '33702101150': 0, '33702101180': 0, '33702101200': 0, '33702101210': 0, '33702101250': 0, '33702101260': 0, '33702101270': 0, '33702101280': 0, '33702101290': 0, '33702101300': 0, '33702101340': 0, '33702101350': 0, '33702101360': 0, '33702101370': 0, '33702101410': 0, '33702101430': 0, '33702101450': 0, '33702101460': 0, '33702101470': 0, '33702101480': 0, '33702101490': 0, '3370210150': 0, '33702101500': 0, '33702101530': 0, '33702101540': 0, '33702101550': 0, '33702101580': 0, '33702101590': 0, '33702101600': 0, '33702101620': 0, '33702101630': 0, '33702101640': 0, '33702101650': 0, '33702101660': 0, '33702101700': 0, '33702101710': 0, '33702101730': 0, '33702101740': 0, '33702101750': 0, '33702101760': 0, '3370210180': 0, '33702102100': 0, '33702102110': 0, '33702102130': 0, '33702102140': 0, '33702102160': 0, '33702102170': 0, '33702102180': 0, '33702102190': 0, '33702102200': 0, '33702102220': 0, '33702102230': 0, '33702102240': 0, '33702102250': 0, '33702102280': 0, '3370210230': 0, '33702102300': 0, '33702102310': 0, '33702102330': 0, '33702102350': 0, '33702102390': 0, '3370210240': 0, '33702102400': 0, '33702102420': 0, '33702102430': 0, '33702102470': 0, '33702102500': 0, '33702102530': 0, '33702102540': 0, '33702102550': 0, '33702102570': 0, '33702102580': 0, '33702102590': 0, '3370210260': 0, '33702102600': 0, '33702102640': 0, '33702102670': 0, '33702102690': 0, '33702102710': 0, '33702102740': 0, '3370210280': 0, '33702102820': 0, '33702102840': 0, '33702102850': 0, '33702102870': 0, '33702102880': 0, '342227010': 0, '342227011': 0, '3422270111': 1, '3422270112': 0, '3422270115': 0, '3422270116': 0, '3422270117': 0, '3422270118': 0, '3422270121': 0, '3422270122': 0, '3422270123': 0, '3422270126': 0, '3422270127': 0, '3422270128': 0, '3422270129': 1, '342227013': 0, '3422270130': 0, '3422270131': 0, '3422270133': 0, '3422270134': 0, '3422270135': 0, '3422270138': 0, '3422270139': 0, '3422270140': 0, '3422270141': 0, '3422270142': 0, '3422270143': 0, '3422270144': 0, '3422270149': 0, '3422270151': 0, '3422270152': 0, '3422270153': 0, '3422270154': 0, '3422270155': 0, '3422270157': 0, '3422270158': 0, '3422270160': 0, '3422270165': 0, '3422270166': 0, '3422270167': 1, '3422270168': 0, '3422270169': 0, '3422270171': 0, '3422270172': 0, '342227020': 0, '342227021': 0, '3422270210': 0, '3422270211': 0, '3422270212': 0, '3422270213': 0, '3422270215': 0, '3422270216': 0, '3422270217': 0, '3422270219': 0, '3422270220': 0, '3422270221': 0, '3422270222': 0, '3422270223': 0, '3422270224': 0, '3422270225': 0, '3422270227': 0, '342227023': 0, '3422270230': 0, '3422270238': 0, '3422270239': 0, '342227024': 0, '3422270240': 0, '3422270241': 0, '3422270242': 0, '3422270244': 0, '3422270245': 0, '3422270246': 0, '3422270247': 0, '3422270249': 0, '342227025': 0, '3422270250': 0, '3422270251': 0, '3422270252': 0, '3422270253': 0, '3422270254': 0, '3422270255': 0, '3422270256': 0, '3422270257': 0, '3422270261': 0, '3422270262': 0, '3422270263': 0, '3422270264': 0, '3422270267': 0, '3422270268': 0, '3422270269': 0, '342227027': 0, '3422270274': 0, '3422270278': 0, '3422270279': 0, '3422270280': 0, '3422270281': 0, '342227029': 0, '350361011': 0, '3503610110': 0, '3503610111': 0, '3503610112': 0, '3503610113': 0, '3503610114': 0, '3503610115': 0, '3503610116': 0, '3503610117': 0, '3503610118': 0, '3503610119': 0, '350361012': 0, '3503610120': 0, '3503610121': 0, '3503610122': 0, '3503610123': 0, '3503610124': 0, '3503610125': 0, '3503610126': 0, '3503610127': 0, '3503610128': 0, '3503610129': 0, '350361013': 0, '3503610130': 0, '3503610131': 0, '3503610132': 0, '3503610133': 0, '3503610134': 0, '3503610135': 0, '3503610136': 0, '3503610137': 0, '3503610138': 0, '3503610139': 0, '350361014': 0, '3503610140': 0, '3503610141': 0, '3503610142': 0, '3503610143': 0, '3503610144': 0, '3503610145': 0, '3503610146': 0, '3503610147': 0, '3503610148': 0, '3503610149': 0, '350361015': 0, '3503610150': 0, '3503610151': 0, '3503610152': 0, '3503610154': 0, '3503610156': 0, '3503610157': 0, '3503610158': 1, '350361016': 0, '3503610163': 0, '3503610168': 1, '350361017': 0, '350361019': 0, '350361021': 0, '3503610210': 0, '3503610212': 0, '3503610213': 0, '3503610214': 0, '3503610217': 0, '350361022': 0, '3503610223': 0, '3503610224': 0, '3503610225': 0, '3503610226': 0, '3503610227': 0, '3503610228': 0, '350361023': 0, '3503610230': 0, '3503610231': 0, '3503610233': 0, '3503610234': 0, '3503610235': 0, '3503610236': 0, '3503610237': 0, '3503610238': 0, '350361024': 0, '3503610240': 0, '3503610241': 0, '3503610242': 0, '3503610245': 0, '3503610246': 0, '3503610248': 0, '3503610250': 0, '3503610251': 0, '3503610252': 0, '3503610253': 0, '3503610254': 0, '3503610255': 0, '3503610256': 0, '3503610257': 0, '350361026': 0, '3503610260': 0, '3503610261': 0, '3503610264': 0, '3503610265': 0, '3503610266': 0, '3503610267': 0, '3503610268': 0, '3503610269': 0, '3503610270': 0, '3503610272': 0, '3503610273': 0, '3503610275': 0, '3503610276': 0, '3503610277': 0, '3503610278': 0, '3503610279': 0, '350361028': 1, '350361029': 0, '4000181002': 0, '4000181004': 1, '4000181005': 0, '4000181006': 0, '4000181007': 0, '4000181008': 0, '4000181010': 0, '4000181011': 0, '4000181012': 0, '4000181013': 0, '4000181014': 0, '4000181015': 1, '4000181016': 0, '4000181017': 0, '4000181019': 0, '4000181020': 0, '4000181022': 0, '4000181023': 0, '4000181024': 0, '4000181026': 0, '4000181027': 0, '4000181028': 0, '4000181029': 0, '4000181030': 0, '4000181031': 0, '4000181032': 0, '4000181033': 0, '4000181035': 0, '4000181036': 0, '4000181037': 0, '4000181039': 0, '4000181041': 0, '4000181042': 0, '4000181043': 0, '4000181044': 0, '4000181045': 0, '4000181046': 0, '4000181047': 0, '4000181048': 0, '4000181049': 0, '4000181053': 0, '4000181054': 0, '4000181055': 0, '4000181056': 0, '4000181057': 0, '4000181060': 0, '4000181061': 0, '4000181062': 0, '4000181063': 0, '4000181064': 0, '4000181065': 0, '4000181066': 0, '4000181067': 0, '4000181068': 0, '4000181069': 0, '4000181070': 0, '4000181072': 0, '4000181073': 0, '4000181074': 0, '4000181075': 0, '4000181076': 0, '4000181077': 0, '4000181078': 0, '4000181079': 0, '4000181080': 0, '4000182003': 0, '4000182004': 0, '4000182005': 0, '4000182006': 0, '4000182007': 0, '4000182008': 0, '4000182009': 0, '4000182010': 0, '4000182011': 0, '4000182013': 0, '4000182014': 0, '4000182015': 0, '4000182016': 0, '4000182017': 0, '4000182018': 0, '4000182020': 0, '4000182022': 0, '4000182024': 0, '4000182025': 0, '4000182026': 0, '4000182027': 0, '4000182028': 0, '4000182029': 0, '4000182030': 0, '4000182031': 0, '4000182032': 0, '4000182033': 0, '4000182035': 1, '4000182036': 0, '4000182037': 0, '4000182038': 0, '4000182039': 0, '4000182040': 0, '4000182041': 0, '4000182042': 0, '4000182044': 0, '4000182046': 0, '4000182047': 0, '4000182049': 0, '4000182050': 0, '4000182051': 0, '4000182053': 0, '4000182054': 0, '4000182055': 0, '4000182058': 0, '4000182059': 0, '4000182060': 0, '4000182062': 0, '4000182063': 0, '4000182064': 0, '4000182067': 0, '4000182068': 0, '4000182069': 0, '4000221001': 0, '4000221002': 0, '4000221006': 0, '4000221008': 0, '4000221009': 0, '4000221010': 0, '4000221011': 0, '4000221013': 0, '4000221014': 0, '4000221015': 0, '4000221016': 0, '4000221017': 0, '4000221018': 0, '4000221024': 0, '4000221033': 0, '4000221034': 0, '4000221035': 0, '4000221036': 0, '4000221040': 1, '4000221041': 0, '4000221042': 0, '4000221054': 0, '4000221055': 0, '4000221061': 0, '4000221062': 0, '4000221064': 0, '4000221065': 0, '4000221066': 0, '4000221067': 0, '4000221071': 0, '4000221072': 0, '4000222001': 0, '4000222003': 0, '4000222004': 0, '4000222007': 0, '4000222012': 0, '4000222013': 0, '4000222014': 0, '4000222015': 0, '4000222017': 0, '4000222031': 1, '4000222032': 1, '4000222035': 0, '4000222036': 1, '4000222038': 0, '4000222039': 0, '4000222040': 0, '4000222041': 1, '4000222042': 0, '4000222044': 0, '4000222045': 0, '4000222046': 0, '4000222051': 0, '4000222052': 0, '4000222054': 0, '4000222056': 0, '4000222057': 0, '4000222068': 0, '4000222069': 0, '4000222070': 0, '4000231001': 0, '4000231008': 0, '4000231010': 0, '4000231011': 0, '4000231012': 0, '4000231013': 0, '4000231014': 0, '4000231021': 0, '4000231032': 0, '4000231033': 0, '4000231034': 0, '4000231037': 0, '4000231038': 0, '4000231047': 0, '4000231049': 0, '4000231052': 0, '4000231060': 0, '4000231061': 0, '4000231063': 0, '4000231065': 0, '4000231070': 0, '4000231071': 0, '4000231073': 0, '4000231074': 0, '4000231081': 0, '4000232001': 0, '4000232004': 0, '4000232005': 0, '4000232006': 0, '4000232007': 0, '4000232010': 0, '4000232016': 0, '4000232017': 0, '4000232018': 0, '4000232022': 0, '4000232024': 0, '4000232027': 0, '4000232034': 0, '4000232035': 0, '4000232036': 0, '4000232037': 0, '4000232038': 0, '4000232042': 0, '4000232044': 0, '4000232045': 0, '4000232048': 0, '4000232051': 0, '4000232054': 0, '4000232059': 0, '4000232062': 0, '4000232065': 0, '4000232068': 0, '4000232071': 1, '4000232072': 0, '4000301002': 0, '4000301003': 0, '4000301005': 1, '4000301006': 1, '4000301007': 0, '4000301008': 0, '4000301010': 1, '4000301011': 1, '4000301012': 0, '4000301013': 0, '4000301014': 0, '4000301015': 0, '4000301016': 0, '4000301018': 0, '4000301019': 0, '4000301020': 0, '4000301021': 1, '4000301022': 0, '4000301023': 0, '4000301025': 0, '4000301026': 0, '4000301027': 0, '4000301028': 1, '4000301030': 1, '4000301031': 0, '4000301032': 0, '4000301034': 0, '4000301038': 0, '4000301039': 0, '4000301040': 0, '4000301041': 0, '4000301042': 1, '4000301043': 0, '4000301044': 0, '4000301045': 0, '4000301047': 0, '4000301049': 1, '4000301052': 0, '4000301053': 0, '4000301054': 0, '4000301055': 1, '4000301056': 0, '4000301057': 0, '4000301058': 0, '4000301059': 0, '4000301060': 1, '4000301061': 0, '4000301062': 0, '4000301063': 0, '4000301064': 0, '4000301065': 1, '4000301066': 1, '4000301067': 1, '4000301068': 0, '4000301069': 0, '4000301070': 1, '4000301071': 0, '4000301072': 0, '4000301073': 0, '4000301074': 0, '4000301076': 0, '4000301079': 0, '4000331001': 0, '4000331002': 0, '4000331003': 0, '4000331004': 0, '4000331005': 0, '4000331006': 0, '4000331007': 0, '4000331008': 0, '4000331011': 0, '4000331012': 0, '4000331013': 0, '4000331015': 0, '4000331017': 0, '4000331019': 0, '4000331020': 0, '4000331021': 0, '4000331022': 0, '4000331023': 0, '4000331025': 0, '4000331027': 0, '4000331029': 0, '4000331030': 0, '4000331031': 0, '4000331032': 0, '4000331033': 0, '4000331035': 0, '4000331036': 0, '4000331037': 0, '4000331038': 0, '4000331039': 0, '4000331040': 0, '4000331041': 0, '4000331042': 0, '4000331043': 0, '4000331044': 0, '4000331045': 0, '4000331046': 0, '4000331051': 0, '4000331052': 0, '4000331053': 0, '4000331054': 0, '4000331055': 0, '4000331056': 0, '4000331057': 0, '4000331058': 0, '4000331060': 0, '4000331062': 0, '4000331063': 0, '4000331064': 0, '4000331067': 0, '4000331068': 0, '4000331069': 0, '4000332001': 0, '4000332002': 0, '4000332007': 0, '4000332008': 0, '4000332009': 0, '4000332010': 0, '4000332012': 0, '4000332013': 0, '4000332014': 0, '4000332015': 0, '4000332017': 0, '4000332019': 0, '4000332020': 0, '4000332021': 0, '4000332022': 0, '4000332023': 0, '4000332025': 0, '4000332027': 0, '4000332030': 0, '4000332031': 0, '4000332032': 0, '4000332034': 0, '4000332035': 0, '4000332036': 0, '4000332037': 0, '4000332038': 0, '4000332039': 0, '4000332041': 0, '4000332044': 0, '4000332045': 0, '4000332046': 0, '4000332048': 0, '4000332050': 0, '4000332051': 0, '4000332052': 0, '4000332057': 0, '4000332059': 0, '4000332060': 0, '4000332061': 0, '4000332062': 0, '4000332063': 0, '4000332064': 0, '4000332066': 0, '4000332067': 0, '4000332068': 0, '4000332071': 0, '4000332072': 0, '4000332073': 0, '4000332074': 0, '4000332075': 0, '4000332077': 0, '4000332078': 0, '4000332079': 0, '4000332080': 0, '4000332081': 0, '4000332082': 1, '401835011': 0, '4018350112': 0, '4018350115': 0, '4018350116': 0, '4018350118': 0, '4018350119': 0, '4018350120': 0, '4018350121': 0, '4018350122': 0, '4018350126': 0, '4018350127': 0, '401835013': 0, '4018350130': 0, '4018350132': 0, '4018350134': 0, '4018350136': 0, '4018350137': 0, '4018350138': 0, '4018350139': 0, '4018350140': 0, '4018350141': 0, '4018350143': 0, '4018350144': 0, '4018350145': 0, '4018350146': 0, '4018350147': 0, '4018350149': 0, '401835015': 1, '4018350150': 0, '4018350152': 0, '4018350156': 0, '4018350157': 0, '4018350159': 0, '4018350160': 0, '4018350161': 0, '4018350162': 0, '4018350163': 0, '4018350166': 0, '4018350167': 0, '401835017': 0, '401835018': 0, '401835021': 0, '4018350213': 0, '4018350215': 0, '4018350217': 0, '4018350219': 0, '4018350220': 0, '4018350221': 0, '4018350222': 0, '4018350223': 0, '4018350224': 0, '4018350225': 0, '4018350226': 0, '4018350227': 0, '4018350231': 0, '4018350232': 0, '4018350233': 0, '4018350234': 0, '4018350236': 0, '4018350239': 0, '401835024': 0, '4018350240': 0, '4018350241': 0, '4018350244': 0, '4018350247': 0, '4018350251': 0, '4018350254': 0, '4018350256': 0, '4018350257': 0, '4018350258': 0, '4018350259': 0, '4018350260': 0, '4018350261': 0, '4018350263': 0, '4018350268': 0, '4018350269': 0, '4018350274': 0, '4018350276': 0, '4018350277': 0, '4018350279': 0, '401835028': 0, '4018350281': 0, '4018350282': 1, '4100191001': 0, '4100191002': 0, '4100191003': 0, '4100191004': 0, '4100191006': 0, '4100191007': 0, '4100191008': 1, '4100191010': 0, '4100191012': 0, '4100191014': 0, '4100191016': 0, '4100191017': 0, '4100191018': 0, '4100191020': 0, '4100191021': 0, '4100191023': 0, '4100191024': 0, '4100191025': 0, '4100191026': 0, '4100191030': 0, '4100191031': 0, '4100191032': 0, '4100191033': 1, '4100191034': 0, '4100191035': 0, '4100191038': 0, '4100191039': 0, '4100191041': 1, '4100191042': 0, '4100191043': 0, '4100191045': 0, '4100191046': 0, '4100191052': 0, '4100191053': 0, '4100192001': 0, '4100192002': 0, '4100192003': 0, '4100192004': 0, '4100192005': 0, '4100192006': 0, '4100192007': 0, '4100192010': 1, '4100192011': 1, '4100192012': 0, '4100192013': 0, '4100192014': 0, '4100192015': 1, '4100192016': 1, '4100192019': 0, '4100192020': 0, '4100192022': 0, '4100192023': 0, '4100192024': 0, '4100192025': 0, '4100192026': 1, '4100192027': 0, '4100192028': 0, '4100192029': 1, '4100192031': 1, '4100192032': 0, '4100192033': 0, '4100192034': 0, '4100192036': 0, '4100192037': 0, '4100192038': 0, '4100192039': 0, '4100192040': 0, '4100192043': 0, '4100192044': 0, '4100192045': 0, '4100192046': 0, '4100192047': 0, '4100192048': 0, '4100192049': 1, '4100192050': 0, '4100192051': 0, '4100192052': 0, '4100192053': 1, '4100192054': 0, '4100192055': 0, '4100192056': 0, '4100192057': 0, '4100192058': 0, '4100192060': 1, '4100192061': 0, '4100192062': 0, '4100192063': 0, '4100192066': 0, '4100192068': 0, '4100201001': 0, '4100201003': 0, '4100201004': 0, '4100201005': 0, '4100201006': 0, '4100201007': 0, '4100201008': 0, '4100201009': 0, '4100201010': 0, '4100201011': 0, '4100201013': 0, '4100201014': 0, '4100201016': 0, '4100201017': 0, '4100201018': 0, '4100201020': 0, '4100201021': 0, '4100201022': 0, '4100201023': 0, '4100201024': 0, '4100201025': 0, '4100201026': 0, '4100201027': 0, '4100201030': 1, '4100201031': 0, '4100201032': 1, '4100201033': 0, '4100201034': 0, '4100201035': 0, '4100201039': 1, '4100201040': 0, '4100201041': 0, '4100201042': 0, '4100201043': 1, '4100201044': 0, '4100201045': 0, '4100201046': 0, '4100201048': 0, '4100201049': 0, '4100201051': 0, '4100201052': 0, '4100201053': 0, '4100201054': 0, '4100201055': 0, '4100201056': 0, '4100201058': 0, '4100201059': 0, '4100201060': 0, '4100201061': 1, '4100201062': 0, '4100201063': 0, '4100201064': 0, '4100201068': 0, '4100201069': 0, '4100201071': 0, '4100201072': 0, '4100201073': 0, '4100201074': 0, '4100201075': 0, '4100201076': 0, '4100201078': 0, '4100201079': 0, '4100201081': 0, '4100201082': 0, '4100202001': 0, '4100202004': 0, '4100202005': 0, '4100202006': 0, '4100202007': 0, '4100202008': 0, '4100202009': 0, '4100202010': 0, '4100202011': 0, '4100202012': 0, '4100202013': 0, '4100202014': 1, '4100202015': 0, '4100202016': 0, '4100202017': 0, '4100202018': 0, '4100202019': 0, '4100202021': 0, '4100202022': 0, '4100202023': 0, '4100202024': 0, '4100202025': 0, '4100202032': 0, '4100202037': 0, '4100202039': 0, '4100202040': 0, '4100202041': 0, '4100202042': 0, '4100202043': 0, '4100202045': 0, '4100202046': 1, '4100202048': 0, '4100202052': 0, '4100202053': 0, '4100202054': 0, '4100202055': 0, '4100202056': 0, '4100202063': 0, '4100202065': 1, '4100202067': 0, '4100202068': 0, '4100241001': 0, '4100241002': 0, '4100241003': 0, '4100241004': 0, '4100241006': 0, '4100241007': 0, '4100241008': 0, '4100241009': 0, '4100241011': 0, '4100241013': 0, '4100241016': 0, '4100241017': 0, '4100241018': 0, '4100241020': 0, '4100241029': 1, '4100241030': 0, '4100241031': 0, '4100241042': 0, '4100241045': 0, '4100241046': 0, '4100241049': 0, '4100241051': 0, '4100241052': 0, '4100241053': 0, '4100241054': 0, '4100241055': 1, '4100241056': 0, '4100241059': 1, '4100241060': 0, '4100241061': 0, '4100241062': 0, '4100241063': 0, '4100241064': 0, '4100241068': 1, '4100241069': 0, '4100241075': 0, '4100242001': 0, '4100242002': 0, '4100242003': 1, '4100242004': 0, '4100242005': 0, '4100242006': 0, '4100242008': 0, '4100242011': 0, '4100242020': 0, '4100242021': 0, '4100242029': 0, '4100242031': 0, '4100242032': 1, '4100242033': 1, '4100242034': 0, '4100242035': 1, '4100242036': 0, '4100242037': 0, '4100242038': 0, '4100242040': 0, '4100242045': 0, '4100242048': 0, '4100242050': 0, '4100242053': 0, '4100242054': 0, '4100242057': 1, '4100242059': 0, '4100242060': 0, '4100242063': 1, '4100242065': 0, '4100242066': 0, '4100242067': 0, '4100251003': 0, '4100251004': 0, '4100251005': 0, '4100251006': 1, '4100251010': 0, '4100251011': 0, '4100251012': 0, '4100251013': 0, '4100251014': 0, '4100251015': 0, '4100251016': 1, '4100251017': 0, '4100251018': 0, '4100251019': 0, '4100251020': 1, '4100251021': 1, '4100251022': 0, '4100251024': 1, '4100251026': 0, '4100251027': 1, '4100251028': 1, '4100251029': 1, '4100251030': 0, '4100251031': 0, '4100251032': 1, '4100251033': 1, '4100251034': 0, '4100251035': 0, '4100251036': 1, '4100251038': 1, '4100251039': 0, '4100251040': 0, '4100251041': 1, '4100251042': 0, '4100251044': 0, '4100251046': 1, '4100251047': 0, '4100251048': 0, '4100251049': 1, '4100251051': 0, '4100251052': 0, '4100251053': 0, '4100251054': 0, '4100251056': 0, '4100251057': 1, '4100251059': 0, '4100251060': 0, '4100251061': 1, '4100251062': 0, '4100251063': 0, '4100251064': 0, '4100251065': 0, '4100251068': 1, '4100251069': 0, '4100251070': 0, '4100252001': 0, '4100252003': 0, '4100252004': 0, '4100252005': 0, '4100252007': 0, '4100252010': 0, '4100252011': 0, '4100252012': 0, '4100252013': 0, '4100252014': 0, '4100252015': 0, '4100252016': 0, '4100252019': 0, '4100252021': 0, '4100252022': 0, '4100252023': 0, '4100252024': 0, '4100252027': 0, '4100252031': 0, '4100252032': 0, '4100252033': 0, '4100252034': 0, '4100252035': 0, '4100252036': 1, '4100252037': 0, '4100252038': 0, '4100252039': 0, '4100252040': 0, '4100252041': 1, '4100252043': 0, '4100252044': 1, '4100252045': 0, '4100252048': 0, '4100252049': 0, '4100252050': 0, '4100252051': 0, '4100252053': 0, '4100252054': 0, '4100252055': 0, '4100252056': 0, '4100252057': 0, '4100252058': 0, '4100252060': 0, '4100252061': 1, '4100252062': 0, '4100252063': 0, '4100252066': 0, '4100252069': 0, '4100252070': 0, '4100252071': 0, '4100252072': 0, '4100252073': 0, '4100252074': 0, '4100252075': 0, '4100252076': 0, '4100252078': 0, '4100252081': 0, '4100261001': 0, '4100261002': 0, '4100261003': 0, '4100261004': 0, '4100261005': 1, '4100261006': 1, '4100261007': 0, '4100261010': 0, '4100261012': 0, '4100261013': 0, '4100261015': 0, '4100261016': 0, '4100261020': 0, '4100261023': 0, '4100261025': 0, '4100261027': 1, '4100261028': 0, '4100261029': 0, '4100261030': 1, '4100261031': 0, '4100261032': 0, '4100261033': 0, '4100261034': 1, '4100261035': 0, '4100261036': 0, '4100261038': 0, '4100261041': 1, '4100261044': 0, '4100261045': 0, '4100261046': 0, '4100261047': 0, '4100261048': 0, '4100261049': 0, '4100261050': 1, '4100261055': 0, '4100261056': 1, '4100261057': 0, '4100261058': 1, '4100261060': 0, '4100261061': 0, '4100262001': 0, '4100262003': 0, '4100262004': 1, '4100262006': 1, '4100262007': 0, '4100262008': 0, '4100262009': 0, '4100262010': 0, '4100262014': 0, '4100262015': 0, '4100262016': 0, '4100262017': 0, '4100262018': 0, '4100262019': 0, '4100262020': 0, '4100262022': 0, '4100262023': 0, '4100262024': 0, '4100262025': 0, '4100262027': 0, '4100262034': 1, '4100262035': 0, '4100262037': 0, '4100262038': 0, '4100262040': 0, '4100262041': 0, '4100262042': 0, '4100262043': 0, '4100262044': 0, '4100262045': 0, '4100262046': 0, '4100262047': 0, '4100262052': 0, '4100262053': 0, '4100262056': 1, '4100262057': 0, '4100262060': 0, '4100262063': 0, '4100262064': 0, '4100262065': 0, '4100262066': 0, '4100262067': 0, '4100262068': 0, '4100262069': 0, '4100262070': 0, '4100271007': 0, '4100271008': 0, '4100271009': 0, '4100271010': 0, '4100271011': 0, '4100271012': 0, '4100271026': 0, '4100271028': 0, '4100271029': 0, '4100271030': 0, '4100271032': 0, '4100271033': 0, '4100271034': 0, '4100271038': 1, '4100271039': 0, '4100271041': 1, '4100271042': 0, '4100271043': 0, '4100271056': 1, '4100272024': 0, '4100272029': 0, '4100272033': 0, '4100272034': 0, '4100272036': 0, '4100272037': 0, '4100272043': 0, '4100272051': 0, '4100272052': 0, '4100272056': 0, '4100281001': 0, '4100281002': 0, '4100281015': 0, '4100281016': 0, '4100281019': 0, '4100281022': 0, '4100281023': 0, '4100281027': 0, '4100281029': 0, '4100281030': 0, '4100281032': 1, '4100281033': 0, '4100281034': 0, '4100281035': 0, '4100281036': 0, '4100281037': 0, '4100281041': 0, '4100281042': 0, '4100281045': 0, '4100281046': 1, '4100281048': 0, '4100281049': 0, '4100281050': 0, '4100281052': 0, '4100281053': 1, '4100281054': 0, '4100281057': 0, '4100281058': 0, '4100281059': 0, '4100281060': 0, '4100281061': 0, '4100281062': 0, '4100281063': 0, '4100281066': 0, '4100281067': 1, '4100281068': 0, '4100281070': 1, '4100281072': 0, '4100281075': 0, '4100281076': 1, '4100281078': 0, '4100281079': 0, '4100281080': 0, '4100281081': 0, '4100282001': 0, '4100282002': 0, '4100282003': 0, '4100282004': 0, '4100282005': 0, '4100282007': 0, '4100282008': 0, '4100282009': 1, '4100282012': 0, '4100282013': 0, '4100282014': 0, '4100282015': 0, '4100282017': 0, '4100282018': 0, '4100282019': 0, '4100282020': 0, '4100282021': 0, '4100282022': 0, '4100282023': 0, '4100282024': 0, '4100282033': 0, '4100282043': 0, '4100282048': 0, '4100282053': 0, '4100282057': 0, '4100282058': 0, '4100282066': 1, '4100282067': 0, '4100282068': 0, '4100282070': 0, '4100291002': 0, '4100291003': 0, '4100291004': 0, '4100291005': 0, '4100291006': 1, '4100291007': 1, '4100291008': 0, '4100291009': 0, '4100291010': 1, '4100291011': 0, '4100291012': 0, '4100291014': 0, '4100291015': 0, '4100291016': 0, '4100291017': 0, '4100291018': 0, '4100291019': 1, '4100291021': 0, '4100291022': 0, '4100291025': 0, '4100291026': 1, '4100291027': 1, '4100291028': 0, '4100291032': 1, '4100291033': 0, '4100291034': 0, '4100291036': 1, '4100291037': 0, '4100291039': 0, '4100291040': 0, '4100291041': 1, '4100291043': 0, '4100291046': 0, '4100291047': 0, '4100291048': 0, '4100291049': 0, '4100291050': 0, '4100291051': 0, '4100291055': 0, '4100291056': 0, '4100291059': 0, '4100291060': 0, '4100291061': 0, '4100291062': 0, '4100291063': 0, '4100291064': 0, '4100291065': 0, '4100291070': 1, '4100291073': 1, '4100291074': 0, '4100291076': 0, '4100291077': 0, '4100291078': 1, '4100291079': 0, '4100291080': 0, '4100291081': 1, '4100291082': 1, '4100291083': 0, '4100291084': 1, '4100292001': 0, '4100292003': 0, '4100292005': 0, '4100292008': 0, '4100292010': 0, '4100292016': 0, '4100292019': 0, '4100292020': 0, '4100292021': 0, '4100292022': 0, '4100292023': 0, '4100292024': 0, '4100292025': 0, '4100292026': 0, '4100292027': 0, '4100292028': 0, '4100292035': 0, '4100292036': 0, '4100292037': 0, '4100292040': 0, '4100292041': 0, '4100292042': 0, '4100292043': 0, '4100292044': 0, '4100292045': 0, '4100292046': 0, '4100292048': 1, '4100292049': 0, '4100292050': 0, '4100292052': 0, '4100292053': 0, '4100292056': 0, '4100292057': 0, '4100292059': 0, '4100292060': 0, '4100292061': 0, '4100292062': 0, '4100292063': 0, '4100292064': 0, '4100292065': 0, '4100292066': 0, '4100292067': 0, '4100292068': 0, '4100292069': 0, '4100292070': 0, '4100292071': 0, '4100292072': 0, '4100292073': 0, '4100292074': 0, '4100292075': 0, '4100292077': 0, '4100292078': 0, '4100292079': 0, '4100292081': 0, '4100292083': 0, '4100292084': 0, '4100292085': 0, '4100292087': 0, '4100292088': 0, '4100302002': 0, '4100302013': 1, '4100302014': 0, '4100302016': 1, '4100302017': 0, '4100302018': 1, '4100302019': 0, '4100302020': 0, '4100302024': 0, '4100302028': 0, '4100302030': 1, '4100302040': 1, '4100302041': 0, '4100302042': 1, '4100302043': 1, '4100302044': 1, '4100302045': 1, '4100302046': 0, '4100302047': 0, '4100302048': 1, '4100302049': 0, '4100302050': 0, '4100302051': 0, '4100302052': 0, '4100302053': 0, '4100302054': 0, '4100302055': 1, '4100302058': 1, '4100302061': 0, '4100302063': 0, '4100302064': 1, '4100302066': 1, '4100302067': 0, '4100302068': 0, '4100302069': 0, '4100321001': 1, '4100321002': 0, '4100321003': 0, '4100321004': 0, '4100321005': 0, '4100321006': 0, '4100321008': 0, '4100321009': 1, '4100321010': 0, '4100321011': 0, '4100321012': 0, '4100321014': 0, '4100321015': 0, '4100321016': 0, '4100321019': 1, '4100321020': 0, '4100321021': 0, '4100321022': 0, '4100321023': 0, '4100321024': 0, '4100321026': 0, '4100321027': 0, '4100321028': 0, '4100321029': 0, '4100321030': 0, '4100321032': 0, '4100321033': 0, '4100321034': 0, '4100321037': 0, '4100321038': 0, '4100321039': 0, '4100321041': 0, '4100321042': 1, '4100321043': 1, '4100321044': 1, '4100321045': 0, '4100321046': 0, '4100321049': 0, '4100321051': 0, '4100321052': 0, '4100321053': 0, '4100322001': 0, '4100322007': 0, '4100322025': 0, '4100322031': 0, '4100322032': 1, '4100322033': 0, '4100322034': 0, '4100322035': 0, '4100322037': 0, '4100322038': 0, '4100322039': 0, '4100322040': 0, '4100322041': 0, '4100322042': 0, '4100322044': 0, '4100322045': 0, '4100322048': 0, '4100322051': 0, '4100322052': 0, '4100322053': 0, '4100322055': 0, '4100322056': 0, '4100322057': 0, '4100322058': 0, '4100322059': 0, '4100322060': 0, '4100322061': 0, '4110211001': 1, '4110211004': 1, '4110211005': 1, '4110211006': 0, '4110211007': 0, '4110211008': 0, '4110211009': 0, '4110211011': 0, '4110211013': 1, '4110211014': 1, '4110211015': 1, '4110211016': 0, '4110211018': 0, '4110211019': 0, '4110211020': 0, '4110211021': 1, '4110211022': 1, '4110211023': 1, '4110211024': 0, '4110211025': 1, '4110211026': 0, '4110211027': 1, '4110211028': 1, '4110211030': 0, '4110211032': 0, '4110211033': 0, '4110211034': 0, '4110211035': 0, '4110211036': 1, '4110211037': 0, '4110211038': 1, '4110211039': 1, '4110211040': 1, '4110211041': 0, '4110211043': 0, '4110211044': 0, '4110211045': 1, '4110211046': 0, '4110211047': 0, '4110211048': 0, '4110211049': 0, '4110211050': 0, '4110211051': 0, '4110211052': 0, '4110211053': 1, '4110211054': 0, '4110211055': 1, '4110211056': 0, '4110211057': 0, '4110211058': 0, '4110211060': 0, '4110211061': 1, '4110211062': 0, '4110211063': 0, '4110211064': 0, '4110211065': 0, '4110211067': 0, '4110211068': 0, '4110211072': 0, '4110211073': 0, '4110211075': 1, '4110211076': 0, '4110211078': 1, '4110211079': 0, '4110211080': 0, '4110212003': 0, '4110212004': 0, '4110212007': 0, '4110212008': 0, '4110212009': 0, '4110212010': 0, '4110212011': 0, '4110212013': 0, '4110212014': 0, '4110212015': 0, '4110212016': 0, '4110212017': 0, '4110212018': 0, '4110212019': 0, '4110212021': 0, '4110212023': 0, '4110212024': 0, '4110212026': 0, '4110212027': 0, '4110212029': 0, '4110212030': 0, '4110212033': 0, '4110212034': 1, '4110212035': 0, '4110212036': 1, '4110212038': 0, '4110212039': 0, '4110212041': 0, '4110212042': 0, '4110212044': 0, '4110212045': 0, '4110212046': 0, '4110212047': 0, '4110212049': 1, '4110212050': 0, '4110212051': 1, '4110212052': 0, '4110212053': 0, '4110212054': 0, '4110212055': 0, '4110212056': 0, '4110212059': 0, '4110212061': 0, '4110212062': 1, '4110212063': 0, '4110212064': 0, '4110212069': 0, '4110311001': 0, '4110311003': 0, '4110311004': 0, '4110311005': 0, '4110311006': 1, '4110311012': 0, '4110311015': 0, '4110311017': 0, '4110311018': 0, '4110311019': 0, '4110311020': 0, '4110311021': 0, '4110311023': 1, '4110311030': 0, '4110311031': 0, '4110311032': 0, '4110311033': 0, '4110311034': 0, '4110311036': 0, '4110311037': 0, '4110311038': 0, '4110311042': 0, '4110311043': 0, '4110311044': 0, '4110311045': 1, '4110311046': 0, '4110311048': 1, '4110311049': 0, '4110311050': 0, '4110311053': 0, '4110311054': 1, '4110311057': 0, '4110311061': 0, '4110311062': 1, '4110311064': 0, '4110311065': 0, '4110311067': 0, '4110311068': 0, '4110311072': 0, '4110312006': 0, '4110312007': 0, '4110312008': 0, '4110312009': 1, '4110312013': 0, '4110312023': 0, '4110312024': 0, '4110312025': 0, '4110312027': 0, '4110312030': 0, '4110312031': 0, '4110312048': 0, '4110312049': 0, '4110312078': 0, '414081010': 0, '414081011': 0, '4140810110': 0, '4140810114': 0, '4140810117': 0, '4140810122': 0, '4140810124': 0, '4140810125': 0, '4140810126': 0, '4140810127': 0, '4140810128': 0, '4140810129': 0, '414081013': 0, '4140810132': 0, '4140810133': 0, '4140810135': 0, '4140810136': 0, '4140810138': 0, '4140810139': 0, '4140810140': 0, '4140810142': 0, '4140810143': 0, '4140810144': 0, '4140810145': 0, '4140810146': 0, '4140810148': 0, '414081015': 0, '4140810150': 0, '4140810151': 0, '4140810152': 0, '4140810153': 1, '4140810154': 0, '4140810158': 0, '4140810159': 0, '414081016': 0, '4140810162': 1, '4140810163': 0, '4140810164': 0, '4140810165': 0, '414081017': 0, '4140810171': 0, '4140810173': 0, '4140810175': 0, '4140810176': 0, '4140810179': 0, '414081018': 0, '4140810180': 0, '4140810181': 0, '4140810182': 0, '4140810183': 0, '4140810184': 0, '4140810185': 0, '414081019': 0, '414081021': 0, '4140810210': 1, '4140810211': 0, '4140810212': 0, '4140810215': 0, '4140810217': 1, '4140810219': 1, '4140810220': 0, '4140810221': 0, '4140810222': 0, '4140810223': 0, '4140810224': 0, '4140810225': 0, '4140810226': 0, '4140810228': 0, '4140810229': 0, '414081023': 0, '4140810230': 0, '4140810233': 0, '4140810234': 0, '4140810237': 0, '4140810239': 0, '4140810240': 0, '4140810242': 0, '4140810244': 0, '4140810246': 0, '4140810247': 0, '4140810249': 0, '414081025': 0, '4140810250': 0, '4140810251': 0, '4140810252': 0, '4140810253': 0, '4140810254': 0, '4140810255': 0, '4140810256': 0, '4140810257': 0, '4140810258': 0, '4140810259': 0, '414081026': 0, '4140810264': 0, '4140810265': 0, '4140810266': 0, '4140810268': 0, '4140810269': 0, '414081027': 0, '4140810270': 0, '4140810271': 0, '4140810272': 1, '4140810273': 0, '4140810274': 0, '4140810276': 0, '4140810277': 0, '4140810278': 0, '4140810279': 0, '414081028': 0, '4140810280': 0, '414081029': 0, '459999011': 0, '4599990110': 0, '4599990112': 0, '4599990113': 0, '4599990114': 0, '4599990116': 0, '4599990117': 0, '4599990118': 0, '4599990119': 0, '459999012': 0, '4599990120': 0, '4599990125': 0, '4599990126': 0, '4599990128': 0, '4599990129': 0, '459999013': 0, '4599990130': 0, '4599990131': 0, '4599990132': 1, '4599990133': 0, '4599990134': 0, '4599990136': 0, '4599990137': 0, '4599990139': 0, '4599990141': 0, '4599990144': 0, '4599990146': 0, '4599990148': 0, '4599990149': 0, '4599990153': 0, '4599990154': 0, '4599990155': 0, '459999016': 0, '4599990163': 0, '4599990165': 0, '4599990166': 0, '4599990168': 0, '459999017': 0, '4599990171': 0, '459999021': 0, '4599990211': 0, '4599990212': 0, '4599990214': 0, '4599990216': 0, '4599990218': 0, '459999022': 0, '4599990221': 0, '4599990222': 0, '4599990223': 0, '4599990224': 0, '4599990226': 0, '4599990231': 0, '4599990233': 0, '4599990234': 0, '4599990235': 1, '4599990238': 0, '459999024': 0, '4599990240': 0, '4599990241': 0, '4599990243': 0, '4599990244': 0, '4599990245': 0, '4599990246': 0, '4599990247': 0, '4599990248': 0, '4599990249': 0, '459999025': 0, '4599990253': 0, '4599990254': 0, '4599990255': 0, '4599990256': 0, '4599990263': 0, '4599990264': 0, '4599990269': 0, '4599990270': 0, '4599990272': 0, '4599990273': 0, '4599990274': 0, '4599990275': 0, '4599990276': 0, '459999028': 0, '4599990283': 0, '5000391001': 0, '5000391002': 0, '5000391004': 0, '5000391005': 0, '5000391007': 0, '5000391008': 0, '5000391010': 0, '5000391012': 0, '5000391013': 0, '5000391014': 0, '5000391015': 0, '5000391016': 0, '5000391017': 1, '5000391019': 0, '5000391020': 0, '5000391022': 0, '5000391023': 0, '5000391024': 0, '5000391026': 0, '5000391028': 0, '5000391029': 0, '5000391030': 0, '5000391031': 0, '5000391032': 0, '5000391034': 0, '5000391035': 0, '5000391036': 0, '5000391037': 0, '5000391038': 0, '5000391040': 0, '5000391045': 1, '5000391046': 0, '5000391047': 0, '5000391049': 0, '5000391050': 0, '5000391054': 0, '5000391055': 1, '5000391056': 1, '5000391059': 0, '5000391060': 1, '5000391061': 0, '5000391062': 0, '5000391063': 0, '5000391064': 0, '5000391065': 0, '5000391066': 0, '5000391067': 0, '5000391068': 0, '5000391069': 0, '5000391070': 0, '5000391071': 0, '5000391072': 0, '5000391073': 0, '5000391074': 0, '5000391076': 0, '5000391078': 0, '5000391079': 0, '5000391080': 0, '5000391081': 0, '5000392001': 0, '5000392002': 0, '5000392003': 0, '5000392006': 0, '5000392007': 0, '5000392010': 0, '5000392011': 0, '5000392015': 0, '5000392016': 0, '5000392017': 0, '5000392018': 0, '5000392019': 0, '5000392020': 0, '5000392021': 0, '5000392022': 0, '5000392025': 0, '5000392026': 0, '5000392027': 0, '5000392029': 0, '5000392033': 1, '5000392035': 0, '5000392036': 0, '5000392038': 0, '5000392039': 0, '5000392040': 0, '5000392041': 0, '5000392042': 0, '5000392044': 0, '5000392047': 0, '5000392048': 0, '5000392049': 0, '5000392050': 0, '5000392051': 0, '5000392052': 1, '5000392053': 0, '5000392054': 0, '5000392055': 0, '5000392056': 0, '5000392058': 0, '5000392060': 1, '5000392062': 0, '5000392063': 0, '5000392064': 0, '5000392065': 0, '5000392066': 0, '5000392067': 0, '5000392070': 0, '5000392071': 0, '5000392072': 0, '5000431019': 0, '5000431020': 0, '5000431021': 0, '5000431022': 0, '5000431023': 0, '5000431025': 0, '5000431026': 0, '5000431049': 0, '5000431050': 0, '5000432001': 0, '5000432003': 0, '5000432006': 0, '5000432059': 0, '5000441001': 0, '5000441002': 0, '5000441003': 0, '5000441005': 0, '5000441006': 0, '5000441007': 0, '5000441008': 0, '5000441009': 0, '5000441010': 0, '5000441012': 0, '5000441013': 0, '5000441014': 0, '5000441015': 0, '5000441016': 0, '5000441017': 0, '5000441018': 0, '5000441021': 0, '5000441022': 0, '5000441023': 0, '5000441024': 1, '5000441027': 0, '5000441030': 0, '5000441031': 0, '5000441032': 0, '5000441033': 0, '5000441034': 0, '5000441035': 0, '5000441037': 0, '5000441038': 0, '5000441039': 0, '5000441040': 0, '5000441041': 0, '5000441042': 0, '5000441043': 0, '5000441044': 0, '5000441045': 0, '5000441046': 0, '5000441047': 0, '5000441048': 0, '5000441050': 0, '5000441051': 0, '5000441052': 0, '5000441053': 0, '5000441054': 0, '5000441055': 0, '5000441058': 1, '5000441059': 0, '5000441061': 0, '5000441062': 0, '5000441064': 0, '5000441065': 0, '5000441066': 0, '5000441067': 1, '5000441068': 0, '5000441069': 0, '5000441070': 0, '5000441071': 0, '5000441072': 0, '5000442001': 0, '5000442002': 0, '5000442003': 0, '5000442004': 0, '5000442005': 0, '5000442007': 0, '5000442008': 0, '5000442009': 0, '5000442010': 0, '5000442014': 0, '5000442015': 0, '5000442016': 0, '5000442019': 0, '5000442021': 0, '5000442022': 0, '5000442024': 0, '5000442025': 0, '5000442026': 0, '5000442027': 0, '5000442028': 0, '5000442029': 0, '5000442033': 0, '5000442034': 0, '5000442035': 0, '5000442036': 0, '5000442037': 0, '5000442038': 0, '5000442039': 0, '5000442040': 0, '5000442042': 0, '5000442043': 0, '5000442045': 0, '5000442047': 0, '5000442048': 0, '5000442050': 0, '5000442051': 0, '5000442052': 0, '5000442053': 0, '5000442054': 0, '5000442055': 0, '5000442056': 0, '5000442057': 0, '5000442058': 0, '5000442059': 0, '5000442060': 0, '5000442062': 0, '5000442063': 0, '5000442064': 0, '5000442065': 0, '5000442066': 0, '5000442067': 0, '5000442068': 0, '5000442069': 0, '5000442070': 0, '5000442072': 0, '5000442073': 0, '5000442074': 0, '5000442075': 0, '5000442076': 0, '5000442077': 0, '5000442078': 0, '5000671001': 0, '5000671002': 0, '5000671003': 0, '5000671004': 0, '5000671005': 0, '5000671006': 0, '5000671008': 0, '5000671009': 0, '5000671010': 0, '5000671011': 0, '5000671012': 0, '5000671013': 0, '5000671014': 0, '5000671015': 0, '5000671016': 0, '5000671017': 0, '5000671018': 0, '5000671019': 0, '5000671020': 0, '5000671022': 0, '5000671023': 0, '5000671024': 0, '5000671026': 0, '5000671027': 0, '5000671028': 0, '5000671029': 0, '5000671030': 0, '5000671031': 0, '5000671032': 0, '5000671033': 0, '5000671034': 0, '5000671035': 0, '5000671036': 0, '5000671037': 0, '5000671038': 0, '5000671039': 0, '5000671040': 0, '5000671041': 1, '5000671042': 1, '5000671043': 0, '5000671046': 0, '5000671047': 0, '5000671048': 1, '5000671049': 1, '5000671050': 0, '5000671051': 0, '5000671053': 0, '5000671055': 0, '5000671056': 0, '5000671057': 0, '5000671058': 1, '5000671059': 0, '5000671060': 0, '5000671061': 1, '5000671062': 0, '5000671063': 0, '5000671064': 0, '5000671065': 0, '5000671066': 0, '5000671067': 0, '5000671069': 1, '5000671070': 1, '5000671071': 0, '5000672002': 0, '5000672004': 0, '5000672005': 0, '5000672006': 0, '5000672007': 0, '5000672008': 0, '5000672010': 0, '5000672011': 0, '5000672012': 0, '5000672013': 0, '5000672014': 0, '5000672016': 0, '5000672017': 0, '5000672019': 0, '5000672020': 0, '5000672021': 0, '5000672022': 0, '5000672023': 0, '5000672024': 0, '5000672025': 0, '5000672026': 0, '5000672027': 0, '5000672030': 0, '5000672031': 0, '5000672033': 0, '5000672034': 0, '5000672035': 0, '5000672036': 0, '5000672038': 0, '5000672042': 0, '5000672043': 0, '5000672044': 0, '5000672045': 0, '5000672046': 0, '5000672047': 0, '5000672048': 0, '5000672049': 0, '5000672050': 0, '5000672051': 0, '5000672052': 0, '5000672053': 0, '5000672054': 0, '5000672055': 0, '5000672056': 0, '5000672057': 0, '5000672058': 0, '5000672059': 0, '5000672060': 0, '5000672062': 0, '5000672064': 0, '5000672065': 0, '5000672066': 0, '5000672067': 0, '5000672068': 0, '5000672070': 0, '5000672071': 0, '5000672072': 0, '5000672074': 0, '5000672075': 0, '5000672076': 0, '5000672077': 0, '5000672081': 0, '5000672082': 0, '5000951001': 0, '5000951002': 0, '5000951003': 0, '5000951004': 0, '5000951005': 0, '5000951006': 0, '5000951007': 0, '5000951008': 0, '5000951009': 0, '5000951010': 0, '5000951011': 0, '5000951012': 0, '5000951013': 0, '5000951015': 0, '5000951016': 0, '5000951017': 0, '5000951018': 0, '5000951019': 1, '5000951021': 0, '5000951023': 1, '5000951024': 1, '5000951025': 0, '5000951027': 1, '5000951028': 0, '5000951033': 0, '5000951034': 0, '5000951035': 0, '5000951037': 0, '5000951039': 0, '5000951040': 0, '5000951042': 0, '5000951043': 0, '5000951044': 0, '5000951045': 0, '5000951047': 0, '5000951049': 0, '5000951051': 0, '5000951052': 0, '5000951053': 0, '5000951054': 0, '5000951055': 0, '5000951056': 0, '5000951057': 0, '5000951058': 0, '5000951060': 0, '5000951061': 0, '5000951062': 0, '5000951063': 0, '5000951065': 0, '5000951066': 0, '5000951067': 0, '5000952002': 0, '5000952003': 0, '5000952004': 0, '5000952005': 0, '5000952007': 0, '5000952008': 0, '5000952011': 0, '5000952013': 0, '5000952014': 0, '5000952015': 0, '5000952016': 0, '5000952017': 0, '5000952018': 0, '5000952020': 0, '5000952021': 0, '5000952022': 0, '5000952023': 0, '5000952024': 0, '5000952025': 0, '5000952026': 0, '5000952027': 0, '5000952028': 0, '5000952029': 0, '5000952031': 0, '5000952032': 0, '5000952033': 0, '5000952034': 1, '5000952035': 0, '5000952036': 0, '5000952038': 0, '5000952040': 0, '5000952041': 0, '5000952042': 0, '5000952044': 0, '5000952045': 0, '5000952046': 0, '5000952048': 0, '5000952050': 0, '5000952052': 0, '5000952053': 0, '5000952054': 0, '5000952055': 0, '5000952060': 0, '5000952061': 0, '5000952062': 1, '5000952063': 0, '5000952064': 0, '5000952065': 0, '5000952066': 0, '5000952068': 0, '5000952069': 0, '5000952070': 0, '5000952071': 0, '5000952072': 0, '5000952073': 0, '5000952075': 0, '5000952076': 0, '5000952077': 0, '5000952078': 0, '5000952080': 0, '5000952083': 1, '5100091001': 0, '5100091003': 0, '5100091004': 0, '5100091005': 0, '5100091006': 0, '5100091007': 0, '5100091008': 0, '5100091009': 0, '5100091010': 0, '5100091012': 0, '5100091017': 0, '5100091019': 0, '5100091020': 0, '5100091025': 0, '5100091026': 0, '5100091027': 0, '5100091028': 0, '5100091032': 0, '5100091033': 0, '5100091034': 0, '5100091035': 0, '5100091036': 0, '5100091038': 0, '5100091039': 0, '5100091042': 0, '5100091046': 0, '5100091049': 1, '5100091050': 0, '5100091051': 0, '5100091053': 0, '5100091055': 0, '5100091056': 0, '5100091057': 0, '5100091058': 0, '5100091059': 0, '5100091062': 0, '5100091064': 0, '5100091065': 0, '5100091066': 0, '5100091067': 0, '5100091068': 0, '5100091069': 0, '5100092002': 0, '5100092003': 0, '5100092005': 0, '5100092006': 0, '5100092008': 0, '5100092010': 0, '5100092011': 0, '5100092013': 0, '5100092017': 0, '5100092019': 0, '5100092021': 0, '5100092022': 0, '5100092023': 0, '5100092026': 0, '5100092027': 0, '5100092032': 0, '5100092033': 0, '5100092034': 0, '5100092035': 0, '5100092037': 0, '5100092038': 0, '5100092039': 0, '5100092040': 0, '5100092041': 0, '5100092042': 0, '5100092043': 0, '5100092044': 0, '5100092045': 0, '5100092053': 0, '5100092056': 0, '5100092057': 0, '5100092060': 0, '5100092061': 0, '5100092062': 0, '5100092063': 0, '5100092064': 0, '5100092065': 0, '5100092067': 0, '5100092068': 0, '5100092069': 0, '5100092071': 0, '5100092072': 0, '5100341002': 0, '5100341003': 0, '5100341004': 0, '5100341005': 0, '5100341006': 0, '5100341008': 0, '5100341009': 0, '5100341010': 0, '5100341012': 0, '5100341013': 0, '5100341014': 0, '5100341015': 0, '5100341016': 0, '5100341017': 0, '5100341019': 0, '5100341020': 0, '5100341021': 0, '5100341022': 0, '5100341023': 0, '5100341024': 0, '5100341025': 0, '5100341026': 0, '5100341027': 0, '5100341028': 0, '5100341030': 0, '5100341031': 0, '5100341032': 0, '5100341033': 0, '5100341034': 0, '5100341035': 0, '5100341037': 0, '5100341038': 0, '5100341039': 0, '5100341042': 0, '5100341043': 1, '5100341046': 0, '5100341048': 0, '5100341050': 0, '5100341052': 0, '5100341054': 0, '5100341055': 0, '5100341056': 0, '5100341057': 0, '5100341058': 0, '5100341061': 0, '5100341062': 0, '5100341065': 0, '5100341067': 0, '5100341068': 0, '5100341070': 0, '5100341071': 0, '5100341072': 0, '5100341074': 1, '5100341075': 0, '5100341076': 0, '5100341077': 0, '5100341078': 0, '5100341079': 0, '5100342002': 0, '5100342003': 0, '5100342007': 0, '5100342008': 0, '5100342009': 0, '5100342012': 0, '5100342016': 0, '5100342017': 0, '5100342018': 0, '5100342020': 0, '5100342022': 1, '5100342023': 1, '5100342024': 1, '5100342025': 0, '5100342028': 1, '5100342030': 0, '5100342031': 0, '5100342034': 0, '5100342036': 1, '5100342042': 0, '5100342043': 0, '5100342045': 0, '5100342048': 1, '5100351001': 1, '5100351002': 1, '5100351004': 0, '5100351005': 0, '5100351007': 0, '5100351009': 0, '5100351010': 0, '5100351012': 0, '5100351013': 1, '5100351015': 0, '5100351016': 0, '5100351019': 0, '5100351020': 0, '5100351021': 0, '5100351022': 1, '5100351023': 0, '5100351024': 0, '5100351025': 0, '5100351026': 0, '5100351032': 0, '5100351034': 0, '5100351035': 0, '5100351036': 0, '5100351038': 0, '5100351039': 0, '5100351040': 0, '5100351042': 1, '5100351043': 0, '5100351044': 0, '5100351045': 0, '5100351046': 0, '5100351049': 0, '5100351051': 0, '5100351054': 0, '5100351058': 0, '5100352001': 0, '5100352002': 0, '5100352003': 0, '5100352004': 0, '5100352005': 0, '5100352006': 0, '5100352007': 0, '5100352008': 0, '5100352009': 0, '5100352011': 0, '5100352012': 0, '5100352013': 0, '5100352014': 0, '5100352015': 0, '5100352016': 0, '5100352017': 0, '5100352018': 0, '5100352020': 0, '5100352021': 0, '5100352022': 1, '5100352026': 0, '5100352027': 0, '5100352028': 0, '5100352030': 0, '5100352031': 0, '5100352032': 0, '5100352033': 0, '5100352034': 0, '5100352035': 0, '5100352037': 0, '5100352038': 0, '5100352039': 0, '5100352041': 0, '5100352042': 0, '5100352043': 1, '5100352044': 0, '5100352045': 0, '5100352046': 0, '5100352049': 0, '5100352050': 0, '5100352051': 0, '5100352052': 0, '5100352054': 1, '5100352055': 0, '5100352056': 0, '5100352057': 0, '5100352060': 0, '5100352061': 0, '5100352063': 0, '5100361009': 0, '5100361056': 0, '5100362028': 0, '5100362029': 0, '5100362030': 0, '5100362052': 0, '5100371022': 0, '5100371023': 0, '5100371024': 0, '5100371026': 0, '5100371027': 0, '5100371042': 0, '5100371055': 0, '5100371056': 0, '5100371067': 0, '5100371079': 0, '5100372001': 0, '5100372002': 0, '5100372003': 0, '5100372005': 0, '5100372006': 0, '5100372007': 0, '5100372009': 0, '5100372011': 0, '5100372015': 0, '5100372016': 0, '5100372017': 0, '5100372018': 0, '5100372019': 0, '5100372020': 0, '5100372021': 0, '5100372022': 0, '5100372023': 0, '5100372026': 0, '5100372027': 0, '5100372028': 0, '5100372069': 0, '5100381002': 0, '5100381003': 0, '5100381004': 0, '5100381005': 0, '5100381006': 0, '5100381007': 0, '5100381008': 0, '5100381009': 0, '5100381010': 0, '5100381011': 0, '5100381012': 0, '5100381015': 0, '5100381016': 0, '5100381017': 0, '5100381018': 0, '5100381019': 0, '5100381020': 0, '5100381021': 0, '5100381022': 0, '5100381023': 0, '5100381024': 0, '5100381026': 0, '5100381027': 0, '5100381028': 0, '5100381029': 0, '5100381031': 0, '5100381032': 0, '5100381034': 0, '5100381035': 0, '5100381037': 0, '5100381038': 0, '5100381039': 0, '5100381040': 0, '5100381041': 0, '5100381042': 0, '5100381043': 0, '5100381044': 0, '5100381045': 0, '5100381046': 0, '5100381047': 0, '5100381048': 0, '5100381049': 0, '5100381050': 0, '5100381051': 0, '5100381052': 0, '5100381053': 0, '5100381054': 0, '5100381055': 0, '5100381056': 0, '5100381058': 0, '5100381059': 0, '5100381060': 0, '5100381061': 0, '5100381063': 0, '5100381065': 0, '5100381066': 0, '5100381067': 0, '5100381069': 0, '5100382001': 0, '5100382003': 0, '5100382007': 0, '5100382008': 0, '5100382010': 0, '5100382011': 0, '5100382012': 0, '5100382013': 0, '5100382014': 0, '5100382015': 0, '5100382016': 0, '5100382018': 0, '5100382019': 0, '5100382020': 0, '5100382021': 0, '5100382022': 0, '5100382023': 0, '5100382025': 0, '5100382026': 0, '5100382027': 0, '5100382028': 0, '5100382029': 0, '5100382030': 0, '5100382031': 0, '5100382032': 0, '5100382033': 0, '5100382034': 0, '5100382035': 0, '5100382036': 0, '5100382037': 0, '5100382038': 0, '5100382039': 0, '5100382040': 0, '5100382042': 0, '5100382045': 0, '5100382046': 0, '5100382048': 0, '5100382050': 0, '5100382051': 0, '5100382052': 0, '5100382053': 0, '5100382054': 0, '5100382055': 0, '5100382056': 0, '5100382057': 0, '5100382058': 0, '5100382059': 0, '5100382060': 0, '5100382061': 0, '5100382062': 0, '5100382063': 0, '5100382064': 0, '5100382065': 0, '5100382066': 0, '5100382067': 0, '5100382068': 0, '5100382069': 0, '5100382070': 0, '5100382071': 0, '5100382072': 0, '5100382073': 0, '5100382075': 0, '5100382076': 0, '5100382077': 0, '5100382078': 0, '5100382079': 0, '5100401001': 0, '5100401003': 0, '5100401005': 0, '5100401006': 0, '5100401007': 0, '5100401008': 0, '5100401010': 0, '5100401011': 0, '5100401012': 0, '5100401014': 0, '5100401015': 0, '5100401016': 0, '5100401018': 0, '5100401021': 0, '5100401022': 0, '5100401023': 1, '5100401025': 0, '5100401026': 0, '5100401028': 0, '5100401029': 0, '5100401030': 0, '5100401031': 0, '5100401032': 0, '5100401033': 0, '5100401034': 1, '5100401035': 0, '5100401036': 0, '5100401038': 0, '5100401039': 0, '5100401040': 0, '5100401042': 0, '5100401043': 1, '5100401044': 0, '5100401045': 0, '5100401046': 0, '5100401047': 0, '5100401048': 0, '5100401049': 0, '5100401050': 0, '5100401051': 0, '5100401053': 0, '5100401054': 0, '5100401055': 0, '5100401056': 0, '5100401057': 0, '5100401059': 0, '5100401060': 0, '5100401061': 0, '5100401062': 0, '5100401063': 0, '5100401064': 0, '5100401065': 1, '5100401066': 0, '5100401067': 0, '5100401069': 0, '5100401070': 0, '5100401071': 0, '5100401072': 0, '5100401073': 0, '5100401074': 0, '5100401075': 0, '5100401076': 0, '5100401077': 0, '5100401078': 0, '5100402001': 1, '5100402002': 0, '5100402004': 0, '5100402005': 0, '5100402007': 0, '5100402008': 0, '5100402009': 0, '5100402011': 0, '5100402012': 0, '5100402015': 0, '5100402016': 0, '5100402017': 0, '5100402019': 0, '5100402020': 0, '5100402023': 0, '5100402024': 0, '5100402028': 0, '5100402029': 0, '5100402031': 0, '5100402032': 0, '5100402033': 0, '5100402034': 0, '5100402035': 0, '5100402036': 0, '5100402037': 0, '5100402038': 0, '5100402039': 0, '5100402040': 0, '5100402046': 0, '5100402047': 0, '5100402048': 0, '5100402049': 0, '5100402050': 0, '5100402051': 0, '5100402052': 0, '5100402053': 0, '5100402054': 0, '5100402055': 0, '5100402057': 0, '5100402058': 0, '5100402059': 0, '5100402062': 1, '5100402063': 1, '5100402065': 0, '5100402066': 0, '5100402067': 0, '5100402068': 0, '5100402069': 0, '5100421001': 0, '5100421002': 0, '5100421003': 0, '5100421005': 0, '5100421007': 0, '5100421009': 0, '5100421011': 0, '5100421012': 0, '5100421013': 0, '5100421015': 0, '5100421016': 0, '5100421017': 0, '5100421018': 0, '5100421019': 0, '5100421020': 0, '5100421021': 0, '5100421024': 0, '5100421025': 0, '5100421026': 0, '5100421027': 0, '5100421029': 0, '5100421032': 0, '5100421033': 0, '5100421034': 0, '5100421038': 0, '5100421039': 0, '5100421040': 0, '5100421041': 0, '5100421043': 0, '5100421045': 0, '5100421047': 0, '5100421048': 0, '5100421049': 0, '5100421050': 0, '5100421051': 0, '5100421052': 0, '5100421053': 0, '5100421054': 0, '5100421056': 0, '5100421057': 0, '5100421058': 0, '5100421059': 0, '5100421060': 0, '5100421061': 0, '5100421062': 0, '5100421063': 0, '5100421064': 0, '5100421065': 0, '5100421067': 0, '5100421068': 0, '5100421069': 0, '5100421070': 0, '5100421071': 0, '5100421072': 0, '5100421073': 0, '5100421074': 0, '5100421076': 0, '5100421078': 0, '5100421079': 0, '5100421080': 0, '5100421081': 0, '5100422002': 0, '5100422003': 0, '5100422004': 0, '5100422005': 0, '5100422006': 0, '5100422007': 0, '5100422008': 0, '5100422009': 0, '5100422011': 0, '5100422012': 0, '5100422013': 0, '5100422014': 0, '5100422016': 0, '5100422017': 0, '5100422018': 0, '5100422019': 0, '5100422022': 0, '5100422023': 0, '5100422024': 0, '5100422025': 0, '5100422026': 0, '5100422027': 0, '5100422028': 0, '5100422029': 0, '5100422030': 0, '5100422033': 0, '5100422034': 0, '5100422035': 0, '5100422036': 0, '5100422037': 0, '5100422038': 0, '5100422039': 0, '5100422041': 0, '5100422042': 0, '5100422044': 0, '5100422045': 0, '5100422046': 0, '5100422047': 0, '5100422049': 0, '5100422050': 0, '5100422051': 0, '5100422052': 0, '5100422055': 0, '5100422056': 0, '5100422057': 0, '5100422058': 0, '5100422059': 0, '5100422060': 0, '5100422061': 0, '5100422062': 0, '5100422063': 0, '5100422065': 0, '5100422066': 0, '5100422067': 0, '5100422068': 0, '5100422069': 0, '5100422071': 0, '5100422072': 0, '5100422073': 0, '5100422074': 0, '5100422075': 0, '5100422077': 0, '5100422078': 0, '5100422079': 0, '5100422080': 0, '5100422081': 0, '5100422084': 0, '5100422085': 0, '5100451001': 0, '5100451003': 0, '5100451004': 0, '5100451006': 0, '5100451007': 0, '5100451012': 0, '5100451013': 0, '5100451015': 0, '5100451016': 0, '5100451017': 0, '5100451018': 0, '5100451019': 0, '5100451020': 0, '5100451024': 0, '5100451026': 0, '5100451027': 0, '5100451033': 0, '5100451034': 0, '5100451035': 0, '5100451036': 0, '5100451038': 0, '5100451041': 0, '5100451043': 0, '5100451044': 0, '5100451045': 0, '5100451049': 0, '5100451050': 0, '5100451051': 0, '5100451052': 0, '5100451055': 0, '5100451056': 0, '5100451059': 0, '5100451060': 0, '5100451061': 0, '5100451064': 0, '5100451065': 0, '5100451066': 0, '5100451067': 0, '5100451070': 0, '5100451071': 0, '5100452002': 0, '5100452004': 0, '5100452005': 0, '5100452006': 0, '5100452007': 0, '5100452008': 0, '5100452009': 0, '5100452010': 0, '5100452011': 0, '5100452012': 0, '5100452013': 0, '5100452014': 0, '5100452016': 1, '5100452017': 0, '5100452018': 0, '5100452021': 0, '5100452023': 0, '5100452025': 0, '5100452027': 0, '5100452028': 0, '5100452030': 0, '5100452031': 0, '5100452032': 0, '5100452033': 0, '5100452034': 0, '5100452035': 0, '5100452036': 0, '5100452037': 0, '5100452038': 0, '5100452039': 0, '5100452040': 0, '5100452047': 0, '5100452049': 0, '5100452050': 0, '5100452053': 0, '5100452054': 0, '5100452055': 0, '5100452059': 0, '5100452060': 0, '5100452061': 0, '5100452065': 0, '5100452066': 0, '5100452067': 0, '5100452076': 0, '5100452078': 0, '5100452079': 0, '5100452080': 0, '5100452081': 0, '5100461004': 0, '5100461005': 0, '5100461006': 0, '5100461007': 1, '5100461008': 0, '5100461009': 0, '5100461010': 0, '5100461011': 0, '5100461014': 0, '5100461015': 0, '5100461016': 0, '5100461017': 0, '5100461018': 0, '5100461020': 0, '5100461021': 0, '5100461022': 0, '5100461023': 0, '5100461025': 0, '5100461029': 0, '5100461030': 0, '5100461031': 0, '5100461032': 0, '5100461033': 0, '5100461034': 0, '5100461035': 0, '5100461036': 0, '5100461037': 0, '5100461038': 0, '5100461039': 0, '5100461040': 0, '5100461042': 0, '5100461043': 0, '5100461044': 0, '5100461046': 0, '5100461047': 0, '5100461048': 0, '5100461049': 0, '5100461050': 0, '5100461051': 0, '5100461052': 0, '5100461053': 0, '5100461054': 0, '5100461055': 0, '5100461056': 0, '5100461057': 0, '5100461058': 0, '5100461061': 0, '5100461062': 0, '5100461063': 0, '5100461064': 0, '5100461065': 0, '5100461066': 0, '5100461067': 0, '5100461068': 0, '5100461069': 0, '5100462001': 0, '5100462002': 0, '5100462003': 1, '5100462005': 0, '5100462009': 0, '5100462010': 0, '5100462011': 0, '5100462012': 0, '5100462014': 0, '5100462015': 0, '5100462016': 0, '5100462017': 0, '5100462018': 0, '5100462019': 0, '5100462021': 0, '5100462022': 0, '5100462023': 0, '5100462024': 0, '5100462025': 0, '5100462026': 0, '5100462027': 0, '5100462028': 0, '5100462029': 0, '5100462031': 0, '5100462032': 0, '5100462033': 0, '5100462035': 0, '5100462037': 0, '5100462038': 0, '5100462039': 0, '5100462040': 0, '5100462041': 0, '5100462042': 0, '5100462043': 0, '5100462044': 0, '5100462045': 0, '5100462046': 0, '5100462047': 0, '5100462048': 0, '5100462050': 0, '5100462051': 0, '5100462052': 0, '5100462053': 0, '5100462054': 0, '5100462055': 0, '5100462057': 0, '5100462058': 0, '5100462059': 0, '5100462061': 0, '5100462062': 0, '5100462063': 0, '5100462064': 0, '5100462066': 0, '5100462067': 0, '5100462068': 0, '5100462069': 0, '5100462070': 0, '5100462071': 0, '5100462072': 0, '5100462074': 0, '5100462075': 0, '5100462077': 0, '5100462078': 0, '5100462079': 0, '5100462080': 0, '5100462081': 0, '5100462082': 0, '5100471001': 0, '5100471002': 0, '5100471003': 0, '5100471011': 0, '5100471012': 0, '5100471013': 0, '5100471015': 0, '5100471016': 0, '5100471018': 0, '5100471019': 0, '5100471020': 0, '5100471021': 0, '5100471023': 0, '5100471026': 0, '5100471027': 0, '5100471028': 0, '5100471029': 0, '5100471030': 0, '5100471031': 0, '5100471034': 0, '5100471037': 0, '5100471038': 0, '5100471039': 0, '5100471041': 0, '5100471042': 0, '5100471044': 0, '5100471045': 0, '5100471047': 0, '5100471049': 0, '5100471050': 0, '5100471051': 0, '5100471052': 0, '5100471054': 0, '5100471056': 0, '5100471057': 0, '5100471058': 0, '5100471059': 0, '5100471060': 0, '5100471062': 0, '5100471063': 0, '5100471065': 0, '5100471068': 0, '5100471069': 0, '5100471070': 0, '5100471072': 0, '5100471074': 0, '5100471075': 0, '5100471080': 0, '5100471081': 0, '5100472001': 1, '5100472002': 0, '5100472003': 0, '5100472004': 0, '5100472005': 0, '5100472007': 0, '5100472009': 0, '5100472010': 0, '5100472011': 0, '5100472012': 0, '5100472014': 0, '5100472019': 0, '5100472020': 0, '5100472021': 0, '5100472027': 0, '5100472030': 0, '5100472031': 0, '5100472032': 0, '5100472035': 0, '5100472039': 0, '5100472040': 0, '5100472041': 0, '5100472042': 0, '5100472044': 0, '5100472045': 0, '5100472047': 0, '5100472050': 0, '5100472052': 0, '5100472053': 0, '5100472054': 0, '5100472058': 1, '5100472060': 0, '5100472063': 0, '5100472064': 0, '5221290110': 0, '5221290111': 0, '5221290112': 0, '5221290114': 0, '5221290115': 0, '5221290116': 0, '5221290118': 0, '5221290119': 0, '5221290121': 0, '5221290122': 0, '5221290123': 0, '5221290124': 0, '5221290126': 0, '5221290127': 0, '5221290129': 0, '522129013': 0, '5221290131': 0, '5221290132': 0, '5221290134': 0, '5221290135': 0, '5221290137': 0, '5221290138': 0, '5221290140': 0, '5221290141': 0, '5221290142': 0, '5221290144': 0, '5221290145': 0, '5221290147': 0, '5221290149': 0, '5221290150': 0, '5221290151': 0, '5221290155': 0, '5221290158': 0, '522129016': 0, '5221290161': 0, '5221290162': 0, '5221290163': 0, '5221290164': 0, '5221290165': 0, '5221290166': 0, '5221290167': 0, '5221290169': 0, '522129017': 0, '5221290171': 0, '5221290172': 0, '5221290173': 0, '5221290174': 0, '5221290175': 0, '5221290177': 0, '5221290178': 0, '5221290179': 0, '522129018': 0, '5221290180': 0, '5221290184': 0, '522129021': 0, '5221290210': 0, '5221290212': 0, '5221290213': 0, '5221290214': 0, '5221290215': 0, '5221290216': 0, '5221290217': 0, '522129022': 0, '5221290220': 0, '5221290221': 0, '5221290222': 0, '5221290223': 0, '5221290226': 0, '5221290227': 0, '5221290228': 0, '5221290230': 0, '5221290231': 0, '5221290235': 0, '5221290237': 0, '5221290238': 0, '5221290239': 0, '522129024': 0, '5221290240': 0, '5221290242': 0, '5221290247': 0, '5221290249': 0, '522129025': 0, '5221290250': 0, '5221290251': 0, '5221290252': 0, '5221290253': 0, '5221290254': 0, '5221290255': 0, '5221290256': 0, '5221290257': 0, '5221290258': 0, '5221290259': 0, '522129026': 0, '5221290263': 0, '5221290264': 0, '5221290266': 0, '5221290268': 0, '5221290269': 0, '522129027': 0, '5221290270': 0, '5221290271': 0, '5221290272': 0, '5221290273': 0, '5221290274': 0, '5221290275': 0, '5221290279': 0, '5221290280': 1, '5221290282': 0, '5221290284': 0, '5564630110': 0, '5564630112': 0, '5564630115': 0, '5564630117': 0, '556463012': 0, '5564630121': 0, '5564630122': 0, '5564630123': 0, '5564630126': 1, '5564630127': 0, '5564630128': 0, '5564630129': 0, '556463013': 0, '5564630130': 0, '5564630132': 1, '5564630133': 0, '5564630134': 0, '5564630135': 0, '5564630137': 1, '5564630138': 1, '5564630139': 0, '556463014': 1, '5564630140': 0, '5564630141': 1, '5564630142': 0, '5564630143': 0, '5564630145': 0, '5564630147': 0, '5564630148': 0, '5564630149': 0, '5564630150': 0, '5564630152': 0, '5564630153': 0, '5564630154': 1, '5564630156': 1, '5564630157': 0, '5564630158': 0, '556463016': 0, '5564630160': 0, '5564630161': 0, '5564630162': 0, '5564630163': 0, '5564630165': 0, '5564630166': 0, '5564630167': 0, '5564630168': 1, '556463018': 0, '556463019': 0, '5564630211': 1, '5564630212': 0, '5564630213': 0, '5564630215': 0, '5564630216': 0, '5564630217': 0, '5564630218': 0, '5564630219': 0, '556463022': 1, '5564630221': 0, '5564630222': 0, '5564630226': 1, '5564630228': 0, '5564630229': 0, '5564630230': 0, '5564630232': 0, '5564630233': 0, '5564630234': 0, '5564630235': 0, '5564630236': 0, '5564630237': 0, '5564630238': 1, '556463024': 0, '5564630240': 0, '5564630241': 0, '5564630247': 0, '5564630249': 0, '556463025': 1, '5564630252': 0, '5564630253': 0, '5564630254': 0, '5564630256': 0, '5564630257': 1, '5564630258': 0, '556463026': 0, '5564630261': 0, '5564630262': 0, '5564630264': 0, '5564630265': 0, '5564630269': 0, '556463027': 0, '5564630273': 0, '5564630275': 0, '5564630276': 0, '556463028': 0, '5564630281': 0, '556463029': 0, '567496011': 0, '5674960111': 0, '5674960114': 0, '5674960115': 0, '5674960116': 0, '5674960117': 0, '5674960118': 0, '5674960121': 0, '5674960123': 0, '5674960124': 0, '5674960125': 0, '5674960126': 0, '567496013': 0, '5674960131': 0, '5674960132': 0, '5674960134': 0, '5674960136': 0, '5674960138': 0, '567496014': 0, '5674960142': 0, '5674960144': 0, '5674960145': 0, '5674960146': 0, '5674960148': 0, '5674960151': 0, '5674960153': 0, '5674960154': 0, '5674960155': 1, '5674960156': 0, '5674960157': 0, '5674960158': 0, '5674960160': 0, '5674960161': 0, '5674960166': 0, '567496017': 0, '5674960170': 0, '567496018': 0, '567496019': 0, '567496021': 1, '5674960211': 0, '5674960215': 0, '5674960216': 0, '5674960219': 0, '567496022': 1, '5674960220': 0, '5674960221': 0, '5674960222': 1, '5674960224': 0, '5674960225': 1, '5674960227': 0, '5674960228': 0, '5674960229': 0, '5674960230': 0, '5674960234': 0, '5674960235': 0, '567496024': 0, '5674960242': 0, '5674960246': 0, '5674960249': 0, '5674960251': 0, '5674960252': 0, '5674960255': 0, '5674960257': 0, '567496026': 0, '5674960261': 0, '5674960264': 0, '5674960268': 0, '5674960272': 0, '5674960273': 0, '5674960274': 0, '5674960275': 0, '5674960276': 0, '5674960277': 0, '5674960278': 0, '5674960279': 0, '567496028': 0, '5674960281': 0, '5674960282': 0, '5674960283': 1, '567496029': 0, '5912920111': 0, '5912920112': 0, '5912920113': 0, '5912920114': 0, '5912920119': 0, '5912920121': 0, '5912920123': 0, '5912920124': 0, '5912920125': 0, '5912920126': 0, '5912920127': 0, '5912920128': 1, '5912920129': 0, '5912920131': 0, '5912920133': 0, '5912920135': 0, '5912920137': 0, '5912920140': 0, '5912920142': 0, '5912920143': 0, '5912920145': 0, '5912920146': 0, '5912920147': 0, '5912920148': 0, '5912920149': 0, '591292015': 0, '5912920151': 0, '5912920152': 0, '5912920154': 0, '5912920156': 0, '5912920158': 0, '5912920159': 0, '5912920160': 0, '5912920163': 0, '5912920167': 0, '5912920168': 0, '5912920169': 0, '5912920170': 0, '5912920171': 0, '5912920172': 0, '591292019': 0, '591292021': 0, '5912920211': 0, '5912920212': 0, '5912920213': 0, '5912920216': 0, '5912920217': 0, '5912920220': 0, '5912920222': 0, '5912920223': 0, '5912920225': 0, '5912920227': 0, '5912920228': 0, '5912920230': 0, '5912920231': 0, '5912920233': 0, '5912920234': 0, '5912920235': 0, '5912920236': 0, '5912920239': 0, '591292024': 0, '5912920240': 0, '5912920241': 0, '5912920242': 0, '5912920243': 0, '5912920244': 0, '5912920245': 0, '5912920249': 0, '5912920250': 0, '5912920256': 0, '5912920260': 0, '5912920263': 0, '5912920265': 0, '5912920266': 0, '5912920267': 0, '5912920268': 0, '5912920273': 0, '5912920274': 0, '5912920275': 0, '5912920276': 0, '5912920277': 0, '5912920279': 0, '5912920280': 0, '769862011': 0, '7698620112': 0, '7698620113': 0, '7698620115': 0, '7698620116': 0, '7698620118': 0, '7698620120': 0, '7698620122': 0, '7698620123': 0, '7698620126': 0, '7698620129': 0, '7698620130': 0, '7698620131': 0, '7698620132': 0, '7698620133': 0, '7698620134': 0, '7698620136': 0, '7698620138': 0, '7698620139': 0, '769862014': 0, '7698620141': 0, '7698620144': 0, '7698620145': 0, '7698620149': 0, '769862015': 0, '7698620150': 0, '7698620151': 0, '7698620152': 0, '7698620153': 0, '7698620156': 0, '7698620158': 0, '769862016': 0, '7698620160': 0, '7698620161': 0, '7698620163': 0, '7698620165': 0, '7698620166': 0, '7698620167': 0, '7698620169': 0, '769862017': 1, '7698620170': 0, '7698620171': 0, '769862018': 0, '769862019': 0, '769862021': 0, '7698620211': 0, '7698620212': 0, '7698620217': 0, '7698620218': 0, '769862022': 0, '7698620221': 0, '7698620222': 0, '7698620224': 0, '7698620225': 0, '7698620227': 0, '7698620229': 0, '7698620230': 0, '7698620231': 0, '7698620233': 1, '7698620236': 0, '7698620238': 0, '7698620239': 0, '7698620240': 0, '7698620241': 0, '7698620244': 0, '7698620245': 0, '7698620248': 0, '7698620250': 0, '7698620252': 1, '7698620253': 0, '7698620255': 0, '7698620256': 0, '7698620257': 0, '7698620258': 0, '7698620260': 0, '7698620261': 0, '7698620262': 0, '7698620264': 0, '7698620265': 0, '7698620267': 0, '7698620268': 0, '769862027': 0, '7698620270': 0, '7698620272': 0, '7698620274': 0, '7698620275': 0, '7698620278': 0, '769862028': 0, '7698620281': 0, '7698620283': 0, '7994020110': 0, '79940201100': 0, '79940201110': 0, '79940201140': 0, '79940201150': 0, '79940201160': 0, '79940201180': 0, '79940201210': 0, '79940201230': 0, '79940201250': 0, '79940201270': 0, '7994020130': 0, '79940201300': 1, '79940201320': 0, '79940201330': 0, '79940201340': 0, '79940201350': 0, '79940201360': 0, '79940201370': 0, '79940201380': 0, '79940201390': 1, '7994020140': 0, '79940201410': 0, '79940201420': 0, '79940201430': 0, '79940201470': 0, '79940201490': 0, '79940201510': 0, '79940201560': 0, '79940201570': 0, '79940201580': 0, '7994020160': 0, '79940201620': 0, '79940201650': 0, '79940201660': 1, '79940201690': 0, '79940201700': 0, '79940201710': 0, '79940201720': 0, '79940201730': 0, '79940201740': 0, '79940201750': 0, '79940201760': 0, '79940201770': 0, '79940201780': 0, '79940201790': 1, '79940201810': 0, '79940201820': 0, '79940201850': 0, '79940201860': 0, '79940201880': 0, '79940201930': 0, '79940201950': 0, '79940202100': 0, '79940202120': 0, '79940202130': 0, '79940202140': 0, '79940202160': 0, '79940202170': 0, '79940202180': 0, '79940202190': 0, '79940202200': 0, '79940202210': 0, '79940202220': 0, '79940202230': 0, '79940202270': 1, '79940202280': 1, '7994020230': 1, '79940202300': 0, '79940202310': 1, '79940202320': 0, '79940202340': 0, '79940202350': 0, '79940202370': 0, '79940202390': 0, '79940202400': 0, '79940202410': 0, '79940202450': 0, '79940202470': 0, '79940202480': 0, '79940202490': 1, '7994020250': 0, '79940202510': 0, '79940202520': 0, '79940202540': 0, '79940202560': 0, '79940202570': 0, '79940202580': 0, '79940202620': 0, '79940202690': 0, '7994020270': 0, '79940202700': 0, '79940202710': 0, '79940202750': 0, '79940202760': 0, '79940202790': 0, '7994020280': 0, '79940202800': 1, '79940202820': 0, '79940202840': 1, '79940202850': 1, '79940202860': 1, '79940202870': 0, '79940202890': 0, '7994020290': 0, '8263820112': 0, '8263820113': 0, '8263820120': 0, '8263820123': 0, '8263820124': 0, '8263820126': 0, '8263820132': 0, '8263820135': 0, '8263820136': 0, '8263820138': 0, '8263820139': 0, '8263820140': 0, '8263820141': 0, '8263820144': 0, '8263820145': 0, '8263820146': 0, '8263820147': 0, '8263820148': 0, '826382015': 0, '8263820150': 0, '8263820151': 0, '8263820152': 0, '8263820155': 0, '8263820156': 0, '8263820159': 0, '826382016': 0, '8263820160': 0, '8263820162': 0, '8263820165': 0, '8263820169': 0, '8263820170': 0, '826382018': 0, '826382021': 0, '8263820210': 0, '8263820211': 0, '8263820212': 0, '8263820213': 0, '8263820214': 0, '8263820221': 0, '8263820223': 0, '8263820224': 0, '8263820227': 0, '8263820228': 0, '826382023': 0, '8263820231': 0, '8263820233': 0, '8263820234': 0, '8263820235': 0, '8263820237': 0, '8263820239': 0, '826382024': 1, '8263820240': 0, '8263820242': 0, '8263820243': 0, '8263820245': 0, '8263820246': 0, '8263820247': 0, '8263820251': 0, '8263820253': 0, '8263820254': 0, '8263820255': 0, '8263820256': 0, '8263820257': 0, '8263820259': 0, '826382026': 0, '8263820260': 0, '8263820264': 0, '8263820265': 0, '8263820266': 0, '8263820268': 0, '8263820269': 0, '826382027': 0, '8263820272': 0, '8263820273': 0, '8263820275': 0, '8263820277': 0, '8263820278': 0, '8263820279': 0, '826382028': 0, '826412010': 0, '8264120110': 0, '8264120111': 0, '8264120112': 0, '8264120113': 0, '8264120116': 1, '8264120117': 0, '8264120119': 0, '8264120120': 1, '8264120121': 0, '8264120122': 0, '8264120123': 1, '8264120124': 0, '8264120125': 0, '8264120126': 0, '8264120127': 1, '826412013': 1, '8264120131': 0, '8264120132': 0, '8264120136': 0, '8264120139': 0, '8264120141': 0, '8264120144': 0, '8264120145': 0, '8264120146': 0, '8264120149': 0, '8264120150': 1, '8264120156': 1, '8264120157': 0, '8264120159': 0, '8264120165': 0, '8264120166': 0, '8264120169': 1, '826412017': 0, '826412018': 0, '826412019': 0, '8264120210': 0, '8264120211': 1, '8264120213': 0, '8264120215': 0, '8264120216': 0, '8264120218': 0, '8264120219': 0, '8264120220': 0, '8264120221': 0, '8264120223': 0, '8264120224': 0, '8264120227': 0, '8264120228': 0, '8264120229': 0, '826412023': 0, '8264120231': 1, '8264120232': 0, '8264120233': 0, '8264120234': 0, '8264120239': 1, '826412024': 0, '8264120240': 1, '8264120241': 0, '8264120242': 0, '8264120243': 1, '8264120245': 0, '8264120247': 0, '8264120248': 0, '8264120249': 1, '826412025': 0, '8264120254': 1, '8264120256': 1, '8264120257': 0, '8264120258': 0, '8264120261': 1, '8264120262': 1, '8264120263': 1, '8264120265': 1, '8264120266': 1, '8264120268': 0, '8264120269': 1, '826412027': 0, '8264120274': 0, '8264120275': 0, '8264120279': 1, '8264120280': 0, '8264120282': 1, '8264120284': 1, '88265401100': 0, '88265401130': 0, '88265401140': 0, '88265401150': 0, '88265401160': 0, '88265401170': 0, '88265401190': 0, '8826540120': 0, '88265401200': 0, '88265401240': 0, '88265401260': 0, '88265401270': 0, '88265401280': 0, '88265401300': 0, '88265401320': 0, '88265401350': 0, '88265401360': 0, '88265401380': 0, '88265401390': 0, '88265401400': 0, '88265401410': 0, '88265401420': 0, '88265401430': 0, '88265401450': 0, '88265401470': 0, '88265401480': 0, '88265401490': 0, '8826540150': 0, '88265401520': 0, '88265401550': 0, '88265401630': 0, '88265401640': 0, '88265401660': 0, '88265401690': 0, '8826540170': 0, '88265401730': 0, '88265401740': 0, '88265401750': 1, '8826540180': 0, '88265402120': 0, '88265402150': 0, '88265402160': 0, '88265402170': 0, '88265402180': 0, '88265402190': 0, '88265402200': 0, '88265402230': 0, '88265402240': 0, '88265402270': 0, '8826540230': 0, '88265402300': 0, '88265402310': 0, '88265402320': 0, '88265402330': 0, '88265402340': 0, '88265402350': 0, '88265402370': 0, '88265402380': 0, '8826540240': 0, '88265402400': 0, '88265402420': 0, '88265402440': 0, '88265402450': 0, '88265402480': 0, '88265402490': 0, '88265402500': 0, '88265402520': 0, '88265402540': 0, '88265402570': 0, '88265402580': 0, '88265402590': 0, '8826540260': 0, '88265402600': 0, '88265402630': 0, '88265402660': 0, '88265402690': 0, '8826540270': 0, '88265402700': 0, '88265402770': 0, '88265402780': 0, '88265402790': 0, '8826540280': 0, '88265402800': 0, '88265402810': 0, '88265402820': 0, '88265402840': 0, '88265402850': 0, '88265402880': 0, '88265402890': 0, '8826540290': 0, '88265402900': 0, '907001100': 0, '9070011010': 0, '9070011020': 0, '9070011060': 0, '9070011090': 0, '907001110': 0, '9070011110': 0, '907001120': 0, '907001150': 0, '907001160': 0, '907001170': 0, '907001180': 0, '907001210': 0, '907001220': 0, '907001240': 0, '907001270': 0, '907001280': 0, '907001310': 0, '907001340': 0, '907001350': 0, '907001360': 0, '907001370': 0, '907001400': 0, '907001430': 0, '907001450': 0, '907001480': 1, '907001490': 0, '90700150': 0, '907001500': 0, '907001520': 0, '907001550': 0, '907001560': 0, '907001570': 0, '907001580': 0, '90700160': 0, '907001600': 0, '907001620': 0, '907001650': 0, '907001670': 0, '907001680': 0, '90700170': 0, '907001730': 0, '907001740': 0, '907001780': 0, '907001790': 0, '90700180': 0, '907001820': 0, '907001840': 0, '907001850': 0, '907001860': 0, '90700190': 0, '907001910': 0, '907001940': 0, '907001950': 1, '907001970': 0, '9289010111': 0, '9289010112': 0, '9289010113': 0, '9289010114': 1, '9289010115': 0, '9289010117': 0, '9289010118': 0, '9289010119': 0, '9289010120': 0, '9289010121': 0, '9289010127': 0, '928901013': 0, '9289010131': 0, '9289010132': 0, '9289010133': 0, '9289010134': 0, '9289010138': 0, '9289010139': 0, '928901014': 1, '9289010143': 0, '9289010144': 0, '9289010145': 1, '9289010147': 0, '9289010149': 0, '9289010150': 0, '9289010151': 0, '9289010152': 1, '9289010153': 0, '9289010154': 0, '9289010155': 0, '9289010157': 0, '9289010158': 0, '928901016': 0, '9289010160': 0, '9289010161': 0, '9289010163': 0, '9289010166': 0, '9289010167': 0, '928901018': 0, '9289010210': 0, '9289010211': 0, '9289010216': 0, '9289010221': 0, '9289010222': 0, '9289010223': 0, '9289010227': 0, '9289010229': 0, '928901023': 0, '9289010230': 0, '9289010231': 0, '9289010232': 0, '9289010233': 0, '9289010235': 0, '9289010242': 0, '9289010243': 0, '9289010244': 0, '9289010245': 0, '9289010248': 0, '9289010249': 0, '928901025': 0, '9289010250': 0, '9289010251': 0, '9289010253': 0, '9289010254': 0, '9289010257': 0, '9289010259': 0, '928901026': 0, '9289010261': 0, '9289010262': 0, '9289010263': 0, '9289010265': 0, '9289010266': 0, '9289010267': 0, '9289010268': 0, '9289010269': 0, '9289010270': 0, '9289010271': 0, '9289010273': 0, '9289010274': 0, '9289010275': 0, '9289010276': 1, '9289010278': 0, '928901028': 0, '928901029': 0, '940328011': 0, '9403280110': 0, '9403280112': 0, '9403280114': 0, '9403280115': 0, '9403280116': 0, '9403280117': 0, '940328012': 0, '9403280126': 0, '9403280129': 0, '9403280132': 0, '9403280134': 0, '9403280136': 0, '9403280138': 0, '940328014': 0, '9403280140': 0, '9403280143': 0, '9403280145': 0, '9403280146': 0, '9403280147': 0, '9403280149': 0, '9403280150': 0, '9403280151': 0, '9403280152': 0, '9403280155': 0, '9403280156': 0, '9403280157': 0, '9403280159': 0, '940328016': 0, '9403280164': 0, '9403280165': 0, '9403280167': 0, '940328017': 0, '940328018': 0, '9403280212': 0, '9403280213': 0, '9403280217': 0, '9403280218': 0, '9403280219': 0, '940328022': 0, '9403280227': 0, '9403280229': 0, '9403280234': 0, '9403280235': 0, '9403280236': 0, '9403280238': 0, '9403280241': 0, '9403280243': 0, '9403280245': 0, '9403280246': 0, '9403280247': 0, '9403280249': 0, '9403280250': 0, '9403280251': 0, '9403280254': 0, '9403280255': 0, '9403280256': 0, '9403280259': 0, '9403280260': 0, '9403280262': 0, '9403280265': 0, '9403280266': 0, '9403280271': 1, '9403280272': 0, '9403280273': 0, '9403280277': 0, '9403280279': 0, '9877360111': 0, '9877360113': 0, '9877360114': 0, '9877360115': 0, '9877360116': 0, '9877360117': 0, '9877360120': 1, '9877360121': 0, '9877360124': 0, '9877360125': 0, '9877360126': 0, '9877360127': 0, '9877360128': 0, '9877360130': 0, '9877360131': 0, '9877360132': 0, '9877360133': 1, '9877360134': 0, '9877360135': 0, '9877360138': 0, '987736014': 0, '9877360140': 0, '9877360141': 0, '9877360143': 0, '9877360147': 0, '9877360149': 0, '987736015': 0, '9877360151': 0, '9877360152': 0, '9877360154': 0, '9877360156': 0, '9877360157': 1, '9877360158': 0, '9877360159': 0, '987736016': 0, '9877360163': 0, '9877360164': 0, '9877360165': 0, '9877360166': 0, '9877360168': 0, '9877360169': 1}\n"
     ]
    }
   ],
   "source": [
    "ENGAGE_WILD_DATASET, BIN_CLASSIFICATION, N_CLASSES, DATASET_NAME, BASE_DATASET_DIR, ext = define_dataset(False, True)\n",
    "video2label, labels_list = get_video2label()\n",
    "print(labels_list)\n",
    "print(video2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2541821e-e6ec-400f-954c-f01eeb373001",
   "metadata": {},
   "source": [
    "### Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edff7cbe-da8d-4a85-a469-82d59bf8867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.std\n",
    "stat_name = \"std\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c864c9ce-7841-4dfe-8905-1c604c5978f3",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f8fa8b1-be1b-403a-8b7d-fb91113e6052",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba7a8a78-8b27-44c6-91a8-3179d9feff9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d67b23ce-9a74-45ab-988e-9e1d7ac077e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "test:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n",
      "val:\n",
      "0 1537/1720: 89.36046511627907%\n",
      "1 183/1720: 10.63953488372093%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9df74c-95bb-4f52-aee9-c6070241db66",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46f1fad7-e908-436d-834c-465f7ba9cde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e01f7066-7ddc-4d30-a777-e8d939dc81e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba540def-94f3-4282-8fa7-2b801357662b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9046ef9-cee2-458d-8a5e-0c9af19c5e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5234  248] {0: 1.0, 1: 21.10483870967742} 2 [0 1]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "628ebe73-b2bb-40ff-a607-6919212d1f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 21:14:39.863028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "#save_best_model = SaveBestModelByUAR(X_subsample_val, y_subsample_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d98f4f3f-ffa9-4c47-971b-28c0548918a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 21:14:49.383482: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8884061ed0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-11 21:14:49.383666: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-08-11 21:14:49.387767: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-11 21:14:49.438957: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-08-11 21:14:49.494201: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 7s 88ms/step - loss: 1.2773 - acc: 0.6638 - auc: 0.6550 - binary_accuracy: 0.6638 - recall: 0.5806 - precision: 0.0765 - val_loss: 0.7971 - val_acc: 0.5459 - val_auc: 0.6771 - val_binary_accuracy: 0.5459 - val_recall: 0.7814 - val_precision: 0.1618\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 1.0950 - acc: 0.7335 - auc: 0.7709 - binary_accuracy: 0.7335 - recall: 0.6895 - precision: 0.1100 - val_loss: 0.8405 - val_acc: 0.5233 - val_auc: 0.6811 - val_binary_accuracy: 0.5233 - val_recall: 0.8197 - val_precision: 0.1601\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 1.0397 - acc: 0.7202 - auc: 0.8012 - binary_accuracy: 0.7202 - recall: 0.7218 - precision: 0.1089 - val_loss: 0.6223 - val_acc: 0.6535 - val_auc: 0.6792 - val_binary_accuracy: 0.6535 - val_recall: 0.6011 - val_precision: 0.1738\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 1.0171 - acc: 0.7435 - auc: 0.8079 - binary_accuracy: 0.7435 - recall: 0.7056 - precision: 0.1160 - val_loss: 0.5950 - val_acc: 0.6779 - val_auc: 0.6791 - val_binary_accuracy: 0.6779 - val_recall: 0.5738 - val_precision: 0.1807\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.9549 - acc: 0.7598 - auc: 0.8362 - binary_accuracy: 0.7598 - recall: 0.7137 - precision: 0.1244 - val_loss: 0.5690 - val_acc: 0.6971 - val_auc: 0.6727 - val_binary_accuracy: 0.6971 - val_recall: 0.4973 - val_precision: 0.1750\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.9446 - acc: 0.7481 - auc: 0.8388 - binary_accuracy: 0.7481 - recall: 0.7782 - precision: 0.1271 - val_loss: 0.5155 - val_acc: 0.7250 - val_auc: 0.6756 - val_binary_accuracy: 0.7250 - val_recall: 0.4590 - val_precision: 0.1834\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.9164 - acc: 0.7705 - auc: 0.8503 - binary_accuracy: 0.7705 - recall: 0.7581 - precision: 0.1356 - val_loss: 0.6771 - val_acc: 0.6122 - val_auc: 0.6790 - val_binary_accuracy: 0.6122 - val_recall: 0.6011 - val_precision: 0.1562\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.9193 - acc: 0.7578 - auc: 0.8465 - binary_accuracy: 0.7578 - recall: 0.7460 - precision: 0.1276 - val_loss: 0.4831 - val_acc: 0.7564 - val_auc: 0.6728 - val_binary_accuracy: 0.7564 - val_recall: 0.4044 - val_precision: 0.1927\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.8769 - acc: 0.7795 - auc: 0.8644 - binary_accuracy: 0.7795 - recall: 0.7621 - precision: 0.1412 - val_loss: 0.5474 - val_acc: 0.7238 - val_auc: 0.6722 - val_binary_accuracy: 0.7238 - val_recall: 0.4809 - val_precision: 0.1880\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.8595 - acc: 0.7833 - auc: 0.8681 - binary_accuracy: 0.7833 - recall: 0.7540 - precision: 0.1423 - val_loss: 0.4756 - val_acc: 0.7657 - val_auc: 0.6667 - val_binary_accuracy: 0.7657 - val_recall: 0.3934 - val_precision: 0.1978\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.8469 - acc: 0.7858 - auc: 0.8766 - binary_accuracy: 0.7858 - recall: 0.8266 - precision: 0.1534 - val_loss: 0.5813 - val_acc: 0.6872 - val_auc: 0.6823 - val_binary_accuracy: 0.6872 - val_recall: 0.5301 - val_precision: 0.1767\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.7949 - acc: 0.7931 - auc: 0.8907 - binary_accuracy: 0.7931 - recall: 0.8145 - precision: 0.1566 - val_loss: 0.5166 - val_acc: 0.7494 - val_auc: 0.6716 - val_binary_accuracy: 0.7494 - val_recall: 0.3934 - val_precision: 0.1837\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.7696 - acc: 0.8065 - auc: 0.8992 - binary_accuracy: 0.8065 - recall: 0.8185 - precision: 0.1665 - val_loss: 0.5821 - val_acc: 0.6971 - val_auc: 0.6666 - val_binary_accuracy: 0.6971 - val_recall: 0.4973 - val_precision: 0.1750\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.7545 - acc: 0.7984 - auc: 0.9025 - binary_accuracy: 0.7984 - recall: 0.8427 - precision: 0.1639 - val_loss: 0.5970 - val_acc: 0.6965 - val_auc: 0.6641 - val_binary_accuracy: 0.6965 - val_recall: 0.4754 - val_precision: 0.1696\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.7377 - acc: 0.8147 - auc: 0.9066 - binary_accuracy: 0.8147 - recall: 0.8145 - precision: 0.1724 - val_loss: 0.5117 - val_acc: 0.7570 - val_auc: 0.6644 - val_binary_accuracy: 0.7570 - val_recall: 0.3716 - val_precision: 0.1833\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.7260 - acc: 0.8242 - auc: 0.9099 - binary_accuracy: 0.8242 - recall: 0.8105 - precision: 0.1798 - val_loss: 0.5777 - val_acc: 0.7128 - val_auc: 0.6403 - val_binary_accuracy: 0.7128 - val_recall: 0.3989 - val_precision: 0.1597\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.6855 - acc: 0.8300 - auc: 0.9209 - binary_accuracy: 0.8300 - recall: 0.8589 - precision: 0.1919 - val_loss: 0.6321 - val_acc: 0.6901 - val_auc: 0.6640 - val_binary_accuracy: 0.6901 - val_recall: 0.4863 - val_precision: 0.1686\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.6713 - acc: 0.8271 - auc: 0.9239 - binary_accuracy: 0.8271 - recall: 0.8871 - precision: 0.1930 - val_loss: 0.6796 - val_acc: 0.6669 - val_auc: 0.6497 - val_binary_accuracy: 0.6669 - val_recall: 0.5246 - val_precision: 0.1649\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.6471 - acc: 0.8424 - auc: 0.9303 - binary_accuracy: 0.8424 - recall: 0.8548 - precision: 0.2038 - val_loss: 0.6873 - val_acc: 0.6581 - val_auc: 0.6298 - val_binary_accuracy: 0.6581 - val_recall: 0.4699 - val_precision: 0.1490\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.6525 - acc: 0.8263 - auc: 0.9282 - binary_accuracy: 0.8263 - recall: 0.9032 - precision: 0.1944 - val_loss: 0.6638 - val_acc: 0.6855 - val_auc: 0.6458 - val_binary_accuracy: 0.6855 - val_recall: 0.4536 - val_precision: 0.1584\n",
      "0.4756067395210266\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8892bcd3-66f0-4fca-884f-bc7594dacbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_2765461/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e55f1bcd-dfa3-4c83-a4be-8c663a0a06dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional Accuracy:  0.4712710388856645 MSE:  0.5287289611143354 UAR:  0.6326833297421532 Recall:  0.8117647058823529 Precision:  0.07157676348547717 F1:  0.1315538608198284\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional Accuracy:  0.6482878699941962 MSE:  0.3517121300058038 UAR:  0.6588594412123824 Recall:  0.6705882352941176 Precision:  0.08976377952755905 F1:  0.15833333333333333\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional Accuracy:  0.7382472431804992 MSE:  0.2617527568195009 UAR:  0.6727106227106228 Recall:  0.6 Precision:  0.10897435897435898 F1:  0.18444846292947562\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional Accuracy:  0.803830528148578 MSE:  0.19616947185142194 UAR:  0.6737412913883503 Recall:  0.5294117647058824 Precision:  0.13119533527696792 F1:  0.2102803738317757\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional Accuracy:  0.8496807893209518 MSE:  0.15031921067904816 UAR:  0.6699705523234936 Recall:  0.47058823529411764 Precision:  0.15748031496062992 F1:  0.23598820058997047\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional Accuracy:  0.8891468369123622 MSE:  0.11085316308763785 UAR:  0.6628420599008834 Recall:  0.4117647058823529 Precision:  0.19886363636363635 F1:  0.2681992337164751\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional Accuracy:  0.9082994776552524 MSE:  0.09170052234474753 UAR:  0.6450298067945127 Recall:  0.35294117647058826 Precision:  0.22556390977443608 F1:  0.27522935779816515\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional Accuracy:  0.9291932675565874 MSE:  0.07080673244341265 UAR:  0.6114019966961144 Recall:  0.25882352941176473 Precision:  0.2716049382716049 F1:  0.2650602409638554\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional Accuracy:  0.9437028438769588 MSE:  0.05629715612304121 UAR:  0.5799935358758888 Recall:  0.17647058823529413 Precision:  0.35714285714285715 F1:  0.23622047244094493\n",
      "0.4 0.6737412913883503\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb2c40a8-8ab7-4e44-a09f-f72d4a25a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33dfe327-5d8c-432e-b4ef-62d479bacb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_2765461/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd2e5b90-1b18-489e-883e-56ca79521b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.4097504352872896 MSE:  0.5902495647127104 UAR:  0.6226352079293256 Recall:  0.8588235294117647 Precision:  0.06771799628942486 F1:  0.12553740326741186\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.6111433546140452 MSE:  0.3888566453859547 UAR:  0.6839402427637722 Recall:  0.7647058823529411 Precision:  0.09090909090909091 F1:  0.1625\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.7777132907719094 MSE:  0.22228670922809055 UAR:  0.676736335559865 Recall:  0.5647058823529412 Precision:  0.1218274111675127 F1:  0.20041753653444677\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.865351131746953 MSE:  0.134648868253047 UAR:  0.6559039000215471 Recall:  0.4235294117647059 Precision:  0.1643835616438356 F1:  0.23684210526315785\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.9077190946024376 MSE:  0.0922809053975624 UAR:  0.63357035121741 Recall:  0.32941176470588235 Precision:  0.2153846153846154 F1:  0.26046511627906976\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.934416715031921 MSE:  0.06558328496807893 UAR:  0.6029950441715147 Recall:  0.23529411764705882 Precision:  0.29411764705882354 F1:  0.26143790849673204\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.9489262913522926 MSE:  0.05107370864770749 UAR:  0.5883178912590677 Recall:  0.18823529411764706 Precision:  0.45714285714285713 F1:  0.2666666666666667\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.9529889727219966 MSE:  0.047011027278003485 UAR:  0.5569920275802629 Recall:  0.11764705882352941 Precision:  0.625 F1:  0.19801980198019803\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.9529889727219966 MSE:  0.047011027278003485 UAR:  0.5346836170365582 Recall:  0.07058823529411765 Precision:  0.75 F1:  0.12903225806451613\n",
      "0.2 0.6839402427637722\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4366fef2-77f3-45d4-bda9-a4d01716346e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c83339-8eb2-454e-ab13-0963effd34a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "cb3e3d7d-41c9-4d01-96f9-20ce9170072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ad731708-9dd8-4587-bc1b-98e2dc417d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b2f5463b-fad4-4592-a086-6326e0870a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_6 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_6[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_6[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "fc8cb043-e313-4dd3-bb40-3d8349eed399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 127ms/step - loss: 0.3520 - acc: 0.9435 - auc: 0.5372 - binary_accuracy: 0.9435 - recall_1: 0.0121 - precision_1: 0.0441 - val_loss: 0.3655 - val_acc: 0.8936 - val_auc: 0.6054 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1676 - acc: 0.9544 - auc: 0.7332 - binary_accuracy: 0.9544 - recall_1: 0.0081 - precision_1: 0.3333 - val_loss: 0.4156 - val_acc: 0.8936 - val_auc: 0.6291 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1589 - acc: 0.9533 - auc: 0.7800 - binary_accuracy: 0.9533 - recall_1: 0.0081 - precision_1: 0.1667 - val_loss: 0.3692 - val_acc: 0.8907 - val_auc: 0.6405 - val_binary_accuracy: 0.8907 - val_recall_1: 0.0328 - val_precision_1: 0.3529\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1570 - acc: 0.9538 - auc: 0.7916 - binary_accuracy: 0.9538 - recall_1: 0.0282 - precision_1: 0.3684 - val_loss: 0.4193 - val_acc: 0.8930 - val_auc: 0.6368 - val_binary_accuracy: 0.8930 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1648 - acc: 0.9526 - auc: 0.7644 - binary_accuracy: 0.9526 - recall_1: 0.0403 - precision_1: 0.3125 - val_loss: 0.3956 - val_acc: 0.8936 - val_auc: 0.6295 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1544 - acc: 0.9557 - auc: 0.8021 - binary_accuracy: 0.9557 - recall_1: 0.0524 - precision_1: 0.6190 - val_loss: 0.3884 - val_acc: 0.8942 - val_auc: 0.6372 - val_binary_accuracy: 0.8942 - val_recall_1: 0.0164 - val_precision_1: 0.6000\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1498 - acc: 0.9564 - auc: 0.8126 - binary_accuracy: 0.9564 - recall_1: 0.0726 - precision_1: 0.6667 - val_loss: 0.4350 - val_acc: 0.8936 - val_auc: 0.6258 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1505 - acc: 0.9562 - auc: 0.7941 - binary_accuracy: 0.9562 - recall_1: 0.0927 - precision_1: 0.6053 - val_loss: 0.4107 - val_acc: 0.8936 - val_auc: 0.6443 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1529 - acc: 0.9529 - auc: 0.8132 - binary_accuracy: 0.9529 - recall_1: 0.0565 - precision_1: 0.3684 - val_loss: 0.3560 - val_acc: 0.8901 - val_auc: 0.6600 - val_binary_accuracy: 0.8901 - val_recall_1: 0.0328 - val_precision_1: 0.3333\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1611 - acc: 0.9544 - auc: 0.7951 - binary_accuracy: 0.9544 - recall_1: 0.0766 - precision_1: 0.4750 - val_loss: 0.3404 - val_acc: 0.8919 - val_auc: 0.6709 - val_binary_accuracy: 0.8919 - val_recall_1: 0.0164 - val_precision_1: 0.3333\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1480 - acc: 0.9551 - auc: 0.8080 - binary_accuracy: 0.9551 - recall_1: 0.0645 - precision_1: 0.5333 - val_loss: 0.3748 - val_acc: 0.8791 - val_auc: 0.6659 - val_binary_accuracy: 0.8791 - val_recall_1: 0.0546 - val_precision_1: 0.2222\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1393 - acc: 0.9577 - auc: 0.8477 - binary_accuracy: 0.9577 - recall_1: 0.1169 - precision_1: 0.6905 - val_loss: 0.4060 - val_acc: 0.8843 - val_auc: 0.6437 - val_binary_accuracy: 0.8843 - val_recall_1: 0.0328 - val_precision_1: 0.2143\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1391 - acc: 0.9584 - auc: 0.8543 - binary_accuracy: 0.9584 - recall_1: 0.1694 - precision_1: 0.6562 - val_loss: 0.4013 - val_acc: 0.8913 - val_auc: 0.6270 - val_binary_accuracy: 0.8913 - val_recall_1: 0.0055 - val_precision_1: 0.1667\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1430 - acc: 0.9564 - auc: 0.8307 - binary_accuracy: 0.9564 - recall_1: 0.1250 - precision_1: 0.5849 - val_loss: 0.4422 - val_acc: 0.8936 - val_auc: 0.6349 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0164 - val_precision_1: 0.5000\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1403 - acc: 0.9593 - auc: 0.8408 - binary_accuracy: 0.9593 - recall_1: 0.1532 - precision_1: 0.7451 - val_loss: 0.3936 - val_acc: 0.8860 - val_auc: 0.6520 - val_binary_accuracy: 0.8860 - val_recall_1: 0.0273 - val_precision_1: 0.2174\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1331 - acc: 0.9599 - auc: 0.8623 - binary_accuracy: 0.9599 - recall_1: 0.1815 - precision_1: 0.7258 - val_loss: 0.4326 - val_acc: 0.8890 - val_auc: 0.6155 - val_binary_accuracy: 0.8890 - val_recall_1: 0.0109 - val_precision_1: 0.1667\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1567 - acc: 0.9579 - auc: 0.8211 - binary_accuracy: 0.9579 - recall_1: 0.1855 - precision_1: 0.6133 - val_loss: 0.6409 - val_acc: 0.8901 - val_auc: 0.5315 - val_binary_accuracy: 0.8901 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1939 - acc: 0.9513 - auc: 0.7187 - binary_accuracy: 0.9513 - recall_1: 0.0927 - precision_1: 0.3538 - val_loss: 0.4528 - val_acc: 0.8924 - val_auc: 0.6278 - val_binary_accuracy: 0.8924 - val_recall_1: 0.0109 - val_precision_1: 0.3333\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1382 - acc: 0.9582 - auc: 0.8531 - binary_accuracy: 0.9582 - recall_1: 0.1532 - precision_1: 0.6667 - val_loss: 0.4255 - val_acc: 0.8831 - val_auc: 0.6076 - val_binary_accuracy: 0.8831 - val_recall_1: 0.0328 - val_precision_1: 0.2000\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1471 - acc: 0.9573 - auc: 0.8318 - binary_accuracy: 0.9573 - recall_1: 0.1653 - precision_1: 0.6029 - val_loss: 0.3628 - val_acc: 0.8831 - val_auc: 0.6370 - val_binary_accuracy: 0.8831 - val_recall_1: 0.0273 - val_precision_1: 0.1786\n",
      "0.340364933013916\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f4a97098-009d-4bd1-95a9-f717c54407a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f2948234-3243-41aa-aa2d-abf82f6b1368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.8415554265815438 MSE:  0.1584445734184562 UAR:  0.6043489190548015 Recall:  0.3411764705882353 Precision:  0.11788617886178862 F1:  0.17522658610271902\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.930354033662217 MSE:  0.06964596633778293 UAR:  0.5450872656755009 Recall:  0.11764705882352941 Precision:  0.18181818181818182 F1:  0.14285714285714285\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9437028438769588 MSE:  0.05629715612304121 UAR:  0.5409538174244057 Recall:  0.09411764705882353 Precision:  0.2857142857142857 F1:  0.1415929203539823\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.947185142193848 MSE:  0.05281485780615206 UAR:  0.526054011348129 Recall:  0.058823529411764705 Precision:  0.3125 F1:  0.09900990099009901\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5281907634848811 Recall:  0.058823529411764705 Precision:  0.5555555555555556 F1:  0.10638297872340426\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5229189111542053 Recall:  0.047058823529411764 Precision:  0.6666666666666666 F1:  0.08791208791208792\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9529889727219966 MSE:  0.047011027278003485 UAR:  0.5235294117647059 Recall:  0.047058823529411764 Precision:  1.0 F1:  0.0898876404494382\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5176470588235295 Recall:  0.03529411764705882 Precision:  1.0 F1:  0.06818181818181818\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5117647058823529 Recall:  0.023529411764705882 Precision:  1.0 F1:  0.04597701149425288\n",
      "0.1 0.6043489190548015\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "33cb7345-dcf8-423c-8dcb-d6c977457dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "63a24600-cf63-4a68-8a53-d15c7f2d1de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "cb2dbc3b-e8b8-4033-a12d-3a128606b6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.8340104468949506 MSE:  0.16598955310504934 UAR:  0.6282661782661783 Recall:  0.4 Precision:  0.12639405204460966 F1:  0.192090395480226\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9297736506094022 MSE:  0.0702263493905978 UAR:  0.5949759390935861 Recall:  0.2235294117647059 Precision:  0.25675675675675674 F1:  0.2389937106918239\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9477655252466628 MSE:  0.0522344747533372 UAR:  0.5653989801048624 Recall:  0.1411764705882353 Precision:  0.41379310344827586 F1:  0.21052631578947367\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5566867772750126 Recall:  0.11764705882352941 Precision:  0.5882352941176471 F1:  0.19607843137254902\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9529889727219966 MSE:  0.047011027278003485 UAR:  0.5402607196724843 Recall:  0.08235294117647059 Precision:  0.7 F1:  0.14736842105263157\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5288012640953818 Recall:  0.058823529411764705 Precision:  0.7142857142857143 F1:  0.10869565217391305\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9500870574579222 MSE:  0.04991294254207777 UAR:  0.5052718523306758 Recall:  0.011764705882352941 Precision:  0.3333333333333333 F1:  0.022727272727272728\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5058823529411764 Recall:  0.011764705882352941 Precision:  1.0 F1:  0.023255813953488372\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6282661782661783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e8a9bb-3862-41cf-8874-b1d836f1ed46",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98bc46ed-ccd4-4e43-bbe8-ff63bc3ca5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03f736dc-4ff5-4a26-acb5-4c250e6c3c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e05c0f4-9c24-43a7-bca6-3931ff63e61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "val:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce4cd71e-18dc-4102-84ab-de8e4e5b9d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482,) (5482,)\n",
      "(1723,) (1723,)\n",
      "(7205,) (7205,)\n",
      "[0 1] [6872  333]\n",
      "7205\n",
      "5475\n",
      "1730\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d6a000a-98eb-4664-962f-0d840cd146c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5222/5475: 95.37899543378995%\n",
      "1 253/5475: 4.621004566210046%\n",
      "val:\n",
      "0 1650/1730: 95.3757225433526%\n",
      "1 80/1730: 4.624277456647399%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1246107a-1a3b-48b1-b43a-1182e7388351",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae4302db-ad1a-44bb-ab32-91147ea5ba3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c1ade1e-b384-45ef-b9ba-a814f37845ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1613455f-09ae-455c-89a2-31c678953ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 2560) (5475,)\n",
      "(1730, 128, 2560) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "64d36312-69e4-478a-9713-9c21984fa520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5222  253] {0: 1.0, 1: 20.640316205533598} 2 [0 1]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9675b01-331c-4fac-a5d3-fcbbab3f83b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "#save_best_model = SaveBestModelByUAR(X_subsample_test, y_subsample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "46f45f4a-2ea6-447e-a088-a9c84f47ad23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 78ms/step - loss: 1.3137 - acc: 0.6356 - auc: 0.6562 - binary_accuracy: 0.6356 - recall_1: 0.6008 - precision_1: 0.0743 - val_loss: 0.5989 - val_acc: 0.7451 - val_auc: 0.7696 - val_binary_accuracy: 0.7451 - val_recall_1: 0.6875 - val_precision_1: 0.1168\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 1.0760 - acc: 0.7531 - auc: 0.7792 - binary_accuracy: 0.7531 - recall_1: 0.6719 - precision_1: 0.1181 - val_loss: 0.5128 - val_acc: 0.7780 - val_auc: 0.7834 - val_binary_accuracy: 0.7780 - val_recall_1: 0.6000 - val_precision_1: 0.1200\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 1.0183 - acc: 0.7618 - auc: 0.8149 - binary_accuracy: 0.7618 - recall_1: 0.7115 - precision_1: 0.1276 - val_loss: 0.4452 - val_acc: 0.8197 - val_auc: 0.7822 - val_binary_accuracy: 0.8197 - val_recall_1: 0.5625 - val_precision_1: 0.1398\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 1.0787 - acc: 0.7374 - auc: 0.7809 - binary_accuracy: 0.7374 - recall_1: 0.6561 - precision_1: 0.1094 - val_loss: 0.4091 - val_acc: 0.8821 - val_auc: 0.7871 - val_binary_accuracy: 0.8821 - val_recall_1: 0.4625 - val_precision_1: 0.1869\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.9755 - acc: 0.7682 - auc: 0.8308 - binary_accuracy: 0.7682 - recall_1: 0.7312 - precision_1: 0.1335 - val_loss: 0.5025 - val_acc: 0.7740 - val_auc: 0.7909 - val_binary_accuracy: 0.7740 - val_recall_1: 0.6625 - val_precision_1: 0.1271\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.9285 - acc: 0.7909 - auc: 0.8472 - binary_accuracy: 0.7909 - recall_1: 0.7391 - precision_1: 0.1477 - val_loss: 0.7776 - val_acc: 0.5665 - val_auc: 0.7899 - val_binary_accuracy: 0.5665 - val_recall_1: 0.8250 - val_precision_1: 0.0823\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.9183 - acc: 0.7695 - auc: 0.8504 - binary_accuracy: 0.7695 - recall_1: 0.7747 - precision_1: 0.1399 - val_loss: 0.5218 - val_acc: 0.7572 - val_auc: 0.7725 - val_binary_accuracy: 0.7572 - val_recall_1: 0.6625 - val_precision_1: 0.1188\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.9271 - acc: 0.7814 - auc: 0.8463 - binary_accuracy: 0.7814 - recall_1: 0.7352 - precision_1: 0.1413 - val_loss: 0.4572 - val_acc: 0.8081 - val_auc: 0.7797 - val_binary_accuracy: 0.8081 - val_recall_1: 0.6125 - val_precision_1: 0.1400\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.8753 - acc: 0.7761 - auc: 0.8657 - binary_accuracy: 0.7761 - recall_1: 0.7826 - precision_1: 0.1446 - val_loss: 0.5334 - val_acc: 0.7462 - val_auc: 0.7760 - val_binary_accuracy: 0.7462 - val_recall_1: 0.6500 - val_precision_1: 0.1123\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 29ms/step - loss: 0.8167 - acc: 0.8020 - auc: 0.8871 - binary_accuracy: 0.8020 - recall_1: 0.7945 - precision_1: 0.1630 - val_loss: 0.4170 - val_acc: 0.8116 - val_auc: 0.7796 - val_binary_accuracy: 0.8116 - val_recall_1: 0.6125 - val_precision_1: 0.1424\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.7975 - acc: 0.8079 - auc: 0.8905 - binary_accuracy: 0.8079 - recall_1: 0.8221 - precision_1: 0.1712 - val_loss: 0.4388 - val_acc: 0.8127 - val_auc: 0.7714 - val_binary_accuracy: 0.8127 - val_recall_1: 0.5750 - val_precision_1: 0.1369\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.7855 - acc: 0.8058 - auc: 0.8937 - binary_accuracy: 0.8058 - recall_1: 0.8221 - precision_1: 0.1697 - val_loss: 0.3422 - val_acc: 0.8653 - val_auc: 0.7701 - val_binary_accuracy: 0.8653 - val_recall_1: 0.5625 - val_precision_1: 0.1852\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.8036 - acc: 0.8082 - auc: 0.8878 - binary_accuracy: 0.8082 - recall_1: 0.7905 - precision_1: 0.1671 - val_loss: 0.7721 - val_acc: 0.5890 - val_auc: 0.7764 - val_binary_accuracy: 0.5890 - val_recall_1: 0.8000 - val_precision_1: 0.0843\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.7658 - acc: 0.7945 - auc: 0.8997 - binary_accuracy: 0.7945 - recall_1: 0.8458 - precision_1: 0.1646 - val_loss: 0.3004 - val_acc: 0.8890 - val_auc: 0.7583 - val_binary_accuracy: 0.8890 - val_recall_1: 0.4875 - val_precision_1: 0.2053\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.7239 - acc: 0.8256 - auc: 0.9103 - binary_accuracy: 0.8256 - recall_1: 0.8221 - precision_1: 0.1860 - val_loss: 0.4008 - val_acc: 0.8254 - val_auc: 0.7551 - val_binary_accuracy: 0.8254 - val_recall_1: 0.5875 - val_precision_1: 0.1487\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.7066 - acc: 0.8183 - auc: 0.9157 - binary_accuracy: 0.8183 - recall_1: 0.8379 - precision_1: 0.1818 - val_loss: 0.4122 - val_acc: 0.8098 - val_auc: 0.7274 - val_binary_accuracy: 0.8098 - val_recall_1: 0.5250 - val_precision_1: 0.1261\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.6761 - acc: 0.8311 - auc: 0.9241 - binary_accuracy: 0.8311 - recall_1: 0.8617 - precision_1: 0.1968 - val_loss: 0.4279 - val_acc: 0.8116 - val_auc: 0.7627 - val_binary_accuracy: 0.8116 - val_recall_1: 0.5750 - val_precision_1: 0.1361\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.6356 - acc: 0.8427 - auc: 0.9340 - binary_accuracy: 0.8427 - recall_1: 0.8696 - precision_1: 0.2099 - val_loss: 0.4409 - val_acc: 0.7913 - val_auc: 0.7522 - val_binary_accuracy: 0.7913 - val_recall_1: 0.6000 - val_precision_1: 0.1273\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.6352 - acc: 0.8358 - auc: 0.9314 - binary_accuracy: 0.8358 - recall_1: 0.8854 - precision_1: 0.2048 - val_loss: 0.4320 - val_acc: 0.8098 - val_auc: 0.7644 - val_binary_accuracy: 0.8098 - val_recall_1: 0.5375 - val_precision_1: 0.1284\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.6557 - acc: 0.8402 - auc: 0.9271 - binary_accuracy: 0.8402 - recall_1: 0.8775 - precision_1: 0.2083 - val_loss: 0.4321 - val_acc: 0.8035 - val_auc: 0.7460 - val_binary_accuracy: 0.8035 - val_recall_1: 0.5875 - val_precision_1: 0.1328\n",
      "0.300433874130249\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3f8ad29-ba7a-4529-b3c9-fd964a9faebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_2765461/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0f13c5df-c620-47c3-ad61-dd4fc5aebc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced Accuracy:  0.4184971098265896 MSE:  0.5815028901734104 UAR:  0.6118939393939393 Recall:  0.825 Precision:  0.062381852551984876 F1:  0.11599297012302284\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced Accuracy:  0.5589595375722544 MSE:  0.44104046242774564 UAR:  0.6439015151515152 Recall:  0.7375 Precision:  0.07365792759051186 F1:  0.13393870601589103\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced Accuracy:  0.6485549132947976 MSE:  0.3514450867052023 UAR:  0.6730303030303031 Recall:  0.7 Precision:  0.0875 F1:  0.15555555555555553\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced Accuracy:  0.7375722543352601 MSE:  0.26242774566473986 UAR:  0.6899621212121212 Recall:  0.6375 Precision:  0.10714285714285714 F1:  0.18345323741007194\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced Accuracy:  0.8 MSE:  0.2 UAR:  0.7048484848484848 Recall:  0.6 Precision:  0.13259668508287292 F1:  0.21719457013574658\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced Accuracy:  0.8549132947976879 MSE:  0.14508670520231215 UAR:  0.6920075757575757 Recall:  0.5125 Precision:  0.16205533596837945 F1:  0.24624624624624625\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced Accuracy:  0.8913294797687862 MSE:  0.10867052023121387 UAR:  0.6754166666666667 Recall:  0.4375 Precision:  0.19662921348314608 F1:  0.2713178294573644\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced Accuracy:  0.9213872832369943 MSE:  0.07861271676300578 UAR:  0.6257575757575757 Recall:  0.3 Precision:  0.23076923076923078 F1:  0.2608695652173913\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced Accuracy:  0.9439306358381503 MSE:  0.05606936416184971 UAR:  0.5721590909090909 Recall:  0.1625 Precision:  0.3023255813953488 F1:  0.21138211382113822\n",
      "0.5 0.7048484848484848\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name, from_int=True)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "788c2071-97d6-4c38-b8c4-94bd359d44cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "99a860e3-3a9b-4460-93ab-3499ea74b032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_2765461/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "004ce109-65ab-4eb0-a642-59838a03084e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.47572254335260117 MSE:  0.5242774566473989 UAR:  0.6359469696969697 Recall:  0.8125 Precision:  0.06792058516196448 F1:  0.12536162005785922\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.6566473988439306 MSE:  0.34335260115606936 UAR:  0.6713257575757576 Recall:  0.6875 Precision:  0.08814102564102565 F1:  0.15625\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.7716763005780347 MSE:  0.22832369942196531 UAR:  0.7018939393939394 Recall:  0.625 Precision:  0.12048192771084337 F1:  0.20202020202020202\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.8369942196531792 MSE:  0.1630057803468208 UAR:  0.7064015151515152 Recall:  0.5625 Precision:  0.1541095890410959 F1:  0.24193548387096775\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.8884393063583815 MSE:  0.1115606936416185 UAR:  0.6917424242424242 Recall:  0.475 Precision:  0.20105820105820105 F1:  0.28252788104089216\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.9208092485549133 MSE:  0.07919075144508671 UAR:  0.6670833333333334 Recall:  0.3875 Precision:  0.2605042016806723 F1:  0.31155778894472363\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.9398843930635838 MSE:  0.06011560693641618 UAR:  0.6354545454545455 Recall:  0.3 Precision:  0.3333333333333333 F1:  0.3157894736842105\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.9502890173410404 MSE:  0.04971098265895954 UAR:  0.5873863636363637 Recall:  0.1875 Precision:  0.4166666666666667 F1:  0.2586206896551724\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.5350757575757575 Recall:  0.075 Precision:  0.42857142857142855 F1:  0.1276595744680851\n",
      "0.4 0.7064015151515152\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name, from_int=True)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8353e0d-9e9e-4dbb-b5e9-cf87382fb327",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "20b9c376-486e-427e-9660-7dd838cb42d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a25b6aec-9448-4d0d-9fd9-39bf2e6711e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ee797bfc-b3ad-4e9b-bc12-aa269ad4d83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 2560) (5475,)\n",
      "(1730, 128, 2560) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b171ce19-4ced-4166-bc16-c6d01a658e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_7 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_7[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_7[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "1d824048-840c-468f-8164-7a222209ce2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 125ms/step - loss: 0.3764 - acc: 0.9412 - auc: 0.5374 - binary_accuracy: 0.9412 - recall_3: 0.0277 - precision_3: 0.0843 - val_loss: 0.1875 - val_acc: 0.9526 - val_auc: 0.6787 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0125 - val_precision_3: 0.2500\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1737 - acc: 0.9540 - auc: 0.7014 - binary_accuracy: 0.9540 - recall_3: 0.0514 - precision_3: 0.5200 - val_loss: 0.1701 - val_acc: 0.9526 - val_auc: 0.7431 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0250 - val_precision_3: 0.3333\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1627 - acc: 0.9536 - auc: 0.7562 - binary_accuracy: 0.9536 - recall_3: 0.0435 - precision_3: 0.4783 - val_loss: 0.1690 - val_acc: 0.9526 - val_auc: 0.7421 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1558 - acc: 0.9563 - auc: 0.7868 - binary_accuracy: 0.9563 - recall_3: 0.0751 - precision_3: 0.7917 - val_loss: 0.1788 - val_acc: 0.9532 - val_auc: 0.7731 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1543 - acc: 0.9558 - auc: 0.7960 - binary_accuracy: 0.9558 - recall_3: 0.0870 - precision_3: 0.6667 - val_loss: 0.1673 - val_acc: 0.9468 - val_auc: 0.7855 - val_binary_accuracy: 0.9468 - val_recall_3: 0.0375 - val_precision_3: 0.1667\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1532 - acc: 0.9542 - auc: 0.8100 - binary_accuracy: 0.9542 - recall_3: 0.0672 - precision_3: 0.5312 - val_loss: 0.1618 - val_acc: 0.9509 - val_auc: 0.7852 - val_binary_accuracy: 0.9509 - val_recall_3: 0.0500 - val_precision_3: 0.3077\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1613 - acc: 0.9542 - auc: 0.7767 - binary_accuracy: 0.9542 - recall_3: 0.0830 - precision_3: 0.5250 - val_loss: 0.1652 - val_acc: 0.9538 - val_auc: 0.7618 - val_binary_accuracy: 0.9538 - val_recall_3: 0.0125 - val_precision_3: 0.5000\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1583 - acc: 0.9538 - auc: 0.7944 - binary_accuracy: 0.9538 - recall_3: 0.0711 - precision_3: 0.5000 - val_loss: 0.1699 - val_acc: 0.9538 - val_auc: 0.7600 - val_binary_accuracy: 0.9538 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1508 - acc: 0.9556 - auc: 0.8224 - binary_accuracy: 0.9556 - recall_3: 0.0909 - precision_3: 0.6389 - val_loss: 0.1673 - val_acc: 0.9468 - val_auc: 0.7807 - val_binary_accuracy: 0.9468 - val_recall_3: 0.0375 - val_precision_3: 0.1667\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1453 - acc: 0.9567 - auc: 0.8235 - binary_accuracy: 0.9567 - recall_3: 0.1186 - precision_3: 0.6818 - val_loss: 0.1636 - val_acc: 0.9462 - val_auc: 0.7945 - val_binary_accuracy: 0.9462 - val_recall_3: 0.0750 - val_precision_3: 0.2400\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1429 - acc: 0.9558 - auc: 0.8417 - binary_accuracy: 0.9558 - recall_3: 0.1502 - precision_3: 0.5846 - val_loss: 0.1630 - val_acc: 0.9526 - val_auc: 0.7949 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0750 - val_precision_3: 0.4286\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1419 - acc: 0.9563 - auc: 0.8401 - binary_accuracy: 0.9563 - recall_3: 0.1225 - precision_3: 0.6458 - val_loss: 0.1636 - val_acc: 0.9480 - val_auc: 0.7922 - val_binary_accuracy: 0.9480 - val_recall_3: 0.0750 - val_precision_3: 0.2727\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1377 - acc: 0.9574 - auc: 0.8583 - binary_accuracy: 0.9574 - recall_3: 0.1502 - precision_3: 0.6786 - val_loss: 0.1665 - val_acc: 0.9532 - val_auc: 0.7744 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0625 - val_precision_3: 0.4545\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1382 - acc: 0.9569 - auc: 0.8516 - binary_accuracy: 0.9569 - recall_3: 0.1423 - precision_3: 0.6545 - val_loss: 0.1775 - val_acc: 0.9445 - val_auc: 0.7679 - val_binary_accuracy: 0.9445 - val_recall_3: 0.1625 - val_precision_3: 0.3095\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1597 - acc: 0.9536 - auc: 0.7827 - binary_accuracy: 0.9536 - recall_3: 0.1265 - precision_3: 0.4923 - val_loss: 0.1692 - val_acc: 0.9543 - val_auc: 0.7693 - val_binary_accuracy: 0.9543 - val_recall_3: 0.0625 - val_precision_3: 0.5556\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1370 - acc: 0.9582 - auc: 0.8615 - binary_accuracy: 0.9582 - recall_3: 0.1581 - precision_3: 0.7143 - val_loss: 0.1664 - val_acc: 0.9503 - val_auc: 0.7886 - val_binary_accuracy: 0.9503 - val_recall_3: 0.1250 - val_precision_3: 0.3846\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1338 - acc: 0.9591 - auc: 0.8699 - binary_accuracy: 0.9591 - recall_3: 0.1897 - precision_3: 0.7164 - val_loss: 0.1720 - val_acc: 0.9538 - val_auc: 0.7680 - val_binary_accuracy: 0.9538 - val_recall_3: 0.0625 - val_precision_3: 0.5000\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1501 - acc: 0.9553 - auc: 0.8296 - binary_accuracy: 0.9553 - recall_3: 0.1462 - precision_3: 0.5606 - val_loss: 0.1714 - val_acc: 0.9532 - val_auc: 0.7667 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1465 - acc: 0.9556 - auc: 0.8340 - binary_accuracy: 0.9556 - recall_3: 0.0949 - precision_3: 0.6316 - val_loss: 0.1637 - val_acc: 0.9468 - val_auc: 0.7976 - val_binary_accuracy: 0.9468 - val_recall_3: 0.0500 - val_precision_3: 0.2000\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1520 - acc: 0.9527 - auc: 0.8244 - binary_accuracy: 0.9527 - recall_3: 0.1542 - precision_3: 0.4643 - val_loss: 0.1976 - val_acc: 0.9532 - val_auc: 0.6923 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0125 - val_precision_3: 0.3333\n",
      "0.16184794902801514\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "51499141-4437-4375-bf6a-ce67b52b74d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "0b725b94-d65b-4c2d-82a7-fad243039945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9445086705202312 MSE:  0.055491329479768786 UAR:  0.5903030303030303 Recall:  0.2 Precision:  0.3333333333333333 F1:  0.25\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9520231213872833 MSE:  0.04797687861271676 UAR:  0.5526136363636364 Recall:  0.1125 Precision:  0.42857142857142855 F1:  0.1782178217821782\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5297348484848485 Recall:  0.0625 Precision:  0.5 F1:  0.1111111111111111\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.954335260115607 MSE:  0.04566473988439306 UAR:  0.5181439393939394 Recall:  0.0375 Precision:  0.6 F1:  0.07058823529411765\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.4993939393939394 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.5903030303030303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "d3b508f9-12df-4445-ba6a-9729f52adcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "0de2a6cc-d0be-405b-8e5b-276dc40aa0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "75c06925-5ff8-4be2-a613-64661ddca460",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.8549132947976879 MSE:  0.14508670520231215 UAR:  0.6979545454545455 Recall:  0.525 Precision:  0.16470588235294117 F1:  0.2507462686567164\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9260115606936417 MSE:  0.07398843930635839 UAR:  0.6460227272727272 Recall:  0.3375 Precision:  0.2647058823529412 F1:  0.29670329670329665\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.946242774566474 MSE:  0.05375722543352601 UAR:  0.5852651515151515 Recall:  0.1875 Precision:  0.3488372093023256 F1:  0.2439024390243903\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.954335260115607 MSE:  0.04566473988439306 UAR:  0.5716666666666667 Recall:  0.15 Precision:  0.5217391304347826 F1:  0.23300970873786406\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.5350757575757575 Recall:  0.075 Precision:  0.42857142857142855 F1:  0.1276595744680851\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5118939393939393 Recall:  0.025 Precision:  0.5 F1:  0.047619047619047616\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6979545454545455\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56761344-54be-4a04-8b7c-5e51207e8d68",
   "metadata": {},
   "source": [
    "### Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "91d4314d-e320-4871-bed3-23d387fef4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.max\n",
    "stat_name = \"max\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1b7317-0215-4c70-9472-9a122be6a7ce",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "819c1e15-5f7c-492d-bc28-eca789ced80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "830143e4-e9e6-4a38-abba-34e5a4050e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "710d32dc-f0f5-410e-ae6a-222262bc89c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "test:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n",
      "val:\n",
      "0 1537/1720: 89.36046511627907%\n",
      "1 183/1720: 10.63953488372093%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5f347b-dfe8-4318-9270-b7829b5eccf2",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3f827524-1825-482c-9346-b76929770fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "801dd1ea-a2df-481f-82d0-9e9a21679f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "58fe917d-590f-485e-b788-c0dec810f989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "25040487-149e-4a0d-a4ba-4515ca45b65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5234  248] {0: 1.0, 1: 21.10483870967742} 2 [0 1]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b311e230-d5f5-4b64-b679-5b1203eec2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "#save_best_model = SaveBestModelByUAR(X_subsample_val, y_subsample_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c3c7c42e-1813-49d0-87eb-65bd27151bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 4s 66ms/step - loss: 1.3745 - acc: 0.6554 - auc: 0.6534 - binary_accuracy: 0.6554 - recall_2: 0.5887 - precision_2: 0.0755 - val_loss: 0.5669 - val_acc: 0.7105 - val_auc: 0.6817 - val_binary_accuracy: 0.7105 - val_recall_2: 0.4754 - val_precision_2: 0.1779\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 1.1120 - acc: 0.7242 - auc: 0.7738 - binary_accuracy: 0.7242 - recall_2: 0.7056 - precision_2: 0.1084 - val_loss: 0.5996 - val_acc: 0.6895 - val_auc: 0.6817 - val_binary_accuracy: 0.6895 - val_recall_2: 0.5246 - val_precision_2: 0.1768\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 1.0626 - acc: 0.7340 - auc: 0.7947 - binary_accuracy: 0.7340 - recall_2: 0.7016 - precision_2: 0.1117 - val_loss: 0.6415 - val_acc: 0.6657 - val_auc: 0.6711 - val_binary_accuracy: 0.6657 - val_recall_2: 0.5738 - val_precision_2: 0.1744\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 1.0243 - acc: 0.7399 - auc: 0.8063 - binary_accuracy: 0.7399 - recall_2: 0.7379 - precision_2: 0.1185 - val_loss: 0.3891 - val_acc: 0.8692 - val_auc: 0.6683 - val_binary_accuracy: 0.8692 - val_recall_2: 0.1475 - val_precision_2: 0.2812\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.9990 - acc: 0.7432 - auc: 0.8205 - binary_accuracy: 0.7432 - recall_2: 0.7419 - precision_2: 0.1204 - val_loss: 0.5627 - val_acc: 0.6913 - val_auc: 0.6800 - val_binary_accuracy: 0.6913 - val_recall_2: 0.5137 - val_precision_2: 0.1754\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.9580 - acc: 0.7738 - auc: 0.8334 - binary_accuracy: 0.7738 - recall_2: 0.7258 - precision_2: 0.1331 - val_loss: 0.5461 - val_acc: 0.7017 - val_auc: 0.6838 - val_binary_accuracy: 0.7017 - val_recall_2: 0.4918 - val_precision_2: 0.1765\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.9065 - acc: 0.7689 - auc: 0.8549 - binary_accuracy: 0.7689 - recall_2: 0.8024 - precision_2: 0.1404 - val_loss: 0.6111 - val_acc: 0.6512 - val_auc: 0.6704 - val_binary_accuracy: 0.6512 - val_recall_2: 0.5246 - val_precision_2: 0.1576\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.9133 - acc: 0.7526 - auc: 0.8517 - binary_accuracy: 0.7526 - recall_2: 0.7823 - precision_2: 0.1297 - val_loss: 0.5278 - val_acc: 0.7314 - val_auc: 0.6675 - val_binary_accuracy: 0.7314 - val_recall_2: 0.4208 - val_precision_2: 0.1778\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.8890 - acc: 0.7713 - auc: 0.8632 - binary_accuracy: 0.7713 - recall_2: 0.7903 - precision_2: 0.1402 - val_loss: 0.4622 - val_acc: 0.7767 - val_auc: 0.6678 - val_binary_accuracy: 0.7767 - val_recall_2: 0.3443 - val_precision_2: 0.1927\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.8713 - acc: 0.7917 - auc: 0.8659 - binary_accuracy: 0.7917 - recall_2: 0.7581 - precision_2: 0.1480 - val_loss: 0.4564 - val_acc: 0.7826 - val_auc: 0.6702 - val_binary_accuracy: 0.7826 - val_recall_2: 0.3333 - val_precision_2: 0.1949\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.8356 - acc: 0.7785 - auc: 0.8774 - binary_accuracy: 0.7785 - recall_2: 0.7984 - precision_2: 0.1454 - val_loss: 0.5056 - val_acc: 0.7477 - val_auc: 0.6566 - val_binary_accuracy: 0.7477 - val_recall_2: 0.3607 - val_precision_2: 0.1723\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.7756 - acc: 0.7944 - auc: 0.8965 - binary_accuracy: 0.7944 - recall_2: 0.8427 - precision_2: 0.1611 - val_loss: 0.5726 - val_acc: 0.7128 - val_auc: 0.6712 - val_binary_accuracy: 0.7128 - val_recall_2: 0.4918 - val_precision_2: 0.1833\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.7617 - acc: 0.8167 - auc: 0.9021 - binary_accuracy: 0.8167 - recall_2: 0.8266 - precision_2: 0.1757 - val_loss: 0.6363 - val_acc: 0.6831 - val_auc: 0.6703 - val_binary_accuracy: 0.6831 - val_recall_2: 0.5137 - val_precision_2: 0.1709\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.7551 - acc: 0.8065 - auc: 0.9025 - binary_accuracy: 0.8065 - recall_2: 0.8347 - precision_2: 0.1687 - val_loss: 0.5959 - val_acc: 0.6860 - val_auc: 0.6484 - val_binary_accuracy: 0.6860 - val_recall_2: 0.4208 - val_precision_2: 0.1507\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.7067 - acc: 0.8183 - auc: 0.9162 - binary_accuracy: 0.8183 - recall_2: 0.8750 - precision_2: 0.1836 - val_loss: 0.5718 - val_acc: 0.7360 - val_auc: 0.6715 - val_binary_accuracy: 0.7360 - val_recall_2: 0.4426 - val_precision_2: 0.1871\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.6957 - acc: 0.8263 - auc: 0.9176 - binary_accuracy: 0.8263 - recall_2: 0.8548 - precision_2: 0.1879 - val_loss: 0.6005 - val_acc: 0.6936 - val_auc: 0.6507 - val_binary_accuracy: 0.6936 - val_recall_2: 0.4098 - val_precision_2: 0.1518\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.6630 - acc: 0.8293 - auc: 0.9269 - binary_accuracy: 0.8293 - recall_2: 0.8548 - precision_2: 0.1906 - val_loss: 0.6735 - val_acc: 0.6564 - val_auc: 0.6652 - val_binary_accuracy: 0.6564 - val_recall_2: 0.5137 - val_precision_2: 0.1577\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.6569 - acc: 0.8309 - auc: 0.9262 - binary_accuracy: 0.8309 - recall_2: 0.8790 - precision_2: 0.1955 - val_loss: 0.5329 - val_acc: 0.7547 - val_auc: 0.6571 - val_binary_accuracy: 0.7547 - val_recall_2: 0.3716 - val_precision_2: 0.1813\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.6566 - acc: 0.8338 - auc: 0.9261 - binary_accuracy: 0.8338 - recall_2: 0.8871 - precision_2: 0.1995 - val_loss: 0.4597 - val_acc: 0.8163 - val_auc: 0.6558 - val_binary_accuracy: 0.8163 - val_recall_2: 0.2623 - val_precision_2: 0.2096\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.6038 - acc: 0.8409 - auc: 0.9379 - binary_accuracy: 0.8409 - recall_2: 0.9073 - precision_2: 0.2095 - val_loss: 0.5408 - val_acc: 0.7483 - val_auc: 0.6449 - val_binary_accuracy: 0.7483 - val_recall_2: 0.3388 - val_precision_2: 0.1658\n",
      "0.3891335427761078\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "be25dd78-08e6-457a-845b-b1acf4f84591",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_2765461/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "348c3303-9fc2-40ff-aac1-c277453b77ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional Accuracy:  0.5612304120719674 MSE:  0.4387695879280325 UAR:  0.6409574086044674 Recall:  0.7294117647058823 Precision:  0.0779874213836478 F1:  0.1409090909090909\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional Accuracy:  0.7301218804410912 MSE:  0.2698781195589089 UAR:  0.6684371184371185 Recall:  0.6 Precision:  0.10580912863070539 F1:  0.1798941798941799\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional Accuracy:  0.8189204875217644 MSE:  0.18107951247823564 UAR:  0.6705235940530059 Recall:  0.5058823529411764 Precision:  0.13738019169329074 F1:  0.21608040201005024\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional Accuracy:  0.8630295995356936 MSE:  0.13697040046430645 UAR:  0.6491057961646196 Recall:  0.4117647058823529 Precision:  0.1583710407239819 F1:  0.2287581699346405\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional Accuracy:  0.9013348810214742 MSE:  0.09866511897852583 UAR:  0.6302125978596567 Recall:  0.32941176470588235 Precision:  0.19858156028368795 F1:  0.24778761061946905\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional Accuracy:  0.9251305861868834 MSE:  0.07486941381311665 UAR:  0.6148423471952884 Recall:  0.27058823529411763 Precision:  0.25555555555555554 F1:  0.2628571428571429\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional Accuracy:  0.9408009286128846 MSE:  0.0591990713871155 UAR:  0.5896214896214896 Recall:  0.2 Precision:  0.3333333333333333 F1:  0.25\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional Accuracy:  0.9454439930354034 MSE:  0.054556006964596636 UAR:  0.5586008762479351 Recall:  0.12941176470588237 Precision:  0.3548387096774194 F1:  0.18965517241379312\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5390397184514831 Recall:  0.08235294117647059 Precision:  0.5 F1:  0.1414141414141414\n",
      "0.3 0.6705235940530059\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name, from_int=True)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7653fcf8-9de6-4250-88b1-21e5f6274091",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d0e83e01-18c7-451d-b696-bee4ccd3e9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_2765461/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c5e3c38a-ecd2-4e1c-ab56-43c4bc70b642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.2547881601857226 MSE:  0.7452118398142774 UAR:  0.574595992243051 Recall:  0.9294117647058824 Precision:  0.05821665438467207 F1:  0.10957004160887657\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.6018572257690076 MSE:  0.3981427742309925 UAR:  0.6400165194282841 Recall:  0.6823529411764706 Precision:  0.08089260808926081 F1:  0.14463840399002495\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.820661636680209 MSE:  0.17933836331979106 UAR:  0.6658622423328306 Recall:  0.49411764705882355 Precision:  0.13636363636363635 F1:  0.21374045801526717\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.914683691236216 MSE:  0.0853163087637841 UAR:  0.6205020469726352 Recall:  0.29411764705882354 Precision:  0.22321428571428573 F1:  0.25380710659898476\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.9413813116656994 MSE:  0.05861868833430064 UAR:  0.5843496372908137 Recall:  0.18823529411764706 Precision:  0.3333333333333333 F1:  0.24060150375939854\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.539955469367234 Recall:  0.08235294117647059 Precision:  0.6363636363636364 F1:  0.14583333333333331\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5170365582130289 Recall:  0.03529411764705882 Precision:  0.6 F1:  0.06666666666666667\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5058823529411764 Recall:  0.011764705882352941 Precision:  1.0 F1:  0.023255813953488372\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.3 0.6658622423328306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name, from_int=True)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778cab92-f53b-4ac0-bd44-81a8977f89e6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "83dfe74e-d76b-4d88-8370-450e17019873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "350d48a7-ffb9-4344-a7e1-a84528404228",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1c19483e-fcfe-4675-9cee-5727da85ea7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b51663ce-f2d4-4e89-9ed0-ec0fcc5922df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_6 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_6[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_6[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "324883a2-9608-4a65-b509-ec5df16971c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 127ms/step - loss: 0.3520 - acc: 0.9435 - auc: 0.5372 - binary_accuracy: 0.9435 - recall_1: 0.0121 - precision_1: 0.0441 - val_loss: 0.3655 - val_acc: 0.8936 - val_auc: 0.6054 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1676 - acc: 0.9544 - auc: 0.7332 - binary_accuracy: 0.9544 - recall_1: 0.0081 - precision_1: 0.3333 - val_loss: 0.4156 - val_acc: 0.8936 - val_auc: 0.6291 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1589 - acc: 0.9533 - auc: 0.7800 - binary_accuracy: 0.9533 - recall_1: 0.0081 - precision_1: 0.1667 - val_loss: 0.3692 - val_acc: 0.8907 - val_auc: 0.6405 - val_binary_accuracy: 0.8907 - val_recall_1: 0.0328 - val_precision_1: 0.3529\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1570 - acc: 0.9538 - auc: 0.7916 - binary_accuracy: 0.9538 - recall_1: 0.0282 - precision_1: 0.3684 - val_loss: 0.4193 - val_acc: 0.8930 - val_auc: 0.6368 - val_binary_accuracy: 0.8930 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1648 - acc: 0.9526 - auc: 0.7644 - binary_accuracy: 0.9526 - recall_1: 0.0403 - precision_1: 0.3125 - val_loss: 0.3956 - val_acc: 0.8936 - val_auc: 0.6295 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1544 - acc: 0.9557 - auc: 0.8021 - binary_accuracy: 0.9557 - recall_1: 0.0524 - precision_1: 0.6190 - val_loss: 0.3884 - val_acc: 0.8942 - val_auc: 0.6372 - val_binary_accuracy: 0.8942 - val_recall_1: 0.0164 - val_precision_1: 0.6000\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1498 - acc: 0.9564 - auc: 0.8126 - binary_accuracy: 0.9564 - recall_1: 0.0726 - precision_1: 0.6667 - val_loss: 0.4350 - val_acc: 0.8936 - val_auc: 0.6258 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1505 - acc: 0.9562 - auc: 0.7941 - binary_accuracy: 0.9562 - recall_1: 0.0927 - precision_1: 0.6053 - val_loss: 0.4107 - val_acc: 0.8936 - val_auc: 0.6443 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1529 - acc: 0.9529 - auc: 0.8132 - binary_accuracy: 0.9529 - recall_1: 0.0565 - precision_1: 0.3684 - val_loss: 0.3560 - val_acc: 0.8901 - val_auc: 0.6600 - val_binary_accuracy: 0.8901 - val_recall_1: 0.0328 - val_precision_1: 0.3333\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1611 - acc: 0.9544 - auc: 0.7951 - binary_accuracy: 0.9544 - recall_1: 0.0766 - precision_1: 0.4750 - val_loss: 0.3404 - val_acc: 0.8919 - val_auc: 0.6709 - val_binary_accuracy: 0.8919 - val_recall_1: 0.0164 - val_precision_1: 0.3333\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1480 - acc: 0.9551 - auc: 0.8080 - binary_accuracy: 0.9551 - recall_1: 0.0645 - precision_1: 0.5333 - val_loss: 0.3748 - val_acc: 0.8791 - val_auc: 0.6659 - val_binary_accuracy: 0.8791 - val_recall_1: 0.0546 - val_precision_1: 0.2222\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1393 - acc: 0.9577 - auc: 0.8477 - binary_accuracy: 0.9577 - recall_1: 0.1169 - precision_1: 0.6905 - val_loss: 0.4060 - val_acc: 0.8843 - val_auc: 0.6437 - val_binary_accuracy: 0.8843 - val_recall_1: 0.0328 - val_precision_1: 0.2143\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1391 - acc: 0.9584 - auc: 0.8543 - binary_accuracy: 0.9584 - recall_1: 0.1694 - precision_1: 0.6562 - val_loss: 0.4013 - val_acc: 0.8913 - val_auc: 0.6270 - val_binary_accuracy: 0.8913 - val_recall_1: 0.0055 - val_precision_1: 0.1667\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1430 - acc: 0.9564 - auc: 0.8307 - binary_accuracy: 0.9564 - recall_1: 0.1250 - precision_1: 0.5849 - val_loss: 0.4422 - val_acc: 0.8936 - val_auc: 0.6349 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0164 - val_precision_1: 0.5000\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1403 - acc: 0.9593 - auc: 0.8408 - binary_accuracy: 0.9593 - recall_1: 0.1532 - precision_1: 0.7451 - val_loss: 0.3936 - val_acc: 0.8860 - val_auc: 0.6520 - val_binary_accuracy: 0.8860 - val_recall_1: 0.0273 - val_precision_1: 0.2174\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1331 - acc: 0.9599 - auc: 0.8623 - binary_accuracy: 0.9599 - recall_1: 0.1815 - precision_1: 0.7258 - val_loss: 0.4326 - val_acc: 0.8890 - val_auc: 0.6155 - val_binary_accuracy: 0.8890 - val_recall_1: 0.0109 - val_precision_1: 0.1667\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1567 - acc: 0.9579 - auc: 0.8211 - binary_accuracy: 0.9579 - recall_1: 0.1855 - precision_1: 0.6133 - val_loss: 0.6409 - val_acc: 0.8901 - val_auc: 0.5315 - val_binary_accuracy: 0.8901 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1939 - acc: 0.9513 - auc: 0.7187 - binary_accuracy: 0.9513 - recall_1: 0.0927 - precision_1: 0.3538 - val_loss: 0.4528 - val_acc: 0.8924 - val_auc: 0.6278 - val_binary_accuracy: 0.8924 - val_recall_1: 0.0109 - val_precision_1: 0.3333\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1382 - acc: 0.9582 - auc: 0.8531 - binary_accuracy: 0.9582 - recall_1: 0.1532 - precision_1: 0.6667 - val_loss: 0.4255 - val_acc: 0.8831 - val_auc: 0.6076 - val_binary_accuracy: 0.8831 - val_recall_1: 0.0328 - val_precision_1: 0.2000\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1471 - acc: 0.9573 - auc: 0.8318 - binary_accuracy: 0.9573 - recall_1: 0.1653 - precision_1: 0.6029 - val_loss: 0.3628 - val_acc: 0.8831 - val_auc: 0.6370 - val_binary_accuracy: 0.8831 - val_recall_1: 0.0273 - val_precision_1: 0.1786\n",
      "0.340364933013916\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "12d400c6-c1e8-46bf-a496-6cccf9562098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "004a36df-11d8-4ff9-9339-0e77b3fbfefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.8415554265815438 MSE:  0.1584445734184562 UAR:  0.6043489190548015 Recall:  0.3411764705882353 Precision:  0.11788617886178862 F1:  0.17522658610271902\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.930354033662217 MSE:  0.06964596633778293 UAR:  0.5450872656755009 Recall:  0.11764705882352941 Precision:  0.18181818181818182 F1:  0.14285714285714285\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9437028438769588 MSE:  0.05629715612304121 UAR:  0.5409538174244057 Recall:  0.09411764705882353 Precision:  0.2857142857142857 F1:  0.1415929203539823\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.947185142193848 MSE:  0.05281485780615206 UAR:  0.526054011348129 Recall:  0.058823529411764705 Precision:  0.3125 F1:  0.09900990099009901\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5281907634848811 Recall:  0.058823529411764705 Precision:  0.5555555555555556 F1:  0.10638297872340426\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5229189111542053 Recall:  0.047058823529411764 Precision:  0.6666666666666666 F1:  0.08791208791208792\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9529889727219966 MSE:  0.047011027278003485 UAR:  0.5235294117647059 Recall:  0.047058823529411764 Precision:  1.0 F1:  0.0898876404494382\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5176470588235295 Recall:  0.03529411764705882 Precision:  1.0 F1:  0.06818181818181818\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5117647058823529 Recall:  0.023529411764705882 Precision:  1.0 F1:  0.04597701149425288\n",
      "0.1 0.6043489190548015\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e6205f7c-d06e-4933-80e5-5d8ce06bbf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "94e032a8-3901-4509-80e8-70d462f42290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a6790cc1-d5ee-4706-8746-650d156915cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.8340104468949506 MSE:  0.16598955310504934 UAR:  0.6282661782661783 Recall:  0.4 Precision:  0.12639405204460966 F1:  0.192090395480226\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9297736506094022 MSE:  0.0702263493905978 UAR:  0.5949759390935861 Recall:  0.2235294117647059 Precision:  0.25675675675675674 F1:  0.2389937106918239\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9477655252466628 MSE:  0.0522344747533372 UAR:  0.5653989801048624 Recall:  0.1411764705882353 Precision:  0.41379310344827586 F1:  0.21052631578947367\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5566867772750126 Recall:  0.11764705882352941 Precision:  0.5882352941176471 F1:  0.19607843137254902\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9529889727219966 MSE:  0.047011027278003485 UAR:  0.5402607196724843 Recall:  0.08235294117647059 Precision:  0.7 F1:  0.14736842105263157\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5288012640953818 Recall:  0.058823529411764705 Precision:  0.7142857142857143 F1:  0.10869565217391305\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9500870574579222 MSE:  0.04991294254207777 UAR:  0.5052718523306758 Recall:  0.011764705882352941 Precision:  0.3333333333333333 F1:  0.022727272727272728\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5058823529411764 Recall:  0.011764705882352941 Precision:  1.0 F1:  0.023255813953488372\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6282661782661783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a494d2dd-4812-4d61-b7a1-2344e4a3a21d",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b75a3df1-b71e-4e9a-b02b-03668a1e53b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a85168a9-64d8-4f33-af44-359d7f63a26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c716a253-d7ea-4e64-9cd7-3e494ba7d943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "val:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "28381598-c2d5-47f7-9d8a-8c1f804af880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482,) (5482,)\n",
      "(1723,) (1723,)\n",
      "(7205,) (7205,)\n",
      "[0 1] [6872  333]\n",
      "7205\n",
      "5475\n",
      "1730\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9753e7ea-f2a3-4054-911f-bfc54b7b9882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5222/5475: 95.37899543378995%\n",
      "1 253/5475: 4.621004566210046%\n",
      "val:\n",
      "0 1650/1730: 95.3757225433526%\n",
      "1 80/1730: 4.624277456647399%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf31640-2b0e-45d6-afdc-1ae238d7b474",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eca041af-12c6-4088-8dfa-7cfe7948a3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "721ba1b7-4ac8-493e-a731-af9a0a2cc5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5929d9a1-1ec5-4def-ab3b-875b1c5ed16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 2560) (5475,)\n",
      "(1730, 128, 2560) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a653ac7e-1b56-44ab-aeee-fcec2bb5967e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5222  253] {0: 1.0, 1: 20.640316205533598} 2 [0 1]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a3117ef9-7d19-4efc-82d6-0fc3e74a5373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1311232   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1314306 (5.01 MB)\n",
      "Trainable params: 1314306 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "#save_best_model = SaveBestModelByUAR(X_subsample_test, y_subsample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "269137fa-131b-47ef-82f9-8e558691c389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 4s 68ms/step - loss: 1.3650 - acc: 0.6424 - auc: 0.6571 - binary_accuracy: 0.6424 - recall_3: 0.5810 - precision_3: 0.0735 - val_loss: 0.7326 - val_acc: 0.5751 - val_auc: 0.7461 - val_binary_accuracy: 0.5751 - val_recall_3: 0.7750 - val_precision_3: 0.0796\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 1.0975 - acc: 0.7299 - auc: 0.7768 - binary_accuracy: 0.7299 - recall_3: 0.6838 - precision_3: 0.1101 - val_loss: 0.5188 - val_acc: 0.7809 - val_auc: 0.7722 - val_binary_accuracy: 0.7809 - val_recall_3: 0.6000 - val_precision_3: 0.1215\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 1.0762 - acc: 0.7598 - auc: 0.8020 - binary_accuracy: 0.7598 - recall_3: 0.6917 - precision_3: 0.1239 - val_loss: 0.5161 - val_acc: 0.7954 - val_auc: 0.7711 - val_binary_accuracy: 0.7954 - val_recall_3: 0.6125 - val_precision_3: 0.1317\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.9767 - acc: 0.7620 - auc: 0.8275 - binary_accuracy: 0.7620 - recall_3: 0.7628 - precision_3: 0.1344 - val_loss: 0.5457 - val_acc: 0.7324 - val_auc: 0.7760 - val_binary_accuracy: 0.7324 - val_recall_3: 0.6625 - val_precision_3: 0.1084\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.9155 - acc: 0.7741 - auc: 0.8527 - binary_accuracy: 0.7741 - recall_3: 0.7668 - precision_3: 0.1414 - val_loss: 0.6251 - val_acc: 0.6665 - val_auc: 0.7803 - val_binary_accuracy: 0.6665 - val_recall_3: 0.7125 - val_precision_3: 0.0933\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.8986 - acc: 0.7602 - auc: 0.8554 - binary_accuracy: 0.7602 - recall_3: 0.7984 - precision_3: 0.1380 - val_loss: 0.7221 - val_acc: 0.6289 - val_auc: 0.7662 - val_binary_accuracy: 0.6289 - val_recall_3: 0.7500 - val_precision_3: 0.0880\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.9111 - acc: 0.7865 - auc: 0.8600 - binary_accuracy: 0.7865 - recall_3: 0.7747 - precision_3: 0.1498 - val_loss: 0.4448 - val_acc: 0.7861 - val_auc: 0.7657 - val_binary_accuracy: 0.7861 - val_recall_3: 0.6000 - val_precision_3: 0.1244\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.8334 - acc: 0.7848 - auc: 0.8798 - binary_accuracy: 0.7848 - recall_3: 0.8103 - precision_3: 0.1536 - val_loss: 0.5794 - val_acc: 0.7173 - val_auc: 0.7626 - val_binary_accuracy: 0.7173 - val_recall_3: 0.6750 - val_precision_3: 0.1044\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.7899 - acc: 0.8064 - auc: 0.8917 - binary_accuracy: 0.8064 - recall_3: 0.8221 - precision_3: 0.1701 - val_loss: 0.4385 - val_acc: 0.7983 - val_auc: 0.7720 - val_binary_accuracy: 0.7983 - val_recall_3: 0.6250 - val_precision_3: 0.1355\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.7502 - acc: 0.8075 - auc: 0.9037 - binary_accuracy: 0.8075 - recall_3: 0.8538 - precision_3: 0.1752 - val_loss: 0.4230 - val_acc: 0.8081 - val_auc: 0.7704 - val_binary_accuracy: 0.8081 - val_recall_3: 0.6125 - val_precision_3: 0.1400\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.7336 - acc: 0.8130 - auc: 0.9059 - binary_accuracy: 0.8130 - recall_3: 0.8340 - precision_3: 0.1769 - val_loss: 0.5229 - val_acc: 0.7445 - val_auc: 0.7634 - val_binary_accuracy: 0.7445 - val_recall_3: 0.6375 - val_precision_3: 0.1099\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.7152 - acc: 0.8132 - auc: 0.9125 - binary_accuracy: 0.8132 - recall_3: 0.8814 - precision_3: 0.1834 - val_loss: 0.3043 - val_acc: 0.8838 - val_auc: 0.7662 - val_binary_accuracy: 0.8838 - val_recall_3: 0.5250 - val_precision_3: 0.2049\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.6821 - acc: 0.8261 - auc: 0.9211 - binary_accuracy: 0.8261 - recall_3: 0.8696 - precision_3: 0.1932 - val_loss: 0.3632 - val_acc: 0.8462 - val_auc: 0.7489 - val_binary_accuracy: 0.8462 - val_recall_3: 0.5625 - val_precision_3: 0.1630\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.6662 - acc: 0.8276 - auc: 0.9261 - binary_accuracy: 0.8276 - recall_3: 0.8617 - precision_3: 0.1934 - val_loss: 0.3618 - val_acc: 0.8422 - val_auc: 0.7493 - val_binary_accuracy: 0.8422 - val_recall_3: 0.5375 - val_precision_3: 0.1541\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.6263 - acc: 0.8420 - auc: 0.9350 - binary_accuracy: 0.8420 - recall_3: 0.8893 - precision_3: 0.2119 - val_loss: 0.4758 - val_acc: 0.8168 - val_auc: 0.7557 - val_binary_accuracy: 0.8168 - val_recall_3: 0.5875 - val_precision_3: 0.1420\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.6640 - acc: 0.8303 - auc: 0.9244 - binary_accuracy: 0.8303 - recall_3: 0.8814 - precision_3: 0.1988 - val_loss: 0.4465 - val_acc: 0.7902 - val_auc: 0.7508 - val_binary_accuracy: 0.7902 - val_recall_3: 0.6125 - val_precision_3: 0.1286\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.6084 - acc: 0.8442 - auc: 0.9383 - binary_accuracy: 0.8442 - recall_3: 0.8775 - precision_3: 0.2126 - val_loss: 0.4263 - val_acc: 0.8064 - val_auc: 0.7483 - val_binary_accuracy: 0.8064 - val_recall_3: 0.6000 - val_precision_3: 0.1368\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.6982 - acc: 0.8442 - auc: 0.9343 - binary_accuracy: 0.8442 - recall_3: 0.9051 - precision_3: 0.2164 - val_loss: 0.5165 - val_acc: 0.7699 - val_auc: 0.7245 - val_binary_accuracy: 0.7699 - val_recall_3: 0.5875 - val_precision_3: 0.1141\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.5839 - acc: 0.8449 - auc: 0.9416 - binary_accuracy: 0.8449 - recall_3: 0.8972 - precision_3: 0.2162 - val_loss: 0.4399 - val_acc: 0.8012 - val_auc: 0.7384 - val_binary_accuracy: 0.8012 - val_recall_3: 0.5750 - val_precision_3: 0.1292\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.5588 - acc: 0.8658 - auc: 0.9483 - binary_accuracy: 0.8658 - recall_3: 0.9249 - precision_3: 0.2463 - val_loss: 0.5486 - val_acc: 0.7578 - val_auc: 0.7280 - val_binary_accuracy: 0.7578 - val_recall_3: 0.6250 - val_precision_3: 0.1139\n",
      "0.3042576014995575\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "596e78ec-1a2d-4a93-96b7-4aadebd7ed53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_2765461/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "08b4a461-5b96-458c-a275-e2552256c30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced Accuracy:  0.44913294797687864 MSE:  0.5508670520231214 UAR:  0.6101136363636364 Recall:  0.7875 Precision:  0.06306306306306306 F1:  0.11677479147358663\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced Accuracy:  0.5508670520231214 MSE:  0.44913294797687864 UAR:  0.6515530303030304 Recall:  0.7625 Precision:  0.07448107448107448 F1:  0.13570634037819798\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced Accuracy:  0.63121387283237 MSE:  0.36878612716763004 UAR:  0.6639393939393939 Recall:  0.7 Precision:  0.08358208955223881 F1:  0.14933333333333335\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced Accuracy:  0.7023121387283237 MSE:  0.2976878612716763 UAR:  0.6952651515151516 Recall:  0.6875 Precision:  0.10091743119266056 F1:  0.176\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced Accuracy:  0.7589595375722543 MSE:  0.24104046242774566 UAR:  0.7011742424242424 Recall:  0.6375 Precision:  0.11617312072892938 F1:  0.19653179190751444\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced Accuracy:  0.7982658959537572 MSE:  0.20173410404624278 UAR:  0.6801515151515152 Recall:  0.55 Precision:  0.12324929971988796 F1:  0.2013729977116705\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced Accuracy:  0.8393063583815029 MSE:  0.1606936416184971 UAR:  0.6719318181818181 Recall:  0.4875 Precision:  0.14130434782608695 F1:  0.2191011235955056\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced Accuracy:  0.8832369942196532 MSE:  0.11676300578034682 UAR:  0.6533333333333333 Recall:  0.4 Precision:  0.17204301075268819 F1:  0.24060150375939857\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced Accuracy:  0.9109826589595376 MSE:  0.08901734104046242 UAR:  0.5786742424242424 Recall:  0.2125 Precision:  0.1574074074074074 F1:  0.18085106382978725\n",
      "0.5 0.7011742424242424\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name, from_int=True)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7d1e40a6-4cac-4fa6-8076-dc7b8f64e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6bf5f25b-58a4-4761-9b40-522fca1ae2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_2765461/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2b289a07-e013-454f-b3f0-83bd44ef6b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.523121387283237 MSE:  0.476878612716763 UAR:  0.6548484848484848 Recall:  0.8 Precision:  0.07331042382588775 F1:  0.13431269674711438\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.6890173410404624 MSE:  0.3109826589595376 UAR:  0.6882954545454545 Recall:  0.6875 Precision:  0.09683098591549295 F1:  0.16975308641975306\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.7826589595375723 MSE:  0.21734104046242775 UAR:  0.7135984848484849 Recall:  0.6375 Precision:  0.12814070351758794 F1:  0.21338912133891216\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.8398843930635839 MSE:  0.1601156069364162 UAR:  0.7257575757575758 Recall:  0.6 Precision:  0.16382252559726962 F1:  0.257372654155496\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.8832369942196532 MSE:  0.11676300578034682 UAR:  0.71875 Recall:  0.5375 Precision:  0.20673076923076922 F1:  0.2986111111111111\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.9115606936416185 MSE:  0.0884393063583815 UAR:  0.6979166666666667 Recall:  0.4625 Precision:  0.25170068027210885 F1:  0.3259911894273128\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.9329479768786128 MSE:  0.06705202312138728 UAR:  0.6377651515151515 Recall:  0.3125 Precision:  0.29069767441860467 F1:  0.3012048192771084\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.945664739884393 MSE:  0.05433526011560694 UAR:  0.60875 Recall:  0.2375 Precision:  0.36538461538461536 F1:  0.2878787878787879\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.546969696969697 Recall:  0.1 Precision:  0.4444444444444444 F1:  0.163265306122449\n",
      "0.4 0.7257575757575758\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name, from_int=True)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e060213a-9775-4dee-be60-2a5ddef5180a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "390b99de-7712-4d44-88c5-7b4c779511cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a3470787-f236-4517-a34a-4d23547b69b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "4436437f-0071-4c18-b760-8b416b5f56e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 2560) (5475,)\n",
      "(1730, 128, 2560) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "1490d7d6-b133-4568-93d2-d030e6d7e03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_7 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_7[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_7[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "f387020f-74b9-4d99-9de5-3b84384bd73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 125ms/step - loss: 0.3764 - acc: 0.9412 - auc: 0.5374 - binary_accuracy: 0.9412 - recall_3: 0.0277 - precision_3: 0.0843 - val_loss: 0.1875 - val_acc: 0.9526 - val_auc: 0.6787 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0125 - val_precision_3: 0.2500\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1737 - acc: 0.9540 - auc: 0.7014 - binary_accuracy: 0.9540 - recall_3: 0.0514 - precision_3: 0.5200 - val_loss: 0.1701 - val_acc: 0.9526 - val_auc: 0.7431 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0250 - val_precision_3: 0.3333\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1627 - acc: 0.9536 - auc: 0.7562 - binary_accuracy: 0.9536 - recall_3: 0.0435 - precision_3: 0.4783 - val_loss: 0.1690 - val_acc: 0.9526 - val_auc: 0.7421 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1558 - acc: 0.9563 - auc: 0.7868 - binary_accuracy: 0.9563 - recall_3: 0.0751 - precision_3: 0.7917 - val_loss: 0.1788 - val_acc: 0.9532 - val_auc: 0.7731 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1543 - acc: 0.9558 - auc: 0.7960 - binary_accuracy: 0.9558 - recall_3: 0.0870 - precision_3: 0.6667 - val_loss: 0.1673 - val_acc: 0.9468 - val_auc: 0.7855 - val_binary_accuracy: 0.9468 - val_recall_3: 0.0375 - val_precision_3: 0.1667\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1532 - acc: 0.9542 - auc: 0.8100 - binary_accuracy: 0.9542 - recall_3: 0.0672 - precision_3: 0.5312 - val_loss: 0.1618 - val_acc: 0.9509 - val_auc: 0.7852 - val_binary_accuracy: 0.9509 - val_recall_3: 0.0500 - val_precision_3: 0.3077\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1613 - acc: 0.9542 - auc: 0.7767 - binary_accuracy: 0.9542 - recall_3: 0.0830 - precision_3: 0.5250 - val_loss: 0.1652 - val_acc: 0.9538 - val_auc: 0.7618 - val_binary_accuracy: 0.9538 - val_recall_3: 0.0125 - val_precision_3: 0.5000\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1583 - acc: 0.9538 - auc: 0.7944 - binary_accuracy: 0.9538 - recall_3: 0.0711 - precision_3: 0.5000 - val_loss: 0.1699 - val_acc: 0.9538 - val_auc: 0.7600 - val_binary_accuracy: 0.9538 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1508 - acc: 0.9556 - auc: 0.8224 - binary_accuracy: 0.9556 - recall_3: 0.0909 - precision_3: 0.6389 - val_loss: 0.1673 - val_acc: 0.9468 - val_auc: 0.7807 - val_binary_accuracy: 0.9468 - val_recall_3: 0.0375 - val_precision_3: 0.1667\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1453 - acc: 0.9567 - auc: 0.8235 - binary_accuracy: 0.9567 - recall_3: 0.1186 - precision_3: 0.6818 - val_loss: 0.1636 - val_acc: 0.9462 - val_auc: 0.7945 - val_binary_accuracy: 0.9462 - val_recall_3: 0.0750 - val_precision_3: 0.2400\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1429 - acc: 0.9558 - auc: 0.8417 - binary_accuracy: 0.9558 - recall_3: 0.1502 - precision_3: 0.5846 - val_loss: 0.1630 - val_acc: 0.9526 - val_auc: 0.7949 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0750 - val_precision_3: 0.4286\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1419 - acc: 0.9563 - auc: 0.8401 - binary_accuracy: 0.9563 - recall_3: 0.1225 - precision_3: 0.6458 - val_loss: 0.1636 - val_acc: 0.9480 - val_auc: 0.7922 - val_binary_accuracy: 0.9480 - val_recall_3: 0.0750 - val_precision_3: 0.2727\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1377 - acc: 0.9574 - auc: 0.8583 - binary_accuracy: 0.9574 - recall_3: 0.1502 - precision_3: 0.6786 - val_loss: 0.1665 - val_acc: 0.9532 - val_auc: 0.7744 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0625 - val_precision_3: 0.4545\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1382 - acc: 0.9569 - auc: 0.8516 - binary_accuracy: 0.9569 - recall_3: 0.1423 - precision_3: 0.6545 - val_loss: 0.1775 - val_acc: 0.9445 - val_auc: 0.7679 - val_binary_accuracy: 0.9445 - val_recall_3: 0.1625 - val_precision_3: 0.3095\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1597 - acc: 0.9536 - auc: 0.7827 - binary_accuracy: 0.9536 - recall_3: 0.1265 - precision_3: 0.4923 - val_loss: 0.1692 - val_acc: 0.9543 - val_auc: 0.7693 - val_binary_accuracy: 0.9543 - val_recall_3: 0.0625 - val_precision_3: 0.5556\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1370 - acc: 0.9582 - auc: 0.8615 - binary_accuracy: 0.9582 - recall_3: 0.1581 - precision_3: 0.7143 - val_loss: 0.1664 - val_acc: 0.9503 - val_auc: 0.7886 - val_binary_accuracy: 0.9503 - val_recall_3: 0.1250 - val_precision_3: 0.3846\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1338 - acc: 0.9591 - auc: 0.8699 - binary_accuracy: 0.9591 - recall_3: 0.1897 - precision_3: 0.7164 - val_loss: 0.1720 - val_acc: 0.9538 - val_auc: 0.7680 - val_binary_accuracy: 0.9538 - val_recall_3: 0.0625 - val_precision_3: 0.5000\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1501 - acc: 0.9553 - auc: 0.8296 - binary_accuracy: 0.9553 - recall_3: 0.1462 - precision_3: 0.5606 - val_loss: 0.1714 - val_acc: 0.9532 - val_auc: 0.7667 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1465 - acc: 0.9556 - auc: 0.8340 - binary_accuracy: 0.9556 - recall_3: 0.0949 - precision_3: 0.6316 - val_loss: 0.1637 - val_acc: 0.9468 - val_auc: 0.7976 - val_binary_accuracy: 0.9468 - val_recall_3: 0.0500 - val_precision_3: 0.2000\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1520 - acc: 0.9527 - auc: 0.8244 - binary_accuracy: 0.9527 - recall_3: 0.1542 - precision_3: 0.4643 - val_loss: 0.1976 - val_acc: 0.9532 - val_auc: 0.6923 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0125 - val_precision_3: 0.3333\n",
      "0.16184794902801514\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "e1df9321-5a6e-4567-ab90-8ca45c94d4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "1d626bcd-7abd-4dd3-97d0-f5c1d51229bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9445086705202312 MSE:  0.055491329479768786 UAR:  0.5903030303030303 Recall:  0.2 Precision:  0.3333333333333333 F1:  0.25\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9520231213872833 MSE:  0.04797687861271676 UAR:  0.5526136363636364 Recall:  0.1125 Precision:  0.42857142857142855 F1:  0.1782178217821782\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5297348484848485 Recall:  0.0625 Precision:  0.5 F1:  0.1111111111111111\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.954335260115607 MSE:  0.04566473988439306 UAR:  0.5181439393939394 Recall:  0.0375 Precision:  0.6 F1:  0.07058823529411765\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.4993939393939394 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.5903030303030303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "3991fd5f-1db4-455d-972b-c78759bfca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "cf6a262a-b645-4cf1-9927-cb6ee39c0a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "fcb15030-bc45-43ba-b810-39fdbc10236e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.8549132947976879 MSE:  0.14508670520231215 UAR:  0.6979545454545455 Recall:  0.525 Precision:  0.16470588235294117 F1:  0.2507462686567164\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9260115606936417 MSE:  0.07398843930635839 UAR:  0.6460227272727272 Recall:  0.3375 Precision:  0.2647058823529412 F1:  0.29670329670329665\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.946242774566474 MSE:  0.05375722543352601 UAR:  0.5852651515151515 Recall:  0.1875 Precision:  0.3488372093023256 F1:  0.2439024390243903\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.954335260115607 MSE:  0.04566473988439306 UAR:  0.5716666666666667 Recall:  0.15 Precision:  0.5217391304347826 F1:  0.23300970873786406\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.5350757575757575 Recall:  0.075 Precision:  0.42857142857142855 F1:  0.1276595744680851\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5118939393939393 Recall:  0.025 Precision:  0.5 F1:  0.047619047619047616\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6979545454545455\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437e9b8c-2d80-41f6-bf80-c0d37b02f075",
   "metadata": {},
   "source": [
    "### STAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a631b348-bc81-47ba-9a37-6d7823acace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = compute_descriptor\n",
    "stat_name = \"STAT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9e486c-c1a2-4285-b6c0-c126ee6eb29d",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fe8fe376-4231-4ab2-9950-beff9b4823fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ab99b879-bda8-41c7-b9b2-28b903171d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f7d1247b-7cc8-47fe-974b-fc1685e48bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "test:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n",
      "val:\n",
      "0 1537/1720: 89.36046511627907%\n",
      "1 183/1720: 10.63953488372093%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec0491b-3265-4842-97f9-61301952fc6e",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "759c24c9-1e51-4b4d-834e-b095c703d3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "89573297-4392-4b3c-b015-0f5fdf3189f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "68e4b75a-14b9-4363-be86-e187cf99f222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 3840) (5482,)\n",
      "(1723, 128, 3840) (1723,)\n",
      "(1720, 128, 3840) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0d095942-1c9a-4d3c-9530-43ec309177c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5234  248] {0: 1.0, 1: 21.10483870967742} 2 [0 1]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2ff1d42c-fce2-4e4a-aad0-d4f31e86862f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1966592   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1970946 (7.52 MB)\n",
      "Trainable params: 1970946 (7.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "#save_best_model = SaveBestModelByUAR(X_subsample_val, y_subsample_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d1893467-e7c5-471d-be6d-d053b0754f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "43/43 [==============================] - 6s 95ms/step - loss: 1.3552 - acc: 0.6476 - auc: 0.6517 - binary_accuracy: 0.6476 - recall_4: 0.5927 - precision_4: 0.0743 - val_loss: 0.7934 - val_acc: 0.5988 - val_auc: 0.6766 - val_binary_accuracy: 0.5988 - val_recall_4: 0.6721 - val_precision_4: 0.1633\n",
      "Epoch 2/11\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 1.0784 - acc: 0.7344 - auc: 0.7831 - binary_accuracy: 0.7344 - recall_4: 0.7097 - precision_4: 0.1128 - val_loss: 0.7322 - val_acc: 0.6145 - val_auc: 0.6804 - val_binary_accuracy: 0.6145 - val_recall_4: 0.6175 - val_precision_4: 0.1601\n",
      "Epoch 3/11\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 1.0498 - acc: 0.7381 - auc: 0.7994 - binary_accuracy: 0.7381 - recall_4: 0.7097 - precision_4: 0.1143 - val_loss: 0.5746 - val_acc: 0.6738 - val_auc: 0.6748 - val_binary_accuracy: 0.6738 - val_recall_4: 0.5301 - val_precision_4: 0.1696\n",
      "Epoch 4/11\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 1.0115 - acc: 0.7373 - auc: 0.8112 - binary_accuracy: 0.7373 - recall_4: 0.6976 - precision_4: 0.1125 - val_loss: 0.5683 - val_acc: 0.6919 - val_auc: 0.6692 - val_binary_accuracy: 0.6919 - val_recall_4: 0.4973 - val_precision_4: 0.1720\n",
      "Epoch 5/11\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.9966 - acc: 0.7428 - auc: 0.8180 - binary_accuracy: 0.7428 - recall_4: 0.7258 - precision_4: 0.1183 - val_loss: 0.5766 - val_acc: 0.6884 - val_auc: 0.6738 - val_binary_accuracy: 0.6884 - val_recall_4: 0.5137 - val_precision_4: 0.1738\n",
      "Epoch 6/11\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.9454 - acc: 0.7618 - auc: 0.8396 - binary_accuracy: 0.7618 - recall_4: 0.7661 - precision_4: 0.1321 - val_loss: 0.5083 - val_acc: 0.7314 - val_auc: 0.6671 - val_binary_accuracy: 0.7314 - val_recall_4: 0.4153 - val_precision_4: 0.1763\n",
      "Epoch 7/11\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.9122 - acc: 0.7727 - auc: 0.8517 - binary_accuracy: 0.7727 - recall_4: 0.7500 - precision_4: 0.1358 - val_loss: 0.6484 - val_acc: 0.6442 - val_auc: 0.6704 - val_binary_accuracy: 0.6442 - val_recall_4: 0.5738 - val_precision_4: 0.1643\n",
      "Epoch 8/11\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.8804 - acc: 0.7775 - auc: 0.8625 - binary_accuracy: 0.7775 - recall_4: 0.7540 - precision_4: 0.1389 - val_loss: 0.6776 - val_acc: 0.6302 - val_auc: 0.6656 - val_binary_accuracy: 0.6302 - val_recall_4: 0.6011 - val_precision_4: 0.1634\n",
      "Epoch 9/11\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.8770 - acc: 0.7769 - auc: 0.8632 - binary_accuracy: 0.7769 - recall_4: 0.7823 - precision_4: 0.1423 - val_loss: 0.4768 - val_acc: 0.7709 - val_auc: 0.6655 - val_binary_accuracy: 0.7709 - val_recall_4: 0.3443 - val_precision_4: 0.1869\n",
      "Epoch 10/11\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.8656 - acc: 0.7798 - auc: 0.8681 - binary_accuracy: 0.7798 - recall_4: 0.7742 - precision_4: 0.1430 - val_loss: 0.6489 - val_acc: 0.6552 - val_auc: 0.6734 - val_binary_accuracy: 0.6552 - val_recall_4: 0.5464 - val_precision_4: 0.1639\n",
      "Epoch 11/11\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.8528 - acc: 0.7784 - auc: 0.8720 - binary_accuracy: 0.7784 - recall_4: 0.8185 - precision_4: 0.1479 - val_loss: 0.4713 - val_acc: 0.7773 - val_auc: 0.6629 - val_binary_accuracy: 0.7773 - val_recall_4: 0.3333 - val_precision_4: 0.1894\n",
      "0.47132202982902527\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=11, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "acccf113-96fc-4168-ba50-86177f5b2a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_2765461/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f65aab52-1536-44cf-a377-8e528268810b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.403946604759141 MSE:  0.596053395240859 UAR:  0.6195827048768225 Recall:  0.8588235294117647 Precision:  0.06709558823529412 F1:  0.12446717817561806\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.6987811955890888 MSE:  0.3012188044109112 UAR:  0.6686849098613804 Recall:  0.6352941176470588 Precision:  0.0996309963099631 F1:  0.17224880382775118\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.8183401044689496 MSE:  0.1816598955310505 UAR:  0.6702183437477556 Recall:  0.5058823529411764 Precision:  0.13694267515923567 F1:  0.21553884711779447\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.881601857225769 MSE:  0.118398142774231 UAR:  0.6700280112044819 Recall:  0.43529411764705883 Precision:  0.19170984455958548 F1:  0.2661870503597122\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.9117817759721416 MSE:  0.08821822402785838 UAR:  0.6524384112619407 Recall:  0.36470588235294116 Precision:  0.24031007751937986 F1:  0.2897196261682243\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.9373186302959954 MSE:  0.06268136970400465 UAR:  0.6156755009696186 Recall:  0.25882352941176473 Precision:  0.3283582089552239 F1:  0.2894736842105263\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.9454439930354034 MSE:  0.054556006964596636 UAR:  0.5864863894275659 Recall:  0.18823529411764706 Precision:  0.3902439024390244 F1:  0.25396825396825395\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5557710263592617 Recall:  0.11764705882352941 Precision:  0.5 F1:  0.19047619047619047\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5340731164260576 Recall:  0.07058823529411765 Precision:  0.6 F1:  0.12631578947368421\n",
      "0.3 0.6702183437477556\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name, from_int=True)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "04079aea-bab3-4386-bca3-91c09d4fe3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aee1f13b-bd32-4553-ab76-4d1cc47660ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_2765461/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2c88572b-478b-4dd5-9124-efa9be55a090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.403946604759141 MSE:  0.596053395240859 UAR:  0.6195827048768225 Recall:  0.8588235294117647 Precision:  0.06709558823529412 F1:  0.12446717817561806\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.6987811955890888 MSE:  0.3012188044109112 UAR:  0.6686849098613804 Recall:  0.6352941176470588 Precision:  0.0996309963099631 F1:  0.17224880382775118\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.8183401044689496 MSE:  0.1816598955310505 UAR:  0.6702183437477556 Recall:  0.5058823529411764 Precision:  0.13694267515923567 F1:  0.21553884711779447\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.881601857225769 MSE:  0.118398142774231 UAR:  0.6700280112044819 Recall:  0.43529411764705883 Precision:  0.19170984455958548 F1:  0.2661870503597122\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.9117817759721416 MSE:  0.08821822402785838 UAR:  0.6524384112619407 Recall:  0.36470588235294116 Precision:  0.24031007751937986 F1:  0.2897196261682243\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.9373186302959954 MSE:  0.06268136970400465 UAR:  0.6156755009696186 Recall:  0.25882352941176473 Precision:  0.3283582089552239 F1:  0.2894736842105263\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.9454439930354034 MSE:  0.054556006964596636 UAR:  0.5864863894275659 Recall:  0.18823529411764706 Precision:  0.3902439024390244 F1:  0.25396825396825395\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5557710263592617 Recall:  0.11764705882352941 Precision:  0.5 F1:  0.19047619047619047\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5340731164260576 Recall:  0.07058823529411765 Precision:  0.6 F1:  0.12631578947368421\n",
      "0.3 0.6702183437477556\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name, from_int=True)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469408e2-6e8b-447c-b0d1-f08466e78188",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d887544a-5c87-4d37-a121-fe392c172e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6ab23fa5-22c0-42a3-b799-1e1e5d03fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "acd5ee2c-15d8-4764-adcf-810280bca6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f8b9406c-ab8d-4936-b6a7-6c9050a54106",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_6 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_6[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_6[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "07d53e64-0459-4bde-afb9-180952609504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 127ms/step - loss: 0.3520 - acc: 0.9435 - auc: 0.5372 - binary_accuracy: 0.9435 - recall_1: 0.0121 - precision_1: 0.0441 - val_loss: 0.3655 - val_acc: 0.8936 - val_auc: 0.6054 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1676 - acc: 0.9544 - auc: 0.7332 - binary_accuracy: 0.9544 - recall_1: 0.0081 - precision_1: 0.3333 - val_loss: 0.4156 - val_acc: 0.8936 - val_auc: 0.6291 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1589 - acc: 0.9533 - auc: 0.7800 - binary_accuracy: 0.9533 - recall_1: 0.0081 - precision_1: 0.1667 - val_loss: 0.3692 - val_acc: 0.8907 - val_auc: 0.6405 - val_binary_accuracy: 0.8907 - val_recall_1: 0.0328 - val_precision_1: 0.3529\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1570 - acc: 0.9538 - auc: 0.7916 - binary_accuracy: 0.9538 - recall_1: 0.0282 - precision_1: 0.3684 - val_loss: 0.4193 - val_acc: 0.8930 - val_auc: 0.6368 - val_binary_accuracy: 0.8930 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1648 - acc: 0.9526 - auc: 0.7644 - binary_accuracy: 0.9526 - recall_1: 0.0403 - precision_1: 0.3125 - val_loss: 0.3956 - val_acc: 0.8936 - val_auc: 0.6295 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1544 - acc: 0.9557 - auc: 0.8021 - binary_accuracy: 0.9557 - recall_1: 0.0524 - precision_1: 0.6190 - val_loss: 0.3884 - val_acc: 0.8942 - val_auc: 0.6372 - val_binary_accuracy: 0.8942 - val_recall_1: 0.0164 - val_precision_1: 0.6000\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1498 - acc: 0.9564 - auc: 0.8126 - binary_accuracy: 0.9564 - recall_1: 0.0726 - precision_1: 0.6667 - val_loss: 0.4350 - val_acc: 0.8936 - val_auc: 0.6258 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1505 - acc: 0.9562 - auc: 0.7941 - binary_accuracy: 0.9562 - recall_1: 0.0927 - precision_1: 0.6053 - val_loss: 0.4107 - val_acc: 0.8936 - val_auc: 0.6443 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1529 - acc: 0.9529 - auc: 0.8132 - binary_accuracy: 0.9529 - recall_1: 0.0565 - precision_1: 0.3684 - val_loss: 0.3560 - val_acc: 0.8901 - val_auc: 0.6600 - val_binary_accuracy: 0.8901 - val_recall_1: 0.0328 - val_precision_1: 0.3333\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1611 - acc: 0.9544 - auc: 0.7951 - binary_accuracy: 0.9544 - recall_1: 0.0766 - precision_1: 0.4750 - val_loss: 0.3404 - val_acc: 0.8919 - val_auc: 0.6709 - val_binary_accuracy: 0.8919 - val_recall_1: 0.0164 - val_precision_1: 0.3333\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1480 - acc: 0.9551 - auc: 0.8080 - binary_accuracy: 0.9551 - recall_1: 0.0645 - precision_1: 0.5333 - val_loss: 0.3748 - val_acc: 0.8791 - val_auc: 0.6659 - val_binary_accuracy: 0.8791 - val_recall_1: 0.0546 - val_precision_1: 0.2222\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1393 - acc: 0.9577 - auc: 0.8477 - binary_accuracy: 0.9577 - recall_1: 0.1169 - precision_1: 0.6905 - val_loss: 0.4060 - val_acc: 0.8843 - val_auc: 0.6437 - val_binary_accuracy: 0.8843 - val_recall_1: 0.0328 - val_precision_1: 0.2143\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1391 - acc: 0.9584 - auc: 0.8543 - binary_accuracy: 0.9584 - recall_1: 0.1694 - precision_1: 0.6562 - val_loss: 0.4013 - val_acc: 0.8913 - val_auc: 0.6270 - val_binary_accuracy: 0.8913 - val_recall_1: 0.0055 - val_precision_1: 0.1667\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1430 - acc: 0.9564 - auc: 0.8307 - binary_accuracy: 0.9564 - recall_1: 0.1250 - precision_1: 0.5849 - val_loss: 0.4422 - val_acc: 0.8936 - val_auc: 0.6349 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0164 - val_precision_1: 0.5000\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1403 - acc: 0.9593 - auc: 0.8408 - binary_accuracy: 0.9593 - recall_1: 0.1532 - precision_1: 0.7451 - val_loss: 0.3936 - val_acc: 0.8860 - val_auc: 0.6520 - val_binary_accuracy: 0.8860 - val_recall_1: 0.0273 - val_precision_1: 0.2174\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1331 - acc: 0.9599 - auc: 0.8623 - binary_accuracy: 0.9599 - recall_1: 0.1815 - precision_1: 0.7258 - val_loss: 0.4326 - val_acc: 0.8890 - val_auc: 0.6155 - val_binary_accuracy: 0.8890 - val_recall_1: 0.0109 - val_precision_1: 0.1667\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1567 - acc: 0.9579 - auc: 0.8211 - binary_accuracy: 0.9579 - recall_1: 0.1855 - precision_1: 0.6133 - val_loss: 0.6409 - val_acc: 0.8901 - val_auc: 0.5315 - val_binary_accuracy: 0.8901 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1939 - acc: 0.9513 - auc: 0.7187 - binary_accuracy: 0.9513 - recall_1: 0.0927 - precision_1: 0.3538 - val_loss: 0.4528 - val_acc: 0.8924 - val_auc: 0.6278 - val_binary_accuracy: 0.8924 - val_recall_1: 0.0109 - val_precision_1: 0.3333\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1382 - acc: 0.9582 - auc: 0.8531 - binary_accuracy: 0.9582 - recall_1: 0.1532 - precision_1: 0.6667 - val_loss: 0.4255 - val_acc: 0.8831 - val_auc: 0.6076 - val_binary_accuracy: 0.8831 - val_recall_1: 0.0328 - val_precision_1: 0.2000\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1471 - acc: 0.9573 - auc: 0.8318 - binary_accuracy: 0.9573 - recall_1: 0.1653 - precision_1: 0.6029 - val_loss: 0.3628 - val_acc: 0.8831 - val_auc: 0.6370 - val_binary_accuracy: 0.8831 - val_recall_1: 0.0273 - val_precision_1: 0.1786\n",
      "0.340364933013916\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3ff34fe8-4316-41f9-abef-603e301066a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b05172a7-1b08-4536-ad17-e1174531ffc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.8415554265815438 MSE:  0.1584445734184562 UAR:  0.6043489190548015 Recall:  0.3411764705882353 Precision:  0.11788617886178862 F1:  0.17522658610271902\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.930354033662217 MSE:  0.06964596633778293 UAR:  0.5450872656755009 Recall:  0.11764705882352941 Precision:  0.18181818181818182 F1:  0.14285714285714285\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9437028438769588 MSE:  0.05629715612304121 UAR:  0.5409538174244057 Recall:  0.09411764705882353 Precision:  0.2857142857142857 F1:  0.1415929203539823\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.947185142193848 MSE:  0.05281485780615206 UAR:  0.526054011348129 Recall:  0.058823529411764705 Precision:  0.3125 F1:  0.09900990099009901\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5281907634848811 Recall:  0.058823529411764705 Precision:  0.5555555555555556 F1:  0.10638297872340426\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5229189111542053 Recall:  0.047058823529411764 Precision:  0.6666666666666666 F1:  0.08791208791208792\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9529889727219966 MSE:  0.047011027278003485 UAR:  0.5235294117647059 Recall:  0.047058823529411764 Precision:  1.0 F1:  0.0898876404494382\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5176470588235295 Recall:  0.03529411764705882 Precision:  1.0 F1:  0.06818181818181818\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5117647058823529 Recall:  0.023529411764705882 Precision:  1.0 F1:  0.04597701149425288\n",
      "0.1 0.6043489190548015\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6193ddee-b958-4025-8d29-4f5702e590a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "96b1f3ff-f8f9-402d-83c5-f27bbd960b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a43db0a1-e636-4c52-9a83-fb66352d7e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.8340104468949506 MSE:  0.16598955310504934 UAR:  0.6282661782661783 Recall:  0.4 Precision:  0.12639405204460966 F1:  0.192090395480226\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9297736506094022 MSE:  0.0702263493905978 UAR:  0.5949759390935861 Recall:  0.2235294117647059 Precision:  0.25675675675675674 F1:  0.2389937106918239\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9477655252466628 MSE:  0.0522344747533372 UAR:  0.5653989801048624 Recall:  0.1411764705882353 Precision:  0.41379310344827586 F1:  0.21052631578947367\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5566867772750126 Recall:  0.11764705882352941 Precision:  0.5882352941176471 F1:  0.19607843137254902\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9529889727219966 MSE:  0.047011027278003485 UAR:  0.5402607196724843 Recall:  0.08235294117647059 Precision:  0.7 F1:  0.14736842105263157\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5288012640953818 Recall:  0.058823529411764705 Precision:  0.7142857142857143 F1:  0.10869565217391305\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9500870574579222 MSE:  0.04991294254207777 UAR:  0.5052718523306758 Recall:  0.011764705882352941 Precision:  0.3333333333333333 F1:  0.022727272727272728\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5058823529411764 Recall:  0.011764705882352941 Precision:  1.0 F1:  0.023255813953488372\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6282661782661783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42afbc2f-a062-4f50-9120-1ecefc1401d0",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c09b85dd-bf21-4bb4-9c5c-012f383b23b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c2396165-e1e3-44f3-8e44-f72206f02ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d5693bdc-de36-4515-89e6-56fe9759a06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "val:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a8d70f21-307e-4585-bdee-4676d376eef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 2560) (5482,)\n",
      "(1723, 2560) (1723,)\n",
      "(7205, 2560) (7205,)\n",
      "[0 1] [6872  333]\n",
      "7205\n",
      "5475\n",
      "1730\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "225c2205-5a44-423c-bf3e-0b9727a2d0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5222/5475: 95.37899543378995%\n",
      "1 253/5475: 4.621004566210046%\n",
      "val:\n",
      "0 1650/1730: 95.3757225433526%\n",
      "1 80/1730: 4.624277456647399%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7235c4c5-7e3d-442f-91cc-1156da41589f",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "60f389bc-4493-48c2-97a0-5bb8f40f74d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1b6eb940-0809-4408-b990-5f0f3fe51a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ec07a0bb-8ad8-4b34-a2da-8f4f02ca1f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 3840) (5475,)\n",
      "(1730, 128, 3840) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f4141e24-7757-4115-b8e9-f55e2b39e0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5222  253] {0: 1.0, 1: 20.640316205533598} 2 [0 1]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dcd76d67-d959-4478-8073-99a8d961f2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3840)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3841      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3840, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3840)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3840)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3840)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1966592   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1970946 (7.52 MB)\n",
      "Trainable params: 1970946 (7.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "#save_best_model = SaveBestModelByUAR(X_subsample_test, y_subsample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e0465cf8-8c96-4c41-b69d-a85c557147c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "43/43 [==============================] - 5s 93ms/step - loss: 1.2319 - acc: 0.6530 - auc: 0.6958 - binary_accuracy: 0.6530 - recall_5: 0.6166 - precision_5: 0.0796 - val_loss: 0.5303 - val_acc: 0.7821 - val_auc: 0.7755 - val_binary_accuracy: 0.7821 - val_recall_5: 0.6500 - val_precision_5: 0.1297\n",
      "Epoch 2/11\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 1.1106 - acc: 0.7507 - auc: 0.7852 - binary_accuracy: 0.7507 - recall_5: 0.7036 - precision_5: 0.1213 - val_loss: 0.4811 - val_acc: 0.7954 - val_auc: 0.7831 - val_binary_accuracy: 0.7954 - val_recall_5: 0.6500 - val_precision_5: 0.1376\n",
      "Epoch 3/11\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 1.0441 - acc: 0.7468 - auc: 0.7991 - binary_accuracy: 0.7468 - recall_5: 0.7194 - precision_5: 0.1216 - val_loss: 0.4548 - val_acc: 0.8197 - val_auc: 0.7902 - val_binary_accuracy: 0.8197 - val_recall_5: 0.6125 - val_precision_5: 0.1485\n",
      "Epoch 4/11\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.9752 - acc: 0.7669 - auc: 0.8297 - binary_accuracy: 0.7669 - recall_5: 0.7312 - precision_5: 0.1328 - val_loss: 0.6768 - val_acc: 0.6399 - val_auc: 0.7838 - val_binary_accuracy: 0.6399 - val_recall_5: 0.7625 - val_precision_5: 0.0917\n",
      "Epoch 5/11\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.9528 - acc: 0.7543 - auc: 0.8356 - binary_accuracy: 0.7543 - recall_5: 0.7391 - precision_5: 0.1276 - val_loss: 0.4236 - val_acc: 0.8225 - val_auc: 0.7800 - val_binary_accuracy: 0.8225 - val_recall_5: 0.5625 - val_precision_5: 0.1420\n",
      "Epoch 6/11\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.9076 - acc: 0.7830 - auc: 0.8537 - binary_accuracy: 0.7830 - recall_5: 0.7312 - precision_5: 0.1418 - val_loss: 0.5353 - val_acc: 0.7370 - val_auc: 0.7865 - val_binary_accuracy: 0.7370 - val_recall_5: 0.6875 - val_precision_5: 0.1134\n",
      "Epoch 7/11\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.9358 - acc: 0.7627 - auc: 0.8412 - binary_accuracy: 0.7627 - recall_5: 0.7312 - precision_5: 0.1306 - val_loss: 1.0349 - val_acc: 0.3960 - val_auc: 0.7822 - val_binary_accuracy: 0.3960 - val_recall_5: 0.9000 - val_precision_5: 0.0649\n",
      "Epoch 8/11\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.8982 - acc: 0.7695 - auc: 0.8563 - binary_accuracy: 0.7695 - recall_5: 0.7787 - precision_5: 0.1404 - val_loss: 0.6144 - val_acc: 0.6844 - val_auc: 0.7816 - val_binary_accuracy: 0.6844 - val_recall_5: 0.7125 - val_precision_5: 0.0983\n",
      "Epoch 9/11\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.8350 - acc: 0.7894 - auc: 0.8797 - binary_accuracy: 0.7894 - recall_5: 0.8142 - precision_5: 0.1570 - val_loss: 0.4236 - val_acc: 0.8156 - val_auc: 0.7860 - val_binary_accuracy: 0.8156 - val_recall_5: 0.6000 - val_precision_5: 0.1433\n",
      "Epoch 10/11\n",
      "43/43 [==============================] - 2s 49ms/step - loss: 0.7955 - acc: 0.8031 - auc: 0.8902 - binary_accuracy: 0.8031 - recall_5: 0.8024 - precision_5: 0.1649 - val_loss: 0.6191 - val_acc: 0.6844 - val_auc: 0.7807 - val_binary_accuracy: 0.6844 - val_recall_5: 0.7125 - val_precision_5: 0.0983\n",
      "Epoch 11/11\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.8126 - acc: 0.7916 - auc: 0.8838 - binary_accuracy: 0.7916 - recall_5: 0.8142 - precision_5: 0.1585 - val_loss: 0.5607 - val_acc: 0.7064 - val_auc: 0.7766 - val_binary_accuracy: 0.7064 - val_recall_5: 0.6625 - val_precision_5: 0.0993\n",
      "0.4235779047012329\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=11, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "54fddd93-f679-463c-af14-0abbca5268c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_2765461/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7546fcae-3e31-422b-8ebc-7b95d58b9972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.26878612716763006 MSE:  0.7312138728323699 UAR:  0.5869318181818182 Recall:  0.9375 Precision:  0.056179775280898875 F1:  0.10600706713780918\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.3832369942196532 MSE:  0.6167630057803468 UAR:  0.6171969696969697 Recall:  0.875 Precision:  0.062111801242236024 F1:  0.115990057995029\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.5 MSE:  0.5 UAR:  0.6665151515151515 Recall:  0.85 Precision:  0.0738327904451683 F1:  0.13586413586413587\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.6138728323699422 MSE:  0.3861271676300578 UAR:  0.6964772727272728 Recall:  0.7875 Precision:  0.08823529411764706 F1:  0.15869017632241814\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.708092485549133 MSE:  0.29190751445086704 UAR:  0.6923484848484849 Recall:  0.675 Precision:  0.10131332082551595 F1:  0.1761827079934747\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.7942196531791907 MSE:  0.20578034682080926 UAR:  0.6958712121212121 Recall:  0.5875 Precision:  0.12702702702702703 F1:  0.20888888888888887\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.8705202312138728 MSE:  0.12947976878612716 UAR:  0.700189393939394 Recall:  0.5125 Precision:  0.18141592920353983 F1:  0.2679738562091503\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.9271676300578034 MSE:  0.07283236994219654 UAR:  0.6942045454545455 Recall:  0.4375 Precision:  0.3017241379310345 F1:  0.3571428571428571\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.9502890173410404 MSE:  0.04971098265895954 UAR:  0.6290151515151515 Recall:  0.275 Precision:  0.44 F1:  0.3384615384615385\n",
      "0.7 0.700189393939394\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name, from_int=True)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b60663fc-8ee2-4be3-9a06-8115c5c64ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1a1034d9-0d49-4ea9-86ae-a982d84b052b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_2765461/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ec2d2997-864b-46a1-9567-d528de78aa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.2514450867052023 MSE:  0.7485549132947977 UAR:  0.5837878787878787 Recall:  0.95 Precision:  0.055596196049743966 F1:  0.1050449205252246\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.4485549132947977 MSE:  0.5514450867052023 UAR:  0.6395454545454545 Recall:  0.85 Precision:  0.06732673267326733 F1:  0.12477064220183488\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.6161849710982659 MSE:  0.3838150289017341 UAR:  0.697689393939394 Recall:  0.7875 Precision:  0.08873239436619719 F1:  0.15949367088607597\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.7514450867052023 MSE:  0.24855491329479767 UAR:  0.7210227272727272 Recall:  0.6875 Precision:  0.11956521739130435 F1:  0.20370370370370372\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.8219653179190751 MSE:  0.17803468208092485 UAR:  0.6925757575757576 Recall:  0.55 Precision:  0.13924050632911392 F1:  0.22222222222222224\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.8832369942196532 MSE:  0.11676300578034682 UAR:  0.6949621212121212 Recall:  0.4875 Precision:  0.195 F1:  0.2785714285714286\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.9167630057803469 MSE:  0.08323699421965318 UAR:  0.6709090909090909 Recall:  0.4 Precision:  0.25 F1:  0.3076923076923077\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.9427745664739884 MSE:  0.05722543352601156 UAR:  0.6191287878787879 Recall:  0.2625 Precision:  0.3442622950819672 F1:  0.2978723404255319\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.9497109826589596 MSE:  0.050289017341040465 UAR:  0.5514015151515151 Recall:  0.1125 Precision:  0.36 F1:  0.17142857142857143\n",
      "0.4 0.7210227272727272\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name, from_int=True)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e88a6c-37f4-4a04-af4f-3c94951cd318",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a7535654-0faf-4059-bdac-91d1dd5c6f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "65c4b648-1574-4538-a1c2-07991aecb2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "abf32348-69da-4d8f-8113-8ef24d85c56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 2560) (5475,)\n",
      "(1730, 128, 2560) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c484ce82-0616-4b12-913a-60811db09d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_7 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_7[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_7[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "c3975d20-204c-4f45-a196-63fe789f097d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 125ms/step - loss: 0.3764 - acc: 0.9412 - auc: 0.5374 - binary_accuracy: 0.9412 - recall_3: 0.0277 - precision_3: 0.0843 - val_loss: 0.1875 - val_acc: 0.9526 - val_auc: 0.6787 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0125 - val_precision_3: 0.2500\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1737 - acc: 0.9540 - auc: 0.7014 - binary_accuracy: 0.9540 - recall_3: 0.0514 - precision_3: 0.5200 - val_loss: 0.1701 - val_acc: 0.9526 - val_auc: 0.7431 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0250 - val_precision_3: 0.3333\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1627 - acc: 0.9536 - auc: 0.7562 - binary_accuracy: 0.9536 - recall_3: 0.0435 - precision_3: 0.4783 - val_loss: 0.1690 - val_acc: 0.9526 - val_auc: 0.7421 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1558 - acc: 0.9563 - auc: 0.7868 - binary_accuracy: 0.9563 - recall_3: 0.0751 - precision_3: 0.7917 - val_loss: 0.1788 - val_acc: 0.9532 - val_auc: 0.7731 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1543 - acc: 0.9558 - auc: 0.7960 - binary_accuracy: 0.9558 - recall_3: 0.0870 - precision_3: 0.6667 - val_loss: 0.1673 - val_acc: 0.9468 - val_auc: 0.7855 - val_binary_accuracy: 0.9468 - val_recall_3: 0.0375 - val_precision_3: 0.1667\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1532 - acc: 0.9542 - auc: 0.8100 - binary_accuracy: 0.9542 - recall_3: 0.0672 - precision_3: 0.5312 - val_loss: 0.1618 - val_acc: 0.9509 - val_auc: 0.7852 - val_binary_accuracy: 0.9509 - val_recall_3: 0.0500 - val_precision_3: 0.3077\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1613 - acc: 0.9542 - auc: 0.7767 - binary_accuracy: 0.9542 - recall_3: 0.0830 - precision_3: 0.5250 - val_loss: 0.1652 - val_acc: 0.9538 - val_auc: 0.7618 - val_binary_accuracy: 0.9538 - val_recall_3: 0.0125 - val_precision_3: 0.5000\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1583 - acc: 0.9538 - auc: 0.7944 - binary_accuracy: 0.9538 - recall_3: 0.0711 - precision_3: 0.5000 - val_loss: 0.1699 - val_acc: 0.9538 - val_auc: 0.7600 - val_binary_accuracy: 0.9538 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1508 - acc: 0.9556 - auc: 0.8224 - binary_accuracy: 0.9556 - recall_3: 0.0909 - precision_3: 0.6389 - val_loss: 0.1673 - val_acc: 0.9468 - val_auc: 0.7807 - val_binary_accuracy: 0.9468 - val_recall_3: 0.0375 - val_precision_3: 0.1667\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1453 - acc: 0.9567 - auc: 0.8235 - binary_accuracy: 0.9567 - recall_3: 0.1186 - precision_3: 0.6818 - val_loss: 0.1636 - val_acc: 0.9462 - val_auc: 0.7945 - val_binary_accuracy: 0.9462 - val_recall_3: 0.0750 - val_precision_3: 0.2400\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1429 - acc: 0.9558 - auc: 0.8417 - binary_accuracy: 0.9558 - recall_3: 0.1502 - precision_3: 0.5846 - val_loss: 0.1630 - val_acc: 0.9526 - val_auc: 0.7949 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0750 - val_precision_3: 0.4286\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1419 - acc: 0.9563 - auc: 0.8401 - binary_accuracy: 0.9563 - recall_3: 0.1225 - precision_3: 0.6458 - val_loss: 0.1636 - val_acc: 0.9480 - val_auc: 0.7922 - val_binary_accuracy: 0.9480 - val_recall_3: 0.0750 - val_precision_3: 0.2727\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1377 - acc: 0.9574 - auc: 0.8583 - binary_accuracy: 0.9574 - recall_3: 0.1502 - precision_3: 0.6786 - val_loss: 0.1665 - val_acc: 0.9532 - val_auc: 0.7744 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0625 - val_precision_3: 0.4545\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1382 - acc: 0.9569 - auc: 0.8516 - binary_accuracy: 0.9569 - recall_3: 0.1423 - precision_3: 0.6545 - val_loss: 0.1775 - val_acc: 0.9445 - val_auc: 0.7679 - val_binary_accuracy: 0.9445 - val_recall_3: 0.1625 - val_precision_3: 0.3095\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1597 - acc: 0.9536 - auc: 0.7827 - binary_accuracy: 0.9536 - recall_3: 0.1265 - precision_3: 0.4923 - val_loss: 0.1692 - val_acc: 0.9543 - val_auc: 0.7693 - val_binary_accuracy: 0.9543 - val_recall_3: 0.0625 - val_precision_3: 0.5556\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1370 - acc: 0.9582 - auc: 0.8615 - binary_accuracy: 0.9582 - recall_3: 0.1581 - precision_3: 0.7143 - val_loss: 0.1664 - val_acc: 0.9503 - val_auc: 0.7886 - val_binary_accuracy: 0.9503 - val_recall_3: 0.1250 - val_precision_3: 0.3846\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1338 - acc: 0.9591 - auc: 0.8699 - binary_accuracy: 0.9591 - recall_3: 0.1897 - precision_3: 0.7164 - val_loss: 0.1720 - val_acc: 0.9538 - val_auc: 0.7680 - val_binary_accuracy: 0.9538 - val_recall_3: 0.0625 - val_precision_3: 0.5000\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1501 - acc: 0.9553 - auc: 0.8296 - binary_accuracy: 0.9553 - recall_3: 0.1462 - precision_3: 0.5606 - val_loss: 0.1714 - val_acc: 0.9532 - val_auc: 0.7667 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1465 - acc: 0.9556 - auc: 0.8340 - binary_accuracy: 0.9556 - recall_3: 0.0949 - precision_3: 0.6316 - val_loss: 0.1637 - val_acc: 0.9468 - val_auc: 0.7976 - val_binary_accuracy: 0.9468 - val_recall_3: 0.0500 - val_precision_3: 0.2000\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1520 - acc: 0.9527 - auc: 0.8244 - binary_accuracy: 0.9527 - recall_3: 0.1542 - precision_3: 0.4643 - val_loss: 0.1976 - val_acc: 0.9532 - val_auc: 0.6923 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0125 - val_precision_3: 0.3333\n",
      "0.16184794902801514\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "5e8ed0b4-95e6-43cd-bafe-89a8b2ff7f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4da73c17-d735-4e0b-9376-5c543f1f011c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9445086705202312 MSE:  0.055491329479768786 UAR:  0.5903030303030303 Recall:  0.2 Precision:  0.3333333333333333 F1:  0.25\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9520231213872833 MSE:  0.04797687861271676 UAR:  0.5526136363636364 Recall:  0.1125 Precision:  0.42857142857142855 F1:  0.1782178217821782\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5297348484848485 Recall:  0.0625 Precision:  0.5 F1:  0.1111111111111111\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.954335260115607 MSE:  0.04566473988439306 UAR:  0.5181439393939394 Recall:  0.0375 Precision:  0.6 F1:  0.07058823529411765\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.4993939393939394 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.5903030303030303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e30cb4ba-e1b6-4966-b27a-e40fb22b9df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "bff6c999-062a-4d32-ba06-91ff46000aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "6a9042db-6d6b-4c36-af60-3925530424ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.8549132947976879 MSE:  0.14508670520231215 UAR:  0.6979545454545455 Recall:  0.525 Precision:  0.16470588235294117 F1:  0.2507462686567164\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9260115606936417 MSE:  0.07398843930635839 UAR:  0.6460227272727272 Recall:  0.3375 Precision:  0.2647058823529412 F1:  0.29670329670329665\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.946242774566474 MSE:  0.05375722543352601 UAR:  0.5852651515151515 Recall:  0.1875 Precision:  0.3488372093023256 F1:  0.2439024390243903\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.954335260115607 MSE:  0.04566473988439306 UAR:  0.5716666666666667 Recall:  0.15 Precision:  0.5217391304347826 F1:  0.23300970873786406\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.5350757575757575 Recall:  0.075 Precision:  0.42857142857142855 F1:  0.1276595744680851\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5118939393939393 Recall:  0.025 Precision:  0.5 F1:  0.047619047619047616\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6979545454545455\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3062cf9-e8cb-4ed8-8bfd-5f5456720532",
   "metadata": {},
   "source": [
    "## MobileNet_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1421a469-4d92-4e5d-93b7-fb50af3a38b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_key = 'mobilenet_7.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfbd48af-0c81-42c0-be75-abb8240bb409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['engaged', 'distracted']\n",
      "{'1100011002': 0, '1100011003': 0, '1100011004': 0, '1100011005': 0, '1100011006': 0, '1100011007': 0, '1100011008': 0, '1100011009': 0, '1100011010': 0, '1100011011': 0, '1100011012': 0, '1100011013': 0, '1100011014': 0, '1100011015': 0, '1100011016': 0, '1100011017': 0, '1100011018': 0, '1100011019': 0, '1100011020': 0, '1100011021': 0, '1100011022': 0, '1100011023': 0, '1100011025': 0, '1100011026': 0, '1100011027': 0, '1100011028': 0, '1100011029': 0, '1100011031': 0, '1100011032': 0, '1100011034': 0, '1100011035': 0, '1100011037': 0, '1100011038': 0, '1100011040': 0, '1100011046': 0, '1100011047': 0, '1100011048': 0, '1100011049': 0, '1100011050': 0, '1100011051': 0, '1100011052': 0, '1100011053': 0, '1100011054': 0, '1100011055': 0, '1100011056': 0, '1100011057': 0, '1100011058': 0, '1100011059': 0, '1100011060': 0, '1100011062': 0, '1100011063': 0, '1100011064': 0, '1100011066': 0, '1100011067': 0, '1100011068': 0, '1100011069': 0, '1100011070': 0, '1100011071': 0, '1100011072': 0, '1100011073': 0, '1100011075': 0, '1100011076': 0, '1100011078': 0, '1100011079': 0, '1100011080': 0, '1100011081': 0, '1100011082': 0, '1100011083': 0, '1100012001': 0, '1100012003': 0, '1100012007': 0, '1100012008': 0, '1100012009': 0, '1100012010': 0, '1100012011': 0, '1100012013': 0, '1100012014': 0, '1100012015': 0, '1100012016': 0, '1100012017': 0, '1100012018': 0, '1100012021': 0, '1100012022': 0, '1100012023': 0, '1100012025': 0, '1100012026': 0, '1100012027': 0, '1100012028': 0, '1100012030': 0, '1100012031': 0, '1100012032': 0, '1100012033': 0, '1100012036': 0, '1100012037': 0, '1100012038': 0, '1100012041': 0, '1100012042': 0, '1100012045': 0, '1100012046': 0, '1100012047': 0, '1100012049': 0, '1100012050': 0, '1100012051': 0, '1100012052': 0, '1100012057': 0, '1100012059': 0, '1100012060': 0, '1100012061': 0, '1100012062': 0, '1100012063': 0, '1100012064': 0, '1100012065': 0, '1100012066': 0, '1100012069': 0, '1100021001': 0, '1100021003': 1, '1100021015': 0, '1100021038': 0, '1100021039': 0, '1100021040': 0, '1100021045': 0, '1100021050': 0, '1100021055': 1, '1100022001': 0, '1100022002': 0, '1100022003': 0, '1100022004': 0, '1100022005': 1, '1100022008': 0, '1100022009': 0, '1100022014': 0, '1100022019': 0, '1100022020': 0, '1100022021': 0, '1100022022': 0, '1100022026': 0, '1100022027': 0, '1100022028': 0, '1100022029': 0, '1100022031': 0, '1100022035': 0, '1100022038': 0, '1100022039': 0, '1100022045': 0, '1100022046': 0, '1100022047': 0, '1100022048': 0, '1100022049': 0, '1100022051': 0, '1100022052': 0, '1100022053': 0, '1100022054': 0, '1100022055': 0, '1100022056': 0, '1100022057': 0, '1100041006': 0, '1100041015': 0, '1100041016': 0, '1100041017': 0, '1100041018': 0, '1100041021': 0, '1100041022': 0, '1100041023': 0, '1100041024': 0, '1100041029': 0, '1100041034': 0, '1100041044': 0, '1100041051': 0, '1100041052': 0, '1100042009': 0, '1100042010': 0, '1100042011': 0, '1100042017': 0, '1100042018': 0, '1100042019': 0, '1100042020': 0, '1100042023': 1, '1100042024': 0, '1100042025': 0, '1100042026': 1, '1100042029': 0, '1100042030': 0, '1100042031': 0, '1100042034': 0, '1100042040': 0, '1100042041': 0, '1100042058': 0, '1100042059': 0, '1100042060': 0, '1100051002': 0, '1100051004': 0, '1100051006': 0, '1100051007': 1, '1100051008': 0, '1100051009': 0, '1100051011': 0, '1100051012': 0, '1100051013': 0, '1100051014': 0, '1100051016': 1, '1100051017': 0, '1100051019': 0, '1100051020': 0, '1100051021': 0, '1100051022': 0, '1100051023': 0, '1100051024': 0, '1100051025': 0, '1100051026': 0, '1100051028': 0, '1100051029': 0, '1100051030': 1, '1100051031': 1, '1100051032': 0, '1100051033': 0, '1100051034': 0, '1100051035': 0, '1100051036': 0, '1100051037': 0, '1100051039': 0, '1100051041': 0, '1100051042': 0, '1100051044': 0, '1100051045': 0, '1100051046': 0, '1100051048': 0, '1100051049': 0, '1100051050': 0, '1100051051': 0, '1100051052': 0, '1100051053': 1, '1100051054': 0, '1100051055': 0, '1100051056': 0, '1100051057': 0, '1100051059': 0, '1100051061': 0, '1100051062': 0, '1100051064': 0, '1100051065': 0, '1100051066': 0, '1100051067': 0, '1100051068': 0, '1100051071': 0, '1100051076': 0, '1100051078': 0, '1100051079': 0, '1100052001': 0, '1100052002': 0, '1100052006': 0, '1100052007': 0, '1100052008': 0, '1100052009': 0, '1100052014': 1, '1100052023': 0, '1100052024': 0, '1100052026': 0, '1100052027': 0, '1100052028': 0, '1100052030': 0, '1100052031': 0, '1100052032': 0, '1100052033': 0, '1100052035': 0, '1100052036': 0, '1100052037': 0, '1100052038': 0, '1100052039': 0, '1100052040': 0, '1100052041': 0, '1100052047': 0, '1100052048': 0, '1100052049': 0, '1100052051': 0, '1100052055': 0, '1100052057': 0, '1100052060': 0, '1100052061': 0, '1100052062': 0, '1100052065': 0, '1100052068': 0, '1100052070': 0, '1100061009': 0, '1100061010': 0, '1100061011': 0, '1100061012': 0, '1100061013': 0, '1100061015': 0, '1100061016': 0, '1100061018': 0, '1100061019': 0, '1100061022': 0, '1100061023': 0, '1100061025': 0, '1100061027': 0, '1100061028': 0, '1100061030': 0, '1100061031': 0, '1100061032': 0, '1100061033': 0, '1100061034': 0, '1100061035': 0, '1100061036': 0, '1100061038': 0, '1100061039': 0, '1100061040': 0, '1100061042': 0, '1100061043': 0, '1100061044': 0, '1100061046': 0, '1100061047': 0, '1100061048': 0, '1100061049': 0, '1100061050': 0, '1100061051': 0, '1100061053': 0, '1100061057': 0, '1100061058': 0, '1100061061': 0, '1100061063': 0, '1100061064': 0, '1100061067': 0, '1100061068': 0, '1100061069': 0, '1100061073': 0, '1100061074': 0, '1100061077': 0, '1100061078': 0, '1100062004': 0, '1100062005': 0, '1100062007': 0, '1100062008': 1, '1100062009': 0, '1100062016': 0, '1100062017': 0, '1100062024': 0, '1100062028': 0, '1100062029': 0, '1100062036': 0, '1100062037': 0, '1100062044': 0, '1100062045': 1, '1100062046': 0, '1100062049': 1, '1100062051': 0, '1100062053': 0, '1100062054': 0, '1100062059': 0, '1100062060': 0, '1100062061': 0, '1100062062': 0, '1100062063': 0, '1100062064': 0, '1100062065': 0, '1100062066': 0, '1100062067': 0, '1100062068': 0, '1100062069': 0, '1100062070': 0, '1100062071': 0, '1100062072': 0, '1100071005': 0, '1100071006': 0, '1100071007': 0, '1100071008': 0, '1100071009': 0, '1100071010': 0, '1100071011': 0, '1100071012': 0, '1100071013': 0, '1100071014': 0, '1100071015': 0, '1100071016': 0, '1100071017': 0, '1100071018': 0, '1100071019': 0, '1100071020': 0, '1100071021': 0, '1100071022': 0, '1100071023': 0, '1100071024': 0, '1100071026': 0, '1100071027': 0, '1100071028': 0, '1100071029': 0, '1100071030': 0, '1100071031': 0, '1100071032': 0, '1100071033': 0, '1100071034': 0, '1100071035': 0, '1100071036': 0, '1100071037': 0, '1100071040': 0, '1100071041': 0, '1100071042': 0, '1100071043': 0, '1100071044': 0, '1100071045': 0, '1100071046': 0, '1100071047': 0, '1100071049': 0, '1100071050': 0, '1100071052': 0, '1100071054': 0, '1100071055': 0, '1100071056': 0, '1100071057': 0, '1100071058': 0, '1100071059': 0, '1100071060': 0, '1100071061': 0, '1100071062': 0, '1100071063': 0, '1100071064': 0, '1100071065': 0, '1100071066': 0, '1100071067': 0, '1100071069': 0, '1100071070': 0, '1100071071': 0, '1100071072': 0, '1100071073': 0, '1100071074': 0, '1100071075': 0, '1100071076': 0, '1100071077': 0, '1100071078': 0, '1100071079': 0, '1100071080': 0, '1100071081': 0, '1100072001': 0, '1100072002': 0, '1100072003': 0, '1100072004': 0, '1100072006': 0, '1100072007': 0, '1100072008': 0, '1100072009': 0, '1100072010': 0, '1100072011': 0, '1100072012': 0, '1100072013': 0, '1100072014': 0, '1100072015': 0, '1100072016': 0, '1100072021': 0, '1100072022': 0, '1100072023': 0, '1100072024': 0, '1100072027': 0, '1100072028': 0, '1100072029': 0, '1100072030': 0, '1100072031': 0, '1100072032': 0, '1100072033': 0, '1100072034': 0, '1100072036': 0, '1100072037': 0, '1100072038': 0, '1100072039': 0, '1100072040': 0, '1100072042': 0, '1100072043': 0, '1100072045': 0, '1100072047': 0, '1100072048': 0, '1100072049': 0, '1100072050': 0, '1100072051': 0, '1100072052': 0, '1100072053': 0, '1100072054': 0, '1100072056': 0, '1100072057': 0, '1100072058': 0, '1100072059': 0, '1100072060': 0, '1100072061': 0, '1100072062': 0, '1100072063': 0, '1100072065': 0, '1100072066': 0, '1100072067': 0, '1100072068': 0, '1100072069': 0, '1100072070': 0, '1100072071': 0, '1100072072': 0, '1100072073': 0, '1100072074': 0, '1100072075': 0, '1100072076': 0, '1100072077': 0, '1100072078': 0, '1100072079': 0, '1100072080': 0, '1100072081': 0, '1100072082': 0, '1100072083': 0, '1100072084': 0, '1100072085': 0, '1100081044': 0, '1100081045': 0, '1100081046': 0, '1100081047': 0, '1100081048': 0, '1100082002': 0, '1100082003': 0, '1100082018': 0, '1100082027': 0, '1100102003': 0, '1100111001': 0, '1100111002': 0, '1100111003': 0, '1100111008': 0, '1100111009': 0, '1100111010': 0, '1100111011': 0, '1100111012': 0, '1100111013': 0, '1100111014': 0, '1100111016': 0, '1100111017': 0, '1100111018': 0, '1100111019': 0, '1100111021': 0, '1100111023': 0, '1100111025': 0, '1100111026': 0, '1100111027': 0, '1100111029': 0, '1100111030': 0, '1100111032': 0, '1100112001': 0, '1100112002': 1, '1100112003': 0, '1100112004': 0, '1100112006': 1, '1100112007': 0, '1100112008': 0, '1100112009': 0, '1100112010': 0, '1100112011': 0, '1100112012': 0, '1100112013': 0, '1100112014': 0, '1100112015': 0, '1100112016': 0, '1100112017': 0, '1100112018': 0, '1100112021': 0, '1100112022': 0, '1100112024': 0, '1100112025': 0, '1100112026': 0, '1100112029': 0, '1100112030': 0, '1100112033': 0, '1100112035': 0, '1100112036': 0, '1100112037': 0, '1100112038': 0, '1100112039': 0, '1100112040': 0, '1100112041': 0, '1100112042': 0, '1100112043': 0, '1100112044': 0, '1100112045': 0, '1100112047': 0, '1100112048': 0, '1100112051': 0, '1100112052': 0, '1100112053': 0, '1100112056': 0, '1100112057': 0, '1100112058': 0, '1100112059': 0, '1100112060': 0, '1100112061': 0, '1100112062': 0, '1100112063': 0, '1100112064': 0, '1100112065': 0, '1100112066': 0, '1100112068': 0, '1100121002': 0, '1100121003': 0, '1100121004': 0, '1100121005': 0, '1100121006': 0, '1100121007': 0, '1100121008': 0, '1100121009': 0, '1100121010': 0, '1100121011': 0, '1100121012': 0, '1100121015': 0, '1100121016': 0, '1100121017': 0, '1100121018': 0, '1100121019': 0, '1100121020': 0, '1100121024': 0, '1100121025': 0, '1100121028': 0, '1100121031': 0, '1100121032': 0, '1100121033': 0, '1100121034': 0, '1100121035': 0, '1100121036': 0, '1100121038': 0, '1100121040': 0, '1100121041': 0, '1100121042': 0, '1100121044': 0, '1100121045': 0, '1100121047': 0, '1100121049': 0, '1100121050': 0, '1100121052': 0, '1100121053': 0, '1100121054': 0, '1100121056': 0, '1100121057': 0, '1100121059': 0, '1100121060': 0, '1100121061': 0, '1100121064': 0, '1100122001': 0, '1100122002': 0, '1100122003': 0, '1100122005': 0, '1100122006': 0, '1100122007': 0, '1100122008': 0, '1100122009': 0, '1100122010': 0, '1100122011': 0, '1100122012': 0, '1100122013': 0, '1100122014': 0, '1100122015': 0, '1100122017': 0, '1100122018': 0, '1100122019': 0, '1100122020': 0, '1100122021': 0, '1100122023': 0, '1100122024': 0, '1100122025': 0, '1100122026': 0, '1100122031': 0, '1100122032': 0, '1100122033': 0, '1100122034': 0, '1100122035': 0, '1100122036': 0, '1100122037': 0, '1100122038': 0, '1100122039': 0, '1100122040': 0, '1100122041': 0, '1100122045': 0, '1100122047': 0, '1100122048': 0, '1100122050': 0, '1100122051': 0, '1100122052': 0, '1100122053': 0, '1100122054': 0, '1100122056': 1, '1100131006': 0, '1100131007': 0, '1100131009': 0, '1100131010': 0, '1100131011': 0, '1100131012': 0, '1100131017': 1, '1100131019': 0, '1100141001': 0, '1100141002': 0, '1100141003': 0, '1100141004': 0, '1100141005': 0, '1100141006': 0, '1100141007': 0, '1100141008': 0, '1100141009': 0, '1100141010': 0, '1100141011': 0, '1100141012': 0, '1100141013': 1, '1100141014': 0, '1100141015': 0, '1100141016': 0, '1100141017': 0, '1100141019': 0, '1100141020': 0, '1100141021': 0, '1100141023': 0, '1100141027': 1, '1100141028': 0, '1100141029': 0, '1100141030': 0, '1100141031': 0, '1100141032': 0, '1100141033': 0, '1100141034': 0, '1100141035': 0, '1100141036': 0, '1100141039': 0, '1100141040': 0, '1100141042': 0, '1100141044': 0, '1100141045': 0, '1100141046': 0, '1100141049': 0, '1100141050': 0, '1100141052': 0, '1100141053': 0, '1100141054': 0, '1100141055': 0, '1100141056': 0, '1100141057': 0, '1100142002': 0, '1100142003': 0, '1100142004': 0, '1100142007': 0, '1100142008': 0, '1100142009': 0, '1100142010': 0, '1100142011': 0, '1100142013': 0, '1100142014': 0, '1100142015': 0, '1100142017': 0, '1100142018': 0, '1100142019': 0, '1100142021': 0, '1100142022': 0, '1100142023': 0, '1100142024': 0, '1100142027': 0, '1100142028': 0, '1100142029': 0, '1100142030': 0, '1100142031': 0, '1100142032': 0, '1100142033': 1, '1100142034': 0, '1100142035': 0, '1100142038': 0, '1100142041': 0, '1100142043': 0, '1100142044': 0, '1100142045': 0, '1100142046': 0, '1100142048': 0, '1100142049': 0, '1100142050': 0, '1100142051': 0, '1100142052': 0, '1100142053': 0, '1100142056': 0, '1100142057': 0, '1100142058': 0, '1100142059': 0, '1100142060': 0, '1100151003': 0, '1100151004': 0, '1100151008': 0, '1100151009': 0, '1100151010': 0, '1100151011': 1, '1100151012': 0, '1100151013': 0, '1100151014': 0, '1100151015': 0, '1100151016': 0, '1100151017': 0, '1100151018': 0, '1100151019': 0, '1100151020': 0, '1100151021': 0, '1100151022': 0, '1100151023': 0, '1100151024': 0, '1100151028': 0, '1100151030': 0, '1100151032': 0, '1100151033': 0, '1100151035': 0, '1100151037': 0, '1100151038': 0, '1100151039': 0, '1100151040': 0, '1100151042': 0, '1100151043': 0, '1100151044': 0, '1100151047': 0, '1100151049': 0, '1100151050': 0, '1100151051': 0, '1100151052': 0, '1100151054': 0, '1100151055': 0, '1100151056': 0, '1100151057': 1, '1100151058': 0, '1100151062': 0, '1100152001': 0, '1100152004': 0, '1100152005': 0, '1100152006': 0, '1100152008': 0, '1100152009': 0, '1100152010': 1, '1100152013': 0, '1100152014': 0, '1100152015': 0, '1100152017': 1, '1100152019': 0, '1100152020': 0, '1100152022': 0, '1100152024': 0, '1100152025': 0, '1100152026': 0, '1100152027': 0, '1100152031': 1, '1100152032': 0, '1100152039': 0, '1100152040': 0, '1100152041': 0, '1100152042': 0, '1100152043': 0, '1100152048': 0, '1100152049': 0, '1100152050': 0, '1100152051': 0, '1100152055': 1, '1100152056': 0, '1100152061': 0, '1100152062': 0, '1100152067': 0, '1100152069': 0, '1100152070': 1, '1100161002': 0, '1100161004': 0, '1100161011': 0, '1100161012': 0, '1100161013': 0, '1100161014': 0, '1100161015': 0, '1100161016': 0, '1100161020': 0, '1100161021': 0, '1100161022': 0, '1100161023': 0, '1100161028': 0, '1100161029': 0, '1100161032': 0, '1100161035': 0, '1100161036': 0, '1100161038': 0, '1100161039': 0, '1100161041': 0, '1100161043': 0, '1100161044': 0, '1100161045': 0, '1100161046': 0, '1100161048': 0, '1100161050': 0, '1100161053': 1, '1100162005': 1, '1100162007': 0, '1100162011': 0, '1100162016': 1, '1100171001': 0, '1100171002': 0, '1100171004': 1, '1100171005': 0, '1100171007': 0, '1100171008': 1, '1100171009': 0, '1100171010': 0, '1100171011': 0, '1100171012': 0, '1100171013': 0, '1100171015': 0, '1100171016': 0, '1100171017': 0, '1100171019': 0, '1100171021': 0, '1100171022': 0, '1100171023': 0, '1100171031': 0, '1100171035': 0, '1100171036': 0, '1100171038': 0, '1100171039': 0, '1100171040': 0, '1100171041': 0, '1100171043': 0, '1100171045': 0, '1100171049': 0, '1100171055': 0, '1100171056': 0, '1100171057': 0, '1100171059': 1, '1100171061': 0, '1100171063': 0, '1100171064': 0, '1100171065': 0, '1100171067': 0, '1100171069': 0, '1100171070': 0, '1100171071': 0, '1100171072': 0, '1100171073': 0, '1100171074': 0, '1100171075': 0, '1100171076': 0, '1100171077': 0, '1100171078': 0, '1100171080': 0, '1100171083': 0, '1100172003': 0, '1100172004': 0, '1100172007': 0, '1100172012': 1, '1100172013': 0, '1100172014': 0, '1100172015': 0, '1100172016': 0, '1100172017': 1, '1100172018': 0, '1100172020': 0, '1100172021': 0, '1100172022': 0, '1100172026': 0, '1100172028': 0, '1100172030': 0, '1100172032': 0, '1100172033': 1, '1100172034': 1, '1100172035': 0, '1100172037': 0, '1100172039': 0, '1100172042': 0, '1100172043': 1, '1100172047': 0, '1100172050': 0, '1100172058': 1, '1100172063': 0, '1100172066': 0, '1100411010': 0, '1100411011': 0, '1100411012': 0, '1100411013': 0, '1100411015': 0, '1100411016': 0, '1100411018': 0, '1100411020': 0, '1100411023': 0, '1100411036': 0, '1100411041': 0, '1100411045': 0, '1100411047': 0, '1100411048': 0, '1100411049': 0, '1100411050': 0, '1100411051': 0, '1100411053': 0, '1100411054': 0, '1100411055': 0, '1100411057': 0, '1100412001': 0, '1100412003': 0, '1100412010': 0, '1100412018': 1, '1100412033': 1, '1100412038': 0, '1100412039': 1, '1100412040': 0, '1110031003': 0, '1110031007': 0, '1110031010': 1, '1110031011': 0, '1110031012': 0, '1110031014': 0, '1110031019': 0, '1110031020': 0, '1110031021': 0, '1110031025': 1, '1110031027': 1, '1110031031': 0, '1110031033': 1, '1110031037': 0, '1110031038': 1, '1110031039': 0, '1110031040': 0, '1110031042': 0, '1110031048': 0, '1110031049': 0, '1110031050': 0, '1110031056': 1, '1110031061': 0, '1110031062': 0, '1110031063': 1, '1110031064': 0, '1110031065': 0, '1110032002': 0, '1110032004': 0, '1110032006': 0, '1110032008': 0, '1110032010': 0, '1110032014': 1, '1110032015': 0, '1110032018': 0, '1110032019': 0, '1110032020': 0, '1110032021': 0, '1110032022': 0, '1110032023': 0, '1110032024': 0, '1110032025': 0, '1110032027': 1, '1110032029': 0, '1110032031': 0, '1110032032': 0, '1110032033': 0, '1110032034': 0, '1110032036': 0, '1110032037': 0, '1110032042': 0, '1110032043': 1, '1110032045': 0, '1110032047': 0, '1110032048': 0, '1110032049': 0, '1110032050': 0, '1110032051': 0, '1110032052': 0, '1110032053': 0, '1110032055': 0, '1110032056': 0, '1110032058': 0, '1110032059': 0, '1110032060': 0, '1110032061': 0, '1110032062': 0, '1110032063': 0, '1813740111': 0, '1813740112': 0, '1813740115': 0, '1813740116': 0, '1813740118': 0, '1813740119': 0, '1813740122': 0, '1813740123': 0, '1813740124': 0, '1813740126': 0, '1813740127': 0, '1813740128': 0, '1813740131': 0, '1813740133': 0, '1813740135': 0, '1813740137': 0, '1813740138': 1, '1813740143': 0, '1813740144': 0, '1813740149': 0, '181374015': 0, '1813740150': 0, '1813740153': 0, '1813740155': 0, '1813740157': 0, '1813740159': 0, '181374016': 0, '1813740162': 0, '1813740164': 0, '1813740165': 0, '1813740167': 0, '1813740168': 0, '1813740169': 0, '181374017': 0, '1813740171': 0, '1813740172': 0, '1813740173': 0, '1813740174': 0, '1813740176': 0, '1813740178': 0, '1813740179': 0, '1813740180': 0, '1813740181': 0, '1813740182': 0, '1813740183': 0, '1813740184': 1, '1813740185': 1, '181374019': 0, '1813740210': 0, '1813740211': 0, '1813740212': 0, '1813740213': 0, '1813740214': 0, '1813740218': 0, '1813740219': 0, '1813740220': 0, '1813740221': 0, '1813740224': 0, '1813740225': 0, '1813740226': 0, '1813740227': 0, '1813740229': 0, '181374023': 0, '1813740231': 0, '1813740232': 0, '1813740233': 0, '1813740234': 0, '1813740235': 0, '1813740236': 0, '1813740237': 0, '1813740238': 0, '181374024': 0, '1813740240': 0, '1813740241': 0, '1813740242': 0, '1813740243': 0, '1813740245': 0, '1813740249': 0, '181374025': 0, '1813740250': 0, '1813740251': 0, '1813740252': 0, '1813740253': 0, '1813740255': 0, '1813740256': 0, '1813740257': 0, '1813740258': 0, '1813740259': 0, '181374026': 0, '1813740260': 0, '1813740261': 0, '1813740262': 0, '1813740263': 0, '1813740264': 0, '1813740265': 0, '1813740266': 0, '1813740267': 0, '1813740268': 0, '1813740269': 0, '181374027': 0, '1813740270': 0, '1813740271': 0, '1813740272': 0, '1813740273': 0, '1813740274': 0, '1813740275': 0, '1813740276': 0, '1813740277': 0, '1813740278': 0, '1813740279': 0, '181374028': 0, '181374029': 0, '2000481035': 0, '2000481036': 0, '2000481037': 0, '2000481038': 0, '2000481039': 0, '2000481040': 0, '2000481041': 0, '2000481043': 0, '2000481048': 0, '2000482008': 0, '2000482009': 0, '2000482012': 0, '2000482018': 0, '2000482021': 0, '2000482034': 0, '2000482037': 0, '2000482038': 0, '2000482039': 0, '2000482041': 0, '2000482042': 0, '2000482043': 0, '2000482044': 0, '2000482049': 0, '2000482050': 0, '2000482052': 0, '2000482059': 0, '2000482065': 0, '2000482066': 0, '2000482067': 0, '2000482068': 0, '2000482070': 0, '2000491062': 0, '2000491064': 0, '2000491065': 0, '2000491066': 0, '2000491067': 0, '2000491068': 0, '2000491070': 0, '2000491072': 0, '2000491074': 0, '2000491075': 0, '2000491076': 0, '2000491077': 1, '2000491078': 0, '2000491079': 0, '2000501001': 0, '2000501002': 0, '2000501003': 0, '2000501004': 0, '2000501006': 1, '2000501009': 0, '2000501010': 0, '2000501011': 0, '2000501012': 0, '2000501014': 0, '2000501015': 0, '2000501016': 0, '2000501018': 0, '2000501019': 0, '2000501020': 0, '2000501021': 0, '2000501023': 0, '2000501027': 0, '2000501028': 0, '2000501030': 1, '2000501031': 0, '2000501032': 0, '2000501033': 0, '2000501035': 0, '2000501036': 0, '2000501037': 0, '2000501038': 0, '2000501039': 0, '2000501040': 0, '2000501041': 0, '2000501042': 0, '2000501043': 0, '2000501044': 0, '2000501045': 0, '2000501046': 0, '2000501049': 0, '2000501050': 0, '2000501051': 0, '2000501052': 0, '2000501053': 0, '2000501054': 0, '2000501056': 0, '2000501057': 0, '2000501060': 0, '2000501061': 0, '2000501062': 0, '2000501063': 0, '2000501065': 0, '2000501066': 0, '2000501067': 0, '2000501071': 0, '2000501074': 0, '2000501075': 0, '2000501076': 0, '2000501078': 0, '2000502002': 0, '2000502005': 0, '2000502006': 0, '2000502007': 0, '2000502009': 0, '2000502010': 0, '2000502012': 0, '2000502013': 0, '2000502014': 0, '2000502015': 0, '2000502019': 0, '2000502020': 0, '2000502023': 0, '2000502025': 0, '2000502033': 0, '2000502036': 0, '2000502037': 0, '2000502039': 0, '2000502040': 0, '2000502041': 0, '2000502043': 0, '2000502044': 0, '2000502045': 0, '2000502047': 0, '2000502048': 0, '2000502049': 0, '2000502050': 0, '2000502051': 0, '2000502053': 1, '2000502054': 0, '2000502055': 0, '2000502056': 0, '2000502057': 0, '2000502058': 0, '2000502059': 0, '2000502061': 0, '2000502062': 0, '2000502063': 0, '2000502065': 1, '2000502066': 0, '2000502067': 0, '2000502069': 0, '2000502070': 0, '2000502072': 0, '2000502073': 0, '2000502075': 0, '2000502076': 0, '2000502077': 0, '2000502078': 0, '2000502081': 1, '2000502084': 0, '2000502087': 0, '2000502088': 0, '2000502090': 0, '2000541001': 0, '2000541002': 0, '2000541003': 0, '2000541006': 0, '2000541007': 0, '2000541010': 0, '2000541011': 0, '2000541014': 0, '2000541015': 0, '2000541016': 0, '2000541018': 0, '2000541019': 0, '2000541020': 0, '2000541021': 0, '2000541022': 0, '2000541023': 0, '2000541024': 0, '2000541025': 0, '2000541027': 0, '2000541028': 0, '2000541029': 0, '2000541030': 0, '2000541031': 0, '2000541032': 0, '2000541034': 0, '2000541035': 0, '2000541038': 0, '2000541039': 0, '2000541040': 0, '2000541041': 0, '2000541043': 0, '2000541044': 0, '2000541045': 0, '2000541046': 0, '2000541049': 0, '2000541050': 0, '2000541051': 0, '2000541052': 0, '2000541053': 0, '2000541054': 0, '2000541055': 0, '2000541056': 0, '2000541057': 0, '2000541059': 0, '2000541062': 0, '2000541064': 0, '2000541066': 0, '2000541067': 0, '2000541068': 0, '2000541069': 0, '2000541070': 0, '2000541071': 0, '2000541072': 0, '2000541073': 0, '2000541074': 0, '2000541075': 0, '2000541076': 0, '2000541077': 0, '2000541079': 0, '2000541080': 0, '2000541081': 0, '2000542001': 0, '2000542002': 0, '2000542007': 0, '2000542008': 0, '2000542009': 0, '2000542010': 0, '2000542013': 0, '2000542015': 0, '2000542016': 0, '2000542021': 0, '2000542022': 0, '2000542025': 0, '2000542026': 0, '2000542027': 0, '2000542029': 0, '2000542030': 0, '2000542032': 0, '2000542033': 0, '2000542034': 0, '2000542035': 0, '2000542036': 0, '2000542042': 0, '2000542049': 0, '2000542050': 0, '2000542051': 0, '2000542052': 0, '2000542054': 0, '2000542056': 0, '2026140111': 0, '2026140113': 0, '2026140116': 0, '2026140117': 0, '2026140118': 0, '2026140119': 0, '2026140120': 0, '2026140122': 0, '2026140124': 0, '2026140125': 0, '2026140126': 0, '2026140128': 0, '2026140129': 0, '2026140130': 0, '2026140131': 0, '2026140133': 0, '2026140134': 0, '2026140135': 0, '2026140138': 0, '2026140141': 0, '2026140145': 0, '2026140147': 0, '2026140149': 0, '202614015': 0, '2026140151': 0, '2026140154': 0, '2026140158': 0, '2026140159': 0, '202614016': 0, '2026140160': 0, '2026140161': 0, '2026140165': 0, '2026140169': 0, '202614017': 0, '2026140170': 0, '2026140172': 0, '202614018': 0, '202614019': 0, '202614020': 0, '202614021': 0, '2026140210': 0, '2026140212': 0, '2026140213': 0, '2026140220': 0, '2026140221': 0, '2026140223': 0, '2026140224': 0, '2026140225': 0, '202614023': 0, '2026140230': 0, '2026140233': 0, '2026140236': 0, '2026140237': 0, '2026140239': 0, '2026140241': 0, '2026140243': 0, '2026140246': 0, '2026140247': 0, '2026140249': 0, '202614025': 0, '2026140250': 0, '2026140253': 0, '2026140254': 0, '2026140255': 0, '2026140257': 1, '2026140259': 0, '2026140260': 0, '2026140263': 0, '2026140264': 1, '2026140272': 0, '2026140273': 1, '2026140275': 0, '2026140276': 0, '2026140277': 0, '2026140279': 0, '2026140281': 0, '202614029': 0, '205601011': 0, '2056010112': 0, '2056010113': 0, '2056010114': 0, '2056010116': 0, '2056010118': 0, '2056010119': 0, '205601012': 0, '2056010120': 0, '2056010122': 0, '2056010123': 0, '2056010124': 0, '2056010126': 0, '2056010130': 0, '2056010133': 0, '2056010134': 1, '2056010136': 0, '2056010137': 0, '2056010139': 0, '2056010141': 0, '2056010142': 0, '2056010148': 0, '2056010149': 0, '2056010153': 0, '2056010155': 0, '2056010156': 0, '2056010157': 0, '205601016': 0, '2056010160': 0, '2056010162': 0, '2056010164': 0, '2056010165': 0, '2056010167': 0, '205601017': 0, '205601018': 0, '2056010210': 0, '2056010212': 0, '2056010213': 0, '2056010214': 0, '2056010215': 0, '2056010218': 0, '2056010219': 0, '2056010222': 0, '2056010224': 1, '2056010225': 0, '2056010226': 0, '2056010228': 0, '2056010229': 0, '2056010230': 0, '2056010232': 0, '2056010233': 0, '2056010234': 0, '2056010235': 0, '2056010236': 0, '2056010238': 0, '2056010239': 0, '205601024': 0, '2056010240': 0, '2056010241': 0, '2056010242': 0, '2056010244': 0, '2056010245': 0, '2056010247': 0, '2056010249': 0, '205601025': 0, '2056010250': 0, '2056010252': 0, '2056010253': 0, '2056010254': 0, '2056010255': 0, '2056010258': 0, '2056010260': 0, '2056010261': 0, '2056010262': 0, '2056010263': 0, '2056010265': 0, '2056010267': 0, '2056010269': 0, '205601027': 0, '2056010272': 0, '2056010274': 0, '2056010275': 0, '2056010276': 0, '2056010277': 0, '2056010279': 0, '205601028': 0, '2056010281': 0, '2056010283': 0, '2100511002': 0, '2100511003': 0, '2100511005': 0, '2100511008': 0, '2100511011': 0, '2100511012': 0, '2100511013': 0, '2100511015': 0, '2100511016': 0, '2100511018': 0, '2100511019': 0, '2100511024': 0, '2100511026': 0, '2100511027': 0, '2100511028': 0, '2100511031': 0, '2100511032': 0, '2100511034': 0, '2100511035': 0, '2100511036': 0, '2100511038': 0, '2100511039': 0, '2100511040': 0, '2100511044': 0, '2100511048': 0, '2100511057': 0, '2100511058': 0, '2100511059': 0, '2100511060': 0, '2100511061': 0, '2100511062': 0, '2100511063': 0, '2100511064': 0, '2100511065': 0, '2100511067': 0, '2100511069': 1, '2100511070': 0, '2100511071': 0, '2100511072': 0, '2100511073': 0, '2100511074': 0, '2100511076': 0, '2100511077': 0, '2100511078': 0, '2100511079': 0, '2100511080': 0, '2100511081': 0, '2100511082': 0, '2100512001': 0, '2100512002': 0, '2100512003': 0, '2100512006': 0, '2100512007': 0, '2100512009': 0, '2100512010': 0, '2100512011': 0, '2100512012': 0, '2100512014': 0, '2100512015': 0, '2100512016': 0, '2100512017': 0, '2100512018': 0, '2100512020': 0, '2100512021': 0, '2100512025': 0, '2100512026': 0, '2100512028': 0, '2100512029': 0, '2100512032': 0, '2100512034': 0, '2100512035': 0, '2100512036': 0, '2100512037': 0, '2100512038': 0, '2100512039': 0, '2100512041': 0, '2100512042': 0, '2100512044': 0, '2100512045': 0, '2100512051': 1, '2100512052': 0, '2100512053': 0, '2100512055': 0, '2100512057': 0, '2100512058': 0, '2100512061': 0, '2100512062': 0, '2100512063': 0, '2100512064': 1, '2100512065': 0, '2100521002': 0, '2100521005': 0, '2100521006': 0, '2100521008': 0, '2100521009': 0, '2100521010': 0, '2100521013': 0, '2100521014': 0, '2100521015': 0, '2100521016': 0, '2100521017': 0, '2100521018': 0, '2100521021': 0, '2100521022': 0, '2100521023': 0, '2100521024': 0, '2100521025': 0, '2100521026': 0, '2100521027': 0, '2100521028': 0, '2100521029': 0, '2100521030': 0, '2100521031': 0, '2100521032': 1, '2100521033': 0, '2100521034': 0, '2100521035': 0, '2100521037': 0, '2100521038': 0, '2100521039': 0, '2100521040': 0, '2100521041': 0, '2100521042': 0, '2100521043': 0, '2100521044': 0, '2100521046': 0, '2100521047': 0, '2100521048': 0, '2100521049': 0, '2100521050': 0, '2100521051': 0, '2100521052': 0, '2100521054': 0, '2100521055': 0, '2100521056': 0, '2100521057': 0, '2100521059': 0, '2100521060': 0, '2100521061': 0, '2100521062': 0, '2100521063': 0, '2100521067': 0, '2100521069': 0, '2100521070': 0, '2100521072': 0, '2100521073': 0, '2100521074': 0, '2100521075': 0, '2100521076': 0, '2100521077': 0, '2100521078': 0, '2100521079': 0, '2100522001': 0, '2100522004': 0, '2100522005': 0, '2100522006': 0, '2100522007': 0, '2100522008': 0, '2100522009': 0, '2100522010': 0, '2100522011': 0, '2100522012': 0, '2100522013': 0, '2100522018': 0, '2100522019': 0, '2100522020': 0, '2100522021': 0, '2100522023': 0, '2100522024': 0, '2100522026': 0, '2100522028': 0, '2100522031': 0, '2100522033': 0, '2100522034': 0, '2100522035': 0, '2100522036': 0, '2100522038': 0, '2100522039': 0, '2100522040': 0, '2100522041': 0, '2100522042': 0, '2100522046': 0, '2100522047': 0, '2100522048': 0, '2100522049': 0, '2100522050': 0, '2100522051': 0, '2100522052': 0, '2100522053': 0, '2100522054': 0, '2100522055': 0, '2100522056': 0, '2100522059': 0, '2100522060': 0, '2100522061': 0, '2100522062': 0, '2100522063': 0, '2100522064': 0, '2100522067': 0, '2100522068': 0, '2100522070': 0, '2100531001': 0, '2100531002': 0, '2100531003': 0, '2100531004': 0, '2100531006': 0, '2100531007': 0, '2100531008': 0, '2100531009': 0, '2100531010': 0, '2100531012': 0, '2100531013': 0, '2100531014': 0, '2100531015': 0, '2100531016': 0, '2100531017': 0, '2100531018': 0, '2100531019': 0, '2100531021': 0, '2100531022': 0, '2100531023': 0, '2100531024': 0, '2100531025': 0, '2100531026': 0, '2100531027': 0, '2100531028': 0, '2100531030': 0, '2100531031': 0, '2100531033': 0, '2100531034': 0, '2100531035': 0, '2100531036': 0, '2100531037': 0, '2100531040': 0, '2100531041': 0, '2100531042': 0, '2100531043': 0, '2100531044': 0, '2100531045': 0, '2100531047': 0, '2100531048': 0, '2100531049': 0, '2100531050': 0, '2100531051': 0, '2100531052': 0, '2100531053': 0, '2100531054': 1, '2100531055': 0, '2100531056': 0, '2100531057': 0, '2100531058': 0, '2100531059': 0, '2100531060': 0, '2100531061': 0, '2100531063': 0, '2100531064': 0, '2100531065': 0, '2100531066': 0, '2100531067': 0, '2100531068': 0, '2100531070': 0, '2100531071': 0, '2100531072': 0, '2100531073': 0, '2100531074': 0, '2100531076': 0, '2100531077': 0, '2100531078': 0, '2100531079': 0, '2100531080': 0, '2100531081': 0, '2100531082': 0, '2100531084': 0, '2100532002': 0, '2100532003': 0, '2100532004': 0, '2100532005': 0, '2100532007': 0, '2100532008': 0, '2100532010': 0, '2100532012': 0, '2100532013': 0, '2100532015': 0, '2100532016': 1, '2100532017': 0, '2100532019': 0, '2100532020': 0, '2100532022': 1, '2100532023': 0, '2100532024': 0, '2100532025': 0, '2100532026': 0, '2100532027': 0, '2100532028': 0, '2100532029': 0, '2100532030': 0, '2100532031': 0, '2100532032': 0, '2100532033': 0, '2100532034': 0, '2100532037': 0, '2100532042': 0, '2100532043': 0, '2100532044': 0, '2100532045': 0, '2100532046': 0, '2100532047': 0, '2100532048': 0, '2100532050': 0, '2100532052': 0, '2100532053': 0, '2100532054': 0, '2100532055': 0, '2100532056': 0, '2100532057': 0, '2100532058': 0, '2100532059': 0, '2100532060': 0, '2100532061': 0, '2100532062': 0, '2100532063': 0, '2100532064': 0, '2100532066': 0, '2100532067': 0, '2100532068': 0, '2100532070': 0, '2100532071': 0, '2100532072': 0, '2100551002': 0, '2100551005': 1, '2100551006': 0, '2100551007': 0, '2100551010': 1, '2100551011': 0, '2100551013': 0, '2100551014': 0, '2100551015': 0, '2100551016': 0, '2100551017': 0, '2100551018': 0, '2100551019': 0, '2100551020': 0, '2100551021': 0, '2100551022': 0, '2100551023': 0, '2100551024': 0, '2100551025': 0, '2100551027': 0, '2100551028': 0, '2100551029': 0, '2100551032': 1, '2100551033': 0, '2100551034': 0, '2100551035': 1, '2100551036': 0, '2100551037': 0, '2100551039': 0, '2100551041': 0, '2100551042': 1, '2100551043': 0, '2100551044': 0, '2100551045': 0, '2100551046': 0, '2100551049': 0, '2100551050': 0, '2100551051': 0, '2100551052': 0, '2100551053': 0, '2100551054': 0, '2100551055': 0, '2100551056': 0, '2100551057': 0, '2100551059': 0, '2100551060': 0, '2100551061': 0, '2100551062': 0, '2100551063': 0, '2100551064': 0, '2100551065': 0, '2100551066': 0, '2100551067': 0, '2100551068': 0, '2100551069': 0, '2100551071': 0, '2100551072': 0, '2100551073': 0, '2100551074': 0, '2100551075': 0, '2100551076': 0, '2100551077': 0, '2100551079': 0, '2100551080': 0, '2100551081': 0, '2100552002': 0, '2100552003': 0, '2100552004': 0, '2100552005': 0, '2100552006': 0, '2100552007': 0, '2100552008': 0, '2100552009': 0, '2100552010': 0, '2100552011': 0, '2100552012': 0, '2100552013': 0, '2100552014': 0, '2100552015': 0, '2100552016': 0, '2100552017': 0, '2100552018': 0, '2100552019': 0, '2100552021': 0, '2100552022': 0, '2100552023': 0, '2100552024': 0, '2100552025': 0, '2100552027': 0, '2100552028': 0, '2100552029': 0, '2100552030': 0, '2100552031': 0, '2100552032': 0, '2100552033': 0, '2100552034': 0, '2100552035': 0, '2100552037': 0, '2100552038': 0, '2100552039': 0, '2100552041': 0, '2100552042': 0, '2100552043': 0, '2100552044': 0, '2100552045': 0, '2100552047': 0, '2100552048': 1, '2100552051': 0, '2100552052': 0, '2100552053': 0, '2100552055': 0, '2100552057': 0, '2100552059': 0, '2100552060': 0, '2100552061': 0, '2100552062': 0, '2100552063': 1, '2100552065': 0, '2100552066': 0, '2100552068': 0, '2100552072': 0, '2100561006': 0, '2100561010': 0, '2100561011': 0, '2100561013': 0, '2100561014': 0, '2100561015': 0, '2100561016': 0, '2100561018': 0, '2100561019': 0, '2100561020': 0, '2100561021': 0, '2100561022': 0, '2100561023': 0, '2100561024': 0, '2100561027': 0, '2100561029': 0, '2100561032': 0, '2100561038': 0, '2100561043': 0, '2100561044': 0, '2100561046': 0, '2100561051': 0, '2100561052': 0, '2100561053': 0, '2100561054': 0, '2100561056': 0, '2100561057': 0, '2100561058': 0, '2100561059': 0, '2100561062': 0, '2100561063': 0, '2100561064': 0, '2100561065': 0, '2100561070': 0, '2100561071': 0, '2100561074': 0, '2100561079': 0, '2100562001': 0, '2100562002': 0, '2100562003': 0, '2100562004': 0, '2100562005': 0, '2100562007': 0, '2100562008': 0, '2100562009': 0, '2100562010': 0, '2100562011': 0, '2100562012': 0, '2100562013': 0, '2100562014': 0, '2100562015': 0, '2100562017': 0, '2100562018': 0, '2100562019': 1, '2100562020': 0, '2100562024': 1, '2100562026': 0, '2100562027': 0, '2100562029': 0, '2100562030': 0, '2100562032': 0, '2100562033': 0, '2100562034': 0, '2100562035': 0, '2100562037': 0, '2100562038': 0, '2100562039': 0, '2100562040': 0, '2100562042': 0, '2100562043': 0, '2100562044': 0, '2100562046': 0, '2100562047': 0, '2100562048': 0, '2100562049': 0, '2100562050': 0, '2100562051': 0, '2100562053': 0, '2100562054': 0, '2100562055': 0, '2100562056': 0, '2100562058': 0, '2100562059': 0, '2100562060': 0, '2100562061': 0, '2100571001': 0, '2100571002': 1, '2100571004': 0, '2100571007': 1, '2100571008': 0, '2100571009': 0, '2100571011': 0, '2100571012': 0, '2100571013': 0, '2100571015': 0, '2100571017': 0, '2100571018': 0, '2100571019': 0, '2100571020': 0, '2100571021': 1, '2100571022': 0, '2100571023': 1, '2100571024': 0, '2100571025': 0, '2100571027': 0, '2100571029': 0, '2100571030': 0, '2100571031': 0, '2100571033': 0, '2100571034': 0, '2100571036': 0, '2100571038': 1, '2100571039': 0, '2100571040': 0, '2100571041': 0, '2100571042': 0, '2100571044': 1, '2100571045': 0, '2100571046': 0, '2100571047': 0, '2100571048': 0, '2100571049': 1, '2100571050': 0, '2100571051': 0, '2100571052': 0, '2100571053': 0, '2100571055': 0, '2100571056': 0, '2100571057': 0, '2100571058': 0, '2100571061': 0, '2100571062': 1, '2100571063': 0, '2100571064': 0, '2100571065': 0, '2100571066': 0, '2100571067': 0, '2100571068': 0, '2100571069': 0, '2100571070': 0, '2100571072': 0, '2100571073': 0, '2100571074': 0, '2100571075': 0, '2100571077': 0, '2100571078': 0, '2100571079': 0, '2100571081': 0, '2100571082': 0, '2100572001': 0, '2100572002': 0, '2100572004': 0, '2100572006': 0, '2100572009': 0, '2100572010': 0, '2100572011': 0, '2100572012': 0, '2100572013': 0, '2100572015': 0, '2100572017': 0, '2100572018': 0, '2100572019': 0, '2100572020': 0, '2100572021': 1, '2100572023': 0, '2100572024': 0, '2100572025': 0, '2100572026': 0, '2100572027': 0, '2100572028': 0, '2100572029': 0, '2100572030': 0, '2100572032': 0, '2100572033': 0, '2100572034': 0, '2100572036': 0, '2100572038': 0, '2100572039': 0, '2100572040': 0, '2100572041': 0, '2100572042': 0, '2100572043': 0, '2100572044': 0, '2100572045': 0, '2100572046': 0, '2100572047': 0, '2100572048': 0, '2100572050': 0, '2100572051': 0, '2100572054': 0, '2100572055': 0, '2100572056': 0, '2100572057': 1, '2100572058': 0, '2100572059': 0, '2100572060': 0, '2100572061': 0, '2100572062': 0, '2100572063': 0, '2100572064': 0, '2100572067': 0, '2100572068': 0, '2100572069': 0, '2100581001': 1, '2100581002': 0, '2100581003': 0, '2100581004': 0, '2100581005': 0, '2100581006': 0, '2100581007': 0, '2100581009': 0, '2100581010': 0, '2100581011': 0, '2100581012': 0, '2100581013': 0, '2100581014': 0, '2100581015': 0, '2100581018': 0, '2100581019': 0, '2100581021': 1, '2100581022': 0, '2100581024': 0, '2100581025': 0, '2100581026': 0, '2100581027': 0, '2100581028': 0, '2100581029': 0, '2100581030': 0, '2100581034': 0, '2100581035': 0, '2100581036': 0, '2100581037': 0, '2100581038': 0, '2100581039': 0, '2100581040': 0, '2100581041': 0, '2100581042': 0, '2100581044': 0, '2100581045': 0, '2100581051': 0, '2100581054': 0, '2100581056': 0, '2100581057': 0, '2100581058': 0, '2100581059': 0, '2100581061': 0, '2100581062': 0, '2100581064': 0, '2100581066': 0, '2100581067': 0, '2100581068': 0, '2100581069': 0, '2100581070': 0, '2100581071': 0, '2100581072': 0, '2100581073': 0, '2100581074': 0, '2100581075': 0, '2100581076': 0, '2100581077': 0, '2100582001': 0, '2100582002': 0, '2100582003': 0, '2100582004': 0, '2100582005': 0, '2100582006': 0, '2100582008': 0, '2100582009': 0, '2100582012': 0, '2100582013': 0, '2100582015': 0, '2100582017': 0, '2100582019': 0, '2100582020': 0, '2100582021': 0, '2100582023': 0, '2100582024': 0, '2100582025': 0, '2100582026': 0, '2100582027': 1, '2100582028': 0, '2100582038': 0, '2100582043': 0, '2100582044': 0, '2100582045': 0, '2100582046': 0, '2100582048': 0, '2100582050': 0, '2100582051': 0, '2100582052': 1, '2100582053': 0, '2100582054': 0, '2100582055': 1, '2100582056': 1, '2100582057': 1, '2100582058': 1, '2100582060': 1, '2100582061': 1, '2100582062': 1, '2100582064': 0, '2100582067': 0, '2100582069': 0, '2100591002': 0, '2100591003': 0, '2100591004': 0, '2100591005': 0, '2100591006': 0, '2100591007': 0, '2100591008': 0, '2100591010': 0, '2100591013': 0, '2100591015': 0, '2100591016': 0, '2100591017': 0, '2100591019': 0, '2100591020': 0, '2100591021': 0, '2100591022': 0, '2100591023': 0, '2100591025': 0, '2100591026': 0, '2100591027': 0, '2100591028': 0, '2100591030': 0, '2100591034': 0, '2100591035': 0, '2100591036': 0, '2100591037': 0, '2100591038': 0, '2100591039': 0, '2100591040': 0, '2100591041': 0, '2100591042': 0, '2100591043': 0, '2100591044': 0, '2100591045': 0, '2100591046': 1, '2100591047': 0, '2100591048': 0, '2100591049': 0, '2100591050': 0, '2100591053': 0, '2100591054': 0, '2100591055': 0, '2100591056': 0, '2100591057': 0, '2100591059': 0, '2100591060': 0, '2100591061': 0, '2100591062': 0, '2100591064': 0, '2100591065': 0, '2100591066': 0, '2100591067': 0, '2100591068': 0, '2100591069': 0, '2100591070': 0, '2100591072': 0, '2100591073': 0, '2100591074': 0, '2100591075': 0, '2100591076': 0, '2100591077': 0, '2100591078': 0, '2100591080': 0, '2100591081': 0, '2100591082': 0, '2100592002': 0, '2100592003': 0, '2100592004': 0, '2100592005': 0, '2100592007': 0, '2100592009': 0, '2100592010': 0, '2100592011': 0, '2100592012': 0, '2100592013': 0, '2100592014': 0, '2100592015': 0, '2100592016': 0, '2100592017': 0, '2100592018': 0, '2100592019': 0, '2100592020': 0, '2100592021': 0, '2100592022': 0, '2100592023': 0, '2100592024': 0, '2100592025': 0, '2100592026': 0, '2100592027': 0, '2100592028': 0, '2100592029': 0, '2100592030': 0, '2100592032': 0, '2100592033': 0, '2100592034': 0, '2100592035': 0, '2100592036': 0, '2100592038': 0, '2100592040': 0, '2100592041': 0, '2100592042': 0, '2100592043': 0, '2100592044': 0, '2100592046': 0, '2100592047': 0, '2100592048': 0, '2100592049': 0, '2100592052': 0, '2100592053': 0, '2100592054': 0, '2100592056': 0, '2100592057': 0, '2100592058': 0, '2100592059': 0, '2100592060': 0, '2100592064': 0, '2100592065': 0, '2100592066': 0, '2100592067': 0, '2100592068': 0, '2100592069': 0, '2100592070': 0, '2100592071': 0, '2100592072': 0, '2100601001': 0, '2100601002': 0, '2100601004': 0, '2100601005': 0, '2100601006': 0, '2100601007': 0, '2100601008': 0, '2100601009': 0, '2100601010': 0, '2100601011': 0, '2100601012': 1, '2100601013': 0, '2100601014': 0, '2100601015': 0, '2100601016': 0, '2100601017': 0, '2100601018': 1, '2100601020': 0, '2100601021': 0, '2100601023': 0, '2100601024': 0, '2100601025': 0, '2100601027': 0, '2100601028': 0, '2100601029': 0, '2100601030': 0, '2100601031': 0, '2100601032': 0, '2100601033': 0, '2100601035': 0, '2100601036': 0, '2100601037': 0, '2100601038': 0, '2100601039': 0, '2100601040': 0, '2100601041': 0, '2100601042': 0, '2100601043': 0, '2100601044': 0, '2100601045': 0, '2100601046': 0, '2100601049': 0, '2100601050': 0, '2100601052': 0, '2100601053': 0, '2100601054': 0, '2100601055': 0, '2100601056': 0, '2100601057': 0, '2100601059': 0, '2100601062': 0, '2100601063': 0, '2100601064': 0, '2100601065': 0, '2100601066': 0, '2100601067': 0, '2100601068': 0, '2100601069': 0, '2100601071': 0, '2100601073': 0, '2100601074': 0, '2100601075': 0, '2100601077': 0, '2100601078': 0, '2100602001': 0, '2100602002': 0, '2100602003': 0, '2100602004': 0, '2100602005': 0, '2100602006': 0, '2100602008': 0, '2100602009': 0, '2100602010': 0, '2100602011': 0, '2100602012': 0, '2100602014': 0, '2100602015': 0, '2100602017': 0, '2100602018': 0, '2100602019': 0, '2100602020': 0, '2100602022': 0, '2100602023': 0, '2100602024': 0, '2100602025': 0, '2100602026': 0, '2100602027': 0, '2100602028': 0, '2100602029': 0, '2100602030': 0, '2100602032': 0, '2100602033': 0, '2100602034': 0, '2100602035': 0, '2100602036': 0, '2100602038': 0, '2100602040': 0, '2100602041': 1, '2100602042': 0, '2100602043': 0, '2100602044': 0, '2100602046': 0, '2100602047': 0, '2100602049': 0, '2100602050': 0, '2100602051': 0, '2100602052': 0, '2100602053': 0, '2100602054': 0, '2100602056': 0, '2100602058': 0, '2100602059': 0, '2100602060': 0, '2100602061': 0, '2100602062': 0, '2100602063': 0, '2100602065': 0, '2100602067': 0, '2100602068': 0, '2100602069': 0, '2100602072': 0, '2100611002': 0, '2100611003': 0, '2100611004': 0, '2100611005': 0, '2100611006': 0, '2100611010': 0, '2100611011': 0, '2100611012': 0, '2100611013': 0, '2100611014': 0, '2100611015': 0, '2100611016': 0, '2100611017': 0, '2100611018': 0, '2100611019': 0, '2100611021': 0, '2100611023': 0, '2100611024': 0, '2100611025': 0, '2100611026': 0, '2100611027': 1, '2100611028': 0, '2100611029': 0, '2100611031': 0, '2100611032': 0, '2100611034': 0, '2100611035': 0, '2100611036': 0, '2100611037': 0, '2100611038': 0, '2100611039': 0, '2100611040': 0, '2100611041': 0, '2100611042': 0, '2100611043': 0, '2100611044': 0, '2100611045': 0, '2100611046': 0, '2100611047': 0, '2100611048': 0, '2100611049': 0, '2100611050': 0, '2100611051': 0, '2100611052': 0, '2100611055': 0, '2100611056': 0, '2100611057': 0, '2100611058': 0, '2100611059': 0, '2100611060': 0, '2100611061': 0, '2100611062': 0, '2100611063': 0, '2100611064': 0, '2100611066': 0, '2100611067': 0, '2100611068': 0, '2100611069': 0, '2100611070': 0, '2100611071': 0, '2100611075': 0, '2100611076': 0, '2100611077': 0, '2100611078': 0, '2100611079': 0, '2100611081': 0, '2100611083': 0, '2100612001': 0, '2100612002': 0, '2100612003': 0, '2100612005': 0, '2100612006': 0, '2100612007': 0, '2100612008': 0, '2100612009': 1, '2100612010': 0, '2100612011': 0, '2100612012': 0, '2100612014': 0, '2100612015': 0, '2100612020': 0, '2100612022': 0, '2100612024': 0, '2100612025': 0, '2100612026': 0, '2100612027': 0, '2100612028': 0, '2100612029': 0, '2100612030': 0, '2100612031': 0, '2100612033': 0, '2100612034': 0, '2100612035': 0, '2100612037': 0, '2100612038': 0, '2100612040': 0, '2100612041': 0, '2100612042': 0, '2100612043': 0, '2100612044': 0, '2100612045': 0, '2100612046': 0, '2100612047': 0, '2100612048': 0, '2100612051': 0, '2100612053': 0, '2100612056': 0, '2100612057': 0, '2100612058': 0, '2100612059': 0, '2100612060': 0, '2100612061': 0, '2100612062': 0, '2100612063': 0, '2100612064': 0, '2100612065': 0, '2100612066': 0, '2100612067': 0, '2100612068': 0, '2100612069': 0, '2100612070': 0, '2100612071': 0, '2100612072': 0, '2260510110': 0, '2260510113': 0, '2260510114': 0, '2260510115': 0, '2260510116': 0, '2260510118': 0, '2260510122': 0, '2260510124': 0, '2260510125': 0, '2260510126': 0, '2260510127': 0, '2260510129': 0, '226051013': 0, '2260510131': 0, '2260510134': 0, '2260510136': 0, '2260510138': 0, '2260510139': 0, '226051014': 0, '2260510140': 0, '2260510141': 0, '2260510142': 0, '2260510143': 0, '2260510146': 0, '2260510147': 0, '2260510148': 0, '2260510151': 0, '2260510152': 0, '2260510155': 1, '2260510156': 0, '2260510158': 0, '2260510159': 0, '226051016': 0, '2260510160': 0, '2260510162': 0, '2260510163': 1, '2260510167': 0, '2260510168': 0, '226051017': 0, '2260510172': 0, '2260510174': 0, '2260510176': 0, '2260510177': 1, '2260510180': 0, '2260510182': 0, '2260510183': 0, '2260510185': 0, '226051019': 0, '226051021': 0, '2260510212': 0, '2260510213': 0, '2260510214': 0, '2260510217': 0, '226051022': 0, '2260510220': 0, '2260510221': 0, '2260510222': 0, '2260510223': 0, '2260510227': 0, '2260510228': 0, '2260510229': 0, '226051023': 0, '2260510230': 0, '2260510231': 0, '2260510232': 0, '2260510233': 0, '2260510237': 0, '2260510238': 0, '2260510240': 0, '2260510241': 0, '2260510242': 0, '2260510243': 0, '2260510244': 0, '2260510247': 0, '2260510248': 0, '226051025': 0, '2260510250': 0, '2260510252': 0, '2260510253': 0, '2260510254': 0, '2260510257': 0, '2260510258': 0, '2260510259': 0, '226051026': 0, '2260510260': 0, '2260510262': 0, '2260510266': 0, '2260510267': 0, '226051027': 0, '2260510270': 0, '2260510271': 0, '2260510272': 0, '2260510276': 0, '2260510277': 0, '2260510278': 0, '240846010': 0, '240846011': 0, '2408460110': 0, '2408460111': 0, '2408460118': 1, '240846012': 0, '2408460120': 0, '2408460123': 0, '2408460125': 0, '2408460126': 0, '2408460127': 0, '2408460129': 0, '240846013': 0, '2408460130': 0, '2408460131': 0, '2408460132': 0, '2408460133': 0, '2408460134': 0, '2408460135': 0, '2408460137': 1, '2408460139': 0, '2408460143': 0, '2408460145': 0, '2408460146': 0, '2408460148': 0, '2408460149': 0, '240846015': 0, '2408460150': 0, '2408460151': 0, '2408460152': 0, '2408460154': 0, '2408460155': 0, '2408460156': 0, '2408460158': 0, '2408460159': 0, '240846016': 0, '2408460163': 0, '2408460166': 0, '240846017': 0, '240846018': 0, '240846019': 0, '2408460211': 0, '2408460212': 0, '2408460213': 0, '2408460215': 0, '2408460217': 0, '2408460219': 0, '240846022': 0, '2408460220': 0, '2408460221': 0, '2408460222': 0, '2408460223': 0, '2408460225': 0, '2408460226': 0, '2408460227': 0, '2408460229': 0, '240846023': 0, '2408460234': 0, '2408460236': 0, '2408460237': 0, '2408460238': 0, '240846024': 0, '2408460240': 0, '2408460242': 0, '2408460243': 0, '2408460244': 0, '2408460246': 0, '2408460247': 0, '2408460249': 0, '2408460252': 0, '2408460254': 0, '2408460255': 0, '2408460257': 0, '2408460260': 0, '2408460261': 0, '2408460265': 0, '2408460266': 0, '2408460268': 0, '2408460269': 0, '240846027': 0, '2408460271': 0, '2408460272': 0, '2408460274': 0, '2408460276': 0, '2408460277': 0, '2408460278': 0, '240846028': 0, '2408460280': 0, '240846029': 0, '24851011': 0, '248510111': 0, '248510112': 0, '248510114': 0, '248510116': 0, '248510117': 0, '248510118': 0, '248510119': 0, '248510120': 0, '248510125': 0, '248510127': 0, '248510128': 0, '248510129': 0, '24851013': 0, '248510131': 0, '248510136': 0, '248510137': 0, '24851014': 0, '248510142': 0, '248510147': 0, '248510148': 0, '24851015': 0, '248510150': 0, '248510151': 0, '248510153': 0, '248510155': 0, '248510156': 0, '248510157': 0, '248510160': 0, '248510161': 0, '248510163': 0, '248510164': 0, '248510167': 0, '248510170': 0, '24851018': 0, '24851019': 0, '248510211': 0, '248510212': 0, '248510213': 0, '248510214': 0, '248510215': 0, '248510216': 0, '24851022': 0, '248510220': 0, '248510223': 0, '248510225': 0, '248510227': 0, '248510229': 0, '248510230': 0, '248510232': 0, '248510233': 0, '248510235': 0, '248510236': 0, '24851024': 0, '248510241': 0, '248510242': 0, '248510245': 0, '248510246': 0, '248510248': 0, '248510249': 0, '248510250': 0, '248510251': 0, '248510253': 0, '248510255': 0, '248510256': 0, '248510259': 0, '24851026': 0, '248510260': 0, '248510262': 0, '248510264': 0, '248510265': 0, '248510267': 0, '248510268': 0, '24851027': 0, '248510271': 0, '248510272': 0, '248510273': 0, '248510276': 0, '248510278': 0, '24851028': 0, '2904280110': 0, '29042801110': 0, '29042801170': 0, '29042801180': 0, '2904280120': 0, '29042801220': 0, '29042801230': 0, '29042801250': 0, '29042801260': 0, '29042801290': 0, '29042801300': 0, '29042801320': 0, '29042801340': 0, '29042801350': 0, '29042801370': 1, '29042801390': 0, '2904280140': 0, '29042801440': 0, '29042801450': 0, '29042801470': 0, '29042801480': 0, '2904280150': 0, '29042801500': 0, '29042801550': 0, '29042801570': 0, '29042801580': 0, '2904280160': 0, '29042801600': 0, '29042801630': 0, '29042801640': 0, '29042801650': 0, '29042801680': 0, '29042801690': 0, '2904280170': 0, '29042801710': 0, '29042801740': 0, '29042801750': 0, '29042801770': 0, '29042801780': 0, '29042801790': 0, '2904280180': 0, '2904280190': 0, '29042802110': 0, '29042802140': 0, '29042802150': 0, '29042802180': 0, '29042802200': 0, '29042802220': 0, '29042802240': 0, '29042802260': 0, '29042802280': 0, '2904280230': 0, '29042802310': 0, '29042802320': 0, '29042802340': 0, '29042802350': 0, '29042802380': 0, '29042802390': 0, '29042802410': 0, '29042802420': 0, '29042802430': 0, '29042802440': 0, '29042802450': 0, '29042802460': 0, '29042802470': 0, '29042802480': 0, '2904280250': 0, '29042802500': 0, '29042802510': 0, '29042802520': 0, '29042802530': 0, '29042802560': 0, '29042802570': 0, '2904280260': 1, '29042802600': 0, '29042802640': 0, '29042802660': 0, '29042802670': 0, '29042802680': 0, '29042802690': 0, '2904280270': 0, '29042802700': 0, '29042802720': 0, '29042802740': 0, '29042802750': 0, '29042802760': 0, '29042802770': 0, '29042802790': 0, '2904280280': 0, '29042802800': 0, '29042802830': 0, '29042802860': 0, '2904280290': 0, '303830110': 0, '303830113': 1, '303830115': 0, '303830117': 0, '303830118': 0, '303830121': 0, '303830122': 0, '303830123': 0, '303830126': 1, '303830127': 0, '303830128': 0, '30383013': 0, '303830131': 0, '303830132': 0, '303830133': 0, '303830138': 0, '303830139': 1, '30383014': 0, '303830141': 0, '303830143': 0, '303830144': 0, '303830146': 0, '303830147': 0, '303830148': 0, '303830149': 1, '30383015': 0, '303830151': 0, '303830155': 1, '303830156': 0, '303830157': 0, '303830158': 0, '303830159': 0, '30383016': 0, '303830160': 0, '303830161': 0, '303830162': 0, '303830166': 0, '303830167': 0, '303830169': 0, '303830171': 0, '303830174': 0, '303830175': 0, '303830178': 0, '303830182': 0, '303830183': 0, '303830184': 0, '303830210': 0, '303830211': 0, '303830212': 0, '303830216': 0, '303830217': 0, '303830218': 0, '30383022': 0, '303830220': 0, '303830221': 0, '303830223': 0, '303830224': 0, '303830225': 0, '303830227': 0, '303830229': 0, '30383023': 1, '303830234': 0, '303830236': 0, '303830239': 0, '303830240': 0, '303830241': 0, '303830242': 0, '303830245': 0, '303830246': 0, '303830247': 0, '303830249': 0, '30383025': 0, '303830250': 0, '303830255': 0, '303830258': 0, '303830259': 0, '303830263': 0, '303830269': 0, '303830270': 0, '303830273': 0, '303830274': 0, '303830278': 0, '30383028': 0, '3100621001': 0, '3100621002': 0, '3100621003': 0, '3100621004': 0, '3100621005': 0, '3100621007': 0, '3100621009': 0, '3100621010': 0, '3100621011': 0, '3100621012': 0, '3100621013': 0, '3100621014': 0, '3100621016': 0, '3100621018': 0, '3100621019': 0, '3100621020': 0, '3100621022': 0, '3100621023': 0, '3100621024': 0, '3100621025': 0, '3100621026': 0, '3100621027': 0, '3100621028': 0, '3100621030': 0, '3100621031': 0, '3100621032': 0, '3100621033': 0, '3100621034': 0, '3100621035': 0, '3100621037': 1, '3100621039': 0, '3100621040': 0, '3100621041': 0, '3100621042': 0, '3100621043': 0, '3100621045': 0, '3100621046': 0, '3100621047': 0, '3100621048': 0, '3100621049': 0, '3100621051': 0, '3100621052': 0, '3100621053': 0, '3100621055': 0, '3100621057': 0, '3100621058': 0, '3100621059': 0, '3100621061': 0, '3100621062': 0, '3100621063': 0, '3100621064': 0, '3100622001': 0, '3100622002': 0, '3100622003': 0, '3100622006': 0, '3100622007': 0, '3100622008': 0, '3100622009': 0, '3100622011': 0, '3100622013': 0, '3100622015': 0, '3100622019': 0, '3100622020': 0, '3100622021': 0, '3100622023': 0, '3100622024': 0, '3100622026': 0, '3100622027': 0, '3100622033': 0, '3100622034': 0, '3100622036': 0, '3100622037': 0, '3100622038': 0, '3100622040': 0, '3100622041': 0, '3100622042': 0, '3100622043': 0, '3100622044': 0, '3100622045': 0, '3100622047': 0, '3100622048': 0, '3100622049': 0, '3100622051': 0, '3100622053': 0, '3100622054': 0, '3100622057': 0, '3100631001': 0, '3100631002': 0, '3100631003': 0, '3100631004': 0, '3100631005': 0, '3100631006': 0, '3100631008': 0, '3100631009': 0, '3100631010': 0, '3100631011': 0, '3100631013': 0, '3100631014': 0, '3100631015': 0, '3100631016': 0, '3100631018': 0, '3100631019': 0, '3100631022': 0, '3100631023': 0, '3100631025': 0, '3100631026': 0, '3100631027': 0, '3100631029': 0, '3100631032': 0, '3100631035': 0, '3100631037': 0, '3100631042': 0, '3100631043': 0, '3100631044': 0, '3100631045': 0, '3100631046': 0, '3100631047': 0, '3100631048': 0, '3100631049': 0, '3100631051': 0, '3100631052': 0, '3100631053': 0, '3100631054': 0, '3100631055': 0, '3100631056': 0, '3100631057': 0, '3100631058': 0, '3100631059': 0, '3100631062': 0, '3100632001': 0, '3100632002': 0, '3100632003': 0, '3100632004': 0, '3100632007': 0, '3100632008': 0, '3100632011': 0, '3100632012': 0, '3100632015': 0, '3100632016': 0, '3100632017': 0, '3100632018': 0, '3100632019': 0, '3100632021': 0, '3100632023': 0, '3100632024': 0, '3100632025': 0, '3100632026': 0, '3100632027': 0, '3100632030': 0, '3100632031': 0, '3100632039': 0, '3100632041': 0, '3100632042': 0, '3100632043': 0, '3100632044': 0, '3100632045': 0, '3100641002': 0, '3100641003': 1, '3100641004': 1, '3100641006': 1, '3100641007': 0, '3100641008': 0, '3100641023': 1, '3100642002': 0, '3100642003': 0, '3100642005': 0, '3100642006': 0, '3100642007': 1, '3100642008': 0, '3100642009': 0, '3100642011': 0, '3100642012': 0, '3100642013': 0, '3100642015': 0, '3100642017': 1, '3100642019': 0, '3100642020': 0, '3100642021': 0, '3100642022': 0, '3100642024': 0, '3100642025': 0, '3100642026': 0, '3100642027': 0, '3100642028': 0, '3100642030': 0, '3100642031': 0, '3100642032': 0, '3100642033': 0, '3100642034': 0, '3100642035': 0, '3100642036': 1, '3100642037': 0, '3100642038': 0, '3100642040': 0, '3100642045': 0, '3100642047': 0, '3100642052': 0, '3100642054': 0, '3100642055': 1, '3100642056': 0, '3100642057': 0, '3100642058': 0, '3100642060': 0, '3100642061': 0, '3100642063': 0, '3100642064': 0, '3100642066': 0, '3100642069': 0, '3100642070': 0, '3100661002': 0, '3100661007': 0, '3100661009': 0, '3100661015': 0, '3100661016': 0, '3100661022': 0, '3100661023': 0, '3100661024': 0, '3100661025': 0, '3100661027': 0, '3100661028': 0, '3100661029': 0, '3100661031': 0, '3100661032': 0, '3100661033': 0, '3100661036': 0, '3100661037': 0, '3100661038': 0, '3100661040': 0, '3100661043': 0, '3100661044': 0, '3100661046': 0, '3100661049': 0, '3100661050': 0, '3100662014': 0, '3100662015': 0, '3100662016': 0, '3100662017': 0, '3100662020': 0, '3100662022': 0, '3100662023': 0, '3100662026': 0, '3100662029': 0, '3100662032': 0, '3100662035': 0, '3100662036': 0, '3100662037': 1, '3100662045': 0, '3100662046': 0, '3100662048': 0, '3100662049': 0, '3100662050': 0, '3100662052': 0, '3100662053': 0, '3100662055': 0, '3100681001': 0, '3100681002': 0, '3100681005': 0, '3100681006': 0, '3100681015': 1, '3100681017': 1, '3100681018': 1, '3100681042': 1, '3100681043': 0, '3100681044': 0, '3100681045': 0, '3100681046': 0, '3100682001': 0, '3100682002': 0, '3100682003': 0, '3100682007': 0, '3100682008': 0, '3100682030': 0, '3100682040': 0, '3100691005': 0, '3100691006': 0, '3100691007': 0, '3100691011': 0, '3100691012': 0, '3100691021': 0, '3100691026': 0, '3100691042': 0, '3100691045': 0, '3100691048': 0, '3100692002': 0, '3100692005': 0, '3100692006': 0, '3100692007': 0, '3100692009': 0, '3100692010': 0, '3100692011': 0, '3100692012': 0, '3100692013': 0, '3100692015': 1, '3100692016': 0, '3100692020': 0, '3100692022': 0, '3100692023': 0, '3100692024': 0, '3100692025': 0, '3100692028': 0, '3100692029': 0, '3100692032': 0, '3100692034': 0, '3100692035': 0, '3100692038': 0, '3100692039': 0, '3100692045': 0, '3100692052': 0, '3100692054': 0, '3100692055': 0, '3100692056': 0, '3100701001': 0, '3100701002': 0, '3100701004': 0, '3100701005': 0, '3100701008': 0, '3100701009': 0, '3100701010': 1, '3100701011': 0, '3100701012': 0, '3100701013': 0, '3100701014': 0, '3100701015': 0, '3100701016': 0, '3100701019': 0, '3100701021': 0, '3100701022': 0, '3100701023': 1, '3100701024': 0, '3100701029': 0, '3100701031': 0, '3100701032': 0, '3100701036': 0, '3100701043': 0, '3100701044': 0, '3100701050': 0, '3100701051': 0, '3100701056': 0, '3100701057': 0, '3100701058': 0, '3100701061': 0, '3100701063': 0, '3100701072': 0, '3100701073': 0, '3100702004': 0, '3100702005': 0, '3100702006': 0, '3100702010': 0, '3100702012': 0, '3100702013': 0, '3100702016': 0, '3100702017': 0, '3100702019': 0, '3100702020': 0, '3100702021': 0, '3100702022': 0, '3100702023': 0, '3100702024': 0, '3100702025': 0, '3100702026': 0, '3100702027': 0, '3100702028': 0, '3100702029': 0, '3100702030': 0, '3100702031': 0, '3100702033': 0, '3100702034': 0, '3100702035': 0, '3100702036': 0, '3100702037': 0, '3100702038': 1, '3100702039': 0, '3100702040': 0, '3100702041': 0, '3100702043': 0, '3100702044': 0, '3100702045': 0, '3100702046': 0, '3100702047': 0, '3100702048': 0, '3100702051': 0, '3100702052': 0, '3100702054': 0, '3100702055': 0, '3100702059': 0, '3100702060': 0, '3100702061': 0, '3100702062': 0, '3100702063': 0, '3100702064': 0, '3100702065': 0, '3100702066': 0, '3100702067': 0, '3100702068': 0, '3100711007': 0, '3100711009': 0, '3100711042': 0, '3100711043': 0, '3100711049': 0, '3100711050': 0, '3100711051': 0, '3100711052': 0, '3100712014': 0, '3100721002': 0, '3100721003': 0, '3100721004': 0, '3100721005': 0, '3100721006': 0, '3100721007': 0, '3100721008': 0, '3100721011': 0, '3100721012': 0, '3100721013': 0, '3100721014': 0, '3100721015': 0, '3100721016': 0, '3100721018': 0, '3100721019': 0, '3100721020': 0, '3100721021': 0, '3100721022': 0, '3100721023': 0, '3100721024': 0, '3100721028': 0, '3100721029': 0, '3100721030': 0, '3100721031': 1, '3100721032': 0, '3100721033': 0, '3100721034': 0, '3100721036': 0, '3100721038': 0, '3100721039': 0, '3100721040': 0, '3100721041': 0, '3100721042': 0, '3100721044': 0, '3100721045': 0, '3100721046': 0, '3100721047': 0, '3100721048': 0, '3100721049': 0, '3100721050': 0, '3100721051': 0, '3100721052': 0, '3100721053': 0, '3100721054': 0, '3100721055': 0, '3100721056': 0, '3100721057': 0, '3100721058': 0, '3100721059': 0, '3100721060': 0, '3100721062': 0, '3100721063': 0, '3100721064': 0, '3100721065': 0, '3100721066': 0, '3100721068': 0, '3100721070': 0, '3100721071': 0, '3100721072': 0, '3100722003': 0, '3100722004': 0, '3100722005': 0, '3100722006': 0, '3100722007': 0, '3100722012': 0, '3100722013': 0, '3100722014': 0, '3100722016': 0, '3100722017': 0, '3100722020': 0, '3100722021': 0, '3100722022': 0, '3100722023': 0, '3100722024': 0, '3100722025': 0, '3100722026': 0, '3100722027': 0, '3100722030': 0, '3100722031': 0, '3100722032': 0, '3100722033': 0, '3100722034': 0, '3100722036': 0, '3100722038': 0, '3100722039': 0, '3100722040': 0, '3100722042': 0, '3100722044': 0, '3100722045': 0, '3100722046': 0, '3100722047': 0, '3100722048': 0, '3100722054': 0, '3100722055': 0, '3100722057': 0, '3100722059': 0, '3100722061': 0, '3100722062': 0, '3100722063': 0, '3100722064': 0, '3100722065': 0, '3100722066': 0, '3100722067': 0, '3100722068': 0, '3100722069': 0, '3100722070': 0, '3100722072': 0, '3100722073': 0, '3100722074': 0, '3100722076': 0, '3100722077': 0, '3100722078': 0, '3100722079': 0, '3100731001': 0, '3100731006': 0, '3100731007': 0, '3100731008': 0, '3100731009': 0, '3100731011': 0, '3100731012': 0, '3100731013': 0, '3100731014': 0, '3100731025': 0, '3100731026': 0, '3100731028': 0, '3100731029': 0, '3100731030': 0, '3100731031': 0, '3100731037': 0, '3100731038': 0, '3100731050': 0, '3100731052': 0, '3100731054': 0, '3100731056': 0, '3100731057': 0, '3100731058': 0, '3100732001': 0, '3100732002': 0, '3100732003': 0, '3100732006': 0, '3100732013': 0, '3100732014': 0, '3100732015': 0, '3100732017': 0, '3100732018': 0, '3100732020': 0, '3100732021': 0, '3100732022': 0, '3100732023': 0, '3100732025': 0, '3100732027': 0, '3100732028': 0, '3100732029': 0, '3100732031': 0, '3100732036': 0, '3100732040': 0, '3100732041': 0, '3100732042': 0, '3100732067': 0, '3100741001': 0, '3100741002': 0, '3100741003': 0, '3100741004': 0, '3100741011': 0, '3100741012': 0, '3100741013': 0, '3100741014': 0, '3100741016': 0, '3100741017': 0, '3100741018': 0, '3100741019': 0, '3100741020': 0, '3100741022': 0, '3100741023': 0, '3100741024': 0, '3100741025': 0, '3100741026': 0, '3100741027': 0, '3100741028': 0, '3100741029': 0, '3100741030': 0, '3100741032': 0, '3100741034': 0, '3100741035': 0, '3100741036': 0, '3100741037': 0, '3100741038': 0, '3100741039': 0, '3100741042': 0, '3100741043': 0, '3100741044': 0, '3100741045': 0, '3100741047': 0, '3100741049': 0, '3100741053': 0, '3100741054': 0, '3100741056': 0, '3100741057': 0, '3100741058': 0, '3100741059': 0, '3100741060': 0, '3100741061': 0, '3100741063': 0, '3100741064': 0, '3100741065': 0, '3100741066': 1, '3100741068': 0, '3100741069': 0, '3100741070': 0, '3100741071': 0, '3100741072': 0, '3100741073': 0, '3100741074': 0, '3100741075': 0, '3100741076': 0, '3100741077': 0, '3100741079': 0, '3100742001': 0, '3100742003': 0, '3100742004': 0, '3100742005': 0, '3100742007': 0, '3100742010': 0, '3100742011': 0, '3100742012': 0, '3100742013': 0, '3100742014': 0, '3100742015': 0, '3100742016': 0, '3100742018': 0, '3100742020': 0, '3100742021': 0, '3100742022': 0, '3100742023': 0, '3100742024': 0, '3100742025': 0, '3100742027': 0, '3100742028': 0, '3100742033': 0, '3100742034': 0, '3100742037': 0, '3100742038': 0, '3100742041': 0, '3100742042': 0, '3100742044': 0, '3100742045': 0, '3100742046': 0, '3100742047': 0, '3100742048': 0, '3100742050': 0, '3100742051': 0, '3100742052': 0, '3100742053': 0, '3100742054': 0, '3100742055': 0, '3100742056': 0, '3100742057': 0, '3100742058': 1, '3100742059': 0, '3100742060': 0, '3100742061': 0, '3100742062': 0, '3100742063': 0, '3100742065': 0, '3100742067': 0, '3100742068': 0, '3100751003': 0, '3100751004': 0, '3100751005': 0, '3100751006': 1, '3100751007': 1, '3100751008': 1, '3100751009': 0, '3100751010': 1, '3100751011': 0, '3100751012': 1, '3100751014': 0, '3100751015': 0, '3100751016': 0, '3100751017': 0, '3100751018': 0, '3100751019': 1, '3100751020': 0, '3100751021': 0, '3100751022': 0, '3100751024': 0, '3100751026': 0, '3100751027': 0, '3100751028': 0, '3100751032': 0, '3100751033': 0, '3100751034': 0, '3100751035': 0, '3100751037': 0, '3100751039': 0, '3100751040': 0, '3100751041': 0, '3100751043': 0, '3100751044': 0, '3100751045': 0, '3100751048': 0, '3100751050': 0, '3100751055': 0, '3100751056': 1, '3100751057': 1, '3100751058': 0, '3100751059': 0, '3100751063': 0, '3100751064': 0, '3100751065': 0, '3100751068': 0, '3100751069': 0, '3100751070': 0, '3100751072': 0, '3100751073': 0, '3100751074': 0, '3100751075': 0, '3100751076': 0, '3100751077': 0, '3100751078': 0, '3100751079': 0, '3100752001': 0, '3100752002': 0, '3100752003': 0, '3100752004': 0, '3100752005': 0, '3100752007': 0, '3100752008': 0, '3100752009': 0, '3100752010': 0, '3100752012': 0, '3100752014': 1, '3100752015': 0, '3100752016': 0, '3100752017': 0, '3100752018': 0, '3100752019': 0, '3100752020': 0, '3100752021': 1, '3100752022': 0, '3100752023': 0, '3100752026': 0, '3100752027': 0, '3100752029': 0, '3100752030': 1, '3100752032': 0, '3100752034': 0, '3100752035': 0, '3100752036': 0, '3100752037': 1, '3100752038': 0, '3100752039': 0, '3100752040': 0, '3100752041': 0, '3100752042': 0, '3100752043': 0, '3100752044': 0, '3100752045': 0, '3100752046': 0, '3100752047': 0, '3100752048': 1, '3100752049': 0, '3100752050': 0, '3100752051': 1, '3100752052': 0, '3100752054': 0, '3100752055': 1, '3100752056': 0, '3100752057': 0, '3100752058': 0, '3100752059': 0, '3100752060': 0, '3100752061': 0, '3100752063': 0, '3100752068': 0, '3100761003': 1, '3100761004': 0, '3100761005': 1, '3100761007': 0, '3100761008': 1, '3100761013': 0, '3100761014': 0, '3100761015': 0, '3100761016': 0, '3100761017': 0, '3100761019': 0, '3100761020': 0, '3100761021': 0, '3100761023': 0, '3100761027': 0, '3100761028': 0, '3100761029': 0, '3100761030': 0, '3100761031': 0, '3100761034': 0, '3100761042': 0, '3100761046': 0, '3100761047': 0, '3100761048': 0, '3100761049': 0, '3100761050': 0, '3100761051': 0, '3100761056': 0, '3100761062': 0, '3100761063': 0, '3100762003': 0, '3100762004': 1, '3100762005': 0, '3100762007': 0, '3100762012': 0, '3100762013': 0, '3100762016': 0, '3100762027': 1, '3100762029': 0, '3100762030': 1, '3100762052': 0, '3100762053': 0, '3100762055': 1, '3100771001': 1, '3100771002': 0, '3100771003': 0, '3100771005': 0, '3100771007': 1, '3100771008': 0, '3100771009': 0, '3100771012': 0, '3100771014': 0, '3100771016': 0, '3100771018': 0, '3100771019': 0, '3100771020': 0, '3100771021': 0, '3100771022': 0, '3100771024': 0, '3100771027': 0, '3100771028': 0, '3100771029': 0, '3100771030': 0, '3100771031': 0, '3100771032': 0, '3100771033': 0, '3100771034': 0, '3100771036': 0, '3100771037': 0, '3100771039': 0, '3100771040': 0, '3100771041': 0, '3100771042': 0, '3100771043': 0, '3100771046': 0, '3100771047': 0, '3100771048': 0, '3100771049': 0, '3100771050': 0, '3100771052': 0, '3100771054': 0, '3100771055': 0, '3100771056': 0, '3100771057': 0, '3100771058': 0, '3100771059': 0, '3100771062': 0, '3100771063': 0, '3100771064': 0, '3100771065': 0, '3100771066': 0, '3100771067': 0, '3100771068': 0, '3100771069': 0, '3100771071': 0, '3100771072': 0, '3100771073': 0, '3100771075': 0, '3100771076': 0, '3100771077': 0, '3100771078': 0, '3100771080': 0, '3100771081': 0, '3100772002': 0, '3100772004': 0, '3100772005': 0, '3100772006': 0, '3100772007': 0, '3100772008': 0, '3100772009': 0, '3100772010': 0, '3100772011': 0, '3100772013': 0, '3100772014': 0, '3100772015': 0, '3100772018': 0, '3100772019': 0, '3100772020': 0, '3100772021': 0, '3100772022': 0, '3100772023': 0, '3100772024': 0, '3100772025': 0, '3100772026': 0, '3100772027': 0, '3100772028': 0, '3100772029': 0, '3100772031': 0, '3100772032': 0, '3100772033': 0, '3100772034': 0, '3100772035': 0, '3100772036': 0, '3100772037': 0, '3100772039': 0, '3100772040': 0, '3100772041': 0, '3100772042': 0, '3100772043': 0, '3100772045': 0, '3100772046': 0, '3100772048': 0, '3100772050': 0, '3100772051': 1, '3100772052': 0, '3100772053': 0, '3100772054': 0, '3100772055': 0, '3100772056': 0, '3100772058': 0, '3100772059': 0, '3100772063': 0, '3100772065': 0, '3100772066': 0, '3100772067': 0, '3100772068': 0, '3100772069': 0, '3100781001': 0, '3100781002': 1, '3100781004': 0, '3100781006': 0, '3100781007': 1, '3100781008': 0, '3100781009': 0, '3100781010': 0, '3100781011': 0, '3100781013': 0, '3100781015': 0, '3100781016': 0, '3100781017': 0, '3100781019': 0, '3100781020': 0, '3100781021': 0, '3100781023': 0, '3100781024': 0, '3100781027': 0, '3100781029': 0, '3100781030': 0, '3100781031': 0, '3100781032': 0, '3100781033': 0, '3100781034': 1, '3100781036': 0, '3100781038': 0, '3100781040': 0, '3100781041': 0, '3100781043': 0, '3100781044': 0, '3100781046': 0, '3100781047': 0, '3100781048': 0, '3100781051': 0, '3100781052': 0, '3100781053': 0, '3100781054': 0, '3100781055': 0, '3100781056': 0, '3100781057': 0, '3100781058': 0, '3100781059': 0, '3100781061': 0, '3100781062': 0, '3100781064': 0, '3100781065': 0, '3100781066': 0, '3100781068': 0, '3100781069': 0, '3100781070': 0, '3100781071': 0, '3100781073': 0, '3100781074': 0, '3100781075': 0, '3100781076': 0, '3100781078': 0, '3100781079': 0, '3100781080': 0, '3100781081': 0, '3100782001': 0, '3100782003': 0, '3100782004': 0, '3100782005': 0, '3100782006': 0, '3100782008': 0, '3100782010': 0, '3100782011': 0, '3100782012': 0, '3100782013': 0, '3100782014': 0, '3100782015': 0, '3100782016': 0, '3100782017': 0, '3100782018': 0, '3100782019': 0, '3100782021': 0, '3100782022': 0, '3100782023': 0, '3100782024': 0, '3100782025': 0, '3100782026': 0, '3100782027': 0, '3100782028': 0, '3100782031': 0, '3100782032': 0, '3100782033': 0, '3100782035': 0, '3100782036': 0, '3100782037': 0, '3100782038': 0, '3100782039': 0, '3100782042': 0, '3100782043': 0, '3100782045': 0, '3100782046': 0, '3100782047': 0, '3100782049': 0, '3100782050': 0, '3100782053': 0, '3100782054': 0, '3100782055': 0, '3100782057': 0, '3100782058': 0, '3100782059': 0, '3100782061': 0, '3100782062': 0, '3100782063': 0, '3100782064': 0, '3100782065': 0, '3100782066': 0, '3100782067': 1, '3100782068': 0, '3100782069': 0, '3100782071': 0, '3100782072': 0, '3100791004': 0, '3100791006': 0, '3100791007': 0, '3100791008': 0, '3100791016': 0, '3100791018': 0, '3100791020': 0, '3100791021': 0, '3100791026': 0, '3100791028': 0, '3100791031': 0, '3100791033': 0, '3100791034': 0, '3100791035': 0, '3100791042': 0, '3100791044': 0, '3100791045': 0, '3100791046': 0, '3100791047': 0, '3100791049': 0, '3100791050': 0, '3100791052': 0, '3100791054': 0, '3100791056': 0, '3100791058': 1, '3100791059': 0, '3100791060': 0, '3100791061': 0, '3100791062': 0, '3100791063': 0, '3100791064': 0, '3100791065': 0, '3100791066': 0, '3100791067': 0, '3100791069': 0, '3100791070': 0, '3100791071': 0, '3100791072': 0, '3100791073': 0, '3100792002': 0, '3100792003': 0, '3100792004': 0, '3100792005': 0, '3100792006': 0, '3100792007': 0, '3100792008': 0, '3100792009': 0, '3100792010': 0, '3100792011': 0, '3100792013': 0, '3100792014': 0, '3100792015': 0, '3100792016': 0, '3100792019': 0, '3100792020': 0, '3100792021': 0, '3100792022': 0, '3100792023': 0, '3100792024': 0, '3100792025': 0, '3100792027': 0, '3100792028': 0, '3100792030': 0, '3100792031': 0, '3100792032': 0, '3100792033': 0, '3100792035': 0, '3100792036': 0, '3100792037': 0, '3100792038': 0, '3100792039': 0, '3100792040': 0, '3100792041': 0, '3100792042': 0, '3100792043': 0, '3100792044': 0, '3100792045': 1, '3100792046': 0, '3100792048': 0, '3100792050': 0, '3100792051': 0, '3100792052': 0, '3100792053': 0, '3100792057': 0, '3100792058': 0, '3100792060': 0, '3100792069': 0, '3100801006': 0, '3100802001': 0, '3100802028': 0, '3100811002': 0, '3100811018': 0, '3100811027': 0, '3100811034': 0, '3100811035': 0, '3100811036': 0, '3100811037': 0, '3100811038': 0, '3100811039': 0, '3100811040': 0, '3100811041': 0, '3100811042': 0, '3100811043': 0, '3100811045': 0, '3100811046': 0, '3100811047': 0, '3100811050': 0, '3100811051': 0, '3100811053': 0, '3100811054': 0, '3100811055': 0, '3100811056': 0, '3100811059': 0, '3100811060': 0, '3100811061': 0, '3100811063': 0, '3100811068': 0, '3100811075': 0, '3100812003': 0, '3100812004': 0, '3100812005': 0, '3100812006': 0, '3100812007': 0, '3100812008': 0, '3100812013': 0, '3100812014': 0, '3100812016': 0, '3100812017': 0, '3100812018': 0, '3100812019': 0, '3100812020': 0, '3100812021': 0, '3100812026': 0, '3100812027': 0, '3100812028': 1, '3100812040': 0, '3100821004': 0, '3100821015': 0, '3100821016': 0, '3100821019': 0, '3100821020': 0, '3100821021': 0, '3100821022': 1, '3100821030': 0, '3100821031': 0, '3100821032': 1, '3100821033': 1, '3100821034': 0, '3100821035': 0, '3100821036': 0, '3100821037': 0, '3100821038': 1, '3100821039': 0, '3100821040': 0, '3100821041': 0, '3100821042': 0, '3100821045': 0, '3100821046': 0, '3100821047': 0, '3100821048': 1, '3100821049': 0, '3100821051': 0, '3100821052': 1, '3100821054': 0, '3100821055': 0, '3100821057': 1, '3100821067': 0, '3100821068': 0, '3100821069': 1, '3100821075': 1, '3100822001': 0, '3100822011': 1, '3100822012': 0, '3100822014': 0, '3100822030': 0, '3100822031': 1, '3100822044': 0, '3100822050': 0, '3100822051': 0, '3100822057': 0, '3100822058': 0, '3100822059': 0, '3100822064': 0, '3100822065': 1, '3100822066': 1, '3100822067': 0, '3100822068': 0, '3100822069': 0, '3100822070': 0, '3100822075': 0, '3100822080': 0, '3100831003': 0, '3100831004': 0, '3100831006': 0, '3100831007': 0, '3100831008': 0, '3100831010': 0, '3100831011': 0, '3100831013': 0, '3100831014': 0, '3100831015': 0, '3100831016': 0, '3100831018': 0, '3100831019': 0, '3100831020': 0, '3100831022': 0, '3100831024': 0, '3100831026': 0, '3100831027': 0, '3100831028': 0, '3100831029': 0, '3100831032': 0, '3100831033': 0, '3100831035': 0, '3100831036': 0, '3100831037': 0, '3100831044': 0, '3100831045': 0, '3100831046': 0, '3100831047': 0, '3344630110': 0, '33446301100': 0, '33446301101': 0, '33446301103': 0, '33446301104': 0, '33446301107': 0, '3344630112': 0, '3344630113': 0, '3344630115': 0, '3344630116': 0, '3344630117': 0, '3344630119': 0, '334463012': 0, '3344630120': 0, '3344630121': 1, '3344630127': 0, '3344630130': 0, '3344630131': 1, '3344630132': 0, '3344630133': 0, '3344630136': 0, '3344630139': 0, '334463014': 0, '3344630140': 0, '3344630141': 0, '3344630142': 0, '3344630143': 0, '3344630146': 0, '3344630147': 0, '3344630148': 0, '3344630149': 0, '3344630150': 0, '3344630151': 0, '3344630153': 0, '3344630156': 0, '3344630161': 0, '3344630162': 1, '3344630163': 0, '3344630164': 0, '3344630166': 0, '3344630170': 0, '3344630171': 0, '3344630172': 0, '3344630173': 0, '3344630176': 0, '3344630179': 0, '3344630180': 0, '3344630181': 0, '3344630182': 0, '3344630184': 0, '3344630185': 0, '3344630186': 0, '3344630188': 0, '3344630189': 0, '334463019': 0, '3344630190': 0, '3344630196': 0, '3344630197': 0, '3344630198': 0, '3344630199': 0, '334463021': 0, '3344630210': 0, '3344630211': 1, '3344630213': 0, '3344630215': 0, '3344630216': 0, '3344630219': 0, '334463022': 0, '3344630220': 0, '3344630221': 0, '3344630224': 0, '3344630225': 0, '3344630226': 0, '3344630231': 0, '3344630232': 0, '3344630233': 0, '3344630236': 0, '3344630238': 0, '3344630240': 0, '3344630241': 0, '3344630242': 0, '3344630243': 0, '3344630245': 0, '3344630247': 0, '3344630248': 0, '334463025': 0, '3344630251': 0, '3344630252': 0, '3344630255': 0, '3344630257': 0, '334463026': 0, '3344630260': 0, '3344630262': 0, '3344630264': 0, '3344630265': 0, '3344630266': 0, '3344630267': 0, '334463027': 0, '3344630270': 0, '3344630271': 0, '3344630273': 0, '3344630276': 0, '3344630278': 0, '334463028': 0, '3344630280': 0, '3344630281': 0, '3344630282': 1, '334463029': 0, '33702101100': 0, '33702101110': 0, '33702101130': 0, '33702101140': 0, '33702101150': 0, '33702101180': 0, '33702101200': 0, '33702101210': 0, '33702101250': 0, '33702101260': 0, '33702101270': 0, '33702101280': 0, '33702101290': 0, '33702101300': 0, '33702101340': 0, '33702101350': 0, '33702101360': 0, '33702101370': 0, '33702101410': 0, '33702101430': 0, '33702101450': 0, '33702101460': 0, '33702101470': 0, '33702101480': 0, '33702101490': 0, '3370210150': 0, '33702101500': 0, '33702101530': 0, '33702101540': 0, '33702101550': 0, '33702101580': 0, '33702101590': 0, '33702101600': 0, '33702101620': 0, '33702101630': 0, '33702101640': 0, '33702101650': 0, '33702101660': 0, '33702101700': 0, '33702101710': 0, '33702101730': 0, '33702101740': 0, '33702101750': 0, '33702101760': 0, '3370210180': 0, '33702102100': 0, '33702102110': 0, '33702102130': 0, '33702102140': 0, '33702102160': 0, '33702102170': 0, '33702102180': 0, '33702102190': 0, '33702102200': 0, '33702102220': 0, '33702102230': 0, '33702102240': 0, '33702102250': 0, '33702102280': 0, '3370210230': 0, '33702102300': 0, '33702102310': 0, '33702102330': 0, '33702102350': 0, '33702102390': 0, '3370210240': 0, '33702102400': 0, '33702102420': 0, '33702102430': 0, '33702102470': 0, '33702102500': 0, '33702102530': 0, '33702102540': 0, '33702102550': 0, '33702102570': 0, '33702102580': 0, '33702102590': 0, '3370210260': 0, '33702102600': 0, '33702102640': 0, '33702102670': 0, '33702102690': 0, '33702102710': 0, '33702102740': 0, '3370210280': 0, '33702102820': 0, '33702102840': 0, '33702102850': 0, '33702102870': 0, '33702102880': 0, '342227010': 0, '342227011': 0, '3422270111': 1, '3422270112': 0, '3422270115': 0, '3422270116': 0, '3422270117': 0, '3422270118': 0, '3422270121': 0, '3422270122': 0, '3422270123': 0, '3422270126': 0, '3422270127': 0, '3422270128': 0, '3422270129': 1, '342227013': 0, '3422270130': 0, '3422270131': 0, '3422270133': 0, '3422270134': 0, '3422270135': 0, '3422270138': 0, '3422270139': 0, '3422270140': 0, '3422270141': 0, '3422270142': 0, '3422270143': 0, '3422270144': 0, '3422270149': 0, '3422270151': 0, '3422270152': 0, '3422270153': 0, '3422270154': 0, '3422270155': 0, '3422270157': 0, '3422270158': 0, '3422270160': 0, '3422270165': 0, '3422270166': 0, '3422270167': 1, '3422270168': 0, '3422270169': 0, '3422270171': 0, '3422270172': 0, '342227020': 0, '342227021': 0, '3422270210': 0, '3422270211': 0, '3422270212': 0, '3422270213': 0, '3422270215': 0, '3422270216': 0, '3422270217': 0, '3422270219': 0, '3422270220': 0, '3422270221': 0, '3422270222': 0, '3422270223': 0, '3422270224': 0, '3422270225': 0, '3422270227': 0, '342227023': 0, '3422270230': 0, '3422270238': 0, '3422270239': 0, '342227024': 0, '3422270240': 0, '3422270241': 0, '3422270242': 0, '3422270244': 0, '3422270245': 0, '3422270246': 0, '3422270247': 0, '3422270249': 0, '342227025': 0, '3422270250': 0, '3422270251': 0, '3422270252': 0, '3422270253': 0, '3422270254': 0, '3422270255': 0, '3422270256': 0, '3422270257': 0, '3422270261': 0, '3422270262': 0, '3422270263': 0, '3422270264': 0, '3422270267': 0, '3422270268': 0, '3422270269': 0, '342227027': 0, '3422270274': 0, '3422270278': 0, '3422270279': 0, '3422270280': 0, '3422270281': 0, '342227029': 0, '350361011': 0, '3503610110': 0, '3503610111': 0, '3503610112': 0, '3503610113': 0, '3503610114': 0, '3503610115': 0, '3503610116': 0, '3503610117': 0, '3503610118': 0, '3503610119': 0, '350361012': 0, '3503610120': 0, '3503610121': 0, '3503610122': 0, '3503610123': 0, '3503610124': 0, '3503610125': 0, '3503610126': 0, '3503610127': 0, '3503610128': 0, '3503610129': 0, '350361013': 0, '3503610130': 0, '3503610131': 0, '3503610132': 0, '3503610133': 0, '3503610134': 0, '3503610135': 0, '3503610136': 0, '3503610137': 0, '3503610138': 0, '3503610139': 0, '350361014': 0, '3503610140': 0, '3503610141': 0, '3503610142': 0, '3503610143': 0, '3503610144': 0, '3503610145': 0, '3503610146': 0, '3503610147': 0, '3503610148': 0, '3503610149': 0, '350361015': 0, '3503610150': 0, '3503610151': 0, '3503610152': 0, '3503610154': 0, '3503610156': 0, '3503610157': 0, '3503610158': 1, '350361016': 0, '3503610163': 0, '3503610168': 1, '350361017': 0, '350361019': 0, '350361021': 0, '3503610210': 0, '3503610212': 0, '3503610213': 0, '3503610214': 0, '3503610217': 0, '350361022': 0, '3503610223': 0, '3503610224': 0, '3503610225': 0, '3503610226': 0, '3503610227': 0, '3503610228': 0, '350361023': 0, '3503610230': 0, '3503610231': 0, '3503610233': 0, '3503610234': 0, '3503610235': 0, '3503610236': 0, '3503610237': 0, '3503610238': 0, '350361024': 0, '3503610240': 0, '3503610241': 0, '3503610242': 0, '3503610245': 0, '3503610246': 0, '3503610248': 0, '3503610250': 0, '3503610251': 0, '3503610252': 0, '3503610253': 0, '3503610254': 0, '3503610255': 0, '3503610256': 0, '3503610257': 0, '350361026': 0, '3503610260': 0, '3503610261': 0, '3503610264': 0, '3503610265': 0, '3503610266': 0, '3503610267': 0, '3503610268': 0, '3503610269': 0, '3503610270': 0, '3503610272': 0, '3503610273': 0, '3503610275': 0, '3503610276': 0, '3503610277': 0, '3503610278': 0, '3503610279': 0, '350361028': 1, '350361029': 0, '4000181002': 0, '4000181004': 1, '4000181005': 0, '4000181006': 0, '4000181007': 0, '4000181008': 0, '4000181010': 0, '4000181011': 0, '4000181012': 0, '4000181013': 0, '4000181014': 0, '4000181015': 1, '4000181016': 0, '4000181017': 0, '4000181019': 0, '4000181020': 0, '4000181022': 0, '4000181023': 0, '4000181024': 0, '4000181026': 0, '4000181027': 0, '4000181028': 0, '4000181029': 0, '4000181030': 0, '4000181031': 0, '4000181032': 0, '4000181033': 0, '4000181035': 0, '4000181036': 0, '4000181037': 0, '4000181039': 0, '4000181041': 0, '4000181042': 0, '4000181043': 0, '4000181044': 0, '4000181045': 0, '4000181046': 0, '4000181047': 0, '4000181048': 0, '4000181049': 0, '4000181053': 0, '4000181054': 0, '4000181055': 0, '4000181056': 0, '4000181057': 0, '4000181060': 0, '4000181061': 0, '4000181062': 0, '4000181063': 0, '4000181064': 0, '4000181065': 0, '4000181066': 0, '4000181067': 0, '4000181068': 0, '4000181069': 0, '4000181070': 0, '4000181072': 0, '4000181073': 0, '4000181074': 0, '4000181075': 0, '4000181076': 0, '4000181077': 0, '4000181078': 0, '4000181079': 0, '4000181080': 0, '4000182003': 0, '4000182004': 0, '4000182005': 0, '4000182006': 0, '4000182007': 0, '4000182008': 0, '4000182009': 0, '4000182010': 0, '4000182011': 0, '4000182013': 0, '4000182014': 0, '4000182015': 0, '4000182016': 0, '4000182017': 0, '4000182018': 0, '4000182020': 0, '4000182022': 0, '4000182024': 0, '4000182025': 0, '4000182026': 0, '4000182027': 0, '4000182028': 0, '4000182029': 0, '4000182030': 0, '4000182031': 0, '4000182032': 0, '4000182033': 0, '4000182035': 1, '4000182036': 0, '4000182037': 0, '4000182038': 0, '4000182039': 0, '4000182040': 0, '4000182041': 0, '4000182042': 0, '4000182044': 0, '4000182046': 0, '4000182047': 0, '4000182049': 0, '4000182050': 0, '4000182051': 0, '4000182053': 0, '4000182054': 0, '4000182055': 0, '4000182058': 0, '4000182059': 0, '4000182060': 0, '4000182062': 0, '4000182063': 0, '4000182064': 0, '4000182067': 0, '4000182068': 0, '4000182069': 0, '4000221001': 0, '4000221002': 0, '4000221006': 0, '4000221008': 0, '4000221009': 0, '4000221010': 0, '4000221011': 0, '4000221013': 0, '4000221014': 0, '4000221015': 0, '4000221016': 0, '4000221017': 0, '4000221018': 0, '4000221024': 0, '4000221033': 0, '4000221034': 0, '4000221035': 0, '4000221036': 0, '4000221040': 1, '4000221041': 0, '4000221042': 0, '4000221054': 0, '4000221055': 0, '4000221061': 0, '4000221062': 0, '4000221064': 0, '4000221065': 0, '4000221066': 0, '4000221067': 0, '4000221071': 0, '4000221072': 0, '4000222001': 0, '4000222003': 0, '4000222004': 0, '4000222007': 0, '4000222012': 0, '4000222013': 0, '4000222014': 0, '4000222015': 0, '4000222017': 0, '4000222031': 1, '4000222032': 1, '4000222035': 0, '4000222036': 1, '4000222038': 0, '4000222039': 0, '4000222040': 0, '4000222041': 1, '4000222042': 0, '4000222044': 0, '4000222045': 0, '4000222046': 0, '4000222051': 0, '4000222052': 0, '4000222054': 0, '4000222056': 0, '4000222057': 0, '4000222068': 0, '4000222069': 0, '4000222070': 0, '4000231001': 0, '4000231008': 0, '4000231010': 0, '4000231011': 0, '4000231012': 0, '4000231013': 0, '4000231014': 0, '4000231021': 0, '4000231032': 0, '4000231033': 0, '4000231034': 0, '4000231037': 0, '4000231038': 0, '4000231047': 0, '4000231049': 0, '4000231052': 0, '4000231060': 0, '4000231061': 0, '4000231063': 0, '4000231065': 0, '4000231070': 0, '4000231071': 0, '4000231073': 0, '4000231074': 0, '4000231081': 0, '4000232001': 0, '4000232004': 0, '4000232005': 0, '4000232006': 0, '4000232007': 0, '4000232010': 0, '4000232016': 0, '4000232017': 0, '4000232018': 0, '4000232022': 0, '4000232024': 0, '4000232027': 0, '4000232034': 0, '4000232035': 0, '4000232036': 0, '4000232037': 0, '4000232038': 0, '4000232042': 0, '4000232044': 0, '4000232045': 0, '4000232048': 0, '4000232051': 0, '4000232054': 0, '4000232059': 0, '4000232062': 0, '4000232065': 0, '4000232068': 0, '4000232071': 1, '4000232072': 0, '4000301002': 0, '4000301003': 0, '4000301005': 1, '4000301006': 1, '4000301007': 0, '4000301008': 0, '4000301010': 1, '4000301011': 1, '4000301012': 0, '4000301013': 0, '4000301014': 0, '4000301015': 0, '4000301016': 0, '4000301018': 0, '4000301019': 0, '4000301020': 0, '4000301021': 1, '4000301022': 0, '4000301023': 0, '4000301025': 0, '4000301026': 0, '4000301027': 0, '4000301028': 1, '4000301030': 1, '4000301031': 0, '4000301032': 0, '4000301034': 0, '4000301038': 0, '4000301039': 0, '4000301040': 0, '4000301041': 0, '4000301042': 1, '4000301043': 0, '4000301044': 0, '4000301045': 0, '4000301047': 0, '4000301049': 1, '4000301052': 0, '4000301053': 0, '4000301054': 0, '4000301055': 1, '4000301056': 0, '4000301057': 0, '4000301058': 0, '4000301059': 0, '4000301060': 1, '4000301061': 0, '4000301062': 0, '4000301063': 0, '4000301064': 0, '4000301065': 1, '4000301066': 1, '4000301067': 1, '4000301068': 0, '4000301069': 0, '4000301070': 1, '4000301071': 0, '4000301072': 0, '4000301073': 0, '4000301074': 0, '4000301076': 0, '4000301079': 0, '4000331001': 0, '4000331002': 0, '4000331003': 0, '4000331004': 0, '4000331005': 0, '4000331006': 0, '4000331007': 0, '4000331008': 0, '4000331011': 0, '4000331012': 0, '4000331013': 0, '4000331015': 0, '4000331017': 0, '4000331019': 0, '4000331020': 0, '4000331021': 0, '4000331022': 0, '4000331023': 0, '4000331025': 0, '4000331027': 0, '4000331029': 0, '4000331030': 0, '4000331031': 0, '4000331032': 0, '4000331033': 0, '4000331035': 0, '4000331036': 0, '4000331037': 0, '4000331038': 0, '4000331039': 0, '4000331040': 0, '4000331041': 0, '4000331042': 0, '4000331043': 0, '4000331044': 0, '4000331045': 0, '4000331046': 0, '4000331051': 0, '4000331052': 0, '4000331053': 0, '4000331054': 0, '4000331055': 0, '4000331056': 0, '4000331057': 0, '4000331058': 0, '4000331060': 0, '4000331062': 0, '4000331063': 0, '4000331064': 0, '4000331067': 0, '4000331068': 0, '4000331069': 0, '4000332001': 0, '4000332002': 0, '4000332007': 0, '4000332008': 0, '4000332009': 0, '4000332010': 0, '4000332012': 0, '4000332013': 0, '4000332014': 0, '4000332015': 0, '4000332017': 0, '4000332019': 0, '4000332020': 0, '4000332021': 0, '4000332022': 0, '4000332023': 0, '4000332025': 0, '4000332027': 0, '4000332030': 0, '4000332031': 0, '4000332032': 0, '4000332034': 0, '4000332035': 0, '4000332036': 0, '4000332037': 0, '4000332038': 0, '4000332039': 0, '4000332041': 0, '4000332044': 0, '4000332045': 0, '4000332046': 0, '4000332048': 0, '4000332050': 0, '4000332051': 0, '4000332052': 0, '4000332057': 0, '4000332059': 0, '4000332060': 0, '4000332061': 0, '4000332062': 0, '4000332063': 0, '4000332064': 0, '4000332066': 0, '4000332067': 0, '4000332068': 0, '4000332071': 0, '4000332072': 0, '4000332073': 0, '4000332074': 0, '4000332075': 0, '4000332077': 0, '4000332078': 0, '4000332079': 0, '4000332080': 0, '4000332081': 0, '4000332082': 1, '401835011': 0, '4018350112': 0, '4018350115': 0, '4018350116': 0, '4018350118': 0, '4018350119': 0, '4018350120': 0, '4018350121': 0, '4018350122': 0, '4018350126': 0, '4018350127': 0, '401835013': 0, '4018350130': 0, '4018350132': 0, '4018350134': 0, '4018350136': 0, '4018350137': 0, '4018350138': 0, '4018350139': 0, '4018350140': 0, '4018350141': 0, '4018350143': 0, '4018350144': 0, '4018350145': 0, '4018350146': 0, '4018350147': 0, '4018350149': 0, '401835015': 1, '4018350150': 0, '4018350152': 0, '4018350156': 0, '4018350157': 0, '4018350159': 0, '4018350160': 0, '4018350161': 0, '4018350162': 0, '4018350163': 0, '4018350166': 0, '4018350167': 0, '401835017': 0, '401835018': 0, '401835021': 0, '4018350213': 0, '4018350215': 0, '4018350217': 0, '4018350219': 0, '4018350220': 0, '4018350221': 0, '4018350222': 0, '4018350223': 0, '4018350224': 0, '4018350225': 0, '4018350226': 0, '4018350227': 0, '4018350231': 0, '4018350232': 0, '4018350233': 0, '4018350234': 0, '4018350236': 0, '4018350239': 0, '401835024': 0, '4018350240': 0, '4018350241': 0, '4018350244': 0, '4018350247': 0, '4018350251': 0, '4018350254': 0, '4018350256': 0, '4018350257': 0, '4018350258': 0, '4018350259': 0, '4018350260': 0, '4018350261': 0, '4018350263': 0, '4018350268': 0, '4018350269': 0, '4018350274': 0, '4018350276': 0, '4018350277': 0, '4018350279': 0, '401835028': 0, '4018350281': 0, '4018350282': 1, '4100191001': 0, '4100191002': 0, '4100191003': 0, '4100191004': 0, '4100191006': 0, '4100191007': 0, '4100191008': 1, '4100191010': 0, '4100191012': 0, '4100191014': 0, '4100191016': 0, '4100191017': 0, '4100191018': 0, '4100191020': 0, '4100191021': 0, '4100191023': 0, '4100191024': 0, '4100191025': 0, '4100191026': 0, '4100191030': 0, '4100191031': 0, '4100191032': 0, '4100191033': 1, '4100191034': 0, '4100191035': 0, '4100191038': 0, '4100191039': 0, '4100191041': 1, '4100191042': 0, '4100191043': 0, '4100191045': 0, '4100191046': 0, '4100191052': 0, '4100191053': 0, '4100192001': 0, '4100192002': 0, '4100192003': 0, '4100192004': 0, '4100192005': 0, '4100192006': 0, '4100192007': 0, '4100192010': 1, '4100192011': 1, '4100192012': 0, '4100192013': 0, '4100192014': 0, '4100192015': 1, '4100192016': 1, '4100192019': 0, '4100192020': 0, '4100192022': 0, '4100192023': 0, '4100192024': 0, '4100192025': 0, '4100192026': 1, '4100192027': 0, '4100192028': 0, '4100192029': 1, '4100192031': 1, '4100192032': 0, '4100192033': 0, '4100192034': 0, '4100192036': 0, '4100192037': 0, '4100192038': 0, '4100192039': 0, '4100192040': 0, '4100192043': 0, '4100192044': 0, '4100192045': 0, '4100192046': 0, '4100192047': 0, '4100192048': 0, '4100192049': 1, '4100192050': 0, '4100192051': 0, '4100192052': 0, '4100192053': 1, '4100192054': 0, '4100192055': 0, '4100192056': 0, '4100192057': 0, '4100192058': 0, '4100192060': 1, '4100192061': 0, '4100192062': 0, '4100192063': 0, '4100192066': 0, '4100192068': 0, '4100201001': 0, '4100201003': 0, '4100201004': 0, '4100201005': 0, '4100201006': 0, '4100201007': 0, '4100201008': 0, '4100201009': 0, '4100201010': 0, '4100201011': 0, '4100201013': 0, '4100201014': 0, '4100201016': 0, '4100201017': 0, '4100201018': 0, '4100201020': 0, '4100201021': 0, '4100201022': 0, '4100201023': 0, '4100201024': 0, '4100201025': 0, '4100201026': 0, '4100201027': 0, '4100201030': 1, '4100201031': 0, '4100201032': 1, '4100201033': 0, '4100201034': 0, '4100201035': 0, '4100201039': 1, '4100201040': 0, '4100201041': 0, '4100201042': 0, '4100201043': 1, '4100201044': 0, '4100201045': 0, '4100201046': 0, '4100201048': 0, '4100201049': 0, '4100201051': 0, '4100201052': 0, '4100201053': 0, '4100201054': 0, '4100201055': 0, '4100201056': 0, '4100201058': 0, '4100201059': 0, '4100201060': 0, '4100201061': 1, '4100201062': 0, '4100201063': 0, '4100201064': 0, '4100201068': 0, '4100201069': 0, '4100201071': 0, '4100201072': 0, '4100201073': 0, '4100201074': 0, '4100201075': 0, '4100201076': 0, '4100201078': 0, '4100201079': 0, '4100201081': 0, '4100201082': 0, '4100202001': 0, '4100202004': 0, '4100202005': 0, '4100202006': 0, '4100202007': 0, '4100202008': 0, '4100202009': 0, '4100202010': 0, '4100202011': 0, '4100202012': 0, '4100202013': 0, '4100202014': 1, '4100202015': 0, '4100202016': 0, '4100202017': 0, '4100202018': 0, '4100202019': 0, '4100202021': 0, '4100202022': 0, '4100202023': 0, '4100202024': 0, '4100202025': 0, '4100202032': 0, '4100202037': 0, '4100202039': 0, '4100202040': 0, '4100202041': 0, '4100202042': 0, '4100202043': 0, '4100202045': 0, '4100202046': 1, '4100202048': 0, '4100202052': 0, '4100202053': 0, '4100202054': 0, '4100202055': 0, '4100202056': 0, '4100202063': 0, '4100202065': 1, '4100202067': 0, '4100202068': 0, '4100241001': 0, '4100241002': 0, '4100241003': 0, '4100241004': 0, '4100241006': 0, '4100241007': 0, '4100241008': 0, '4100241009': 0, '4100241011': 0, '4100241013': 0, '4100241016': 0, '4100241017': 0, '4100241018': 0, '4100241020': 0, '4100241029': 1, '4100241030': 0, '4100241031': 0, '4100241042': 0, '4100241045': 0, '4100241046': 0, '4100241049': 0, '4100241051': 0, '4100241052': 0, '4100241053': 0, '4100241054': 0, '4100241055': 1, '4100241056': 0, '4100241059': 1, '4100241060': 0, '4100241061': 0, '4100241062': 0, '4100241063': 0, '4100241064': 0, '4100241068': 1, '4100241069': 0, '4100241075': 0, '4100242001': 0, '4100242002': 0, '4100242003': 1, '4100242004': 0, '4100242005': 0, '4100242006': 0, '4100242008': 0, '4100242011': 0, '4100242020': 0, '4100242021': 0, '4100242029': 0, '4100242031': 0, '4100242032': 1, '4100242033': 1, '4100242034': 0, '4100242035': 1, '4100242036': 0, '4100242037': 0, '4100242038': 0, '4100242040': 0, '4100242045': 0, '4100242048': 0, '4100242050': 0, '4100242053': 0, '4100242054': 0, '4100242057': 1, '4100242059': 0, '4100242060': 0, '4100242063': 1, '4100242065': 0, '4100242066': 0, '4100242067': 0, '4100251003': 0, '4100251004': 0, '4100251005': 0, '4100251006': 1, '4100251010': 0, '4100251011': 0, '4100251012': 0, '4100251013': 0, '4100251014': 0, '4100251015': 0, '4100251016': 1, '4100251017': 0, '4100251018': 0, '4100251019': 0, '4100251020': 1, '4100251021': 1, '4100251022': 0, '4100251024': 1, '4100251026': 0, '4100251027': 1, '4100251028': 1, '4100251029': 1, '4100251030': 0, '4100251031': 0, '4100251032': 1, '4100251033': 1, '4100251034': 0, '4100251035': 0, '4100251036': 1, '4100251038': 1, '4100251039': 0, '4100251040': 0, '4100251041': 1, '4100251042': 0, '4100251044': 0, '4100251046': 1, '4100251047': 0, '4100251048': 0, '4100251049': 1, '4100251051': 0, '4100251052': 0, '4100251053': 0, '4100251054': 0, '4100251056': 0, '4100251057': 1, '4100251059': 0, '4100251060': 0, '4100251061': 1, '4100251062': 0, '4100251063': 0, '4100251064': 0, '4100251065': 0, '4100251068': 1, '4100251069': 0, '4100251070': 0, '4100252001': 0, '4100252003': 0, '4100252004': 0, '4100252005': 0, '4100252007': 0, '4100252010': 0, '4100252011': 0, '4100252012': 0, '4100252013': 0, '4100252014': 0, '4100252015': 0, '4100252016': 0, '4100252019': 0, '4100252021': 0, '4100252022': 0, '4100252023': 0, '4100252024': 0, '4100252027': 0, '4100252031': 0, '4100252032': 0, '4100252033': 0, '4100252034': 0, '4100252035': 0, '4100252036': 1, '4100252037': 0, '4100252038': 0, '4100252039': 0, '4100252040': 0, '4100252041': 1, '4100252043': 0, '4100252044': 1, '4100252045': 0, '4100252048': 0, '4100252049': 0, '4100252050': 0, '4100252051': 0, '4100252053': 0, '4100252054': 0, '4100252055': 0, '4100252056': 0, '4100252057': 0, '4100252058': 0, '4100252060': 0, '4100252061': 1, '4100252062': 0, '4100252063': 0, '4100252066': 0, '4100252069': 0, '4100252070': 0, '4100252071': 0, '4100252072': 0, '4100252073': 0, '4100252074': 0, '4100252075': 0, '4100252076': 0, '4100252078': 0, '4100252081': 0, '4100261001': 0, '4100261002': 0, '4100261003': 0, '4100261004': 0, '4100261005': 1, '4100261006': 1, '4100261007': 0, '4100261010': 0, '4100261012': 0, '4100261013': 0, '4100261015': 0, '4100261016': 0, '4100261020': 0, '4100261023': 0, '4100261025': 0, '4100261027': 1, '4100261028': 0, '4100261029': 0, '4100261030': 1, '4100261031': 0, '4100261032': 0, '4100261033': 0, '4100261034': 1, '4100261035': 0, '4100261036': 0, '4100261038': 0, '4100261041': 1, '4100261044': 0, '4100261045': 0, '4100261046': 0, '4100261047': 0, '4100261048': 0, '4100261049': 0, '4100261050': 1, '4100261055': 0, '4100261056': 1, '4100261057': 0, '4100261058': 1, '4100261060': 0, '4100261061': 0, '4100262001': 0, '4100262003': 0, '4100262004': 1, '4100262006': 1, '4100262007': 0, '4100262008': 0, '4100262009': 0, '4100262010': 0, '4100262014': 0, '4100262015': 0, '4100262016': 0, '4100262017': 0, '4100262018': 0, '4100262019': 0, '4100262020': 0, '4100262022': 0, '4100262023': 0, '4100262024': 0, '4100262025': 0, '4100262027': 0, '4100262034': 1, '4100262035': 0, '4100262037': 0, '4100262038': 0, '4100262040': 0, '4100262041': 0, '4100262042': 0, '4100262043': 0, '4100262044': 0, '4100262045': 0, '4100262046': 0, '4100262047': 0, '4100262052': 0, '4100262053': 0, '4100262056': 1, '4100262057': 0, '4100262060': 0, '4100262063': 0, '4100262064': 0, '4100262065': 0, '4100262066': 0, '4100262067': 0, '4100262068': 0, '4100262069': 0, '4100262070': 0, '4100271007': 0, '4100271008': 0, '4100271009': 0, '4100271010': 0, '4100271011': 0, '4100271012': 0, '4100271026': 0, '4100271028': 0, '4100271029': 0, '4100271030': 0, '4100271032': 0, '4100271033': 0, '4100271034': 0, '4100271038': 1, '4100271039': 0, '4100271041': 1, '4100271042': 0, '4100271043': 0, '4100271056': 1, '4100272024': 0, '4100272029': 0, '4100272033': 0, '4100272034': 0, '4100272036': 0, '4100272037': 0, '4100272043': 0, '4100272051': 0, '4100272052': 0, '4100272056': 0, '4100281001': 0, '4100281002': 0, '4100281015': 0, '4100281016': 0, '4100281019': 0, '4100281022': 0, '4100281023': 0, '4100281027': 0, '4100281029': 0, '4100281030': 0, '4100281032': 1, '4100281033': 0, '4100281034': 0, '4100281035': 0, '4100281036': 0, '4100281037': 0, '4100281041': 0, '4100281042': 0, '4100281045': 0, '4100281046': 1, '4100281048': 0, '4100281049': 0, '4100281050': 0, '4100281052': 0, '4100281053': 1, '4100281054': 0, '4100281057': 0, '4100281058': 0, '4100281059': 0, '4100281060': 0, '4100281061': 0, '4100281062': 0, '4100281063': 0, '4100281066': 0, '4100281067': 1, '4100281068': 0, '4100281070': 1, '4100281072': 0, '4100281075': 0, '4100281076': 1, '4100281078': 0, '4100281079': 0, '4100281080': 0, '4100281081': 0, '4100282001': 0, '4100282002': 0, '4100282003': 0, '4100282004': 0, '4100282005': 0, '4100282007': 0, '4100282008': 0, '4100282009': 1, '4100282012': 0, '4100282013': 0, '4100282014': 0, '4100282015': 0, '4100282017': 0, '4100282018': 0, '4100282019': 0, '4100282020': 0, '4100282021': 0, '4100282022': 0, '4100282023': 0, '4100282024': 0, '4100282033': 0, '4100282043': 0, '4100282048': 0, '4100282053': 0, '4100282057': 0, '4100282058': 0, '4100282066': 1, '4100282067': 0, '4100282068': 0, '4100282070': 0, '4100291002': 0, '4100291003': 0, '4100291004': 0, '4100291005': 0, '4100291006': 1, '4100291007': 1, '4100291008': 0, '4100291009': 0, '4100291010': 1, '4100291011': 0, '4100291012': 0, '4100291014': 0, '4100291015': 0, '4100291016': 0, '4100291017': 0, '4100291018': 0, '4100291019': 1, '4100291021': 0, '4100291022': 0, '4100291025': 0, '4100291026': 1, '4100291027': 1, '4100291028': 0, '4100291032': 1, '4100291033': 0, '4100291034': 0, '4100291036': 1, '4100291037': 0, '4100291039': 0, '4100291040': 0, '4100291041': 1, '4100291043': 0, '4100291046': 0, '4100291047': 0, '4100291048': 0, '4100291049': 0, '4100291050': 0, '4100291051': 0, '4100291055': 0, '4100291056': 0, '4100291059': 0, '4100291060': 0, '4100291061': 0, '4100291062': 0, '4100291063': 0, '4100291064': 0, '4100291065': 0, '4100291070': 1, '4100291073': 1, '4100291074': 0, '4100291076': 0, '4100291077': 0, '4100291078': 1, '4100291079': 0, '4100291080': 0, '4100291081': 1, '4100291082': 1, '4100291083': 0, '4100291084': 1, '4100292001': 0, '4100292003': 0, '4100292005': 0, '4100292008': 0, '4100292010': 0, '4100292016': 0, '4100292019': 0, '4100292020': 0, '4100292021': 0, '4100292022': 0, '4100292023': 0, '4100292024': 0, '4100292025': 0, '4100292026': 0, '4100292027': 0, '4100292028': 0, '4100292035': 0, '4100292036': 0, '4100292037': 0, '4100292040': 0, '4100292041': 0, '4100292042': 0, '4100292043': 0, '4100292044': 0, '4100292045': 0, '4100292046': 0, '4100292048': 1, '4100292049': 0, '4100292050': 0, '4100292052': 0, '4100292053': 0, '4100292056': 0, '4100292057': 0, '4100292059': 0, '4100292060': 0, '4100292061': 0, '4100292062': 0, '4100292063': 0, '4100292064': 0, '4100292065': 0, '4100292066': 0, '4100292067': 0, '4100292068': 0, '4100292069': 0, '4100292070': 0, '4100292071': 0, '4100292072': 0, '4100292073': 0, '4100292074': 0, '4100292075': 0, '4100292077': 0, '4100292078': 0, '4100292079': 0, '4100292081': 0, '4100292083': 0, '4100292084': 0, '4100292085': 0, '4100292087': 0, '4100292088': 0, '4100302002': 0, '4100302013': 1, '4100302014': 0, '4100302016': 1, '4100302017': 0, '4100302018': 1, '4100302019': 0, '4100302020': 0, '4100302024': 0, '4100302028': 0, '4100302030': 1, '4100302040': 1, '4100302041': 0, '4100302042': 1, '4100302043': 1, '4100302044': 1, '4100302045': 1, '4100302046': 0, '4100302047': 0, '4100302048': 1, '4100302049': 0, '4100302050': 0, '4100302051': 0, '4100302052': 0, '4100302053': 0, '4100302054': 0, '4100302055': 1, '4100302058': 1, '4100302061': 0, '4100302063': 0, '4100302064': 1, '4100302066': 1, '4100302067': 0, '4100302068': 0, '4100302069': 0, '4100321001': 1, '4100321002': 0, '4100321003': 0, '4100321004': 0, '4100321005': 0, '4100321006': 0, '4100321008': 0, '4100321009': 1, '4100321010': 0, '4100321011': 0, '4100321012': 0, '4100321014': 0, '4100321015': 0, '4100321016': 0, '4100321019': 1, '4100321020': 0, '4100321021': 0, '4100321022': 0, '4100321023': 0, '4100321024': 0, '4100321026': 0, '4100321027': 0, '4100321028': 0, '4100321029': 0, '4100321030': 0, '4100321032': 0, '4100321033': 0, '4100321034': 0, '4100321037': 0, '4100321038': 0, '4100321039': 0, '4100321041': 0, '4100321042': 1, '4100321043': 1, '4100321044': 1, '4100321045': 0, '4100321046': 0, '4100321049': 0, '4100321051': 0, '4100321052': 0, '4100321053': 0, '4100322001': 0, '4100322007': 0, '4100322025': 0, '4100322031': 0, '4100322032': 1, '4100322033': 0, '4100322034': 0, '4100322035': 0, '4100322037': 0, '4100322038': 0, '4100322039': 0, '4100322040': 0, '4100322041': 0, '4100322042': 0, '4100322044': 0, '4100322045': 0, '4100322048': 0, '4100322051': 0, '4100322052': 0, '4100322053': 0, '4100322055': 0, '4100322056': 0, '4100322057': 0, '4100322058': 0, '4100322059': 0, '4100322060': 0, '4100322061': 0, '4110211001': 1, '4110211004': 1, '4110211005': 1, '4110211006': 0, '4110211007': 0, '4110211008': 0, '4110211009': 0, '4110211011': 0, '4110211013': 1, '4110211014': 1, '4110211015': 1, '4110211016': 0, '4110211018': 0, '4110211019': 0, '4110211020': 0, '4110211021': 1, '4110211022': 1, '4110211023': 1, '4110211024': 0, '4110211025': 1, '4110211026': 0, '4110211027': 1, '4110211028': 1, '4110211030': 0, '4110211032': 0, '4110211033': 0, '4110211034': 0, '4110211035': 0, '4110211036': 1, '4110211037': 0, '4110211038': 1, '4110211039': 1, '4110211040': 1, '4110211041': 0, '4110211043': 0, '4110211044': 0, '4110211045': 1, '4110211046': 0, '4110211047': 0, '4110211048': 0, '4110211049': 0, '4110211050': 0, '4110211051': 0, '4110211052': 0, '4110211053': 1, '4110211054': 0, '4110211055': 1, '4110211056': 0, '4110211057': 0, '4110211058': 0, '4110211060': 0, '4110211061': 1, '4110211062': 0, '4110211063': 0, '4110211064': 0, '4110211065': 0, '4110211067': 0, '4110211068': 0, '4110211072': 0, '4110211073': 0, '4110211075': 1, '4110211076': 0, '4110211078': 1, '4110211079': 0, '4110211080': 0, '4110212003': 0, '4110212004': 0, '4110212007': 0, '4110212008': 0, '4110212009': 0, '4110212010': 0, '4110212011': 0, '4110212013': 0, '4110212014': 0, '4110212015': 0, '4110212016': 0, '4110212017': 0, '4110212018': 0, '4110212019': 0, '4110212021': 0, '4110212023': 0, '4110212024': 0, '4110212026': 0, '4110212027': 0, '4110212029': 0, '4110212030': 0, '4110212033': 0, '4110212034': 1, '4110212035': 0, '4110212036': 1, '4110212038': 0, '4110212039': 0, '4110212041': 0, '4110212042': 0, '4110212044': 0, '4110212045': 0, '4110212046': 0, '4110212047': 0, '4110212049': 1, '4110212050': 0, '4110212051': 1, '4110212052': 0, '4110212053': 0, '4110212054': 0, '4110212055': 0, '4110212056': 0, '4110212059': 0, '4110212061': 0, '4110212062': 1, '4110212063': 0, '4110212064': 0, '4110212069': 0, '4110311001': 0, '4110311003': 0, '4110311004': 0, '4110311005': 0, '4110311006': 1, '4110311012': 0, '4110311015': 0, '4110311017': 0, '4110311018': 0, '4110311019': 0, '4110311020': 0, '4110311021': 0, '4110311023': 1, '4110311030': 0, '4110311031': 0, '4110311032': 0, '4110311033': 0, '4110311034': 0, '4110311036': 0, '4110311037': 0, '4110311038': 0, '4110311042': 0, '4110311043': 0, '4110311044': 0, '4110311045': 1, '4110311046': 0, '4110311048': 1, '4110311049': 0, '4110311050': 0, '4110311053': 0, '4110311054': 1, '4110311057': 0, '4110311061': 0, '4110311062': 1, '4110311064': 0, '4110311065': 0, '4110311067': 0, '4110311068': 0, '4110311072': 0, '4110312006': 0, '4110312007': 0, '4110312008': 0, '4110312009': 1, '4110312013': 0, '4110312023': 0, '4110312024': 0, '4110312025': 0, '4110312027': 0, '4110312030': 0, '4110312031': 0, '4110312048': 0, '4110312049': 0, '4110312078': 0, '414081010': 0, '414081011': 0, '4140810110': 0, '4140810114': 0, '4140810117': 0, '4140810122': 0, '4140810124': 0, '4140810125': 0, '4140810126': 0, '4140810127': 0, '4140810128': 0, '4140810129': 0, '414081013': 0, '4140810132': 0, '4140810133': 0, '4140810135': 0, '4140810136': 0, '4140810138': 0, '4140810139': 0, '4140810140': 0, '4140810142': 0, '4140810143': 0, '4140810144': 0, '4140810145': 0, '4140810146': 0, '4140810148': 0, '414081015': 0, '4140810150': 0, '4140810151': 0, '4140810152': 0, '4140810153': 1, '4140810154': 0, '4140810158': 0, '4140810159': 0, '414081016': 0, '4140810162': 1, '4140810163': 0, '4140810164': 0, '4140810165': 0, '414081017': 0, '4140810171': 0, '4140810173': 0, '4140810175': 0, '4140810176': 0, '4140810179': 0, '414081018': 0, '4140810180': 0, '4140810181': 0, '4140810182': 0, '4140810183': 0, '4140810184': 0, '4140810185': 0, '414081019': 0, '414081021': 0, '4140810210': 1, '4140810211': 0, '4140810212': 0, '4140810215': 0, '4140810217': 1, '4140810219': 1, '4140810220': 0, '4140810221': 0, '4140810222': 0, '4140810223': 0, '4140810224': 0, '4140810225': 0, '4140810226': 0, '4140810228': 0, '4140810229': 0, '414081023': 0, '4140810230': 0, '4140810233': 0, '4140810234': 0, '4140810237': 0, '4140810239': 0, '4140810240': 0, '4140810242': 0, '4140810244': 0, '4140810246': 0, '4140810247': 0, '4140810249': 0, '414081025': 0, '4140810250': 0, '4140810251': 0, '4140810252': 0, '4140810253': 0, '4140810254': 0, '4140810255': 0, '4140810256': 0, '4140810257': 0, '4140810258': 0, '4140810259': 0, '414081026': 0, '4140810264': 0, '4140810265': 0, '4140810266': 0, '4140810268': 0, '4140810269': 0, '414081027': 0, '4140810270': 0, '4140810271': 0, '4140810272': 1, '4140810273': 0, '4140810274': 0, '4140810276': 0, '4140810277': 0, '4140810278': 0, '4140810279': 0, '414081028': 0, '4140810280': 0, '414081029': 0, '459999011': 0, '4599990110': 0, '4599990112': 0, '4599990113': 0, '4599990114': 0, '4599990116': 0, '4599990117': 0, '4599990118': 0, '4599990119': 0, '459999012': 0, '4599990120': 0, '4599990125': 0, '4599990126': 0, '4599990128': 0, '4599990129': 0, '459999013': 0, '4599990130': 0, '4599990131': 0, '4599990132': 1, '4599990133': 0, '4599990134': 0, '4599990136': 0, '4599990137': 0, '4599990139': 0, '4599990141': 0, '4599990144': 0, '4599990146': 0, '4599990148': 0, '4599990149': 0, '4599990153': 0, '4599990154': 0, '4599990155': 0, '459999016': 0, '4599990163': 0, '4599990165': 0, '4599990166': 0, '4599990168': 0, '459999017': 0, '4599990171': 0, '459999021': 0, '4599990211': 0, '4599990212': 0, '4599990214': 0, '4599990216': 0, '4599990218': 0, '459999022': 0, '4599990221': 0, '4599990222': 0, '4599990223': 0, '4599990224': 0, '4599990226': 0, '4599990231': 0, '4599990233': 0, '4599990234': 0, '4599990235': 1, '4599990238': 0, '459999024': 0, '4599990240': 0, '4599990241': 0, '4599990243': 0, '4599990244': 0, '4599990245': 0, '4599990246': 0, '4599990247': 0, '4599990248': 0, '4599990249': 0, '459999025': 0, '4599990253': 0, '4599990254': 0, '4599990255': 0, '4599990256': 0, '4599990263': 0, '4599990264': 0, '4599990269': 0, '4599990270': 0, '4599990272': 0, '4599990273': 0, '4599990274': 0, '4599990275': 0, '4599990276': 0, '459999028': 0, '4599990283': 0, '5000391001': 0, '5000391002': 0, '5000391004': 0, '5000391005': 0, '5000391007': 0, '5000391008': 0, '5000391010': 0, '5000391012': 0, '5000391013': 0, '5000391014': 0, '5000391015': 0, '5000391016': 0, '5000391017': 1, '5000391019': 0, '5000391020': 0, '5000391022': 0, '5000391023': 0, '5000391024': 0, '5000391026': 0, '5000391028': 0, '5000391029': 0, '5000391030': 0, '5000391031': 0, '5000391032': 0, '5000391034': 0, '5000391035': 0, '5000391036': 0, '5000391037': 0, '5000391038': 0, '5000391040': 0, '5000391045': 1, '5000391046': 0, '5000391047': 0, '5000391049': 0, '5000391050': 0, '5000391054': 0, '5000391055': 1, '5000391056': 1, '5000391059': 0, '5000391060': 1, '5000391061': 0, '5000391062': 0, '5000391063': 0, '5000391064': 0, '5000391065': 0, '5000391066': 0, '5000391067': 0, '5000391068': 0, '5000391069': 0, '5000391070': 0, '5000391071': 0, '5000391072': 0, '5000391073': 0, '5000391074': 0, '5000391076': 0, '5000391078': 0, '5000391079': 0, '5000391080': 0, '5000391081': 0, '5000392001': 0, '5000392002': 0, '5000392003': 0, '5000392006': 0, '5000392007': 0, '5000392010': 0, '5000392011': 0, '5000392015': 0, '5000392016': 0, '5000392017': 0, '5000392018': 0, '5000392019': 0, '5000392020': 0, '5000392021': 0, '5000392022': 0, '5000392025': 0, '5000392026': 0, '5000392027': 0, '5000392029': 0, '5000392033': 1, '5000392035': 0, '5000392036': 0, '5000392038': 0, '5000392039': 0, '5000392040': 0, '5000392041': 0, '5000392042': 0, '5000392044': 0, '5000392047': 0, '5000392048': 0, '5000392049': 0, '5000392050': 0, '5000392051': 0, '5000392052': 1, '5000392053': 0, '5000392054': 0, '5000392055': 0, '5000392056': 0, '5000392058': 0, '5000392060': 1, '5000392062': 0, '5000392063': 0, '5000392064': 0, '5000392065': 0, '5000392066': 0, '5000392067': 0, '5000392070': 0, '5000392071': 0, '5000392072': 0, '5000431019': 0, '5000431020': 0, '5000431021': 0, '5000431022': 0, '5000431023': 0, '5000431025': 0, '5000431026': 0, '5000431049': 0, '5000431050': 0, '5000432001': 0, '5000432003': 0, '5000432006': 0, '5000432059': 0, '5000441001': 0, '5000441002': 0, '5000441003': 0, '5000441005': 0, '5000441006': 0, '5000441007': 0, '5000441008': 0, '5000441009': 0, '5000441010': 0, '5000441012': 0, '5000441013': 0, '5000441014': 0, '5000441015': 0, '5000441016': 0, '5000441017': 0, '5000441018': 0, '5000441021': 0, '5000441022': 0, '5000441023': 0, '5000441024': 1, '5000441027': 0, '5000441030': 0, '5000441031': 0, '5000441032': 0, '5000441033': 0, '5000441034': 0, '5000441035': 0, '5000441037': 0, '5000441038': 0, '5000441039': 0, '5000441040': 0, '5000441041': 0, '5000441042': 0, '5000441043': 0, '5000441044': 0, '5000441045': 0, '5000441046': 0, '5000441047': 0, '5000441048': 0, '5000441050': 0, '5000441051': 0, '5000441052': 0, '5000441053': 0, '5000441054': 0, '5000441055': 0, '5000441058': 1, '5000441059': 0, '5000441061': 0, '5000441062': 0, '5000441064': 0, '5000441065': 0, '5000441066': 0, '5000441067': 1, '5000441068': 0, '5000441069': 0, '5000441070': 0, '5000441071': 0, '5000441072': 0, '5000442001': 0, '5000442002': 0, '5000442003': 0, '5000442004': 0, '5000442005': 0, '5000442007': 0, '5000442008': 0, '5000442009': 0, '5000442010': 0, '5000442014': 0, '5000442015': 0, '5000442016': 0, '5000442019': 0, '5000442021': 0, '5000442022': 0, '5000442024': 0, '5000442025': 0, '5000442026': 0, '5000442027': 0, '5000442028': 0, '5000442029': 0, '5000442033': 0, '5000442034': 0, '5000442035': 0, '5000442036': 0, '5000442037': 0, '5000442038': 0, '5000442039': 0, '5000442040': 0, '5000442042': 0, '5000442043': 0, '5000442045': 0, '5000442047': 0, '5000442048': 0, '5000442050': 0, '5000442051': 0, '5000442052': 0, '5000442053': 0, '5000442054': 0, '5000442055': 0, '5000442056': 0, '5000442057': 0, '5000442058': 0, '5000442059': 0, '5000442060': 0, '5000442062': 0, '5000442063': 0, '5000442064': 0, '5000442065': 0, '5000442066': 0, '5000442067': 0, '5000442068': 0, '5000442069': 0, '5000442070': 0, '5000442072': 0, '5000442073': 0, '5000442074': 0, '5000442075': 0, '5000442076': 0, '5000442077': 0, '5000442078': 0, '5000671001': 0, '5000671002': 0, '5000671003': 0, '5000671004': 0, '5000671005': 0, '5000671006': 0, '5000671008': 0, '5000671009': 0, '5000671010': 0, '5000671011': 0, '5000671012': 0, '5000671013': 0, '5000671014': 0, '5000671015': 0, '5000671016': 0, '5000671017': 0, '5000671018': 0, '5000671019': 0, '5000671020': 0, '5000671022': 0, '5000671023': 0, '5000671024': 0, '5000671026': 0, '5000671027': 0, '5000671028': 0, '5000671029': 0, '5000671030': 0, '5000671031': 0, '5000671032': 0, '5000671033': 0, '5000671034': 0, '5000671035': 0, '5000671036': 0, '5000671037': 0, '5000671038': 0, '5000671039': 0, '5000671040': 0, '5000671041': 1, '5000671042': 1, '5000671043': 0, '5000671046': 0, '5000671047': 0, '5000671048': 1, '5000671049': 1, '5000671050': 0, '5000671051': 0, '5000671053': 0, '5000671055': 0, '5000671056': 0, '5000671057': 0, '5000671058': 1, '5000671059': 0, '5000671060': 0, '5000671061': 1, '5000671062': 0, '5000671063': 0, '5000671064': 0, '5000671065': 0, '5000671066': 0, '5000671067': 0, '5000671069': 1, '5000671070': 1, '5000671071': 0, '5000672002': 0, '5000672004': 0, '5000672005': 0, '5000672006': 0, '5000672007': 0, '5000672008': 0, '5000672010': 0, '5000672011': 0, '5000672012': 0, '5000672013': 0, '5000672014': 0, '5000672016': 0, '5000672017': 0, '5000672019': 0, '5000672020': 0, '5000672021': 0, '5000672022': 0, '5000672023': 0, '5000672024': 0, '5000672025': 0, '5000672026': 0, '5000672027': 0, '5000672030': 0, '5000672031': 0, '5000672033': 0, '5000672034': 0, '5000672035': 0, '5000672036': 0, '5000672038': 0, '5000672042': 0, '5000672043': 0, '5000672044': 0, '5000672045': 0, '5000672046': 0, '5000672047': 0, '5000672048': 0, '5000672049': 0, '5000672050': 0, '5000672051': 0, '5000672052': 0, '5000672053': 0, '5000672054': 0, '5000672055': 0, '5000672056': 0, '5000672057': 0, '5000672058': 0, '5000672059': 0, '5000672060': 0, '5000672062': 0, '5000672064': 0, '5000672065': 0, '5000672066': 0, '5000672067': 0, '5000672068': 0, '5000672070': 0, '5000672071': 0, '5000672072': 0, '5000672074': 0, '5000672075': 0, '5000672076': 0, '5000672077': 0, '5000672081': 0, '5000672082': 0, '5000951001': 0, '5000951002': 0, '5000951003': 0, '5000951004': 0, '5000951005': 0, '5000951006': 0, '5000951007': 0, '5000951008': 0, '5000951009': 0, '5000951010': 0, '5000951011': 0, '5000951012': 0, '5000951013': 0, '5000951015': 0, '5000951016': 0, '5000951017': 0, '5000951018': 0, '5000951019': 1, '5000951021': 0, '5000951023': 1, '5000951024': 1, '5000951025': 0, '5000951027': 1, '5000951028': 0, '5000951033': 0, '5000951034': 0, '5000951035': 0, '5000951037': 0, '5000951039': 0, '5000951040': 0, '5000951042': 0, '5000951043': 0, '5000951044': 0, '5000951045': 0, '5000951047': 0, '5000951049': 0, '5000951051': 0, '5000951052': 0, '5000951053': 0, '5000951054': 0, '5000951055': 0, '5000951056': 0, '5000951057': 0, '5000951058': 0, '5000951060': 0, '5000951061': 0, '5000951062': 0, '5000951063': 0, '5000951065': 0, '5000951066': 0, '5000951067': 0, '5000952002': 0, '5000952003': 0, '5000952004': 0, '5000952005': 0, '5000952007': 0, '5000952008': 0, '5000952011': 0, '5000952013': 0, '5000952014': 0, '5000952015': 0, '5000952016': 0, '5000952017': 0, '5000952018': 0, '5000952020': 0, '5000952021': 0, '5000952022': 0, '5000952023': 0, '5000952024': 0, '5000952025': 0, '5000952026': 0, '5000952027': 0, '5000952028': 0, '5000952029': 0, '5000952031': 0, '5000952032': 0, '5000952033': 0, '5000952034': 1, '5000952035': 0, '5000952036': 0, '5000952038': 0, '5000952040': 0, '5000952041': 0, '5000952042': 0, '5000952044': 0, '5000952045': 0, '5000952046': 0, '5000952048': 0, '5000952050': 0, '5000952052': 0, '5000952053': 0, '5000952054': 0, '5000952055': 0, '5000952060': 0, '5000952061': 0, '5000952062': 1, '5000952063': 0, '5000952064': 0, '5000952065': 0, '5000952066': 0, '5000952068': 0, '5000952069': 0, '5000952070': 0, '5000952071': 0, '5000952072': 0, '5000952073': 0, '5000952075': 0, '5000952076': 0, '5000952077': 0, '5000952078': 0, '5000952080': 0, '5000952083': 1, '5100091001': 0, '5100091003': 0, '5100091004': 0, '5100091005': 0, '5100091006': 0, '5100091007': 0, '5100091008': 0, '5100091009': 0, '5100091010': 0, '5100091012': 0, '5100091017': 0, '5100091019': 0, '5100091020': 0, '5100091025': 0, '5100091026': 0, '5100091027': 0, '5100091028': 0, '5100091032': 0, '5100091033': 0, '5100091034': 0, '5100091035': 0, '5100091036': 0, '5100091038': 0, '5100091039': 0, '5100091042': 0, '5100091046': 0, '5100091049': 1, '5100091050': 0, '5100091051': 0, '5100091053': 0, '5100091055': 0, '5100091056': 0, '5100091057': 0, '5100091058': 0, '5100091059': 0, '5100091062': 0, '5100091064': 0, '5100091065': 0, '5100091066': 0, '5100091067': 0, '5100091068': 0, '5100091069': 0, '5100092002': 0, '5100092003': 0, '5100092005': 0, '5100092006': 0, '5100092008': 0, '5100092010': 0, '5100092011': 0, '5100092013': 0, '5100092017': 0, '5100092019': 0, '5100092021': 0, '5100092022': 0, '5100092023': 0, '5100092026': 0, '5100092027': 0, '5100092032': 0, '5100092033': 0, '5100092034': 0, '5100092035': 0, '5100092037': 0, '5100092038': 0, '5100092039': 0, '5100092040': 0, '5100092041': 0, '5100092042': 0, '5100092043': 0, '5100092044': 0, '5100092045': 0, '5100092053': 0, '5100092056': 0, '5100092057': 0, '5100092060': 0, '5100092061': 0, '5100092062': 0, '5100092063': 0, '5100092064': 0, '5100092065': 0, '5100092067': 0, '5100092068': 0, '5100092069': 0, '5100092071': 0, '5100092072': 0, '5100341002': 0, '5100341003': 0, '5100341004': 0, '5100341005': 0, '5100341006': 0, '5100341008': 0, '5100341009': 0, '5100341010': 0, '5100341012': 0, '5100341013': 0, '5100341014': 0, '5100341015': 0, '5100341016': 0, '5100341017': 0, '5100341019': 0, '5100341020': 0, '5100341021': 0, '5100341022': 0, '5100341023': 0, '5100341024': 0, '5100341025': 0, '5100341026': 0, '5100341027': 0, '5100341028': 0, '5100341030': 0, '5100341031': 0, '5100341032': 0, '5100341033': 0, '5100341034': 0, '5100341035': 0, '5100341037': 0, '5100341038': 0, '5100341039': 0, '5100341042': 0, '5100341043': 1, '5100341046': 0, '5100341048': 0, '5100341050': 0, '5100341052': 0, '5100341054': 0, '5100341055': 0, '5100341056': 0, '5100341057': 0, '5100341058': 0, '5100341061': 0, '5100341062': 0, '5100341065': 0, '5100341067': 0, '5100341068': 0, '5100341070': 0, '5100341071': 0, '5100341072': 0, '5100341074': 1, '5100341075': 0, '5100341076': 0, '5100341077': 0, '5100341078': 0, '5100341079': 0, '5100342002': 0, '5100342003': 0, '5100342007': 0, '5100342008': 0, '5100342009': 0, '5100342012': 0, '5100342016': 0, '5100342017': 0, '5100342018': 0, '5100342020': 0, '5100342022': 1, '5100342023': 1, '5100342024': 1, '5100342025': 0, '5100342028': 1, '5100342030': 0, '5100342031': 0, '5100342034': 0, '5100342036': 1, '5100342042': 0, '5100342043': 0, '5100342045': 0, '5100342048': 1, '5100351001': 1, '5100351002': 1, '5100351004': 0, '5100351005': 0, '5100351007': 0, '5100351009': 0, '5100351010': 0, '5100351012': 0, '5100351013': 1, '5100351015': 0, '5100351016': 0, '5100351019': 0, '5100351020': 0, '5100351021': 0, '5100351022': 1, '5100351023': 0, '5100351024': 0, '5100351025': 0, '5100351026': 0, '5100351032': 0, '5100351034': 0, '5100351035': 0, '5100351036': 0, '5100351038': 0, '5100351039': 0, '5100351040': 0, '5100351042': 1, '5100351043': 0, '5100351044': 0, '5100351045': 0, '5100351046': 0, '5100351049': 0, '5100351051': 0, '5100351054': 0, '5100351058': 0, '5100352001': 0, '5100352002': 0, '5100352003': 0, '5100352004': 0, '5100352005': 0, '5100352006': 0, '5100352007': 0, '5100352008': 0, '5100352009': 0, '5100352011': 0, '5100352012': 0, '5100352013': 0, '5100352014': 0, '5100352015': 0, '5100352016': 0, '5100352017': 0, '5100352018': 0, '5100352020': 0, '5100352021': 0, '5100352022': 1, '5100352026': 0, '5100352027': 0, '5100352028': 0, '5100352030': 0, '5100352031': 0, '5100352032': 0, '5100352033': 0, '5100352034': 0, '5100352035': 0, '5100352037': 0, '5100352038': 0, '5100352039': 0, '5100352041': 0, '5100352042': 0, '5100352043': 1, '5100352044': 0, '5100352045': 0, '5100352046': 0, '5100352049': 0, '5100352050': 0, '5100352051': 0, '5100352052': 0, '5100352054': 1, '5100352055': 0, '5100352056': 0, '5100352057': 0, '5100352060': 0, '5100352061': 0, '5100352063': 0, '5100361009': 0, '5100361056': 0, '5100362028': 0, '5100362029': 0, '5100362030': 0, '5100362052': 0, '5100371022': 0, '5100371023': 0, '5100371024': 0, '5100371026': 0, '5100371027': 0, '5100371042': 0, '5100371055': 0, '5100371056': 0, '5100371067': 0, '5100371079': 0, '5100372001': 0, '5100372002': 0, '5100372003': 0, '5100372005': 0, '5100372006': 0, '5100372007': 0, '5100372009': 0, '5100372011': 0, '5100372015': 0, '5100372016': 0, '5100372017': 0, '5100372018': 0, '5100372019': 0, '5100372020': 0, '5100372021': 0, '5100372022': 0, '5100372023': 0, '5100372026': 0, '5100372027': 0, '5100372028': 0, '5100372069': 0, '5100381002': 0, '5100381003': 0, '5100381004': 0, '5100381005': 0, '5100381006': 0, '5100381007': 0, '5100381008': 0, '5100381009': 0, '5100381010': 0, '5100381011': 0, '5100381012': 0, '5100381015': 0, '5100381016': 0, '5100381017': 0, '5100381018': 0, '5100381019': 0, '5100381020': 0, '5100381021': 0, '5100381022': 0, '5100381023': 0, '5100381024': 0, '5100381026': 0, '5100381027': 0, '5100381028': 0, '5100381029': 0, '5100381031': 0, '5100381032': 0, '5100381034': 0, '5100381035': 0, '5100381037': 0, '5100381038': 0, '5100381039': 0, '5100381040': 0, '5100381041': 0, '5100381042': 0, '5100381043': 0, '5100381044': 0, '5100381045': 0, '5100381046': 0, '5100381047': 0, '5100381048': 0, '5100381049': 0, '5100381050': 0, '5100381051': 0, '5100381052': 0, '5100381053': 0, '5100381054': 0, '5100381055': 0, '5100381056': 0, '5100381058': 0, '5100381059': 0, '5100381060': 0, '5100381061': 0, '5100381063': 0, '5100381065': 0, '5100381066': 0, '5100381067': 0, '5100381069': 0, '5100382001': 0, '5100382003': 0, '5100382007': 0, '5100382008': 0, '5100382010': 0, '5100382011': 0, '5100382012': 0, '5100382013': 0, '5100382014': 0, '5100382015': 0, '5100382016': 0, '5100382018': 0, '5100382019': 0, '5100382020': 0, '5100382021': 0, '5100382022': 0, '5100382023': 0, '5100382025': 0, '5100382026': 0, '5100382027': 0, '5100382028': 0, '5100382029': 0, '5100382030': 0, '5100382031': 0, '5100382032': 0, '5100382033': 0, '5100382034': 0, '5100382035': 0, '5100382036': 0, '5100382037': 0, '5100382038': 0, '5100382039': 0, '5100382040': 0, '5100382042': 0, '5100382045': 0, '5100382046': 0, '5100382048': 0, '5100382050': 0, '5100382051': 0, '5100382052': 0, '5100382053': 0, '5100382054': 0, '5100382055': 0, '5100382056': 0, '5100382057': 0, '5100382058': 0, '5100382059': 0, '5100382060': 0, '5100382061': 0, '5100382062': 0, '5100382063': 0, '5100382064': 0, '5100382065': 0, '5100382066': 0, '5100382067': 0, '5100382068': 0, '5100382069': 0, '5100382070': 0, '5100382071': 0, '5100382072': 0, '5100382073': 0, '5100382075': 0, '5100382076': 0, '5100382077': 0, '5100382078': 0, '5100382079': 0, '5100401001': 0, '5100401003': 0, '5100401005': 0, '5100401006': 0, '5100401007': 0, '5100401008': 0, '5100401010': 0, '5100401011': 0, '5100401012': 0, '5100401014': 0, '5100401015': 0, '5100401016': 0, '5100401018': 0, '5100401021': 0, '5100401022': 0, '5100401023': 1, '5100401025': 0, '5100401026': 0, '5100401028': 0, '5100401029': 0, '5100401030': 0, '5100401031': 0, '5100401032': 0, '5100401033': 0, '5100401034': 1, '5100401035': 0, '5100401036': 0, '5100401038': 0, '5100401039': 0, '5100401040': 0, '5100401042': 0, '5100401043': 1, '5100401044': 0, '5100401045': 0, '5100401046': 0, '5100401047': 0, '5100401048': 0, '5100401049': 0, '5100401050': 0, '5100401051': 0, '5100401053': 0, '5100401054': 0, '5100401055': 0, '5100401056': 0, '5100401057': 0, '5100401059': 0, '5100401060': 0, '5100401061': 0, '5100401062': 0, '5100401063': 0, '5100401064': 0, '5100401065': 1, '5100401066': 0, '5100401067': 0, '5100401069': 0, '5100401070': 0, '5100401071': 0, '5100401072': 0, '5100401073': 0, '5100401074': 0, '5100401075': 0, '5100401076': 0, '5100401077': 0, '5100401078': 0, '5100402001': 1, '5100402002': 0, '5100402004': 0, '5100402005': 0, '5100402007': 0, '5100402008': 0, '5100402009': 0, '5100402011': 0, '5100402012': 0, '5100402015': 0, '5100402016': 0, '5100402017': 0, '5100402019': 0, '5100402020': 0, '5100402023': 0, '5100402024': 0, '5100402028': 0, '5100402029': 0, '5100402031': 0, '5100402032': 0, '5100402033': 0, '5100402034': 0, '5100402035': 0, '5100402036': 0, '5100402037': 0, '5100402038': 0, '5100402039': 0, '5100402040': 0, '5100402046': 0, '5100402047': 0, '5100402048': 0, '5100402049': 0, '5100402050': 0, '5100402051': 0, '5100402052': 0, '5100402053': 0, '5100402054': 0, '5100402055': 0, '5100402057': 0, '5100402058': 0, '5100402059': 0, '5100402062': 1, '5100402063': 1, '5100402065': 0, '5100402066': 0, '5100402067': 0, '5100402068': 0, '5100402069': 0, '5100421001': 0, '5100421002': 0, '5100421003': 0, '5100421005': 0, '5100421007': 0, '5100421009': 0, '5100421011': 0, '5100421012': 0, '5100421013': 0, '5100421015': 0, '5100421016': 0, '5100421017': 0, '5100421018': 0, '5100421019': 0, '5100421020': 0, '5100421021': 0, '5100421024': 0, '5100421025': 0, '5100421026': 0, '5100421027': 0, '5100421029': 0, '5100421032': 0, '5100421033': 0, '5100421034': 0, '5100421038': 0, '5100421039': 0, '5100421040': 0, '5100421041': 0, '5100421043': 0, '5100421045': 0, '5100421047': 0, '5100421048': 0, '5100421049': 0, '5100421050': 0, '5100421051': 0, '5100421052': 0, '5100421053': 0, '5100421054': 0, '5100421056': 0, '5100421057': 0, '5100421058': 0, '5100421059': 0, '5100421060': 0, '5100421061': 0, '5100421062': 0, '5100421063': 0, '5100421064': 0, '5100421065': 0, '5100421067': 0, '5100421068': 0, '5100421069': 0, '5100421070': 0, '5100421071': 0, '5100421072': 0, '5100421073': 0, '5100421074': 0, '5100421076': 0, '5100421078': 0, '5100421079': 0, '5100421080': 0, '5100421081': 0, '5100422002': 0, '5100422003': 0, '5100422004': 0, '5100422005': 0, '5100422006': 0, '5100422007': 0, '5100422008': 0, '5100422009': 0, '5100422011': 0, '5100422012': 0, '5100422013': 0, '5100422014': 0, '5100422016': 0, '5100422017': 0, '5100422018': 0, '5100422019': 0, '5100422022': 0, '5100422023': 0, '5100422024': 0, '5100422025': 0, '5100422026': 0, '5100422027': 0, '5100422028': 0, '5100422029': 0, '5100422030': 0, '5100422033': 0, '5100422034': 0, '5100422035': 0, '5100422036': 0, '5100422037': 0, '5100422038': 0, '5100422039': 0, '5100422041': 0, '5100422042': 0, '5100422044': 0, '5100422045': 0, '5100422046': 0, '5100422047': 0, '5100422049': 0, '5100422050': 0, '5100422051': 0, '5100422052': 0, '5100422055': 0, '5100422056': 0, '5100422057': 0, '5100422058': 0, '5100422059': 0, '5100422060': 0, '5100422061': 0, '5100422062': 0, '5100422063': 0, '5100422065': 0, '5100422066': 0, '5100422067': 0, '5100422068': 0, '5100422069': 0, '5100422071': 0, '5100422072': 0, '5100422073': 0, '5100422074': 0, '5100422075': 0, '5100422077': 0, '5100422078': 0, '5100422079': 0, '5100422080': 0, '5100422081': 0, '5100422084': 0, '5100422085': 0, '5100451001': 0, '5100451003': 0, '5100451004': 0, '5100451006': 0, '5100451007': 0, '5100451012': 0, '5100451013': 0, '5100451015': 0, '5100451016': 0, '5100451017': 0, '5100451018': 0, '5100451019': 0, '5100451020': 0, '5100451024': 0, '5100451026': 0, '5100451027': 0, '5100451033': 0, '5100451034': 0, '5100451035': 0, '5100451036': 0, '5100451038': 0, '5100451041': 0, '5100451043': 0, '5100451044': 0, '5100451045': 0, '5100451049': 0, '5100451050': 0, '5100451051': 0, '5100451052': 0, '5100451055': 0, '5100451056': 0, '5100451059': 0, '5100451060': 0, '5100451061': 0, '5100451064': 0, '5100451065': 0, '5100451066': 0, '5100451067': 0, '5100451070': 0, '5100451071': 0, '5100452002': 0, '5100452004': 0, '5100452005': 0, '5100452006': 0, '5100452007': 0, '5100452008': 0, '5100452009': 0, '5100452010': 0, '5100452011': 0, '5100452012': 0, '5100452013': 0, '5100452014': 0, '5100452016': 1, '5100452017': 0, '5100452018': 0, '5100452021': 0, '5100452023': 0, '5100452025': 0, '5100452027': 0, '5100452028': 0, '5100452030': 0, '5100452031': 0, '5100452032': 0, '5100452033': 0, '5100452034': 0, '5100452035': 0, '5100452036': 0, '5100452037': 0, '5100452038': 0, '5100452039': 0, '5100452040': 0, '5100452047': 0, '5100452049': 0, '5100452050': 0, '5100452053': 0, '5100452054': 0, '5100452055': 0, '5100452059': 0, '5100452060': 0, '5100452061': 0, '5100452065': 0, '5100452066': 0, '5100452067': 0, '5100452076': 0, '5100452078': 0, '5100452079': 0, '5100452080': 0, '5100452081': 0, '5100461004': 0, '5100461005': 0, '5100461006': 0, '5100461007': 1, '5100461008': 0, '5100461009': 0, '5100461010': 0, '5100461011': 0, '5100461014': 0, '5100461015': 0, '5100461016': 0, '5100461017': 0, '5100461018': 0, '5100461020': 0, '5100461021': 0, '5100461022': 0, '5100461023': 0, '5100461025': 0, '5100461029': 0, '5100461030': 0, '5100461031': 0, '5100461032': 0, '5100461033': 0, '5100461034': 0, '5100461035': 0, '5100461036': 0, '5100461037': 0, '5100461038': 0, '5100461039': 0, '5100461040': 0, '5100461042': 0, '5100461043': 0, '5100461044': 0, '5100461046': 0, '5100461047': 0, '5100461048': 0, '5100461049': 0, '5100461050': 0, '5100461051': 0, '5100461052': 0, '5100461053': 0, '5100461054': 0, '5100461055': 0, '5100461056': 0, '5100461057': 0, '5100461058': 0, '5100461061': 0, '5100461062': 0, '5100461063': 0, '5100461064': 0, '5100461065': 0, '5100461066': 0, '5100461067': 0, '5100461068': 0, '5100461069': 0, '5100462001': 0, '5100462002': 0, '5100462003': 1, '5100462005': 0, '5100462009': 0, '5100462010': 0, '5100462011': 0, '5100462012': 0, '5100462014': 0, '5100462015': 0, '5100462016': 0, '5100462017': 0, '5100462018': 0, '5100462019': 0, '5100462021': 0, '5100462022': 0, '5100462023': 0, '5100462024': 0, '5100462025': 0, '5100462026': 0, '5100462027': 0, '5100462028': 0, '5100462029': 0, '5100462031': 0, '5100462032': 0, '5100462033': 0, '5100462035': 0, '5100462037': 0, '5100462038': 0, '5100462039': 0, '5100462040': 0, '5100462041': 0, '5100462042': 0, '5100462043': 0, '5100462044': 0, '5100462045': 0, '5100462046': 0, '5100462047': 0, '5100462048': 0, '5100462050': 0, '5100462051': 0, '5100462052': 0, '5100462053': 0, '5100462054': 0, '5100462055': 0, '5100462057': 0, '5100462058': 0, '5100462059': 0, '5100462061': 0, '5100462062': 0, '5100462063': 0, '5100462064': 0, '5100462066': 0, '5100462067': 0, '5100462068': 0, '5100462069': 0, '5100462070': 0, '5100462071': 0, '5100462072': 0, '5100462074': 0, '5100462075': 0, '5100462077': 0, '5100462078': 0, '5100462079': 0, '5100462080': 0, '5100462081': 0, '5100462082': 0, '5100471001': 0, '5100471002': 0, '5100471003': 0, '5100471011': 0, '5100471012': 0, '5100471013': 0, '5100471015': 0, '5100471016': 0, '5100471018': 0, '5100471019': 0, '5100471020': 0, '5100471021': 0, '5100471023': 0, '5100471026': 0, '5100471027': 0, '5100471028': 0, '5100471029': 0, '5100471030': 0, '5100471031': 0, '5100471034': 0, '5100471037': 0, '5100471038': 0, '5100471039': 0, '5100471041': 0, '5100471042': 0, '5100471044': 0, '5100471045': 0, '5100471047': 0, '5100471049': 0, '5100471050': 0, '5100471051': 0, '5100471052': 0, '5100471054': 0, '5100471056': 0, '5100471057': 0, '5100471058': 0, '5100471059': 0, '5100471060': 0, '5100471062': 0, '5100471063': 0, '5100471065': 0, '5100471068': 0, '5100471069': 0, '5100471070': 0, '5100471072': 0, '5100471074': 0, '5100471075': 0, '5100471080': 0, '5100471081': 0, '5100472001': 1, '5100472002': 0, '5100472003': 0, '5100472004': 0, '5100472005': 0, '5100472007': 0, '5100472009': 0, '5100472010': 0, '5100472011': 0, '5100472012': 0, '5100472014': 0, '5100472019': 0, '5100472020': 0, '5100472021': 0, '5100472027': 0, '5100472030': 0, '5100472031': 0, '5100472032': 0, '5100472035': 0, '5100472039': 0, '5100472040': 0, '5100472041': 0, '5100472042': 0, '5100472044': 0, '5100472045': 0, '5100472047': 0, '5100472050': 0, '5100472052': 0, '5100472053': 0, '5100472054': 0, '5100472058': 1, '5100472060': 0, '5100472063': 0, '5100472064': 0, '5221290110': 0, '5221290111': 0, '5221290112': 0, '5221290114': 0, '5221290115': 0, '5221290116': 0, '5221290118': 0, '5221290119': 0, '5221290121': 0, '5221290122': 0, '5221290123': 0, '5221290124': 0, '5221290126': 0, '5221290127': 0, '5221290129': 0, '522129013': 0, '5221290131': 0, '5221290132': 0, '5221290134': 0, '5221290135': 0, '5221290137': 0, '5221290138': 0, '5221290140': 0, '5221290141': 0, '5221290142': 0, '5221290144': 0, '5221290145': 0, '5221290147': 0, '5221290149': 0, '5221290150': 0, '5221290151': 0, '5221290155': 0, '5221290158': 0, '522129016': 0, '5221290161': 0, '5221290162': 0, '5221290163': 0, '5221290164': 0, '5221290165': 0, '5221290166': 0, '5221290167': 0, '5221290169': 0, '522129017': 0, '5221290171': 0, '5221290172': 0, '5221290173': 0, '5221290174': 0, '5221290175': 0, '5221290177': 0, '5221290178': 0, '5221290179': 0, '522129018': 0, '5221290180': 0, '5221290184': 0, '522129021': 0, '5221290210': 0, '5221290212': 0, '5221290213': 0, '5221290214': 0, '5221290215': 0, '5221290216': 0, '5221290217': 0, '522129022': 0, '5221290220': 0, '5221290221': 0, '5221290222': 0, '5221290223': 0, '5221290226': 0, '5221290227': 0, '5221290228': 0, '5221290230': 0, '5221290231': 0, '5221290235': 0, '5221290237': 0, '5221290238': 0, '5221290239': 0, '522129024': 0, '5221290240': 0, '5221290242': 0, '5221290247': 0, '5221290249': 0, '522129025': 0, '5221290250': 0, '5221290251': 0, '5221290252': 0, '5221290253': 0, '5221290254': 0, '5221290255': 0, '5221290256': 0, '5221290257': 0, '5221290258': 0, '5221290259': 0, '522129026': 0, '5221290263': 0, '5221290264': 0, '5221290266': 0, '5221290268': 0, '5221290269': 0, '522129027': 0, '5221290270': 0, '5221290271': 0, '5221290272': 0, '5221290273': 0, '5221290274': 0, '5221290275': 0, '5221290279': 0, '5221290280': 1, '5221290282': 0, '5221290284': 0, '5564630110': 0, '5564630112': 0, '5564630115': 0, '5564630117': 0, '556463012': 0, '5564630121': 0, '5564630122': 0, '5564630123': 0, '5564630126': 1, '5564630127': 0, '5564630128': 0, '5564630129': 0, '556463013': 0, '5564630130': 0, '5564630132': 1, '5564630133': 0, '5564630134': 0, '5564630135': 0, '5564630137': 1, '5564630138': 1, '5564630139': 0, '556463014': 1, '5564630140': 0, '5564630141': 1, '5564630142': 0, '5564630143': 0, '5564630145': 0, '5564630147': 0, '5564630148': 0, '5564630149': 0, '5564630150': 0, '5564630152': 0, '5564630153': 0, '5564630154': 1, '5564630156': 1, '5564630157': 0, '5564630158': 0, '556463016': 0, '5564630160': 0, '5564630161': 0, '5564630162': 0, '5564630163': 0, '5564630165': 0, '5564630166': 0, '5564630167': 0, '5564630168': 1, '556463018': 0, '556463019': 0, '5564630211': 1, '5564630212': 0, '5564630213': 0, '5564630215': 0, '5564630216': 0, '5564630217': 0, '5564630218': 0, '5564630219': 0, '556463022': 1, '5564630221': 0, '5564630222': 0, '5564630226': 1, '5564630228': 0, '5564630229': 0, '5564630230': 0, '5564630232': 0, '5564630233': 0, '5564630234': 0, '5564630235': 0, '5564630236': 0, '5564630237': 0, '5564630238': 1, '556463024': 0, '5564630240': 0, '5564630241': 0, '5564630247': 0, '5564630249': 0, '556463025': 1, '5564630252': 0, '5564630253': 0, '5564630254': 0, '5564630256': 0, '5564630257': 1, '5564630258': 0, '556463026': 0, '5564630261': 0, '5564630262': 0, '5564630264': 0, '5564630265': 0, '5564630269': 0, '556463027': 0, '5564630273': 0, '5564630275': 0, '5564630276': 0, '556463028': 0, '5564630281': 0, '556463029': 0, '567496011': 0, '5674960111': 0, '5674960114': 0, '5674960115': 0, '5674960116': 0, '5674960117': 0, '5674960118': 0, '5674960121': 0, '5674960123': 0, '5674960124': 0, '5674960125': 0, '5674960126': 0, '567496013': 0, '5674960131': 0, '5674960132': 0, '5674960134': 0, '5674960136': 0, '5674960138': 0, '567496014': 0, '5674960142': 0, '5674960144': 0, '5674960145': 0, '5674960146': 0, '5674960148': 0, '5674960151': 0, '5674960153': 0, '5674960154': 0, '5674960155': 1, '5674960156': 0, '5674960157': 0, '5674960158': 0, '5674960160': 0, '5674960161': 0, '5674960166': 0, '567496017': 0, '5674960170': 0, '567496018': 0, '567496019': 0, '567496021': 1, '5674960211': 0, '5674960215': 0, '5674960216': 0, '5674960219': 0, '567496022': 1, '5674960220': 0, '5674960221': 0, '5674960222': 1, '5674960224': 0, '5674960225': 1, '5674960227': 0, '5674960228': 0, '5674960229': 0, '5674960230': 0, '5674960234': 0, '5674960235': 0, '567496024': 0, '5674960242': 0, '5674960246': 0, '5674960249': 0, '5674960251': 0, '5674960252': 0, '5674960255': 0, '5674960257': 0, '567496026': 0, '5674960261': 0, '5674960264': 0, '5674960268': 0, '5674960272': 0, '5674960273': 0, '5674960274': 0, '5674960275': 0, '5674960276': 0, '5674960277': 0, '5674960278': 0, '5674960279': 0, '567496028': 0, '5674960281': 0, '5674960282': 0, '5674960283': 1, '567496029': 0, '5912920111': 0, '5912920112': 0, '5912920113': 0, '5912920114': 0, '5912920119': 0, '5912920121': 0, '5912920123': 0, '5912920124': 0, '5912920125': 0, '5912920126': 0, '5912920127': 0, '5912920128': 1, '5912920129': 0, '5912920131': 0, '5912920133': 0, '5912920135': 0, '5912920137': 0, '5912920140': 0, '5912920142': 0, '5912920143': 0, '5912920145': 0, '5912920146': 0, '5912920147': 0, '5912920148': 0, '5912920149': 0, '591292015': 0, '5912920151': 0, '5912920152': 0, '5912920154': 0, '5912920156': 0, '5912920158': 0, '5912920159': 0, '5912920160': 0, '5912920163': 0, '5912920167': 0, '5912920168': 0, '5912920169': 0, '5912920170': 0, '5912920171': 0, '5912920172': 0, '591292019': 0, '591292021': 0, '5912920211': 0, '5912920212': 0, '5912920213': 0, '5912920216': 0, '5912920217': 0, '5912920220': 0, '5912920222': 0, '5912920223': 0, '5912920225': 0, '5912920227': 0, '5912920228': 0, '5912920230': 0, '5912920231': 0, '5912920233': 0, '5912920234': 0, '5912920235': 0, '5912920236': 0, '5912920239': 0, '591292024': 0, '5912920240': 0, '5912920241': 0, '5912920242': 0, '5912920243': 0, '5912920244': 0, '5912920245': 0, '5912920249': 0, '5912920250': 0, '5912920256': 0, '5912920260': 0, '5912920263': 0, '5912920265': 0, '5912920266': 0, '5912920267': 0, '5912920268': 0, '5912920273': 0, '5912920274': 0, '5912920275': 0, '5912920276': 0, '5912920277': 0, '5912920279': 0, '5912920280': 0, '769862011': 0, '7698620112': 0, '7698620113': 0, '7698620115': 0, '7698620116': 0, '7698620118': 0, '7698620120': 0, '7698620122': 0, '7698620123': 0, '7698620126': 0, '7698620129': 0, '7698620130': 0, '7698620131': 0, '7698620132': 0, '7698620133': 0, '7698620134': 0, '7698620136': 0, '7698620138': 0, '7698620139': 0, '769862014': 0, '7698620141': 0, '7698620144': 0, '7698620145': 0, '7698620149': 0, '769862015': 0, '7698620150': 0, '7698620151': 0, '7698620152': 0, '7698620153': 0, '7698620156': 0, '7698620158': 0, '769862016': 0, '7698620160': 0, '7698620161': 0, '7698620163': 0, '7698620165': 0, '7698620166': 0, '7698620167': 0, '7698620169': 0, '769862017': 1, '7698620170': 0, '7698620171': 0, '769862018': 0, '769862019': 0, '769862021': 0, '7698620211': 0, '7698620212': 0, '7698620217': 0, '7698620218': 0, '769862022': 0, '7698620221': 0, '7698620222': 0, '7698620224': 0, '7698620225': 0, '7698620227': 0, '7698620229': 0, '7698620230': 0, '7698620231': 0, '7698620233': 1, '7698620236': 0, '7698620238': 0, '7698620239': 0, '7698620240': 0, '7698620241': 0, '7698620244': 0, '7698620245': 0, '7698620248': 0, '7698620250': 0, '7698620252': 1, '7698620253': 0, '7698620255': 0, '7698620256': 0, '7698620257': 0, '7698620258': 0, '7698620260': 0, '7698620261': 0, '7698620262': 0, '7698620264': 0, '7698620265': 0, '7698620267': 0, '7698620268': 0, '769862027': 0, '7698620270': 0, '7698620272': 0, '7698620274': 0, '7698620275': 0, '7698620278': 0, '769862028': 0, '7698620281': 0, '7698620283': 0, '7994020110': 0, '79940201100': 0, '79940201110': 0, '79940201140': 0, '79940201150': 0, '79940201160': 0, '79940201180': 0, '79940201210': 0, '79940201230': 0, '79940201250': 0, '79940201270': 0, '7994020130': 0, '79940201300': 1, '79940201320': 0, '79940201330': 0, '79940201340': 0, '79940201350': 0, '79940201360': 0, '79940201370': 0, '79940201380': 0, '79940201390': 1, '7994020140': 0, '79940201410': 0, '79940201420': 0, '79940201430': 0, '79940201470': 0, '79940201490': 0, '79940201510': 0, '79940201560': 0, '79940201570': 0, '79940201580': 0, '7994020160': 0, '79940201620': 0, '79940201650': 0, '79940201660': 1, '79940201690': 0, '79940201700': 0, '79940201710': 0, '79940201720': 0, '79940201730': 0, '79940201740': 0, '79940201750': 0, '79940201760': 0, '79940201770': 0, '79940201780': 0, '79940201790': 1, '79940201810': 0, '79940201820': 0, '79940201850': 0, '79940201860': 0, '79940201880': 0, '79940201930': 0, '79940201950': 0, '79940202100': 0, '79940202120': 0, '79940202130': 0, '79940202140': 0, '79940202160': 0, '79940202170': 0, '79940202180': 0, '79940202190': 0, '79940202200': 0, '79940202210': 0, '79940202220': 0, '79940202230': 0, '79940202270': 1, '79940202280': 1, '7994020230': 1, '79940202300': 0, '79940202310': 1, '79940202320': 0, '79940202340': 0, '79940202350': 0, '79940202370': 0, '79940202390': 0, '79940202400': 0, '79940202410': 0, '79940202450': 0, '79940202470': 0, '79940202480': 0, '79940202490': 1, '7994020250': 0, '79940202510': 0, '79940202520': 0, '79940202540': 0, '79940202560': 0, '79940202570': 0, '79940202580': 0, '79940202620': 0, '79940202690': 0, '7994020270': 0, '79940202700': 0, '79940202710': 0, '79940202750': 0, '79940202760': 0, '79940202790': 0, '7994020280': 0, '79940202800': 1, '79940202820': 0, '79940202840': 1, '79940202850': 1, '79940202860': 1, '79940202870': 0, '79940202890': 0, '7994020290': 0, '8263820112': 0, '8263820113': 0, '8263820120': 0, '8263820123': 0, '8263820124': 0, '8263820126': 0, '8263820132': 0, '8263820135': 0, '8263820136': 0, '8263820138': 0, '8263820139': 0, '8263820140': 0, '8263820141': 0, '8263820144': 0, '8263820145': 0, '8263820146': 0, '8263820147': 0, '8263820148': 0, '826382015': 0, '8263820150': 0, '8263820151': 0, '8263820152': 0, '8263820155': 0, '8263820156': 0, '8263820159': 0, '826382016': 0, '8263820160': 0, '8263820162': 0, '8263820165': 0, '8263820169': 0, '8263820170': 0, '826382018': 0, '826382021': 0, '8263820210': 0, '8263820211': 0, '8263820212': 0, '8263820213': 0, '8263820214': 0, '8263820221': 0, '8263820223': 0, '8263820224': 0, '8263820227': 0, '8263820228': 0, '826382023': 0, '8263820231': 0, '8263820233': 0, '8263820234': 0, '8263820235': 0, '8263820237': 0, '8263820239': 0, '826382024': 1, '8263820240': 0, '8263820242': 0, '8263820243': 0, '8263820245': 0, '8263820246': 0, '8263820247': 0, '8263820251': 0, '8263820253': 0, '8263820254': 0, '8263820255': 0, '8263820256': 0, '8263820257': 0, '8263820259': 0, '826382026': 0, '8263820260': 0, '8263820264': 0, '8263820265': 0, '8263820266': 0, '8263820268': 0, '8263820269': 0, '826382027': 0, '8263820272': 0, '8263820273': 0, '8263820275': 0, '8263820277': 0, '8263820278': 0, '8263820279': 0, '826382028': 0, '826412010': 0, '8264120110': 0, '8264120111': 0, '8264120112': 0, '8264120113': 0, '8264120116': 1, '8264120117': 0, '8264120119': 0, '8264120120': 1, '8264120121': 0, '8264120122': 0, '8264120123': 1, '8264120124': 0, '8264120125': 0, '8264120126': 0, '8264120127': 1, '826412013': 1, '8264120131': 0, '8264120132': 0, '8264120136': 0, '8264120139': 0, '8264120141': 0, '8264120144': 0, '8264120145': 0, '8264120146': 0, '8264120149': 0, '8264120150': 1, '8264120156': 1, '8264120157': 0, '8264120159': 0, '8264120165': 0, '8264120166': 0, '8264120169': 1, '826412017': 0, '826412018': 0, '826412019': 0, '8264120210': 0, '8264120211': 1, '8264120213': 0, '8264120215': 0, '8264120216': 0, '8264120218': 0, '8264120219': 0, '8264120220': 0, '8264120221': 0, '8264120223': 0, '8264120224': 0, '8264120227': 0, '8264120228': 0, '8264120229': 0, '826412023': 0, '8264120231': 1, '8264120232': 0, '8264120233': 0, '8264120234': 0, '8264120239': 1, '826412024': 0, '8264120240': 1, '8264120241': 0, '8264120242': 0, '8264120243': 1, '8264120245': 0, '8264120247': 0, '8264120248': 0, '8264120249': 1, '826412025': 0, '8264120254': 1, '8264120256': 1, '8264120257': 0, '8264120258': 0, '8264120261': 1, '8264120262': 1, '8264120263': 1, '8264120265': 1, '8264120266': 1, '8264120268': 0, '8264120269': 1, '826412027': 0, '8264120274': 0, '8264120275': 0, '8264120279': 1, '8264120280': 0, '8264120282': 1, '8264120284': 1, '88265401100': 0, '88265401130': 0, '88265401140': 0, '88265401150': 0, '88265401160': 0, '88265401170': 0, '88265401190': 0, '8826540120': 0, '88265401200': 0, '88265401240': 0, '88265401260': 0, '88265401270': 0, '88265401280': 0, '88265401300': 0, '88265401320': 0, '88265401350': 0, '88265401360': 0, '88265401380': 0, '88265401390': 0, '88265401400': 0, '88265401410': 0, '88265401420': 0, '88265401430': 0, '88265401450': 0, '88265401470': 0, '88265401480': 0, '88265401490': 0, '8826540150': 0, '88265401520': 0, '88265401550': 0, '88265401630': 0, '88265401640': 0, '88265401660': 0, '88265401690': 0, '8826540170': 0, '88265401730': 0, '88265401740': 0, '88265401750': 1, '8826540180': 0, '88265402120': 0, '88265402150': 0, '88265402160': 0, '88265402170': 0, '88265402180': 0, '88265402190': 0, '88265402200': 0, '88265402230': 0, '88265402240': 0, '88265402270': 0, '8826540230': 0, '88265402300': 0, '88265402310': 0, '88265402320': 0, '88265402330': 0, '88265402340': 0, '88265402350': 0, '88265402370': 0, '88265402380': 0, '8826540240': 0, '88265402400': 0, '88265402420': 0, '88265402440': 0, '88265402450': 0, '88265402480': 0, '88265402490': 0, '88265402500': 0, '88265402520': 0, '88265402540': 0, '88265402570': 0, '88265402580': 0, '88265402590': 0, '8826540260': 0, '88265402600': 0, '88265402630': 0, '88265402660': 0, '88265402690': 0, '8826540270': 0, '88265402700': 0, '88265402770': 0, '88265402780': 0, '88265402790': 0, '8826540280': 0, '88265402800': 0, '88265402810': 0, '88265402820': 0, '88265402840': 0, '88265402850': 0, '88265402880': 0, '88265402890': 0, '8826540290': 0, '88265402900': 0, '907001100': 0, '9070011010': 0, '9070011020': 0, '9070011060': 0, '9070011090': 0, '907001110': 0, '9070011110': 0, '907001120': 0, '907001150': 0, '907001160': 0, '907001170': 0, '907001180': 0, '907001210': 0, '907001220': 0, '907001240': 0, '907001270': 0, '907001280': 0, '907001310': 0, '907001340': 0, '907001350': 0, '907001360': 0, '907001370': 0, '907001400': 0, '907001430': 0, '907001450': 0, '907001480': 1, '907001490': 0, '90700150': 0, '907001500': 0, '907001520': 0, '907001550': 0, '907001560': 0, '907001570': 0, '907001580': 0, '90700160': 0, '907001600': 0, '907001620': 0, '907001650': 0, '907001670': 0, '907001680': 0, '90700170': 0, '907001730': 0, '907001740': 0, '907001780': 0, '907001790': 0, '90700180': 0, '907001820': 0, '907001840': 0, '907001850': 0, '907001860': 0, '90700190': 0, '907001910': 0, '907001940': 0, '907001950': 1, '907001970': 0, '9289010111': 0, '9289010112': 0, '9289010113': 0, '9289010114': 1, '9289010115': 0, '9289010117': 0, '9289010118': 0, '9289010119': 0, '9289010120': 0, '9289010121': 0, '9289010127': 0, '928901013': 0, '9289010131': 0, '9289010132': 0, '9289010133': 0, '9289010134': 0, '9289010138': 0, '9289010139': 0, '928901014': 1, '9289010143': 0, '9289010144': 0, '9289010145': 1, '9289010147': 0, '9289010149': 0, '9289010150': 0, '9289010151': 0, '9289010152': 1, '9289010153': 0, '9289010154': 0, '9289010155': 0, '9289010157': 0, '9289010158': 0, '928901016': 0, '9289010160': 0, '9289010161': 0, '9289010163': 0, '9289010166': 0, '9289010167': 0, '928901018': 0, '9289010210': 0, '9289010211': 0, '9289010216': 0, '9289010221': 0, '9289010222': 0, '9289010223': 0, '9289010227': 0, '9289010229': 0, '928901023': 0, '9289010230': 0, '9289010231': 0, '9289010232': 0, '9289010233': 0, '9289010235': 0, '9289010242': 0, '9289010243': 0, '9289010244': 0, '9289010245': 0, '9289010248': 0, '9289010249': 0, '928901025': 0, '9289010250': 0, '9289010251': 0, '9289010253': 0, '9289010254': 0, '9289010257': 0, '9289010259': 0, '928901026': 0, '9289010261': 0, '9289010262': 0, '9289010263': 0, '9289010265': 0, '9289010266': 0, '9289010267': 0, '9289010268': 0, '9289010269': 0, '9289010270': 0, '9289010271': 0, '9289010273': 0, '9289010274': 0, '9289010275': 0, '9289010276': 1, '9289010278': 0, '928901028': 0, '928901029': 0, '940328011': 0, '9403280110': 0, '9403280112': 0, '9403280114': 0, '9403280115': 0, '9403280116': 0, '9403280117': 0, '940328012': 0, '9403280126': 0, '9403280129': 0, '9403280132': 0, '9403280134': 0, '9403280136': 0, '9403280138': 0, '940328014': 0, '9403280140': 0, '9403280143': 0, '9403280145': 0, '9403280146': 0, '9403280147': 0, '9403280149': 0, '9403280150': 0, '9403280151': 0, '9403280152': 0, '9403280155': 0, '9403280156': 0, '9403280157': 0, '9403280159': 0, '940328016': 0, '9403280164': 0, '9403280165': 0, '9403280167': 0, '940328017': 0, '940328018': 0, '9403280212': 0, '9403280213': 0, '9403280217': 0, '9403280218': 0, '9403280219': 0, '940328022': 0, '9403280227': 0, '9403280229': 0, '9403280234': 0, '9403280235': 0, '9403280236': 0, '9403280238': 0, '9403280241': 0, '9403280243': 0, '9403280245': 0, '9403280246': 0, '9403280247': 0, '9403280249': 0, '9403280250': 0, '9403280251': 0, '9403280254': 0, '9403280255': 0, '9403280256': 0, '9403280259': 0, '9403280260': 0, '9403280262': 0, '9403280265': 0, '9403280266': 0, '9403280271': 1, '9403280272': 0, '9403280273': 0, '9403280277': 0, '9403280279': 0, '9877360111': 0, '9877360113': 0, '9877360114': 0, '9877360115': 0, '9877360116': 0, '9877360117': 0, '9877360120': 1, '9877360121': 0, '9877360124': 0, '9877360125': 0, '9877360126': 0, '9877360127': 0, '9877360128': 0, '9877360130': 0, '9877360131': 0, '9877360132': 0, '9877360133': 1, '9877360134': 0, '9877360135': 0, '9877360138': 0, '987736014': 0, '9877360140': 0, '9877360141': 0, '9877360143': 0, '9877360147': 0, '9877360149': 0, '987736015': 0, '9877360151': 0, '9877360152': 0, '9877360154': 0, '9877360156': 0, '9877360157': 1, '9877360158': 0, '9877360159': 0, '987736016': 0, '9877360163': 0, '9877360164': 0, '9877360165': 0, '9877360166': 0, '9877360168': 0, '9877360169': 1}\n"
     ]
    }
   ],
   "source": [
    "ENGAGE_WILD_DATASET, BIN_CLASSIFICATION, N_CLASSES, DATASET_NAME, BASE_DATASET_DIR, ext = define_dataset(False, True)\n",
    "video2label, labels_list = get_video2label()\n",
    "print(labels_list)\n",
    "print(video2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42ac9a4-a89c-48a7-8096-bf42e312148c",
   "metadata": {},
   "source": [
    "### Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14622b53-fc0b-4e30-b764-af50e15c19a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.std\n",
    "stat_name = \"std\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce0a97-54a5-40f6-94a1-97dffb170341",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02c15e10-164d-4c4a-bd81-014d3094da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "121670c9-c7c3-4dd3-a953-a30af17b2667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8611cc2-edbb-4da2-b4a1-bc73618396f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "test:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n",
      "val:\n",
      "0 1537/1720: 89.36046511627907%\n",
      "1 183/1720: 10.63953488372093%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915f6397-44e0-4c9a-b63b-d3cec456d9f8",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13240206-257d-4299-ab33-9ea8f3ee2cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3940412-4ce6-47e4-85da-82bb77a7e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76a7c6b8-349b-46e2-8963-6d92d9987484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2048) (5482,)\n",
      "(1723, 128, 2048) (1723,)\n",
      "(1720, 128, 2048) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ba3a00c-27a4-4ebd-aa67-1dc818c91e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5234  248] {0: 1.0, 1: 21.10483870967742} 2 [0 1]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1172b3c1-2d22-4dbc-9ff7-df0ddb0a2c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 21:37:55.974305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38431 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:11:00.0, compute capability: 8.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "#save_best_model = SaveBestModelByUAR(X_subsample_val, y_subsample_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e737e006-f668-4ece-ab81-231e2f69c2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 21:38:03.987877: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f85c00bc310 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-11 21:38:03.988038: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-08-11 21:38:03.992173: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-11 21:38:04.039536: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-08-11 21:38:04.091079: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 6s 82ms/step - loss: 1.2558 - acc: 0.6410 - auc: 0.6688 - binary_accuracy: 0.6410 - recall: 0.6129 - precision: 0.0751 - val_loss: 0.7303 - val_acc: 0.5930 - val_auc: 0.6772 - val_binary_accuracy: 0.5930 - val_recall: 0.6721 - val_precision: 0.1612\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 1.1178 - acc: 0.7162 - auc: 0.7648 - binary_accuracy: 0.7162 - recall: 0.7016 - precision: 0.1051 - val_loss: 0.5479 - val_acc: 0.7320 - val_auc: 0.6853 - val_binary_accuracy: 0.7320 - val_recall: 0.4809 - val_precision: 0.1938\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 1.0737 - acc: 0.7324 - auc: 0.7823 - binary_accuracy: 0.7324 - recall: 0.6935 - precision: 0.1100 - val_loss: 1.0138 - val_acc: 0.3331 - val_auc: 0.7081 - val_binary_accuracy: 0.3331 - val_recall: 0.9344 - val_precision: 0.1309\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 1.0101 - acc: 0.7499 - auc: 0.8130 - binary_accuracy: 0.7499 - recall: 0.7339 - precision: 0.1224 - val_loss: 0.5729 - val_acc: 0.7209 - val_auc: 0.6807 - val_binary_accuracy: 0.7209 - val_recall: 0.5137 - val_precision: 0.1938\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.9699 - acc: 0.7599 - auc: 0.8304 - binary_accuracy: 0.7599 - recall: 0.7379 - precision: 0.1276 - val_loss: 1.0560 - val_acc: 0.4256 - val_auc: 0.6959 - val_binary_accuracy: 0.4256 - val_recall: 0.8525 - val_precision: 0.1397\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.9568 - acc: 0.7725 - auc: 0.8347 - binary_accuracy: 0.7725 - recall: 0.7218 - precision: 0.1319 - val_loss: 0.6449 - val_acc: 0.6657 - val_auc: 0.6946 - val_binary_accuracy: 0.6657 - val_recall: 0.5956 - val_precision: 0.1787\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 1.0152 - acc: 0.7291 - auc: 0.8103 - binary_accuracy: 0.7291 - recall: 0.6976 - precision: 0.1093 - val_loss: 0.6053 - val_acc: 0.6936 - val_auc: 0.6938 - val_binary_accuracy: 0.6936 - val_recall: 0.5683 - val_precision: 0.1884\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.8962 - acc: 0.7889 - auc: 0.8599 - binary_accuracy: 0.7889 - recall: 0.7903 - precision: 0.1507 - val_loss: 0.6398 - val_acc: 0.6744 - val_auc: 0.6918 - val_binary_accuracy: 0.6744 - val_recall: 0.5902 - val_precision: 0.1821\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.8897 - acc: 0.7822 - auc: 0.8617 - binary_accuracy: 0.7822 - recall: 0.7984 - precision: 0.1475 - val_loss: 0.5882 - val_acc: 0.7029 - val_auc: 0.6866 - val_binary_accuracy: 0.7029 - val_recall: 0.5355 - val_precision: 0.1870\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.8401 - acc: 0.8057 - auc: 0.8789 - binary_accuracy: 0.8057 - recall: 0.8065 - precision: 0.1643 - val_loss: 0.6871 - val_acc: 0.6488 - val_auc: 0.6862 - val_binary_accuracy: 0.6488 - val_recall: 0.5956 - val_precision: 0.1706\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.8499 - acc: 0.7948 - auc: 0.8737 - binary_accuracy: 0.7948 - recall: 0.8024 - precision: 0.1561 - val_loss: 0.5901 - val_acc: 0.7064 - val_auc: 0.6880 - val_binary_accuracy: 0.7064 - val_recall: 0.5301 - val_precision: 0.1880\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.8173 - acc: 0.8008 - auc: 0.8848 - binary_accuracy: 0.8008 - recall: 0.7823 - precision: 0.1575 - val_loss: 0.5738 - val_acc: 0.7105 - val_auc: 0.6753 - val_binary_accuracy: 0.7105 - val_recall: 0.4809 - val_precision: 0.1792\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.7858 - acc: 0.8026 - auc: 0.8953 - binary_accuracy: 0.8026 - recall: 0.8306 - precision: 0.1653 - val_loss: 0.4555 - val_acc: 0.7936 - val_auc: 0.6689 - val_binary_accuracy: 0.7936 - val_recall: 0.3169 - val_precision: 0.2014\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.7958 - acc: 0.8004 - auc: 0.8897 - binary_accuracy: 0.8004 - recall: 0.8185 - precision: 0.1621 - val_loss: 0.5329 - val_acc: 0.7488 - val_auc: 0.6775 - val_binary_accuracy: 0.7488 - val_recall: 0.4481 - val_precision: 0.1985\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.7371 - acc: 0.8254 - auc: 0.9085 - binary_accuracy: 0.8254 - recall: 0.8105 - precision: 0.1809 - val_loss: 0.5118 - val_acc: 0.7703 - val_auc: 0.6748 - val_binary_accuracy: 0.7703 - val_recall: 0.4372 - val_precision: 0.2151\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.8089 - acc: 0.7924 - auc: 0.8864 - binary_accuracy: 0.7924 - recall: 0.8065 - precision: 0.1550 - val_loss: 0.8754 - val_acc: 0.5576 - val_auc: 0.6735 - val_binary_accuracy: 0.5576 - val_recall: 0.7268 - val_precision: 0.1576\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.7261 - acc: 0.8351 - auc: 0.9124 - binary_accuracy: 0.8351 - recall: 0.8266 - precision: 0.1923 - val_loss: 0.5762 - val_acc: 0.7233 - val_auc: 0.6646 - val_binary_accuracy: 0.7233 - val_recall: 0.4699 - val_precision: 0.1849\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.6852 - acc: 0.8243 - auc: 0.9214 - binary_accuracy: 0.8243 - recall: 0.8750 - precision: 0.1889 - val_loss: 0.6538 - val_acc: 0.7017 - val_auc: 0.6752 - val_binary_accuracy: 0.7017 - val_recall: 0.5137 - val_precision: 0.1815\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.6850 - acc: 0.8329 - auc: 0.9208 - binary_accuracy: 0.8329 - recall: 0.8589 - precision: 0.1947 - val_loss: 0.5395 - val_acc: 0.7471 - val_auc: 0.6632 - val_binary_accuracy: 0.7471 - val_recall: 0.3989 - val_precision: 0.1834\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 24ms/step - loss: 0.6602 - acc: 0.8325 - auc: 0.9270 - binary_accuracy: 0.8325 - recall: 0.8589 - precision: 0.1943 - val_loss: 0.5284 - val_acc: 0.7558 - val_auc: 0.6617 - val_binary_accuracy: 0.7558 - val_recall: 0.4044 - val_precision: 0.1922\n",
      "0.4554593563079834\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97147488-a7a1-489b-8804-f617bee0b21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3108480/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fada5053-da93-49b9-a02c-6afb6497623c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional Accuracy:  0.3087637840975044 MSE:  0.6912362159024956 UAR:  0.552790346907994 Recall:  0.8235294117647058 Precision:  0.056179775280898875 F1:  0.10518407212622088\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional Accuracy:  0.4341265235055136 MSE:  0.5658734764944864 UAR:  0.5573762838468721 Recall:  0.6941176470588235 Precision:  0.05853174603174603 F1:  0.10795974382433669\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional Accuracy:  0.5536854323853744 MSE:  0.4463145676146257 UAR:  0.5756410256410256 Recall:  0.6 Precision:  0.0648854961832061 F1:  0.11710677382319173\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional Accuracy:  0.6604759141033082 MSE:  0.3395240858966918 UAR:  0.6318070818070818 Recall:  0.6 Precision:  0.08471760797342193 F1:  0.14847161572052403\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional Accuracy:  0.7521764364480558 MSE:  0.2478235635519443 UAR:  0.6521511168569991 Recall:  0.5411764705882353 Precision:  0.10599078341013825 F1:  0.1772639691714836\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional Accuracy:  0.8229831688914684 MSE:  0.17701683110853164 UAR:  0.6615061409179056 Recall:  0.4823529411764706 Precision:  0.1357615894039735 F1:  0.21188630490956076\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional Accuracy:  0.8786999419616948 MSE:  0.12130005803830528 UAR:  0.6406162464985994 Recall:  0.3764705882352941 Precision:  0.1702127659574468 F1:  0.2344322344322344\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional Accuracy:  0.9158444573418456 MSE:  0.08415554265815438 UAR:  0.6211125475831358 Recall:  0.29411764705882354 Precision:  0.22727272727272727 F1:  0.25641025641025644\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional Accuracy:  0.93905977945444 MSE:  0.06094022054556007 UAR:  0.5552431228901817 Recall:  0.12941176470588237 Precision:  0.2619047619047619 F1:  0.1732283464566929\n",
      "0.6 0.6615061409179056\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name, from_int=True)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb09ed35-8ade-4fcd-910a-c10b6e10dcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "825be502-acd1-4912-a9a1-0050502228de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3108480/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a14f0c04-ecbb-4bfc-9f14-3d30fb50cd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.3064422518862449 MSE:  0.693557748113755 UAR:  0.5794548588666235 Recall:  0.8823529411764706 Precision:  0.05952380952380952 F1:  0.11152416356877322\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.4904236796285548 MSE:  0.5095763203714452 UAR:  0.598139768728004 Recall:  0.7176470588235294 Precision:  0.06666666666666667 F1:  0.122\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.632617527568195 MSE:  0.367382472431805 UAR:  0.5948466566113625 Recall:  0.5529411764705883 Precision:  0.07320872274143302 F1:  0.1292984869325997\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.7544979686593152 MSE:  0.24550203134068485 UAR:  0.6422179128061482 Recall:  0.5176470588235295 Precision:  0.10328638497652583 F1:  0.1722113502935421\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.8334300638421358 MSE:  0.1665699361578642 UAR:  0.6446922358687064 Recall:  0.43529411764705883 Precision:  0.13405797101449277 F1:  0.20498614958448755\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.8786999419616948 MSE:  0.12130005803830528 UAR:  0.6350391438626732 Recall:  0.36470588235294116 Precision:  0.16666666666666666 F1:  0.2287822878228782\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.91874637260592 MSE:  0.0812536273940801 UAR:  0.6226387991093874 Recall:  0.29411764705882354 Precision:  0.23809523809523808 F1:  0.2631578947368421\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.942542077771329 MSE:  0.057457922228670924 UAR:  0.5682288299935359 Recall:  0.15294117647058825 Precision:  0.325 F1:  0.20800000000000002\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_traditional_best Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5508044243338361 Recall:  0.10588235294117647 Precision:  0.5625 F1:  0.1782178217821782\n",
      "0.5 0.6446922358687064\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name, from_int=True)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b65aa-df20-4fac-8f5b-5425a764686d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e87e80c2-a7fc-4d09-81de-0775224bcd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_2_std_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ceb1c479-254e-4055-86e1-668603a28d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ef2df500-36b7-43f5-a8a3-c3d79833cae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b551a687-a94f-496f-937c-78ad2c657f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_6 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_6[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_6[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7efd9905-6815-4c53-af5a-16ce7e239c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 127ms/step - loss: 0.3520 - acc: 0.9435 - auc: 0.5372 - binary_accuracy: 0.9435 - recall_1: 0.0121 - precision_1: 0.0441 - val_loss: 0.3655 - val_acc: 0.8936 - val_auc: 0.6054 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1676 - acc: 0.9544 - auc: 0.7332 - binary_accuracy: 0.9544 - recall_1: 0.0081 - precision_1: 0.3333 - val_loss: 0.4156 - val_acc: 0.8936 - val_auc: 0.6291 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1589 - acc: 0.9533 - auc: 0.7800 - binary_accuracy: 0.9533 - recall_1: 0.0081 - precision_1: 0.1667 - val_loss: 0.3692 - val_acc: 0.8907 - val_auc: 0.6405 - val_binary_accuracy: 0.8907 - val_recall_1: 0.0328 - val_precision_1: 0.3529\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1570 - acc: 0.9538 - auc: 0.7916 - binary_accuracy: 0.9538 - recall_1: 0.0282 - precision_1: 0.3684 - val_loss: 0.4193 - val_acc: 0.8930 - val_auc: 0.6368 - val_binary_accuracy: 0.8930 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1648 - acc: 0.9526 - auc: 0.7644 - binary_accuracy: 0.9526 - recall_1: 0.0403 - precision_1: 0.3125 - val_loss: 0.3956 - val_acc: 0.8936 - val_auc: 0.6295 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1544 - acc: 0.9557 - auc: 0.8021 - binary_accuracy: 0.9557 - recall_1: 0.0524 - precision_1: 0.6190 - val_loss: 0.3884 - val_acc: 0.8942 - val_auc: 0.6372 - val_binary_accuracy: 0.8942 - val_recall_1: 0.0164 - val_precision_1: 0.6000\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1498 - acc: 0.9564 - auc: 0.8126 - binary_accuracy: 0.9564 - recall_1: 0.0726 - precision_1: 0.6667 - val_loss: 0.4350 - val_acc: 0.8936 - val_auc: 0.6258 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1505 - acc: 0.9562 - auc: 0.7941 - binary_accuracy: 0.9562 - recall_1: 0.0927 - precision_1: 0.6053 - val_loss: 0.4107 - val_acc: 0.8936 - val_auc: 0.6443 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1529 - acc: 0.9529 - auc: 0.8132 - binary_accuracy: 0.9529 - recall_1: 0.0565 - precision_1: 0.3684 - val_loss: 0.3560 - val_acc: 0.8901 - val_auc: 0.6600 - val_binary_accuracy: 0.8901 - val_recall_1: 0.0328 - val_precision_1: 0.3333\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1611 - acc: 0.9544 - auc: 0.7951 - binary_accuracy: 0.9544 - recall_1: 0.0766 - precision_1: 0.4750 - val_loss: 0.3404 - val_acc: 0.8919 - val_auc: 0.6709 - val_binary_accuracy: 0.8919 - val_recall_1: 0.0164 - val_precision_1: 0.3333\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1480 - acc: 0.9551 - auc: 0.8080 - binary_accuracy: 0.9551 - recall_1: 0.0645 - precision_1: 0.5333 - val_loss: 0.3748 - val_acc: 0.8791 - val_auc: 0.6659 - val_binary_accuracy: 0.8791 - val_recall_1: 0.0546 - val_precision_1: 0.2222\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1393 - acc: 0.9577 - auc: 0.8477 - binary_accuracy: 0.9577 - recall_1: 0.1169 - precision_1: 0.6905 - val_loss: 0.4060 - val_acc: 0.8843 - val_auc: 0.6437 - val_binary_accuracy: 0.8843 - val_recall_1: 0.0328 - val_precision_1: 0.2143\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1391 - acc: 0.9584 - auc: 0.8543 - binary_accuracy: 0.9584 - recall_1: 0.1694 - precision_1: 0.6562 - val_loss: 0.4013 - val_acc: 0.8913 - val_auc: 0.6270 - val_binary_accuracy: 0.8913 - val_recall_1: 0.0055 - val_precision_1: 0.1667\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1430 - acc: 0.9564 - auc: 0.8307 - binary_accuracy: 0.9564 - recall_1: 0.1250 - precision_1: 0.5849 - val_loss: 0.4422 - val_acc: 0.8936 - val_auc: 0.6349 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0164 - val_precision_1: 0.5000\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1403 - acc: 0.9593 - auc: 0.8408 - binary_accuracy: 0.9593 - recall_1: 0.1532 - precision_1: 0.7451 - val_loss: 0.3936 - val_acc: 0.8860 - val_auc: 0.6520 - val_binary_accuracy: 0.8860 - val_recall_1: 0.0273 - val_precision_1: 0.2174\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1331 - acc: 0.9599 - auc: 0.8623 - binary_accuracy: 0.9599 - recall_1: 0.1815 - precision_1: 0.7258 - val_loss: 0.4326 - val_acc: 0.8890 - val_auc: 0.6155 - val_binary_accuracy: 0.8890 - val_recall_1: 0.0109 - val_precision_1: 0.1667\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1567 - acc: 0.9579 - auc: 0.8211 - binary_accuracy: 0.9579 - recall_1: 0.1855 - precision_1: 0.6133 - val_loss: 0.6409 - val_acc: 0.8901 - val_auc: 0.5315 - val_binary_accuracy: 0.8901 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1939 - acc: 0.9513 - auc: 0.7187 - binary_accuracy: 0.9513 - recall_1: 0.0927 - precision_1: 0.3538 - val_loss: 0.4528 - val_acc: 0.8924 - val_auc: 0.6278 - val_binary_accuracy: 0.8924 - val_recall_1: 0.0109 - val_precision_1: 0.3333\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1382 - acc: 0.9582 - auc: 0.8531 - binary_accuracy: 0.9582 - recall_1: 0.1532 - precision_1: 0.6667 - val_loss: 0.4255 - val_acc: 0.8831 - val_auc: 0.6076 - val_binary_accuracy: 0.8831 - val_recall_1: 0.0328 - val_precision_1: 0.2000\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1471 - acc: 0.9573 - auc: 0.8318 - binary_accuracy: 0.9573 - recall_1: 0.1653 - precision_1: 0.6029 - val_loss: 0.3628 - val_acc: 0.8831 - val_auc: 0.6370 - val_binary_accuracy: 0.8831 - val_recall_1: 0.0273 - val_precision_1: 0.1786\n",
      "0.340364933013916\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "102b4c65-3554-4ab1-b618-ab301b9dd710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c64ca2a7-8010-423c-aa37-6400fcaa8956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.8415554265815438 MSE:  0.1584445734184562 UAR:  0.6043489190548015 Recall:  0.3411764705882353 Precision:  0.11788617886178862 F1:  0.17522658610271902\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.930354033662217 MSE:  0.06964596633778293 UAR:  0.5450872656755009 Recall:  0.11764705882352941 Precision:  0.18181818181818182 F1:  0.14285714285714285\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9437028438769588 MSE:  0.05629715612304121 UAR:  0.5409538174244057 Recall:  0.09411764705882353 Precision:  0.2857142857142857 F1:  0.1415929203539823\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.947185142193848 MSE:  0.05281485780615206 UAR:  0.526054011348129 Recall:  0.058823529411764705 Precision:  0.3125 F1:  0.09900990099009901\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5281907634848811 Recall:  0.058823529411764705 Precision:  0.5555555555555556 F1:  0.10638297872340426\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5229189111542053 Recall:  0.047058823529411764 Precision:  0.6666666666666666 F1:  0.08791208791208792\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9529889727219966 MSE:  0.047011027278003485 UAR:  0.5235294117647059 Recall:  0.047058823529411764 Precision:  1.0 F1:  0.0898876404494382\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5176470588235295 Recall:  0.03529411764705882 Precision:  1.0 F1:  0.06818181818181818\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5117647058823529 Recall:  0.023529411764705882 Precision:  1.0 F1:  0.04597701149425288\n",
      "0.1 0.6043489190548015\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "4ee5e2e4-3ab5-48a6-93a5-4882e3bf2cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "4e1fcb9c-ac0a-42c7-9d13-17f28f9be349",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a246499a-1a8e-41ae-b734-825eeef3a08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.8340104468949506 MSE:  0.16598955310504934 UAR:  0.6282661782661783 Recall:  0.4 Precision:  0.12639405204460966 F1:  0.192090395480226\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9297736506094022 MSE:  0.0702263493905978 UAR:  0.5949759390935861 Recall:  0.2235294117647059 Precision:  0.25675675675675674 F1:  0.2389937106918239\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9477655252466628 MSE:  0.0522344747533372 UAR:  0.5653989801048624 Recall:  0.1411764705882353 Precision:  0.41379310344827586 F1:  0.21052631578947367\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5566867772750126 Recall:  0.11764705882352941 Precision:  0.5882352941176471 F1:  0.19607843137254902\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9529889727219966 MSE:  0.047011027278003485 UAR:  0.5402607196724843 Recall:  0.08235294117647059 Precision:  0.7 F1:  0.14736842105263157\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5288012640953818 Recall:  0.058823529411764705 Precision:  0.7142857142857143 F1:  0.10869565217391305\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9500870574579222 MSE:  0.04991294254207777 UAR:  0.5052718523306758 Recall:  0.011764705882352941 Precision:  0.3333333333333333 F1:  0.022727272727272728\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5058823529411764 Recall:  0.011764705882352941 Precision:  1.0 F1:  0.023255813953488372\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6282661782661783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd31cb75-4f34-46dc-8222-871a7966e072",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e75b174-fc62-4f63-80d5-3d6d0dc1657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5bb4eedb-0df9-472a-b853-ca247b69d4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65777728-1828-454c-b555-df389e6352d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "val:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87acfa6b-9061-41af-be13-af5c8a74253e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482,) (5482,)\n",
      "(1723,) (1723,)\n",
      "(7205,) (7205,)\n",
      "[0 1] [6872  333]\n",
      "7205\n",
      "5475\n",
      "1730\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "49cedd32-1daf-4f53-a198-0c6f0e5e140a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5222/5475: 95.37899543378995%\n",
      "1 253/5475: 4.621004566210046%\n",
      "val:\n",
      "0 1650/1730: 95.3757225433526%\n",
      "1 80/1730: 4.624277456647399%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785a4f32-ac4f-43c0-8a77-59bdc5a1712b",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f52ba75e-475a-47f8-9319-8daa2a026534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "51dba86d-0b7c-4a17-9d19-42ce28faa5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "497c4121-343f-446a-a45f-f4a5740486fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 2048) (5475,)\n",
      "(1730, 128, 2048) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c17e604c-f084-42d7-832e-7382ba72aa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5222  253] {0: 1.0, 1: 20.640316205533598} 2 [0 1]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3233abc9-3d3f-4cbd-b4b2-9861899f11be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "#save_best_model = SaveBestModelByUAR(X_subsample_test, y_subsample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d2008087-280c-4b93-aad5-39ad19cd8e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 4s 62ms/step - loss: 1.2829 - acc: 0.6261 - auc: 0.6488 - binary_accuracy: 0.6261 - recall_1: 0.5850 - precision_1: 0.0708 - val_loss: 0.4208 - val_acc: 0.9000 - val_auc: 0.7464 - val_binary_accuracy: 0.9000 - val_recall_1: 0.3625 - val_precision_1: 0.1921\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 1.1081 - acc: 0.7257 - auc: 0.7643 - binary_accuracy: 0.7257 - recall_1: 0.6798 - precision_1: 0.1080 - val_loss: 0.6158 - val_acc: 0.6919 - val_auc: 0.7683 - val_binary_accuracy: 0.6919 - val_recall_1: 0.7125 - val_precision_1: 0.1005\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 1.0464 - acc: 0.7711 - auc: 0.7955 - binary_accuracy: 0.7711 - recall_1: 0.6759 - precision_1: 0.1274 - val_loss: 0.6546 - val_acc: 0.6405 - val_auc: 0.7692 - val_binary_accuracy: 0.6405 - val_recall_1: 0.7625 - val_precision_1: 0.0919\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 1.0078 - acc: 0.7459 - auc: 0.8137 - binary_accuracy: 0.7459 - recall_1: 0.7273 - precision_1: 0.1222 - val_loss: 0.7374 - val_acc: 0.5740 - val_auc: 0.7748 - val_binary_accuracy: 0.5740 - val_recall_1: 0.7750 - val_precision_1: 0.0794\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.9790 - acc: 0.7668 - auc: 0.8266 - binary_accuracy: 0.7668 - recall_1: 0.7312 - precision_1: 0.1327 - val_loss: 0.4779 - val_acc: 0.7948 - val_auc: 0.7717 - val_binary_accuracy: 0.7948 - val_recall_1: 0.6250 - val_precision_1: 0.1333\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.9176 - acc: 0.7713 - auc: 0.8519 - binary_accuracy: 0.7713 - recall_1: 0.7708 - precision_1: 0.1404 - val_loss: 0.6509 - val_acc: 0.6480 - val_auc: 0.7766 - val_binary_accuracy: 0.6480 - val_recall_1: 0.7625 - val_precision_1: 0.0937\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.8817 - acc: 0.7874 - auc: 0.8652 - binary_accuracy: 0.7874 - recall_1: 0.7826 - precision_1: 0.1515 - val_loss: 0.5834 - val_acc: 0.6925 - val_auc: 0.7688 - val_binary_accuracy: 0.6925 - val_recall_1: 0.7250 - val_precision_1: 0.1021\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.8827 - acc: 0.7757 - auc: 0.8639 - binary_accuracy: 0.7757 - recall_1: 0.8024 - precision_1: 0.1470 - val_loss: 0.3511 - val_acc: 0.8740 - val_auc: 0.7562 - val_binary_accuracy: 0.8740 - val_recall_1: 0.5375 - val_precision_1: 0.1920\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.8627 - acc: 0.7921 - auc: 0.8686 - binary_accuracy: 0.7921 - recall_1: 0.7549 - precision_1: 0.1507 - val_loss: 0.4640 - val_acc: 0.7827 - val_auc: 0.7677 - val_binary_accuracy: 0.7827 - val_recall_1: 0.6250 - val_precision_1: 0.1263\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.8602 - acc: 0.7929 - auc: 0.8698 - binary_accuracy: 0.7929 - recall_1: 0.7866 - precision_1: 0.1556 - val_loss: 0.3542 - val_acc: 0.8636 - val_auc: 0.7702 - val_binary_accuracy: 0.8636 - val_recall_1: 0.5500 - val_precision_1: 0.1803\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.8240 - acc: 0.7786 - auc: 0.8829 - binary_accuracy: 0.7786 - recall_1: 0.8182 - precision_1: 0.1508 - val_loss: 0.3877 - val_acc: 0.8364 - val_auc: 0.7623 - val_binary_accuracy: 0.8364 - val_recall_1: 0.5750 - val_precision_1: 0.1559\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.7743 - acc: 0.8115 - auc: 0.8971 - binary_accuracy: 0.8115 - recall_1: 0.8103 - precision_1: 0.1724 - val_loss: 0.4497 - val_acc: 0.7902 - val_auc: 0.7720 - val_binary_accuracy: 0.7902 - val_recall_1: 0.6500 - val_precision_1: 0.1344\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.7630 - acc: 0.8040 - auc: 0.8997 - binary_accuracy: 0.8040 - recall_1: 0.8379 - precision_1: 0.1704 - val_loss: 0.3647 - val_acc: 0.8434 - val_auc: 0.7670 - val_binary_accuracy: 0.8434 - val_recall_1: 0.5750 - val_precision_1: 0.1625\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.7182 - acc: 0.8236 - auc: 0.9126 - binary_accuracy: 0.8236 - recall_1: 0.8379 - precision_1: 0.1865 - val_loss: 0.7082 - val_acc: 0.6526 - val_auc: 0.7660 - val_binary_accuracy: 0.6526 - val_recall_1: 0.7500 - val_precision_1: 0.0936\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.7413 - acc: 0.8066 - auc: 0.9042 - binary_accuracy: 0.8066 - recall_1: 0.8340 - precision_1: 0.1718 - val_loss: 0.4125 - val_acc: 0.8150 - val_auc: 0.7584 - val_binary_accuracy: 0.8150 - val_recall_1: 0.5750 - val_precision_1: 0.1386\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.6925 - acc: 0.8234 - auc: 0.9180 - binary_accuracy: 0.8234 - recall_1: 0.8538 - precision_1: 0.1885 - val_loss: 0.8447 - val_acc: 0.5838 - val_auc: 0.7655 - val_binary_accuracy: 0.5838 - val_recall_1: 0.8000 - val_precision_1: 0.0833\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.6900 - acc: 0.8232 - auc: 0.9182 - binary_accuracy: 0.8232 - recall_1: 0.8656 - precision_1: 0.1899 - val_loss: 0.4744 - val_acc: 0.7792 - val_auc: 0.7434 - val_binary_accuracy: 0.7792 - val_recall_1: 0.6125 - val_precision_1: 0.1225\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.6715 - acc: 0.8239 - auc: 0.9225 - binary_accuracy: 0.8239 - recall_1: 0.8577 - precision_1: 0.1895 - val_loss: 0.5982 - val_acc: 0.7052 - val_auc: 0.7474 - val_binary_accuracy: 0.7052 - val_recall_1: 0.7125 - val_precision_1: 0.1048\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.6285 - acc: 0.8426 - auc: 0.9338 - binary_accuracy: 0.8426 - recall_1: 0.8775 - precision_1: 0.2108 - val_loss: 0.6205 - val_acc: 0.6983 - val_auc: 0.7506 - val_binary_accuracy: 0.6983 - val_recall_1: 0.7000 - val_precision_1: 0.1011\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.6171 - acc: 0.8356 - auc: 0.9360 - binary_accuracy: 0.8356 - recall_1: 0.9051 - precision_1: 0.2072 - val_loss: 0.5834 - val_acc: 0.7133 - val_auc: 0.7415 - val_binary_accuracy: 0.7133 - val_recall_1: 0.6750 - val_precision_1: 0.1031\n",
      "0.35112321376800537\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f7f1e08-7197-4c2e-91af-1d384fb887fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3108480/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6d2b5258-4d02-482d-b0de-9b2a4bfe2f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced Accuracy:  0.36416184971098264 MSE:  0.6358381502890174 UAR:  0.5953030303030302 Recall:  0.85 Precision:  0.058823529411764705 F1:  0.11003236245954692\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced Accuracy:  0.47398843930635837 MSE:  0.5260115606936416 UAR:  0.6231439393939394 Recall:  0.7875 Precision:  0.06589958158995816 F1:  0.12162162162162164\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced Accuracy:  0.5716763005780346 MSE:  0.4283236994219653 UAR:  0.6624621212121211 Recall:  0.7625 Precision:  0.07790549169859515 F1:  0.1413673232908459\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced Accuracy:  0.6456647398843931 MSE:  0.35433526011560695 UAR:  0.6715151515151515 Recall:  0.7 Precision:  0.08682170542635659 F1:  0.15448275862068966\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced Accuracy:  0.715028901734104 MSE:  0.28497109826589595 UAR:  0.7019318181818182 Recall:  0.6875 Precision:  0.10516252390057361 F1:  0.1824212271973466\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced Accuracy:  0.7658959537572254 MSE:  0.23410404624277456 UAR:  0.6750757575757576 Recall:  0.575 Precision:  0.11031175059952038 F1:  0.18511066398390344\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced Accuracy:  0.8300578034682081 MSE:  0.1699421965317919 UAR:  0.6908712121212122 Recall:  0.5375 Precision:  0.14333333333333334 F1:  0.22631578947368422\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced Accuracy:  0.8867052023121387 MSE:  0.11329479768786127 UAR:  0.678939393939394 Recall:  0.45 Precision:  0.19148936170212766 F1:  0.26865671641791045\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced Accuracy:  0.9369942196531792 MSE:  0.0630057803468208 UAR:  0.6755681818181818 Recall:  0.3875 Precision:  0.34065934065934067 F1:  0.36257309941520466\n",
      "0.5 0.7019318181818182\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name, from_int=True)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a332aa04-6b72-4887-9c0e-e31c1a704656",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96dbeb80-18ae-48e3-bbce-f5cc2aeb7e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3108480/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f4831d27-e023-474f-a844-a73c9d172d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.29132947976878615 MSE:  0.7086705202312139 UAR:  0.5630681818181819 Recall:  0.8625 Precision:  0.053738317757009345 F1:  0.10117302052785923\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.5410404624277456 MSE:  0.45895953757225433 UAR:  0.6582954545454545 Recall:  0.7875 Precision:  0.075 F1:  0.13695652173913045\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.6976878612716763 MSE:  0.3023121387283237 UAR:  0.7047348484848486 Recall:  0.7125 Precision:  0.10233393177737882 F1:  0.17896389324960754\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.7971098265895954 MSE:  0.20289017341040463 UAR:  0.6914393939393939 Recall:  0.575 Precision:  0.12672176308539945 F1:  0.20767494356659144\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.8722543352601156 MSE:  0.12774566473988438 UAR:  0.7070454545454545 Recall:  0.525 Precision:  0.18666666666666668 F1:  0.2754098360655738\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.9190751445086706 MSE:  0.08092485549132948 UAR:  0.6899621212121212 Recall:  0.4375 Precision:  0.2692307692307692 F1:  0.33333333333333337\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.9404624277456647 MSE:  0.05953757225433526 UAR:  0.6357575757575757 Recall:  0.3 Precision:  0.3380281690140845 F1:  0.3178807947019867\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.9491329479768786 MSE:  0.05086705202312139 UAR:  0.568939393939394 Recall:  0.15 Precision:  0.375 F1:  0.21428571428571425\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_std_single_attention_balanced_best Accuracy:  0.9520231213872833 MSE:  0.04797687861271676 UAR:  0.5109848484848485 Recall:  0.025 Precision:  0.2857142857142857 F1:  0.04597701149425287\n",
      "0.5 0.7070454545454545\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name, from_int=True)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32d5c2d-d34c-427d-a576-0d2cd987cfc5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b30cf2c4-f806-4e71-8ed3-95982991491b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "578c3448-4caf-4d21-95b0-127e2cb7ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5a75e77d-87c1-48f7-805d-997229ce5ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 2560) (5475,)\n",
      "(1730, 128, 2560) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "66219443-2b1a-4bd1-bdb9-863d12dafd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_7 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_7[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_7[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "3b782148-c760-4068-b5e9-9c26a03790ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 125ms/step - loss: 0.3764 - acc: 0.9412 - auc: 0.5374 - binary_accuracy: 0.9412 - recall_3: 0.0277 - precision_3: 0.0843 - val_loss: 0.1875 - val_acc: 0.9526 - val_auc: 0.6787 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0125 - val_precision_3: 0.2500\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1737 - acc: 0.9540 - auc: 0.7014 - binary_accuracy: 0.9540 - recall_3: 0.0514 - precision_3: 0.5200 - val_loss: 0.1701 - val_acc: 0.9526 - val_auc: 0.7431 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0250 - val_precision_3: 0.3333\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1627 - acc: 0.9536 - auc: 0.7562 - binary_accuracy: 0.9536 - recall_3: 0.0435 - precision_3: 0.4783 - val_loss: 0.1690 - val_acc: 0.9526 - val_auc: 0.7421 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1558 - acc: 0.9563 - auc: 0.7868 - binary_accuracy: 0.9563 - recall_3: 0.0751 - precision_3: 0.7917 - val_loss: 0.1788 - val_acc: 0.9532 - val_auc: 0.7731 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1543 - acc: 0.9558 - auc: 0.7960 - binary_accuracy: 0.9558 - recall_3: 0.0870 - precision_3: 0.6667 - val_loss: 0.1673 - val_acc: 0.9468 - val_auc: 0.7855 - val_binary_accuracy: 0.9468 - val_recall_3: 0.0375 - val_precision_3: 0.1667\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1532 - acc: 0.9542 - auc: 0.8100 - binary_accuracy: 0.9542 - recall_3: 0.0672 - precision_3: 0.5312 - val_loss: 0.1618 - val_acc: 0.9509 - val_auc: 0.7852 - val_binary_accuracy: 0.9509 - val_recall_3: 0.0500 - val_precision_3: 0.3077\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1613 - acc: 0.9542 - auc: 0.7767 - binary_accuracy: 0.9542 - recall_3: 0.0830 - precision_3: 0.5250 - val_loss: 0.1652 - val_acc: 0.9538 - val_auc: 0.7618 - val_binary_accuracy: 0.9538 - val_recall_3: 0.0125 - val_precision_3: 0.5000\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1583 - acc: 0.9538 - auc: 0.7944 - binary_accuracy: 0.9538 - recall_3: 0.0711 - precision_3: 0.5000 - val_loss: 0.1699 - val_acc: 0.9538 - val_auc: 0.7600 - val_binary_accuracy: 0.9538 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1508 - acc: 0.9556 - auc: 0.8224 - binary_accuracy: 0.9556 - recall_3: 0.0909 - precision_3: 0.6389 - val_loss: 0.1673 - val_acc: 0.9468 - val_auc: 0.7807 - val_binary_accuracy: 0.9468 - val_recall_3: 0.0375 - val_precision_3: 0.1667\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1453 - acc: 0.9567 - auc: 0.8235 - binary_accuracy: 0.9567 - recall_3: 0.1186 - precision_3: 0.6818 - val_loss: 0.1636 - val_acc: 0.9462 - val_auc: 0.7945 - val_binary_accuracy: 0.9462 - val_recall_3: 0.0750 - val_precision_3: 0.2400\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1429 - acc: 0.9558 - auc: 0.8417 - binary_accuracy: 0.9558 - recall_3: 0.1502 - precision_3: 0.5846 - val_loss: 0.1630 - val_acc: 0.9526 - val_auc: 0.7949 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0750 - val_precision_3: 0.4286\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1419 - acc: 0.9563 - auc: 0.8401 - binary_accuracy: 0.9563 - recall_3: 0.1225 - precision_3: 0.6458 - val_loss: 0.1636 - val_acc: 0.9480 - val_auc: 0.7922 - val_binary_accuracy: 0.9480 - val_recall_3: 0.0750 - val_precision_3: 0.2727\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1377 - acc: 0.9574 - auc: 0.8583 - binary_accuracy: 0.9574 - recall_3: 0.1502 - precision_3: 0.6786 - val_loss: 0.1665 - val_acc: 0.9532 - val_auc: 0.7744 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0625 - val_precision_3: 0.4545\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1382 - acc: 0.9569 - auc: 0.8516 - binary_accuracy: 0.9569 - recall_3: 0.1423 - precision_3: 0.6545 - val_loss: 0.1775 - val_acc: 0.9445 - val_auc: 0.7679 - val_binary_accuracy: 0.9445 - val_recall_3: 0.1625 - val_precision_3: 0.3095\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1597 - acc: 0.9536 - auc: 0.7827 - binary_accuracy: 0.9536 - recall_3: 0.1265 - precision_3: 0.4923 - val_loss: 0.1692 - val_acc: 0.9543 - val_auc: 0.7693 - val_binary_accuracy: 0.9543 - val_recall_3: 0.0625 - val_precision_3: 0.5556\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1370 - acc: 0.9582 - auc: 0.8615 - binary_accuracy: 0.9582 - recall_3: 0.1581 - precision_3: 0.7143 - val_loss: 0.1664 - val_acc: 0.9503 - val_auc: 0.7886 - val_binary_accuracy: 0.9503 - val_recall_3: 0.1250 - val_precision_3: 0.3846\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1338 - acc: 0.9591 - auc: 0.8699 - binary_accuracy: 0.9591 - recall_3: 0.1897 - precision_3: 0.7164 - val_loss: 0.1720 - val_acc: 0.9538 - val_auc: 0.7680 - val_binary_accuracy: 0.9538 - val_recall_3: 0.0625 - val_precision_3: 0.5000\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1501 - acc: 0.9553 - auc: 0.8296 - binary_accuracy: 0.9553 - recall_3: 0.1462 - precision_3: 0.5606 - val_loss: 0.1714 - val_acc: 0.9532 - val_auc: 0.7667 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1465 - acc: 0.9556 - auc: 0.8340 - binary_accuracy: 0.9556 - recall_3: 0.0949 - precision_3: 0.6316 - val_loss: 0.1637 - val_acc: 0.9468 - val_auc: 0.7976 - val_binary_accuracy: 0.9468 - val_recall_3: 0.0500 - val_precision_3: 0.2000\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1520 - acc: 0.9527 - auc: 0.8244 - binary_accuracy: 0.9527 - recall_3: 0.1542 - precision_3: 0.4643 - val_loss: 0.1976 - val_acc: 0.9532 - val_auc: 0.6923 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0125 - val_precision_3: 0.3333\n",
      "0.16184794902801514\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "7bf60d1b-6e34-4e59-b586-45b4e6ff7115",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4bd01b4b-9310-4387-8635-a35ec4fc5023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9445086705202312 MSE:  0.055491329479768786 UAR:  0.5903030303030303 Recall:  0.2 Precision:  0.3333333333333333 F1:  0.25\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9520231213872833 MSE:  0.04797687861271676 UAR:  0.5526136363636364 Recall:  0.1125 Precision:  0.42857142857142855 F1:  0.1782178217821782\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5297348484848485 Recall:  0.0625 Precision:  0.5 F1:  0.1111111111111111\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.954335260115607 MSE:  0.04566473988439306 UAR:  0.5181439393939394 Recall:  0.0375 Precision:  0.6 F1:  0.07058823529411765\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.4993939393939394 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.5903030303030303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "1c59c684-4f1c-40a3-ad40-3b404a095b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e42fc2b5-08d7-45e7-b7d2-552c1fde835f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "be6824f7-1834-405f-a4fd-2c130ee990bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.8549132947976879 MSE:  0.14508670520231215 UAR:  0.6979545454545455 Recall:  0.525 Precision:  0.16470588235294117 F1:  0.2507462686567164\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9260115606936417 MSE:  0.07398843930635839 UAR:  0.6460227272727272 Recall:  0.3375 Precision:  0.2647058823529412 F1:  0.29670329670329665\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.946242774566474 MSE:  0.05375722543352601 UAR:  0.5852651515151515 Recall:  0.1875 Precision:  0.3488372093023256 F1:  0.2439024390243903\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.954335260115607 MSE:  0.04566473988439306 UAR:  0.5716666666666667 Recall:  0.15 Precision:  0.5217391304347826 F1:  0.23300970873786406\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.5350757575757575 Recall:  0.075 Precision:  0.42857142857142855 F1:  0.1276595744680851\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5118939393939393 Recall:  0.025 Precision:  0.5 F1:  0.047619047619047616\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6979545454545455\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819dd0d-0ec3-4cc6-9bf7-3c9e438faf8d",
   "metadata": {},
   "source": [
    "### Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "344c4eb9-2529-49cf-8fdd-35e46d3badbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = np.max\n",
    "stat_name = \"max\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7268e2-3e47-4ece-bd38-5b61fbcbaddc",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8986a1a8-4161-48f7-8cc0-6a25b6cbac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "533bff96-0807-4393-93c6-d6e925f5e8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5f651bc3-416f-464d-88ac-975793d30f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "test:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n",
      "val:\n",
      "0 1537/1720: 89.36046511627907%\n",
      "1 183/1720: 10.63953488372093%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb297638-2220-4c47-89fa-2ed63160188f",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "84041f30-2ba5-443e-afee-a36529f371a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef845b58-c38a-42af-a800-4ae755dfd22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6b46d6d2-b763-4140-9c78-ffd053a77c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2048) (5482,)\n",
      "(1723, 128, 2048) (1723,)\n",
      "(1720, 128, 2048) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fc1b5568-43a2-447b-aa81-9c768e657690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5234  248] {0: 1.0, 1: 21.10483870967742} 2 [0 1]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8101f317-62c4-43db-9afb-7c77ad9d02b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "#save_best_model = SaveBestModelByUAR(X_subsample_val, y_subsample_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e9f55365-3d21-4708-a737-cb0104eeb7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 4s 56ms/step - loss: 1.3729 - acc: 0.6012 - auc: 0.6168 - binary_accuracy: 0.6012 - recall_2: 0.5605 - precision_2: 0.0627 - val_loss: 0.7126 - val_acc: 0.6221 - val_auc: 0.6898 - val_binary_accuracy: 0.6221 - val_recall_2: 0.6831 - val_precision_2: 0.1743\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 1.1179 - acc: 0.7231 - auc: 0.7574 - binary_accuracy: 0.7231 - recall_2: 0.6573 - precision_2: 0.1021 - val_loss: 0.8344 - val_acc: 0.4750 - val_auc: 0.6674 - val_binary_accuracy: 0.4750 - val_recall_2: 0.7814 - val_precision_2: 0.1421\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 1.0699 - acc: 0.7401 - auc: 0.7847 - binary_accuracy: 0.7401 - recall_2: 0.6976 - precision_2: 0.1136 - val_loss: 0.9737 - val_acc: 0.4378 - val_auc: 0.6840 - val_binary_accuracy: 0.4378 - val_recall_2: 0.8634 - val_precision_2: 0.1436\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 1.0742 - acc: 0.7140 - auc: 0.7840 - binary_accuracy: 0.7140 - recall_2: 0.7339 - precision_2: 0.1081 - val_loss: 0.4544 - val_acc: 0.7959 - val_auc: 0.6776 - val_binary_accuracy: 0.7959 - val_recall_2: 0.3169 - val_precision_2: 0.2042\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 1.0134 - acc: 0.7424 - auc: 0.8102 - binary_accuracy: 0.7424 - recall_2: 0.7177 - precision_2: 0.1171 - val_loss: 0.5393 - val_acc: 0.7355 - val_auc: 0.6999 - val_binary_accuracy: 0.7355 - val_recall_2: 0.4973 - val_precision_2: 0.2004\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.9794 - acc: 0.7559 - auc: 0.8269 - binary_accuracy: 0.7559 - recall_2: 0.7339 - precision_2: 0.1252 - val_loss: 0.6029 - val_acc: 0.7081 - val_auc: 0.6882 - val_binary_accuracy: 0.7081 - val_recall_2: 0.5628 - val_precision_2: 0.1962\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.9562 - acc: 0.7601 - auc: 0.8347 - binary_accuracy: 0.7601 - recall_2: 0.7500 - precision_2: 0.1293 - val_loss: 0.7006 - val_acc: 0.6541 - val_auc: 0.6937 - val_binary_accuracy: 0.6541 - val_recall_2: 0.6120 - val_precision_2: 0.1761\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.9704 - acc: 0.7647 - auc: 0.8281 - binary_accuracy: 0.7647 - recall_2: 0.7137 - precision_2: 0.1268 - val_loss: 0.4018 - val_acc: 0.8273 - val_auc: 0.6806 - val_binary_accuracy: 0.8273 - val_recall_2: 0.2842 - val_precision_2: 0.2385\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.9118 - acc: 0.7596 - auc: 0.8530 - binary_accuracy: 0.7596 - recall_2: 0.7944 - precision_2: 0.1346 - val_loss: 0.4787 - val_acc: 0.7779 - val_auc: 0.6914 - val_binary_accuracy: 0.7779 - val_recall_2: 0.4262 - val_precision_2: 0.2197\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.8716 - acc: 0.7948 - auc: 0.8680 - binary_accuracy: 0.7948 - recall_2: 0.7944 - precision_2: 0.1550 - val_loss: 0.6902 - val_acc: 0.6355 - val_auc: 0.6920 - val_binary_accuracy: 0.6355 - val_recall_2: 0.6011 - val_precision_2: 0.1657\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.8598 - acc: 0.7804 - auc: 0.8722 - binary_accuracy: 0.7804 - recall_2: 0.8185 - precision_2: 0.1490 - val_loss: 0.4105 - val_acc: 0.8169 - val_auc: 0.6770 - val_binary_accuracy: 0.8169 - val_recall_2: 0.2678 - val_precision_2: 0.2130\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.8482 - acc: 0.7910 - auc: 0.8735 - binary_accuracy: 0.7910 - recall_2: 0.7742 - precision_2: 0.1498 - val_loss: 0.7751 - val_acc: 0.6052 - val_auc: 0.6782 - val_binary_accuracy: 0.6052 - val_recall_2: 0.6557 - val_precision_2: 0.1630\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.8248 - acc: 0.7999 - auc: 0.8831 - binary_accuracy: 0.7999 - recall_2: 0.7823 - precision_2: 0.1568 - val_loss: 0.8180 - val_acc: 0.6157 - val_auc: 0.6906 - val_binary_accuracy: 0.6157 - val_recall_2: 0.6448 - val_precision_2: 0.1653\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.8196 - acc: 0.7948 - auc: 0.8835 - binary_accuracy: 0.7948 - recall_2: 0.8266 - precision_2: 0.1593 - val_loss: 0.4839 - val_acc: 0.7727 - val_auc: 0.6760 - val_binary_accuracy: 0.7727 - val_recall_2: 0.4372 - val_precision_2: 0.2174\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.7688 - acc: 0.8048 - auc: 0.9000 - binary_accuracy: 0.8048 - recall_2: 0.8185 - precision_2: 0.1653 - val_loss: 0.4904 - val_acc: 0.7657 - val_auc: 0.6790 - val_binary_accuracy: 0.7657 - val_recall_2: 0.4262 - val_precision_2: 0.2074\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.7509 - acc: 0.8192 - auc: 0.9041 - binary_accuracy: 0.8192 - recall_2: 0.8427 - precision_2: 0.1800 - val_loss: 0.5897 - val_acc: 0.7064 - val_auc: 0.6605 - val_binary_accuracy: 0.7064 - val_recall_2: 0.4918 - val_precision_2: 0.1793\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.7457 - acc: 0.8034 - auc: 0.9060 - binary_accuracy: 0.8034 - recall_2: 0.8589 - precision_2: 0.1696 - val_loss: 0.4500 - val_acc: 0.7953 - val_auc: 0.6702 - val_binary_accuracy: 0.7953 - val_recall_2: 0.3388 - val_precision_2: 0.2116\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.7553 - acc: 0.8311 - auc: 0.9018 - binary_accuracy: 0.8311 - recall_2: 0.8105 - precision_2: 0.1861 - val_loss: 1.0013 - val_acc: 0.5477 - val_auc: 0.6905 - val_binary_accuracy: 0.5477 - val_recall_2: 0.7268 - val_precision_2: 0.1545\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.7199 - acc: 0.8152 - auc: 0.9126 - binary_accuracy: 0.8152 - recall_2: 0.8790 - precision_2: 0.1815 - val_loss: 0.4595 - val_acc: 0.7983 - val_auc: 0.6697 - val_binary_accuracy: 0.7983 - val_recall_2: 0.3661 - val_precision_2: 0.2248\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.7114 - acc: 0.8236 - auc: 0.9133 - binary_accuracy: 0.8236 - recall_2: 0.8548 - precision_2: 0.1855 - val_loss: 0.4280 - val_acc: 0.8186 - val_auc: 0.6603 - val_binary_accuracy: 0.8186 - val_recall_2: 0.2623 - val_precision_2: 0.2133\n",
      "0.40176132321357727\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7dfaa20d-ad9b-4132-9af9-bb953dec93c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3108480/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a934f000-5639-4a46-9d46-8235c8bcd253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional Accuracy:  0.4312246082414393 MSE:  0.5687753917585606 UAR:  0.5502729296846944 Recall:  0.6823529411764706 Precision:  0.057368941641938676 F1:  0.10583941605839416\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional Accuracy:  0.5722576900754498 MSE:  0.4277423099245502 UAR:  0.5909861380449616 Recall:  0.611764705882353 Precision:  0.06878306878306878 F1:  0.12366230677764564\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional Accuracy:  0.6796285548461984 MSE:  0.3203714451538015 UAR:  0.608417726064785 Recall:  0.5294117647058824 Precision:  0.0807899461400359 F1:  0.14018691588785048\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional Accuracy:  0.7777132907719094 MSE:  0.22228670922809055 UAR:  0.6265424118365295 Recall:  0.4588235294117647 Precision:  0.10372340425531915 F1:  0.1691973969631236\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional Accuracy:  0.853163087637841 MSE:  0.146836912362159 UAR:  0.6494936436112907 Recall:  0.4235294117647059 Precision:  0.15 F1:  0.22153846153846152\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional Accuracy:  0.8961114335461404 MSE:  0.10388856645385955 UAR:  0.6218882424764778 Recall:  0.3176470588235294 Precision:  0.18243243243243243 F1:  0.2317596566523605\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional Accuracy:  0.9193267556587348 MSE:  0.08067324434126523 UAR:  0.6229440494146377 Recall:  0.29411764705882354 Precision:  0.2403846153846154 F1:  0.26455026455026454\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional Accuracy:  0.9367382472431804 MSE:  0.0632617527568195 UAR:  0.5763305322128851 Recall:  0.17647058823529413 Precision:  0.2777777777777778 F1:  0.2158273381294964\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional Accuracy:  0.9483459082994776 MSE:  0.05165409170052235 UAR:  0.5489729225023343 Recall:  0.10588235294117647 Precision:  0.4090909090909091 F1:  0.16822429906542055\n",
      "0.5 0.6494936436112907\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name, from_int=True)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "62bb4d3d-f9a9-4baa-a646-7cc67236aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0047ffc3-8a41-4ef5-bc93-6f1d416c3c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3108480/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3b031653-4e66-45c4-ac36-e27a6755a277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.20951828206616366 MSE:  0.7904817179338364 UAR:  0.5675177763413057 Recall:  0.9647058823529412 Precision:  0.05690492713393477 F1:  0.10747051114023591\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.4515380150899594 MSE:  0.5484619849100406 UAR:  0.5999964088199382 Recall:  0.7647058823529411 Precision:  0.06565656565656566 F1:  0.12093023255813955\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.6500290191526408 MSE:  0.3499709808473593 UAR:  0.6263125763125763 Recall:  0.6 Precision:  0.08225806451612903 F1:  0.14468085106382977\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.7893209518282066 MSE:  0.2106790481717934 UAR:  0.6270703153056094 Recall:  0.4470588235294118 Precision:  0.10734463276836158 F1:  0.17312072892938496\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.8723157283807312 MSE:  0.1276842716192687 UAR:  0.6428355957767723 Recall:  0.38823529411764707 Precision:  0.16417910447761194 F1:  0.23076923076923078\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.9106210098665118 MSE:  0.0893789901334881 UAR:  0.6295195001077354 Recall:  0.3176470588235294 Precision:  0.21951219512195122 F1:  0.2596153846153846\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.9442832269297736 MSE:  0.05571677307022635 UAR:  0.5970300940889176 Recall:  0.21176470588235294 Precision:  0.3829787234042553 F1:  0.2727272727272727\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.539955469367234 Recall:  0.08235294117647059 Precision:  0.6363636363636364 F1:  0.14583333333333331\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_traditional_best Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5058823529411764 Recall:  0.011764705882352941 Precision:  1.0 F1:  0.023255813953488372\n",
      "0.5 0.6428355957767723\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name, from_int=True)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ca12f-1037-4d1d-9598-f8e9744d0ee2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "0622b6dd-ae15-410d-97b0-0520cbc270e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "5054d919-8a06-4fa8-b313-4991e8669c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "9352edfe-1283-4ccb-afa6-fc53497afa10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4a115602-49a1-4f01-863a-828723b025bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_6 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_6[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_6[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c8463369-5688-4626-9e06-3fcc67114169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 127ms/step - loss: 0.3520 - acc: 0.9435 - auc: 0.5372 - binary_accuracy: 0.9435 - recall_1: 0.0121 - precision_1: 0.0441 - val_loss: 0.3655 - val_acc: 0.8936 - val_auc: 0.6054 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1676 - acc: 0.9544 - auc: 0.7332 - binary_accuracy: 0.9544 - recall_1: 0.0081 - precision_1: 0.3333 - val_loss: 0.4156 - val_acc: 0.8936 - val_auc: 0.6291 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1589 - acc: 0.9533 - auc: 0.7800 - binary_accuracy: 0.9533 - recall_1: 0.0081 - precision_1: 0.1667 - val_loss: 0.3692 - val_acc: 0.8907 - val_auc: 0.6405 - val_binary_accuracy: 0.8907 - val_recall_1: 0.0328 - val_precision_1: 0.3529\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1570 - acc: 0.9538 - auc: 0.7916 - binary_accuracy: 0.9538 - recall_1: 0.0282 - precision_1: 0.3684 - val_loss: 0.4193 - val_acc: 0.8930 - val_auc: 0.6368 - val_binary_accuracy: 0.8930 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1648 - acc: 0.9526 - auc: 0.7644 - binary_accuracy: 0.9526 - recall_1: 0.0403 - precision_1: 0.3125 - val_loss: 0.3956 - val_acc: 0.8936 - val_auc: 0.6295 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1544 - acc: 0.9557 - auc: 0.8021 - binary_accuracy: 0.9557 - recall_1: 0.0524 - precision_1: 0.6190 - val_loss: 0.3884 - val_acc: 0.8942 - val_auc: 0.6372 - val_binary_accuracy: 0.8942 - val_recall_1: 0.0164 - val_precision_1: 0.6000\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1498 - acc: 0.9564 - auc: 0.8126 - binary_accuracy: 0.9564 - recall_1: 0.0726 - precision_1: 0.6667 - val_loss: 0.4350 - val_acc: 0.8936 - val_auc: 0.6258 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1505 - acc: 0.9562 - auc: 0.7941 - binary_accuracy: 0.9562 - recall_1: 0.0927 - precision_1: 0.6053 - val_loss: 0.4107 - val_acc: 0.8936 - val_auc: 0.6443 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1529 - acc: 0.9529 - auc: 0.8132 - binary_accuracy: 0.9529 - recall_1: 0.0565 - precision_1: 0.3684 - val_loss: 0.3560 - val_acc: 0.8901 - val_auc: 0.6600 - val_binary_accuracy: 0.8901 - val_recall_1: 0.0328 - val_precision_1: 0.3333\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1611 - acc: 0.9544 - auc: 0.7951 - binary_accuracy: 0.9544 - recall_1: 0.0766 - precision_1: 0.4750 - val_loss: 0.3404 - val_acc: 0.8919 - val_auc: 0.6709 - val_binary_accuracy: 0.8919 - val_recall_1: 0.0164 - val_precision_1: 0.3333\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1480 - acc: 0.9551 - auc: 0.8080 - binary_accuracy: 0.9551 - recall_1: 0.0645 - precision_1: 0.5333 - val_loss: 0.3748 - val_acc: 0.8791 - val_auc: 0.6659 - val_binary_accuracy: 0.8791 - val_recall_1: 0.0546 - val_precision_1: 0.2222\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1393 - acc: 0.9577 - auc: 0.8477 - binary_accuracy: 0.9577 - recall_1: 0.1169 - precision_1: 0.6905 - val_loss: 0.4060 - val_acc: 0.8843 - val_auc: 0.6437 - val_binary_accuracy: 0.8843 - val_recall_1: 0.0328 - val_precision_1: 0.2143\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1391 - acc: 0.9584 - auc: 0.8543 - binary_accuracy: 0.9584 - recall_1: 0.1694 - precision_1: 0.6562 - val_loss: 0.4013 - val_acc: 0.8913 - val_auc: 0.6270 - val_binary_accuracy: 0.8913 - val_recall_1: 0.0055 - val_precision_1: 0.1667\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1430 - acc: 0.9564 - auc: 0.8307 - binary_accuracy: 0.9564 - recall_1: 0.1250 - precision_1: 0.5849 - val_loss: 0.4422 - val_acc: 0.8936 - val_auc: 0.6349 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0164 - val_precision_1: 0.5000\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1403 - acc: 0.9593 - auc: 0.8408 - binary_accuracy: 0.9593 - recall_1: 0.1532 - precision_1: 0.7451 - val_loss: 0.3936 - val_acc: 0.8860 - val_auc: 0.6520 - val_binary_accuracy: 0.8860 - val_recall_1: 0.0273 - val_precision_1: 0.2174\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1331 - acc: 0.9599 - auc: 0.8623 - binary_accuracy: 0.9599 - recall_1: 0.1815 - precision_1: 0.7258 - val_loss: 0.4326 - val_acc: 0.8890 - val_auc: 0.6155 - val_binary_accuracy: 0.8890 - val_recall_1: 0.0109 - val_precision_1: 0.1667\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1567 - acc: 0.9579 - auc: 0.8211 - binary_accuracy: 0.9579 - recall_1: 0.1855 - precision_1: 0.6133 - val_loss: 0.6409 - val_acc: 0.8901 - val_auc: 0.5315 - val_binary_accuracy: 0.8901 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1939 - acc: 0.9513 - auc: 0.7187 - binary_accuracy: 0.9513 - recall_1: 0.0927 - precision_1: 0.3538 - val_loss: 0.4528 - val_acc: 0.8924 - val_auc: 0.6278 - val_binary_accuracy: 0.8924 - val_recall_1: 0.0109 - val_precision_1: 0.3333\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1382 - acc: 0.9582 - auc: 0.8531 - binary_accuracy: 0.9582 - recall_1: 0.1532 - precision_1: 0.6667 - val_loss: 0.4255 - val_acc: 0.8831 - val_auc: 0.6076 - val_binary_accuracy: 0.8831 - val_recall_1: 0.0328 - val_precision_1: 0.2000\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1471 - acc: 0.9573 - auc: 0.8318 - binary_accuracy: 0.9573 - recall_1: 0.1653 - precision_1: 0.6029 - val_loss: 0.3628 - val_acc: 0.8831 - val_auc: 0.6370 - val_binary_accuracy: 0.8831 - val_recall_1: 0.0273 - val_precision_1: 0.1786\n",
      "0.340364933013916\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "941662d9-290a-4023-826b-35f587693c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ee9422a7-9ef3-4a14-970d-5a96d3a3542a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.8415554265815438 MSE:  0.1584445734184562 UAR:  0.6043489190548015 Recall:  0.3411764705882353 Precision:  0.11788617886178862 F1:  0.17522658610271902\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.930354033662217 MSE:  0.06964596633778293 UAR:  0.5450872656755009 Recall:  0.11764705882352941 Precision:  0.18181818181818182 F1:  0.14285714285714285\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9437028438769588 MSE:  0.05629715612304121 UAR:  0.5409538174244057 Recall:  0.09411764705882353 Precision:  0.2857142857142857 F1:  0.1415929203539823\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.947185142193848 MSE:  0.05281485780615206 UAR:  0.526054011348129 Recall:  0.058823529411764705 Precision:  0.3125 F1:  0.09900990099009901\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5281907634848811 Recall:  0.058823529411764705 Precision:  0.5555555555555556 F1:  0.10638297872340426\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5229189111542053 Recall:  0.047058823529411764 Precision:  0.6666666666666666 F1:  0.08791208791208792\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9529889727219966 MSE:  0.047011027278003485 UAR:  0.5235294117647059 Recall:  0.047058823529411764 Precision:  1.0 F1:  0.0898876404494382\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5176470588235295 Recall:  0.03529411764705882 Precision:  1.0 F1:  0.06818181818181818\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5117647058823529 Recall:  0.023529411764705882 Precision:  1.0 F1:  0.04597701149425288\n",
      "0.1 0.6043489190548015\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "63926368-a2bf-451e-9bd7-3ceabffe7885",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "5f7aeb47-bd14-49bd-ad41-accd7502e770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "60f79269-9d1e-43db-9b41-27e2631b9e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.8340104468949506 MSE:  0.16598955310504934 UAR:  0.6282661782661783 Recall:  0.4 Precision:  0.12639405204460966 F1:  0.192090395480226\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9297736506094022 MSE:  0.0702263493905978 UAR:  0.5949759390935861 Recall:  0.2235294117647059 Precision:  0.25675675675675674 F1:  0.2389937106918239\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9477655252466628 MSE:  0.0522344747533372 UAR:  0.5653989801048624 Recall:  0.1411764705882353 Precision:  0.41379310344827586 F1:  0.21052631578947367\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5566867772750126 Recall:  0.11764705882352941 Precision:  0.5882352941176471 F1:  0.19607843137254902\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9529889727219966 MSE:  0.047011027278003485 UAR:  0.5402607196724843 Recall:  0.08235294117647059 Precision:  0.7 F1:  0.14736842105263157\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5288012640953818 Recall:  0.058823529411764705 Precision:  0.7142857142857143 F1:  0.10869565217391305\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9500870574579222 MSE:  0.04991294254207777 UAR:  0.5052718523306758 Recall:  0.011764705882352941 Precision:  0.3333333333333333 F1:  0.022727272727272728\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5058823529411764 Recall:  0.011764705882352941 Precision:  1.0 F1:  0.023255813953488372\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6282661782661783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c36992a-338b-4948-a111-8df02e0d07a4",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aa937174-412c-4585-836b-40adea1091a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "316b2039-ce28-4646-b457-fc524e2ca584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3f105026-f13f-4e92-b28a-eda00f5a3870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "val:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bcf159f5-3048-4328-ab89-b3481dfdde5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482,) (5482,)\n",
      "(1723,) (1723,)\n",
      "(7205,) (7205,)\n",
      "[0 1] [6872  333]\n",
      "7205\n",
      "5475\n",
      "1730\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "634edaa2-4836-4f1a-893e-2b13f6a93aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5222/5475: 95.37899543378995%\n",
      "1 253/5475: 4.621004566210046%\n",
      "val:\n",
      "0 1650/1730: 95.3757225433526%\n",
      "1 80/1730: 4.624277456647399%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd462a9-caac-41a8-83a6-2064cd0ac5d7",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "49f8fc68-4490-4e4f-8c4c-411b6311c7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "45f553fe-0b08-426c-945f-ecf3b70a8bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "38b71f98-da4b-4a5d-987d-449986ebd2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 2048) (5475,)\n",
      "(1730, 128, 2048) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "874249d6-1926-436b-aeeb-b0d761719502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5222  253] {0: 1.0, 1: 20.640316205533598} 2 [0 1]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "14acdf8e-37f8-4892-87c8-e5e8d63ea8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2048)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2049      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2048, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2048)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2048)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2048)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1049088   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1051650 (4.01 MB)\n",
      "Trainable params: 1051650 (4.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "#save_best_model = SaveBestModelByUAR(X_subsample_test, y_subsample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8930cf78-2d89-4b10-b026-a36ae6544991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 4s 59ms/step - loss: 1.5547 - acc: 0.6031 - auc: 0.6044 - binary_accuracy: 0.6031 - recall_3: 0.5810 - precision_3: 0.0664 - val_loss: 0.6103 - val_acc: 0.7260 - val_auc: 0.7356 - val_binary_accuracy: 0.7260 - val_recall_3: 0.6375 - val_precision_3: 0.1028\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 1.1779 - acc: 0.6795 - auc: 0.7111 - binary_accuracy: 0.6795 - recall_3: 0.6364 - precision_3: 0.0883 - val_loss: 0.7102 - val_acc: 0.6023 - val_auc: 0.7705 - val_binary_accuracy: 0.6023 - val_recall_3: 0.8250 - val_precision_3: 0.0892\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 1.0750 - acc: 0.7622 - auc: 0.7820 - binary_accuracy: 0.7622 - recall_3: 0.6877 - precision_3: 0.1246 - val_loss: 0.4661 - val_acc: 0.8364 - val_auc: 0.7632 - val_binary_accuracy: 0.8364 - val_recall_3: 0.6000 - val_precision_3: 0.1605\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 1.0399 - acc: 0.7668 - auc: 0.7990 - binary_accuracy: 0.7668 - recall_3: 0.6838 - precision_3: 0.1263 - val_loss: 0.4856 - val_acc: 0.8064 - val_auc: 0.7651 - val_binary_accuracy: 0.8064 - val_recall_3: 0.6125 - val_precision_3: 0.1388\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 1.0054 - acc: 0.7635 - auc: 0.8159 - binary_accuracy: 0.7635 - recall_3: 0.6917 - precision_3: 0.1257 - val_loss: 0.5771 - val_acc: 0.7179 - val_auc: 0.7778 - val_binary_accuracy: 0.7179 - val_recall_3: 0.7250 - val_precision_3: 0.1107\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 1s 28ms/step - loss: 0.9584 - acc: 0.7783 - auc: 0.8387 - binary_accuracy: 0.7783 - recall_3: 0.7154 - precision_3: 0.1368 - val_loss: 0.5088 - val_acc: 0.7630 - val_auc: 0.7749 - val_binary_accuracy: 0.7630 - val_recall_3: 0.6500 - val_precision_3: 0.1198\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.9627 - acc: 0.7627 - auc: 0.8328 - binary_accuracy: 0.7627 - recall_3: 0.7589 - precision_3: 0.1343 - val_loss: 0.5366 - val_acc: 0.7347 - val_auc: 0.7777 - val_binary_accuracy: 0.7347 - val_recall_3: 0.6875 - val_precision_3: 0.1125\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.9103 - acc: 0.7867 - auc: 0.8552 - binary_accuracy: 0.7867 - recall_3: 0.7312 - precision_3: 0.1440 - val_loss: 0.6618 - val_acc: 0.6457 - val_auc: 0.7772 - val_binary_accuracy: 0.6457 - val_recall_3: 0.8000 - val_precision_3: 0.0968\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.8946 - acc: 0.7868 - auc: 0.8610 - binary_accuracy: 0.7868 - recall_3: 0.7866 - precision_3: 0.1517 - val_loss: 0.7094 - val_acc: 0.6116 - val_auc: 0.7711 - val_binary_accuracy: 0.6116 - val_recall_3: 0.7625 - val_precision_3: 0.0854\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.9004 - acc: 0.7810 - auc: 0.8565 - binary_accuracy: 0.7810 - recall_3: 0.7984 - precision_3: 0.1496 - val_loss: 0.6680 - val_acc: 0.6509 - val_auc: 0.7737 - val_binary_accuracy: 0.6509 - val_recall_3: 0.7750 - val_precision_3: 0.0957\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.8750 - acc: 0.7834 - auc: 0.8652 - binary_accuracy: 0.7834 - recall_3: 0.7866 - precision_3: 0.1495 - val_loss: 0.4971 - val_acc: 0.7665 - val_auc: 0.7681 - val_binary_accuracy: 0.7665 - val_recall_3: 0.6125 - val_precision_3: 0.1161\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.8317 - acc: 0.7907 - auc: 0.8801 - binary_accuracy: 0.7907 - recall_3: 0.7708 - precision_3: 0.1520 - val_loss: 0.4878 - val_acc: 0.7595 - val_auc: 0.7568 - val_binary_accuracy: 0.7595 - val_recall_3: 0.6625 - val_precision_3: 0.1199\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.7759 - acc: 0.8075 - auc: 0.8991 - binary_accuracy: 0.8075 - recall_3: 0.8458 - precision_3: 0.1741 - val_loss: 0.3481 - val_acc: 0.8613 - val_auc: 0.7449 - val_binary_accuracy: 0.8613 - val_recall_3: 0.5750 - val_precision_3: 0.1825\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.7870 - acc: 0.8212 - auc: 0.8949 - binary_accuracy: 0.8212 - recall_3: 0.7945 - precision_3: 0.1782 - val_loss: 0.5363 - val_acc: 0.7249 - val_auc: 0.7546 - val_binary_accuracy: 0.7249 - val_recall_3: 0.6375 - val_precision_3: 0.1024\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.7857 - acc: 0.7960 - auc: 0.8930 - binary_accuracy: 0.7960 - recall_3: 0.8142 - precision_3: 0.1614 - val_loss: 0.5252 - val_acc: 0.7382 - val_auc: 0.7474 - val_binary_accuracy: 0.7382 - val_recall_3: 0.6250 - val_precision_3: 0.1057\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 1s 27ms/step - loss: 0.7436 - acc: 0.8100 - auc: 0.9065 - binary_accuracy: 0.8100 - recall_3: 0.8379 - precision_3: 0.1751 - val_loss: 0.3133 - val_acc: 0.8821 - val_auc: 0.7482 - val_binary_accuracy: 0.8821 - val_recall_3: 0.4750 - val_precision_3: 0.1900\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 1s 26ms/step - loss: 0.7046 - acc: 0.8345 - auc: 0.9170 - binary_accuracy: 0.8345 - recall_3: 0.8300 - precision_3: 0.1957 - val_loss: 0.3814 - val_acc: 0.8422 - val_auc: 0.7374 - val_binary_accuracy: 0.8422 - val_recall_3: 0.5375 - val_precision_3: 0.1541\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.6999 - acc: 0.8225 - auc: 0.9180 - binary_accuracy: 0.8225 - recall_3: 0.8696 - precision_3: 0.1898 - val_loss: 0.4766 - val_acc: 0.7769 - val_auc: 0.7472 - val_binary_accuracy: 0.7769 - val_recall_3: 0.6125 - val_precision_3: 0.1213\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.6654 - acc: 0.8321 - auc: 0.9259 - binary_accuracy: 0.8321 - recall_3: 0.8617 - precision_3: 0.1978 - val_loss: 0.3729 - val_acc: 0.8509 - val_auc: 0.7386 - val_binary_accuracy: 0.8509 - val_recall_3: 0.5750 - val_precision_3: 0.1704\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 1s 25ms/step - loss: 0.6982 - acc: 0.8268 - auc: 0.9159 - binary_accuracy: 0.8268 - recall_3: 0.8538 - precision_3: 0.1917 - val_loss: 0.6367 - val_acc: 0.6746 - val_auc: 0.7575 - val_binary_accuracy: 0.6746 - val_recall_3: 0.7375 - val_precision_3: 0.0982\n",
      "0.31328460574150085\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3a40c366-b318-4380-997e-d3e4c1aabaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3108480/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "852c72d7-4d3d-4bcc-bcee-d3591e96ad54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced Accuracy:  0.28265895953757225 MSE:  0.7173410404624277 UAR:  0.564469696969697 Recall:  0.875 Precision:  0.053804765564950036 F1:  0.10137581462708181\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced Accuracy:  0.4023121387283237 MSE:  0.5976878612716763 UAR:  0.6093560606060606 Recall:  0.8375 Precision:  0.06158088235294118 F1:  0.11472602739726026\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced Accuracy:  0.5144508670520231 MSE:  0.48554913294797686 UAR:  0.6503030303030304 Recall:  0.8 Precision:  0.07207207207207207 F1:  0.13223140495867766\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced Accuracy:  0.5976878612716763 MSE:  0.4023121387283237 UAR:  0.6760984848484848 Recall:  0.7625 Precision:  0.08265582655826559 F1:  0.14914425427872863\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced Accuracy:  0.6797687861271676 MSE:  0.3202312138728324 UAR:  0.7131818181818181 Recall:  0.75 Precision:  0.10101010101010101 F1:  0.17804154302670624\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced Accuracy:  0.7531791907514451 MSE:  0.2468208092485549 UAR:  0.7159848484848486 Recall:  0.675 Precision:  0.11868131868131868 F1:  0.20186915887850468\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced Accuracy:  0.8132947976878613 MSE:  0.18670520231213872 UAR:  0.7058712121212121 Recall:  0.5875 Precision:  0.1394658753709199 F1:  0.22541966426858515\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced Accuracy:  0.8728323699421965 MSE:  0.12716763005780346 UAR:  0.6954545454545454 Recall:  0.5 Precision:  0.18181818181818182 F1:  0.26666666666666666\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced Accuracy:  0.9369942196531792 MSE:  0.0630057803468208 UAR:  0.6636742424242424 Recall:  0.3625 Precision:  0.3333333333333333 F1:  0.34730538922155685\n",
      "0.6 0.7159848484848486\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name, from_int=True)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ea63b280-093e-457f-8671-45212d801ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7d97c43b-86fb-4af3-98dc-42ef8fea1a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3108480/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ff6f90e3-f518-4a6e-bc39-631fbc8c4926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.4601156069364162 MSE:  0.5398843930635838 UAR:  0.6277651515151516 Recall:  0.8125 Precision:  0.06605691056910569 F1:  0.12218045112781956\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.6323699421965318 MSE:  0.3676300578034682 UAR:  0.676439393939394 Recall:  0.725 Precision:  0.08630952380952381 F1:  0.15425531914893617\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.7468208092485549 MSE:  0.25317919075144507 UAR:  0.7007575757575757 Recall:  0.65 Precision:  0.11255411255411256 F1:  0.1918819188191882\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.823121387283237 MSE:  0.176878612716763 UAR:  0.699128787878788 Recall:  0.5625 Precision:  0.14240506329113925 F1:  0.22727272727272732\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.8820809248554913 MSE:  0.11791907514450867 UAR:  0.688409090909091 Recall:  0.475 Precision:  0.19 F1:  0.2714285714285714\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.9277456647398844 MSE:  0.07225433526011561 UAR:  0.6885606060606061 Recall:  0.425 Precision:  0.3008849557522124 F1:  0.3523316062176166\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.946242774566474 MSE:  0.05375722543352601 UAR:  0.6685227272727272 Recall:  0.3625 Precision:  0.4084507042253521 F1:  0.3841059602649007\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.9520231213872833 MSE:  0.04797687861271676 UAR:  0.600189393939394 Recall:  0.2125 Precision:  0.4594594594594595 F1:  0.2905982905982906\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_max_single_attention_balanced_best Accuracy:  0.9520231213872833 MSE:  0.04797687861271676 UAR:  0.5288257575757576 Recall:  0.0625 Precision:  0.38461538461538464 F1:  0.10752688172043011\n",
      "0.3 0.7007575757575757\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name, from_int=True)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8e830f-ca25-4ad1-96a6-fdde586a87f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "f2012184-67a5-4817-bee9-573714f0d0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "99d75a04-fbe7-4935-a6d7-244a92935da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "769e54ec-3f81-4beb-af10-15ec4e35ed03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 2560) (5475,)\n",
      "(1730, 128, 2560) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "6fd74bb5-bcf7-42d6-a5e2-fe21cc9cc51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_7 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_7[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_7[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6b0eb376-9ec8-4a7d-8fb7-b49fad30a235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 125ms/step - loss: 0.3764 - acc: 0.9412 - auc: 0.5374 - binary_accuracy: 0.9412 - recall_3: 0.0277 - precision_3: 0.0843 - val_loss: 0.1875 - val_acc: 0.9526 - val_auc: 0.6787 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0125 - val_precision_3: 0.2500\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1737 - acc: 0.9540 - auc: 0.7014 - binary_accuracy: 0.9540 - recall_3: 0.0514 - precision_3: 0.5200 - val_loss: 0.1701 - val_acc: 0.9526 - val_auc: 0.7431 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0250 - val_precision_3: 0.3333\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1627 - acc: 0.9536 - auc: 0.7562 - binary_accuracy: 0.9536 - recall_3: 0.0435 - precision_3: 0.4783 - val_loss: 0.1690 - val_acc: 0.9526 - val_auc: 0.7421 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1558 - acc: 0.9563 - auc: 0.7868 - binary_accuracy: 0.9563 - recall_3: 0.0751 - precision_3: 0.7917 - val_loss: 0.1788 - val_acc: 0.9532 - val_auc: 0.7731 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1543 - acc: 0.9558 - auc: 0.7960 - binary_accuracy: 0.9558 - recall_3: 0.0870 - precision_3: 0.6667 - val_loss: 0.1673 - val_acc: 0.9468 - val_auc: 0.7855 - val_binary_accuracy: 0.9468 - val_recall_3: 0.0375 - val_precision_3: 0.1667\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1532 - acc: 0.9542 - auc: 0.8100 - binary_accuracy: 0.9542 - recall_3: 0.0672 - precision_3: 0.5312 - val_loss: 0.1618 - val_acc: 0.9509 - val_auc: 0.7852 - val_binary_accuracy: 0.9509 - val_recall_3: 0.0500 - val_precision_3: 0.3077\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1613 - acc: 0.9542 - auc: 0.7767 - binary_accuracy: 0.9542 - recall_3: 0.0830 - precision_3: 0.5250 - val_loss: 0.1652 - val_acc: 0.9538 - val_auc: 0.7618 - val_binary_accuracy: 0.9538 - val_recall_3: 0.0125 - val_precision_3: 0.5000\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1583 - acc: 0.9538 - auc: 0.7944 - binary_accuracy: 0.9538 - recall_3: 0.0711 - precision_3: 0.5000 - val_loss: 0.1699 - val_acc: 0.9538 - val_auc: 0.7600 - val_binary_accuracy: 0.9538 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1508 - acc: 0.9556 - auc: 0.8224 - binary_accuracy: 0.9556 - recall_3: 0.0909 - precision_3: 0.6389 - val_loss: 0.1673 - val_acc: 0.9468 - val_auc: 0.7807 - val_binary_accuracy: 0.9468 - val_recall_3: 0.0375 - val_precision_3: 0.1667\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1453 - acc: 0.9567 - auc: 0.8235 - binary_accuracy: 0.9567 - recall_3: 0.1186 - precision_3: 0.6818 - val_loss: 0.1636 - val_acc: 0.9462 - val_auc: 0.7945 - val_binary_accuracy: 0.9462 - val_recall_3: 0.0750 - val_precision_3: 0.2400\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1429 - acc: 0.9558 - auc: 0.8417 - binary_accuracy: 0.9558 - recall_3: 0.1502 - precision_3: 0.5846 - val_loss: 0.1630 - val_acc: 0.9526 - val_auc: 0.7949 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0750 - val_precision_3: 0.4286\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1419 - acc: 0.9563 - auc: 0.8401 - binary_accuracy: 0.9563 - recall_3: 0.1225 - precision_3: 0.6458 - val_loss: 0.1636 - val_acc: 0.9480 - val_auc: 0.7922 - val_binary_accuracy: 0.9480 - val_recall_3: 0.0750 - val_precision_3: 0.2727\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1377 - acc: 0.9574 - auc: 0.8583 - binary_accuracy: 0.9574 - recall_3: 0.1502 - precision_3: 0.6786 - val_loss: 0.1665 - val_acc: 0.9532 - val_auc: 0.7744 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0625 - val_precision_3: 0.4545\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1382 - acc: 0.9569 - auc: 0.8516 - binary_accuracy: 0.9569 - recall_3: 0.1423 - precision_3: 0.6545 - val_loss: 0.1775 - val_acc: 0.9445 - val_auc: 0.7679 - val_binary_accuracy: 0.9445 - val_recall_3: 0.1625 - val_precision_3: 0.3095\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1597 - acc: 0.9536 - auc: 0.7827 - binary_accuracy: 0.9536 - recall_3: 0.1265 - precision_3: 0.4923 - val_loss: 0.1692 - val_acc: 0.9543 - val_auc: 0.7693 - val_binary_accuracy: 0.9543 - val_recall_3: 0.0625 - val_precision_3: 0.5556\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1370 - acc: 0.9582 - auc: 0.8615 - binary_accuracy: 0.9582 - recall_3: 0.1581 - precision_3: 0.7143 - val_loss: 0.1664 - val_acc: 0.9503 - val_auc: 0.7886 - val_binary_accuracy: 0.9503 - val_recall_3: 0.1250 - val_precision_3: 0.3846\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1338 - acc: 0.9591 - auc: 0.8699 - binary_accuracy: 0.9591 - recall_3: 0.1897 - precision_3: 0.7164 - val_loss: 0.1720 - val_acc: 0.9538 - val_auc: 0.7680 - val_binary_accuracy: 0.9538 - val_recall_3: 0.0625 - val_precision_3: 0.5000\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1501 - acc: 0.9553 - auc: 0.8296 - binary_accuracy: 0.9553 - recall_3: 0.1462 - precision_3: 0.5606 - val_loss: 0.1714 - val_acc: 0.9532 - val_auc: 0.7667 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1465 - acc: 0.9556 - auc: 0.8340 - binary_accuracy: 0.9556 - recall_3: 0.0949 - precision_3: 0.6316 - val_loss: 0.1637 - val_acc: 0.9468 - val_auc: 0.7976 - val_binary_accuracy: 0.9468 - val_recall_3: 0.0500 - val_precision_3: 0.2000\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1520 - acc: 0.9527 - auc: 0.8244 - binary_accuracy: 0.9527 - recall_3: 0.1542 - precision_3: 0.4643 - val_loss: 0.1976 - val_acc: 0.9532 - val_auc: 0.6923 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0125 - val_precision_3: 0.3333\n",
      "0.16184794902801514\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "b6d3396d-60ca-42a5-b432-2057343faf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "55b829b7-d007-43aa-ad33-359174e9c7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9445086705202312 MSE:  0.055491329479768786 UAR:  0.5903030303030303 Recall:  0.2 Precision:  0.3333333333333333 F1:  0.25\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9520231213872833 MSE:  0.04797687861271676 UAR:  0.5526136363636364 Recall:  0.1125 Precision:  0.42857142857142855 F1:  0.1782178217821782\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5297348484848485 Recall:  0.0625 Precision:  0.5 F1:  0.1111111111111111\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.954335260115607 MSE:  0.04566473988439306 UAR:  0.5181439393939394 Recall:  0.0375 Precision:  0.6 F1:  0.07058823529411765\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.4993939393939394 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.5903030303030303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "d6e8497a-ab2a-40b9-8964-47e024e08d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "d1538257-af06-46d4-8898-2b8ee1be2a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "8794d841-ee0b-472f-b529-53ad973b3e65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.8549132947976879 MSE:  0.14508670520231215 UAR:  0.6979545454545455 Recall:  0.525 Precision:  0.16470588235294117 F1:  0.2507462686567164\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9260115606936417 MSE:  0.07398843930635839 UAR:  0.6460227272727272 Recall:  0.3375 Precision:  0.2647058823529412 F1:  0.29670329670329665\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.946242774566474 MSE:  0.05375722543352601 UAR:  0.5852651515151515 Recall:  0.1875 Precision:  0.3488372093023256 F1:  0.2439024390243903\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.954335260115607 MSE:  0.04566473988439306 UAR:  0.5716666666666667 Recall:  0.15 Precision:  0.5217391304347826 F1:  0.23300970873786406\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.5350757575757575 Recall:  0.075 Precision:  0.42857142857142855 F1:  0.1276595744680851\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5118939393939393 Recall:  0.025 Precision:  0.5 F1:  0.047619047619047616\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6979545454545455\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f801e2ca-9dbd-4ab0-be18-ee5b17595d12",
   "metadata": {},
   "source": [
    "### STAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bec91198-4538-4600-8e2e-80bd9db5d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_func = compute_descriptor\n",
    "stat_name = \"STAT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b1d837-6fb7-4939-ae36-aa68002b8aa1",
   "metadata": {},
   "source": [
    "#### Traditional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6fb3ffde-c5e6-49a9-b6a8-da7aead5acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "val_pickle = FEATURES_DIR + 'val_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)\n",
    "filename2features_val = load_features(val_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e47783d7-95c5-43ec-ac8e-547538c577ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n",
      "Val:  1720\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))\n",
    "print(\"Val: \", len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fc818614-6add-40d1-ac71-c5a46a34637b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "test:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n",
      "val:\n",
      "0 1537/1720: 89.36046511627907%\n",
      "1 183/1720: 10.63953488372093%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"test:\")\n",
    "print_classes(get_labels(filename2features_test))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0ba122-414c-456d-929d-8f54fecd08b9",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "27f796b7-f23c-4d35-9d4d-0f4c72069b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dffd4aa3-1796-4df5-afc5-dc4baf388e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "70a36e08-e01a-469d-8941-a6f6acc0d1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 3072) (5482,)\n",
      "(1723, 128, 3072) (1723,)\n",
      "(1720, 128, 3072) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "83d9f748-9f6d-4d41-8519-14b0cdb574a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5234  248] {0: 1.0, 1: 21.10483870967742} 2 [0 1]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a8da3d15-a854-4f4d-b534-776a5fa6d313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1573376   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1576962 (6.02 MB)\n",
      "Trainable params: 1576962 (6.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "#save_best_model = SaveBestModelByUAR(X_subsample_val, y_subsample_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8f4b80ec-048d-4816-9ff6-3e4c060e1cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 78ms/step - loss: 1.3927 - acc: 0.6441 - auc: 0.5977 - binary_accuracy: 0.6441 - recall_4: 0.5444 - precision_4: 0.0684 - val_loss: 0.8600 - val_acc: 0.3843 - val_auc: 0.6910 - val_binary_accuracy: 0.3843 - val_recall_4: 0.8907 - val_precision_4: 0.1356\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 1.1498 - acc: 0.6946 - auc: 0.7366 - binary_accuracy: 0.6946 - recall_4: 0.6452 - precision_4: 0.0916 - val_loss: 0.8465 - val_acc: 0.4826 - val_auc: 0.6889 - val_binary_accuracy: 0.4826 - val_recall_4: 0.8306 - val_precision_4: 0.1503\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 1.0800 - acc: 0.7588 - auc: 0.7820 - binary_accuracy: 0.7588 - recall_4: 0.6613 - precision_4: 0.1170 - val_loss: 0.5910 - val_acc: 0.7215 - val_auc: 0.6926 - val_binary_accuracy: 0.7215 - val_recall_4: 0.5246 - val_precision_4: 0.1967\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 1.0448 - acc: 0.7554 - auc: 0.7953 - binary_accuracy: 0.7554 - recall_4: 0.7056 - precision_4: 0.1213 - val_loss: 0.9203 - val_acc: 0.4651 - val_auc: 0.6894 - val_binary_accuracy: 0.4651 - val_recall_4: 0.8306 - val_precision_4: 0.1460\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 1.0086 - acc: 0.7406 - auc: 0.8146 - binary_accuracy: 0.7406 - recall_4: 0.7177 - precision_4: 0.1163 - val_loss: 0.5619 - val_acc: 0.7244 - val_auc: 0.6873 - val_binary_accuracy: 0.7244 - val_recall_4: 0.4918 - val_precision_4: 0.1911\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.9823 - acc: 0.7685 - auc: 0.8260 - binary_accuracy: 0.7685 - recall_4: 0.6976 - precision_4: 0.1266 - val_loss: 0.8071 - val_acc: 0.5890 - val_auc: 0.6948 - val_binary_accuracy: 0.5890 - val_recall_4: 0.6940 - val_precision_4: 0.1632\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.9353 - acc: 0.7979 - auc: 0.8456 - binary_accuracy: 0.7979 - recall_4: 0.7298 - precision_4: 0.1481 - val_loss: 0.9234 - val_acc: 0.5122 - val_auc: 0.6946 - val_binary_accuracy: 0.5122 - val_recall_4: 0.7923 - val_precision_4: 0.1533\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 0.9509 - acc: 0.7537 - auc: 0.8400 - binary_accuracy: 0.7537 - recall_4: 0.7863 - precision_4: 0.1307 - val_loss: 0.6728 - val_acc: 0.6686 - val_auc: 0.6936 - val_binary_accuracy: 0.6686 - val_recall_4: 0.6011 - val_precision_4: 0.1812\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.9040 - acc: 0.7826 - auc: 0.8568 - binary_accuracy: 0.7826 - recall_4: 0.7782 - precision_4: 0.1451 - val_loss: 0.4596 - val_acc: 0.7895 - val_auc: 0.6764 - val_binary_accuracy: 0.7895 - val_recall_4: 0.3279 - val_precision_4: 0.2007\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.8969 - acc: 0.7848 - auc: 0.8604 - binary_accuracy: 0.7848 - recall_4: 0.7742 - precision_4: 0.1459 - val_loss: 0.6009 - val_acc: 0.7058 - val_auc: 0.6925 - val_binary_accuracy: 0.7058 - val_recall_4: 0.5410 - val_precision_4: 0.1900\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.9075 - acc: 0.7822 - auc: 0.8548 - binary_accuracy: 0.7822 - recall_4: 0.7621 - precision_4: 0.1427 - val_loss: 0.8495 - val_acc: 0.5756 - val_auc: 0.6869 - val_binary_accuracy: 0.5756 - val_recall_4: 0.6776 - val_precision_4: 0.1560\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.8336 - acc: 0.7877 - auc: 0.8820 - binary_accuracy: 0.7877 - recall_4: 0.8105 - precision_4: 0.1525 - val_loss: 0.4548 - val_acc: 0.7831 - val_auc: 0.6861 - val_binary_accuracy: 0.7831 - val_recall_4: 0.3770 - val_precision_4: 0.2104\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.8149 - acc: 0.8105 - auc: 0.8874 - binary_accuracy: 0.8105 - recall_4: 0.8185 - precision_4: 0.1696 - val_loss: 0.4445 - val_acc: 0.8029 - val_auc: 0.6755 - val_binary_accuracy: 0.8029 - val_recall_4: 0.3497 - val_precision_4: 0.2254\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.7838 - acc: 0.8112 - auc: 0.8965 - binary_accuracy: 0.8112 - recall_4: 0.8145 - precision_4: 0.1696 - val_loss: 0.6266 - val_acc: 0.7041 - val_auc: 0.6776 - val_binary_accuracy: 0.7041 - val_recall_4: 0.5246 - val_precision_4: 0.1853\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.8137 - acc: 0.8074 - auc: 0.8858 - binary_accuracy: 0.8074 - recall_4: 0.8065 - precision_4: 0.1656 - val_loss: 0.8422 - val_acc: 0.6058 - val_auc: 0.6851 - val_binary_accuracy: 0.6058 - val_recall_4: 0.6721 - val_precision_4: 0.1660\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.7549 - acc: 0.8061 - auc: 0.9040 - binary_accuracy: 0.8061 - recall_4: 0.8306 - precision_4: 0.1679 - val_loss: 0.4134 - val_acc: 0.8233 - val_auc: 0.6704 - val_binary_accuracy: 0.8233 - val_recall_4: 0.2787 - val_precision_4: 0.2287\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.7531 - acc: 0.8232 - auc: 0.9038 - binary_accuracy: 0.8232 - recall_4: 0.8185 - precision_4: 0.1801 - val_loss: 0.8158 - val_acc: 0.6140 - val_auc: 0.6840 - val_binary_accuracy: 0.6140 - val_recall_4: 0.6448 - val_precision_4: 0.1646\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.7126 - acc: 0.8178 - auc: 0.9169 - binary_accuracy: 0.8178 - recall_4: 0.8669 - precision_4: 0.1820 - val_loss: 0.5739 - val_acc: 0.7262 - val_auc: 0.6814 - val_binary_accuracy: 0.7262 - val_recall_4: 0.4973 - val_precision_4: 0.1936\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.6962 - acc: 0.8360 - auc: 0.9192 - binary_accuracy: 0.8360 - recall_4: 0.8548 - precision_4: 0.1972 - val_loss: 0.7487 - val_acc: 0.6552 - val_auc: 0.6828 - val_binary_accuracy: 0.6552 - val_recall_4: 0.6284 - val_precision_4: 0.1797\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.6892 - acc: 0.8280 - auc: 0.9210 - binary_accuracy: 0.8280 - recall_4: 0.8629 - precision_4: 0.1906 - val_loss: 0.5081 - val_acc: 0.7733 - val_auc: 0.6661 - val_binary_accuracy: 0.7733 - val_recall_4: 0.3989 - val_precision_4: 0.2068\n",
      "0.4134182035923004\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a651acf4-24ec-491d-9f65-419ac54f8a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3108480/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3a7b7c11-1c21-410f-b492-55c422a0cafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.3691236215902496 MSE:  0.6308763784097504 UAR:  0.5845363786540256 Recall:  0.8235294117647058 Precision:  0.06129597197898424 F1:  0.11409942950285247\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.5037724898432966 MSE:  0.4962275101567034 UAR:  0.5772750125691302 Recall:  0.6588235294117647 Precision:  0.06349206349206349 F1:  0.11582213029989658\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.6157864190365642 MSE:  0.3842135809634359 UAR:  0.6027257056668822 Recall:  0.5882352941176471 Precision:  0.07385524372230429 F1:  0.13123359580052496\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.7208357515960534 MSE:  0.2791642484039466 UAR:  0.6300904977375565 Recall:  0.5294117647058824 Precision:  0.09259259259259259 F1:  0.1576182136602452\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.8067324434126524 MSE:  0.19326755658734765 UAR:  0.6306507218271924 Recall:  0.43529411764705883 Precision:  0.11490683229813664 F1:  0.18181818181818185\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.8607080673244342 MSE:  0.13929193267556586 UAR:  0.6367305896717661 Recall:  0.38823529411764707 Precision:  0.1493212669683258 F1:  0.21568627450980393\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.9065583284968078 MSE:  0.0934416715031921 UAR:  0.6329598506069094 Recall:  0.32941176470588235 Precision:  0.21212121212121213 F1:  0.25806451612903225\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.9326755658734764 MSE:  0.0673244341265235 UAR:  0.6020792932557638 Recall:  0.23529411764705882 Precision:  0.28169014084507044 F1:  0.2564102564102564\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional Accuracy:  0.947185142193848 MSE:  0.05281485780615206 UAR:  0.5762479350714645 Recall:  0.16470588235294117 Precision:  0.4117647058823529 F1:  0.23529411764705885\n",
      "0.6 0.6367305896717661\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name, from_int=True)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "374cd953-c03c-42a3-aad8-e25f0bf6d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ad0e0cee-c777-433a-ad39-fa2691e44340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3108480/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "25a2004b-5c0b-43f3-8bc5-bab22fa583a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.387695879280325 MSE:  0.612304120719675 UAR:  0.5831501831501832 Recall:  0.8 Precision:  0.06148282097649186 F1:  0.11418975650713686\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.5972141613464886 MSE:  0.4027858386535113 UAR:  0.6096890038066509 Recall:  0.6235294117647059 Precision:  0.07412587412587412 F1:  0.1325\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.7446314567614626 MSE:  0.2553685432385374 UAR:  0.6202973497091144 Recall:  0.4823529411764706 Precision:  0.09382151029748284 F1:  0.15708812260536398\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.8270458502611724 MSE:  0.17295414973882764 UAR:  0.6301802772391008 Recall:  0.4117647058823529 Precision:  0.12367491166077739 F1:  0.19021739130434784\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.8810214741729542 MSE:  0.11897852582704585 UAR:  0.6306830424477483 Recall:  0.35294117647058826 Precision:  0.16666666666666666 F1:  0.22641509433962262\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.914103308183401 MSE:  0.08589669181659895 UAR:  0.6090425913955325 Recall:  0.27058823529411763 Precision:  0.21100917431192662 F1:  0.2371134020618557\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.9367382472431804 MSE:  0.0632617527568195 UAR:  0.5874847374847375 Recall:  0.2 Precision:  0.29310344827586204 F1:  0.23776223776223776\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.9483459082994776 MSE:  0.05165409170052235 UAR:  0.5712813330460389 Recall:  0.15294117647058825 Precision:  0.43333333333333335 F1:  0.22608695652173916\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_traditional_best Accuracy:  0.9529889727219966 MSE:  0.047011027278003485 UAR:  0.5402607196724843 Recall:  0.08235294117647059 Precision:  0.7 F1:  0.14736842105263157\n",
      "0.5 0.6306830424477483\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name, from_int=True)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2f4167-97b9-4cb2-8a6d-a79ffccd8484",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "fb88d2c9-ff2c-4944-8475-562c9c4b2ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_traditional\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "608b8049-de65-4d32-b0a8-6a1dde972ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5e7d1c72-6554-478a-a886-f58a6b854284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 128, 2560) (5482,)\n",
      "(1723, 128, 2560) (1723,)\n",
      "(1720, 128, 2560) (1720,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "X_subsample_val, y_subsample_val = get_samples(filename2features_val)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8c02b53b-a7a6-4261-90f1-9544a05a4b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_6 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_6[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_6[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0ba27305-f3ce-4da5-91a5-486964bfb8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 127ms/step - loss: 0.3520 - acc: 0.9435 - auc: 0.5372 - binary_accuracy: 0.9435 - recall_1: 0.0121 - precision_1: 0.0441 - val_loss: 0.3655 - val_acc: 0.8936 - val_auc: 0.6054 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1676 - acc: 0.9544 - auc: 0.7332 - binary_accuracy: 0.9544 - recall_1: 0.0081 - precision_1: 0.3333 - val_loss: 0.4156 - val_acc: 0.8936 - val_auc: 0.6291 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1589 - acc: 0.9533 - auc: 0.7800 - binary_accuracy: 0.9533 - recall_1: 0.0081 - precision_1: 0.1667 - val_loss: 0.3692 - val_acc: 0.8907 - val_auc: 0.6405 - val_binary_accuracy: 0.8907 - val_recall_1: 0.0328 - val_precision_1: 0.3529\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1570 - acc: 0.9538 - auc: 0.7916 - binary_accuracy: 0.9538 - recall_1: 0.0282 - precision_1: 0.3684 - val_loss: 0.4193 - val_acc: 0.8930 - val_auc: 0.6368 - val_binary_accuracy: 0.8930 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1648 - acc: 0.9526 - auc: 0.7644 - binary_accuracy: 0.9526 - recall_1: 0.0403 - precision_1: 0.3125 - val_loss: 0.3956 - val_acc: 0.8936 - val_auc: 0.6295 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1544 - acc: 0.9557 - auc: 0.8021 - binary_accuracy: 0.9557 - recall_1: 0.0524 - precision_1: 0.6190 - val_loss: 0.3884 - val_acc: 0.8942 - val_auc: 0.6372 - val_binary_accuracy: 0.8942 - val_recall_1: 0.0164 - val_precision_1: 0.6000\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1498 - acc: 0.9564 - auc: 0.8126 - binary_accuracy: 0.9564 - recall_1: 0.0726 - precision_1: 0.6667 - val_loss: 0.4350 - val_acc: 0.8936 - val_auc: 0.6258 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1505 - acc: 0.9562 - auc: 0.7941 - binary_accuracy: 0.9562 - recall_1: 0.0927 - precision_1: 0.6053 - val_loss: 0.4107 - val_acc: 0.8936 - val_auc: 0.6443 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1529 - acc: 0.9529 - auc: 0.8132 - binary_accuracy: 0.9529 - recall_1: 0.0565 - precision_1: 0.3684 - val_loss: 0.3560 - val_acc: 0.8901 - val_auc: 0.6600 - val_binary_accuracy: 0.8901 - val_recall_1: 0.0328 - val_precision_1: 0.3333\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1611 - acc: 0.9544 - auc: 0.7951 - binary_accuracy: 0.9544 - recall_1: 0.0766 - precision_1: 0.4750 - val_loss: 0.3404 - val_acc: 0.8919 - val_auc: 0.6709 - val_binary_accuracy: 0.8919 - val_recall_1: 0.0164 - val_precision_1: 0.3333\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1480 - acc: 0.9551 - auc: 0.8080 - binary_accuracy: 0.9551 - recall_1: 0.0645 - precision_1: 0.5333 - val_loss: 0.3748 - val_acc: 0.8791 - val_auc: 0.6659 - val_binary_accuracy: 0.8791 - val_recall_1: 0.0546 - val_precision_1: 0.2222\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1393 - acc: 0.9577 - auc: 0.8477 - binary_accuracy: 0.9577 - recall_1: 0.1169 - precision_1: 0.6905 - val_loss: 0.4060 - val_acc: 0.8843 - val_auc: 0.6437 - val_binary_accuracy: 0.8843 - val_recall_1: 0.0328 - val_precision_1: 0.2143\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1391 - acc: 0.9584 - auc: 0.8543 - binary_accuracy: 0.9584 - recall_1: 0.1694 - precision_1: 0.6562 - val_loss: 0.4013 - val_acc: 0.8913 - val_auc: 0.6270 - val_binary_accuracy: 0.8913 - val_recall_1: 0.0055 - val_precision_1: 0.1667\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1430 - acc: 0.9564 - auc: 0.8307 - binary_accuracy: 0.9564 - recall_1: 0.1250 - precision_1: 0.5849 - val_loss: 0.4422 - val_acc: 0.8936 - val_auc: 0.6349 - val_binary_accuracy: 0.8936 - val_recall_1: 0.0164 - val_precision_1: 0.5000\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1403 - acc: 0.9593 - auc: 0.8408 - binary_accuracy: 0.9593 - recall_1: 0.1532 - precision_1: 0.7451 - val_loss: 0.3936 - val_acc: 0.8860 - val_auc: 0.6520 - val_binary_accuracy: 0.8860 - val_recall_1: 0.0273 - val_precision_1: 0.2174\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1331 - acc: 0.9599 - auc: 0.8623 - binary_accuracy: 0.9599 - recall_1: 0.1815 - precision_1: 0.7258 - val_loss: 0.4326 - val_acc: 0.8890 - val_auc: 0.6155 - val_binary_accuracy: 0.8890 - val_recall_1: 0.0109 - val_precision_1: 0.1667\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1567 - acc: 0.9579 - auc: 0.8211 - binary_accuracy: 0.9579 - recall_1: 0.1855 - precision_1: 0.6133 - val_loss: 0.6409 - val_acc: 0.8901 - val_auc: 0.5315 - val_binary_accuracy: 0.8901 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1939 - acc: 0.9513 - auc: 0.7187 - binary_accuracy: 0.9513 - recall_1: 0.0927 - precision_1: 0.3538 - val_loss: 0.4528 - val_acc: 0.8924 - val_auc: 0.6278 - val_binary_accuracy: 0.8924 - val_recall_1: 0.0109 - val_precision_1: 0.3333\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.1382 - acc: 0.9582 - auc: 0.8531 - binary_accuracy: 0.9582 - recall_1: 0.1532 - precision_1: 0.6667 - val_loss: 0.4255 - val_acc: 0.8831 - val_auc: 0.6076 - val_binary_accuracy: 0.8831 - val_recall_1: 0.0328 - val_precision_1: 0.2000\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1471 - acc: 0.9573 - auc: 0.8318 - binary_accuracy: 0.9573 - recall_1: 0.1653 - precision_1: 0.6029 - val_loss: 0.3628 - val_acc: 0.8831 - val_auc: 0.6370 - val_binary_accuracy: 0.8831 - val_recall_1: 0.0273 - val_precision_1: 0.1786\n",
      "0.340364933013916\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_val,y_subsample_val))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "7080943c-7fd4-4777-b91c-2f4484d5747b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0ca56ac7-b71b-4f08-a019-10e7a4b62d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.8415554265815438 MSE:  0.1584445734184562 UAR:  0.6043489190548015 Recall:  0.3411764705882353 Precision:  0.11788617886178862 F1:  0.17522658610271902\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.930354033662217 MSE:  0.06964596633778293 UAR:  0.5450872656755009 Recall:  0.11764705882352941 Precision:  0.18181818181818182 F1:  0.14285714285714285\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9437028438769588 MSE:  0.05629715612304121 UAR:  0.5409538174244057 Recall:  0.09411764705882353 Precision:  0.2857142857142857 F1:  0.1415929203539823\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.947185142193848 MSE:  0.05281485780615206 UAR:  0.526054011348129 Recall:  0.058823529411764705 Precision:  0.3125 F1:  0.09900990099009901\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5281907634848811 Recall:  0.058823529411764705 Precision:  0.5555555555555556 F1:  0.10638297872340426\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5229189111542053 Recall:  0.047058823529411764 Precision:  0.6666666666666666 F1:  0.08791208791208792\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9529889727219966 MSE:  0.047011027278003485 UAR:  0.5235294117647059 Recall:  0.047058823529411764 Precision:  1.0 F1:  0.0898876404494382\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5176470588235295 Recall:  0.03529411764705882 Precision:  1.0 F1:  0.06818181818181818\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional Accuracy:  0.9518282066163668 MSE:  0.0481717933836332 UAR:  0.5117647058823529 Recall:  0.023529411764705882 Precision:  1.0 F1:  0.04597701149425288\n",
      "0.1 0.6043489190548015\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6cd91b09-e043-4835-970a-a520f723e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "1102e768-8afc-4818-bdfe-0ca211f5d8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "630afd34-61db-41ac-b33c-20435d732541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.8340104468949506 MSE:  0.16598955310504934 UAR:  0.6282661782661783 Recall:  0.4 Precision:  0.12639405204460966 F1:  0.192090395480226\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9297736506094022 MSE:  0.0702263493905978 UAR:  0.5949759390935861 Recall:  0.2235294117647059 Precision:  0.25675675675675674 F1:  0.2389937106918239\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9477655252466628 MSE:  0.0522344747533372 UAR:  0.5653989801048624 Recall:  0.1411764705882353 Precision:  0.41379310344827586 F1:  0.21052631578947367\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5566867772750126 Recall:  0.11764705882352941 Precision:  0.5882352941176471 F1:  0.19607843137254902\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9529889727219966 MSE:  0.047011027278003485 UAR:  0.5402607196724843 Recall:  0.08235294117647059 Precision:  0.7 F1:  0.14736842105263157\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9524085896691816 MSE:  0.04759141033081834 UAR:  0.5288012640953818 Recall:  0.058823529411764705 Precision:  0.7142857142857143 F1:  0.10869565217391305\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.9500870574579222 MSE:  0.04991294254207777 UAR:  0.5052718523306758 Recall:  0.011764705882352941 Precision:  0.3333333333333333 F1:  0.022727272727272728\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.951247823563552 MSE:  0.04875217643644805 UAR:  0.5058823529411764 Recall:  0.011764705882352941 Precision:  1.0 F1:  0.023255813953488372\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_traditional_best Accuracy:  0.950667440510737 MSE:  0.04933255948926291 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6282661782661783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a7d4d5-20fb-4961-b221-098b4482b792",
   "metadata": {},
   "source": [
    "#### Balanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7b1434bc-76dc-4988-bdc9-29f66a2bfeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = FEATURES_DIR + 'train_features_engagement_{}.pickle'.format(base_model_key)\n",
    "test_pickle = FEATURES_DIR + 'test_features_engagement_{}.pickle'.format(base_model_key)\n",
    "filename2features_train = load_features(train_pickle)\n",
    "filename2features_test = load_features(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ac55f6c0-5d95-484a-92dd-71ceb8636d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  5482\n",
      "Test:  1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", len(filename2features_train))\n",
    "print(\"Test: \", len(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7d07b394-5eb5-4ece-9822-9129315fc6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5234/5482: 95.4761036118205%\n",
      "1 248/5482: 4.523896388179496%\n",
      "val:\n",
      "0 1638/1723: 95.06674405107371%\n",
      "1 85/1723: 4.933255948926291%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "902ac7f2-9fd3-4de8-9322-dba6196e95f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5482, 2048) (5482,)\n",
      "(1723, 2048) (1723,)\n",
      "(7205, 2048) (7205,)\n",
      "[0 1] [6872  333]\n",
      "7205\n",
      "5475\n",
      "1730\n"
     ]
    }
   ],
   "source": [
    "filename2features_train, filename2features_test = prepare_new_dataset(filename2features_train, filename2features_test, 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "be6f0524-1a73-49ec-be0a-955400a7a2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0 5222/5475: 95.37899543378995%\n",
      "1 253/5475: 4.621004566210046%\n",
      "val:\n",
      "0 1650/1730: 95.3757225433526%\n",
      "1 80/1730: 4.624277456647399%\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\")\n",
    "print_classes(get_labels(filename2features_train))\n",
    "print(\"val:\")\n",
    "print_classes(get_labels(filename2features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156a9d9e-4f17-4833-a59f-36d38fc6ca05",
   "metadata": {},
   "source": [
    "##### Single attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bad64f0b-0aa8-40e8-84b8-201210281540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"single_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9b2070a1-a5ba-4102-a979-6754f4230917",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ce4789d3-6ca1-499a-9db3-ad1f76088a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 3072) (5475,)\n",
      "(1730, 128, 3072) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6162ddd2-60ec-4abc-b801-1d300576c304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5222  253] {0: 1.0, 1: 20.640316205533598} 2 [0 1]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_subsample_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "117375e1-6e5e-41e1-a642-43ca7909a654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 3072)]         0         []                            \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              3073      ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 3072, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 3072)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 3072)           0         ['image_set[0][0]',           \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 3072)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " hidden_FC (Dense)           (None, 512)                  1573376   ['context[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 1)                    513       ['hidden_FC[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1576962 (6.02 MB)\n",
      "Trainable params: 1576962 (6.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_single_attention(FEATURE_VECTOR_DIM, N_CLASSES)\n",
    "#save_best_model = SaveBestModelByUAR(X_subsample_test, y_subsample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f2125369-a23b-4b97-bb1b-6808d04e66b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 5s 84ms/step - loss: 1.3211 - acc: 0.6230 - auc: 0.6326 - binary_accuracy: 0.6230 - recall_5: 0.5692 - precision_5: 0.0686 - val_loss: 0.4929 - val_acc: 0.8549 - val_auc: 0.7493 - val_binary_accuracy: 0.8549 - val_recall_5: 0.4750 - val_precision_5: 0.1538\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 1.1427 - acc: 0.7366 - auc: 0.7472 - binary_accuracy: 0.7366 - recall_5: 0.6166 - precision_5: 0.1039 - val_loss: 0.8909 - val_acc: 0.3908 - val_auc: 0.7612 - val_binary_accuracy: 0.3908 - val_recall_5: 0.9125 - val_precision_5: 0.0652\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 1.0640 - acc: 0.7251 - auc: 0.7860 - binary_accuracy: 0.7251 - recall_5: 0.7115 - precision_5: 0.1117 - val_loss: 0.5565 - val_acc: 0.7428 - val_auc: 0.7623 - val_binary_accuracy: 0.7428 - val_recall_5: 0.7000 - val_precision_5: 0.1174\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 1.0084 - acc: 0.7644 - auc: 0.8146 - binary_accuracy: 0.7644 - recall_5: 0.6917 - precision_5: 0.1262 - val_loss: 0.5635 - val_acc: 0.7243 - val_auc: 0.7747 - val_binary_accuracy: 0.7243 - val_recall_5: 0.7250 - val_precision_5: 0.1131\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 1.0100 - acc: 0.7428 - auc: 0.8095 - binary_accuracy: 0.7428 - recall_5: 0.6719 - precision_5: 0.1137 - val_loss: 0.6391 - val_acc: 0.6364 - val_auc: 0.7761 - val_binary_accuracy: 0.6364 - val_recall_5: 0.7875 - val_precision_5: 0.0933\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.9523 - acc: 0.7679 - auc: 0.8404 - binary_accuracy: 0.7679 - recall_5: 0.7628 - precision_5: 0.1375 - val_loss: 0.4184 - val_acc: 0.8220 - val_auc: 0.7700 - val_binary_accuracy: 0.8220 - val_recall_5: 0.6125 - val_precision_5: 0.1503\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 0.9195 - acc: 0.7653 - auc: 0.8492 - binary_accuracy: 0.7653 - recall_5: 0.7984 - precision_5: 0.1407 - val_loss: 0.5166 - val_acc: 0.7491 - val_auc: 0.7754 - val_binary_accuracy: 0.7491 - val_recall_5: 0.6750 - val_precision_5: 0.1169\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.8765 - acc: 0.7903 - auc: 0.8664 - binary_accuracy: 0.7903 - recall_5: 0.7708 - precision_5: 0.1518 - val_loss: 0.5065 - val_acc: 0.7578 - val_auc: 0.7712 - val_binary_accuracy: 0.7578 - val_recall_5: 0.6625 - val_precision_5: 0.1191\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 0.8581 - acc: 0.7881 - auc: 0.8717 - binary_accuracy: 0.7881 - recall_5: 0.7747 - precision_5: 0.1509 - val_loss: 0.8086 - val_acc: 0.5775 - val_auc: 0.7760 - val_binary_accuracy: 0.5775 - val_recall_5: 0.8125 - val_precision_5: 0.0832\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.8470 - acc: 0.7890 - auc: 0.8742 - binary_accuracy: 0.7890 - recall_5: 0.7787 - precision_5: 0.1520 - val_loss: 0.6567 - val_acc: 0.6659 - val_auc: 0.7787 - val_binary_accuracy: 0.6659 - val_recall_5: 0.7875 - val_precision_5: 0.1010\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.8337 - acc: 0.7766 - auc: 0.8787 - binary_accuracy: 0.7766 - recall_5: 0.8379 - precision_5: 0.1521 - val_loss: 0.4287 - val_acc: 0.8081 - val_auc: 0.7633 - val_binary_accuracy: 0.8081 - val_recall_5: 0.6000 - val_precision_5: 0.1379\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.8139 - acc: 0.8038 - auc: 0.8852 - binary_accuracy: 0.8038 - recall_5: 0.7905 - precision_5: 0.1638 - val_loss: 0.5867 - val_acc: 0.7035 - val_auc: 0.7654 - val_binary_accuracy: 0.7035 - val_recall_5: 0.6750 - val_precision_5: 0.0998\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.7561 - acc: 0.8126 - auc: 0.9025 - binary_accuracy: 0.8126 - recall_5: 0.8261 - precision_5: 0.1755 - val_loss: 0.4993 - val_acc: 0.7595 - val_auc: 0.7575 - val_binary_accuracy: 0.7595 - val_recall_5: 0.6125 - val_precision_5: 0.1129\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.7680 - acc: 0.8091 - auc: 0.8986 - binary_accuracy: 0.8091 - recall_5: 0.8300 - precision_5: 0.1733 - val_loss: 0.3948 - val_acc: 0.8312 - val_auc: 0.7629 - val_binary_accuracy: 0.8312 - val_recall_5: 0.5750 - val_precision_5: 0.1513\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.7134 - acc: 0.8214 - auc: 0.9134 - binary_accuracy: 0.8214 - recall_5: 0.8735 - precision_5: 0.1894 - val_loss: 0.3843 - val_acc: 0.8364 - val_auc: 0.7540 - val_binary_accuracy: 0.8364 - val_recall_5: 0.5625 - val_precision_5: 0.1536\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 0.6900 - acc: 0.8369 - auc: 0.9198 - binary_accuracy: 0.8369 - recall_5: 0.8656 - precision_5: 0.2032 - val_loss: 0.6159 - val_acc: 0.7012 - val_auc: 0.7582 - val_binary_accuracy: 0.7012 - val_recall_5: 0.7000 - val_precision_5: 0.1020\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 0.7164 - acc: 0.8104 - auc: 0.9112 - binary_accuracy: 0.8104 - recall_5: 0.8696 - precision_5: 0.1796 - val_loss: 0.8801 - val_acc: 0.5688 - val_auc: 0.7522 - val_binary_accuracy: 0.5688 - val_recall_5: 0.7500 - val_precision_5: 0.0763\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 0.6987 - acc: 0.8243 - auc: 0.9157 - binary_accuracy: 0.8243 - recall_5: 0.8498 - precision_5: 0.1888 - val_loss: 0.3859 - val_acc: 0.8277 - val_auc: 0.7452 - val_binary_accuracy: 0.8277 - val_recall_5: 0.5500 - val_precision_5: 0.1438\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 0.6475 - acc: 0.8411 - auc: 0.9286 - binary_accuracy: 0.8411 - recall_5: 0.8538 - precision_5: 0.2059 - val_loss: 0.5271 - val_acc: 0.7514 - val_auc: 0.7437 - val_binary_accuracy: 0.7514 - val_recall_5: 0.6375 - val_precision_5: 0.1128\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 2s 41ms/step - loss: 0.6145 - acc: 0.8453 - auc: 0.9362 - binary_accuracy: 0.8453 - recall_5: 0.8775 - precision_5: 0.2139 - val_loss: 0.5481 - val_acc: 0.7457 - val_auc: 0.7284 - val_binary_accuracy: 0.7457 - val_recall_5: 0.6375 - val_precision_5: 0.1104\n",
      "0.384337842464447\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test), class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c0cfd3c6-9226-4d4c-9466-510b91686c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3108480/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8a24554b-69e0-48eb-b6a2-a5c5488de39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.3861271676300578 MSE:  0.6138728323699422 UAR:  0.5889772727272727 Recall:  0.8125 Precision:  0.05845323741007194 F1:  0.10906040268456375\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.5173410404624278 MSE:  0.48265895953757226 UAR:  0.6399242424242424 Recall:  0.775 Precision:  0.07053469852104664 F1:  0.12930135557872782\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.6086705202312138 MSE:  0.3913294797687861 UAR:  0.6521212121212121 Recall:  0.7 Precision:  0.07898448519040903 F1:  0.14195183776932827\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.6826589595375723 MSE:  0.3173410404624277 UAR:  0.6671212121212121 Recall:  0.65 Precision:  0.09075043630017451 F1:  0.1592649310872894\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.7450867052023121 MSE:  0.2549132947976879 UAR:  0.6939015151515151 Recall:  0.6375 Precision:  0.1101511879049676 F1:  0.1878453038674033\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.793063583815029 MSE:  0.2069364161849711 UAR:  0.6952651515151516 Recall:  0.5875 Precision:  0.12634408602150538 F1:  0.20796460176991152\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.8404624277456647 MSE:  0.15953757225433526 UAR:  0.6963257575757575 Recall:  0.5375 Precision:  0.1524822695035461 F1:  0.23756906077348067\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.8861271676300578 MSE:  0.1138728323699422 UAR:  0.6726893939393939 Recall:  0.4375 Precision:  0.18716577540106952 F1:  0.26217228464419473\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced Accuracy:  0.9260115606936417 MSE:  0.07398843930635839 UAR:  0.6043939393939394 Recall:  0.25 Precision:  0.22727272727272727 F1:  0.23809523809523808\n",
      "0.7 0.6963257575757575\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name, from_int=True)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "625ffe2a-4b86-4633-981f-bddda0428232",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "042e8ba4-5aac-4844-9efd-4205daee82ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_3108480/1443316788.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ccaa38e3-93d9-4c1c-8877-34ba13aee9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.4416184971098266 MSE:  0.5583815028901734 UAR:  0.6240151515151515 Recall:  0.825 Precision:  0.06483300589390963 F1:  0.12021857923497267\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.6098265895953757 MSE:  0.3901734104046243 UAR:  0.6765151515151515 Recall:  0.75 Precision:  0.08391608391608392 F1:  0.1509433962264151\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.7127167630057804 MSE:  0.28728323699421965 UAR:  0.6828787878787879 Recall:  0.65 Precision:  0.09980806142034548 F1:  0.173044925124792\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.7803468208092486 MSE:  0.21965317919075145 UAR:  0.6885984848484848 Recall:  0.5875 Precision:  0.11928934010152284 F1:  0.19831223628691982\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.8323699421965318 MSE:  0.1676300578034682 UAR:  0.698030303030303 Recall:  0.55 Precision:  0.1476510067114094 F1:  0.23280423280423282\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.8734104046242774 MSE:  0.12658959537572254 UAR:  0.6957575757575758 Recall:  0.5 Precision:  0.182648401826484 F1:  0.26755852842809363\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.9098265895953758 MSE:  0.09017341040462427 UAR:  0.6970075757575758 Recall:  0.4625 Precision:  0.24666666666666667 F1:  0.3217391304347826\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.9364161849710982 MSE:  0.06358381502890173 UAR:  0.6693181818181818 Recall:  0.375 Precision:  0.3333333333333333 F1:  0.35294117647058826\n",
      "Metric_name:  mobilenet_7.h5_DAiSEE_2_STAT_single_attention_balanced_best Accuracy:  0.9479768786127167 MSE:  0.05202312138728324 UAR:  0.5921212121212122 Recall:  0.2 Precision:  0.38095238095238093 F1:  0.2622950819672132\n",
      "0.5 0.698030303030303\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name, from_int=True)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a082a6-5f3f-4333-9dba-f5c4da3068dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "cbdd509c-a9c1-4643-a90a-0e5444042907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced\n"
     ]
    }
   ],
   "source": [
    "metric_name = get_metric_name(base_model_key, DATASET_NAME, N_CLASSES, stat_name, \"self_attention_balanced\")\n",
    "print(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "aab63e26-36d4-43d4-9b62-5c79b51ffc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCATENATE_STAT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "fd2ee70f-d2c8-4c48-ad21-3911095c1f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5475, 128, 2560) (5475,)\n",
      "(1730, 128, 2560) (1730,)\n"
     ]
    }
   ],
   "source": [
    "X_subsample_train, y_subsample_train = get_samples(filename2features_train)\n",
    "X_subsample_test, y_subsample_test = get_samples(filename2features_test)\n",
    "FEATURE_VECTOR_DIM=X_subsample_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "34e2f941-ea41-4dba-8867-010ec222b472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_set (InputLayer)      [(None, None, 2560)]         0         []                            \n",
      "                                                                                                  \n",
      " query (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, None, 2560)           6553600   ['image_set[0][0]']           \n",
      "                                                                                                  \n",
      " attention_7 (Attention)     (None, None, 2560)           0         ['query[0][0]',               \n",
      "                                                                     'value[0][0]']               \n",
      "                                                                                                  \n",
      " e (Dense)                   (None, None, 1)              2561      ['attention_7[0][0]']         \n",
      "                                                                                                  \n",
      " alignment (Reshape)         (None, None)                 0         ['e[0][0]']                   \n",
      "                                                                                                  \n",
      " alpha (Activation)          (None, None)                 0         ['alignment[0][0]']           \n",
      "                                                                                                  \n",
      " repeat (RepeatVector)       (None, 2560, None)           0         ['alpha[0][0]']               \n",
      "                                                                                                  \n",
      " alpha_repeated (Permute)    (None, None, 2560)           0         ['repeat[0][0]']              \n",
      "                                                                                                  \n",
      " c (Multiply)                (None, None, 2560)           0         ['attention_7[0][0]',         \n",
      "                                                                     'alpha_repeated[0][0]']      \n",
      "                                                                                                  \n",
      " context (Lambda)            (None, 2560)                 0         ['c[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 1)                    2561      ['context[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13112322 (50.02 MB)\n",
      "Trainable params: 13112322 (50.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelAtn, save_best_model = get_self_attention(FEATURE_VECTOR_DIM, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "29a395ae-ab79-4bec-a5aa-21eddebe6ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 7s 125ms/step - loss: 0.3764 - acc: 0.9412 - auc: 0.5374 - binary_accuracy: 0.9412 - recall_3: 0.0277 - precision_3: 0.0843 - val_loss: 0.1875 - val_acc: 0.9526 - val_auc: 0.6787 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0125 - val_precision_3: 0.2500\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1737 - acc: 0.9540 - auc: 0.7014 - binary_accuracy: 0.9540 - recall_3: 0.0514 - precision_3: 0.5200 - val_loss: 0.1701 - val_acc: 0.9526 - val_auc: 0.7431 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0250 - val_precision_3: 0.3333\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1627 - acc: 0.9536 - auc: 0.7562 - binary_accuracy: 0.9536 - recall_3: 0.0435 - precision_3: 0.4783 - val_loss: 0.1690 - val_acc: 0.9526 - val_auc: 0.7421 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1558 - acc: 0.9563 - auc: 0.7868 - binary_accuracy: 0.9563 - recall_3: 0.0751 - precision_3: 0.7917 - val_loss: 0.1788 - val_acc: 0.9532 - val_auc: 0.7731 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1543 - acc: 0.9558 - auc: 0.7960 - binary_accuracy: 0.9558 - recall_3: 0.0870 - precision_3: 0.6667 - val_loss: 0.1673 - val_acc: 0.9468 - val_auc: 0.7855 - val_binary_accuracy: 0.9468 - val_recall_3: 0.0375 - val_precision_3: 0.1667\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1532 - acc: 0.9542 - auc: 0.8100 - binary_accuracy: 0.9542 - recall_3: 0.0672 - precision_3: 0.5312 - val_loss: 0.1618 - val_acc: 0.9509 - val_auc: 0.7852 - val_binary_accuracy: 0.9509 - val_recall_3: 0.0500 - val_precision_3: 0.3077\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1613 - acc: 0.9542 - auc: 0.7767 - binary_accuracy: 0.9542 - recall_3: 0.0830 - precision_3: 0.5250 - val_loss: 0.1652 - val_acc: 0.9538 - val_auc: 0.7618 - val_binary_accuracy: 0.9538 - val_recall_3: 0.0125 - val_precision_3: 0.5000\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1583 - acc: 0.9538 - auc: 0.7944 - binary_accuracy: 0.9538 - recall_3: 0.0711 - precision_3: 0.5000 - val_loss: 0.1699 - val_acc: 0.9538 - val_auc: 0.7600 - val_binary_accuracy: 0.9538 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1508 - acc: 0.9556 - auc: 0.8224 - binary_accuracy: 0.9556 - recall_3: 0.0909 - precision_3: 0.6389 - val_loss: 0.1673 - val_acc: 0.9468 - val_auc: 0.7807 - val_binary_accuracy: 0.9468 - val_recall_3: 0.0375 - val_precision_3: 0.1667\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1453 - acc: 0.9567 - auc: 0.8235 - binary_accuracy: 0.9567 - recall_3: 0.1186 - precision_3: 0.6818 - val_loss: 0.1636 - val_acc: 0.9462 - val_auc: 0.7945 - val_binary_accuracy: 0.9462 - val_recall_3: 0.0750 - val_precision_3: 0.2400\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1429 - acc: 0.9558 - auc: 0.8417 - binary_accuracy: 0.9558 - recall_3: 0.1502 - precision_3: 0.5846 - val_loss: 0.1630 - val_acc: 0.9526 - val_auc: 0.7949 - val_binary_accuracy: 0.9526 - val_recall_3: 0.0750 - val_precision_3: 0.4286\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1419 - acc: 0.9563 - auc: 0.8401 - binary_accuracy: 0.9563 - recall_3: 0.1225 - precision_3: 0.6458 - val_loss: 0.1636 - val_acc: 0.9480 - val_auc: 0.7922 - val_binary_accuracy: 0.9480 - val_recall_3: 0.0750 - val_precision_3: 0.2727\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1377 - acc: 0.9574 - auc: 0.8583 - binary_accuracy: 0.9574 - recall_3: 0.1502 - precision_3: 0.6786 - val_loss: 0.1665 - val_acc: 0.9532 - val_auc: 0.7744 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0625 - val_precision_3: 0.4545\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1382 - acc: 0.9569 - auc: 0.8516 - binary_accuracy: 0.9569 - recall_3: 0.1423 - precision_3: 0.6545 - val_loss: 0.1775 - val_acc: 0.9445 - val_auc: 0.7679 - val_binary_accuracy: 0.9445 - val_recall_3: 0.1625 - val_precision_3: 0.3095\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.1597 - acc: 0.9536 - auc: 0.7827 - binary_accuracy: 0.9536 - recall_3: 0.1265 - precision_3: 0.4923 - val_loss: 0.1692 - val_acc: 0.9543 - val_auc: 0.7693 - val_binary_accuracy: 0.9543 - val_recall_3: 0.0625 - val_precision_3: 0.5556\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1370 - acc: 0.9582 - auc: 0.8615 - binary_accuracy: 0.9582 - recall_3: 0.1581 - precision_3: 0.7143 - val_loss: 0.1664 - val_acc: 0.9503 - val_auc: 0.7886 - val_binary_accuracy: 0.9503 - val_recall_3: 0.1250 - val_precision_3: 0.3846\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1338 - acc: 0.9591 - auc: 0.8699 - binary_accuracy: 0.9591 - recall_3: 0.1897 - precision_3: 0.7164 - val_loss: 0.1720 - val_acc: 0.9538 - val_auc: 0.7680 - val_binary_accuracy: 0.9538 - val_recall_3: 0.0625 - val_precision_3: 0.5000\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1501 - acc: 0.9553 - auc: 0.8296 - binary_accuracy: 0.9553 - recall_3: 0.1462 - precision_3: 0.5606 - val_loss: 0.1714 - val_acc: 0.9532 - val_auc: 0.7667 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.1465 - acc: 0.9556 - auc: 0.8340 - binary_accuracy: 0.9556 - recall_3: 0.0949 - precision_3: 0.6316 - val_loss: 0.1637 - val_acc: 0.9468 - val_auc: 0.7976 - val_binary_accuracy: 0.9468 - val_recall_3: 0.0500 - val_precision_3: 0.2000\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.1520 - acc: 0.9527 - auc: 0.8244 - binary_accuracy: 0.9527 - recall_3: 0.1542 - precision_3: 0.4643 - val_loss: 0.1976 - val_acc: 0.9532 - val_auc: 0.6923 - val_binary_accuracy: 0.9532 - val_recall_3: 0.0125 - val_precision_3: 0.3333\n",
      "0.16184794902801514\n"
     ]
    }
   ],
   "source": [
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    if USE_GENERATORS:\n",
    "        modelAtn.fit(train_generator,steps_per_epoch=num_samples_train//BATCH_SIZE,\n",
    "                         epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                        validation_data=test_generator,validation_steps=num_samples_test//BATCH_SIZE, class_weight=class_weights)\n",
    "    else:\n",
    "        modelAtn.fit(X_subsample_train,y_subsample_train, batch_size=BATCH_SIZE, epochs=20, verbose=1, callbacks=[save_best_model],\n",
    "                 validation_data=(X_subsample_test,y_subsample_test))#, class_weight=class_weights)\n",
    "    best_model_weights = save_best_model.best_model_weights\n",
    "    print(save_best_model.best)\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "e836ff5f-12db-4576-be1b-04c07417e3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "0df23fb2-4448-4478-a1a7-3c28a7338a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9445086705202312 MSE:  0.055491329479768786 UAR:  0.5903030303030303 Recall:  0.2 Precision:  0.3333333333333333 F1:  0.25\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9520231213872833 MSE:  0.04797687861271676 UAR:  0.5526136363636364 Recall:  0.1125 Precision:  0.42857142857142855 F1:  0.1782178217821782\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5297348484848485 Recall:  0.0625 Precision:  0.5 F1:  0.1111111111111111\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.954335260115607 MSE:  0.04566473988439306 UAR:  0.5181439393939394 Recall:  0.0375 Precision:  0.6 F1:  0.07058823529411765\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.4993939393939394 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.5903030303030303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/echuraev/anaconda3/envs/sciense/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5c75661d-d621-4a06-9880-6abd58c42e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAtn.set_weights(best_model_weights)\n",
    "metric_name += \"_best\"\n",
    "weights_name = get_weights_path(metric_name)\n",
    "if os.path.isfile(weights_name):\n",
    "    load_weights(modelAtn, weights_name)\n",
    "else:\n",
    "    save_weights(modelAtn, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e574d8b5-fd23-4bc2-a87b-3e4e818fb430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/deelvin_disk/echuraev/tmp_dir/ipykernel_1535568/227606356.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_pred.append(float(pred[0]))\n"
     ]
    }
   ],
   "source": [
    "pred, test_labels = get_prediction(modelAtn, filename2features_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "5d30427b-9f03-48b8-928a-b1fa2687e3cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.8549132947976879 MSE:  0.14508670520231215 UAR:  0.6979545454545455 Recall:  0.525 Precision:  0.16470588235294117 F1:  0.2507462686567164\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9260115606936417 MSE:  0.07398843930635839 UAR:  0.6460227272727272 Recall:  0.3375 Precision:  0.2647058823529412 F1:  0.29670329670329665\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.946242774566474 MSE:  0.05375722543352601 UAR:  0.5852651515151515 Recall:  0.1875 Precision:  0.3488372093023256 F1:  0.2439024390243903\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.954335260115607 MSE:  0.04566473988439306 UAR:  0.5716666666666667 Recall:  0.15 Precision:  0.5217391304347826 F1:  0.23300970873786406\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9526011560693641 MSE:  0.047398843930635835 UAR:  0.5350757575757575 Recall:  0.075 Precision:  0.42857142857142855 F1:  0.1276595744680851\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.953757225433526 MSE:  0.046242774566473986 UAR:  0.5118939393939393 Recall:  0.025 Precision:  0.5 F1:  0.047619047619047616\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.5056439393939394 Recall:  0.0125 Precision:  0.3333333333333333 F1:  0.024096385542168676\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "Metric_name:  enet_b0_8_best_afew.pt_DAiSEE_2_std_self_attention_balanced_best Accuracy:  0.9531791907514451 MSE:  0.04682080924855491 UAR:  0.4996969696969697 Recall:  0.0 Precision:  0.0 F1:  0.0\n",
      "0.1 0.6979545454545455\n"
     ]
    }
   ],
   "source": [
    "max_uar = 0\n",
    "max_step = 0\n",
    "for i in range(1, 10):\n",
    "    step = i/10\n",
    "    p = prediction2bin(pred, step)\n",
    "    t = TABLE_NAME.split('.')\n",
    "    tn = '{}_{}.{}'.format(t[0], str(step), t[1])\n",
    "    _, _, uar, _, _, _ = print_results(p, test_labels, table_name=tn, metric_name=metric_name)\n",
    "    if uar > max_uar:\n",
    "        max_uar = uar\n",
    "        max_step = step\n",
    "\n",
    "print(max_step, max_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d19c65-0fae-4887-b25f-70dd28a60799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
